Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/24]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2827e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.289188
Average KL loss: 0.040061
Average total loss: 2.329249
tensor(-0.0005, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-5.6375e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.145351
Average KL loss: 0.716112
Average total loss: 1.861463
tensor(0.0026, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.6987e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.520145
Average KL loss: 0.869078
Average total loss: 1.389222
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4203e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.436012
Average KL loss: 0.737531
Average total loss: 1.173542
tensor(0.0030, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.0514e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.393579
Average KL loss: 0.672284
Average total loss: 1.065863
tensor(0.0030, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.8618e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.365791
Average KL loss: 0.643880
Average total loss: 1.009672
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.7083e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.349812
Average KL loss: 0.624357
Average total loss: 0.974169
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.1316e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.342791
Average KL loss: 0.614731
Average total loss: 0.957521
tensor(0.0031, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(3.0130e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.327976
Average KL loss: 0.607370
Average total loss: 0.935346
tensor(0.0032, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(6.2776e-11, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.322113
Average KL loss: 0.592123
Average total loss: 0.914237
tensor(0.0032, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-5.1023e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.315495
Average KL loss: 0.601501
Average total loss: 0.916996
tensor(0.0032, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-7.9388e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.316939
Average KL loss: 0.601162
Average total loss: 0.918102
tensor(0.0033, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(7.5680e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.311040
Average KL loss: 0.594276
Average total loss: 0.905316
tensor(0.0032, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(1.6640e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.305348
Average KL loss: 0.592750
Average total loss: 0.898098
tensor(0.0033, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-8.2241e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.303044
Average KL loss: 0.591958
Average total loss: 0.895001
tensor(0.0033, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-6.2300e-11, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.300768
Average KL loss: 0.592118
Average total loss: 0.892886
tensor(0.0034, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-2.1005e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.298350
Average KL loss: 0.591008
Average total loss: 0.889358
tensor(0.0033, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-3.3174e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.296021
Average KL loss: 0.590456
Average total loss: 0.886477
tensor(0.0033, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(3.2389e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.296012
Average KL loss: 0.587378
Average total loss: 0.883390
tensor(0.0034, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.5852e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.293133
Average KL loss: 0.586416
Average total loss: 0.879549
tensor(0.0034, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.9136e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.294510
Average KL loss: 0.598474
Average total loss: 0.892984
tensor(0.0035, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(3.4036e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.291490
Average KL loss: 0.590085
Average total loss: 0.881575
tensor(0.0034, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-6.5500e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.292926
Average KL loss: 0.597935
Average total loss: 0.890861
tensor(0.0034, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(1.2215e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.293196
Average KL loss: 0.602090
Average total loss: 0.895286
tensor(0.0034, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-8.1202e-11, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.289223
Average KL loss: 0.591562
Average total loss: 0.880785
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(1.1455e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.287915
Average KL loss: 0.590299
Average total loss: 0.878213
tensor(0.0034, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.7765e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.287750
Average KL loss: 0.593464
Average total loss: 0.881214
tensor(0.0035, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(3.4809e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.287398
Average KL loss: 0.599637
Average total loss: 0.887035
tensor(0.0035, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.1226e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.288272
Average KL loss: 0.592196
Average total loss: 0.880468
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.3782e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.288941
Average KL loss: 0.603572
Average total loss: 0.892513
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(1.8468e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.285232
Average KL loss: 0.591297
Average total loss: 0.876529
tensor(0.0035, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.6707e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.283630
Average KL loss: 0.594906
Average total loss: 0.878536
tensor(0.0035, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.7173e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.282637
Average KL loss: 0.597022
Average total loss: 0.879659
tensor(0.0035, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-9.3485e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.284345
Average KL loss: 0.603096
Average total loss: 0.887441
tensor(0.0036, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.4137e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.283552
Average KL loss: 0.601586
Average total loss: 0.885138
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.3543e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.280423
Average KL loss: 0.596371
Average total loss: 0.876794
tensor(0.0035, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.8968e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.279555
Average KL loss: 0.595641
Average total loss: 0.875196
tensor(0.0035, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.3612e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.281942
Average KL loss: 0.591345
Average total loss: 0.873286
tensor(0.0036, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(1.7419e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.280336
Average KL loss: 0.596158
Average total loss: 0.876494
tensor(0.0036, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-7.4728e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.279741
Average KL loss: 0.600794
Average total loss: 0.880535
tensor(0.0035, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.8782e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.281878
Average KL loss: 0.607070
Average total loss: 0.888948
tensor(0.0036, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.8576e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.280916
Average KL loss: 0.608459
Average total loss: 0.889376
tensor(0.0036, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.1440e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.279586
Average KL loss: 0.596571
Average total loss: 0.876157
tensor(0.0036, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.1439e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.279823
Average KL loss: 0.605538
Average total loss: 0.885361
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(2.6532e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.280433
Average KL loss: 0.601775
Average total loss: 0.882209
tensor(0.0036, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.0647e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.278471
Average KL loss: 0.597348
Average total loss: 0.875819
tensor(0.0036, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(3.8983e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.282639
Average KL loss: 0.606591
Average total loss: 0.889230
tensor(0.0036, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.4308e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.279193
Average KL loss: 0.606841
Average total loss: 0.886035
tensor(0.0037, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(3.6042e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.277485
Average KL loss: 0.600798
Average total loss: 0.878282
tensor(0.0037, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-6.4209e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.271894
Average KL loss: 0.449773
Average total loss: 0.721667
tensor(0.0036, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(9.4432e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.271184
Average KL loss: 0.363186
Average total loss: 0.634370
tensor(0.0036, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(6.7844e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.269213
Average KL loss: 0.351980
Average total loss: 0.621193
tensor(0.0036, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.7114e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.272578
Average KL loss: 0.347834
Average total loss: 0.620412
tensor(0.0036, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.4718e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.271190
Average KL loss: 0.346398
Average total loss: 0.617588
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.0560e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.268221
Average KL loss: 0.344081
Average total loss: 0.612302
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.6163e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.271276
Average KL loss: 0.343967
Average total loss: 0.615243
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.5653e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.269132
Average KL loss: 0.342558
Average total loss: 0.611690
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(4.2396e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.268553
Average KL loss: 0.340537
Average total loss: 0.609090
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.5950e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.271110
Average KL loss: 0.341577
Average total loss: 0.612687
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.6712e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.272191
Average KL loss: 0.341310
Average total loss: 0.613501
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.4696e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.271219
Average KL loss: 0.340490
Average total loss: 0.611709
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.7576e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.271893
Average KL loss: 0.340622
Average total loss: 0.612514
tensor(0.0036, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.5418e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.268789
Average KL loss: 0.339926
Average total loss: 0.608715
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.4118e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.271087
Average KL loss: 0.339647
Average total loss: 0.610734
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(7.1512e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.268659
Average KL loss: 0.338979
Average total loss: 0.607638
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.6156e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.270476
Average KL loss: 0.338504
Average total loss: 0.608981
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.3648e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.268464
Average KL loss: 0.337886
Average total loss: 0.606351
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.7964e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.270993
Average KL loss: 0.338341
Average total loss: 0.609335
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.0074e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.269026
Average KL loss: 0.337357
Average total loss: 0.606382
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(9.9147e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.272694
Average KL loss: 0.338395
Average total loss: 0.611088
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.4319e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.270672
Average KL loss: 0.338209
Average total loss: 0.608881
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(5.5886e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.271898
Average KL loss: 0.337798
Average total loss: 0.609696
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(4.0450e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.270949
Average KL loss: 0.338143
Average total loss: 0.609092
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.7193e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.272001
Average KL loss: 0.337458
Average total loss: 0.609460
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.5165e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.272469
Average KL loss: 0.337656
Average total loss: 0.610125
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.5301e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.272097
Average KL loss: 0.337488
Average total loss: 0.609585
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.4703e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.272357
Average KL loss: 0.338043
Average total loss: 0.610401
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-8.1203e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.271037
Average KL loss: 0.337406
Average total loss: 0.608443
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.1240e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.269141
Average KL loss: 0.331855
Average total loss: 0.600997
tensor(0.0036, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.5418e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.272343
Average KL loss: 0.324463
Average total loss: 0.596806
tensor(0.0036, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.6435e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.272154
Average KL loss: 0.320922
Average total loss: 0.593077
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.7165e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.271464
Average KL loss: 0.318787
Average total loss: 0.590251
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(8.9344e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.271010
Average KL loss: 0.317344
Average total loss: 0.588354
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(9.7046e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.270711
Average KL loss: 0.316216
Average total loss: 0.586928
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-8.8630e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.268705
Average KL loss: 0.315405
Average total loss: 0.584109
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.5717e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.268831
Average KL loss: 0.314690
Average total loss: 0.583521
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.3749e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.270702
Average KL loss: 0.314149
Average total loss: 0.584850
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(6.8923e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.269703
Average KL loss: 0.313709
Average total loss: 0.583412
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-5.0028e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.269508
Average KL loss: 0.313398
Average total loss: 0.582906
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.6536e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.271513
Average KL loss: 0.313109
Average total loss: 0.584622
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.2293e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.271181
Average KL loss: 0.312880
Average total loss: 0.584061
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.5348e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.270304
Average KL loss: 0.312716
Average total loss: 0.583020
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.4021e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.270426
Average KL loss: 0.312437
Average total loss: 0.582863
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.1796e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.269492
Average KL loss: 0.312280
Average total loss: 0.581773
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.6573e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.269992
Average KL loss: 0.312101
Average total loss: 0.582094
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.1592e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.269585
Average KL loss: 0.311951
Average total loss: 0.581536
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.8611e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.272320
Average KL loss: 0.311872
Average total loss: 0.584192
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.0375e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.269830
Average KL loss: 0.311840
Average total loss: 0.581670
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.5501e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.269908
Average KL loss: 0.311730
Average total loss: 0.581637
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(6.4544e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.273199
Average KL loss: 0.311605
Average total loss: 0.584804
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.6949e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.269257
Average KL loss: 0.311460
Average total loss: 0.580717
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.8166e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.270426
Average KL loss: 0.311352
Average total loss: 0.581778
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.8417e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.269905
Average KL loss: 0.311301
Average total loss: 0.581206
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.3467e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.272018
Average KL loss: 0.311317
Average total loss: 0.583335
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.5260e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.269081
Average KL loss: 0.311327
Average total loss: 0.580407
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.9533e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.268958
Average KL loss: 0.311220
Average total loss: 0.580178
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.2278e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.268912
Average KL loss: 0.311117
Average total loss: 0.580029
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.8627e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.271023
Average KL loss: 0.311031
Average total loss: 0.582054
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.2708e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.271030
Average KL loss: 0.311067
Average total loss: 0.582096
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.7226e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.269253
Average KL loss: 0.310970
Average total loss: 0.580223
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.6293e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.267037
Average KL loss: 0.310789
Average total loss: 0.577826
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-4.4764e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.268357
Average KL loss: 0.310750
Average total loss: 0.579107
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(9.5635e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.270859
Average KL loss: 0.310715
Average total loss: 0.581574
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(5.3577e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.270783
Average KL loss: 0.310747
Average total loss: 0.581530
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-6.7875e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.270188
Average KL loss: 0.310722
Average total loss: 0.580909
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.9149e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.270247
Average KL loss: 0.310667
Average total loss: 0.580914
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.5039e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.270168
Average KL loss: 0.310562
Average total loss: 0.580730
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.7820e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.270089
Average KL loss: 0.310509
Average total loss: 0.580598
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.1400e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.268962
Average KL loss: 0.310455
Average total loss: 0.579418
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.3080e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.270493
Average KL loss: 0.310471
Average total loss: 0.580965
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.9410e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.273030
Average KL loss: 0.310421
Average total loss: 0.583451
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(7.8842e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.270977
Average KL loss: 0.310405
Average total loss: 0.581383
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.1945e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.272283
Average KL loss: 0.310283
Average total loss: 0.582566
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.3879e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.269290
Average KL loss: 0.310063
Average total loss: 0.579353
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.2730e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.271862
Average KL loss: 0.309897
Average total loss: 0.581759
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.0235e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.272585
Average KL loss: 0.309776
Average total loss: 0.582361
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.5149e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.271462
Average KL loss: 0.309671
Average total loss: 0.581133
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.5447e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.270280
Average KL loss: 0.309575
Average total loss: 0.579856
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.5462e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.271030
Average KL loss: 0.309481
Average total loss: 0.580511
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.1861e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.272432
Average KL loss: 0.309397
Average total loss: 0.581829
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.5286e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.271936
Average KL loss: 0.309329
Average total loss: 0.581265
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.0925e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.272890
Average KL loss: 0.309259
Average total loss: 0.582149
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.5547e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.271467
Average KL loss: 0.309186
Average total loss: 0.580652
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(6.6767e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.270396
Average KL loss: 0.309148
Average total loss: 0.579544
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.2447e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.271227
Average KL loss: 0.309139
Average total loss: 0.580366
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(6.7773e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.270415
Average KL loss: 0.309130
Average total loss: 0.579545
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.0413e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.272176
Average KL loss: 0.309121
Average total loss: 0.581297
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.9457e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.270587
Average KL loss: 0.309112
Average total loss: 0.579698
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.3219e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.270174
Average KL loss: 0.309102
Average total loss: 0.579276
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(7.2867e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.270311
Average KL loss: 0.309094
Average total loss: 0.579406
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.8223e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.270129
Average KL loss: 0.309086
Average total loss: 0.579215
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.4316e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.271030
Average KL loss: 0.309078
Average total loss: 0.580109
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.0891e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.273179
Average KL loss: 0.309071
Average total loss: 0.582250
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-5.0499e-09, device='cuda:0')
 Percentile value: -5.059696832176992e-07
Non-zero model percentage: 80.0%, Non-zero mask percentage: 80.0%

--- Pruning Level [1/24]: ---
conv1.weight         | nonzeros =    1585 /    1728             ( 91.72%) | total_pruned =     143 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   33270 /   36864             ( 90.25%) | total_pruned =    3594 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   29346 /   36864             ( 79.61%) | total_pruned =    7518 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   27293 /   36864             ( 74.04%) | total_pruned =    9571 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   27909 /   36864             ( 75.71%) | total_pruned =    8955 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   47004 /   73728             ( 63.75%) | total_pruned =   26724 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   91245 /  147456             ( 61.88%) | total_pruned =   56211 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5686 /    8192             ( 69.41%) | total_pruned =    2506 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  102109 /  147456             ( 69.25%) | total_pruned =   45347 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  111076 /  147456             ( 75.33%) | total_pruned =   36380 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  171951 /  294912             ( 58.31%) | total_pruned =  122961 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     140 /     256             ( 54.69%) | total_pruned =     116 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  351058 /  589824             ( 59.52%) | total_pruned =  238766 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   21346 /   32768             ( 65.14%) | total_pruned =   11422 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      87 /     256             ( 33.98%) | total_pruned =     169 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  383671 /  589824             ( 65.05%) | total_pruned =  206153 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  433691 /  589824             ( 73.53%) | total_pruned =  156133 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  767710 / 1179648             ( 65.08%) | total_pruned =  411938 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     103 /     512             ( 20.12%) | total_pruned =     409 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1932945 / 2359296             ( 81.93%) | total_pruned =  426351 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     486 /     512             ( 94.92%) | total_pruned =      26 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     284 /     512             ( 55.47%) | total_pruned =     228 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  113619 /  131072             ( 86.68%) | total_pruned =   17453 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     277 /     512             ( 54.10%) | total_pruned =     235 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1941216 / 2359296             ( 82.28%) | total_pruned =  418080 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2332487 / 2359296             ( 98.86%) | total_pruned =   26809 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5098 /    5120             ( 99.57%) | total_pruned =      22 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 8943010, pruned : 2235752, total: 11178762, Compression rate :       1.25x  ( 20.00% pruned)
Train Epoch: 58/100 Loss: 0.014927 Accuracy: 88.95 100.00 % Best test Accuracy: 89.19%
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.3745e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.607433
Average KL loss: 0.798977
Average total loss: 1.406411
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.5801e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.512429
Average KL loss: 0.692759
Average total loss: 1.205188
tensor(0.0034, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.9871e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.435012
Average KL loss: 0.661857
Average total loss: 1.096869
tensor(0.0034, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.4747e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.395927
Average KL loss: 0.632634
Average total loss: 1.028561
tensor(0.0034, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.8761e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.376687
Average KL loss: 0.628473
Average total loss: 1.005160
tensor(0.0035, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.5925e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.353470
Average KL loss: 0.627576
Average total loss: 0.981046
tensor(0.0034, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.1624e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.343748
Average KL loss: 0.611966
Average total loss: 0.955714
tensor(0.0035, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-8.5148e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.338165
Average KL loss: 0.609306
Average total loss: 0.947471
tensor(0.0035, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-2.3641e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.328016
Average KL loss: 0.609153
Average total loss: 0.937169
tensor(0.0035, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.2656e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.323222
Average KL loss: 0.604966
Average total loss: 0.928188
tensor(0.0036, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(3.8258e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.317324
Average KL loss: 0.609159
Average total loss: 0.926483
tensor(0.0035, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-6.9631e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.312915
Average KL loss: 0.606370
Average total loss: 0.919285
tensor(0.0036, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.3516e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.307430
Average KL loss: 0.605084
Average total loss: 0.912514
tensor(0.0035, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-2.6536e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.306453
Average KL loss: 0.600671
Average total loss: 0.907123
tensor(0.0036, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-9.7975e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.302582
Average KL loss: 0.601057
Average total loss: 0.903640
tensor(0.0035, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.1400e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.303301
Average KL loss: 0.602503
Average total loss: 0.905804
tensor(0.0035, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-5.7459e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.302179
Average KL loss: 0.606792
Average total loss: 0.908971
tensor(0.0036, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-9.6004e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.302080
Average KL loss: 0.608424
Average total loss: 0.910504
tensor(0.0036, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(7.1709e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.297412
Average KL loss: 0.609500
Average total loss: 0.906912
tensor(0.0036, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.7672e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.294535
Average KL loss: 0.606733
Average total loss: 0.901268
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.0587e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.294275
Average KL loss: 0.603108
Average total loss: 0.897383
tensor(0.0037, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(6.0146e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.288510
Average KL loss: 0.604338
Average total loss: 0.892847
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.2454e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.291364
Average KL loss: 0.606516
Average total loss: 0.897879
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(4.8766e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.289694
Average KL loss: 0.602898
Average total loss: 0.892592
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.2765e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.293421
Average KL loss: 0.616944
Average total loss: 0.910365
tensor(0.0037, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(4.4018e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.288496
Average KL loss: 0.612782
Average total loss: 0.901278
tensor(0.0037, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(4.7703e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.289036
Average KL loss: 0.607093
Average total loss: 0.896130
tensor(0.0037, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(3.8989e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.288975
Average KL loss: 0.609410
Average total loss: 0.898385
tensor(0.0037, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(2.7717e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.282890
Average KL loss: 0.608731
Average total loss: 0.891621
tensor(0.0037, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-2.2668e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.285791
Average KL loss: 0.610064
Average total loss: 0.895855
tensor(0.0037, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.2578e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.289265
Average KL loss: 0.613661
Average total loss: 0.902926
tensor(0.0038, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(1.3100e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.289984
Average KL loss: 0.617491
Average total loss: 0.907475
tensor(0.0038, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(3.4384e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.286080
Average KL loss: 0.620876
Average total loss: 0.906956
tensor(0.0037, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.0748e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.286812
Average KL loss: 0.614211
Average total loss: 0.901023
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-4.5995e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.288039
Average KL loss: 0.620672
Average total loss: 0.908711
tensor(0.0037, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.9627e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.285041
Average KL loss: 0.619228
Average total loss: 0.904268
tensor(0.0038, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(1.2488e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.286031
Average KL loss: 0.613675
Average total loss: 0.899706
tensor(0.0037, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-4.9906e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.286556
Average KL loss: 0.620819
Average total loss: 0.907374
tensor(0.0038, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(1.0280e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.283682
Average KL loss: 0.618757
Average total loss: 0.902439
tensor(0.0038, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(1.1537e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.285588
Average KL loss: 0.615365
Average total loss: 0.900953
tensor(0.0038, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(1.8113e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.277076
Average KL loss: 0.501667
Average total loss: 0.778743
tensor(0.0038, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(3.5670e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.275805
Average KL loss: 0.396652
Average total loss: 0.672457
tensor(0.0038, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.9913e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.275778
Average KL loss: 0.373299
Average total loss: 0.649077
tensor(0.0038, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(7.2218e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.273624
Average KL loss: 0.361999
Average total loss: 0.635623
tensor(0.0038, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(2.4154e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.275048
Average KL loss: 0.356179
Average total loss: 0.631227
tensor(0.0038, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.9241e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.276916
Average KL loss: 0.353998
Average total loss: 0.630914
tensor(0.0038, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.1310e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.271940
Average KL loss: 0.350530
Average total loss: 0.622469
tensor(0.0038, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.1409e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.270342
Average KL loss: 0.348702
Average total loss: 0.619045
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-7.7222e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.276526
Average KL loss: 0.347634
Average total loss: 0.624160
tensor(0.0038, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.6630e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.274325
Average KL loss: 0.346910
Average total loss: 0.621234
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.9056e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.275173
Average KL loss: 0.345914
Average total loss: 0.621087
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.4825e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.276564
Average KL loss: 0.345668
Average total loss: 0.622232
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.4991e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.276120
Average KL loss: 0.346116
Average total loss: 0.622237
tensor(0.0038, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(5.4211e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.277087
Average KL loss: 0.345839
Average total loss: 0.622926
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-6.0728e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.273178
Average KL loss: 0.345194
Average total loss: 0.618372
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.1389e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.275210
Average KL loss: 0.344488
Average total loss: 0.619698
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.7762e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.272340
Average KL loss: 0.343688
Average total loss: 0.616028
tensor(0.0038, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(4.1154e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.277963
Average KL loss: 0.344648
Average total loss: 0.622610
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.4759e-11, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.279018
Average KL loss: 0.343826
Average total loss: 0.622844
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.5288e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.274354
Average KL loss: 0.344042
Average total loss: 0.618396
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(3.2309e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.276731
Average KL loss: 0.343056
Average total loss: 0.619787
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.0744e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.276558
Average KL loss: 0.343140
Average total loss: 0.619698
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.6635e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.276154
Average KL loss: 0.342922
Average total loss: 0.619075
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.7590e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.274211
Average KL loss: 0.342812
Average total loss: 0.617023
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(4.0058e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.277892
Average KL loss: 0.342381
Average total loss: 0.620273
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.8707e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.278013
Average KL loss: 0.342458
Average total loss: 0.620471
tensor(0.0038, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.8608e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.276640
Average KL loss: 0.342944
Average total loss: 0.619584
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.3631e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.275233
Average KL loss: 0.342271
Average total loss: 0.617504
tensor(0.0037, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.0626e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.275841
Average KL loss: 0.339110
Average total loss: 0.614950
tensor(0.0037, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.7091e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.273961
Average KL loss: 0.333663
Average total loss: 0.607624
tensor(0.0037, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(4.3728e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.274213
Average KL loss: 0.330374
Average total loss: 0.604587
tensor(0.0037, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-5.7226e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.276598
Average KL loss: 0.327952
Average total loss: 0.604550
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.8016e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.273796
Average KL loss: 0.326168
Average total loss: 0.599964
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.1747e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.273310
Average KL loss: 0.324812
Average total loss: 0.598122
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(1.7011e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.274160
Average KL loss: 0.323614
Average total loss: 0.597774
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-6.4076e-11, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.273079
Average KL loss: 0.322798
Average total loss: 0.595877
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.5498e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.274654
Average KL loss: 0.322059
Average total loss: 0.596713
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.7112e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.279730
Average KL loss: 0.321470
Average total loss: 0.601201
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.1644e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.277329
Average KL loss: 0.320983
Average total loss: 0.598312
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(3.8921e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.275263
Average KL loss: 0.320454
Average total loss: 0.595717
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(7.6706e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.272994
Average KL loss: 0.319953
Average total loss: 0.592947
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.3246e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.270566
Average KL loss: 0.319532
Average total loss: 0.590097
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(3.1687e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.275892
Average KL loss: 0.319134
Average total loss: 0.595026
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.3015e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.275214
Average KL loss: 0.318863
Average total loss: 0.594077
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(5.0706e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.274722
Average KL loss: 0.318643
Average total loss: 0.593365
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(2.8466e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.276576
Average KL loss: 0.318382
Average total loss: 0.594958
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.2258e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.275071
Average KL loss: 0.318153
Average total loss: 0.593223
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.1556e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.275357
Average KL loss: 0.317936
Average total loss: 0.593293
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.0595e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.272882
Average KL loss: 0.317707
Average total loss: 0.590589
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(3.7636e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.273107
Average KL loss: 0.317657
Average total loss: 0.590764
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(3.7016e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.274204
Average KL loss: 0.317446
Average total loss: 0.591650
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.4824e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.275589
Average KL loss: 0.317375
Average total loss: 0.592964
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.4300e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.274477
Average KL loss: 0.317299
Average total loss: 0.591776
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.9643e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.274470
Average KL loss: 0.317135
Average total loss: 0.591605
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(9.0845e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.273313
Average KL loss: 0.316991
Average total loss: 0.590304
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.0544e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.274161
Average KL loss: 0.316866
Average total loss: 0.591028
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(2.5678e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.276841
Average KL loss: 0.316761
Average total loss: 0.593602
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(2.9855e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.277729
Average KL loss: 0.316671
Average total loss: 0.594400
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(5.0815e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.276071
Average KL loss: 0.316599
Average total loss: 0.592670
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.8648e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.272829
Average KL loss: 0.316515
Average total loss: 0.589345
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.8366e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.277639
Average KL loss: 0.316439
Average total loss: 0.594078
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.8621e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.274690
Average KL loss: 0.316369
Average total loss: 0.591059
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.8951e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.275495
Average KL loss: 0.316300
Average total loss: 0.591795
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.5465e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.275225
Average KL loss: 0.316238
Average total loss: 0.591463
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.9891e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.273822
Average KL loss: 0.316168
Average total loss: 0.589989
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.1090e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.274397
Average KL loss: 0.316091
Average total loss: 0.590488
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-5.1572e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.273680
Average KL loss: 0.316022
Average total loss: 0.589702
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.4601e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.274904
Average KL loss: 0.315961
Average total loss: 0.590865
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.2671e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.276272
Average KL loss: 0.315910
Average total loss: 0.592182
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-4.5816e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.274717
Average KL loss: 0.315868
Average total loss: 0.590586
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(7.0245e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.275886
Average KL loss: 0.315826
Average total loss: 0.591712
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.8100e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.274729
Average KL loss: 0.315805
Average total loss: 0.590534
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.5262e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.275504
Average KL loss: 0.315799
Average total loss: 0.591303
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.9526e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.274840
Average KL loss: 0.315792
Average total loss: 0.590632
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.0455e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.276603
Average KL loss: 0.315786
Average total loss: 0.592389
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.9084e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.274971
Average KL loss: 0.315782
Average total loss: 0.590753
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.0538e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.273783
Average KL loss: 0.315776
Average total loss: 0.589558
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.4013e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.273523
Average KL loss: 0.315769
Average total loss: 0.589292
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-7.5371e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.273318
Average KL loss: 0.315764
Average total loss: 0.589082
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.6093e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.275581
Average KL loss: 0.315759
Average total loss: 0.591340
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.2409e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.274712
Average KL loss: 0.315754
Average total loss: 0.590466
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.4919e-11, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.273940
Average KL loss: 0.315748
Average total loss: 0.589688
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-6.5340e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.274221
Average KL loss: 0.315743
Average total loss: 0.589964
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(8.2106e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.275197
Average KL loss: 0.315737
Average total loss: 0.590934
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.3330e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.275264
Average KL loss: 0.315732
Average total loss: 0.590997
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.4141e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.277251
Average KL loss: 0.315727
Average total loss: 0.592978
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.5548e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.276049
Average KL loss: 0.315723
Average total loss: 0.591771
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.1869e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.277232
Average KL loss: 0.315719
Average total loss: 0.592950
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-4.5233e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.273664
Average KL loss: 0.315714
Average total loss: 0.589378
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(5.5756e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.273254
Average KL loss: 0.315709
Average total loss: 0.588962
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.3338e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.274936
Average KL loss: 0.315703
Average total loss: 0.590639
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.4854e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.271700
Average KL loss: 0.315696
Average total loss: 0.587397
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.7849e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.275493
Average KL loss: 0.315690
Average total loss: 0.591183
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(5.8420e-11, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.273205
Average KL loss: 0.315685
Average total loss: 0.588890
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.5157e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.273066
Average KL loss: 0.315679
Average total loss: 0.588745
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.1772e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.274233
Average KL loss: 0.315673
Average total loss: 0.589907
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.3029e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.274342
Average KL loss: 0.315668
Average total loss: 0.590010
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.5257e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.275042
Average KL loss: 0.315663
Average total loss: 0.590704
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(5.7392e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.273782
Average KL loss: 0.315657
Average total loss: 0.589440
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.9810e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.276208
Average KL loss: 0.315652
Average total loss: 0.591860
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.3573e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.274946
Average KL loss: 0.315647
Average total loss: 0.590593
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.2683e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.276339
Average KL loss: 0.315642
Average total loss: 0.591981
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(4.6842e-09, device='cuda:0')
 Percentile value: 8.075215873759589e-08
Non-zero model percentage: 64.0%, Non-zero mask percentage: 64.0%

--- Pruning Level [2/24]: ---
conv1.weight         | nonzeros =    1539 /    1728             ( 89.06%) | total_pruned =     189 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   32190 /   36864             ( 87.32%) | total_pruned =    4674 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   25842 /   36864             ( 70.10%) | total_pruned =   11022 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   24152 /   36864             ( 65.52%) | total_pruned =   12712 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   23800 /   36864             ( 64.56%) | total_pruned =   13064 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   31257 /   73728             ( 42.40%) | total_pruned =   42471 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   60946 /  147456             ( 41.33%) | total_pruned =   86510 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4166 /    8192             ( 50.85%) | total_pruned =    4026 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   72091 /  147456             ( 48.89%) | total_pruned =   75365 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   82986 /  147456             ( 56.28%) | total_pruned =   64470 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  110892 /  294912             ( 37.60%) | total_pruned =  184020 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     118 /     256             ( 46.09%) | total_pruned =     138 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  225074 /  589824             ( 38.16%) | total_pruned =  364750 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   14448 /   32768             ( 44.09%) | total_pruned =   18320 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      67 /     256             ( 26.17%) | total_pruned =     189 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  257194 /  589824             ( 43.61%) | total_pruned =  332630 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  312697 /  589824             ( 53.02%) | total_pruned =  277127 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  470541 / 1179648             ( 39.89%) | total_pruned =  709107 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      85 /     512             ( 16.60%) | total_pruned =     427 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1435626 / 2359296             ( 60.85%) | total_pruned =  923670 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     468 /     512             ( 91.41%) | total_pruned =      44 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     160 /     512             ( 31.25%) | total_pruned =     352 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   88025 /  131072             ( 67.16%) | total_pruned =   43047 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     489 /     512             ( 95.51%) | total_pruned =      23 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     139 /     512             ( 27.15%) | total_pruned =     373 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1647262 / 2359296             ( 69.82%) | total_pruned =  712034 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2217545 / 2359296             ( 93.99%) | total_pruned =  141751 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5085 /    5120             ( 99.32%) | total_pruned =      35 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 7154408, pruned : 4024354, total: 11178762, Compression rate :       1.56x  ( 36.00% pruned)
Train Epoch: 60/100 Loss: 0.012360 Accuracy: 88.31 100.00 % Best test Accuracy: 88.51%
tensor(0.0037, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.4494e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.646319
Average KL loss: 0.740260
Average total loss: 1.386578
tensor(0.0027, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.1705e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.552303
Average KL loss: 0.676010
Average total loss: 1.228313
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.3235e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.463184
Average KL loss: 0.648857
Average total loss: 1.112041
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.0373e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.427116
Average KL loss: 0.638915
Average total loss: 1.066030
tensor(0.0035, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.7584e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.406627
Average KL loss: 0.627511
Average total loss: 1.034139
tensor(0.0035, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.3987e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.385012
Average KL loss: 0.621849
Average total loss: 1.006860
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.3058e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.376042
Average KL loss: 0.620319
Average total loss: 0.996361
tensor(0.0035, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-5.0556e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.367392
Average KL loss: 0.615018
Average total loss: 0.982410
tensor(0.0036, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.7600e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.360355
Average KL loss: 0.608405
Average total loss: 0.968759
tensor(0.0035, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-4.5771e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.355288
Average KL loss: 0.609715
Average total loss: 0.965003
tensor(0.0036, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.3075e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.356082
Average KL loss: 0.615391
Average total loss: 0.971473
tensor(0.0036, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-4.8540e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.342767
Average KL loss: 0.604971
Average total loss: 0.947738
tensor(0.0036, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-3.6836e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.344932
Average KL loss: 0.606599
Average total loss: 0.951531
tensor(0.0036, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-3.9358e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.349138
Average KL loss: 0.616778
Average total loss: 0.965916
tensor(0.0036, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-3.6186e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.344152
Average KL loss: 0.615822
Average total loss: 0.959974
tensor(0.0036, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-5.0245e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.341082
Average KL loss: 0.614973
Average total loss: 0.956055
tensor(0.0014, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-5.5585e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.340940
Average KL loss: 0.614975
Average total loss: 0.955915
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(6.1851e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.333747
Average KL loss: 0.616562
Average total loss: 0.950310
tensor(0.0037, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-4.8587e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.333905
Average KL loss: 0.616664
Average total loss: 0.950568
tensor(0.0037, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(7.1045e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.332449
Average KL loss: 0.611859
Average total loss: 0.944308
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.6085e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.331310
Average KL loss: 0.613391
Average total loss: 0.944700
tensor(0.0041, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(4.6771e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.330646
Average KL loss: 0.612017
Average total loss: 0.942663
tensor(0.0037, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.4561e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.328049
Average KL loss: 0.608583
Average total loss: 0.936633
tensor(0.0037, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-8.3793e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.330985
Average KL loss: 0.618088
Average total loss: 0.949073
tensor(0.0038, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-8.7400e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.327646
Average KL loss: 0.618292
Average total loss: 0.945938
tensor(0.0025, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.2937e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.328211
Average KL loss: 0.619997
Average total loss: 0.948209
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(3.3391e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.323051
Average KL loss: 0.612995
Average total loss: 0.936045
tensor(0.0038, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.5628e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.324486
Average KL loss: 0.615324
Average total loss: 0.939810
tensor(0.0038, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(2.7259e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.329944
Average KL loss: 0.619036
Average total loss: 0.948979
tensor(0.0034, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-3.9648e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.327854
Average KL loss: 0.619836
Average total loss: 0.947690
tensor(0.0038, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.9207e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.326400
Average KL loss: 0.617884
Average total loss: 0.944284
tensor(0.0038, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(4.2731e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.325465
Average KL loss: 0.620396
Average total loss: 0.945861
tensor(0.0038, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.7136e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.325202
Average KL loss: 0.616105
Average total loss: 0.941307
tensor(0.0039, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.1367e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.328391
Average KL loss: 0.623679
Average total loss: 0.952070
tensor(0.0038, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(7.1020e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.322202
Average KL loss: 0.619070
Average total loss: 0.941272
tensor(0.0028, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.4158e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.327620
Average KL loss: 0.622937
Average total loss: 0.950558
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(3.9541e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.325963
Average KL loss: 0.619265
Average total loss: 0.945228
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(6.1339e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.324360
Average KL loss: 0.623358
Average total loss: 0.947718
tensor(0.0039, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.3765e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.313025
Average KL loss: 0.525522
Average total loss: 0.838547
tensor(0.0039, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.9878e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.320753
Average KL loss: 0.428601
Average total loss: 0.749354
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.8649e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.312484
Average KL loss: 0.397463
Average total loss: 0.709947
tensor(0.0038, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(5.3748e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.313858
Average KL loss: 0.381593
Average total loss: 0.695450
tensor(0.0038, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(5.8200e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.310598
Average KL loss: 0.372133
Average total loss: 0.682731
tensor(0.0038, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(5.1275e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.310597
Average KL loss: 0.365797
Average total loss: 0.676394
tensor(0.0038, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(4.9445e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.312884
Average KL loss: 0.362090
Average total loss: 0.674974
tensor(0.0038, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-5.3267e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.316653
Average KL loss: 0.359049
Average total loss: 0.675702
tensor(0.0038, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.1976e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.313279
Average KL loss: 0.357096
Average total loss: 0.670375
tensor(0.0038, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.8331e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.312941
Average KL loss: 0.354867
Average total loss: 0.667808
tensor(0.0038, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-4.9918e-11, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.310014
Average KL loss: 0.353290
Average total loss: 0.663304
tensor(0.0038, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.1738e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.313634
Average KL loss: 0.352335
Average total loss: 0.665969
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(4.6470e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.312082
Average KL loss: 0.351048
Average total loss: 0.663130
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.8383e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.314246
Average KL loss: 0.350373
Average total loss: 0.664619
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(5.4793e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.313124
Average KL loss: 0.350216
Average total loss: 0.663340
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.5756e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.316699
Average KL loss: 0.349392
Average total loss: 0.666091
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(3.0801e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.315168
Average KL loss: 0.349297
Average total loss: 0.664465
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(5.5608e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.317721
Average KL loss: 0.348979
Average total loss: 0.666700
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(7.9058e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.315641
Average KL loss: 0.348709
Average total loss: 0.664350
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.1590e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.312095
Average KL loss: 0.348224
Average total loss: 0.660318
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.0740e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.312965
Average KL loss: 0.347013
Average total loss: 0.659978
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.0489e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.315796
Average KL loss: 0.346874
Average total loss: 0.662671
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.9900e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.314441
Average KL loss: 0.347177
Average total loss: 0.661618
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(6.3475e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.315999
Average KL loss: 0.346744
Average total loss: 0.662743
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.3579e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.316390
Average KL loss: 0.347075
Average total loss: 0.663464
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.4029e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.312812
Average KL loss: 0.345687
Average total loss: 0.658499
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(6.7378e-11, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.314780
Average KL loss: 0.345023
Average total loss: 0.659803
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(3.5774e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.314075
Average KL loss: 0.344747
Average total loss: 0.658822
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.5524e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.316179
Average KL loss: 0.345078
Average total loss: 0.661257
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-5.4819e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.316219
Average KL loss: 0.345811
Average total loss: 0.662030
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-5.4461e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.315654
Average KL loss: 0.345359
Average total loss: 0.661013
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.8491e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.316572
Average KL loss: 0.345365
Average total loss: 0.661937
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(5.3516e-11, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.317009
Average KL loss: 0.345270
Average total loss: 0.662279
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-6.8359e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.318353
Average KL loss: 0.345362
Average total loss: 0.663715
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.6084e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.312502
Average KL loss: 0.345243
Average total loss: 0.657746
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(4.0438e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.315729
Average KL loss: 0.343898
Average total loss: 0.659627
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.1170e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.319075
Average KL loss: 0.344055
Average total loss: 0.663130
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.9077e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.320769
Average KL loss: 0.345008
Average total loss: 0.665777
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.9132e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.317211
Average KL loss: 0.345078
Average total loss: 0.662289
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.1891e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.316346
Average KL loss: 0.344455
Average total loss: 0.660802
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.5364e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.318004
Average KL loss: 0.344743
Average total loss: 0.662747
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.6669e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.317238
Average KL loss: 0.344771
Average total loss: 0.662009
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-5.0610e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.316339
Average KL loss: 0.344293
Average total loss: 0.660632
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.5053e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.313363
Average KL loss: 0.343671
Average total loss: 0.657034
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(8.2065e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.316461
Average KL loss: 0.343765
Average total loss: 0.660227
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-9.2285e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.316526
Average KL loss: 0.343892
Average total loss: 0.660418
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(3.6696e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.314632
Average KL loss: 0.343355
Average total loss: 0.657988
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(7.5847e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.315808
Average KL loss: 0.343204
Average total loss: 0.659012
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-5.0206e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.320779
Average KL loss: 0.343802
Average total loss: 0.664580
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(6.3437e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.319005
Average KL loss: 0.344180
Average total loss: 0.663185
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.8373e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.317214
Average KL loss: 0.344149
Average total loss: 0.661363
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.4157e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.316531
Average KL loss: 0.343402
Average total loss: 0.659933
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.4444e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.315662
Average KL loss: 0.342658
Average total loss: 0.658320
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.0272e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.317643
Average KL loss: 0.342687
Average total loss: 0.660330
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.3040e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.317725
Average KL loss: 0.342469
Average total loss: 0.660194
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.5148e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.317304
Average KL loss: 0.340251
Average total loss: 0.657555
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-4.0638e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.317954
Average KL loss: 0.336084
Average total loss: 0.654038
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.8153e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.315555
Average KL loss: 0.333360
Average total loss: 0.648915
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.7087e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.314509
Average KL loss: 0.331325
Average total loss: 0.645834
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(3.7685e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.314817
Average KL loss: 0.329664
Average total loss: 0.644481
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.9325e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.317143
Average KL loss: 0.328301
Average total loss: 0.645444
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.2981e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.313190
Average KL loss: 0.327210
Average total loss: 0.640400
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.5867e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.316493
Average KL loss: 0.326223
Average total loss: 0.642716
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.3496e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.315432
Average KL loss: 0.325377
Average total loss: 0.640809
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.8476e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.316176
Average KL loss: 0.324714
Average total loss: 0.640890
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.7090e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.314395
Average KL loss: 0.324123
Average total loss: 0.638518
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.8554e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.315047
Average KL loss: 0.323565
Average total loss: 0.638613
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(5.1588e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.317284
Average KL loss: 0.323029
Average total loss: 0.640314
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.3555e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.314153
Average KL loss: 0.322558
Average total loss: 0.636711
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.4648e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.315148
Average KL loss: 0.322113
Average total loss: 0.637261
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.9126e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.315561
Average KL loss: 0.321663
Average total loss: 0.637224
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.5272e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.316959
Average KL loss: 0.321281
Average total loss: 0.638240
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.7196e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.315216
Average KL loss: 0.320984
Average total loss: 0.636200
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-6.0698e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.314617
Average KL loss: 0.320703
Average total loss: 0.635319
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-8.0534e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.315396
Average KL loss: 0.320481
Average total loss: 0.635877
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.2561e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.316338
Average KL loss: 0.320176
Average total loss: 0.636514
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.1084e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.313862
Average KL loss: 0.319944
Average total loss: 0.633806
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.8695e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.313635
Average KL loss: 0.319607
Average total loss: 0.633242
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.0531e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.316357
Average KL loss: 0.319377
Average total loss: 0.635734
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(4.3633e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.313501
Average KL loss: 0.319159
Average total loss: 0.632660
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.0367e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.317527
Average KL loss: 0.318977
Average total loss: 0.636503
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.5386e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.315903
Average KL loss: 0.318789
Average total loss: 0.634692
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.4804e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.316188
Average KL loss: 0.318593
Average total loss: 0.634780
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.1562e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.317071
Average KL loss: 0.318486
Average total loss: 0.635556
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.8542e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.314572
Average KL loss: 0.318349
Average total loss: 0.632921
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.3638e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.318989
Average KL loss: 0.318225
Average total loss: 0.637214
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(4.9055e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.315979
Average KL loss: 0.318168
Average total loss: 0.634147
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.2199e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.310724
Average KL loss: 0.318040
Average total loss: 0.628764
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.6664e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.314882
Average KL loss: 0.317826
Average total loss: 0.632708
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.0577e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.314343
Average KL loss: 0.317683
Average total loss: 0.632026
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.2414e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.315362
Average KL loss: 0.317532
Average total loss: 0.632894
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(3.9007e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.310870
Average KL loss: 0.317475
Average total loss: 0.628344
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.2351e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.319275
Average KL loss: 0.317439
Average total loss: 0.636714
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-8.6780e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.312951
Average KL loss: 0.317438
Average total loss: 0.630389
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.7473e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.318597
Average KL loss: 0.317282
Average total loss: 0.635880
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-9.7062e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.317844
Average KL loss: 0.317144
Average total loss: 0.634988
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-7.2308e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.314678
Average KL loss: 0.317097
Average total loss: 0.631775
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.6950e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.313357
Average KL loss: 0.317023
Average total loss: 0.630381
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.3851e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.317550
Average KL loss: 0.316943
Average total loss: 0.634493
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.8793e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.317808
Average KL loss: 0.316978
Average total loss: 0.634786
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.7311e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.314851
Average KL loss: 0.316951
Average total loss: 0.631802
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-4.1332e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.312378
Average KL loss: 0.316838
Average total loss: 0.629216
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(3.6776e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.318424
Average KL loss: 0.316812
Average total loss: 0.635236
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(4.0775e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.316140
Average KL loss: 0.316786
Average total loss: 0.632926
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-4.9157e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.317642
Average KL loss: 0.316687
Average total loss: 0.634328
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-6.2595e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.318117
Average KL loss: 0.316602
Average total loss: 0.634720
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.0998e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.314638
Average KL loss: 0.316529
Average total loss: 0.631168
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.5183e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.314024
Average KL loss: 0.316464
Average total loss: 0.630488
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-6.6359e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.315826
Average KL loss: 0.316405
Average total loss: 0.632231
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(8.9443e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.317353
Average KL loss: 0.316342
Average total loss: 0.633695
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.8378e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.314242
Average KL loss: 0.316282
Average total loss: 0.630524
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.5329e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.316249
Average KL loss: 0.316224
Average total loss: 0.632472
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.4773e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.316182
Average KL loss: 0.316172
Average total loss: 0.632354
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-4.9055e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.315573
Average KL loss: 0.316122
Average total loss: 0.631695
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(7.5618e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.317249
Average KL loss: 0.316097
Average total loss: 0.633346
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.0142e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.317300
Average KL loss: 0.316092
Average total loss: 0.633392
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-9.8815e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.312722
Average KL loss: 0.316087
Average total loss: 0.628809
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(9.1595e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.316031
Average KL loss: 0.316082
Average total loss: 0.632112
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.7620e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.314425
Average KL loss: 0.316076
Average total loss: 0.630501
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.2485e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.314231
Average KL loss: 0.316070
Average total loss: 0.630300
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-3.9336e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.315942
Average KL loss: 0.316065
Average total loss: 0.632007
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.9251e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.317000
Average KL loss: 0.316060
Average total loss: 0.633059
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.5525e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.314806
Average KL loss: 0.316054
Average total loss: 0.630861
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(3.6986e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.315954
Average KL loss: 0.316048
Average total loss: 0.632003
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.8058e-09, device='cuda:0')
 Percentile value: 8.062653620299897e-08
Non-zero model percentage: 51.200008392333984%, Non-zero mask percentage: 51.200008392333984%

--- Pruning Level [3/24]: ---
conv1.weight         | nonzeros =    1507 /    1728             ( 87.21%) | total_pruned =     221 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
bn1.bias             | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   31668 /   36864             ( 85.90%) | total_pruned =    5196 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   23912 /   36864             ( 64.87%) | total_pruned =   12952 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   22674 /   36864             ( 61.51%) | total_pruned =   14190 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   22070 /   36864             ( 59.87%) | total_pruned =   14794 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   25917 /   73728             ( 35.15%) | total_pruned =   47811 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   45213 /  147456             ( 30.66%) | total_pruned =  102243 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3459 /    8192             ( 42.22%) | total_pruned =    4733 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   52523 /  147456             ( 35.62%) | total_pruned =   94933 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   62561 /  147456             ( 42.43%) | total_pruned =   84895 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   79087 /  294912             ( 26.82%) | total_pruned =  215825 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      98 /     256             ( 38.28%) | total_pruned =     158 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  158723 /  589824             ( 26.91%) | total_pruned =  431101 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   10401 /   32768             ( 31.74%) | total_pruned =   22367 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     218 /     256             ( 85.16%) | total_pruned =      38 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      54 /     256             ( 21.09%) | total_pruned =     202 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  173774 /  589824             ( 29.46%) | total_pruned =  416050 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  212580 /  589824             ( 36.04%) | total_pruned =  377244 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  294616 / 1179648             ( 24.97%) | total_pruned =  885032 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  962801 / 2359296             ( 40.81%) | total_pruned = 1396495 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     435 /     512             ( 84.96%) | total_pruned =      77 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     132 /     512             ( 25.78%) | total_pruned =     380 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   60881 /  131072             ( 46.45%) | total_pruned =   70191 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     449 /     512             ( 87.70%) | total_pruned =      63 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     127 /     512             ( 24.80%) | total_pruned =     385 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1398536 / 2359296             ( 59.28%) | total_pruned =  960760 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2064826 / 2359296             ( 87.52%) | total_pruned =  294470 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
linear.weight        | nonzeros =    5038 /    5120             ( 98.40%) | total_pruned =      82 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 5723527, pruned : 5455235, total: 11178762, Compression rate :       1.95x  ( 48.80% pruned)
Train Epoch: 54/100 Loss: 0.018563 Accuracy: 88.11 100.00 % Best test Accuracy: 88.24%
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-8.6440e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.581592
Average KL loss: 0.620491
Average total loss: 1.202083
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.7625e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.571604
Average KL loss: 0.631199
Average total loss: 1.202803
tensor(0.0033, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.7632e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.500248
Average KL loss: 0.628754
Average total loss: 1.129003
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.4106e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.462641
Average KL loss: 0.623747
Average total loss: 1.086389
tensor(0.0035, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.6289e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.439167
Average KL loss: 0.619276
Average total loss: 1.058443
tensor(0.0035, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.2772e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.423578
Average KL loss: 0.616091
Average total loss: 1.039669
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.2307e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.418182
Average KL loss: 0.616769
Average total loss: 1.034951
tensor(0.0036, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-6.8540e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.413436
Average KL loss: 0.618265
Average total loss: 1.031701
tensor(0.0036, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-4.2390e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.406204
Average KL loss: 0.622242
Average total loss: 1.028446
tensor(0.0037, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-2.2009e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.409772
Average KL loss: 0.621405
Average total loss: 1.031177
tensor(0.0036, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-5.2936e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.400970
Average KL loss: 0.626983
Average total loss: 1.027953
tensor(0.0037, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.9025e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.392451
Average KL loss: 0.621904
Average total loss: 1.014355
tensor(0.0037, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(2.4007e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.398521
Average KL loss: 0.621603
Average total loss: 1.020124
tensor(0.0037, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(7.4148e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.394359
Average KL loss: 0.626471
Average total loss: 1.020830
tensor(0.0037, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(3.0302e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.391509
Average KL loss: 0.629550
Average total loss: 1.021059
tensor(0.0038, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(4.4460e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.391334
Average KL loss: 0.622881
Average total loss: 1.014215
tensor(-0.0012, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.2688e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.386997
Average KL loss: 0.625453
Average total loss: 1.012450
tensor(0.0041, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(2.4122e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.383013
Average KL loss: 0.627115
Average total loss: 1.010128
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.5466e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.386272
Average KL loss: 0.625177
Average total loss: 1.011449
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.8918e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.381701
Average KL loss: 0.621429
Average total loss: 1.003130
tensor(0.0046, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.2168e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.388123
Average KL loss: 0.632699
Average total loss: 1.020822
tensor(0.0044, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.6096e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.383925
Average KL loss: 0.624906
Average total loss: 1.008831
tensor(0.0038, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.6776e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.385203
Average KL loss: 0.628272
Average total loss: 1.013474
tensor(0.0038, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.3599e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.382547
Average KL loss: 0.633266
Average total loss: 1.015813
tensor(0.0033, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.7300e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.379799
Average KL loss: 0.631220
Average total loss: 1.011019
tensor(0.0015, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-5.6306e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.373758
Average KL loss: 0.629237
Average total loss: 1.002995
tensor(0.0042, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(6.8294e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.377632
Average KL loss: 0.629648
Average total loss: 1.007279
tensor(0.0039, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.6218e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.374563
Average KL loss: 0.633384
Average total loss: 1.007948
tensor(0.0047, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(1.7929e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.382921
Average KL loss: 0.633929
Average total loss: 1.016851
tensor(0.0033, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.3803e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.378343
Average KL loss: 0.639761
Average total loss: 1.018103
tensor(0.0040, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(8.1125e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.375592
Average KL loss: 0.630736
Average total loss: 1.006327
tensor(0.0039, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.4643e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.379999
Average KL loss: 0.636113
Average total loss: 1.016113
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(3.9358e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.378135
Average KL loss: 0.631721
Average total loss: 1.009856
tensor(0.0042, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(4.1553e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.377230
Average KL loss: 0.634300
Average total loss: 1.011530
tensor(0.0040, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(4.4015e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.377404
Average KL loss: 0.637432
Average total loss: 1.014836
tensor(0.0021, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-4.6627e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.376649
Average KL loss: 0.641306
Average total loss: 1.017955
tensor(0.0042, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(5.4340e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.377813
Average KL loss: 0.638673
Average total loss: 1.016486
tensor(0.0044, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(7.5139e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.367369
Average KL loss: 0.569591
Average total loss: 0.936960
tensor(0.0040, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(4.4301e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.360901
Average KL loss: 0.479021
Average total loss: 0.839922
tensor(0.0040, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-8.3708e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.358056
Average KL loss: 0.443301
Average total loss: 0.801358
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(4.3307e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.361543
Average KL loss: 0.423875
Average total loss: 0.785418
tensor(0.0040, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.4408e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.362940
Average KL loss: 0.411346
Average total loss: 0.774286
tensor(0.0040, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-4.2466e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.362761
Average KL loss: 0.403267
Average total loss: 0.766028
tensor(0.0039, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.3036e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.360632
Average KL loss: 0.396811
Average total loss: 0.757443
tensor(0.0039, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.3202e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.363852
Average KL loss: 0.391629
Average total loss: 0.755480
tensor(0.0039, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(6.0186e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.365749
Average KL loss: 0.388638
Average total loss: 0.754386
tensor(0.0039, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.8814e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.363809
Average KL loss: 0.386313
Average total loss: 0.750122
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.3750e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.365096
Average KL loss: 0.383431
Average total loss: 0.748526
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.2479e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.359179
Average KL loss: 0.381401
Average total loss: 0.740580
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.7725e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.367340
Average KL loss: 0.379599
Average total loss: 0.746939
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.2528e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.361370
Average KL loss: 0.378489
Average total loss: 0.739859
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.1741e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.366135
Average KL loss: 0.378021
Average total loss: 0.744156
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(5.9991e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.362864
Average KL loss: 0.377090
Average total loss: 0.739954
tensor(0.0039, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.2040e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.365458
Average KL loss: 0.375505
Average total loss: 0.740963
tensor(0.0039, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.2376e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.363508
Average KL loss: 0.374511
Average total loss: 0.738018
tensor(0.0039, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.7849e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.367165
Average KL loss: 0.374068
Average total loss: 0.741233
tensor(0.0039, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.6655e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.365737
Average KL loss: 0.374019
Average total loss: 0.739756
tensor(0.0039, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.8261e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.361178
Average KL loss: 0.373422
Average total loss: 0.734600
tensor(0.0039, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(5.5798e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.366455
Average KL loss: 0.372462
Average total loss: 0.738917
tensor(0.0039, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.5162e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.362081
Average KL loss: 0.371586
Average total loss: 0.733667
tensor(0.0039, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.1852e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.368438
Average KL loss: 0.371265
Average total loss: 0.739704
tensor(0.0039, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.1842e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.365579
Average KL loss: 0.371016
Average total loss: 0.736596
tensor(0.0039, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.8533e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.363834
Average KL loss: 0.369819
Average total loss: 0.733653
tensor(0.0039, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(4.6177e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.364313
Average KL loss: 0.369547
Average total loss: 0.733860
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(3.1701e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.367402
Average KL loss: 0.369164
Average total loss: 0.736566
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(1.2693e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.367066
Average KL loss: 0.368891
Average total loss: 0.735957
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-4.6740e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.368826
Average KL loss: 0.368094
Average total loss: 0.736919
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(2.6790e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.367935
Average KL loss: 0.367996
Average total loss: 0.735931
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-4.9975e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.362809
Average KL loss: 0.367322
Average total loss: 0.730131
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(2.6410e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.367259
Average KL loss: 0.366885
Average total loss: 0.734144
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(3.9465e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.368473
Average KL loss: 0.366973
Average total loss: 0.735446
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.0164e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.364433
Average KL loss: 0.366420
Average total loss: 0.730853
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(4.6399e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.365737
Average KL loss: 0.365530
Average total loss: 0.731267
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(8.0221e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.370705
Average KL loss: 0.366027
Average total loss: 0.736732
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.6610e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.365069
Average KL loss: 0.365987
Average total loss: 0.731056
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-9.9907e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.365353
Average KL loss: 0.365984
Average total loss: 0.731337
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-8.2233e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.369038
Average KL loss: 0.365877
Average total loss: 0.734915
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.0839e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.365396
Average KL loss: 0.365893
Average total loss: 0.731289
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(6.5689e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.363853
Average KL loss: 0.365426
Average total loss: 0.729279
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.2956e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.368031
Average KL loss: 0.364689
Average total loss: 0.732721
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(2.3975e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.367167
Average KL loss: 0.365158
Average total loss: 0.732325
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(3.6163e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.370120
Average KL loss: 0.365284
Average total loss: 0.735404
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(2.9078e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.369667
Average KL loss: 0.365217
Average total loss: 0.734884
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-4.2600e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.367115
Average KL loss: 0.364846
Average total loss: 0.731961
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(4.2304e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.366832
Average KL loss: 0.364274
Average total loss: 0.731107
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(6.2265e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.367268
Average KL loss: 0.364321
Average total loss: 0.731589
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-4.3486e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.368524
Average KL loss: 0.364385
Average total loss: 0.732909
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.1553e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.371615
Average KL loss: 0.364840
Average total loss: 0.736455
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-6.9557e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.368380
Average KL loss: 0.364924
Average total loss: 0.733305
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(4.2032e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.369644
Average KL loss: 0.364832
Average total loss: 0.734476
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-7.9019e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.368059
Average KL loss: 0.363224
Average total loss: 0.731283
tensor(0.0039, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(5.0140e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.362154
Average KL loss: 0.359943
Average total loss: 0.722096
tensor(0.0039, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(6.5217e-11, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.367980
Average KL loss: 0.357723
Average total loss: 0.725703
tensor(0.0039, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(4.7734e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.368611
Average KL loss: 0.355985
Average total loss: 0.724596
tensor(0.0039, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(5.3019e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.364438
Average KL loss: 0.354459
Average total loss: 0.718896
tensor(0.0039, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(4.2695e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.367151
Average KL loss: 0.353271
Average total loss: 0.720422
tensor(0.0039, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.8714e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.364367
Average KL loss: 0.352239
Average total loss: 0.716606
tensor(0.0039, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-4.6738e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.371022
Average KL loss: 0.351354
Average total loss: 0.722376
tensor(0.0039, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.2700e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.364620
Average KL loss: 0.350493
Average total loss: 0.715112
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.9707e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.364039
Average KL loss: 0.349778
Average total loss: 0.713817
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.6269e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.372500
Average KL loss: 0.349146
Average total loss: 0.721647
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.2649e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.367578
Average KL loss: 0.348593
Average total loss: 0.716172
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.5981e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.369218
Average KL loss: 0.348050
Average total loss: 0.717268
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.0414e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.364567
Average KL loss: 0.347489
Average total loss: 0.712055
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-5.9876e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.365119
Average KL loss: 0.346999
Average total loss: 0.712119
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.8847e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.366273
Average KL loss: 0.346579
Average total loss: 0.712852
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.3883e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.365893
Average KL loss: 0.346107
Average total loss: 0.712001
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-8.1189e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.369673
Average KL loss: 0.345723
Average total loss: 0.715396
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.5670e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.365127
Average KL loss: 0.345423
Average total loss: 0.710550
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-4.1105e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.364176
Average KL loss: 0.345122
Average total loss: 0.709298
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-5.7387e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.367780
Average KL loss: 0.344810
Average total loss: 0.712590
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.1027e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.363469
Average KL loss: 0.344530
Average total loss: 0.707999
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.8120e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.365012
Average KL loss: 0.344215
Average total loss: 0.709228
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(6.9351e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.363725
Average KL loss: 0.343941
Average total loss: 0.707666
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.9704e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.364593
Average KL loss: 0.343665
Average total loss: 0.708258
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(6.2955e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.360811
Average KL loss: 0.343338
Average total loss: 0.704149
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.6731e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.367107
Average KL loss: 0.343045
Average total loss: 0.710152
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.8353e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.366793
Average KL loss: 0.342852
Average total loss: 0.709645
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.4775e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.366791
Average KL loss: 0.342646
Average total loss: 0.709437
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-7.9642e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.365060
Average KL loss: 0.342417
Average total loss: 0.707477
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.6662e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.363759
Average KL loss: 0.342220
Average total loss: 0.705979
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(8.8123e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.367991
Average KL loss: 0.341984
Average total loss: 0.709974
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-4.2665e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.365256
Average KL loss: 0.341812
Average total loss: 0.707068
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.4745e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.372514
Average KL loss: 0.341707
Average total loss: 0.714221
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.8863e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.367248
Average KL loss: 0.341613
Average total loss: 0.708861
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.4604e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.362368
Average KL loss: 0.341463
Average total loss: 0.703831
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.4546e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.366750
Average KL loss: 0.341275
Average total loss: 0.708024
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.5435e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.364926
Average KL loss: 0.341158
Average total loss: 0.706084
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.4002e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.367437
Average KL loss: 0.340943
Average total loss: 0.708380
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-9.3601e-11, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.366823
Average KL loss: 0.340825
Average total loss: 0.707648
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-4.2749e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.371228
Average KL loss: 0.340654
Average total loss: 0.711882
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.5052e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.368025
Average KL loss: 0.340546
Average total loss: 0.708571
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.1301e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.363578
Average KL loss: 0.340445
Average total loss: 0.704022
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.5497e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.366094
Average KL loss: 0.340439
Average total loss: 0.706533
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.1737e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.366330
Average KL loss: 0.340344
Average total loss: 0.706675
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(8.5328e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.370084
Average KL loss: 0.340245
Average total loss: 0.710329
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.9986e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.368445
Average KL loss: 0.340193
Average total loss: 0.708637
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.8812e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.370822
Average KL loss: 0.340107
Average total loss: 0.710929
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(3.1832e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.364445
Average KL loss: 0.340045
Average total loss: 0.704490
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(5.1120e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.365513
Average KL loss: 0.339977
Average total loss: 0.705490
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.1758e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.369674
Average KL loss: 0.339918
Average total loss: 0.709592
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(5.3107e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.364828
Average KL loss: 0.339867
Average total loss: 0.704696
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(7.3087e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.367135
Average KL loss: 0.339826
Average total loss: 0.706961
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.3008e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.365392
Average KL loss: 0.339778
Average total loss: 0.705169
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.8898e-12, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.365372
Average KL loss: 0.339737
Average total loss: 0.705108
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(4.5756e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.373408
Average KL loss: 0.339703
Average total loss: 0.713112
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.6195e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.371417
Average KL loss: 0.339672
Average total loss: 0.711089
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-9.2663e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.367149
Average KL loss: 0.339634
Average total loss: 0.706783
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.0039e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.365502
Average KL loss: 0.339613
Average total loss: 0.705115
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.6077e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.364861
Average KL loss: 0.339608
Average total loss: 0.704469
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.4246e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.363753
Average KL loss: 0.339604
Average total loss: 0.703358
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.2126e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.367821
Average KL loss: 0.339601
Average total loss: 0.707422
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.8901e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.369088
Average KL loss: 0.339597
Average total loss: 0.708685
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.7898e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.367287
Average KL loss: 0.339593
Average total loss: 0.706881
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.7049e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.371488
Average KL loss: 0.339589
Average total loss: 0.711077
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(3.1162e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.364286
Average KL loss: 0.339585
Average total loss: 0.703870
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.8084e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.368038
Average KL loss: 0.339580
Average total loss: 0.707619
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-8.7733e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.369582
Average KL loss: 0.339576
Average total loss: 0.709158
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.8542e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.370661
Average KL loss: 0.339572
Average total loss: 0.710233
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.5232e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.367126
Average KL loss: 0.339567
Average total loss: 0.706694
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-7.2272e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.365835
Average KL loss: 0.339563
Average total loss: 0.705398
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.0303e-09, device='cuda:0')
 Percentile value: 8.195515164288737e-08
Non-zero model percentage: 40.96000671386719%, Non-zero mask percentage: 40.96000671386719%

--- Pruning Level [4/24]: ---
conv1.weight         | nonzeros =    1453 /    1728             ( 84.09%) | total_pruned =     275 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.weight           | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
bn1.bias             | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   30722 /   36864             ( 83.34%) | total_pruned =    6142 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   21053 /   36864             ( 57.11%) | total_pruned =   15811 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   19742 /   36864             ( 53.55%) | total_pruned =   17122 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   17520 /   36864             ( 47.53%) | total_pruned =   19344 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   19073 /   73728             ( 25.87%) | total_pruned =   54655 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   32907 /  147456             ( 22.32%) | total_pruned =  114549 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2670 /    8192             ( 32.59%) | total_pruned =    5522 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   39790 /  147456             ( 26.98%) | total_pruned =  107666 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   47902 /  147456             ( 32.49%) | total_pruned =   99554 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   57997 /  294912             ( 19.67%) | total_pruned =  236915 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      87 /     256             ( 33.98%) | total_pruned =     169 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  115158 /  589824             ( 19.52%) | total_pruned =  474666 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     218 /     256             ( 85.16%) | total_pruned =      38 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    7544 /   32768             ( 23.02%) | total_pruned =   25224 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     219 /     256             ( 85.55%) | total_pruned =      37 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      52 /     256             ( 20.31%) | total_pruned =     204 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  116288 /  589824             ( 19.72%) | total_pruned =  473536 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  138710 /  589824             ( 23.52%) | total_pruned =  451114 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  190766 / 1179648             ( 16.17%) | total_pruned =  988882 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     441 /     512             ( 86.13%) | total_pruned =      71 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      68 /     512             ( 13.28%) | total_pruned =     444 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  662610 / 2359296             ( 28.09%) | total_pruned = 1696686 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     429 /     512             ( 83.79%) | total_pruned =      83 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     399 /     512             ( 77.93%) | total_pruned =     113 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     125 /     512             ( 24.41%) | total_pruned =     387 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   38968 /  131072             ( 29.73%) | total_pruned =   92104 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     435 /     512             ( 84.96%) | total_pruned =      77 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     394 /     512             ( 76.95%) | total_pruned =     118 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     120 /     512             ( 23.44%) | total_pruned =     392 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1094733 / 2359296             ( 46.40%) | total_pruned = 1264563 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     471 /     512             ( 91.99%) | total_pruned =      41 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     487 /     512             ( 95.12%) | total_pruned =      25 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1908615 / 2359296             ( 80.90%) | total_pruned =  450681 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     426 /     512             ( 83.20%) | total_pruned =      86 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     476 /     512             ( 92.97%) | total_pruned =      36 | shape = torch.Size([512])
linear.weight        | nonzeros =    4843 /    5120             ( 94.59%) | total_pruned =     277 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 4578822, pruned : 6599940, total: 11178762, Compression rate :       2.44x  ( 59.04% pruned)
Train Epoch: 60/100 Loss: 0.025162 Accuracy: 87.89 100.00 % Best test Accuracy: 88.23%
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.6639e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.590900
Average KL loss: 0.563531
Average total loss: 1.154431
tensor(0.0010, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-8.6653e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.601519
Average KL loss: 0.600730
Average total loss: 1.202249
tensor(0.0032, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.4613e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.529977
Average KL loss: 0.604296
Average total loss: 1.134273
tensor(0.0034, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.5015e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.490984
Average KL loss: 0.605042
Average total loss: 1.096026
tensor(0.0034, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-9.9048e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.470318
Average KL loss: 0.600052
Average total loss: 1.070370
tensor(0.0035, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.2441e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.451836
Average KL loss: 0.604963
Average total loss: 1.056799
tensor(0.0035, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.3687e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.448759
Average KL loss: 0.607466
Average total loss: 1.056226
tensor(0.0035, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-3.0944e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.437120
Average KL loss: 0.606197
Average total loss: 1.043317
tensor(0.0036, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-9.7364e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.434983
Average KL loss: 0.605326
Average total loss: 1.040309
tensor(0.0036, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.7385e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.429331
Average KL loss: 0.605071
Average total loss: 1.034402
tensor(0.0036, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(3.9013e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.426255
Average KL loss: 0.606607
Average total loss: 1.032862
tensor(0.0036, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(2.1831e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.427867
Average KL loss: 0.610571
Average total loss: 1.038438
tensor(0.0037, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.4987e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.423655
Average KL loss: 0.610912
Average total loss: 1.034567
tensor(0.0037, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-8.0696e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.422913
Average KL loss: 0.606519
Average total loss: 1.029433
tensor(0.0037, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-4.8292e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.419341
Average KL loss: 0.613131
Average total loss: 1.032473
tensor(0.0038, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-2.3885e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.413862
Average KL loss: 0.613907
Average total loss: 1.027768
tensor(-0.0027, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.6019e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.412955
Average KL loss: 0.615825
Average total loss: 1.028780
tensor(0.0041, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(8.2962e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.413803
Average KL loss: 0.612830
Average total loss: 1.026634
tensor(0.0037, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-5.4396e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.413311
Average KL loss: 0.615250
Average total loss: 1.028562
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.2506e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.408978
Average KL loss: 0.617652
Average total loss: 1.026630
tensor(0.0049, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.4740e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.410777
Average KL loss: 0.622221
Average total loss: 1.032998
tensor(0.0046, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.6385e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.404035
Average KL loss: 0.614336
Average total loss: 1.018371
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.4231e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.403111
Average KL loss: 0.619719
Average total loss: 1.022830
tensor(0.0039, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(5.7643e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.408119
Average KL loss: 0.616401
Average total loss: 1.024520
tensor(0.0031, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.9842e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.403594
Average KL loss: 0.618657
Average total loss: 1.022251
tensor(0.0007, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-8.0378e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.406698
Average KL loss: 0.616705
Average total loss: 1.023403
tensor(0.0042, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(7.4246e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.405100
Average KL loss: 0.617657
Average total loss: 1.022757
tensor(0.0039, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-8.8664e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.405354
Average KL loss: 0.616845
Average total loss: 1.022199
tensor(0.0049, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(2.6633e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.409328
Average KL loss: 0.616383
Average total loss: 1.025711
tensor(0.0032, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.8089e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.404907
Average KL loss: 0.621737
Average total loss: 1.026644
tensor(0.0040, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.5116e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.404031
Average KL loss: 0.617648
Average total loss: 1.021679
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(4.5210e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.404599
Average KL loss: 0.622308
Average total loss: 1.026908
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(5.5231e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.400636
Average KL loss: 0.619256
Average total loss: 1.019892
tensor(0.0043, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(6.8259e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.392342
Average KL loss: 0.568480
Average total loss: 0.960823
tensor(0.0040, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.0672e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.386659
Average KL loss: 0.498066
Average total loss: 0.884724
tensor(0.0039, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-4.7468e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.387025
Average KL loss: 0.465959
Average total loss: 0.852984
tensor(0.0039, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(1.6641e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.384671
Average KL loss: 0.446778
Average total loss: 0.831449
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.8314e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.386346
Average KL loss: 0.434647
Average total loss: 0.820993
tensor(0.0039, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.0674e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.388023
Average KL loss: 0.425213
Average total loss: 0.813237
tensor(0.0039, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(5.5060e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.388833
Average KL loss: 0.418339
Average total loss: 0.807172
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(3.2738e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.387517
Average KL loss: 0.412847
Average total loss: 0.800364
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.2537e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.386011
Average KL loss: 0.408686
Average total loss: 0.794697
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(4.1670e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.390224
Average KL loss: 0.405539
Average total loss: 0.795763
tensor(0.0039, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.1141e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.386379
Average KL loss: 0.402570
Average total loss: 0.788949
tensor(0.0039, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.2486e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.386034
Average KL loss: 0.399749
Average total loss: 0.785783
tensor(0.0039, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.2542e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.392103
Average KL loss: 0.397791
Average total loss: 0.789893
tensor(0.0039, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.5503e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.392199
Average KL loss: 0.396666
Average total loss: 0.788865
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.5019e-11, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.389823
Average KL loss: 0.394901
Average total loss: 0.784724
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.6129e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.390623
Average KL loss: 0.393937
Average total loss: 0.784560
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.5919e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.390335
Average KL loss: 0.392484
Average total loss: 0.782818
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.4132e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.390759
Average KL loss: 0.391049
Average total loss: 0.781808
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.5505e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.390140
Average KL loss: 0.390160
Average total loss: 0.780300
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(4.0779e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.388900
Average KL loss: 0.389343
Average total loss: 0.778243
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.6527e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.394294
Average KL loss: 0.388874
Average total loss: 0.783169
tensor(0.0038, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.3182e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.394200
Average KL loss: 0.388466
Average total loss: 0.782665
tensor(0.0039, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.7683e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.390952
Average KL loss: 0.387205
Average total loss: 0.778157
tensor(0.0038, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.3026e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.392539
Average KL loss: 0.386417
Average total loss: 0.778957
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(8.9988e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.397392
Average KL loss: 0.386563
Average total loss: 0.783955
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.5752e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.391551
Average KL loss: 0.385923
Average total loss: 0.777475
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.1709e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.397001
Average KL loss: 0.385106
Average total loss: 0.782108
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(5.8590e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.393955
Average KL loss: 0.384698
Average total loss: 0.778653
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.8514e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.392675
Average KL loss: 0.383999
Average total loss: 0.776674
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-7.0071e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.392543
Average KL loss: 0.383907
Average total loss: 0.776450
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.0553e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.395540
Average KL loss: 0.383524
Average total loss: 0.779064
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(8.1982e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.400620
Average KL loss: 0.383595
Average total loss: 0.784215
tensor(0.0039, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(3.2458e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.389195
Average KL loss: 0.383840
Average total loss: 0.773035
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.9914e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.389242
Average KL loss: 0.382638
Average total loss: 0.771879
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-6.4675e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.394651
Average KL loss: 0.381897
Average total loss: 0.776549
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(6.6023e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.392931
Average KL loss: 0.381727
Average total loss: 0.774658
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-9.4955e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.391600
Average KL loss: 0.381419
Average total loss: 0.773019
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.4121e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.393467
Average KL loss: 0.381155
Average total loss: 0.774622
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-7.9715e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.396078
Average KL loss: 0.380839
Average total loss: 0.776916
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.5609e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.391673
Average KL loss: 0.380835
Average total loss: 0.772508
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(9.4308e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.397252
Average KL loss: 0.380812
Average total loss: 0.778064
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(4.6575e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.392572
Average KL loss: 0.380497
Average total loss: 0.773068
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.2118e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.394938
Average KL loss: 0.379837
Average total loss: 0.774774
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-8.7342e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.394664
Average KL loss: 0.379783
Average total loss: 0.774447
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.5884e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.395854
Average KL loss: 0.379821
Average total loss: 0.775675
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.2750e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.397118
Average KL loss: 0.378697
Average total loss: 0.775814
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(3.7355e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.395835
Average KL loss: 0.376422
Average total loss: 0.772257
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.9159e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.392892
Average KL loss: 0.374616
Average total loss: 0.767508
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.9395e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.393430
Average KL loss: 0.373279
Average total loss: 0.766708
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.5931e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.392991
Average KL loss: 0.372183
Average total loss: 0.765174
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(3.3032e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.394734
Average KL loss: 0.371200
Average total loss: 0.765935
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.5283e-11, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.393311
Average KL loss: 0.370319
Average total loss: 0.763630
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.1142e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.391374
Average KL loss: 0.369501
Average total loss: 0.760875
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(3.7263e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.394600
Average KL loss: 0.368750
Average total loss: 0.763350
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-5.0386e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.393355
Average KL loss: 0.368047
Average total loss: 0.761401
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.3572e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.389167
Average KL loss: 0.367437
Average total loss: 0.756604
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.8849e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.394940
Average KL loss: 0.366886
Average total loss: 0.761826
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(4.4405e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.395911
Average KL loss: 0.366388
Average total loss: 0.762299
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.1494e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.393939
Average KL loss: 0.365987
Average total loss: 0.759927
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.0231e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.396846
Average KL loss: 0.365600
Average total loss: 0.762447
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.2664e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.394194
Average KL loss: 0.365238
Average total loss: 0.759432
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.9148e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.390370
Average KL loss: 0.364842
Average total loss: 0.755212
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(4.9948e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.392671
Average KL loss: 0.364492
Average total loss: 0.757163
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.1318e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.393064
Average KL loss: 0.364124
Average total loss: 0.757188
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.8322e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.391535
Average KL loss: 0.363785
Average total loss: 0.755320
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(6.5309e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.392546
Average KL loss: 0.363480
Average total loss: 0.756026
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.3670e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.395863
Average KL loss: 0.363222
Average total loss: 0.759085
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.3898e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.392441
Average KL loss: 0.362879
Average total loss: 0.755320
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.2747e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.395734
Average KL loss: 0.362664
Average total loss: 0.758398
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(4.9743e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.395575
Average KL loss: 0.362458
Average total loss: 0.758033
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.4695e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.393263
Average KL loss: 0.362226
Average total loss: 0.755489
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.9086e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.392036
Average KL loss: 0.361975
Average total loss: 0.754012
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.5090e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.392895
Average KL loss: 0.361753
Average total loss: 0.754648
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-5.2412e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.395370
Average KL loss: 0.361537
Average total loss: 0.756906
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.2702e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.391335
Average KL loss: 0.361362
Average total loss: 0.752697
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.8288e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.394361
Average KL loss: 0.361182
Average total loss: 0.755543
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.7737e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.395341
Average KL loss: 0.360995
Average total loss: 0.756336
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(4.0973e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.396071
Average KL loss: 0.360819
Average total loss: 0.756889
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.1100e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.392717
Average KL loss: 0.360675
Average total loss: 0.753392
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.4815e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.393171
Average KL loss: 0.360503
Average total loss: 0.753673
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.5080e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.390539
Average KL loss: 0.360308
Average total loss: 0.750847
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.8575e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.391429
Average KL loss: 0.360154
Average total loss: 0.751583
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.4733e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.391536
Average KL loss: 0.360038
Average total loss: 0.751575
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(4.3128e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.392232
Average KL loss: 0.359980
Average total loss: 0.752212
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.3458e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.396559
Average KL loss: 0.359825
Average total loss: 0.756383
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.0655e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.391101
Average KL loss: 0.359714
Average total loss: 0.750815
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-4.6116e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.393710
Average KL loss: 0.359531
Average total loss: 0.753241
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.1465e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.394504
Average KL loss: 0.359409
Average total loss: 0.753912
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.4387e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.392948
Average KL loss: 0.359218
Average total loss: 0.752166
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(5.9816e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.392568
Average KL loss: 0.359078
Average total loss: 0.751647
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-5.3846e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.391666
Average KL loss: 0.358979
Average total loss: 0.750645
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.4802e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.394454
Average KL loss: 0.358915
Average total loss: 0.753369
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.6202e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.398112
Average KL loss: 0.358789
Average total loss: 0.756901
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.7395e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.392757
Average KL loss: 0.358673
Average total loss: 0.751429
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-7.8028e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.391898
Average KL loss: 0.358567
Average total loss: 0.750466
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-4.6392e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.397277
Average KL loss: 0.358430
Average total loss: 0.755707
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.9800e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.395244
Average KL loss: 0.358359
Average total loss: 0.753603
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.5600e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.394976
Average KL loss: 0.358264
Average total loss: 0.753240
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(6.6522e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.393317
Average KL loss: 0.358201
Average total loss: 0.751518
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.1357e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.393150
Average KL loss: 0.358054
Average total loss: 0.751203
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.7024e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.392444
Average KL loss: 0.357974
Average total loss: 0.750418
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.0540e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.392138
Average KL loss: 0.357857
Average total loss: 0.749995
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-6.4706e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.391520
Average KL loss: 0.357765
Average total loss: 0.749285
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.1018e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.392562
Average KL loss: 0.357716
Average total loss: 0.750278
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.1451e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.391266
Average KL loss: 0.357576
Average total loss: 0.748842
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.6489e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.391396
Average KL loss: 0.357568
Average total loss: 0.748964
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.9276e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.394267
Average KL loss: 0.357516
Average total loss: 0.751783
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.0240e-11, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.389840
Average KL loss: 0.357447
Average total loss: 0.747286
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.6187e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.395153
Average KL loss: 0.357352
Average total loss: 0.752505
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.5538e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.391729
Average KL loss: 0.357303
Average total loss: 0.749032
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.8333e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.393739
Average KL loss: 0.357219
Average total loss: 0.750959
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.0390e-11, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.391192
Average KL loss: 0.357168
Average total loss: 0.748360
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.4741e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.397257
Average KL loss: 0.357052
Average total loss: 0.754309
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(6.5513e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.396457
Average KL loss: 0.357017
Average total loss: 0.753474
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.7260e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.391605
Average KL loss: 0.356895
Average total loss: 0.748500
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.8859e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.394543
Average KL loss: 0.356867
Average total loss: 0.751410
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.6595e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.395872
Average KL loss: 0.356900
Average total loss: 0.752772
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.7022e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.394256
Average KL loss: 0.356885
Average total loss: 0.751141
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.9250e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.393951
Average KL loss: 0.356865
Average total loss: 0.750816
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-5.6638e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.396496
Average KL loss: 0.356795
Average total loss: 0.753292
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(7.0575e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.394451
Average KL loss: 0.356761
Average total loss: 0.751212
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-6.2721e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.393987
Average KL loss: 0.356723
Average total loss: 0.750710
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.8138e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.391669
Average KL loss: 0.356697
Average total loss: 0.748366
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.3689e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.395412
Average KL loss: 0.356665
Average total loss: 0.752077
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.8586e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.399931
Average KL loss: 0.356629
Average total loss: 0.756560
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(8.8326e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.394444
Average KL loss: 0.356588
Average total loss: 0.751032
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.4786e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.392079
Average KL loss: 0.356551
Average total loss: 0.748630
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(3.7777e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.393780
Average KL loss: 0.356521
Average total loss: 0.750301
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-4.7768e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.396824
Average KL loss: 0.356491
Average total loss: 0.753315
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-4.9158e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.397609
Average KL loss: 0.356467
Average total loss: 0.754076
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(8.1690e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.390453
Average KL loss: 0.356450
Average total loss: 0.746903
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.4370e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.392620
Average KL loss: 0.356447
Average total loss: 0.749067
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(4.8019e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.396857
Average KL loss: 0.356444
Average total loss: 0.753300
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(4.1111e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.393618
Average KL loss: 0.356441
Average total loss: 0.750059
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.4569e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.398283
Average KL loss: 0.356438
Average total loss: 0.754721
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(4.3525e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.395454
Average KL loss: 0.356436
Average total loss: 0.751890
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.3286e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.394056
Average KL loss: 0.356433
Average total loss: 0.750490
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-3.9845e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.394293
Average KL loss: 0.356430
Average total loss: 0.750723
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.5285e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.393414
Average KL loss: 0.356428
Average total loss: 0.749842
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(3.2890e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.394008
Average KL loss: 0.356425
Average total loss: 0.750433
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-8.1604e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.393946
Average KL loss: 0.356422
Average total loss: 0.750367
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(4.2449e-09, device='cuda:0')
 Percentile value: 8.018093922146363e-08
Non-zero model percentage: 32.76801300048828%, Non-zero mask percentage: 32.76801300048828%

--- Pruning Level [5/24]: ---
conv1.weight         | nonzeros =     124 /    1728             (  7.18%) | total_pruned =    1604 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     446 /   36864             (  1.21%) | total_pruned =   36418 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1172 /   36864             (  3.18%) | total_pruned =   35692 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     795 /   36864             (  2.16%) | total_pruned =   36069 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1258 /   36864             (  3.41%) | total_pruned =   35606 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4048 /   73728             (  5.49%) | total_pruned =   69680 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    9061 /  147456             (  6.14%) | total_pruned =  138395 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     586 /    8192             (  7.15%) | total_pruned =    7606 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   10337 /  147456             (  7.01%) | total_pruned =  137119 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   11253 /  147456             (  7.63%) | total_pruned =  136203 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   19784 /  294912             (  6.71%) | total_pruned =  275128 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     149 /     256             ( 58.20%) | total_pruned =     107 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     213 /     256             ( 83.20%) | total_pruned =      43 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      34 /     256             ( 13.28%) | total_pruned =     222 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   36875 /  589824             (  6.25%) | total_pruned =  552949 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     161 /     256             ( 62.89%) | total_pruned =      95 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     227 /     256             ( 88.67%) | total_pruned =      29 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      32 /     256             ( 12.50%) | total_pruned =     224 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2851 /   32768             (  8.70%) | total_pruned =   29917 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     173 /     256             ( 67.58%) | total_pruned =      83 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      33 /     256             ( 12.89%) | total_pruned =     223 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   41372 /  589824             (  7.01%) | total_pruned =  548452 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     155 /     256             ( 60.55%) | total_pruned =     101 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     219 /     256             ( 85.55%) | total_pruned =      37 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   44226 /  589824             (  7.50%) | total_pruned =  545598 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     147 /     256             ( 57.42%) | total_pruned =     109 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     178 /     256             ( 69.53%) | total_pruned =      78 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   82484 / 1179648             (  6.99%) | total_pruned = 1097164 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     341 /     512             ( 66.60%) | total_pruned =     171 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     472 /     512             ( 92.19%) | total_pruned =      40 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  509140 / 2359296             ( 21.58%) | total_pruned = 1850156 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     377 /     512             ( 73.63%) | total_pruned =     135 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     378 /     512             ( 73.83%) | total_pruned =     134 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     120 /     512             ( 23.44%) | total_pruned =     392 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   30803 /  131072             ( 23.50%) | total_pruned =  100269 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     382 /     512             ( 74.61%) | total_pruned =     130 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     347 /     512             ( 67.77%) | total_pruned =     165 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     113 /     512             ( 22.07%) | total_pruned =     399 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1023427 / 2359296             ( 43.38%) | total_pruned = 1335869 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     437 /     512             ( 85.35%) | total_pruned =      75 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     477 /     512             ( 93.16%) | total_pruned =      35 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1820682 / 2359296             ( 77.17%) | total_pruned =  538614 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     362 /     512             ( 70.70%) | total_pruned =     150 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     450 /     512             ( 87.89%) | total_pruned =      62 | shape = torch.Size([512])
linear.weight        | nonzeros =    4549 /    5120             ( 88.85%) | total_pruned =     571 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 3663058, pruned : 7515704, total: 11178762, Compression rate :       3.05x  ( 67.23% pruned)
Train Epoch: 79/100 Loss: 0.017749 Accuracy: 87.43 100.00 % Best test Accuracy: 87.50%
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-5.0274e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.682592
Average KL loss: 0.527979
Average total loss: 1.210571
tensor(0.0004, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.6357e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.670611
Average KL loss: 0.560892
Average total loss: 1.231502
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.6600e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.576956
Average KL loss: 0.561295
Average total loss: 1.138250
tensor(0.0030, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.1316e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.548096
Average KL loss: 0.565042
Average total loss: 1.113138
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.1486e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.517532
Average KL loss: 0.565794
Average total loss: 1.083325
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.3190e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.492805
Average KL loss: 0.569094
Average total loss: 1.061899
tensor(0.0032, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.7703e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.484835
Average KL loss: 0.577152
Average total loss: 1.061987
tensor(0.0032, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.9541e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.477155
Average KL loss: 0.581620
Average total loss: 1.058775
tensor(0.0033, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.9663e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.471175
Average KL loss: 0.585861
Average total loss: 1.057036
tensor(0.0033, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-9.0760e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.470183
Average KL loss: 0.582138
Average total loss: 1.052322
tensor(0.0033, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-2.7996e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.460457
Average KL loss: 0.583941
Average total loss: 1.044397
tensor(0.0033, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-2.3073e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.456867
Average KL loss: 0.584323
Average total loss: 1.041191
tensor(0.0034, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-2.9413e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.455647
Average KL loss: 0.590457
Average total loss: 1.046104
tensor(0.0034, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-9.0554e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.451831
Average KL loss: 0.590475
Average total loss: 1.042306
tensor(0.0035, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(4.7314e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.450754
Average KL loss: 0.594088
Average total loss: 1.044841
tensor(0.0034, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-5.8133e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.444750
Average KL loss: 0.593197
Average total loss: 1.037947
tensor(-0.0029, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.6036e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.441877
Average KL loss: 0.594373
Average total loss: 1.036250
tensor(0.0034, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(1.3263e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.437553
Average KL loss: 0.595749
Average total loss: 1.033302
tensor(0.0035, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-2.4524e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.436009
Average KL loss: 0.596812
Average total loss: 1.032821
tensor(0.0035, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(3.0306e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.438926
Average KL loss: 0.595633
Average total loss: 1.034559
tensor(0.0074, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(9.5664e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.435917
Average KL loss: 0.600805
Average total loss: 1.036722
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.8282e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.424973
Average KL loss: 0.595410
Average total loss: 1.020383
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-5.4778e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.431510
Average KL loss: 0.594796
Average total loss: 1.026307
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.1128e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.432102
Average KL loss: 0.600097
Average total loss: 1.032199
tensor(0.0011, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-5.8273e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.431812
Average KL loss: 0.604413
Average total loss: 1.036225
tensor(0.0022, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-4.6136e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.429187
Average KL loss: 0.600160
Average total loss: 1.029347
tensor(0.0038, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.7264e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.426021
Average KL loss: 0.602831
Average total loss: 1.028852
tensor(0.0036, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(1.1883e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.422896
Average KL loss: 0.594736
Average total loss: 1.017632
tensor(0.0072, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(8.1052e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.428356
Average KL loss: 0.601919
Average total loss: 1.030275
tensor(0.0040, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(2.7570e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.430171
Average KL loss: 0.603579
Average total loss: 1.033750
tensor(0.0037, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(3.5462e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.424182
Average KL loss: 0.602417
Average total loss: 1.026600
tensor(0.0037, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.7417e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.429415
Average KL loss: 0.603390
Average total loss: 1.032806
tensor(0.0039, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(1.3366e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.425423
Average KL loss: 0.602980
Average total loss: 1.028403
tensor(0.0049, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(3.4302e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.425152
Average KL loss: 0.605072
Average total loss: 1.030224
tensor(0.0038, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-4.8863e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.425538
Average KL loss: 0.605526
Average total loss: 1.031064
tensor(0.0027, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.8545e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.421904
Average KL loss: 0.600672
Average total loss: 1.022576
tensor(0.0038, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.7899e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.428835
Average KL loss: 0.608840
Average total loss: 1.037676
tensor(0.0055, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(3.9063e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.423211
Average KL loss: 0.611592
Average total loss: 1.034804
tensor(0.0038, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-6.9844e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.418581
Average KL loss: 0.606868
Average total loss: 1.025450
tensor(0.0036, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.5987e-11, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.414863
Average KL loss: 0.569510
Average total loss: 0.984374
tensor(0.0037, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-7.6690e-11, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.413716
Average KL loss: 0.513802
Average total loss: 0.927518
tensor(0.0037, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(3.6668e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.404040
Average KL loss: 0.483736
Average total loss: 0.887776
tensor(0.0037, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-2.0925e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.407835
Average KL loss: 0.465284
Average total loss: 0.873119
tensor(0.0037, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(1.1965e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.410030
Average KL loss: 0.452111
Average total loss: 0.862140
tensor(0.0037, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.1085e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.405477
Average KL loss: 0.442242
Average total loss: 0.847720
tensor(0.0037, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(6.5748e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.406011
Average KL loss: 0.433779
Average total loss: 0.839790
tensor(0.0037, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(1.6309e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.409566
Average KL loss: 0.427306
Average total loss: 0.836872
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.0061e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.407217
Average KL loss: 0.422601
Average total loss: 0.829818
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.2296e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.408949
Average KL loss: 0.418610
Average total loss: 0.827559
tensor(0.0037, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.4267e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.406408
Average KL loss: 0.415093
Average total loss: 0.821501
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.3817e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.411433
Average KL loss: 0.412037
Average total loss: 0.823469
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.9125e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.411202
Average KL loss: 0.409553
Average total loss: 0.820756
tensor(0.0037, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.0063e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.405802
Average KL loss: 0.406805
Average total loss: 0.812607
tensor(0.0037, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.8816e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.410190
Average KL loss: 0.405080
Average total loss: 0.815270
tensor(0.0037, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.3423e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.408633
Average KL loss: 0.403015
Average total loss: 0.811648
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.6544e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.412990
Average KL loss: 0.401023
Average total loss: 0.814013
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.2270e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.412693
Average KL loss: 0.399951
Average total loss: 0.812644
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.4731e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.414944
Average KL loss: 0.398884
Average total loss: 0.813827
tensor(0.0036, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.0245e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.413486
Average KL loss: 0.397972
Average total loss: 0.811458
tensor(0.0036, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-9.7448e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.411002
Average KL loss: 0.396578
Average total loss: 0.807580
tensor(0.0036, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(3.4068e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.413258
Average KL loss: 0.395716
Average total loss: 0.808974
tensor(0.0036, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.5053e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.411182
Average KL loss: 0.394871
Average total loss: 0.806053
tensor(0.0036, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(3.9822e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.415712
Average KL loss: 0.393890
Average total loss: 0.809602
tensor(0.0036, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.6778e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.411930
Average KL loss: 0.393196
Average total loss: 0.805126
tensor(0.0036, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(2.6147e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.411318
Average KL loss: 0.391929
Average total loss: 0.803247
tensor(0.0036, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.8647e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.414367
Average KL loss: 0.391716
Average total loss: 0.806083
tensor(0.0036, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.3056e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.411762
Average KL loss: 0.390977
Average total loss: 0.802739
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.5142e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.415248
Average KL loss: 0.390085
Average total loss: 0.805333
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.8090e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.418567
Average KL loss: 0.389464
Average total loss: 0.808031
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-6.5548e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.411182
Average KL loss: 0.388897
Average total loss: 0.800079
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.7193e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.416214
Average KL loss: 0.388545
Average total loss: 0.804759
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.4415e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.414421
Average KL loss: 0.388370
Average total loss: 0.802792
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.6528e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.411537
Average KL loss: 0.387333
Average total loss: 0.798871
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(6.8824e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.415396
Average KL loss: 0.386110
Average total loss: 0.801505
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(6.1771e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.415558
Average KL loss: 0.386048
Average total loss: 0.801606
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.1692e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.416139
Average KL loss: 0.386237
Average total loss: 0.802376
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.1633e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.413889
Average KL loss: 0.386113
Average total loss: 0.800002
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.8980e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.414482
Average KL loss: 0.385577
Average total loss: 0.800059
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.7878e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.416966
Average KL loss: 0.385494
Average total loss: 0.802460
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(6.4600e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.417766
Average KL loss: 0.385153
Average total loss: 0.802920
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-6.4404e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.415404
Average KL loss: 0.384726
Average total loss: 0.800130
tensor(0.0036, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.0631e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.417317
Average KL loss: 0.384193
Average total loss: 0.801510
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.1822e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.415843
Average KL loss: 0.384038
Average total loss: 0.799881
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.1505e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.412057
Average KL loss: 0.383355
Average total loss: 0.795412
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.6197e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.413972
Average KL loss: 0.383495
Average total loss: 0.797467
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.3442e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.417004
Average KL loss: 0.383345
Average total loss: 0.800349
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.2741e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.416587
Average KL loss: 0.382979
Average total loss: 0.799566
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.7959e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.417573
Average KL loss: 0.382653
Average total loss: 0.800227
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.1697e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.414448
Average KL loss: 0.382471
Average total loss: 0.796919
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.8014e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.417727
Average KL loss: 0.382109
Average total loss: 0.799835
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(6.2118e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.420096
Average KL loss: 0.381457
Average total loss: 0.801552
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.5945e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.418811
Average KL loss: 0.381656
Average total loss: 0.800467
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.8096e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.418283
Average KL loss: 0.381505
Average total loss: 0.799788
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.0264e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.412890
Average KL loss: 0.381114
Average total loss: 0.794004
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.0751e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.417417
Average KL loss: 0.380631
Average total loss: 0.798048
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.0255e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.418581
Average KL loss: 0.380688
Average total loss: 0.799270
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.9574e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.417511
Average KL loss: 0.380535
Average total loss: 0.798046
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.4888e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.416841
Average KL loss: 0.380554
Average total loss: 0.797394
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-8.8856e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.417414
Average KL loss: 0.380322
Average total loss: 0.797736
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(7.6237e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.419722
Average KL loss: 0.379694
Average total loss: 0.799416
tensor(0.0036, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.9265e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.418598
Average KL loss: 0.379749
Average total loss: 0.798347
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.8594e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.417718
Average KL loss: 0.379181
Average total loss: 0.796899
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.1416e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.421452
Average KL loss: 0.379312
Average total loss: 0.800764
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.0883e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.417813
Average KL loss: 0.379135
Average total loss: 0.796947
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.4490e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.416074
Average KL loss: 0.378891
Average total loss: 0.794965
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(3.6980e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.420330
Average KL loss: 0.378151
Average total loss: 0.798481
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.6215e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.415285
Average KL loss: 0.376624
Average total loss: 0.791910
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.0674e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.418621
Average KL loss: 0.375450
Average total loss: 0.794071
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-5.0276e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.419920
Average KL loss: 0.374496
Average total loss: 0.794416
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.6941e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.420368
Average KL loss: 0.373636
Average total loss: 0.794004
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(7.5606e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.417018
Average KL loss: 0.372903
Average total loss: 0.789921
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(8.9450e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.415279
Average KL loss: 0.372197
Average total loss: 0.787477
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.7191e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.423081
Average KL loss: 0.371554
Average total loss: 0.794634
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(6.4819e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.415288
Average KL loss: 0.370970
Average total loss: 0.786258
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.8648e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.415932
Average KL loss: 0.370440
Average total loss: 0.786372
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.2567e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.419279
Average KL loss: 0.369952
Average total loss: 0.789231
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.3039e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.417800
Average KL loss: 0.369512
Average total loss: 0.787312
tensor(0.0036, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.5452e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.416323
Average KL loss: 0.369099
Average total loss: 0.785422
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.4952e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.416922
Average KL loss: 0.368694
Average total loss: 0.785616
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.1264e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.419462
Average KL loss: 0.368312
Average total loss: 0.787774
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.9080e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.417653
Average KL loss: 0.367910
Average total loss: 0.785563
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-4.2195e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.413171
Average KL loss: 0.367529
Average total loss: 0.780700
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.3645e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.421547
Average KL loss: 0.367206
Average total loss: 0.788753
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.0028e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.421391
Average KL loss: 0.366931
Average total loss: 0.788322
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.1282e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.417467
Average KL loss: 0.366663
Average total loss: 0.784131
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.8086e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.417925
Average KL loss: 0.366410
Average total loss: 0.784335
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-8.2620e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.420194
Average KL loss: 0.366168
Average total loss: 0.786362
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.4939e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.413633
Average KL loss: 0.365865
Average total loss: 0.779498
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.4992e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.415131
Average KL loss: 0.365614
Average total loss: 0.780745
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.1931e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.413982
Average KL loss: 0.365439
Average total loss: 0.779421
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.8173e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.415323
Average KL loss: 0.365243
Average total loss: 0.780566
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.1049e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.416933
Average KL loss: 0.364963
Average total loss: 0.781895
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(3.3565e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.419464
Average KL loss: 0.364723
Average total loss: 0.784187
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-6.3439e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.418801
Average KL loss: 0.364501
Average total loss: 0.783302
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.1215e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.414283
Average KL loss: 0.364315
Average total loss: 0.778598
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.3553e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.421138
Average KL loss: 0.364131
Average total loss: 0.785269
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.5693e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.421106
Average KL loss: 0.363997
Average total loss: 0.785103
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-7.9796e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.416758
Average KL loss: 0.363887
Average total loss: 0.780646
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-7.7442e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.416105
Average KL loss: 0.363724
Average total loss: 0.779829
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-5.0269e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.416942
Average KL loss: 0.363504
Average total loss: 0.780446
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-9.2186e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.421350
Average KL loss: 0.363290
Average total loss: 0.784639
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.5618e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.414763
Average KL loss: 0.363086
Average total loss: 0.777849
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.5144e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.414032
Average KL loss: 0.362934
Average total loss: 0.776966
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.0628e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.417124
Average KL loss: 0.362733
Average total loss: 0.779857
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-7.4281e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.421290
Average KL loss: 0.362579
Average total loss: 0.783869
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-8.7682e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.417997
Average KL loss: 0.362474
Average total loss: 0.780472
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-4.5269e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.417508
Average KL loss: 0.362409
Average total loss: 0.779917
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.0267e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.417479
Average KL loss: 0.362285
Average total loss: 0.779764
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.0903e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.420967
Average KL loss: 0.362211
Average total loss: 0.783178
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.6020e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.415205
Average KL loss: 0.362120
Average total loss: 0.777325
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-4.4824e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.414344
Average KL loss: 0.361975
Average total loss: 0.776319
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.3818e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.415671
Average KL loss: 0.361821
Average total loss: 0.777492
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.1728e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.415496
Average KL loss: 0.361673
Average total loss: 0.777169
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-4.2136e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.414927
Average KL loss: 0.361526
Average total loss: 0.776453
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(3.3314e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.412453
Average KL loss: 0.361449
Average total loss: 0.773902
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.8755e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.419172
Average KL loss: 0.361306
Average total loss: 0.780477
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.5483e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.417848
Average KL loss: 0.361195
Average total loss: 0.779044
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.0560e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.417181
Average KL loss: 0.361140
Average total loss: 0.778321
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(5.6065e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.413055
Average KL loss: 0.361076
Average total loss: 0.774131
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(5.6129e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.416267
Average KL loss: 0.360988
Average total loss: 0.777254
tensor(0.0036, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.1228e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.413781
Average KL loss: 0.360934
Average total loss: 0.774715
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-7.5167e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.422659
Average KL loss: 0.360792
Average total loss: 0.783451
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(4.0218e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.415382
Average KL loss: 0.360662
Average total loss: 0.776044
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(8.1988e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.423614
Average KL loss: 0.360533
Average total loss: 0.784147
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(4.8352e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.418295
Average KL loss: 0.360458
Average total loss: 0.778753
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-4.5110e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.414833
Average KL loss: 0.360408
Average total loss: 0.775241
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(5.3133e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.418516
Average KL loss: 0.360370
Average total loss: 0.778886
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.3489e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.417605
Average KL loss: 0.360338
Average total loss: 0.777943
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.0840e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.416281
Average KL loss: 0.360303
Average total loss: 0.776584
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-4.1045e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.416410
Average KL loss: 0.360273
Average total loss: 0.776683
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.1150e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.417517
Average KL loss: 0.360248
Average total loss: 0.777765
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.1548e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.420193
Average KL loss: 0.360224
Average total loss: 0.780417
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.5298e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.414725
Average KL loss: 0.360199
Average total loss: 0.774924
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.2878e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.416138
Average KL loss: 0.360173
Average total loss: 0.776311
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(7.8083e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.415325
Average KL loss: 0.360144
Average total loss: 0.775469
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.8561e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.418033
Average KL loss: 0.360122
Average total loss: 0.778155
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.1838e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.416713
Average KL loss: 0.360099
Average total loss: 0.776812
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.3022e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.420264
Average KL loss: 0.360085
Average total loss: 0.780349
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.3087e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.418251
Average KL loss: 0.360082
Average total loss: 0.778333
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.2482e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.412928
Average KL loss: 0.360080
Average total loss: 0.773008
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.6842e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.423338
Average KL loss: 0.360077
Average total loss: 0.783414
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.4328e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.413724
Average KL loss: 0.360074
Average total loss: 0.773799
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.3178e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.418788
Average KL loss: 0.360072
Average total loss: 0.778859
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-6.1645e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.421536
Average KL loss: 0.360070
Average total loss: 0.781606
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(4.5307e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.415118
Average KL loss: 0.360067
Average total loss: 0.775185
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.6028e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.419192
Average KL loss: 0.360065
Average total loss: 0.779256
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.9505e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.416939
Average KL loss: 0.360062
Average total loss: 0.777001
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.2125e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.417853
Average KL loss: 0.360060
Average total loss: 0.777913
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-4.2089e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.417257
Average KL loss: 0.360058
Average total loss: 0.777315
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-9.7416e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.415108
Average KL loss: 0.360055
Average total loss: 0.775163
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.9773e-09, device='cuda:0')
 Percentile value: 8.045829247294023e-08
Non-zero model percentage: 26.214414596557617%, Non-zero mask percentage: 26.214414596557617%

--- Pruning Level [6/24]: ---
conv1.weight         | nonzeros =     108 /    1728             (  6.25%) | total_pruned =    1620 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     252 /   36864             (  0.68%) | total_pruned =   36612 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     545 /   36864             (  1.48%) | total_pruned =   36319 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     396 /   36864             (  1.07%) | total_pruned =   36468 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     725 /   36864             (  1.97%) | total_pruned =   36139 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2590 /   73728             (  3.51%) | total_pruned =   71138 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    5758 /  147456             (  3.90%) | total_pruned =  141698 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     411 /    8192             (  5.02%) | total_pruned =    7781 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    6744 /  147456             (  4.57%) | total_pruned =  140712 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    6793 /  147456             (  4.61%) | total_pruned =  140663 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   13372 /  294912             (  4.53%) | total_pruned =  281540 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     108 /     256             ( 42.19%) | total_pruned =     148 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     213 /     256             ( 83.20%) | total_pruned =      43 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      32 /     256             ( 12.50%) | total_pruned =     224 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   24188 /  589824             (  4.10%) | total_pruned =  565636 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1882 /   32768             (  5.74%) | total_pruned =   30886 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     107 /     256             ( 41.80%) | total_pruned =     149 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     162 /     256             ( 63.28%) | total_pruned =      94 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      31 /     256             ( 12.11%) | total_pruned =     225 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   25014 /  589824             (  4.24%) | total_pruned =  564810 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     121 /     256             ( 47.27%) | total_pruned =     135 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     212 /     256             ( 82.81%) | total_pruned =      44 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   24418 /  589824             (  4.14%) | total_pruned =  565406 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      91 /     256             ( 35.55%) | total_pruned =     165 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     160 /     256             ( 62.50%) | total_pruned =      96 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   49614 / 1179648             (  4.21%) | total_pruned = 1130034 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     248 /     512             ( 48.44%) | total_pruned =     264 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     463 /     512             ( 90.43%) | total_pruned =      49 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  405150 / 2359296             ( 17.17%) | total_pruned = 1954146 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     307 /     512             ( 59.96%) | total_pruned =     205 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     335 /     512             ( 65.43%) | total_pruned =     177 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     106 /     512             ( 20.70%) | total_pruned =     406 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   23007 /  131072             ( 17.55%) | total_pruned =  108065 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     326 /     512             ( 63.67%) | total_pruned =     186 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     268 /     512             ( 52.34%) | total_pruned =     244 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      95 /     512             ( 18.55%) | total_pruned =     417 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  791981 / 2359296             ( 33.57%) | total_pruned = 1567315 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     398 /     512             ( 77.73%) | total_pruned =     114 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     383 /     512             ( 74.80%) | total_pruned =     129 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1536656 / 2359296             ( 65.13%) | total_pruned =  822640 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     315 /     512             ( 61.52%) | total_pruned =     197 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     486 /     512             ( 94.92%) | total_pruned =      26 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     405 /     512             ( 79.10%) | total_pruned =     107 | shape = torch.Size([512])
linear.weight        | nonzeros =    4135 /    5120             ( 80.76%) | total_pruned =     985 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 2930447, pruned : 8248315, total: 11178762, Compression rate :       3.81x  ( 73.79% pruned)
Train Epoch: 58/100 Loss: 0.016878 Accuracy: 87.13 100.00 % Best test Accuracy: 87.21%
tensor(0.0036, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-4.1162e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.655958
Average KL loss: 0.479807
Average total loss: 1.135765
tensor(3.3775e-05, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-9.8350e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.685342
Average KL loss: 0.527283
Average total loss: 1.212625
tensor(0.0026, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.3804e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.597252
Average KL loss: 0.535779
Average total loss: 1.133031
tensor(0.0029, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.0558e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.561485
Average KL loss: 0.539006
Average total loss: 1.100490
tensor(0.0030, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.1030e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.531012
Average KL loss: 0.545805
Average total loss: 1.076816
tensor(0.0030, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.1042e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.519220
Average KL loss: 0.550790
Average total loss: 1.070010
tensor(0.0031, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(6.8572e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.500224
Average KL loss: 0.553375
Average total loss: 1.053599
tensor(0.0031, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.9994e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.489622
Average KL loss: 0.551696
Average total loss: 1.041318
tensor(0.0031, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-6.6299e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.476421
Average KL loss: 0.556226
Average total loss: 1.032647
tensor(0.0032, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-3.2338e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.492913
Average KL loss: 0.560172
Average total loss: 1.053085
tensor(0.0032, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(2.7555e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.470516
Average KL loss: 0.563360
Average total loss: 1.033875
tensor(0.0032, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-8.3286e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.472527
Average KL loss: 0.562730
Average total loss: 1.035257
tensor(0.0033, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(8.5714e-12, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.466523
Average KL loss: 0.561061
Average total loss: 1.027584
tensor(0.0033, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-4.3944e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.462999
Average KL loss: 0.562453
Average total loss: 1.025452
tensor(0.0033, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-5.2310e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.466311
Average KL loss: 0.567325
Average total loss: 1.033635
tensor(0.0033, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.1282e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.460255
Average KL loss: 0.571801
Average total loss: 1.032056
tensor(-0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.6060e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.449796
Average KL loss: 0.566160
Average total loss: 1.015956
tensor(0.0030, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.3154e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.456593
Average KL loss: 0.564732
Average total loss: 1.021325
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-7.1593e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.448624
Average KL loss: 0.569784
Average total loss: 1.018408
tensor(0.0034, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.5462e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.449167
Average KL loss: 0.573653
Average total loss: 1.022821
tensor(0.0089, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(1.3537e-07, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.447943
Average KL loss: 0.575461
Average total loss: 1.023403
tensor(0.0031, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.6554e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.438700
Average KL loss: 0.573885
Average total loss: 1.012585
tensor(0.0035, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.1129e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.445278
Average KL loss: 0.573400
Average total loss: 1.018678
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.7184e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.444738
Average KL loss: 0.574506
Average total loss: 1.019244
tensor(-9.5981e-05, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-9.0876e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.442317
Average KL loss: 0.578293
Average total loss: 1.020610
tensor(0.0031, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-8.9350e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.444273
Average KL loss: 0.575099
Average total loss: 1.019373
tensor(0.0035, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.1946e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.438931
Average KL loss: 0.571973
Average total loss: 1.010904
tensor(0.0035, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.2779e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.442639
Average KL loss: 0.573862
Average total loss: 1.016502
tensor(0.0085, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(1.2751e-07, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.436971
Average KL loss: 0.573722
Average total loss: 1.010692
tensor(0.0044, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.5601e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.441452
Average KL loss: 0.578063
Average total loss: 1.019515
tensor(0.0036, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(7.8703e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.433254
Average KL loss: 0.579404
Average total loss: 1.012658
tensor(0.0035, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(3.6236e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.438148
Average KL loss: 0.575687
Average total loss: 1.013835
tensor(0.0039, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(8.8882e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.436848
Average KL loss: 0.581042
Average total loss: 1.017890
tensor(0.0053, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(4.0709e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.434881
Average KL loss: 0.577935
Average total loss: 1.012815
tensor(0.0037, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.4309e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.440135
Average KL loss: 0.579772
Average total loss: 1.019907
tensor(0.0035, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-7.0434e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.432708
Average KL loss: 0.578394
Average total loss: 1.011102
tensor(0.0037, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.4800e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.437024
Average KL loss: 0.586108
Average total loss: 1.023131
tensor(0.0061, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(6.3316e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.433724
Average KL loss: 0.582719
Average total loss: 1.016443
tensor(0.0037, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(4.0451e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.430335
Average KL loss: 0.580814
Average total loss: 1.011150
tensor(0.0036, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-5.7737e-11, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.434648
Average KL loss: 0.581027
Average total loss: 1.015675
tensor(0.0036, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-4.9677e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.427784
Average KL loss: 0.556840
Average total loss: 0.984624
tensor(0.0036, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(6.4074e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.421917
Average KL loss: 0.514664
Average total loss: 0.936581
tensor(0.0036, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(8.1050e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.423091
Average KL loss: 0.490558
Average total loss: 0.913649
tensor(0.0036, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(1.8476e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.420496
Average KL loss: 0.474033
Average total loss: 0.894529
tensor(0.0036, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.1827e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.419633
Average KL loss: 0.462159
Average total loss: 0.881792
tensor(0.0036, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(1.9871e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.414745
Average KL loss: 0.453064
Average total loss: 0.867809
tensor(0.0036, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(3.0143e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.426848
Average KL loss: 0.445209
Average total loss: 0.872058
tensor(0.0036, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(3.8734e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.421718
Average KL loss: 0.439301
Average total loss: 0.861019
tensor(0.0036, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(1.5539e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.426268
Average KL loss: 0.433875
Average total loss: 0.860142
tensor(0.0036, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(7.6694e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.426585
Average KL loss: 0.429789
Average total loss: 0.856373
tensor(0.0036, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-5.8981e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.421839
Average KL loss: 0.426334
Average total loss: 0.848173
tensor(0.0036, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(1.8764e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.419372
Average KL loss: 0.423094
Average total loss: 0.842466
tensor(0.0036, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-3.9902e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.422354
Average KL loss: 0.420364
Average total loss: 0.842717
tensor(0.0036, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-3.0899e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.416387
Average KL loss: 0.417372
Average total loss: 0.833759
tensor(0.0036, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(6.0426e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.423911
Average KL loss: 0.415331
Average total loss: 0.839241
tensor(0.0036, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-9.8832e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.421474
Average KL loss: 0.413267
Average total loss: 0.834741
tensor(0.0036, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.4089e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.426521
Average KL loss: 0.411590
Average total loss: 0.838111
tensor(0.0035, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.2803e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.418291
Average KL loss: 0.409955
Average total loss: 0.828246
tensor(0.0035, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.1499e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.425919
Average KL loss: 0.408460
Average total loss: 0.834379
tensor(0.0035, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.6338e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.425007
Average KL loss: 0.406877
Average total loss: 0.831883
tensor(0.0035, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.1885e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.423339
Average KL loss: 0.405636
Average total loss: 0.828975
tensor(0.0035, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.9881e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.426349
Average KL loss: 0.404603
Average total loss: 0.830952
tensor(0.0035, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.1531e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.424429
Average KL loss: 0.402891
Average total loss: 0.827320
tensor(0.0035, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.1609e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.426268
Average KL loss: 0.402299
Average total loss: 0.828567
tensor(0.0035, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.1479e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.427413
Average KL loss: 0.401357
Average total loss: 0.828770
tensor(0.0035, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(5.9622e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.424338
Average KL loss: 0.400407
Average total loss: 0.824745
tensor(0.0035, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-4.6341e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.424308
Average KL loss: 0.399620
Average total loss: 0.823928
tensor(0.0035, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.6449e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.426406
Average KL loss: 0.398753
Average total loss: 0.825159
tensor(0.0035, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.8711e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.424767
Average KL loss: 0.398436
Average total loss: 0.823204
tensor(0.0035, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-6.1424e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.430234
Average KL loss: 0.397846
Average total loss: 0.828080
tensor(0.0035, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.6502e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.424084
Average KL loss: 0.397110
Average total loss: 0.821193
tensor(0.0035, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.2221e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.435392
Average KL loss: 0.396546
Average total loss: 0.831937
tensor(0.0035, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.0663e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.429004
Average KL loss: 0.396169
Average total loss: 0.825173
tensor(0.0035, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-4.5073e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.428374
Average KL loss: 0.395686
Average total loss: 0.824060
tensor(0.0035, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-4.3911e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.425700
Average KL loss: 0.395061
Average total loss: 0.820761
tensor(0.0035, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(4.1462e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.428975
Average KL loss: 0.393906
Average total loss: 0.822881
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(2.9432e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.433201
Average KL loss: 0.393753
Average total loss: 0.826954
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(1.2469e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.428311
Average KL loss: 0.393146
Average total loss: 0.821457
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(4.8429e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.432436
Average KL loss: 0.392865
Average total loss: 0.825301
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-5.8341e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.431022
Average KL loss: 0.392426
Average total loss: 0.823448
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.0426e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.428584
Average KL loss: 0.392018
Average total loss: 0.820603
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(5.1347e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.428927
Average KL loss: 0.391152
Average total loss: 0.820079
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.2469e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.428299
Average KL loss: 0.390379
Average total loss: 0.818678
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.1737e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.427617
Average KL loss: 0.389443
Average total loss: 0.817060
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(4.9121e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.429869
Average KL loss: 0.389009
Average total loss: 0.818878
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.2178e-11, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.426059
Average KL loss: 0.388304
Average total loss: 0.814362
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.3577e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.430454
Average KL loss: 0.388133
Average total loss: 0.818587
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-4.8041e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.426562
Average KL loss: 0.387780
Average total loss: 0.814343
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.7648e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.433780
Average KL loss: 0.387655
Average total loss: 0.821436
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-4.2327e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.433503
Average KL loss: 0.387373
Average total loss: 0.820876
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.6312e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.433961
Average KL loss: 0.387000
Average total loss: 0.820961
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.3158e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.433224
Average KL loss: 0.386787
Average total loss: 0.820011
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.7051e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.432228
Average KL loss: 0.386137
Average total loss: 0.818365
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.4581e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.432980
Average KL loss: 0.386319
Average total loss: 0.819300
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.5423e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.432733
Average KL loss: 0.385909
Average total loss: 0.818642
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-9.0562e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.434566
Average KL loss: 0.385735
Average total loss: 0.820301
tensor(0.0034, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(8.5626e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.428696
Average KL loss: 0.385681
Average total loss: 0.814377
tensor(0.0034, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.9433e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.430248
Average KL loss: 0.385232
Average total loss: 0.815481
tensor(0.0034, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-7.6692e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.437543
Average KL loss: 0.384290
Average total loss: 0.821833
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.7435e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.431324
Average KL loss: 0.383481
Average total loss: 0.814805
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(6.6527e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.429004
Average KL loss: 0.382803
Average total loss: 0.811807
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-7.3464e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.427828
Average KL loss: 0.382183
Average total loss: 0.810011
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.0301e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.431816
Average KL loss: 0.381556
Average total loss: 0.813371
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-5.0567e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.426602
Average KL loss: 0.381064
Average total loss: 0.807667
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.4160e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.432766
Average KL loss: 0.380611
Average total loss: 0.813377
tensor(0.0035, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.5634e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.435236
Average KL loss: 0.380152
Average total loss: 0.815387
tensor(0.0035, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.9043e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.434416
Average KL loss: 0.379811
Average total loss: 0.814226
tensor(0.0035, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-8.9458e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.431277
Average KL loss: 0.379437
Average total loss: 0.810714
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.1989e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.430530
Average KL loss: 0.379020
Average total loss: 0.809550
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.7897e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.430599
Average KL loss: 0.378700
Average total loss: 0.809299
tensor(0.0035, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(8.0327e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.438878
Average KL loss: 0.378364
Average total loss: 0.817242
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.6474e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.427655
Average KL loss: 0.378042
Average total loss: 0.805697
tensor(0.0035, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.1789e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.432453
Average KL loss: 0.377767
Average total loss: 0.810220
tensor(0.0035, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.9241e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.430742
Average KL loss: 0.377497
Average total loss: 0.808239
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.4697e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.434333
Average KL loss: 0.377208
Average total loss: 0.811542
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.3562e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.429672
Average KL loss: 0.376903
Average total loss: 0.806576
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-8.0866e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.429328
Average KL loss: 0.376613
Average total loss: 0.805941
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.9569e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.432536
Average KL loss: 0.376333
Average total loss: 0.808868
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.0183e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.431988
Average KL loss: 0.376129
Average total loss: 0.808118
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.1291e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.430569
Average KL loss: 0.375926
Average total loss: 0.806495
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.2257e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.435017
Average KL loss: 0.375670
Average total loss: 0.810688
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.1878e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.435380
Average KL loss: 0.375440
Average total loss: 0.810820
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.6490e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.431043
Average KL loss: 0.375242
Average total loss: 0.806285
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.5251e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.432538
Average KL loss: 0.375155
Average total loss: 0.807693
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.3045e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.428020
Average KL loss: 0.375119
Average total loss: 0.803140
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.9349e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.428632
Average KL loss: 0.375083
Average total loss: 0.803715
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.2162e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.431217
Average KL loss: 0.375046
Average total loss: 0.806263
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(6.4872e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.433182
Average KL loss: 0.375018
Average total loss: 0.808200
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.7185e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.426830
Average KL loss: 0.374987
Average total loss: 0.801817
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.7739e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.428785
Average KL loss: 0.374955
Average total loss: 0.803740
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(6.8437e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.435147
Average KL loss: 0.374921
Average total loss: 0.810068
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(8.4999e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.430353
Average KL loss: 0.374892
Average total loss: 0.805245
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.8712e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.433663
Average KL loss: 0.374858
Average total loss: 0.808521
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-4.4535e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.431263
Average KL loss: 0.374826
Average total loss: 0.806089
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.5894e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.433584
Average KL loss: 0.374796
Average total loss: 0.808379
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.2997e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.426022
Average KL loss: 0.374767
Average total loss: 0.800788
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.9429e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.429129
Average KL loss: 0.374733
Average total loss: 0.803862
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.7169e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.430948
Average KL loss: 0.374701
Average total loss: 0.805650
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.6428e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.431607
Average KL loss: 0.374675
Average total loss: 0.806282
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(8.3625e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.433455
Average KL loss: 0.374650
Average total loss: 0.808105
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.4773e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.431649
Average KL loss: 0.374615
Average total loss: 0.806264
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.4242e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.430885
Average KL loss: 0.374586
Average total loss: 0.805471
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.7127e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.426970
Average KL loss: 0.374556
Average total loss: 0.801526
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.6001e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.430708
Average KL loss: 0.374525
Average total loss: 0.805232
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(3.2963e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.431574
Average KL loss: 0.374494
Average total loss: 0.806068
tensor(0.0034, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(5.7871e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.429131
Average KL loss: 0.374468
Average total loss: 0.803600
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.9338e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.429167
Average KL loss: 0.374441
Average total loss: 0.803608
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.1992e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.432397
Average KL loss: 0.374428
Average total loss: 0.806824
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.8995e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.435679
Average KL loss: 0.374425
Average total loss: 0.810105
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.6139e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.431426
Average KL loss: 0.374422
Average total loss: 0.805849
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.9206e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.428625
Average KL loss: 0.374420
Average total loss: 0.803045
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(5.5827e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.435117
Average KL loss: 0.374417
Average total loss: 0.809534
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(5.8091e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.429765
Average KL loss: 0.374414
Average total loss: 0.804179
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(4.0773e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.439064
Average KL loss: 0.374411
Average total loss: 0.813475
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.4768e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.433173
Average KL loss: 0.374408
Average total loss: 0.807581
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(5.4753e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.429452
Average KL loss: 0.374406
Average total loss: 0.803858
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(4.8771e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.431282
Average KL loss: 0.374403
Average total loss: 0.805685
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.0033e-09, device='cuda:0')
 Percentile value: 8.111659610676725e-08
Non-zero model percentage: 20.971534729003906%, Non-zero mask percentage: 20.971534729003906%

--- Pruning Level [7/24]: ---
conv1.weight         | nonzeros =      86 /    1728             (  4.98%) | total_pruned =    1642 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     109 /   36864             (  0.30%) | total_pruned =   36755 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     214 /   36864             (  0.58%) | total_pruned =   36650 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     210 /   36864             (  0.57%) | total_pruned =   36654 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     417 /   36864             (  1.13%) | total_pruned =   36447 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1680 /   73728             (  2.28%) | total_pruned =   72048 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3624 /  147456             (  2.46%) | total_pruned =  143832 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     251 /    8192             (  3.06%) | total_pruned =    7941 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4058 /  147456             (  2.75%) | total_pruned =  143398 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3974 /  147456             (  2.70%) | total_pruned =  143482 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    8890 /  294912             (  3.01%) | total_pruned =  286022 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   15332 /  589824             (  2.60%) | total_pruned =  574492 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1135 /   32768             (  3.46%) | total_pruned =   31633 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      32 /     256             ( 12.50%) | total_pruned =     224 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     143 /     256             ( 55.86%) | total_pruned =     113 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   14197 /  589824             (  2.41%) | total_pruned =  575627 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      48 /     256             ( 18.75%) | total_pruned =     208 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     201 /     256             ( 78.52%) | total_pruned =      55 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   11575 /  589824             (  1.96%) | total_pruned =  578249 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     141 /     256             ( 55.08%) | total_pruned =     115 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   28590 / 1179648             (  2.42%) | total_pruned = 1151058 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      86 /     512             ( 16.80%) | total_pruned =     426 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     441 /     512             ( 86.13%) | total_pruned =      71 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   67119 / 2359296             (  2.84%) | total_pruned = 2292177 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     213 /     512             ( 41.60%) | total_pruned =     299 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     280 /     512             ( 54.69%) | total_pruned =     232 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      89 /     512             ( 17.38%) | total_pruned =     423 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   19583 /  131072             ( 14.94%) | total_pruned =  111489 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     259 /     512             ( 50.59%) | total_pruned =     253 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     199 /     512             ( 38.87%) | total_pruned =     313 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      84 /     512             ( 16.41%) | total_pruned =     428 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  749850 / 2359296             ( 31.78%) | total_pruned = 1609446 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     349 /     512             ( 68.16%) | total_pruned =     163 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     339 /     512             ( 66.21%) | total_pruned =     173 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1404910 / 2359296             ( 59.55%) | total_pruned =  954386 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     231 /     512             ( 45.12%) | total_pruned =     281 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     400 /     512             ( 78.12%) | total_pruned =     112 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     318 /     512             ( 62.11%) | total_pruned =     194 | shape = torch.Size([512])
linear.weight        | nonzeros =    3389 /    5120             ( 66.19%) | total_pruned =    1731 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 2344358, pruned : 8834404, total: 11178762, Compression rate :       4.77x  ( 79.03% pruned)
Train Epoch: 64/100 Loss: 0.021139 Accuracy: 86.69 100.00 % Best test Accuracy: 86.97%
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.7162e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.716251
Average KL loss: 0.449383
Average total loss: 1.165634
tensor(-0.0001, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-9.9256e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.741540
Average KL loss: 0.499073
Average total loss: 1.240613
tensor(0.0025, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.8670e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.625910
Average KL loss: 0.513779
Average total loss: 1.139689
tensor(0.0028, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-6.1370e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.569075
Average KL loss: 0.520093
Average total loss: 1.089168
tensor(0.0028, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.8650e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.555775
Average KL loss: 0.525705
Average total loss: 1.081480
tensor(0.0029, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.6095e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.541967
Average KL loss: 0.532179
Average total loss: 1.074146
tensor(0.0030, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.0447e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.520888
Average KL loss: 0.532644
Average total loss: 1.053533
tensor(0.0030, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.0135e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.510454
Average KL loss: 0.536950
Average total loss: 1.047404
tensor(0.0031, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-2.2392e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.502128
Average KL loss: 0.541411
Average total loss: 1.043539
tensor(0.0031, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.6879e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.494576
Average KL loss: 0.543130
Average total loss: 1.037706
tensor(0.0031, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.1421e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.483410
Average KL loss: 0.546079
Average total loss: 1.029490
tensor(0.0031, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.1784e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.479823
Average KL loss: 0.543420
Average total loss: 1.023243
tensor(0.0032, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(3.6167e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.481099
Average KL loss: 0.549248
Average total loss: 1.030347
tensor(0.0032, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-5.5632e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.479036
Average KL loss: 0.555832
Average total loss: 1.034868
tensor(0.0033, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-2.2548e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.473527
Average KL loss: 0.552338
Average total loss: 1.025864
tensor(0.0033, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(2.0772e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.476341
Average KL loss: 0.558834
Average total loss: 1.035175
tensor(-0.0051, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.1051e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.463767
Average KL loss: 0.559700
Average total loss: 1.023467
tensor(0.0040, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.6432e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.459676
Average KL loss: 0.550506
Average total loss: 1.010182
tensor(0.0032, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-3.2205e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.462712
Average KL loss: 0.554677
Average total loss: 1.017390
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-5.1907e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.461976
Average KL loss: 0.558359
Average total loss: 1.020335
tensor(0.0033, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(2.6045e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.466728
Average KL loss: 0.561053
Average total loss: 1.027781
tensor(0.0048, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(3.4307e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.456488
Average KL loss: 0.559690
Average total loss: 1.016178
tensor(0.0034, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.3230e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.457339
Average KL loss: 0.558827
Average total loss: 1.016165
tensor(0.0034, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-9.3422e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.459186
Average KL loss: 0.561057
Average total loss: 1.020242
tensor(0.0034, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.9538e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.457493
Average KL loss: 0.563957
Average total loss: 1.021450
tensor(-0.0015, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.2258e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.454471
Average KL loss: 0.561714
Average total loss: 1.016185
tensor(0.0038, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(8.7818e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.449239
Average KL loss: 0.563945
Average total loss: 1.013184
tensor(0.0035, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-3.9909e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.447771
Average KL loss: 0.566778
Average total loss: 1.014549
tensor(0.0035, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-5.0645e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.450996
Average KL loss: 0.567468
Average total loss: 1.018464
tensor(0.0020, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-3.6312e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.446990
Average KL loss: 0.549443
Average total loss: 0.996433
tensor(0.0034, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.6726e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.441174
Average KL loss: 0.520135
Average total loss: 0.961309
tensor(0.0035, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.8327e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.436594
Average KL loss: 0.501394
Average total loss: 0.937988
tensor(0.0035, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(5.7854e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.435989
Average KL loss: 0.488192
Average total loss: 0.924180
tensor(0.0035, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.2895e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.437685
Average KL loss: 0.477924
Average total loss: 0.915609
tensor(0.0035, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.9093e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.433807
Average KL loss: 0.469657
Average total loss: 0.903464
tensor(0.0035, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(7.5562e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.437834
Average KL loss: 0.462845
Average total loss: 0.900679
tensor(0.0035, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.9936e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.435961
Average KL loss: 0.457188
Average total loss: 0.893150
tensor(0.0035, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(5.6919e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.439359
Average KL loss: 0.452123
Average total loss: 0.891482
tensor(0.0035, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(3.5582e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.436198
Average KL loss: 0.448153
Average total loss: 0.884352
tensor(0.0035, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.6109e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.441817
Average KL loss: 0.444861
Average total loss: 0.886679
tensor(0.0034, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.7768e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.434297
Average KL loss: 0.440860
Average total loss: 0.875157
tensor(0.0034, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(2.3153e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.438176
Average KL loss: 0.437683
Average total loss: 0.875859
tensor(0.0034, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-4.2206e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.440495
Average KL loss: 0.434997
Average total loss: 0.875493
tensor(0.0034, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.5357e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.439305
Average KL loss: 0.432907
Average total loss: 0.872212
tensor(0.0034, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.7143e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.440676
Average KL loss: 0.430373
Average total loss: 0.871049
tensor(0.0034, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.2188e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.439609
Average KL loss: 0.428225
Average total loss: 0.867834
tensor(0.0034, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.6525e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.441940
Average KL loss: 0.426532
Average total loss: 0.868472
tensor(0.0034, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(9.0963e-11, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.438515
Average KL loss: 0.425256
Average total loss: 0.863771
tensor(0.0034, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.9112e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.442216
Average KL loss: 0.423650
Average total loss: 0.865865
tensor(0.0034, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(3.7514e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.443840
Average KL loss: 0.422046
Average total loss: 0.865886
tensor(0.0034, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-2.6782e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.438890
Average KL loss: 0.420328
Average total loss: 0.859218
tensor(0.0034, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(6.6208e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.443689
Average KL loss: 0.419127
Average total loss: 0.862817
tensor(0.0034, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(4.3139e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.442509
Average KL loss: 0.418141
Average total loss: 0.860650
tensor(0.0034, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-2.3616e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.438970
Average KL loss: 0.417284
Average total loss: 0.856254
tensor(0.0034, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(1.0732e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.438349
Average KL loss: 0.416017
Average total loss: 0.854366
tensor(0.0034, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(1.2246e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.443317
Average KL loss: 0.414441
Average total loss: 0.857759
tensor(0.0034, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.1416e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.445635
Average KL loss: 0.413884
Average total loss: 0.859519
tensor(0.0034, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(5.3164e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.444721
Average KL loss: 0.413104
Average total loss: 0.857825
tensor(0.0034, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(1.9582e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.441531
Average KL loss: 0.412421
Average total loss: 0.853952
tensor(0.0034, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-7.6228e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.443727
Average KL loss: 0.411803
Average total loss: 0.855530
tensor(0.0034, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(1.6939e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.447223
Average KL loss: 0.410970
Average total loss: 0.858192
tensor(0.0034, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(2.1337e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.443247
Average KL loss: 0.410351
Average total loss: 0.853598
tensor(0.0034, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(4.7099e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.443524
Average KL loss: 0.409506
Average total loss: 0.853030
tensor(0.0034, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-2.9574e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.442652
Average KL loss: 0.408651
Average total loss: 0.851303
tensor(0.0034, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-5.3414e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.440817
Average KL loss: 0.408103
Average total loss: 0.848920
tensor(0.0034, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(1.1283e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.443817
Average KL loss: 0.407434
Average total loss: 0.851251
tensor(0.0034, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(2.5989e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.445886
Average KL loss: 0.406892
Average total loss: 0.852778
tensor(0.0034, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(5.4307e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.441684
Average KL loss: 0.406451
Average total loss: 0.848135
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(5.1744e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.450590
Average KL loss: 0.405804
Average total loss: 0.856394
tensor(0.0034, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(1.6100e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.445850
Average KL loss: 0.405143
Average total loss: 0.850993
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.5203e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.445692
Average KL loss: 0.404436
Average total loss: 0.850129
tensor(0.0034, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(1.6439e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.450743
Average KL loss: 0.404124
Average total loss: 0.854867
tensor(0.0034, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(6.7822e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.449765
Average KL loss: 0.404032
Average total loss: 0.853798
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.0249e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.449434
Average KL loss: 0.403992
Average total loss: 0.853426
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(3.1989e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.446105
Average KL loss: 0.403123
Average total loss: 0.849228
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.1101e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.447186
Average KL loss: 0.402620
Average total loss: 0.849806
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(1.2274e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.443653
Average KL loss: 0.402016
Average total loss: 0.845669
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(5.2868e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.449665
Average KL loss: 0.401847
Average total loss: 0.851512
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(3.3140e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.449306
Average KL loss: 0.401711
Average total loss: 0.851016
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-6.9693e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.449113
Average KL loss: 0.401415
Average total loss: 0.850528
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(1.0767e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.448435
Average KL loss: 0.400962
Average total loss: 0.849397
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-2.8681e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.456439
Average KL loss: 0.400467
Average total loss: 0.856905
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(6.4194e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.449311
Average KL loss: 0.400568
Average total loss: 0.849880
tensor(0.0033, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(2.9501e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.448307
Average KL loss: 0.400488
Average total loss: 0.848795
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(3.1300e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.449243
Average KL loss: 0.400642
Average total loss: 0.849885
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(5.7791e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.440139
Average KL loss: 0.400133
Average total loss: 0.840271
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-5.0535e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.448110
Average KL loss: 0.399401
Average total loss: 0.847511
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-8.6502e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.447137
Average KL loss: 0.398831
Average total loss: 0.845968
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.8465e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.445522
Average KL loss: 0.398430
Average total loss: 0.843951
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-3.6114e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.442944
Average KL loss: 0.397821
Average total loss: 0.840764
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.5721e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.445966
Average KL loss: 0.397395
Average total loss: 0.843361
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(7.6399e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.455458
Average KL loss: 0.397404
Average total loss: 0.852862
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(3.8586e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.453740
Average KL loss: 0.397326
Average total loss: 0.851066
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-2.7414e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.458713
Average KL loss: 0.397118
Average total loss: 0.855830
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.6071e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.452964
Average KL loss: 0.397073
Average total loss: 0.850037
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(1.4222e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.450322
Average KL loss: 0.396781
Average total loss: 0.847104
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.9022e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.449411
Average KL loss: 0.396865
Average total loss: 0.846276
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(7.6355e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.447371
Average KL loss: 0.396566
Average total loss: 0.843938
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(3.1941e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.448913
Average KL loss: 0.395826
Average total loss: 0.844740
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(9.4036e-11, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.447588
Average KL loss: 0.395219
Average total loss: 0.842807
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(2.6667e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.446634
Average KL loss: 0.394696
Average total loss: 0.841331
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(2.8125e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.449914
Average KL loss: 0.394221
Average total loss: 0.844135
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(1.0540e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.445422
Average KL loss: 0.393809
Average total loss: 0.839231
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(1.8369e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.451278
Average KL loss: 0.393442
Average total loss: 0.844721
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(3.2477e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.453215
Average KL loss: 0.393086
Average total loss: 0.846300
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(4.6197e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.441998
Average KL loss: 0.392697
Average total loss: 0.834695
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-4.8611e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.444441
Average KL loss: 0.392352
Average total loss: 0.836793
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.6784e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.448499
Average KL loss: 0.392068
Average total loss: 0.840567
tensor(0.0033, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-7.7546e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.452108
Average KL loss: 0.391774
Average total loss: 0.843882
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-4.6167e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.449933
Average KL loss: 0.391524
Average total loss: 0.841457
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(3.8191e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.447201
Average KL loss: 0.391269
Average total loss: 0.838470
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-3.5135e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.445131
Average KL loss: 0.391007
Average total loss: 0.836139
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-5.8584e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.444832
Average KL loss: 0.390728
Average total loss: 0.835560
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-3.0052e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.448976
Average KL loss: 0.390475
Average total loss: 0.839452
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(7.1811e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.446660
Average KL loss: 0.390233
Average total loss: 0.836892
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(1.0697e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.447215
Average KL loss: 0.390005
Average total loss: 0.837220
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(2.6616e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.448973
Average KL loss: 0.389792
Average total loss: 0.838766
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-6.3862e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.448565
Average KL loss: 0.389654
Average total loss: 0.838219
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(2.4019e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.446648
Average KL loss: 0.389629
Average total loss: 0.836277
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(1.3051e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.448244
Average KL loss: 0.389601
Average total loss: 0.837845
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-4.7827e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.447478
Average KL loss: 0.389574
Average total loss: 0.837052
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(2.6499e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.440985
Average KL loss: 0.389546
Average total loss: 0.830531
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(5.0699e-12, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.450370
Average KL loss: 0.389518
Average total loss: 0.839889
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-3.8991e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.447311
Average KL loss: 0.389491
Average total loss: 0.836802
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-2.6028e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.446428
Average KL loss: 0.389463
Average total loss: 0.835891
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.3021e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.446063
Average KL loss: 0.389441
Average total loss: 0.835504
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.4074e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.446451
Average KL loss: 0.389414
Average total loss: 0.835864
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(6.3557e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.448562
Average KL loss: 0.389390
Average total loss: 0.837952
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-2.7823e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.450367
Average KL loss: 0.389365
Average total loss: 0.839732
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-2.4780e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.447739
Average KL loss: 0.389336
Average total loss: 0.837075
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.5160e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.451610
Average KL loss: 0.389308
Average total loss: 0.840918
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(7.2677e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.447667
Average KL loss: 0.389283
Average total loss: 0.836950
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(1.3237e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.445139
Average KL loss: 0.389256
Average total loss: 0.834395
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-2.2358e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.449802
Average KL loss: 0.389241
Average total loss: 0.839043
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(6.8824e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.444697
Average KL loss: 0.389239
Average total loss: 0.833936
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-3.8976e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.443816
Average KL loss: 0.389236
Average total loss: 0.833052
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-5.4617e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.448003
Average KL loss: 0.389234
Average total loss: 0.837237
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-5.4247e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.451011
Average KL loss: 0.389232
Average total loss: 0.840243
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(2.4419e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.449068
Average KL loss: 0.389229
Average total loss: 0.838297
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(1.7847e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.446060
Average KL loss: 0.389227
Average total loss: 0.835286
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-4.4056e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.446471
Average KL loss: 0.389224
Average total loss: 0.835695
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.5252e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.447701
Average KL loss: 0.389222
Average total loss: 0.836923
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-6.3388e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.446188
Average KL loss: 0.389220
Average total loss: 0.835408
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-8.0778e-09, device='cuda:0')
 Percentile value: 8.043165422577658e-08
Non-zero model percentage: 16.777233123779297%, Non-zero mask percentage: 16.777233123779297%

--- Pruning Level [8/24]: ---
conv1.weight         | nonzeros =      81 /    1728             (  4.69%) | total_pruned =    1647 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      91 /   36864             (  0.25%) | total_pruned =   36773 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     164 /   36864             (  0.44%) | total_pruned =   36700 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     159 /   36864             (  0.43%) | total_pruned =   36705 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     322 /   36864             (  0.87%) | total_pruned =   36542 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1253 /   73728             (  1.70%) | total_pruned =   72475 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2712 /  147456             (  1.84%) | total_pruned =  144744 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     198 /    8192             (  2.42%) | total_pruned =    7994 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2914 /  147456             (  1.98%) | total_pruned =  144542 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2798 /  147456             (  1.90%) | total_pruned =  144658 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    6487 /  294912             (  2.20%) | total_pruned =  288425 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      31 /     256             ( 12.11%) | total_pruned =     225 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   11102 /  589824             (  1.88%) | total_pruned =  578722 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     853 /   32768             (  2.60%) | total_pruned =   31915 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     132 /     256             ( 51.56%) | total_pruned =     124 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    9602 /  589824             (  1.63%) | total_pruned =  580222 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     200 /     256             ( 78.12%) | total_pruned =      56 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    7429 /  589824             (  1.26%) | total_pruned =  582395 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     134 /     256             ( 52.34%) | total_pruned =     122 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   18937 / 1179648             (  1.61%) | total_pruned = 1160711 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      68 /     512             ( 13.28%) | total_pruned =     444 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     430 /     512             ( 83.98%) | total_pruned =      82 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   30620 / 2359296             (  1.30%) | total_pruned = 2328676 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     212 /     512             ( 41.41%) | total_pruned =     300 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      75 /     512             ( 14.65%) | total_pruned =     437 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1668 /  131072             (  1.27%) | total_pruned =  129404 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     130 /     512             ( 25.39%) | total_pruned =     382 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      73 /     512             ( 14.26%) | total_pruned =     439 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  389408 / 2359296             ( 16.51%) | total_pruned = 1969888 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     342 /     512             ( 66.80%) | total_pruned =     170 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     332 /     512             ( 64.84%) | total_pruned =     180 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1381284 / 2359296             ( 58.55%) | total_pruned =  978012 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     225 /     512             ( 43.95%) | total_pruned =     287 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     391 /     512             ( 76.37%) | total_pruned =     121 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     273 /     512             ( 53.32%) | total_pruned =     239 | shape = torch.Size([512])
linear.weight        | nonzeros =    3047 /    5120             ( 59.51%) | total_pruned =    2073 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 1875487, pruned : 9303275, total: 11178762, Compression rate :       5.96x  ( 83.22% pruned)
Train Epoch: 70/100 Loss: 0.034000 Accuracy: 85.94 100.00 % Best test Accuracy: 86.55%
tensor(0.0033, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-2.8151e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.773525
Average KL loss: 0.424357
Average total loss: 1.197881
tensor(-0.0004, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.1223e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.798657
Average KL loss: 0.468270
Average total loss: 1.266927
tensor(0.0023, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.2888e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.675438
Average KL loss: 0.488037
Average total loss: 1.163475
tensor(0.0026, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.1666e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.615031
Average KL loss: 0.495356
Average total loss: 1.110387
tensor(0.0027, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.0129e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.593713
Average KL loss: 0.502787
Average total loss: 1.096500
tensor(0.0027, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.3933e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.560789
Average KL loss: 0.507994
Average total loss: 1.068783
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.2933e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.547478
Average KL loss: 0.515956
Average total loss: 1.063434
tensor(0.0029, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.6471e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.533436
Average KL loss: 0.523173
Average total loss: 1.056609
tensor(0.0029, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-6.7138e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.519541
Average KL loss: 0.522189
Average total loss: 1.041730
tensor(0.0030, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(2.6460e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.510546
Average KL loss: 0.525061
Average total loss: 1.035607
tensor(0.0030, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-5.0827e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.506438
Average KL loss: 0.526846
Average total loss: 1.033284
tensor(0.0030, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-5.7427e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.505585
Average KL loss: 0.533507
Average total loss: 1.039092
tensor(0.0031, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.6093e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.505305
Average KL loss: 0.538418
Average total loss: 1.043723
tensor(0.0031, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.8950e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.500021
Average KL loss: 0.540124
Average total loss: 1.040144
tensor(0.0031, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(6.2482e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.490329
Average KL loss: 0.539269
Average total loss: 1.029598
tensor(0.0032, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(1.6369e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.486199
Average KL loss: 0.543703
Average total loss: 1.029902
tensor(-0.0034, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.6497e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.487026
Average KL loss: 0.544178
Average total loss: 1.031204
tensor(0.0028, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.2294e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.484426
Average KL loss: 0.546622
Average total loss: 1.031048
tensor(0.0032, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.6138e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.488545
Average KL loss: 0.545696
Average total loss: 1.034240
tensor(0.0033, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(1.2958e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.477762
Average KL loss: 0.550839
Average total loss: 1.028602
tensor(0.0092, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.4453e-07, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.470780
Average KL loss: 0.550361
Average total loss: 1.021141
tensor(0.0029, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.5805e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.469573
Average KL loss: 0.553203
Average total loss: 1.022776
tensor(0.0034, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.0002e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.472027
Average KL loss: 0.553516
Average total loss: 1.025543
tensor(0.0033, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-5.5691e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.472230
Average KL loss: 0.561773
Average total loss: 1.034003
tensor(-0.0004, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-9.8029e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.469068
Average KL loss: 0.556795
Average total loss: 1.025863
tensor(0.0030, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-8.8780e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.463213
Average KL loss: 0.557750
Average total loss: 1.020963
tensor(0.0034, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(7.2354e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.462880
Average KL loss: 0.558010
Average total loss: 1.020891
tensor(0.0034, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(3.9353e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.461435
Average KL loss: 0.559041
Average total loss: 1.020476
tensor(0.0088, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(1.3370e-07, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.460487
Average KL loss: 0.561421
Average total loss: 1.021908
tensor(0.0044, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.3286e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.462809
Average KL loss: 0.560011
Average total loss: 1.022819
tensor(0.0035, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(7.8977e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.466527
Average KL loss: 0.566121
Average total loss: 1.032648
tensor(0.0035, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-7.4093e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.454019
Average KL loss: 0.563415
Average total loss: 1.017433
tensor(0.0038, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(1.1508e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.453117
Average KL loss: 0.564536
Average total loss: 1.017653
tensor(0.0053, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(4.0705e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.453427
Average KL loss: 0.565179
Average total loss: 1.018606
tensor(0.0037, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(6.8987e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.453410
Average KL loss: 0.572007
Average total loss: 1.025417
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-6.3789e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.450907
Average KL loss: 0.567208
Average total loss: 1.018115
tensor(0.0036, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-3.7059e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.452222
Average KL loss: 0.567350
Average total loss: 1.019572
tensor(0.0062, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(6.4291e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.449427
Average KL loss: 0.567011
Average total loss: 1.016438
tensor(0.0037, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.1301e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.448279
Average KL loss: 0.566528
Average total loss: 1.014807
tensor(0.0035, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(2.7967e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.456977
Average KL loss: 0.570963
Average total loss: 1.027939
tensor(0.0035, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.7068e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.454265
Average KL loss: 0.570430
Average total loss: 1.024694
tensor(0.0077, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(9.7937e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.451596
Average KL loss: 0.573774
Average total loss: 1.025371
tensor(0.0048, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(2.9770e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.444728
Average KL loss: 0.568787
Average total loss: 1.013515
tensor(0.0037, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(9.0368e-11, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.453987
Average KL loss: 0.569974
Average total loss: 1.023962
tensor(0.0038, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(6.2253e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.447359
Average KL loss: 0.574079
Average total loss: 1.021439
tensor(0.0037, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(4.6025e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.457383
Average KL loss: 0.573308
Average total loss: 1.030690
tensor(-0.0075, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-2.7601e-07, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.444038
Average KL loss: 0.577732
Average total loss: 1.021770
tensor(0.0045, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(2.0672e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.447066
Average KL loss: 0.573412
Average total loss: 1.020478
tensor(0.0037, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(2.0534e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.449083
Average KL loss: 0.575012
Average total loss: 1.024095
tensor(0.0037, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-1.6486e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.449705
Average KL loss: 0.572053
Average total loss: 1.021758
tensor(0.0037, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-2.8655e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.447804
Average KL loss: 0.572614
Average total loss: 1.020418
tensor(0.0023, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-3.5487e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.444054
Average KL loss: 0.579167
Average total loss: 1.023222
tensor(0.0037, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-2.4484e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.447181
Average KL loss: 0.575994
Average total loss: 1.023174
tensor(0.0038, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(3.3106e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.444631
Average KL loss: 0.577019
Average total loss: 1.021650
tensor(0.0037, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(2.4308e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.432961
Average KL loss: 0.565497
Average total loss: 0.998458
tensor(0.0037, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(7.2285e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.429218
Average KL loss: 0.542870
Average total loss: 0.972088
tensor(0.0037, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(5.3187e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.435208
Average KL loss: 0.527543
Average total loss: 0.962751
tensor(0.0037, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(4.9448e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.430239
Average KL loss: 0.516260
Average total loss: 0.946498
tensor(0.0037, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(2.3163e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.430174
Average KL loss: 0.506904
Average total loss: 0.937078
tensor(0.0037, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(4.4941e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.431627
Average KL loss: 0.499346
Average total loss: 0.930972
tensor(0.0037, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-3.2449e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.430339
Average KL loss: 0.493445
Average total loss: 0.923784
tensor(0.0037, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(4.8386e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.431295
Average KL loss: 0.488030
Average total loss: 0.919325
tensor(0.0037, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(3.8277e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.430903
Average KL loss: 0.482951
Average total loss: 0.913854
tensor(0.0037, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(5.4573e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.427479
Average KL loss: 0.478544
Average total loss: 0.906023
tensor(0.0037, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(7.6259e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.428433
Average KL loss: 0.474472
Average total loss: 0.902905
tensor(0.0037, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(5.0912e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.430643
Average KL loss: 0.471427
Average total loss: 0.902070
tensor(0.0036, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(1.5982e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.426478
Average KL loss: 0.468599
Average total loss: 0.895077
tensor(0.0036, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(5.6786e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.431626
Average KL loss: 0.465510
Average total loss: 0.897136
tensor(0.0036, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(6.5581e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.432265
Average KL loss: 0.462697
Average total loss: 0.894963
tensor(0.0036, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.1870e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.433065
Average KL loss: 0.460454
Average total loss: 0.893519
tensor(0.0036, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(2.3793e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.426038
Average KL loss: 0.458364
Average total loss: 0.884402
tensor(0.0036, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-4.3746e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.428925
Average KL loss: 0.456285
Average total loss: 0.885209
tensor(0.0036, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.2508e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.434356
Average KL loss: 0.454544
Average total loss: 0.888900
tensor(0.0036, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(1.0854e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.435073
Average KL loss: 0.452490
Average total loss: 0.887563
tensor(0.0036, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(3.4280e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.429636
Average KL loss: 0.450813
Average total loss: 0.880449
tensor(0.0036, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(1.1687e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.433373
Average KL loss: 0.449450
Average total loss: 0.882824
tensor(0.0036, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.6863e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.434371
Average KL loss: 0.447642
Average total loss: 0.882013
tensor(0.0036, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.3070e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.438840
Average KL loss: 0.446020
Average total loss: 0.884860
tensor(0.0036, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(3.4128e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.434870
Average KL loss: 0.445031
Average total loss: 0.879901
tensor(0.0036, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(5.4699e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.435906
Average KL loss: 0.443728
Average total loss: 0.879635
tensor(0.0036, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.3232e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.440133
Average KL loss: 0.442265
Average total loss: 0.882398
tensor(0.0036, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-4.6545e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.436856
Average KL loss: 0.441333
Average total loss: 0.878189
tensor(0.0036, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(9.5384e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.433811
Average KL loss: 0.440546
Average total loss: 0.874356
tensor(0.0036, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(1.0234e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.438169
Average KL loss: 0.439265
Average total loss: 0.877435
tensor(0.0036, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(4.6417e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.436308
Average KL loss: 0.438530
Average total loss: 0.874838
tensor(0.0036, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.1102e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.438710
Average KL loss: 0.437547
Average total loss: 0.876257
tensor(0.0035, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-6.8175e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.438385
Average KL loss: 0.436761
Average total loss: 0.875147
tensor(0.0035, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(6.5149e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.437808
Average KL loss: 0.435651
Average total loss: 0.873460
tensor(0.0035, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-7.3289e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.444491
Average KL loss: 0.434750
Average total loss: 0.879242
tensor(0.0035, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.7529e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.436441
Average KL loss: 0.434254
Average total loss: 0.870695
tensor(0.0035, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.4283e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.438961
Average KL loss: 0.433313
Average total loss: 0.872274
tensor(0.0035, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.4888e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.443982
Average KL loss: 0.432934
Average total loss: 0.876916
tensor(0.0035, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(3.2869e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.440035
Average KL loss: 0.432126
Average total loss: 0.872161
tensor(0.0035, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(1.8107e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.444024
Average KL loss: 0.431402
Average total loss: 0.875426
tensor(0.0035, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-6.5864e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.437517
Average KL loss: 0.430807
Average total loss: 0.868324
tensor(0.0035, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.9865e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.435303
Average KL loss: 0.430194
Average total loss: 0.865497
tensor(0.0035, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.6043e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.440836
Average KL loss: 0.429164
Average total loss: 0.870000
tensor(0.0035, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.4950e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.443788
Average KL loss: 0.428864
Average total loss: 0.872652
tensor(0.0035, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(2.3424e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.440943
Average KL loss: 0.428635
Average total loss: 0.869578
tensor(0.0035, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-8.4575e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.441705
Average KL loss: 0.428209
Average total loss: 0.869913
tensor(0.0035, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.1209e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.448606
Average KL loss: 0.427584
Average total loss: 0.876190
tensor(0.0035, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-9.8886e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.443791
Average KL loss: 0.426695
Average total loss: 0.870486
tensor(0.0035, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-5.3581e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.441450
Average KL loss: 0.426269
Average total loss: 0.867719
tensor(0.0035, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.1808e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.444785
Average KL loss: 0.425741
Average total loss: 0.870526
tensor(0.0035, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.2063e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.447554
Average KL loss: 0.425522
Average total loss: 0.873075
tensor(0.0035, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(4.3932e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.443583
Average KL loss: 0.425055
Average total loss: 0.868638
tensor(0.0035, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.4260e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.441812
Average KL loss: 0.424345
Average total loss: 0.866156
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(3.2068e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.438661
Average KL loss: 0.423748
Average total loss: 0.862409
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-8.3019e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.445443
Average KL loss: 0.423270
Average total loss: 0.868714
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-7.5196e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.443780
Average KL loss: 0.422866
Average total loss: 0.866646
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-4.7167e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.444570
Average KL loss: 0.422478
Average total loss: 0.867048
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.4108e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.442175
Average KL loss: 0.422110
Average total loss: 0.864285
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-5.4847e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.441337
Average KL loss: 0.421757
Average total loss: 0.863094
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.0626e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.445341
Average KL loss: 0.421426
Average total loss: 0.866767
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-3.2009e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.444249
Average KL loss: 0.421124
Average total loss: 0.865372
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-5.9783e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.441101
Average KL loss: 0.420858
Average total loss: 0.861959
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.0890e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.445696
Average KL loss: 0.420572
Average total loss: 0.866268
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.0939e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.442664
Average KL loss: 0.420319
Average total loss: 0.862984
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(8.6256e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.442959
Average KL loss: 0.420081
Average total loss: 0.863040
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.9877e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.445137
Average KL loss: 0.419868
Average total loss: 0.865005
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-4.4379e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.441946
Average KL loss: 0.419664
Average total loss: 0.861609
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(2.7885e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.440614
Average KL loss: 0.419426
Average total loss: 0.860040
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-3.8378e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.445301
Average KL loss: 0.419260
Average total loss: 0.864561
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.3944e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.440543
Average KL loss: 0.419096
Average total loss: 0.859639
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-6.4393e-12, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.443235
Average KL loss: 0.418909
Average total loss: 0.862144
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.1756e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.447267
Average KL loss: 0.418713
Average total loss: 0.865980
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(1.0452e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.440523
Average KL loss: 0.418483
Average total loss: 0.859005
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(1.2080e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.441395
Average KL loss: 0.418283
Average total loss: 0.859678
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-3.0366e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.439683
Average KL loss: 0.418113
Average total loss: 0.857796
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-4.2868e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.447260
Average KL loss: 0.417940
Average total loss: 0.865200
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(6.6612e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.444313
Average KL loss: 0.417781
Average total loss: 0.862094
tensor(0.0035, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-3.7535e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.443864
Average KL loss: 0.417609
Average total loss: 0.861473
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(8.2306e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.442939
Average KL loss: 0.417445
Average total loss: 0.860385
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.6897e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.440663
Average KL loss: 0.417282
Average total loss: 0.857945
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.2789e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.444159
Average KL loss: 0.417149
Average total loss: 0.861308
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(3.1921e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.445314
Average KL loss: 0.417003
Average total loss: 0.862317
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.5001e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.443187
Average KL loss: 0.416854
Average total loss: 0.860041
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-6.6171e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.447197
Average KL loss: 0.416712
Average total loss: 0.863909
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(5.3581e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.446700
Average KL loss: 0.416606
Average total loss: 0.863306
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-3.9333e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.448423
Average KL loss: 0.416476
Average total loss: 0.864899
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(2.3005e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.440201
Average KL loss: 0.416389
Average total loss: 0.856590
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.9731e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.449016
Average KL loss: 0.416371
Average total loss: 0.865387
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-6.3448e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.444728
Average KL loss: 0.416349
Average total loss: 0.861078
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.1667e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.441322
Average KL loss: 0.416327
Average total loss: 0.857649
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.9052e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.446897
Average KL loss: 0.416310
Average total loss: 0.863207
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.6057e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.448627
Average KL loss: 0.416294
Average total loss: 0.864922
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(2.2428e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.443546
Average KL loss: 0.416276
Average total loss: 0.859823
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.3819e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.440015
Average KL loss: 0.416258
Average total loss: 0.856273
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.9347e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.446147
Average KL loss: 0.416240
Average total loss: 0.862387
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(3.1310e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.437684
Average KL loss: 0.416218
Average total loss: 0.853902
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.1877e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.443394
Average KL loss: 0.416195
Average total loss: 0.859590
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-5.8983e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.445393
Average KL loss: 0.416178
Average total loss: 0.861571
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.6438e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.444747
Average KL loss: 0.416163
Average total loss: 0.860910
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(5.3723e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.441740
Average KL loss: 0.416149
Average total loss: 0.857889
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.4392e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.445020
Average KL loss: 0.416133
Average total loss: 0.861153
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.2512e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.443614
Average KL loss: 0.416114
Average total loss: 0.859728
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.7427e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.448992
Average KL loss: 0.416098
Average total loss: 0.865090
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.6364e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.440097
Average KL loss: 0.416085
Average total loss: 0.856182
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-6.7840e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.446253
Average KL loss: 0.416066
Average total loss: 0.862319
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(2.8344e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.445782
Average KL loss: 0.416044
Average total loss: 0.861826
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.2081e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.442301
Average KL loss: 0.416026
Average total loss: 0.858327
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(2.4345e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.443597
Average KL loss: 0.416014
Average total loss: 0.859611
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.3296e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.443296
Average KL loss: 0.416012
Average total loss: 0.859308
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-4.7347e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.441404
Average KL loss: 0.416011
Average total loss: 0.857414
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(8.5868e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.447113
Average KL loss: 0.416009
Average total loss: 0.863122
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(3.9483e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.440279
Average KL loss: 0.416007
Average total loss: 0.856286
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-5.4489e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.445654
Average KL loss: 0.416006
Average total loss: 0.861659
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-5.3457e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.441668
Average KL loss: 0.416004
Average total loss: 0.857672
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.1052e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.444636
Average KL loss: 0.416002
Average total loss: 0.860638
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.4254e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.442350
Average KL loss: 0.416000
Average total loss: 0.858350
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(6.0595e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.445086
Average KL loss: 0.415999
Average total loss: 0.861084
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(3.9819e-09, device='cuda:0')
 Percentile value: 8.030483655829812e-08
Non-zero model percentage: 13.42179012298584%, Non-zero mask percentage: 13.42179012298584%

--- Pruning Level [9/24]: ---
conv1.weight         | nonzeros =      79 /    1728             (  4.57%) | total_pruned =    1649 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      83 /   36864             (  0.23%) | total_pruned =   36781 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     145 /   36864             (  0.39%) | total_pruned =   36719 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     126 /   36864             (  0.34%) | total_pruned =   36738 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     287 /   36864             (  0.78%) | total_pruned =   36577 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     972 /   73728             (  1.32%) | total_pruned =   72756 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2122 /  147456             (  1.44%) | total_pruned =  145334 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     167 /    8192             (  2.04%) | total_pruned =    8025 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2261 /  147456             (  1.53%) | total_pruned =  145195 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2144 /  147456             (  1.45%) | total_pruned =  145312 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    5052 /  294912             (  1.71%) | total_pruned =  289860 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      31 /     256             ( 12.11%) | total_pruned =     225 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    8647 /  589824             (  1.47%) | total_pruned =  581177 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     194 /     256             ( 75.78%) | total_pruned =      62 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     674 /   32768             (  2.06%) | total_pruned =   32094 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     129 /     256             ( 50.39%) | total_pruned =     127 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    7013 /  589824             (  1.19%) | total_pruned =  582811 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     193 /     256             ( 75.39%) | total_pruned =      63 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    5466 /  589824             (  0.93%) | total_pruned =  584358 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   13464 / 1179648             (  1.14%) | total_pruned = 1166184 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      66 /     512             ( 12.89%) | total_pruned =     446 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     418 /     512             ( 81.64%) | total_pruned =      94 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   22861 / 2359296             (  0.97%) | total_pruned = 2336435 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     202 /     512             ( 39.45%) | total_pruned =     310 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      73 /     512             ( 14.26%) | total_pruned =     439 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1291 /  131072             (  0.98%) | total_pruned =  129781 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     112 /     512             ( 21.88%) | total_pruned =     400 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      69 /     512             ( 13.48%) | total_pruned =     443 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   51619 / 2359296             (  2.19%) | total_pruned = 2307677 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     342 /     512             ( 66.80%) | total_pruned =     170 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     324 /     512             ( 63.28%) | total_pruned =     188 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1368838 / 2359296             ( 58.02%) | total_pruned =  990458 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     224 /     512             ( 43.75%) | total_pruned =     288 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     390 /     512             ( 76.17%) | total_pruned =     122 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     266 /     512             ( 51.95%) | total_pruned =     246 | shape = torch.Size([512])
linear.weight        | nonzeros =    2829 /    5120             ( 55.25%) | total_pruned =    2291 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 1500390, pruned : 9678372, total: 11178762, Compression rate :       7.45x  ( 86.58% pruned)
Train Epoch: 77/100 Loss: 0.025189 Accuracy: 85.29 99.99 % Best test Accuracy: 85.61%
tensor(0.0035, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.9402e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.757707
Average KL loss: 0.421486
Average total loss: 1.179193
tensor(-0.0005, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-9.8441e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.833082
Average KL loss: 0.443826
Average total loss: 1.276908
tensor(0.0021, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.6464e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.718184
Average KL loss: 0.467972
Average total loss: 1.186156
tensor(0.0025, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.0750e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.667459
Average KL loss: 0.475685
Average total loss: 1.143144
tensor(0.0025, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.1263e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.624299
Average KL loss: 0.481832
Average total loss: 1.106131
tensor(0.0026, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.2449e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.591731
Average KL loss: 0.491220
Average total loss: 1.082951
tensor(0.0027, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.3715e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.581026
Average KL loss: 0.497959
Average total loss: 1.078986
tensor(0.0027, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.5823e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.568979
Average KL loss: 0.504327
Average total loss: 1.073306
tensor(0.0028, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.4946e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.547852
Average KL loss: 0.505133
Average total loss: 1.052985
tensor(0.0028, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.2036e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.539932
Average KL loss: 0.508580
Average total loss: 1.048512
tensor(0.0028, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.1241e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.540070
Average KL loss: 0.513176
Average total loss: 1.053246
tensor(0.0029, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-6.2071e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.525328
Average KL loss: 0.517134
Average total loss: 1.042462
tensor(0.0029, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-4.7771e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.528612
Average KL loss: 0.518929
Average total loss: 1.047541
tensor(0.0029, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(2.4316e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.519007
Average KL loss: 0.520397
Average total loss: 1.039403
tensor(0.0030, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(2.9440e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.516006
Average KL loss: 0.522729
Average total loss: 1.038735
tensor(0.0030, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(1.8258e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.503288
Average KL loss: 0.526174
Average total loss: 1.029462
tensor(-0.0036, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.6868e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.495068
Average KL loss: 0.528114
Average total loss: 1.023182
tensor(0.0027, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.0231e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.518061
Average KL loss: 0.529710
Average total loss: 1.047771
tensor(0.0030, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.8851e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.494043
Average KL loss: 0.532448
Average total loss: 1.026492
tensor(0.0031, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.5436e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.498068
Average KL loss: 0.532762
Average total loss: 1.030830
tensor(0.0090, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.3950e-07, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.485391
Average KL loss: 0.535455
Average total loss: 1.020846
tensor(0.0028, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.1537e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.481353
Average KL loss: 0.537088
Average total loss: 1.018441
tensor(0.0032, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(5.1492e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.482933
Average KL loss: 0.535354
Average total loss: 1.018287
tensor(0.0032, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-6.0661e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.488894
Average KL loss: 0.541683
Average total loss: 1.030577
tensor(-0.0005, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-9.8631e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.476698
Average KL loss: 0.540992
Average total loss: 1.017690
tensor(0.0029, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-7.7653e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.479935
Average KL loss: 0.541484
Average total loss: 1.021419
tensor(0.0033, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.7437e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.471411
Average KL loss: 0.544779
Average total loss: 1.016190
tensor(0.0033, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.0693e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.467846
Average KL loss: 0.545991
Average total loss: 1.013837
tensor(0.0087, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(1.2955e-07, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.471289
Average KL loss: 0.550084
Average total loss: 1.021373
tensor(0.0043, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.9417e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.472741
Average KL loss: 0.549097
Average total loss: 1.021838
tensor(0.0034, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(1.4577e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.470413
Average KL loss: 0.549662
Average total loss: 1.020076
tensor(0.0034, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.6725e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.463180
Average KL loss: 0.547155
Average total loss: 1.010335
tensor(0.0037, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(1.9537e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.470615
Average KL loss: 0.553686
Average total loss: 1.024301
tensor(0.0052, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(4.3976e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.464214
Average KL loss: 0.551705
Average total loss: 1.015919
tensor(0.0036, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-7.8346e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.457661
Average KL loss: 0.553153
Average total loss: 1.010814
tensor(0.0033, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-4.9050e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.462837
Average KL loss: 0.552638
Average total loss: 1.015475
tensor(0.0035, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.0557e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.465087
Average KL loss: 0.555816
Average total loss: 1.020903
tensor(0.0061, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(6.3712e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.463631
Average KL loss: 0.554614
Average total loss: 1.018245
tensor(0.0036, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(4.4918e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.459154
Average KL loss: 0.553597
Average total loss: 1.012751
tensor(0.0034, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.3032e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.457474
Average KL loss: 0.554354
Average total loss: 1.011828
tensor(0.0034, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-3.1841e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.462348
Average KL loss: 0.556020
Average total loss: 1.018368
tensor(0.0076, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(1.0426e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.449087
Average KL loss: 0.560838
Average total loss: 1.009925
tensor(0.0047, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(3.0331e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.463240
Average KL loss: 0.557108
Average total loss: 1.020348
tensor(0.0036, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-6.7420e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.463583
Average KL loss: 0.559445
Average total loss: 1.023027
tensor(0.0038, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(5.9616e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.453908
Average KL loss: 0.557901
Average total loss: 1.011809
tensor(0.0036, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(4.2240e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.451499
Average KL loss: 0.560048
Average total loss: 1.011547
tensor(-0.0076, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-2.8067e-07, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.458826
Average KL loss: 0.562058
Average total loss: 1.020884
tensor(0.0044, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(2.7282e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.454439
Average KL loss: 0.559995
Average total loss: 1.014434
tensor(0.0036, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(1.3317e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.461217
Average KL loss: 0.563221
Average total loss: 1.024439
tensor(0.0036, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-2.3825e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.454677
Average KL loss: 0.560930
Average total loss: 1.015607
tensor(0.0036, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(4.8383e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.452833
Average KL loss: 0.561660
Average total loss: 1.014494
tensor(0.0023, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-3.2066e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.451449
Average KL loss: 0.567008
Average total loss: 1.018458
tensor(0.0036, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-3.7022e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.449011
Average KL loss: 0.562706
Average total loss: 1.011717
tensor(0.0038, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(1.3225e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.439719
Average KL loss: 0.556402
Average total loss: 0.996120
tensor(0.0036, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(3.3912e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.444062
Average KL loss: 0.541101
Average total loss: 0.985163
tensor(0.0036, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-6.6312e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.438936
Average KL loss: 0.529683
Average total loss: 0.968619
tensor(0.0036, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(2.7114e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.440007
Average KL loss: 0.520899
Average total loss: 0.960906
tensor(0.0036, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(1.3056e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.438518
Average KL loss: 0.513769
Average total loss: 0.952288
tensor(0.0036, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(4.9031e-11, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.435728
Average KL loss: 0.507502
Average total loss: 0.943229
tensor(0.0036, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(4.2054e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.436240
Average KL loss: 0.501902
Average total loss: 0.938142
tensor(0.0036, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.8156e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.441168
Average KL loss: 0.497310
Average total loss: 0.938477
tensor(0.0036, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-3.8931e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.438446
Average KL loss: 0.493605
Average total loss: 0.932051
tensor(0.0036, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(3.5999e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.436708
Average KL loss: 0.489965
Average total loss: 0.926673
tensor(0.0036, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(7.4179e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.436966
Average KL loss: 0.486496
Average total loss: 0.923463
tensor(0.0036, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-2.4747e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.443026
Average KL loss: 0.483392
Average total loss: 0.926418
tensor(0.0036, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-2.9424e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.437087
Average KL loss: 0.480756
Average total loss: 0.917843
tensor(0.0036, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(1.7822e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.438194
Average KL loss: 0.478295
Average total loss: 0.916489
tensor(0.0036, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(3.6285e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.437835
Average KL loss: 0.476040
Average total loss: 0.913875
tensor(0.0036, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(1.0445e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.439428
Average KL loss: 0.473952
Average total loss: 0.913380
tensor(0.0036, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(5.3737e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.437186
Average KL loss: 0.471887
Average total loss: 0.909073
tensor(0.0036, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-6.1099e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.438766
Average KL loss: 0.470045
Average total loss: 0.908812
tensor(0.0036, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-3.5000e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.435750
Average KL loss: 0.468521
Average total loss: 0.904271
tensor(0.0035, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-4.6063e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.437213
Average KL loss: 0.467001
Average total loss: 0.904214
tensor(0.0035, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(5.4033e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.433541
Average KL loss: 0.465469
Average total loss: 0.899010
tensor(0.0035, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(2.3339e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.442335
Average KL loss: 0.463773
Average total loss: 0.906107
tensor(0.0035, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-7.6071e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.438992
Average KL loss: 0.462301
Average total loss: 0.901293
tensor(0.0035, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(6.1802e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.439614
Average KL loss: 0.460938
Average total loss: 0.900552
tensor(0.0035, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-2.6649e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.436463
Average KL loss: 0.459629
Average total loss: 0.896092
tensor(0.0035, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.8507e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.445432
Average KL loss: 0.458471
Average total loss: 0.903903
tensor(0.0035, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-7.4170e-11, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.439971
Average KL loss: 0.457556
Average total loss: 0.897527
tensor(0.0035, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(1.7630e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.443442
Average KL loss: 0.456630
Average total loss: 0.900072
tensor(0.0035, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(2.0050e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.441173
Average KL loss: 0.455278
Average total loss: 0.896451
tensor(0.0035, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-3.2553e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.441662
Average KL loss: 0.454444
Average total loss: 0.896106
tensor(0.0035, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-7.2846e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.445369
Average KL loss: 0.453756
Average total loss: 0.899125
tensor(0.0035, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(1.8598e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.443822
Average KL loss: 0.452780
Average total loss: 0.896602
tensor(0.0035, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.2957e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.441760
Average KL loss: 0.452048
Average total loss: 0.893808
tensor(0.0035, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(3.2875e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.443550
Average KL loss: 0.451065
Average total loss: 0.894615
tensor(0.0035, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-2.5982e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.441151
Average KL loss: 0.450208
Average total loss: 0.891359
tensor(0.0035, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(1.3650e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.443487
Average KL loss: 0.449405
Average total loss: 0.892892
tensor(0.0035, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-2.8597e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.443657
Average KL loss: 0.448459
Average total loss: 0.892116
tensor(0.0035, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(2.0013e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.445066
Average KL loss: 0.447635
Average total loss: 0.892701
tensor(0.0035, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(4.3666e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.443472
Average KL loss: 0.446933
Average total loss: 0.890405
tensor(0.0035, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-3.9212e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.453874
Average KL loss: 0.446081
Average total loss: 0.899955
tensor(0.0035, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-5.6259e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.447496
Average KL loss: 0.445360
Average total loss: 0.892856
tensor(0.0035, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-6.3118e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.447900
Average KL loss: 0.444963
Average total loss: 0.892863
tensor(0.0035, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(7.0262e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.450550
Average KL loss: 0.444184
Average total loss: 0.894734
tensor(0.0035, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(3.6136e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.443751
Average KL loss: 0.443671
Average total loss: 0.887422
tensor(0.0035, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-3.6814e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.444963
Average KL loss: 0.442862
Average total loss: 0.887825
tensor(0.0034, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.7598e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.442787
Average KL loss: 0.442035
Average total loss: 0.884822
tensor(0.0034, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(2.1936e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.447639
Average KL loss: 0.441529
Average total loss: 0.889168
tensor(0.0034, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.1326e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.446220
Average KL loss: 0.441276
Average total loss: 0.887496
tensor(0.0034, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(3.5482e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.449764
Average KL loss: 0.440774
Average total loss: 0.890538
tensor(0.0034, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-6.4359e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.454479
Average KL loss: 0.440268
Average total loss: 0.894747
tensor(0.0034, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(2.3432e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.451045
Average KL loss: 0.439805
Average total loss: 0.890849
tensor(0.0034, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(3.6753e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.446627
Average KL loss: 0.439032
Average total loss: 0.885658
tensor(0.0034, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.7634e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.446853
Average KL loss: 0.438535
Average total loss: 0.885388
tensor(0.0034, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-9.1018e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.448290
Average KL loss: 0.438069
Average total loss: 0.886359
tensor(0.0034, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(4.9374e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.449649
Average KL loss: 0.437690
Average total loss: 0.887339
tensor(0.0034, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.5692e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.451963
Average KL loss: 0.437024
Average total loss: 0.888987
tensor(0.0034, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-8.5330e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.447011
Average KL loss: 0.436740
Average total loss: 0.883751
tensor(0.0034, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(3.4387e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.447889
Average KL loss: 0.436175
Average total loss: 0.884064
tensor(0.0034, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(8.0412e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.453170
Average KL loss: 0.435715
Average total loss: 0.888886
tensor(0.0034, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(2.9454e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.455359
Average KL loss: 0.435390
Average total loss: 0.890749
tensor(0.0034, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(9.4858e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.451689
Average KL loss: 0.435065
Average total loss: 0.886755
tensor(0.0034, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.1164e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.454809
Average KL loss: 0.434554
Average total loss: 0.889362
tensor(0.0034, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.8146e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.446768
Average KL loss: 0.434129
Average total loss: 0.880896
tensor(0.0034, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(2.5732e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.450993
Average KL loss: 0.433824
Average total loss: 0.884818
tensor(0.0034, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(1.5301e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.457342
Average KL loss: 0.433774
Average total loss: 0.891116
tensor(0.0034, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-6.1155e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.449140
Average KL loss: 0.433540
Average total loss: 0.882681
tensor(0.0034, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(2.6055e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.452540
Average KL loss: 0.432765
Average total loss: 0.885306
tensor(0.0034, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(2.5583e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.453288
Average KL loss: 0.432345
Average total loss: 0.885633
tensor(0.0034, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(2.8523e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.448607
Average KL loss: 0.431790
Average total loss: 0.880397
tensor(0.0034, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(1.4826e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.452434
Average KL loss: 0.431591
Average total loss: 0.884025
tensor(0.0034, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(2.7019e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.448598
Average KL loss: 0.431577
Average total loss: 0.880176
tensor(0.0034, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-3.1521e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.452299
Average KL loss: 0.431163
Average total loss: 0.883462
tensor(0.0034, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-7.3009e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.453415
Average KL loss: 0.430702
Average total loss: 0.884117
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.2615e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.451291
Average KL loss: 0.430464
Average total loss: 0.881755
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(5.3086e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.452346
Average KL loss: 0.429997
Average total loss: 0.882343
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-4.4342e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.455663
Average KL loss: 0.429722
Average total loss: 0.885386
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(6.2478e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.451115
Average KL loss: 0.429555
Average total loss: 0.880671
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-8.4341e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.450717
Average KL loss: 0.429454
Average total loss: 0.880172
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.2821e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.458046
Average KL loss: 0.429504
Average total loss: 0.887550
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-8.9967e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.453773
Average KL loss: 0.429129
Average total loss: 0.882902
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-8.1582e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.458681
Average KL loss: 0.428904
Average total loss: 0.887584
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(1.3383e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.451670
Average KL loss: 0.429034
Average total loss: 0.880704
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.5642e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.457712
Average KL loss: 0.428876
Average total loss: 0.886588
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-9.6654e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.451052
Average KL loss: 0.428570
Average total loss: 0.879622
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(4.2813e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.455999
Average KL loss: 0.428270
Average total loss: 0.884269
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(4.5969e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.454164
Average KL loss: 0.428003
Average total loss: 0.882167
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-5.1427e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.457604
Average KL loss: 0.427766
Average total loss: 0.885370
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.3653e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.450342
Average KL loss: 0.427555
Average total loss: 0.877897
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.0635e-11, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.454661
Average KL loss: 0.427322
Average total loss: 0.881983
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.1668e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.454125
Average KL loss: 0.427094
Average total loss: 0.881219
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.1581e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.450605
Average KL loss: 0.426887
Average total loss: 0.877492
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-4.4079e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.452778
Average KL loss: 0.426716
Average total loss: 0.879494
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.8369e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.458545
Average KL loss: 0.426568
Average total loss: 0.885113
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.3771e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.449250
Average KL loss: 0.426386
Average total loss: 0.875636
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-6.8091e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.453783
Average KL loss: 0.426221
Average total loss: 0.880003
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-5.5935e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.451835
Average KL loss: 0.426026
Average total loss: 0.877861
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.6772e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.450728
Average KL loss: 0.425836
Average total loss: 0.876565
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(8.6525e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.451319
Average KL loss: 0.425682
Average total loss: 0.877001
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.0329e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.454992
Average KL loss: 0.425516
Average total loss: 0.880508
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.7912e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.452458
Average KL loss: 0.425363
Average total loss: 0.877821
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(6.1814e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.455885
Average KL loss: 0.425228
Average total loss: 0.881113
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-4.6629e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.453591
Average KL loss: 0.425134
Average total loss: 0.878725
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.0677e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.458325
Average KL loss: 0.425012
Average total loss: 0.883336
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.3117e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.451461
Average KL loss: 0.424875
Average total loss: 0.876336
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.0560e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.456417
Average KL loss: 0.424742
Average total loss: 0.881159
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(3.9091e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.460687
Average KL loss: 0.424677
Average total loss: 0.885364
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-8.8085e-12, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.456144
Average KL loss: 0.424660
Average total loss: 0.880804
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.7223e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.454077
Average KL loss: 0.424642
Average total loss: 0.878719
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.7987e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.451030
Average KL loss: 0.424623
Average total loss: 0.875653
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(3.5861e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.447136
Average KL loss: 0.424608
Average total loss: 0.871745
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.0421e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.449163
Average KL loss: 0.424590
Average total loss: 0.873753
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(4.4545e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.447434
Average KL loss: 0.424572
Average total loss: 0.872006
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-5.9355e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.454955
Average KL loss: 0.424556
Average total loss: 0.879511
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(3.3126e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.450750
Average KL loss: 0.424539
Average total loss: 0.875290
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(8.9119e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.456036
Average KL loss: 0.424522
Average total loss: 0.880558
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(4.8715e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.451143
Average KL loss: 0.424504
Average total loss: 0.875647
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(3.4794e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.446555
Average KL loss: 0.424488
Average total loss: 0.871042
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.4623e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.455443
Average KL loss: 0.424470
Average total loss: 0.879913
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.6898e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.459430
Average KL loss: 0.424454
Average total loss: 0.883884
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(3.3885e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.455599
Average KL loss: 0.424442
Average total loss: 0.880041
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(7.6042e-11, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.451101
Average KL loss: 0.424427
Average total loss: 0.875528
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.7061e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.455042
Average KL loss: 0.424412
Average total loss: 0.879454
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.6706e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.452369
Average KL loss: 0.424398
Average total loss: 0.876767
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.7139e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.452111
Average KL loss: 0.424380
Average total loss: 0.876492
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.8291e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.448634
Average KL loss: 0.424365
Average total loss: 0.873000
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(4.5671e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.453643
Average KL loss: 0.424349
Average total loss: 0.877993
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(3.6020e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.453108
Average KL loss: 0.424334
Average total loss: 0.877442
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(4.4052e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.455328
Average KL loss: 0.424319
Average total loss: 0.879646
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.4938e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.449493
Average KL loss: 0.424312
Average total loss: 0.873806
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.9833e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.454754
Average KL loss: 0.424311
Average total loss: 0.879065
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-6.4887e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.453709
Average KL loss: 0.424309
Average total loss: 0.878018
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(3.6417e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.451122
Average KL loss: 0.424308
Average total loss: 0.875430
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-6.2735e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.452796
Average KL loss: 0.424307
Average total loss: 0.877103
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.6193e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.456344
Average KL loss: 0.424306
Average total loss: 0.880649
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.6555e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.454354
Average KL loss: 0.424304
Average total loss: 0.878658
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.1475e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.456879
Average KL loss: 0.424303
Average total loss: 0.881181
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.5909e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.455013
Average KL loss: 0.424301
Average total loss: 0.879314
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.9657e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.450112
Average KL loss: 0.424300
Average total loss: 0.874412
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(6.1176e-09, device='cuda:0')
 Percentile value: 8.177415367072172e-08
Non-zero model percentage: 10.737431526184082%, Non-zero mask percentage: 10.737431526184082%

--- Pruning Level [10/24]: ---
conv1.weight         | nonzeros =      79 /    1728             (  4.57%) | total_pruned =    1649 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      47 /   36864             (  0.13%) | total_pruned =   36817 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      48 /   36864             (  0.13%) | total_pruned =   36816 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      87 /   36864             (  0.24%) | total_pruned =   36777 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     211 /   36864             (  0.57%) | total_pruned =   36653 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     640 /   73728             (  0.87%) | total_pruned =   73088 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1459 /  147456             (  0.99%) | total_pruned =  145997 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      99 /    8192             (  1.21%) | total_pruned =    8093 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1492 /  147456             (  1.01%) | total_pruned =  145964 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1536 /  147456             (  1.04%) | total_pruned =  145920 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3757 /  294912             (  1.27%) | total_pruned =  291155 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     204 /     256             ( 79.69%) | total_pruned =      52 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    5959 /  589824             (  1.01%) | total_pruned =  583865 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     457 /   32768             (  1.39%) | total_pruned =   32311 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     115 /     256             ( 44.92%) | total_pruned =     141 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    4293 /  589824             (  0.73%) | total_pruned =  585531 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     178 /     256             ( 69.53%) | total_pruned =      78 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2909 /  589824             (  0.49%) | total_pruned =  586915 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     119 /     256             ( 46.48%) | total_pruned =     137 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    7988 / 1179648             (  0.68%) | total_pruned = 1171660 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     374 /     512             ( 73.05%) | total_pruned =     138 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    9395 / 2359296             (  0.40%) | total_pruned = 2349901 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     168 /     512             ( 32.81%) | total_pruned =     344 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      48 /     512             (  9.38%) | total_pruned =     464 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     400 /  131072             (  0.31%) | total_pruned =  130672 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      51 /     512             (  9.96%) | total_pruned =     461 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    5790 / 2359296             (  0.25%) | total_pruned = 2353506 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      97 /     512             ( 18.95%) | total_pruned =     415 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1148710 / 2359296             ( 48.69%) | total_pruned = 1210586 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     208 /     512             ( 40.62%) | total_pruned =     304 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     271 /     512             ( 52.93%) | total_pruned =     241 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     196 /     512             ( 38.28%) | total_pruned =     316 | shape = torch.Size([512])
linear.weight        | nonzeros =    2080 /    5120             ( 40.62%) | total_pruned =    3040 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 1200312, pruned : 9978450, total: 11178762, Compression rate :       9.31x  ( 89.26% pruned)
Train Epoch: 77/100 Loss: 0.036018 Accuracy: 84.12 99.97 % Best test Accuracy: 85.27%
tensor(0.0034, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.3774e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.773847
Average KL loss: 0.413450
Average total loss: 1.187297
tensor(-0.0006, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-8.8742e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.879294
Average KL loss: 0.429105
Average total loss: 1.308399
tensor(0.0021, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-3.0443e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.767827
Average KL loss: 0.452644
Average total loss: 1.220471
tensor(0.0024, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.1690e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.693450
Average KL loss: 0.462431
Average total loss: 1.155880
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.1433e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.646492
Average KL loss: 0.468886
Average total loss: 1.115379
tensor(0.0025, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.3949e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.617752
Average KL loss: 0.475012
Average total loss: 1.092764
tensor(0.0026, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.4426e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.586589
Average KL loss: 0.481683
Average total loss: 1.068273
tensor(0.0027, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.1341e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.574711
Average KL loss: 0.487489
Average total loss: 1.062200
tensor(0.0027, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-6.7842e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.559357
Average KL loss: 0.493861
Average total loss: 1.053218
tensor(0.0028, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-8.2670e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.547297
Average KL loss: 0.497106
Average total loss: 1.044403
tensor(0.0028, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-8.6416e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.543732
Average KL loss: 0.500049
Average total loss: 1.043781
tensor(0.0029, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-4.6070e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.531745
Average KL loss: 0.504991
Average total loss: 1.036736
tensor(0.0029, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-4.3259e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.526561
Average KL loss: 0.509141
Average total loss: 1.035702
tensor(0.0030, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-6.8325e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.514888
Average KL loss: 0.513585
Average total loss: 1.028473
tensor(0.0030, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(2.2065e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.521513
Average KL loss: 0.515848
Average total loss: 1.037361
tensor(0.0030, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-7.0566e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.510957
Average KL loss: 0.524499
Average total loss: 1.035456
tensor(-0.0055, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.1939e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.497374
Average KL loss: 0.524862
Average total loss: 1.022236
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.7527e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.500490
Average KL loss: 0.524644
Average total loss: 1.025134
tensor(0.0030, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.3515e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.493600
Average KL loss: 0.525919
Average total loss: 1.019519
tensor(0.0031, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.4724e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.492389
Average KL loss: 0.528496
Average total loss: 1.020885
tensor(0.0031, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-5.9085e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.495111
Average KL loss: 0.531965
Average total loss: 1.027076
tensor(0.0046, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(3.1436e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.479309
Average KL loss: 0.530356
Average total loss: 1.009665
tensor(0.0032, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(4.3000e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.483714
Average KL loss: 0.531995
Average total loss: 1.015708
tensor(0.0032, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-4.1052e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.486491
Average KL loss: 0.538149
Average total loss: 1.024641
tensor(0.0033, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.3179e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.470825
Average KL loss: 0.539960
Average total loss: 1.010785
tensor(-0.0019, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.2761e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.476961
Average KL loss: 0.535240
Average total loss: 1.012201
tensor(0.0037, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(4.8731e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.472906
Average KL loss: 0.537923
Average total loss: 1.010828
tensor(0.0033, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.5127e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.471877
Average KL loss: 0.540397
Average total loss: 1.012275
tensor(0.0033, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(1.3350e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.473492
Average KL loss: 0.541358
Average total loss: 1.014850
tensor(0.0018, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-3.6969e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.470619
Average KL loss: 0.547974
Average total loss: 1.018593
tensor(0.0035, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.3555e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.467226
Average KL loss: 0.544832
Average total loss: 1.012058
tensor(0.0034, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-7.2196e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.462458
Average KL loss: 0.545696
Average total loss: 1.008153
tensor(0.0034, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(1.5722e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.457189
Average KL loss: 0.548862
Average total loss: 1.006051
tensor(0.0034, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-4.4850e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.461549
Average KL loss: 0.551351
Average total loss: 1.012900
tensor(0.0034, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-3.6025e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.460868
Average KL loss: 0.556269
Average total loss: 1.017137
tensor(-0.0004, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.0064e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.458268
Average KL loss: 0.553260
Average total loss: 1.011528
tensor(0.0039, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(1.2374e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.450040
Average KL loss: 0.552078
Average total loss: 1.002118
tensor(0.0035, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-3.6073e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.449908
Average KL loss: 0.552433
Average total loss: 1.002341
tensor(0.0035, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(2.7500e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.454110
Average KL loss: 0.551618
Average total loss: 1.005728
tensor(0.0030, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.1503e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.453146
Average KL loss: 0.557007
Average total loss: 1.010153
tensor(0.0030, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-1.4479e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.451500
Average KL loss: 0.555834
Average total loss: 1.007333
tensor(0.0037, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(4.8756e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.451864
Average KL loss: 0.556996
Average total loss: 1.008860
tensor(0.0036, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-4.3203e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.449748
Average KL loss: 0.556189
Average total loss: 1.005937
tensor(0.0036, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-2.0637e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.449616
Average KL loss: 0.557516
Average total loss: 1.007132
tensor(0.0132, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(2.3929e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.449240
Average KL loss: 0.561811
Average total loss: 1.011050
tensor(0.0045, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(2.2527e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.449612
Average KL loss: 0.557799
Average total loss: 1.007411
tensor(0.0036, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.7785e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.447104
Average KL loss: 0.559973
Average total loss: 1.007077
tensor(0.0036, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-6.1985e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.454708
Average KL loss: 0.560680
Average total loss: 1.015388
tensor(0.0042, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(1.4511e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.432890
Average KL loss: 0.557243
Average total loss: 0.990133
tensor(0.0037, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.8551e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.438895
Average KL loss: 0.546271
Average total loss: 0.985166
tensor(0.0037, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.5430e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.435142
Average KL loss: 0.538314
Average total loss: 0.973456
tensor(0.0037, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.0058e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.439277
Average KL loss: 0.532116
Average total loss: 0.971393
tensor(0.0037, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.8993e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.427314
Average KL loss: 0.526738
Average total loss: 0.954051
tensor(0.0037, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.0298e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.436430
Average KL loss: 0.522178
Average total loss: 0.958608
tensor(0.0036, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(5.7888e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.429039
Average KL loss: 0.518289
Average total loss: 0.947328
tensor(0.0036, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.5645e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.426980
Average KL loss: 0.514363
Average total loss: 0.941343
tensor(0.0036, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(2.8768e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.438206
Average KL loss: 0.510920
Average total loss: 0.949126
tensor(0.0036, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-8.2497e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.430110
Average KL loss: 0.507896
Average total loss: 0.938006
tensor(0.0036, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(2.8740e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.431830
Average KL loss: 0.505370
Average total loss: 0.937200
tensor(0.0036, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(1.0567e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.438288
Average KL loss: 0.503104
Average total loss: 0.941392
tensor(0.0036, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(5.1419e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.431804
Average KL loss: 0.500953
Average total loss: 0.932757
tensor(0.0036, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(3.0979e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.430597
Average KL loss: 0.498765
Average total loss: 0.929362
tensor(0.0036, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-2.5710e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.433164
Average KL loss: 0.496714
Average total loss: 0.929879
tensor(0.0036, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-6.6432e-12, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.426118
Average KL loss: 0.494624
Average total loss: 0.920742
tensor(0.0036, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-4.5658e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.433522
Average KL loss: 0.492972
Average total loss: 0.926495
tensor(0.0036, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(3.8953e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.431625
Average KL loss: 0.491463
Average total loss: 0.923088
tensor(0.0036, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(1.5166e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.437619
Average KL loss: 0.490022
Average total loss: 0.927641
tensor(0.0036, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(3.3144e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.431795
Average KL loss: 0.488901
Average total loss: 0.920696
tensor(0.0036, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-2.4926e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.435139
Average KL loss: 0.487450
Average total loss: 0.922589
tensor(0.0036, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-1.4032e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.432277
Average KL loss: 0.486193
Average total loss: 0.918470
tensor(0.0036, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(4.2934e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.439589
Average KL loss: 0.484639
Average total loss: 0.924228
tensor(0.0036, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-1.5304e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.433390
Average KL loss: 0.483578
Average total loss: 0.916967
tensor(0.0036, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(2.2076e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.432733
Average KL loss: 0.482485
Average total loss: 0.915219
tensor(0.0036, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(3.2303e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.440392
Average KL loss: 0.481194
Average total loss: 0.921587
tensor(0.0036, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(5.1097e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.434519
Average KL loss: 0.480028
Average total loss: 0.914548
tensor(0.0036, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-1.3397e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.434985
Average KL loss: 0.478996
Average total loss: 0.913981
tensor(0.0036, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(1.0500e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.432361
Average KL loss: 0.478186
Average total loss: 0.910546
tensor(0.0036, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(1.7327e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.430324
Average KL loss: 0.477066
Average total loss: 0.907389
tensor(0.0036, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(3.1771e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.437061
Average KL loss: 0.476193
Average total loss: 0.913254
tensor(0.0036, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(3.9489e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.441705
Average KL loss: 0.475434
Average total loss: 0.917138
tensor(0.0035, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(1.7393e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.435050
Average KL loss: 0.474764
Average total loss: 0.909814
tensor(0.0035, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(4.6207e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.439021
Average KL loss: 0.473691
Average total loss: 0.912712
tensor(0.0035, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.2431e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.437686
Average KL loss: 0.472865
Average total loss: 0.910550
tensor(0.0035, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-5.9963e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.436645
Average KL loss: 0.472219
Average total loss: 0.908863
tensor(0.0035, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.1304e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.442134
Average KL loss: 0.471520
Average total loss: 0.913654
tensor(0.0035, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.5207e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.439263
Average KL loss: 0.470988
Average total loss: 0.910251
tensor(0.0035, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.2293e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.437689
Average KL loss: 0.470414
Average total loss: 0.908103
tensor(0.0035, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(1.6494e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.436113
Average KL loss: 0.469689
Average total loss: 0.905803
tensor(0.0035, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(5.8406e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.437564
Average KL loss: 0.469027
Average total loss: 0.906591
tensor(0.0035, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-1.0213e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.437307
Average KL loss: 0.468595
Average total loss: 0.905902
tensor(0.0035, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-2.5963e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.438343
Average KL loss: 0.468022
Average total loss: 0.906365
tensor(0.0035, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(2.9016e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.441130
Average KL loss: 0.467437
Average total loss: 0.908568
tensor(0.0035, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(3.6720e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.441346
Average KL loss: 0.466770
Average total loss: 0.908116
tensor(0.0035, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-3.5931e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.437912
Average KL loss: 0.466413
Average total loss: 0.904325
tensor(0.0035, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(3.8531e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.440463
Average KL loss: 0.465857
Average total loss: 0.906320
tensor(0.0035, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(1.9645e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.439370
Average KL loss: 0.465120
Average total loss: 0.904490
tensor(0.0035, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-9.9662e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.438877
Average KL loss: 0.464531
Average total loss: 0.903408
tensor(0.0035, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(3.4489e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.445019
Average KL loss: 0.464176
Average total loss: 0.909195
tensor(0.0035, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(4.2714e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.442242
Average KL loss: 0.463790
Average total loss: 0.906033
tensor(0.0035, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-2.9523e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.438384
Average KL loss: 0.463299
Average total loss: 0.901683
tensor(0.0035, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(1.0593e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.441304
Average KL loss: 0.462658
Average total loss: 0.903962
tensor(0.0035, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(1.4789e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.443107
Average KL loss: 0.462193
Average total loss: 0.905299
tensor(0.0035, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(1.5117e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.441455
Average KL loss: 0.461656
Average total loss: 0.903112
tensor(0.0035, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-8.0833e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.442502
Average KL loss: 0.461344
Average total loss: 0.903846
tensor(0.0035, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-1.1442e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.442078
Average KL loss: 0.461202
Average total loss: 0.903280
tensor(0.0035, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-1.3219e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.447330
Average KL loss: 0.460777
Average total loss: 0.908107
tensor(0.0035, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(2.3286e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.447595
Average KL loss: 0.460495
Average total loss: 0.908089
tensor(0.0035, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-6.0405e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.442966
Average KL loss: 0.460132
Average total loss: 0.903098
tensor(0.0035, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-4.1794e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.442886
Average KL loss: 0.459520
Average total loss: 0.902406
tensor(0.0035, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-1.2182e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.445738
Average KL loss: 0.459346
Average total loss: 0.905084
tensor(0.0035, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-8.4914e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.440920
Average KL loss: 0.458915
Average total loss: 0.899835
tensor(0.0035, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(1.7936e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.441886
Average KL loss: 0.458295
Average total loss: 0.900180
tensor(0.0035, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(3.7644e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.441959
Average KL loss: 0.458011
Average total loss: 0.899970
tensor(0.0035, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-2.5931e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.444100
Average KL loss: 0.457737
Average total loss: 0.901838
tensor(0.0035, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-2.6602e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.444331
Average KL loss: 0.457495
Average total loss: 0.901826
tensor(0.0035, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(4.6224e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.448511
Average KL loss: 0.457146
Average total loss: 0.905657
tensor(0.0035, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(2.0319e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.443687
Average KL loss: 0.456865
Average total loss: 0.900552
tensor(0.0035, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-2.1330e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.442737
Average KL loss: 0.456325
Average total loss: 0.899062
tensor(0.0035, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(2.3804e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.447995
Average KL loss: 0.455619
Average total loss: 0.903614
tensor(0.0035, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-7.8622e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.447423
Average KL loss: 0.455399
Average total loss: 0.902822
tensor(0.0035, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-2.3810e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.446298
Average KL loss: 0.455200
Average total loss: 0.901497
tensor(0.0035, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.4563e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.441158
Average KL loss: 0.454946
Average total loss: 0.896104
tensor(0.0035, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.4459e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.444046
Average KL loss: 0.454697
Average total loss: 0.898743
tensor(0.0035, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(2.7352e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.447212
Average KL loss: 0.454122
Average total loss: 0.901335
tensor(0.0034, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(1.6113e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.445734
Average KL loss: 0.453753
Average total loss: 0.899487
tensor(0.0034, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(3.5470e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.453431
Average KL loss: 0.453617
Average total loss: 0.907048
tensor(0.0034, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-3.3910e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.448592
Average KL loss: 0.453418
Average total loss: 0.902009
tensor(0.0034, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(3.8583e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.445413
Average KL loss: 0.453398
Average total loss: 0.898811
tensor(0.0034, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(4.6946e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.451580
Average KL loss: 0.453245
Average total loss: 0.904825
tensor(0.0034, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(1.5958e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.443898
Average KL loss: 0.452886
Average total loss: 0.896785
tensor(0.0034, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.9383e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.451187
Average KL loss: 0.452722
Average total loss: 0.903909
tensor(0.0034, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(1.9730e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.443600
Average KL loss: 0.452562
Average total loss: 0.896163
tensor(0.0034, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(2.1589e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.448973
Average KL loss: 0.452185
Average total loss: 0.901158
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.8430e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.448036
Average KL loss: 0.451886
Average total loss: 0.899922
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(2.2541e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.445923
Average KL loss: 0.451663
Average total loss: 0.897585
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-3.5704e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.440412
Average KL loss: 0.451436
Average total loss: 0.891848
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-2.1543e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.450770
Average KL loss: 0.451241
Average total loss: 0.902011
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(9.7185e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.450336
Average KL loss: 0.451080
Average total loss: 0.901415
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-4.2687e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.445645
Average KL loss: 0.450915
Average total loss: 0.896560
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(5.1600e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.445499
Average KL loss: 0.450759
Average total loss: 0.896259
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(7.2733e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.450968
Average KL loss: 0.450631
Average total loss: 0.901599
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(2.8314e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.446092
Average KL loss: 0.450498
Average total loss: 0.896590
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(7.9029e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.442811
Average KL loss: 0.450328
Average total loss: 0.893139
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-6.7828e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.450665
Average KL loss: 0.450169
Average total loss: 0.900835
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.6581e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.446991
Average KL loss: 0.450062
Average total loss: 0.897053
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(4.5699e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.446080
Average KL loss: 0.449942
Average total loss: 0.896022
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(5.1949e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.446593
Average KL loss: 0.449847
Average total loss: 0.896440
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.2857e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.445219
Average KL loss: 0.449777
Average total loss: 0.894996
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-9.5249e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.445043
Average KL loss: 0.449761
Average total loss: 0.894804
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(1.4274e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.443743
Average KL loss: 0.449749
Average total loss: 0.893492
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(1.9171e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.448700
Average KL loss: 0.449734
Average total loss: 0.898434
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-2.3557e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.445564
Average KL loss: 0.449719
Average total loss: 0.895283
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(1.2186e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.449390
Average KL loss: 0.449702
Average total loss: 0.899092
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-3.0273e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.444660
Average KL loss: 0.449687
Average total loss: 0.894347
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.0088e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.445291
Average KL loss: 0.449673
Average total loss: 0.894963
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-9.3454e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.444055
Average KL loss: 0.449658
Average total loss: 0.893712
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-4.1545e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.445067
Average KL loss: 0.449642
Average total loss: 0.894709
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-3.6321e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.442443
Average KL loss: 0.449630
Average total loss: 0.892072
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(1.5197e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.450920
Average KL loss: 0.449621
Average total loss: 0.900541
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(7.0073e-11, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.442290
Average KL loss: 0.449619
Average total loss: 0.891909
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-6.5054e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.444126
Average KL loss: 0.449618
Average total loss: 0.893744
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(3.9375e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.448787
Average KL loss: 0.449617
Average total loss: 0.898404
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-3.9864e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.444201
Average KL loss: 0.449615
Average total loss: 0.893817
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-4.1103e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.445830
Average KL loss: 0.449614
Average total loss: 0.895444
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(2.5518e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.440685
Average KL loss: 0.449612
Average total loss: 0.890297
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.9450e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.446540
Average KL loss: 0.449611
Average total loss: 0.896151
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-3.8446e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.448292
Average KL loss: 0.449609
Average total loss: 0.897902
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(1.3429e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.449098
Average KL loss: 0.449608
Average total loss: 0.898706
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-2.4664e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.442432
Average KL loss: 0.449606
Average total loss: 0.892038
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-4.9667e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.454732
Average KL loss: 0.449605
Average total loss: 0.904336
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(4.9218e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.446949
Average KL loss: 0.449603
Average total loss: 0.896552
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(2.2393e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.445960
Average KL loss: 0.449602
Average total loss: 0.895562
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-2.3724e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.445752
Average KL loss: 0.449601
Average total loss: 0.895353
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-9.6982e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.446641
Average KL loss: 0.449599
Average total loss: 0.896240
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-3.3007e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.448485
Average KL loss: 0.449598
Average total loss: 0.898083
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-2.9936e-09, device='cuda:0')
 Percentile value: 8.215037894387933e-08
Non-zero model percentage: 8.589949607849121%, Non-zero mask percentage: 8.589949607849121%

--- Pruning Level [11/24]: ---
conv1.weight         | nonzeros =      79 /    1728             (  4.57%) | total_pruned =    1649 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      33 /   36864             (  0.09%) | total_pruned =   36831 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      30 /   36864             (  0.08%) | total_pruned =   36834 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      64 /   36864             (  0.17%) | total_pruned =   36800 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     172 /   36864             (  0.47%) | total_pruned =   36692 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     532 /   73728             (  0.72%) | total_pruned =   73196 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1183 /  147456             (  0.80%) | total_pruned =  146273 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      81 /    8192             (  0.99%) | total_pruned =    8111 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1177 /  147456             (  0.80%) | total_pruned =  146279 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1226 /  147456             (  0.83%) | total_pruned =  146230 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2944 /  294912             (  1.00%) | total_pruned =  291968 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     198 /     256             ( 77.34%) | total_pruned =      58 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    4651 /  589824             (  0.79%) | total_pruned =  585173 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     176 /     256             ( 68.75%) | total_pruned =      80 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     353 /   32768             (  1.08%) | total_pruned =   32415 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     106 /     256             ( 41.41%) | total_pruned =     150 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3112 /  589824             (  0.53%) | total_pruned =  586712 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     171 /     256             ( 66.80%) | total_pruned =      85 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2113 /  589824             (  0.36%) | total_pruned =  587711 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    5444 / 1179648             (  0.46%) | total_pruned = 1174204 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     343 /     512             ( 66.99%) | total_pruned =     169 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    6056 / 2359296             (  0.26%) | total_pruned = 2353240 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     148 /     512             ( 28.91%) | total_pruned =     364 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     235 /  131072             (  0.18%) | total_pruned =  130837 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      49 /     512             (  9.57%) | total_pruned =     463 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      37 /     512             (  7.23%) | total_pruned =     475 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3613 / 2359296             (  0.15%) | total_pruned = 2355683 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      89 /     512             ( 17.38%) | total_pruned =     423 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  922660 / 2359296             ( 39.11%) | total_pruned = 1436636 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     205 /     512             ( 40.04%) | total_pruned =     307 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     255 /     512             ( 49.80%) | total_pruned =     257 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     181 /     512             ( 35.35%) | total_pruned =     331 | shape = torch.Size([512])
linear.weight        | nonzeros =    1883 /    5120             ( 36.78%) | total_pruned =    3237 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 960250, pruned : 10218512, total: 11178762, Compression rate :      11.64x  ( 91.41% pruned)
Train Epoch: 99/100 Loss: 0.154726 Accuracy: 82.80 99.84 % Best test Accuracy: 84.64%
tensor(0.0034, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.8347e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.790811
Average KL loss: 0.413574
Average total loss: 1.204385
tensor(-0.0006, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-9.5028e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.964232
Average KL loss: 0.409732
Average total loss: 1.373964
tensor(0.0020, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.1905e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.798098
Average KL loss: 0.435882
Average total loss: 1.233980
tensor(0.0023, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.9630e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.707622
Average KL loss: 0.446829
Average total loss: 1.154451
tensor(0.0024, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.8236e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.667533
Average KL loss: 0.456064
Average total loss: 1.123598
tensor(0.0025, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-9.4563e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.646464
Average KL loss: 0.461976
Average total loss: 1.108440
tensor(0.0025, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.1481e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.631496
Average KL loss: 0.468095
Average total loss: 1.099591
tensor(0.0026, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.4261e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.591363
Average KL loss: 0.472843
Average total loss: 1.064206
tensor(0.0027, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-5.1898e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.568568
Average KL loss: 0.478826
Average total loss: 1.047393
tensor(0.0027, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-6.4622e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.565390
Average KL loss: 0.483598
Average total loss: 1.048988
tensor(0.0028, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-8.5997e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.553954
Average KL loss: 0.490003
Average total loss: 1.043957
tensor(0.0028, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-3.8437e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.546203
Average KL loss: 0.493049
Average total loss: 1.039252
tensor(0.0028, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.5100e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.533178
Average KL loss: 0.495542
Average total loss: 1.028720
tensor(0.0029, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-3.6676e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.521549
Average KL loss: 0.500101
Average total loss: 1.021649
tensor(0.0029, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.0476e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.527914
Average KL loss: 0.505250
Average total loss: 1.033163
tensor(0.0030, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.1607e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.517620
Average KL loss: 0.508561
Average total loss: 1.026181
tensor(-0.0056, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.1826e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.500287
Average KL loss: 0.510923
Average total loss: 1.011210
tensor(0.0038, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.7144e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.500508
Average KL loss: 0.512356
Average total loss: 1.012864
tensor(0.0030, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-5.1519e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.495394
Average KL loss: 0.513798
Average total loss: 1.009192
tensor(0.0031, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.0797e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.493171
Average KL loss: 0.516799
Average total loss: 1.009970
tensor(0.0031, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-6.1484e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.482561
Average KL loss: 0.521718
Average total loss: 1.004280
tensor(0.0046, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(4.0904e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.479576
Average KL loss: 0.520110
Average total loss: 0.999686
tensor(0.0032, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.7808e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.489104
Average KL loss: 0.520890
Average total loss: 1.009994
tensor(0.0032, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-5.9584e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.476553
Average KL loss: 0.525874
Average total loss: 1.002427
tensor(0.0033, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.8891e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.472664
Average KL loss: 0.530269
Average total loss: 1.002934
tensor(-0.0019, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.2806e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.472203
Average KL loss: 0.528319
Average total loss: 1.000522
tensor(0.0037, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(4.6299e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.467572
Average KL loss: 0.529865
Average total loss: 0.997438
tensor(0.0033, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.7083e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.464998
Average KL loss: 0.533447
Average total loss: 0.998444
tensor(0.0034, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.6338e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.460186
Average KL loss: 0.536908
Average total loss: 0.997094
tensor(0.0019, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-4.2568e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.455529
Average KL loss: 0.540491
Average total loss: 0.996020
tensor(0.0035, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(6.2158e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.456479
Average KL loss: 0.536850
Average total loss: 0.993329
tensor(0.0035, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-4.0650e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.459437
Average KL loss: 0.537658
Average total loss: 0.997095
tensor(0.0034, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(5.3793e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.457309
Average KL loss: 0.540338
Average total loss: 0.997647
tensor(0.0034, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-3.6086e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.445499
Average KL loss: 0.540695
Average total loss: 0.986194
tensor(0.0035, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(2.9998e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.453355
Average KL loss: 0.545250
Average total loss: 0.998605
tensor(-0.0004, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-9.8453e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.446606
Average KL loss: 0.543980
Average total loss: 0.990586
tensor(0.0040, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(1.1263e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.450692
Average KL loss: 0.544247
Average total loss: 0.994940
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-2.9136e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.445936
Average KL loss: 0.545974
Average total loss: 0.991910
tensor(0.0036, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.7773e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.441754
Average KL loss: 0.546166
Average total loss: 0.987920
tensor(0.0030, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.4855e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.442452
Average KL loss: 0.549507
Average total loss: 0.991959
tensor(0.0030, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.4349e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.445077
Average KL loss: 0.548286
Average total loss: 0.993364
tensor(0.0038, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(7.1618e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.444879
Average KL loss: 0.549678
Average total loss: 0.994557
tensor(0.0036, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-9.4070e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.443653
Average KL loss: 0.551215
Average total loss: 0.994868
tensor(0.0036, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-9.3652e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.440429
Average KL loss: 0.551212
Average total loss: 0.991641
tensor(0.0133, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(2.4589e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.438800
Average KL loss: 0.553018
Average total loss: 0.991818
tensor(0.0046, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(1.7395e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.434770
Average KL loss: 0.546514
Average total loss: 0.981284
tensor(0.0037, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(1.9511e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.435056
Average KL loss: 0.539462
Average total loss: 0.974517
tensor(0.0036, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(2.9724e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.428772
Average KL loss: 0.533986
Average total loss: 0.962758
tensor(0.0036, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(1.5922e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.427944
Average KL loss: 0.529636
Average total loss: 0.957580
tensor(0.0036, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(1.5483e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.433689
Average KL loss: 0.526074
Average total loss: 0.959762
tensor(0.0036, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-1.1389e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.429026
Average KL loss: 0.522742
Average total loss: 0.951768
tensor(0.0036, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-2.0705e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.425463
Average KL loss: 0.519830
Average total loss: 0.945293
tensor(0.0036, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(5.3332e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.428987
Average KL loss: 0.517353
Average total loss: 0.946339
tensor(0.0036, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-4.5783e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.426770
Average KL loss: 0.514953
Average total loss: 0.941722
tensor(0.0036, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-1.3177e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.427691
Average KL loss: 0.512717
Average total loss: 0.940408
tensor(0.0036, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-2.8844e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.426651
Average KL loss: 0.510912
Average total loss: 0.937563
tensor(0.0036, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-2.0816e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.422832
Average KL loss: 0.509058
Average total loss: 0.931891
tensor(0.0036, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(1.4963e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.427695
Average KL loss: 0.507380
Average total loss: 0.935075
tensor(0.0036, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(3.8102e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.427899
Average KL loss: 0.505710
Average total loss: 0.933609
tensor(0.0036, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(2.3613e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.425328
Average KL loss: 0.504333
Average total loss: 0.929661
tensor(0.0036, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(3.5848e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.432442
Average KL loss: 0.503008
Average total loss: 0.935450
tensor(0.0036, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(4.5265e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.426530
Average KL loss: 0.501720
Average total loss: 0.928251
tensor(0.0036, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.4157e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.429137
Average KL loss: 0.500456
Average total loss: 0.929592
tensor(0.0036, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-5.2448e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.429507
Average KL loss: 0.499087
Average total loss: 0.928595
tensor(0.0036, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-6.7445e-11, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.424035
Average KL loss: 0.497914
Average total loss: 0.921949
tensor(0.0036, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-5.4081e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.432010
Average KL loss: 0.496706
Average total loss: 0.928716
tensor(0.0036, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(5.1005e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.426231
Average KL loss: 0.495783
Average total loss: 0.922013
tensor(0.0036, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(2.0042e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.426948
Average KL loss: 0.494778
Average total loss: 0.921726
tensor(0.0036, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-2.1776e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.427902
Average KL loss: 0.493843
Average total loss: 0.921745
tensor(0.0036, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(1.6810e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.429389
Average KL loss: 0.492676
Average total loss: 0.922065
tensor(0.0036, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-2.6179e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.429144
Average KL loss: 0.491824
Average total loss: 0.920968
tensor(0.0036, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(4.3094e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.429731
Average KL loss: 0.491141
Average total loss: 0.920872
tensor(0.0036, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.2114e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.428087
Average KL loss: 0.490153
Average total loss: 0.918240
tensor(0.0036, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-5.7645e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.426137
Average KL loss: 0.489456
Average total loss: 0.915593
tensor(0.0036, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-8.9659e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.431033
Average KL loss: 0.488912
Average total loss: 0.919945
tensor(0.0036, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(2.3900e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.429613
Average KL loss: 0.488270
Average total loss: 0.917884
tensor(0.0036, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.0010e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.428098
Average KL loss: 0.487558
Average total loss: 0.915656
tensor(0.0036, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(3.6721e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.427112
Average KL loss: 0.486625
Average total loss: 0.913737
tensor(0.0036, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(2.3889e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.426702
Average KL loss: 0.485721
Average total loss: 0.912423
tensor(0.0036, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.1814e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.428404
Average KL loss: 0.484934
Average total loss: 0.913338
tensor(0.0036, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.6974e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.425331
Average KL loss: 0.484575
Average total loss: 0.909906
tensor(0.0036, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-2.4204e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.429345
Average KL loss: 0.483903
Average total loss: 0.913248
tensor(0.0036, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(5.1407e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.424896
Average KL loss: 0.483623
Average total loss: 0.908518
tensor(0.0036, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.3006e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.427280
Average KL loss: 0.483291
Average total loss: 0.910571
tensor(0.0036, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.8418e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.432942
Average KL loss: 0.482846
Average total loss: 0.915788
tensor(0.0036, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.8289e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.429774
Average KL loss: 0.482542
Average total loss: 0.912316
tensor(0.0036, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.8809e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.430457
Average KL loss: 0.481787
Average total loss: 0.912244
tensor(0.0035, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(4.9390e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.431543
Average KL loss: 0.481525
Average total loss: 0.913068
tensor(0.0036, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(3.1169e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.425974
Average KL loss: 0.481038
Average total loss: 0.907011
tensor(0.0035, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(4.5302e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.429944
Average KL loss: 0.480369
Average total loss: 0.910313
tensor(0.0035, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(3.9626e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.426244
Average KL loss: 0.479916
Average total loss: 0.906159
tensor(0.0035, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.9513e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.430259
Average KL loss: 0.479261
Average total loss: 0.909520
tensor(0.0035, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.2759e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.442043
Average KL loss: 0.478480
Average total loss: 0.920523
tensor(0.0035, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-1.2854e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.432455
Average KL loss: 0.478006
Average total loss: 0.910461
tensor(0.0035, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.7134e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.433955
Average KL loss: 0.477522
Average total loss: 0.911477
tensor(0.0035, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(1.2078e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.436963
Average KL loss: 0.477134
Average total loss: 0.914097
tensor(0.0035, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(3.3847e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.432931
Average KL loss: 0.476749
Average total loss: 0.909680
tensor(0.0035, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(2.5694e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.437549
Average KL loss: 0.476261
Average total loss: 0.913810
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(2.6583e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.437051
Average KL loss: 0.475697
Average total loss: 0.912748
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(2.7917e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.431108
Average KL loss: 0.475323
Average total loss: 0.906431
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-2.7898e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.434420
Average KL loss: 0.475237
Average total loss: 0.909657
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-3.1827e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.432411
Average KL loss: 0.475028
Average total loss: 0.907439
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-2.7880e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.431252
Average KL loss: 0.474655
Average total loss: 0.905907
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(6.6947e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.434525
Average KL loss: 0.474468
Average total loss: 0.908993
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(1.4172e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.433098
Average KL loss: 0.474321
Average total loss: 0.907419
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(6.3245e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.432121
Average KL loss: 0.474199
Average total loss: 0.906320
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-1.1178e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.431121
Average KL loss: 0.474065
Average total loss: 0.905186
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(3.4974e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.438803
Average KL loss: 0.473930
Average total loss: 0.912733
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(3.3911e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.433124
Average KL loss: 0.473801
Average total loss: 0.906925
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-1.7764e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.434992
Average KL loss: 0.473662
Average total loss: 0.908654
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-4.0447e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.433373
Average KL loss: 0.473548
Average total loss: 0.906921
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(1.1634e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.428506
Average KL loss: 0.473422
Average total loss: 0.901928
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(3.6091e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.434309
Average KL loss: 0.473289
Average total loss: 0.907598
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(5.9177e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.424921
Average KL loss: 0.473165
Average total loss: 0.898086
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(2.3012e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.425158
Average KL loss: 0.473061
Average total loss: 0.898219
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(3.1662e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.431259
Average KL loss: 0.472976
Average total loss: 0.904235
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(4.1887e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.434136
Average KL loss: 0.472868
Average total loss: 0.907005
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(4.9631e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.441317
Average KL loss: 0.472786
Average total loss: 0.914103
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-5.1999e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.436562
Average KL loss: 0.472696
Average total loss: 0.909258
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(3.0070e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.429344
Average KL loss: 0.472579
Average total loss: 0.901923
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-2.4815e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.428636
Average KL loss: 0.472492
Average total loss: 0.901128
tensor(0.0035, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-7.0283e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.434432
Average KL loss: 0.472415
Average total loss: 0.906847
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.5125e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.431211
Average KL loss: 0.472313
Average total loss: 0.903523
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.8544e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.433271
Average KL loss: 0.472192
Average total loss: 0.905463
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(2.4968e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.433650
Average KL loss: 0.472101
Average total loss: 0.905750
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(3.4236e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.437559
Average KL loss: 0.472056
Average total loss: 0.909615
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.8153e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.434295
Average KL loss: 0.472042
Average total loss: 0.906337
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.1585e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.428506
Average KL loss: 0.472031
Average total loss: 0.900537
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(6.4489e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.428958
Average KL loss: 0.472022
Average total loss: 0.900981
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-4.9164e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.433480
Average KL loss: 0.472012
Average total loss: 0.905492
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.7038e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.432952
Average KL loss: 0.472003
Average total loss: 0.904956
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.8507e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.430810
Average KL loss: 0.471995
Average total loss: 0.902806
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(2.4926e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.433412
Average KL loss: 0.471985
Average total loss: 0.905397
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-2.0957e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.428716
Average KL loss: 0.471976
Average total loss: 0.900692
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.2612e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.429357
Average KL loss: 0.471967
Average total loss: 0.901324
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.2602e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.430150
Average KL loss: 0.471957
Average total loss: 0.902106
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-3.5415e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.433010
Average KL loss: 0.471950
Average total loss: 0.904960
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(2.8957e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.433134
Average KL loss: 0.471949
Average total loss: 0.905082
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(3.8033e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.430786
Average KL loss: 0.471948
Average total loss: 0.902734
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-4.6186e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.432528
Average KL loss: 0.471947
Average total loss: 0.904474
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-2.7502e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.433991
Average KL loss: 0.471946
Average total loss: 0.905937
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(9.4274e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.430427
Average KL loss: 0.471945
Average total loss: 0.902372
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.2625e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.431332
Average KL loss: 0.471944
Average total loss: 0.903276
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(6.9100e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.430325
Average KL loss: 0.471942
Average total loss: 0.902268
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.3376e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.428320
Average KL loss: 0.471941
Average total loss: 0.900261
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(3.0909e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.425465
Average KL loss: 0.471940
Average total loss: 0.897405
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.2029e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.442308
Average KL loss: 0.471939
Average total loss: 0.914248
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.2669e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.433678
Average KL loss: 0.471938
Average total loss: 0.905616
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.5399e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.433545
Average KL loss: 0.471937
Average total loss: 0.905482
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.4603e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.430527
Average KL loss: 0.471936
Average total loss: 0.902464
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(3.4932e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.430162
Average KL loss: 0.471935
Average total loss: 0.902097
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.5566e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.429179
Average KL loss: 0.471935
Average total loss: 0.901114
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.2462e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.437041
Average KL loss: 0.471934
Average total loss: 0.908974
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.9236e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.427257
Average KL loss: 0.471933
Average total loss: 0.899189
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-2.9245e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.432615
Average KL loss: 0.471932
Average total loss: 0.904547
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(3.3593e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.437295
Average KL loss: 0.471930
Average total loss: 0.909226
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.6823e-09, device='cuda:0')
 Percentile value: 8.058657385845436e-08
Non-zero model percentage: 6.871959686279297%, Non-zero mask percentage: 6.871959686279297%

--- Pruning Level [12/24]: ---
conv1.weight         | nonzeros =      78 /    1728             (  4.51%) | total_pruned =    1650 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      33 /   36864             (  0.09%) | total_pruned =   36831 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      29 /   36864             (  0.08%) | total_pruned =   36835 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      57 /   36864             (  0.15%) | total_pruned =   36807 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     148 /   36864             (  0.40%) | total_pruned =   36716 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     458 /   73728             (  0.62%) | total_pruned =   73270 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1001 /  147456             (  0.68%) | total_pruned =  146455 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      76 /    8192             (  0.93%) | total_pruned =    8116 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1001 /  147456             (  0.68%) | total_pruned =  146455 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1031 /  147456             (  0.70%) | total_pruned =  146425 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2451 /  294912             (  0.83%) | total_pruned =  292461 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     198 /     256             ( 77.34%) | total_pruned =      58 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    3839 /  589824             (  0.65%) | total_pruned =  585985 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     173 /     256             ( 67.58%) | total_pruned =      83 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     292 /   32768             (  0.89%) | total_pruned =   32476 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      96 /     256             ( 37.50%) | total_pruned =     160 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2502 /  589824             (  0.42%) | total_pruned =  587322 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     169 /     256             ( 66.02%) | total_pruned =      87 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1678 /  589824             (  0.28%) | total_pruned =  588146 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     107 /     256             ( 41.80%) | total_pruned =     149 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    4095 / 1179648             (  0.35%) | total_pruned = 1175553 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     329 /     512             ( 64.26%) | total_pruned =     183 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    4624 / 2359296             (  0.20%) | total_pruned = 2354672 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     139 /     512             ( 27.15%) | total_pruned =     373 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      35 /     512             (  6.84%) | total_pruned =     477 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     191 /  131072             (  0.15%) | total_pruned =  130881 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      36 /     512             (  7.03%) | total_pruned =     476 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2708 / 2359296             (  0.11%) | total_pruned = 2356588 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      83 /     512             ( 16.21%) | total_pruned =     429 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  737628 / 2359296             ( 31.26%) | total_pruned = 1621668 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     253 /     512             ( 49.41%) | total_pruned =     259 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     173 /     512             ( 33.79%) | total_pruned =     339 | shape = torch.Size([512])
linear.weight        | nonzeros =    1763 /    5120             ( 34.43%) | total_pruned =    3357 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 768200, pruned : 10410562, total: 11178762, Compression rate :      14.55x  ( 93.13% pruned)
Train Epoch: 99/100 Loss: 0.431084 Accuracy: 76.56 93.12 % Best test Accuracy: 78.53%
tensor(0.0035, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-3.0069e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.356758
Average KL loss: 0.394317
Average total loss: 1.751075
tensor(-0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-9.6439e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.326514
Average KL loss: 0.325417
Average total loss: 1.651930
tensor(0.0014, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.6677e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.139069
Average KL loss: 0.329553
Average total loss: 1.468622
tensor(0.0016, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.4785e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.040051
Average KL loss: 0.333329
Average total loss: 1.373380
tensor(0.0016, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.2138e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.979475
Average KL loss: 0.339133
Average total loss: 1.318607
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.0369e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.955844
Average KL loss: 0.345029
Average total loss: 1.300873
tensor(0.0017, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.1881e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.907486
Average KL loss: 0.346976
Average total loss: 1.254462
tensor(0.0017, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.5572e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.887363
Average KL loss: 0.351217
Average total loss: 1.238580
tensor(0.0018, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.0484e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.882437
Average KL loss: 0.356739
Average total loss: 1.239176
tensor(0.0018, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-9.4716e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.842147
Average KL loss: 0.361339
Average total loss: 1.203485
tensor(0.0019, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.5004e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.828965
Average KL loss: 0.366622
Average total loss: 1.195587
tensor(0.0019, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.1784e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.816422
Average KL loss: 0.370946
Average total loss: 1.187368
tensor(0.0020, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.3492e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.808338
Average KL loss: 0.378284
Average total loss: 1.186622
tensor(0.0020, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.0201e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.786494
Average KL loss: 0.381318
Average total loss: 1.167811
tensor(0.0021, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-2.1104e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.779846
Average KL loss: 0.383516
Average total loss: 1.163361
tensor(0.0021, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.6671e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.774363
Average KL loss: 0.388028
Average total loss: 1.162391
tensor(-0.0065, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-2.2465e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.748875
Average KL loss: 0.391695
Average total loss: 1.140570
tensor(0.0029, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.5377e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.746553
Average KL loss: 0.393599
Average total loss: 1.140151
tensor(0.0022, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-5.9109e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.742884
Average KL loss: 0.397727
Average total loss: 1.140611
tensor(0.0023, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-6.4217e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.732130
Average KL loss: 0.400729
Average total loss: 1.132858
tensor(0.0022, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-6.7904e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.727032
Average KL loss: 0.406098
Average total loss: 1.133130
tensor(0.0038, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(2.7718e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.741713
Average KL loss: 0.408927
Average total loss: 1.150640
tensor(0.0024, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-7.3702e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.718934
Average KL loss: 0.410769
Average total loss: 1.129703
tensor(0.0024, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-3.6928e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.713395
Average KL loss: 0.413657
Average total loss: 1.127052
tensor(0.0025, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.0474e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.708656
Average KL loss: 0.419121
Average total loss: 1.127777
tensor(-0.0027, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.3165e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.701177
Average KL loss: 0.419261
Average total loss: 1.120438
tensor(0.0029, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(6.5484e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.699082
Average KL loss: 0.420998
Average total loss: 1.120080
tensor(0.0025, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.2245e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.703174
Average KL loss: 0.423257
Average total loss: 1.126431
tensor(0.0026, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-6.4932e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.696309
Average KL loss: 0.426211
Average total loss: 1.122520
tensor(0.0011, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-4.3146e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.691644
Average KL loss: 0.432211
Average total loss: 1.123855
tensor(0.0028, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.9016e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.696272
Average KL loss: 0.431223
Average total loss: 1.127495
tensor(0.0027, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-3.2297e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.677807
Average KL loss: 0.432340
Average total loss: 1.110147
tensor(0.0027, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.9165e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.677540
Average KL loss: 0.434006
Average total loss: 1.111546
tensor(0.0027, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(5.4997e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.672063
Average KL loss: 0.434538
Average total loss: 1.106602
tensor(0.0027, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.5780e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.664484
Average KL loss: 0.437864
Average total loss: 1.102348
tensor(-0.0011, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.9004e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.674008
Average KL loss: 0.436284
Average total loss: 1.110291
tensor(0.0032, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(6.4104e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.660227
Average KL loss: 0.439034
Average total loss: 1.099262
tensor(0.0028, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.4062e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.660720
Average KL loss: 0.440971
Average total loss: 1.101691
tensor(0.0028, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-7.8732e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.661885
Average KL loss: 0.442275
Average total loss: 1.104160
tensor(0.0023, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.4370e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.659534
Average KL loss: 0.447503
Average total loss: 1.107037
tensor(0.0023, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.6855e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.655835
Average KL loss: 0.446102
Average total loss: 1.101938
tensor(0.0030, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(5.1681e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.653288
Average KL loss: 0.447204
Average total loss: 1.100492
tensor(0.0029, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(2.1633e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.663330
Average KL loss: 0.448185
Average total loss: 1.111514
tensor(0.0029, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-4.0604e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.643503
Average KL loss: 0.450366
Average total loss: 1.093869
tensor(0.0127, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(2.4204e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.656095
Average KL loss: 0.453551
Average total loss: 1.109646
tensor(0.0039, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(2.1405e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.644906
Average KL loss: 0.452249
Average total loss: 1.097155
tensor(0.0030, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-4.6313e-11, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.645372
Average KL loss: 0.453455
Average total loss: 1.098827
tensor(0.0030, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(2.2195e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.646785
Average KL loss: 0.454202
Average total loss: 1.100987
tensor(0.0036, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.4384e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.637021
Average KL loss: 0.458617
Average total loss: 1.095638
tensor(0.0033, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(5.0244e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.641659
Average KL loss: 0.457255
Average total loss: 1.098914
tensor(0.0029, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-5.5663e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.638324
Average KL loss: 0.458191
Average total loss: 1.096516
tensor(0.0031, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.8374e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.635427
Average KL loss: 0.459155
Average total loss: 1.094583
tensor(0.0030, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-7.3676e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.631607
Average KL loss: 0.462769
Average total loss: 1.094376
tensor(0.0057, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(6.3531e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.630537
Average KL loss: 0.459913
Average total loss: 1.090450
tensor(0.0033, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(3.3777e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.632699
Average KL loss: 0.461296
Average total loss: 1.093995
tensor(0.0031, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-4.5657e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.623906
Average KL loss: 0.462824
Average total loss: 1.086730
tensor(0.0032, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-1.1279e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.629573
Average KL loss: 0.463620
Average total loss: 1.093193
tensor(0.0093, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(1.4868e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.628333
Average KL loss: 0.468050
Average total loss: 1.096383
tensor(0.0023, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-2.4270e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.623482
Average KL loss: 0.465731
Average total loss: 1.089213
tensor(0.0033, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(1.8017e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.621945
Average KL loss: 0.466666
Average total loss: 1.088610
tensor(0.0032, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(3.4920e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.624150
Average KL loss: 0.467260
Average total loss: 1.091410
tensor(0.0041, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(2.4614e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.624700
Average KL loss: 0.471589
Average total loss: 1.096289
tensor(0.0041, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(2.4622e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.621746
Average KL loss: 0.471186
Average total loss: 1.092933
tensor(0.0033, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(8.4958e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.621625
Average KL loss: 0.470499
Average total loss: 1.092124
tensor(0.0033, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-1.4706e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.618855
Average KL loss: 0.472522
Average total loss: 1.091376
tensor(0.0033, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-2.2509e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.619707
Average KL loss: 0.474849
Average total loss: 1.094556
tensor(-0.0038, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.7869e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.614419
Average KL loss: 0.473853
Average total loss: 1.088273
tensor(0.0031, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-8.4348e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.616795
Average KL loss: 0.470927
Average total loss: 1.087722
tensor(0.0033, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(1.5764e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.615640
Average KL loss: 0.466328
Average total loss: 1.081969
tensor(0.0033, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.7412e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.608489
Average KL loss: 0.462734
Average total loss: 1.071223
tensor(0.0033, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.4049e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.603784
Average KL loss: 0.459690
Average total loss: 1.063474
tensor(0.0033, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-1.3639e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.608964
Average KL loss: 0.457179
Average total loss: 1.066143
tensor(0.0033, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(4.1473e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.606462
Average KL loss: 0.455124
Average total loss: 1.061586
tensor(0.0033, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(2.4489e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.608573
Average KL loss: 0.453047
Average total loss: 1.061620
tensor(0.0033, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(3.7140e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.608373
Average KL loss: 0.451386
Average total loss: 1.059759
tensor(0.0033, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-1.7372e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.605786
Average KL loss: 0.449872
Average total loss: 1.055659
tensor(0.0033, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-2.3683e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.608121
Average KL loss: 0.448483
Average total loss: 1.056604
tensor(0.0033, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(2.3241e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.603554
Average KL loss: 0.447152
Average total loss: 1.050706
tensor(0.0033, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(2.7415e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.605505
Average KL loss: 0.445893
Average total loss: 1.051398
tensor(0.0033, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(1.1271e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.600798
Average KL loss: 0.444759
Average total loss: 1.045558
tensor(0.0033, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-4.7696e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.607697
Average KL loss: 0.443595
Average total loss: 1.051292
tensor(0.0033, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-2.0218e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.603343
Average KL loss: 0.442640
Average total loss: 1.045984
tensor(0.0033, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(3.0538e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.601300
Average KL loss: 0.441737
Average total loss: 1.043037
tensor(0.0033, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-2.9013e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.609987
Average KL loss: 0.440778
Average total loss: 1.050765
tensor(0.0033, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-1.3475e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.603156
Average KL loss: 0.440012
Average total loss: 1.043168
tensor(0.0033, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(1.3065e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.609546
Average KL loss: 0.439403
Average total loss: 1.048948
tensor(0.0033, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(2.4384e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.602153
Average KL loss: 0.438804
Average total loss: 1.040957
tensor(0.0033, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-2.1392e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.601156
Average KL loss: 0.438181
Average total loss: 1.039336
tensor(0.0033, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-1.9287e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.600394
Average KL loss: 0.437462
Average total loss: 1.037856
tensor(0.0033, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-1.3088e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.608704
Average KL loss: 0.436731
Average total loss: 1.045435
tensor(0.0033, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(1.3619e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.601951
Average KL loss: 0.436051
Average total loss: 1.038003
tensor(0.0033, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(1.6909e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.605972
Average KL loss: 0.435463
Average total loss: 1.041436
tensor(0.0033, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(1.1927e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.600629
Average KL loss: 0.434939
Average total loss: 1.035568
tensor(0.0033, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(9.9829e-11, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.602236
Average KL loss: 0.434447
Average total loss: 1.036684
tensor(0.0033, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-1.6077e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.607336
Average KL loss: 0.433826
Average total loss: 1.041162
tensor(0.0033, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-7.8885e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.602646
Average KL loss: 0.433370
Average total loss: 1.036015
tensor(0.0033, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(2.2268e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.599629
Average KL loss: 0.433036
Average total loss: 1.032665
tensor(0.0033, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(1.2132e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.605868
Average KL loss: 0.432527
Average total loss: 1.038395
tensor(0.0033, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(7.5025e-11, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.601052
Average KL loss: 0.432016
Average total loss: 1.033068
tensor(0.0033, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(1.9541e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.602575
Average KL loss: 0.431410
Average total loss: 1.033985
tensor(0.0033, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-1.2206e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.604910
Average KL loss: 0.430880
Average total loss: 1.035790
tensor(0.0033, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-3.1147e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.598769
Average KL loss: 0.430600
Average total loss: 1.029369
tensor(0.0033, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(2.0684e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.603189
Average KL loss: 0.430060
Average total loss: 1.033248
tensor(0.0033, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(1.3536e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.603323
Average KL loss: 0.429664
Average total loss: 1.032988
tensor(0.0033, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-1.9650e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.605133
Average KL loss: 0.429144
Average total loss: 1.034277
tensor(0.0033, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-4.0342e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.600250
Average KL loss: 0.428851
Average total loss: 1.029101
tensor(0.0033, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-3.8642e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.599652
Average KL loss: 0.428487
Average total loss: 1.028139
tensor(0.0033, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(4.1609e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.607170
Average KL loss: 0.428088
Average total loss: 1.035258
tensor(0.0033, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-5.9116e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.603284
Average KL loss: 0.427687
Average total loss: 1.030971
tensor(0.0033, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-4.0984e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.605185
Average KL loss: 0.427359
Average total loss: 1.032545
tensor(0.0033, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(2.8287e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.605106
Average KL loss: 0.427131
Average total loss: 1.032237
tensor(0.0033, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(5.9913e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.610994
Average KL loss: 0.426710
Average total loss: 1.037704
tensor(0.0033, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-7.4006e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.607572
Average KL loss: 0.426373
Average total loss: 1.033945
tensor(0.0033, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-1.8466e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.605051
Average KL loss: 0.425924
Average total loss: 1.030975
tensor(0.0033, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-1.8932e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.605205
Average KL loss: 0.425492
Average total loss: 1.030697
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-5.0575e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.605063
Average KL loss: 0.425340
Average total loss: 1.030402
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.1885e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.604001
Average KL loss: 0.425094
Average total loss: 1.029095
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.7763e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.606375
Average KL loss: 0.424732
Average total loss: 1.031107
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(4.3972e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.607636
Average KL loss: 0.424548
Average total loss: 1.032184
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.1602e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.606575
Average KL loss: 0.424437
Average total loss: 1.031012
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.0107e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.610874
Average KL loss: 0.424322
Average total loss: 1.035196
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(5.9831e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.609791
Average KL loss: 0.424242
Average total loss: 1.034034
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.9526e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.607000
Average KL loss: 0.424162
Average total loss: 1.031162
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.0200e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.606777
Average KL loss: 0.424097
Average total loss: 1.030873
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(5.6860e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.604820
Average KL loss: 0.424024
Average total loss: 1.028843
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.6998e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.609704
Average KL loss: 0.423932
Average total loss: 1.033636
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.6730e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.605413
Average KL loss: 0.423850
Average total loss: 1.029263
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(3.3605e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.600570
Average KL loss: 0.423773
Average total loss: 1.024342
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-8.3210e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.606361
Average KL loss: 0.423689
Average total loss: 1.030050
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-4.5299e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.605460
Average KL loss: 0.423618
Average total loss: 1.029079
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.9264e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.609608
Average KL loss: 0.423534
Average total loss: 1.033142
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(6.8140e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.605321
Average KL loss: 0.423442
Average total loss: 1.028763
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(2.5754e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.607525
Average KL loss: 0.423364
Average total loss: 1.030889
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-5.0783e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.609584
Average KL loss: 0.423310
Average total loss: 1.032894
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(5.1065e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.608884
Average KL loss: 0.423230
Average total loss: 1.032115
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.4225e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.609274
Average KL loss: 0.423158
Average total loss: 1.032432
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.9369e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.609553
Average KL loss: 0.423103
Average total loss: 1.032656
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-3.1355e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.606507
Average KL loss: 0.423043
Average total loss: 1.029550
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-4.7435e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.604979
Average KL loss: 0.422988
Average total loss: 1.027968
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.4503e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.603705
Average KL loss: 0.422975
Average total loss: 1.026680
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.1991e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.604259
Average KL loss: 0.422969
Average total loss: 1.027228
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.7608e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.603660
Average KL loss: 0.422961
Average total loss: 1.026621
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.1958e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.608507
Average KL loss: 0.422954
Average total loss: 1.031461
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.9688e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.610489
Average KL loss: 0.422945
Average total loss: 1.033434
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.1575e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.607473
Average KL loss: 0.422938
Average total loss: 1.030411
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(2.7861e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.606281
Average KL loss: 0.422929
Average total loss: 1.029209
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(3.6526e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.602669
Average KL loss: 0.422923
Average total loss: 1.025591
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-5.0864e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.606812
Average KL loss: 0.422917
Average total loss: 1.029729
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-4.3208e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.607702
Average KL loss: 0.422909
Average total loss: 1.030611
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-8.8776e-11, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.603504
Average KL loss: 0.422903
Average total loss: 1.026407
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-4.8671e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.604559
Average KL loss: 0.422900
Average total loss: 1.027459
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-3.6454e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.606916
Average KL loss: 0.422899
Average total loss: 1.029815
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.9341e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.602491
Average KL loss: 0.422898
Average total loss: 1.025389
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(2.5543e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.598405
Average KL loss: 0.422897
Average total loss: 1.021302
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.7688e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.600673
Average KL loss: 0.422897
Average total loss: 1.023570
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(7.5357e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.608980
Average KL loss: 0.422896
Average total loss: 1.031876
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-5.0606e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.607351
Average KL loss: 0.422895
Average total loss: 1.030246
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-3.2154e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.599807
Average KL loss: 0.422895
Average total loss: 1.022701
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(3.6060e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.600188
Average KL loss: 0.422894
Average total loss: 1.023082
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(3.1081e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.608033
Average KL loss: 0.422893
Average total loss: 1.030926
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(4.6257e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.603732
Average KL loss: 0.422893
Average total loss: 1.026624
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.7694e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.601180
Average KL loss: 0.422892
Average total loss: 1.024072
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.4540e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.607058
Average KL loss: 0.422891
Average total loss: 1.029950
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-3.5189e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.607877
Average KL loss: 0.422891
Average total loss: 1.030768
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-3.6796e-09, device='cuda:0')
 Percentile value: 8.125886097332113e-08
Non-zero model percentage: 5.497567176818848%, Non-zero mask percentage: 5.497567176818848%

--- Pruning Level [13/24]: ---
conv1.weight         | nonzeros =      73 /    1728             (  4.22%) | total_pruned =    1655 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      31 /   36864             (  0.08%) | total_pruned =   36833 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      27 /   36864             (  0.07%) | total_pruned =   36837 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      50 /   36864             (  0.14%) | total_pruned =   36814 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     133 /   36864             (  0.36%) | total_pruned =   36731 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     379 /   73728             (  0.51%) | total_pruned =   73349 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     788 /  147456             (  0.53%) | total_pruned =  146668 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      64 /    8192             (  0.78%) | total_pruned =    8128 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     812 /  147456             (  0.55%) | total_pruned =  146644 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     832 /  147456             (  0.56%) | total_pruned =  146624 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1871 /  294912             (  0.63%) | total_pruned =  293041 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     190 /     256             ( 74.22%) | total_pruned =      66 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2834 /  589824             (  0.48%) | total_pruned =  586990 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     168 /     256             ( 65.62%) | total_pruned =      88 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     204 /   32768             (  0.62%) | total_pruned =   32564 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      80 /     256             ( 31.25%) | total_pruned =     176 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1787 /  589824             (  0.30%) | total_pruned =  588037 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     150 /     256             ( 58.59%) | total_pruned =     106 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1198 /  589824             (  0.20%) | total_pruned =  588626 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      97 /     256             ( 37.89%) | total_pruned =     159 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2669 / 1179648             (  0.23%) | total_pruned = 1176979 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     290 /     512             ( 56.64%) | total_pruned =     222 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    2882 / 2359296             (  0.12%) | total_pruned = 2356414 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     129 /     512             ( 25.20%) | total_pruned =     383 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     120 /  131072             (  0.09%) | total_pruned =  130952 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      29 /     512             (  5.66%) | total_pruned =     483 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      31 /     512             (  6.05%) | total_pruned =     481 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1591 / 2359296             (  0.07%) | total_pruned = 2357705 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      76 /     512             ( 14.84%) | total_pruned =     436 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  592337 / 2359296             ( 25.11%) | total_pruned = 1766959 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     245 /     512             ( 47.85%) | total_pruned =     267 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     161 /     512             ( 31.45%) | total_pruned =     351 | shape = torch.Size([512])
linear.weight        | nonzeros =    1566 /    5120             ( 30.59%) | total_pruned =    3554 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 614560, pruned : 10564202, total: 11178762, Compression rate :      18.19x  ( 94.50% pruned)
Train Epoch: 99/100 Loss: 0.469416 Accuracy: 75.17 87.79 % Best test Accuracy: 77.19%
tensor(0.0033, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-3.0857e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.226289
Average KL loss: 0.367453
Average total loss: 1.593742
tensor(-0.0012, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.0134e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.254075
Average KL loss: 0.289155
Average total loss: 1.543229
tensor(0.0013, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.4901e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.126653
Average KL loss: 0.292142
Average total loss: 1.418795
tensor(0.0015, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.8162e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.038483
Average KL loss: 0.294285
Average total loss: 1.332768
tensor(0.0015, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-4.6801e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.984299
Average KL loss: 0.300266
Average total loss: 1.284565
tensor(0.0016, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.6414e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.920286
Average KL loss: 0.304959
Average total loss: 1.225245
tensor(0.0016, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.6447e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.902359
Average KL loss: 0.308267
Average total loss: 1.210626
tensor(0.0017, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.5482e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.863558
Average KL loss: 0.311773
Average total loss: 1.175331
tensor(0.0017, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-8.6592e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.860014
Average KL loss: 0.314917
Average total loss: 1.174931
tensor(0.0017, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.0460e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.842204
Average KL loss: 0.318464
Average total loss: 1.160668
tensor(0.0018, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.1250e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.809166
Average KL loss: 0.320027
Average total loss: 1.129193
tensor(0.0018, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-9.3489e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.822688
Average KL loss: 0.323050
Average total loss: 1.145738
tensor(0.0018, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.5710e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.790828
Average KL loss: 0.326586
Average total loss: 1.117414
tensor(0.0019, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.0273e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.781529
Average KL loss: 0.329434
Average total loss: 1.110963
tensor(0.0019, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.7651e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.784628
Average KL loss: 0.332134
Average total loss: 1.116762
tensor(0.0020, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-5.3486e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.766905
Average KL loss: 0.336908
Average total loss: 1.103813
tensor(-0.0067, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-2.2157e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.762576
Average KL loss: 0.339592
Average total loss: 1.102168
tensor(0.0028, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(1.2321e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.751887
Average KL loss: 0.340642
Average total loss: 1.092528
tensor(0.0020, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-7.0261e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.749789
Average KL loss: 0.343742
Average total loss: 1.093531
tensor(0.0021, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-3.2384e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.752303
Average KL loss: 0.346914
Average total loss: 1.099218
tensor(0.0020, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-4.4305e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.738468
Average KL loss: 0.352798
Average total loss: 1.091266
tensor(0.0036, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(3.4616e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.732499
Average KL loss: 0.352918
Average total loss: 1.085418
tensor(0.0022, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-5.9796e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.733617
Average KL loss: 0.354635
Average total loss: 1.088252
tensor(0.0022, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-5.2916e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.720110
Average KL loss: 0.356643
Average total loss: 1.076753
tensor(0.0023, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-4.0048e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.707174
Average KL loss: 0.361647
Average total loss: 1.068821
tensor(-0.0029, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.3296e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.710275
Average KL loss: 0.360594
Average total loss: 1.070869
tensor(0.0027, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(4.5114e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.702573
Average KL loss: 0.363172
Average total loss: 1.065745
tensor(0.0023, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-5.5857e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.707613
Average KL loss: 0.365654
Average total loss: 1.073267
tensor(0.0024, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-5.5729e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.706192
Average KL loss: 0.367865
Average total loss: 1.074057
tensor(0.0009, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.9817e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.693376
Average KL loss: 0.373730
Average total loss: 1.067106
tensor(0.0026, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(2.3814e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.689565
Average KL loss: 0.371904
Average total loss: 1.061469
tensor(0.0025, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.0381e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.696510
Average KL loss: 0.373707
Average total loss: 1.070216
tensor(0.0025, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.6035e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.691090
Average KL loss: 0.375219
Average total loss: 1.066308
tensor(0.0025, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-5.1538e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.679063
Average KL loss: 0.376050
Average total loss: 1.055113
tensor(0.0025, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-4.9926e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.675433
Average KL loss: 0.380034
Average total loss: 1.055468
tensor(-0.0014, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.0285e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.672394
Average KL loss: 0.379211
Average total loss: 1.051605
tensor(0.0030, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-4.3318e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.670993
Average KL loss: 0.381044
Average total loss: 1.052037
tensor(0.0026, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.2021e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.668598
Average KL loss: 0.383962
Average total loss: 1.052560
tensor(0.0026, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.0509e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.673797
Average KL loss: 0.386031
Average total loss: 1.059827
tensor(0.0021, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.3825e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.676890
Average KL loss: 0.391095
Average total loss: 1.067985
tensor(0.0021, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.8758e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.670692
Average KL loss: 0.389806
Average total loss: 1.060498
tensor(0.0028, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(2.7953e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.664565
Average KL loss: 0.388669
Average total loss: 1.053234
tensor(0.0027, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-4.4111e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.667938
Average KL loss: 0.389854
Average total loss: 1.057792
tensor(0.0027, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-3.1423e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.655091
Average KL loss: 0.391667
Average total loss: 1.046758
tensor(0.0125, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(2.4302e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.659199
Average KL loss: 0.393901
Average total loss: 1.053100
tensor(0.0037, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(2.3402e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.648746
Average KL loss: 0.393394
Average total loss: 1.042140
tensor(0.0028, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-2.6029e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.656378
Average KL loss: 0.394838
Average total loss: 1.051216
tensor(0.0028, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-3.0393e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.654349
Average KL loss: 0.396378
Average total loss: 1.050727
tensor(0.0034, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(1.2050e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.645748
Average KL loss: 0.398973
Average total loss: 1.044721
tensor(0.0031, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(5.0969e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.649475
Average KL loss: 0.395194
Average total loss: 1.044669
tensor(0.0027, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-2.2221e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.650435
Average KL loss: 0.396693
Average total loss: 1.047128
tensor(0.0029, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-2.8952e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.648158
Average KL loss: 0.398486
Average total loss: 1.046645
tensor(0.0027, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-3.5863e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.647564
Average KL loss: 0.402601
Average total loss: 1.050165
tensor(0.0055, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(6.0941e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.637512
Average KL loss: 0.399973
Average total loss: 1.037486
tensor(0.0031, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(3.5028e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.644209
Average KL loss: 0.400411
Average total loss: 1.044621
tensor(0.0029, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(7.4780e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.642349
Average KL loss: 0.402216
Average total loss: 1.044564
tensor(0.0029, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-3.4644e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.645286
Average KL loss: 0.403199
Average total loss: 1.048485
tensor(0.0091, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(1.5165e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.639626
Average KL loss: 0.407094
Average total loss: 1.046719
tensor(0.0021, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-2.5594e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.639288
Average KL loss: 0.404583
Average total loss: 1.043871
tensor(0.0031, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(3.0832e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.641148
Average KL loss: 0.405326
Average total loss: 1.046474
tensor(0.0030, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(1.0718e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.635334
Average KL loss: 0.405889
Average total loss: 1.041223
tensor(0.0039, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(2.0399e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.637061
Average KL loss: 0.410272
Average total loss: 1.047332
tensor(0.0039, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(2.2140e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.638726
Average KL loss: 0.407895
Average total loss: 1.046622
tensor(0.0031, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(1.3201e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.636215
Average KL loss: 0.407387
Average total loss: 1.043603
tensor(0.0030, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-4.3083e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.636157
Average KL loss: 0.407305
Average total loss: 1.043462
tensor(0.0031, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(1.8085e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.635185
Average KL loss: 0.406373
Average total loss: 1.041559
tensor(0.0031, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-2.7323e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.631797
Average KL loss: 0.403524
Average total loss: 1.035321
tensor(0.0031, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(3.2720e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.633985
Average KL loss: 0.401275
Average total loss: 1.035260
tensor(0.0031, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(2.9483e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.635906
Average KL loss: 0.399370
Average total loss: 1.035277
tensor(0.0031, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(5.9919e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.631239
Average KL loss: 0.397962
Average total loss: 1.029200
tensor(0.0031, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-4.6154e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.629717
Average KL loss: 0.396606
Average total loss: 1.026323
tensor(0.0031, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-5.1475e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.625611
Average KL loss: 0.395472
Average total loss: 1.021083
tensor(0.0031, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-3.1587e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.629211
Average KL loss: 0.394294
Average total loss: 1.023505
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(1.3226e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.631595
Average KL loss: 0.393404
Average total loss: 1.025000
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(9.4520e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.627385
Average KL loss: 0.392636
Average total loss: 1.020020
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-2.2604e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.621635
Average KL loss: 0.391630
Average total loss: 1.013265
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(2.3583e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.625120
Average KL loss: 0.390719
Average total loss: 1.015839
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-3.6031e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.623877
Average KL loss: 0.390053
Average total loss: 1.013929
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-9.7005e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.628017
Average KL loss: 0.389428
Average total loss: 1.017445
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(2.2274e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.626455
Average KL loss: 0.388962
Average total loss: 1.015417
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-1.7013e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.623653
Average KL loss: 0.388459
Average total loss: 1.012112
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(6.7572e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.624182
Average KL loss: 0.387939
Average total loss: 1.012121
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-1.3946e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.630595
Average KL loss: 0.387420
Average total loss: 1.018015
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(2.5963e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.621510
Average KL loss: 0.387013
Average total loss: 1.008523
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(4.0786e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.629074
Average KL loss: 0.386530
Average total loss: 1.015605
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(3.0182e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.622256
Average KL loss: 0.386091
Average total loss: 1.008347
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(1.6811e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.622350
Average KL loss: 0.385634
Average total loss: 1.007984
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(2.4998e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.624559
Average KL loss: 0.385200
Average total loss: 1.009759
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(1.2567e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.625806
Average KL loss: 0.384821
Average total loss: 1.010627
tensor(0.0031, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(1.2289e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.621550
Average KL loss: 0.384407
Average total loss: 1.005956
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-1.1951e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.624860
Average KL loss: 0.384068
Average total loss: 1.008928
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-1.8318e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.621873
Average KL loss: 0.383838
Average total loss: 1.005712
tensor(0.0031, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-3.0746e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.622679
Average KL loss: 0.383504
Average total loss: 1.006184
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(5.6854e-11, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.627719
Average KL loss: 0.383241
Average total loss: 1.010961
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(2.8702e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.622448
Average KL loss: 0.382783
Average total loss: 1.005231
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.7667e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.622245
Average KL loss: 0.382419
Average total loss: 1.004663
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-6.8107e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.627101
Average KL loss: 0.382049
Average total loss: 1.009150
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-3.9217e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.623573
Average KL loss: 0.381716
Average total loss: 1.005290
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-1.7862e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.624679
Average KL loss: 0.381496
Average total loss: 1.006174
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(1.9323e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.624415
Average KL loss: 0.381146
Average total loss: 1.005561
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.4702e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.619971
Average KL loss: 0.380918
Average total loss: 1.000889
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.9414e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.625380
Average KL loss: 0.380678
Average total loss: 1.006058
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(1.1475e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.625871
Average KL loss: 0.380391
Average total loss: 1.006262
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-4.8465e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.624663
Average KL loss: 0.380205
Average total loss: 1.004868
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(1.1744e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.626938
Average KL loss: 0.380058
Average total loss: 1.006996
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(1.7530e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.625275
Average KL loss: 0.379991
Average total loss: 1.005266
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-1.6352e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.624386
Average KL loss: 0.379792
Average total loss: 1.004177
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(5.3065e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.623611
Average KL loss: 0.379489
Average total loss: 1.003100
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(2.0403e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.626213
Average KL loss: 0.379199
Average total loss: 1.005412
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.1067e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.627631
Average KL loss: 0.378921
Average total loss: 1.006552
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.7209e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.622681
Average KL loss: 0.378849
Average total loss: 1.001530
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(1.0855e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.624121
Average KL loss: 0.378729
Average total loss: 1.002849
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(3.1460e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.624177
Average KL loss: 0.378659
Average total loss: 1.002836
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-9.2721e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.628376
Average KL loss: 0.378587
Average total loss: 1.006964
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.2483e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.621716
Average KL loss: 0.378506
Average total loss: 1.000223
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(7.0874e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.619824
Average KL loss: 0.378433
Average total loss: 0.998257
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-3.9817e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.624234
Average KL loss: 0.378365
Average total loss: 1.002599
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(8.2398e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.628425
Average KL loss: 0.378303
Average total loss: 1.006728
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-9.9571e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.632629
Average KL loss: 0.378236
Average total loss: 1.010866
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-1.5662e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.628110
Average KL loss: 0.378181
Average total loss: 1.006291
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.3147e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.631058
Average KL loss: 0.378122
Average total loss: 1.009180
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-3.5078e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.625260
Average KL loss: 0.378063
Average total loss: 1.003324
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.2226e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.624150
Average KL loss: 0.378015
Average total loss: 1.002165
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-1.6291e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.626589
Average KL loss: 0.377975
Average total loss: 1.004565
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(3.2275e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.621776
Average KL loss: 0.377930
Average total loss: 0.999706
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(1.3359e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.621250
Average KL loss: 0.377883
Average total loss: 0.999133
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-8.6450e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.623151
Average KL loss: 0.377832
Average total loss: 1.000983
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-5.4308e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.623021
Average KL loss: 0.377799
Average total loss: 1.000820
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(2.2167e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.622246
Average KL loss: 0.377794
Average total loss: 1.000040
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-8.8529e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.623826
Average KL loss: 0.377789
Average total loss: 1.001615
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(2.9282e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.622617
Average KL loss: 0.377784
Average total loss: 1.000401
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(1.8281e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.625965
Average KL loss: 0.377780
Average total loss: 1.003745
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-3.5622e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.628617
Average KL loss: 0.377776
Average total loss: 1.006393
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-4.4925e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.626858
Average KL loss: 0.377771
Average total loss: 1.004629
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-6.1178e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.624743
Average KL loss: 0.377766
Average total loss: 1.002509
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-7.3649e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.625386
Average KL loss: 0.377761
Average total loss: 1.003148
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-3.7843e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.625946
Average KL loss: 0.377756
Average total loss: 1.003701
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(2.1134e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.626162
Average KL loss: 0.377750
Average total loss: 1.003911
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.7308e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.626877
Average KL loss: 0.377747
Average total loss: 1.004623
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(8.2091e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.629347
Average KL loss: 0.377746
Average total loss: 1.007093
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-3.0818e-11, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.622643
Average KL loss: 0.377746
Average total loss: 1.000389
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.6171e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.622279
Average KL loss: 0.377745
Average total loss: 1.000024
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(2.5202e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.623868
Average KL loss: 0.377745
Average total loss: 1.001612
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-4.7001e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.627838
Average KL loss: 0.377744
Average total loss: 1.005582
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-5.3382e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.632167
Average KL loss: 0.377743
Average total loss: 1.009910
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(5.4455e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.621354
Average KL loss: 0.377743
Average total loss: 0.999097
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(6.9732e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.623391
Average KL loss: 0.377742
Average total loss: 1.001133
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(2.9677e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.623257
Average KL loss: 0.377742
Average total loss: 1.000999
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.1103e-09, device='cuda:0')
 Percentile value: 8.149865493578545e-08
Non-zero model percentage: 4.398054122924805%, Non-zero mask percentage: 4.398054122924805%

--- Pruning Level [14/24]: ---
conv1.weight         | nonzeros =      66 /    1728             (  3.82%) | total_pruned =    1662 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      27 /   36864             (  0.07%) | total_pruned =   36837 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      22 /   36864             (  0.06%) | total_pruned =   36842 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      45 /   36864             (  0.12%) | total_pruned =   36819 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     113 /   36864             (  0.31%) | total_pruned =   36751 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     267 /   73728             (  0.36%) | total_pruned =   73461 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     494 /  147456             (  0.34%) | total_pruned =  146962 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      53 /    8192             (  0.65%) | total_pruned =    8139 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     578 /  147456             (  0.39%) | total_pruned =  146878 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     641 /  147456             (  0.43%) | total_pruned =  146815 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1415 /  294912             (  0.48%) | total_pruned =  293497 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     171 /     256             ( 66.80%) | total_pruned =      85 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2021 /  589824             (  0.34%) | total_pruned =  587803 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     152 /     256             ( 59.38%) | total_pruned =     104 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     128 /   32768             (  0.39%) | total_pruned =   32640 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1117 /  589824             (  0.19%) | total_pruned =  588707 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     722 /  589824             (  0.12%) | total_pruned =  589102 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    1589 / 1179648             (  0.13%) | total_pruned = 1178059 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     236 /     512             ( 46.09%) | total_pruned =     276 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1742 / 2359296             (  0.07%) | total_pruned = 2357554 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     108 /     512             ( 21.09%) | total_pruned =     404 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      64 /  131072             (  0.05%) | total_pruned =  131008 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1020 / 2359296             (  0.04%) | total_pruned = 2358276 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      73 /     512             ( 14.26%) | total_pruned =     439 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  476077 / 2359296             ( 20.18%) | total_pruned = 1883219 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     237 /     512             ( 46.29%) | total_pruned =     275 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     148 /     512             ( 28.91%) | total_pruned =     364 | shape = torch.Size([512])
linear.weight        | nonzeros =    1453 /    5120             ( 28.38%) | total_pruned =    3667 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 491648, pruned : 10687114, total: 11178762, Compression rate :      22.74x  ( 95.60% pruned)
Train Epoch: 99/100 Loss: 0.549873 Accuracy: 72.81 82.19 % Best test Accuracy: 74.40%
tensor(0.0030, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.3253e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.164637
Average KL loss: 0.330325
Average total loss: 1.494962
tensor(-0.0013, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.0942e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.348210
Average KL loss: 0.252853
Average total loss: 1.601063
tensor(0.0011, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.6225e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.148494
Average KL loss: 0.254303
Average total loss: 1.402797
tensor(0.0014, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.1093e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.071282
Average KL loss: 0.256856
Average total loss: 1.328138
tensor(0.0014, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.1800e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.017541
Average KL loss: 0.259767
Average total loss: 1.277309
tensor(0.0014, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.1237e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.966055
Average KL loss: 0.262719
Average total loss: 1.228774
tensor(0.0015, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-2.7993e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.952479
Average KL loss: 0.266585
Average total loss: 1.219064
tensor(0.0015, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.2118e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.919936
Average KL loss: 0.270076
Average total loss: 1.190013
tensor(0.0015, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.2399e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.889741
Average KL loss: 0.272296
Average total loss: 1.162037
tensor(0.0016, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.1227e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.881517
Average KL loss: 0.275516
Average total loss: 1.157033
tensor(0.0016, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.0592e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.873706
Average KL loss: 0.278391
Average total loss: 1.152097
tensor(0.0016, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.6407e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.851876
Average KL loss: 0.280836
Average total loss: 1.132713
tensor(0.0017, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-8.4363e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.843438
Average KL loss: 0.283928
Average total loss: 1.127366
tensor(0.0017, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.3998e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.836167
Average KL loss: 0.287569
Average total loss: 1.123736
tensor(0.0018, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.0509e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.823877
Average KL loss: 0.288994
Average total loss: 1.112871
tensor(0.0018, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.1034e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.823322
Average KL loss: 0.294492
Average total loss: 1.117813
tensor(-0.0068, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.2442e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.813745
Average KL loss: 0.296380
Average total loss: 1.110125
tensor(0.0026, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(1.4626e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.805344
Average KL loss: 0.297623
Average total loss: 1.102967
tensor(0.0018, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.4058e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.805157
Average KL loss: 0.300791
Average total loss: 1.105948
tensor(0.0019, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-2.1718e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.786795
Average KL loss: 0.302858
Average total loss: 1.089653
tensor(0.0019, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-6.0536e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.781008
Average KL loss: 0.308204
Average total loss: 1.089212
tensor(0.0035, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(3.7006e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.779746
Average KL loss: 0.308101
Average total loss: 1.087848
tensor(0.0020, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-4.2867e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.771177
Average KL loss: 0.310457
Average total loss: 1.081634
tensor(0.0020, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(2.2426e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.765638
Average KL loss: 0.312172
Average total loss: 1.077810
tensor(0.0021, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-4.2919e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.764536
Average KL loss: 0.316294
Average total loss: 1.080830
tensor(-0.0031, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.3406e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.774779
Average KL loss: 0.315555
Average total loss: 1.090334
tensor(0.0025, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(6.9516e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.752339
Average KL loss: 0.316877
Average total loss: 1.069216
tensor(0.0021, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-3.5504e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.751446
Average KL loss: 0.318479
Average total loss: 1.069926
tensor(0.0022, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.7507e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.760175
Average KL loss: 0.319922
Average total loss: 1.080097
tensor(0.0007, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-3.5736e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.741136
Average KL loss: 0.326843
Average total loss: 1.067979
tensor(0.0024, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.8444e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.740077
Average KL loss: 0.323173
Average total loss: 1.063251
tensor(0.0023, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-5.9740e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.746529
Average KL loss: 0.324533
Average total loss: 1.071062
tensor(0.0023, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-6.0486e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.734734
Average KL loss: 0.326642
Average total loss: 1.061376
tensor(0.0023, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.6789e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.733156
Average KL loss: 0.328035
Average total loss: 1.061191
tensor(0.0023, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.1257e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.729589
Average KL loss: 0.331992
Average total loss: 1.061582
tensor(-0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-9.9628e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.736681
Average KL loss: 0.331419
Average total loss: 1.068100
tensor(0.0028, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(1.0185e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.733764
Average KL loss: 0.332671
Average total loss: 1.066435
tensor(0.0024, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(4.0098e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.727792
Average KL loss: 0.334711
Average total loss: 1.062502
tensor(0.0024, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.2094e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.722137
Average KL loss: 0.334907
Average total loss: 1.057045
tensor(0.0019, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.4619e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.718264
Average KL loss: 0.339632
Average total loss: 1.057895
tensor(0.0019, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.9393e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.716979
Average KL loss: 0.337914
Average total loss: 1.054893
tensor(0.0026, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.1796e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.729106
Average KL loss: 0.340182
Average total loss: 1.069288
tensor(0.0024, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-3.2720e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.723994
Average KL loss: 0.340007
Average total loss: 1.064001
tensor(0.0025, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.6848e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.709286
Average KL loss: 0.341006
Average total loss: 1.050292
tensor(0.0122, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(2.4435e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.716099
Average KL loss: 0.342415
Average total loss: 1.058513
tensor(0.0034, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(5.1646e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.713282
Average KL loss: 0.340641
Average total loss: 1.053923
tensor(0.0025, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.4324e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.710431
Average KL loss: 0.340587
Average total loss: 1.051018
tensor(0.0025, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.8758e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.711757
Average KL loss: 0.342336
Average total loss: 1.054094
tensor(0.0032, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(7.5886e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.706316
Average KL loss: 0.346785
Average total loss: 1.053101
tensor(0.0029, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(4.8203e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.704844
Average KL loss: 0.345639
Average total loss: 1.050484
tensor(0.0024, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.0750e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.701479
Average KL loss: 0.345934
Average total loss: 1.047413
tensor(0.0026, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-3.2347e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.700130
Average KL loss: 0.346895
Average total loss: 1.047025
tensor(0.0025, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-4.3100e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.702160
Average KL loss: 0.351239
Average total loss: 1.053399
tensor(0.0052, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(6.6156e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.707105
Average KL loss: 0.348729
Average total loss: 1.055834
tensor(0.0028, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(5.1704e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.706237
Average KL loss: 0.348622
Average total loss: 1.054859
tensor(0.0026, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-5.6727e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.697911
Average KL loss: 0.349700
Average total loss: 1.047611
tensor(0.0027, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-5.6175e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.697059
Average KL loss: 0.350382
Average total loss: 1.047441
tensor(0.0088, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.5105e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.695962
Average KL loss: 0.354063
Average total loss: 1.050025
tensor(0.0018, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-2.1599e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.693964
Average KL loss: 0.351952
Average total loss: 1.045916
tensor(0.0028, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(2.5146e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.696892
Average KL loss: 0.352366
Average total loss: 1.049258
tensor(0.0027, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-5.2085e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.693622
Average KL loss: 0.352750
Average total loss: 1.046371
tensor(0.0036, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(2.1376e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.691465
Average KL loss: 0.356866
Average total loss: 1.048331
tensor(0.0036, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(2.1041e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.690526
Average KL loss: 0.354341
Average total loss: 1.044866
tensor(0.0028, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(8.4515e-11, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.691874
Average KL loss: 0.355003
Average total loss: 1.046877
tensor(0.0028, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-2.0125e-11, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.688772
Average KL loss: 0.355574
Average total loss: 1.044346
tensor(0.0028, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-3.7273e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.698933
Average KL loss: 0.358472
Average total loss: 1.057405
tensor(-0.0043, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-1.7939e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.688460
Average KL loss: 0.358328
Average total loss: 1.046789
tensor(0.0026, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-5.5275e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.688146
Average KL loss: 0.357638
Average total loss: 1.045784
tensor(0.0029, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.0958e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.686842
Average KL loss: 0.359115
Average total loss: 1.045957
tensor(0.0028, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(8.0039e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.689328
Average KL loss: 0.359262
Average total loss: 1.048590
tensor(0.0036, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(1.9430e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.686163
Average KL loss: 0.362885
Average total loss: 1.049048
tensor(0.0046, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(4.1583e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.683433
Average KL loss: 0.359400
Average total loss: 1.042833
tensor(0.0029, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(1.1410e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.683632
Average KL loss: 0.360339
Average total loss: 1.043971
tensor(0.0029, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(2.4427e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.684174
Average KL loss: 0.362175
Average total loss: 1.046349
tensor(0.0029, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-3.0949e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.686180
Average KL loss: 0.364856
Average total loss: 1.051035
tensor(0.0034, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(1.1932e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.683313
Average KL loss: 0.364410
Average total loss: 1.047723
tensor(0.0037, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(1.9330e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.681412
Average KL loss: 0.363255
Average total loss: 1.044667
tensor(0.0030, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(8.9664e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.689290
Average KL loss: 0.363025
Average total loss: 1.052315
tensor(0.0030, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(3.7633e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.681326
Average KL loss: 0.363800
Average total loss: 1.045126
tensor(0.0030, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-2.6680e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.681759
Average KL loss: 0.364023
Average total loss: 1.045781
tensor(0.0021, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-2.4406e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.680376
Average KL loss: 0.367202
Average total loss: 1.047578
tensor(0.0018, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-3.0657e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.676897
Average KL loss: 0.364321
Average total loss: 1.041218
tensor(0.0031, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(3.7093e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.679667
Average KL loss: 0.364134
Average total loss: 1.043801
tensor(0.0030, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(6.0705e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.677549
Average KL loss: 0.364613
Average total loss: 1.042162
tensor(0.0028, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-6.9849e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.680471
Average KL loss: 0.367619
Average total loss: 1.048090
tensor(0.0032, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(4.6500e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.679881
Average KL loss: 0.365630
Average total loss: 1.045511
tensor(0.0028, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-7.5562e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.677659
Average KL loss: 0.366521
Average total loss: 1.044180
tensor(0.0030, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-3.0030e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.678151
Average KL loss: 0.366780
Average total loss: 1.044931
tensor(0.0030, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-3.2304e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.677025
Average KL loss: 0.369388
Average total loss: 1.046412
tensor(0.0072, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(1.0051e-07, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.678823
Average KL loss: 0.367262
Average total loss: 1.046086
tensor(0.0033, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(5.6500e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.677302
Average KL loss: 0.367174
Average total loss: 1.044476
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-1.5621e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.681789
Average KL loss: 0.366870
Average total loss: 1.048658
tensor(0.0031, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(1.6711e-11, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.677116
Average KL loss: 0.368905
Average total loss: 1.046021
tensor(-0.0037, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.7005e-07, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.674435
Average KL loss: 0.366046
Average total loss: 1.040481
tensor(0.0027, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.0120e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.671879
Average KL loss: 0.363574
Average total loss: 1.035453
tensor(0.0031, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(1.6145e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.672429
Average KL loss: 0.362294
Average total loss: 1.034723
tensor(0.0031, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-2.3130e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.671334
Average KL loss: 0.361322
Average total loss: 1.032656
tensor(0.0031, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-2.3197e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.670969
Average KL loss: 0.360481
Average total loss: 1.031450
tensor(0.0031, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-3.1028e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.670405
Average KL loss: 0.359740
Average total loss: 1.030145
tensor(0.0031, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(1.7538e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.668230
Average KL loss: 0.358973
Average total loss: 1.027203
tensor(0.0031, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-1.5576e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.666436
Average KL loss: 0.358273
Average total loss: 1.024709
tensor(0.0031, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(1.5888e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.670904
Average KL loss: 0.357696
Average total loss: 1.028600
tensor(0.0031, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(8.6404e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.668730
Average KL loss: 0.357175
Average total loss: 1.025905
tensor(0.0031, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-1.6547e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.669407
Average KL loss: 0.356741
Average total loss: 1.026148
tensor(0.0031, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-1.3948e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.668530
Average KL loss: 0.356361
Average total loss: 1.024890
tensor(0.0031, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(1.2348e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.664966
Average KL loss: 0.356034
Average total loss: 1.020999
tensor(0.0031, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(9.5109e-11, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.668710
Average KL loss: 0.355630
Average total loss: 1.024340
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(8.5064e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.668441
Average KL loss: 0.355330
Average total loss: 1.023772
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-5.1261e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.672672
Average KL loss: 0.355108
Average total loss: 1.027780
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-1.0496e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.669492
Average KL loss: 0.354811
Average total loss: 1.024303
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(6.3154e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.670768
Average KL loss: 0.354515
Average total loss: 1.025284
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-4.5547e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.672595
Average KL loss: 0.354194
Average total loss: 1.026789
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(5.2669e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.669193
Average KL loss: 0.353824
Average total loss: 1.023017
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-1.9037e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.665004
Average KL loss: 0.353511
Average total loss: 1.018515
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-1.3589e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.667363
Average KL loss: 0.353228
Average total loss: 1.020592
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-9.3118e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.667158
Average KL loss: 0.353030
Average total loss: 1.020188
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(8.2464e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.668886
Average KL loss: 0.352767
Average total loss: 1.021653
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(1.0781e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.673859
Average KL loss: 0.352463
Average total loss: 1.026322
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-5.4793e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.668801
Average KL loss: 0.352313
Average total loss: 1.021113
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(1.6565e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.670073
Average KL loss: 0.352046
Average total loss: 1.022119
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-4.1474e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.670300
Average KL loss: 0.351931
Average total loss: 1.022231
tensor(0.0031, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-8.0848e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.668403
Average KL loss: 0.351775
Average total loss: 1.020179
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.8022e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.673125
Average KL loss: 0.351562
Average total loss: 1.024687
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.5921e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.668213
Average KL loss: 0.351445
Average total loss: 1.019658
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.4769e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.667530
Average KL loss: 0.351308
Average total loss: 1.018837
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-5.1567e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.666809
Average KL loss: 0.351155
Average total loss: 1.017964
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.7584e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.673646
Average KL loss: 0.351127
Average total loss: 1.024773
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.8207e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.667810
Average KL loss: 0.351098
Average total loss: 1.018908
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-3.3214e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.666950
Average KL loss: 0.351048
Average total loss: 1.017998
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(4.6919e-11, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.671401
Average KL loss: 0.351002
Average total loss: 1.022403
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-3.4830e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.667745
Average KL loss: 0.350950
Average total loss: 1.018695
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-4.6203e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.669438
Average KL loss: 0.350912
Average total loss: 1.020350
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.7593e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.669473
Average KL loss: 0.350874
Average total loss: 1.020347
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.1330e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.666238
Average KL loss: 0.350844
Average total loss: 1.017082
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(6.3760e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.670181
Average KL loss: 0.350816
Average total loss: 1.020996
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(2.0608e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.668706
Average KL loss: 0.350786
Average total loss: 1.019492
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-7.0058e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.670424
Average KL loss: 0.350749
Average total loss: 1.021173
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(7.0346e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.666623
Average KL loss: 0.350715
Average total loss: 1.017338
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.7100e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.670161
Average KL loss: 0.350682
Average total loss: 1.020844
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(2.8562e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.669132
Average KL loss: 0.350655
Average total loss: 1.019788
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.4689e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.671675
Average KL loss: 0.350625
Average total loss: 1.022300
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(8.8132e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.665913
Average KL loss: 0.350593
Average total loss: 1.016505
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.5325e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.669334
Average KL loss: 0.350557
Average total loss: 1.019892
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.0320e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.669957
Average KL loss: 0.350524
Average total loss: 1.020481
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(2.7871e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.670640
Average KL loss: 0.350494
Average total loss: 1.021134
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.8139e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.669854
Average KL loss: 0.350458
Average total loss: 1.020312
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.3600e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.673536
Average KL loss: 0.350421
Average total loss: 1.023957
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-3.1744e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.665861
Average KL loss: 0.350377
Average total loss: 1.016238
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-5.0465e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.671308
Average KL loss: 0.350337
Average total loss: 1.021645
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.2205e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.671694
Average KL loss: 0.350303
Average total loss: 1.021997
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.0488e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.668460
Average KL loss: 0.350274
Average total loss: 1.018734
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(7.7428e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.669807
Average KL loss: 0.350234
Average total loss: 1.020040
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.6425e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.669037
Average KL loss: 0.350212
Average total loss: 1.019249
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.4520e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.668307
Average KL loss: 0.350181
Average total loss: 1.018489
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-8.1370e-12, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.669859
Average KL loss: 0.350152
Average total loss: 1.020012
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-4.5395e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.666599
Average KL loss: 0.350119
Average total loss: 1.016718
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-4.1491e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.663453
Average KL loss: 0.350083
Average total loss: 1.013535
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(9.9235e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.665340
Average KL loss: 0.350048
Average total loss: 1.015388
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(6.7211e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.669328
Average KL loss: 0.350022
Average total loss: 1.019350
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.1217e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.667350
Average KL loss: 0.349998
Average total loss: 1.017348
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-7.0358e-12, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.667251
Average KL loss: 0.349965
Average total loss: 1.017216
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(6.8753e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.667117
Average KL loss: 0.349939
Average total loss: 1.017055
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.2994e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.669433
Average KL loss: 0.349910
Average total loss: 1.019343
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.9326e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.670935
Average KL loss: 0.349886
Average total loss: 1.020822
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(8.6928e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.668454
Average KL loss: 0.349858
Average total loss: 1.018312
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-3.3324e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.670835
Average KL loss: 0.349835
Average total loss: 1.020671
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.3015e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.669595
Average KL loss: 0.349808
Average total loss: 1.019403
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.4182e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.668346
Average KL loss: 0.349772
Average total loss: 1.018118
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(9.9814e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.670009
Average KL loss: 0.349751
Average total loss: 1.019760
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.1120e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.663536
Average KL loss: 0.349748
Average total loss: 1.013284
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.1337e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.669683
Average KL loss: 0.349746
Average total loss: 1.019429
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-5.7530e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.669317
Average KL loss: 0.349743
Average total loss: 1.019060
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.2859e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.667258
Average KL loss: 0.349740
Average total loss: 1.016999
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-3.9360e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.670898
Average KL loss: 0.349738
Average total loss: 1.020636
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.0370e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.672539
Average KL loss: 0.349735
Average total loss: 1.022275
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.5398e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.670602
Average KL loss: 0.349733
Average total loss: 1.020334
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.7894e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.664860
Average KL loss: 0.349730
Average total loss: 1.014590
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.3426e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.669594
Average KL loss: 0.349727
Average total loss: 1.019321
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.2621e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.667951
Average KL loss: 0.349725
Average total loss: 1.017675
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(2.5350e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.669261
Average KL loss: 0.349720
Average total loss: 1.018982
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.1865e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.667580
Average KL loss: 0.349717
Average total loss: 1.017296
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-5.5563e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.667105
Average KL loss: 0.349714
Average total loss: 1.016819
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(1.7079e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.666516
Average KL loss: 0.349714
Average total loss: 1.016230
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(2.4429e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.668161
Average KL loss: 0.349714
Average total loss: 1.017875
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-9.5575e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.666225
Average KL loss: 0.349713
Average total loss: 1.015938
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-8.0098e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.668398
Average KL loss: 0.349713
Average total loss: 1.018111
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.1697e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.668578
Average KL loss: 0.349713
Average total loss: 1.018290
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.2876e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.669874
Average KL loss: 0.349712
Average total loss: 1.019587
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(2.5765e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.666853
Average KL loss: 0.349712
Average total loss: 1.016565
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.3399e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.667248
Average KL loss: 0.349712
Average total loss: 1.016959
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(9.5211e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.664860
Average KL loss: 0.349711
Average total loss: 1.014571
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(6.6746e-10, device='cuda:0')
 Percentile value: 8.120253625065743e-08
Non-zero model percentage: 3.5184483528137207%, Non-zero mask percentage: 3.5184483528137207%

--- Pruning Level [15/24]: ---
conv1.weight         | nonzeros =      61 /    1728             (  3.53%) | total_pruned =    1667 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      18 /   36864             (  0.05%) | total_pruned =   36846 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      12 /   36864             (  0.03%) | total_pruned =   36852 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      34 /   36864             (  0.09%) | total_pruned =   36830 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      84 /   36864             (  0.23%) | total_pruned =   36780 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     233 /   73728             (  0.32%) | total_pruned =   73495 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     400 /  147456             (  0.27%) | total_pruned =  147056 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      32 /    8192             (  0.39%) | total_pruned =    8160 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     463 /  147456             (  0.31%) | total_pruned =  146993 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     546 /  147456             (  0.37%) | total_pruned =  146910 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1144 /  294912             (  0.39%) | total_pruned =  293768 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     155 /     256             ( 60.55%) | total_pruned =     101 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1575 /  589824             (  0.27%) | total_pruned =  588249 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     140 /     256             ( 54.69%) | total_pruned =     116 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      78 /   32768             (  0.24%) | total_pruned =   32690 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     844 /  589824             (  0.14%) | total_pruned =  588980 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      93 /     256             ( 36.33%) | total_pruned =     163 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     547 /  589824             (  0.09%) | total_pruned =  589277 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      69 /     256             ( 26.95%) | total_pruned =     187 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    1155 / 1179648             (  0.10%) | total_pruned = 1178493 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     203 /     512             ( 39.65%) | total_pruned =     309 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1295 / 2359296             (  0.05%) | total_pruned = 2358001 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     102 /     512             ( 19.92%) | total_pruned =     410 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      47 /  131072             (  0.04%) | total_pruned =  131025 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     769 / 2359296             (  0.03%) | total_pruned = 2358527 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      67 /     512             ( 13.09%) | total_pruned =     445 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  380790 / 2359296             ( 16.14%) | total_pruned = 1978506 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     229 /     512             ( 44.73%) | total_pruned =     283 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     140 /     512             ( 27.34%) | total_pruned =     372 | shape = torch.Size([512])
linear.weight        | nonzeros =    1374 /    5120             ( 26.84%) | total_pruned =    3746 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 393319, pruned : 10785443, total: 11178762, Compression rate :      28.42x  ( 96.48% pruned)
Train Epoch: 99/100 Loss: 0.866445 Accuracy: 71.77 79.24 % Best test Accuracy: 71.97%
tensor(0.0031, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.4697e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.144141
Average KL loss: 0.309938
Average total loss: 1.454079
tensor(-0.0014, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-9.2699e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.307104
Average KL loss: 0.218211
Average total loss: 1.525315
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-5.1096e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.187569
Average KL loss: 0.216396
Average total loss: 1.403964
tensor(0.0012, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.4093e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.147473
Average KL loss: 0.219737
Average total loss: 1.367210
tensor(0.0012, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.3246e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.031455
Average KL loss: 0.222435
Average total loss: 1.253890
tensor(0.0013, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.3667e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.008198
Average KL loss: 0.224214
Average total loss: 1.232412
tensor(0.0013, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-8.4670e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.995544
Average KL loss: 0.227615
Average total loss: 1.223159
tensor(0.0013, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.0693e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.966613
Average KL loss: 0.230333
Average total loss: 1.196946
tensor(0.0014, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-6.9341e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.953433
Average KL loss: 0.232508
Average total loss: 1.185941
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-9.6460e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.947780
Average KL loss: 0.235659
Average total loss: 1.183439
tensor(0.0014, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.8128e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.918018
Average KL loss: 0.237611
Average total loss: 1.155629
tensor(0.0014, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.1654e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.896412
Average KL loss: 0.239831
Average total loss: 1.136243
tensor(0.0015, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(3.7255e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.884764
Average KL loss: 0.241825
Average total loss: 1.126589
tensor(0.0015, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.0917e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.877972
Average KL loss: 0.244297
Average total loss: 1.122270
tensor(0.0015, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.1761e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.871359
Average KL loss: 0.247181
Average total loss: 1.118540
tensor(0.0016, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.2794e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.858058
Average KL loss: 0.250937
Average total loss: 1.108995
tensor(-0.0071, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.2361e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.859362
Average KL loss: 0.252303
Average total loss: 1.111665
tensor(0.0024, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.6563e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.853868
Average KL loss: 0.252556
Average total loss: 1.106423
tensor(0.0016, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.1930e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.853147
Average KL loss: 0.255057
Average total loss: 1.108204
tensor(0.0017, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.6609e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.833793
Average KL loss: 0.256750
Average total loss: 1.090543
tensor(0.0016, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.4985e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.839832
Average KL loss: 0.260913
Average total loss: 1.100745
tensor(0.0032, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.3964e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.834836
Average KL loss: 0.260009
Average total loss: 1.094845
tensor(0.0018, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.4877e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.825539
Average KL loss: 0.262316
Average total loss: 1.087855
tensor(0.0018, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.1931e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.822348
Average KL loss: 0.264193
Average total loss: 1.086541
tensor(0.0018, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(8.0420e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.829360
Average KL loss: 0.267765
Average total loss: 1.097125
tensor(-0.0034, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.3259e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.816456
Average KL loss: 0.266996
Average total loss: 1.083453
tensor(0.0022, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(9.0699e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.820268
Average KL loss: 0.267756
Average total loss: 1.088024
tensor(0.0019, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-3.6552e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.808948
Average KL loss: 0.268870
Average total loss: 1.077818
tensor(0.0019, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-2.0739e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.806299
Average KL loss: 0.270547
Average total loss: 1.076845
tensor(0.0004, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-4.8617e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.803080
Average KL loss: 0.275587
Average total loss: 1.078667
tensor(0.0021, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(2.7408e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.805224
Average KL loss: 0.272785
Average total loss: 1.078009
tensor(0.0020, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-9.1784e-11, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.793644
Average KL loss: 0.274218
Average total loss: 1.067862
tensor(0.0020, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.3901e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.797773
Average KL loss: 0.275582
Average total loss: 1.073355
tensor(0.0020, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.2842e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.792937
Average KL loss: 0.276407
Average total loss: 1.069344
tensor(0.0020, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-3.3982e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.797744
Average KL loss: 0.280884
Average total loss: 1.078629
tensor(-0.0019, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-9.8983e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.792575
Average KL loss: 0.280099
Average total loss: 1.072674
tensor(0.0025, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(3.7980e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.798307
Average KL loss: 0.281419
Average total loss: 1.079726
tensor(0.0021, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.9020e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.785355
Average KL loss: 0.282419
Average total loss: 1.067774
tensor(0.0021, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(1.6613e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.790024
Average KL loss: 0.283231
Average total loss: 1.073256
tensor(0.0015, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.2466e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.787304
Average KL loss: 0.287570
Average total loss: 1.074874
tensor(0.0016, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.4246e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.783345
Average KL loss: 0.285030
Average total loss: 1.068376
tensor(0.0023, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.1775e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.790730
Average KL loss: 0.286109
Average total loss: 1.076839
tensor(0.0021, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.6856e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.776741
Average KL loss: 0.287017
Average total loss: 1.063758
tensor(0.0022, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-3.3961e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.778462
Average KL loss: 0.289438
Average total loss: 1.067900
tensor(0.0119, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(2.4357e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.777788
Average KL loss: 0.292735
Average total loss: 1.070523
tensor(0.0031, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(2.4264e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.773250
Average KL loss: 0.290558
Average total loss: 1.063808
tensor(0.0022, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.4787e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.774625
Average KL loss: 0.291134
Average total loss: 1.065759
tensor(0.0022, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.0974e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.770304
Average KL loss: 0.291997
Average total loss: 1.062301
tensor(0.0028, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(9.3253e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.771650
Average KL loss: 0.295061
Average total loss: 1.066711
tensor(0.0025, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(5.4829e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.767610
Average KL loss: 0.293265
Average total loss: 1.060875
tensor(0.0021, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-8.2642e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.770400
Average KL loss: 0.294792
Average total loss: 1.065192
tensor(0.0023, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-3.9485e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.766258
Average KL loss: 0.295419
Average total loss: 1.061676
tensor(0.0022, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-3.1306e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.763481
Average KL loss: 0.298787
Average total loss: 1.062268
tensor(0.0049, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(6.3930e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.766295
Average KL loss: 0.296684
Average total loss: 1.062979
tensor(0.0025, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(1.5680e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.764399
Average KL loss: 0.297443
Average total loss: 1.061842
tensor(0.0023, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.5707e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.768913
Average KL loss: 0.297658
Average total loss: 1.066570
tensor(0.0023, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-8.4337e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.762437
Average KL loss: 0.298379
Average total loss: 1.060816
tensor(0.0085, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.5230e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.766389
Average KL loss: 0.301971
Average total loss: 1.068360
tensor(0.0014, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.4477e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.765781
Average KL loss: 0.299623
Average total loss: 1.065404
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(7.9024e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.758186
Average KL loss: 0.299651
Average total loss: 1.057838
tensor(0.0024, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.4082e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.758030
Average KL loss: 0.300493
Average total loss: 1.058523
tensor(0.0033, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(2.0314e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.756848
Average KL loss: 0.304330
Average total loss: 1.061178
tensor(0.0033, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(2.2135e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.757499
Average KL loss: 0.300889
Average total loss: 1.058389
tensor(0.0025, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(7.6999e-11, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.758108
Average KL loss: 0.301872
Average total loss: 1.059980
tensor(0.0024, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-1.9924e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.762799
Average KL loss: 0.302600
Average total loss: 1.065398
tensor(0.0025, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(1.2447e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.756661
Average KL loss: 0.306082
Average total loss: 1.062742
tensor(-0.0047, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-1.7856e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.751071
Average KL loss: 0.305721
Average total loss: 1.056791
tensor(0.0022, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-7.7700e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.750048
Average KL loss: 0.305298
Average total loss: 1.055346
tensor(0.0025, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-1.6789e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.751847
Average KL loss: 0.305145
Average total loss: 1.056992
tensor(0.0025, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-2.2002e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.753301
Average KL loss: 0.304765
Average total loss: 1.058066
tensor(0.0033, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(1.7570e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.752764
Average KL loss: 0.307683
Average total loss: 1.060447
tensor(0.0042, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(4.2236e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.752067
Average KL loss: 0.305424
Average total loss: 1.057491
tensor(0.0025, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-1.0833e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.751026
Average KL loss: 0.305861
Average total loss: 1.056888
tensor(0.0025, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.7888e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.752052
Average KL loss: 0.306507
Average total loss: 1.058559
tensor(0.0025, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-3.7835e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.755800
Average KL loss: 0.309349
Average total loss: 1.065149
tensor(0.0030, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.3126e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.750604
Average KL loss: 0.308138
Average total loss: 1.058743
tensor(0.0033, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(1.8597e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.749199
Average KL loss: 0.307279
Average total loss: 1.056478
tensor(0.0026, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.0340e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.747368
Average KL loss: 0.307099
Average total loss: 1.054467
tensor(0.0026, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(1.3887e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.746443
Average KL loss: 0.308151
Average total loss: 1.054594
tensor(0.0026, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.4879e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.744568
Average KL loss: 0.309108
Average total loss: 1.053676
tensor(0.0017, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-2.4284e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.745930
Average KL loss: 0.313475
Average total loss: 1.059406
tensor(0.0014, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-3.1496e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.745245
Average KL loss: 0.310423
Average total loss: 1.055668
tensor(0.0028, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-2.8540e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.744093
Average KL loss: 0.310340
Average total loss: 1.054433
tensor(0.0026, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-8.2321e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.746819
Average KL loss: 0.310155
Average total loss: 1.056974
tensor(0.0024, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-6.6618e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.742642
Average KL loss: 0.314089
Average total loss: 1.056731
tensor(0.0028, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(2.6175e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.743068
Average KL loss: 0.311256
Average total loss: 1.054323
tensor(0.0024, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-5.8963e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.746264
Average KL loss: 0.311257
Average total loss: 1.057521
tensor(0.0026, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-1.3059e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.743827
Average KL loss: 0.312138
Average total loss: 1.055965
tensor(0.0026, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-6.1917e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.744285
Average KL loss: 0.314411
Average total loss: 1.058696
tensor(0.0068, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(1.0409e-07, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.743396
Average KL loss: 0.311951
Average total loss: 1.055347
tensor(0.0030, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(5.5375e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.741285
Average KL loss: 0.311872
Average total loss: 1.053157
tensor(0.0027, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(1.7105e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.744946
Average KL loss: 0.312390
Average total loss: 1.057336
tensor(0.0027, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.4806e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.742366
Average KL loss: 0.315494
Average total loss: 1.057860
tensor(-0.0041, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-1.7309e-07, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.740387
Average KL loss: 0.313980
Average total loss: 1.054367
tensor(0.0022, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-1.1557e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.742062
Average KL loss: 0.312424
Average total loss: 1.054486
tensor(0.0027, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(1.7195e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.745736
Average KL loss: 0.312339
Average total loss: 1.058074
tensor(0.0027, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-1.6926e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.743805
Average KL loss: 0.312813
Average total loss: 1.056619
tensor(0.0030, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(3.6813e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.742538
Average KL loss: 0.315912
Average total loss: 1.058450
tensor(0.0003, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-6.1189e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.742169
Average KL loss: 0.313121
Average total loss: 1.055290
tensor(0.0026, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-5.2403e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.743260
Average KL loss: 0.313414
Average total loss: 1.056674
tensor(0.0027, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-1.9627e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.739209
Average KL loss: 0.313854
Average total loss: 1.053063
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-4.6897e-11, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.740442
Average KL loss: 0.316374
Average total loss: 1.056816
tensor(-0.0052, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-1.9882e-07, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.738562
Average KL loss: 0.314872
Average total loss: 1.053434
tensor(0.0024, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.0749e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.736312
Average KL loss: 0.312678
Average total loss: 1.048990
tensor(0.0028, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(2.5397e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.738953
Average KL loss: 0.311818
Average total loss: 1.050771
tensor(0.0028, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-2.7207e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.737366
Average KL loss: 0.311219
Average total loss: 1.048585
tensor(0.0028, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.4764e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.737252
Average KL loss: 0.310696
Average total loss: 1.047948
tensor(0.0028, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.0373e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.741736
Average KL loss: 0.310203
Average total loss: 1.051939
tensor(0.0028, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(5.3227e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.735784
Average KL loss: 0.309734
Average total loss: 1.045518
tensor(0.0028, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.4459e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.735236
Average KL loss: 0.309400
Average total loss: 1.044636
tensor(0.0028, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(1.0740e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.734184
Average KL loss: 0.309077
Average total loss: 1.043261
tensor(0.0028, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(6.1165e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.734052
Average KL loss: 0.308689
Average total loss: 1.042741
tensor(0.0028, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-2.1322e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.735057
Average KL loss: 0.308432
Average total loss: 1.043488
tensor(0.0028, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(2.4133e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.734315
Average KL loss: 0.308137
Average total loss: 1.042453
tensor(0.0028, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(9.0528e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.735089
Average KL loss: 0.307841
Average total loss: 1.042930
tensor(0.0028, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-2.1394e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.736804
Average KL loss: 0.307685
Average total loss: 1.044489
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(1.8674e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.736304
Average KL loss: 0.307414
Average total loss: 1.043718
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(6.6779e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.731555
Average KL loss: 0.307225
Average total loss: 1.038780
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-1.6705e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.732313
Average KL loss: 0.307006
Average total loss: 1.039318
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(2.0126e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.734802
Average KL loss: 0.306665
Average total loss: 1.041467
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-7.8404e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.732778
Average KL loss: 0.306343
Average total loss: 1.039120
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(1.1584e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.735555
Average KL loss: 0.306041
Average total loss: 1.041596
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(1.3852e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.731978
Average KL loss: 0.305816
Average total loss: 1.037795
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-2.6467e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.734596
Average KL loss: 0.305595
Average total loss: 1.040191
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(6.7793e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.733572
Average KL loss: 0.305442
Average total loss: 1.039014
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-1.5667e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.736868
Average KL loss: 0.305327
Average total loss: 1.042195
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-2.2787e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.734556
Average KL loss: 0.305162
Average total loss: 1.039718
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-7.4305e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.735431
Average KL loss: 0.305072
Average total loss: 1.040503
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-9.7284e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.731779
Average KL loss: 0.304935
Average total loss: 1.036713
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-9.6568e-11, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.732665
Average KL loss: 0.304726
Average total loss: 1.037391
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(7.6180e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.733135
Average KL loss: 0.304534
Average total loss: 1.037669
tensor(0.0028, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(2.9532e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.730668
Average KL loss: 0.304323
Average total loss: 1.034992
tensor(0.0028, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-7.8753e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.735210
Average KL loss: 0.304164
Average total loss: 1.039374
tensor(0.0028, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-5.6940e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.737743
Average KL loss: 0.303968
Average total loss: 1.041711
tensor(0.0028, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(4.1006e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.732880
Average KL loss: 0.303787
Average total loss: 1.036667
tensor(0.0028, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(1.1954e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.739323
Average KL loss: 0.303649
Average total loss: 1.042971
tensor(0.0028, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-3.5953e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.736452
Average KL loss: 0.303502
Average total loss: 1.039953
tensor(0.0028, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-4.4386e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.733028
Average KL loss: 0.303431
Average total loss: 1.036459
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-3.2556e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.734110
Average KL loss: 0.303268
Average total loss: 1.037378
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-2.4652e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.738373
Average KL loss: 0.303139
Average total loss: 1.041512
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(4.1204e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.734257
Average KL loss: 0.302938
Average total loss: 1.037195
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(2.5840e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.736227
Average KL loss: 0.302787
Average total loss: 1.039014
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(3.8308e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.733656
Average KL loss: 0.302723
Average total loss: 1.036379
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-5.1796e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.737392
Average KL loss: 0.302639
Average total loss: 1.040031
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-2.4478e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.733784
Average KL loss: 0.302598
Average total loss: 1.036382
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.1478e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.732695
Average KL loss: 0.302556
Average total loss: 1.035252
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(7.3773e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.732816
Average KL loss: 0.302525
Average total loss: 1.035340
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.6139e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.738085
Average KL loss: 0.302498
Average total loss: 1.040583
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-5.5226e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.735045
Average KL loss: 0.302474
Average total loss: 1.037519
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.2158e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.734779
Average KL loss: 0.302453
Average total loss: 1.037232
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.0799e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.735473
Average KL loss: 0.302424
Average total loss: 1.037897
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(3.8998e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.736065
Average KL loss: 0.302396
Average total loss: 1.038460
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(2.4320e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.734045
Average KL loss: 0.302371
Average total loss: 1.036416
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.4573e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.735001
Average KL loss: 0.302342
Average total loss: 1.037343
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(6.7587e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.735246
Average KL loss: 0.302320
Average total loss: 1.037566
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(5.9012e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.736004
Average KL loss: 0.302318
Average total loss: 1.038321
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(1.7091e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.737124
Average KL loss: 0.302315
Average total loss: 1.039438
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(1.9485e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.729686
Average KL loss: 0.302313
Average total loss: 1.031999
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-3.2421e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.733138
Average KL loss: 0.302309
Average total loss: 1.035447
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-8.3518e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.737280
Average KL loss: 0.302307
Average total loss: 1.039586
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(2.3578e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.737173
Average KL loss: 0.302305
Average total loss: 1.039478
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-2.5792e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.739721
Average KL loss: 0.302303
Average total loss: 1.042024
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(6.2593e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.735313
Average KL loss: 0.302300
Average total loss: 1.037613
tensor(0.0027, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(2.9443e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.735074
Average KL loss: 0.302297
Average total loss: 1.037371
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(1.5604e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.734612
Average KL loss: 0.302295
Average total loss: 1.036907
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.6513e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.735944
Average KL loss: 0.302293
Average total loss: 1.038237
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(4.3877e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.737185
Average KL loss: 0.302291
Average total loss: 1.039476
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-6.4587e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.737757
Average KL loss: 0.302287
Average total loss: 1.040045
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-2.2989e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.737352
Average KL loss: 0.302286
Average total loss: 1.039638
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.1515e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.734903
Average KL loss: 0.302285
Average total loss: 1.037187
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.1397e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.738675
Average KL loss: 0.302285
Average total loss: 1.040960
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(8.6324e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.733215
Average KL loss: 0.302284
Average total loss: 1.035499
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.6213e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.733790
Average KL loss: 0.302284
Average total loss: 1.036074
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(4.0294e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.734444
Average KL loss: 0.302284
Average total loss: 1.036728
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(8.4356e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.735206
Average KL loss: 0.302283
Average total loss: 1.037489
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.3507e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.736150
Average KL loss: 0.302283
Average total loss: 1.038433
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(1.0172e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.733615
Average KL loss: 0.302283
Average total loss: 1.035898
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.0736e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.732925
Average KL loss: 0.302283
Average total loss: 1.035208
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(5.6614e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.737580
Average KL loss: 0.302282
Average total loss: 1.039863
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(2.2458e-10, device='cuda:0')
 Percentile value: 8.132263928928296e-08
Non-zero model percentage: 2.8147659301757812%, Non-zero mask percentage: 2.8147659301757812%

--- Pruning Level [16/24]: ---
conv1.weight         | nonzeros =      59 /    1728             (  3.41%) | total_pruned =    1669 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      12 /   36864             (  0.03%) | total_pruned =   36852 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       7 /   36864             (  0.02%) | total_pruned =   36857 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      24 /   36864             (  0.07%) | total_pruned =   36840 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      57 /   36864             (  0.15%) | total_pruned =   36807 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     191 /   73728             (  0.26%) | total_pruned =   73537 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     327 /  147456             (  0.22%) | total_pruned =  147129 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      30 /    8192             (  0.37%) | total_pruned =    8162 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     381 /  147456             (  0.26%) | total_pruned =  147075 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     455 /  147456             (  0.31%) | total_pruned =  147001 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     945 /  294912             (  0.32%) | total_pruned =  293967 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     143 /     256             ( 55.86%) | total_pruned =     113 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1253 /  589824             (  0.21%) | total_pruned =  588571 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     128 /     256             ( 50.00%) | total_pruned =     128 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      50 /   32768             (  0.15%) | total_pruned =   32718 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     647 /  589824             (  0.11%) | total_pruned =  589177 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     417 /  589824             (  0.07%) | total_pruned =  589407 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      59 /     256             ( 23.05%) | total_pruned =     197 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     841 / 1179648             (  0.07%) | total_pruned = 1178807 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     166 /     512             ( 32.42%) | total_pruned =     346 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     978 / 2359296             (  0.04%) | total_pruned = 2358318 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      93 /     512             ( 18.16%) | total_pruned =     419 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      37 /  131072             (  0.03%) | total_pruned =  131035 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     620 / 2359296             (  0.03%) | total_pruned = 2358676 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  304368 / 2359296             ( 12.90%) | total_pruned = 2054928 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     218 /     512             ( 42.58%) | total_pruned =     294 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     135 /     512             ( 26.37%) | total_pruned =     377 | shape = torch.Size([512])
linear.weight        | nonzeros =    1301 /    5120             ( 25.41%) | total_pruned =    3819 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 314656, pruned : 10864106, total: 11178762, Compression rate :      35.53x  ( 97.19% pruned)
Train Epoch: 99/100 Loss: 0.576314 Accuracy: 70.47 77.61 % Best test Accuracy: 70.88%
tensor(0.0027, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-8.7347e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.014980
Average KL loss: 0.277826
Average total loss: 1.292806
tensor(-0.0015, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-8.3813e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.376955
Average KL loss: 0.202438
Average total loss: 1.579392
tensor(0.0009, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.9223e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.235013
Average KL loss: 0.201235
Average total loss: 1.436248
tensor(0.0012, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.8408e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.117073
Average KL loss: 0.204108
Average total loss: 1.321181
tensor(0.0012, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-5.0002e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.082713
Average KL loss: 0.206335
Average total loss: 1.289048
tensor(0.0012, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-8.0283e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.026489
Average KL loss: 0.210221
Average total loss: 1.236710
tensor(0.0012, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-8.8475e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.974760
Average KL loss: 0.213611
Average total loss: 1.188371
tensor(0.0013, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.6770e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.970849
Average KL loss: 0.216540
Average total loss: 1.187388
tensor(0.0013, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-8.0172e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.938617
Average KL loss: 0.219254
Average total loss: 1.157872
tensor(0.0013, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-4.9110e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.929806
Average KL loss: 0.221162
Average total loss: 1.150968
tensor(0.0014, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.7232e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.917691
Average KL loss: 0.223356
Average total loss: 1.141048
tensor(0.0014, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-6.4541e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.906709
Average KL loss: 0.226565
Average total loss: 1.133274
tensor(0.0014, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.5962e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.891102
Average KL loss: 0.229297
Average total loss: 1.120398
tensor(0.0015, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.5215e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.901967
Average KL loss: 0.231443
Average total loss: 1.133410
tensor(0.0015, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.1374e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.875243
Average KL loss: 0.233879
Average total loss: 1.109123
tensor(0.0015, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.8257e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.869767
Average KL loss: 0.236893
Average total loss: 1.106659
tensor(-0.0071, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.2146e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.858522
Average KL loss: 0.239285
Average total loss: 1.097807
tensor(0.0023, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.4087e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.855602
Average KL loss: 0.239897
Average total loss: 1.095498
tensor(0.0015, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.0037e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.845918
Average KL loss: 0.241381
Average total loss: 1.087299
tensor(0.0016, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.5930e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.844702
Average KL loss: 0.242868
Average total loss: 1.087570
tensor(0.0016, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-7.5264e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.846055
Average KL loss: 0.247433
Average total loss: 1.093487
tensor(0.0032, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.1766e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.832704
Average KL loss: 0.246017
Average total loss: 1.078721
tensor(0.0017, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.4968e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.834357
Average KL loss: 0.247124
Average total loss: 1.081481
tensor(0.0017, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.3052e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.837008
Average KL loss: 0.248701
Average total loss: 1.085709
tensor(0.0018, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.2476e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.828655
Average KL loss: 0.252786
Average total loss: 1.081441
tensor(-0.0034, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.3396e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.822720
Average KL loss: 0.251611
Average total loss: 1.074331
tensor(0.0021, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(5.6031e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.818343
Average KL loss: 0.253143
Average total loss: 1.071486
tensor(0.0018, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-3.4476e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.811714
Average KL loss: 0.254468
Average total loss: 1.066183
tensor(0.0018, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-3.8602e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.811794
Average KL loss: 0.255193
Average total loss: 1.066987
tensor(0.0003, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-3.8197e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.809360
Average KL loss: 0.261466
Average total loss: 1.070825
tensor(0.0020, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(1.1715e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.804036
Average KL loss: 0.257619
Average total loss: 1.061654
tensor(0.0019, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.0488e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.803763
Average KL loss: 0.258270
Average total loss: 1.062034
tensor(0.0019, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.2615e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.799280
Average KL loss: 0.259501
Average total loss: 1.058781
tensor(0.0019, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.1756e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.807223
Average KL loss: 0.260952
Average total loss: 1.068175
tensor(0.0019, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(7.1465e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.805386
Average KL loss: 0.265197
Average total loss: 1.070584
tensor(-0.0019, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-9.9973e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.802887
Average KL loss: 0.263924
Average total loss: 1.066811
tensor(0.0024, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(1.1004e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.800428
Average KL loss: 0.263294
Average total loss: 1.063722
tensor(0.0020, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-8.9259e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.798833
Average KL loss: 0.264194
Average total loss: 1.063027
tensor(0.0020, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.3714e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.792873
Average KL loss: 0.265056
Average total loss: 1.057929
tensor(0.0015, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.4543e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.790918
Average KL loss: 0.268646
Average total loss: 1.059564
tensor(0.0015, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.5714e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.790184
Average KL loss: 0.265763
Average total loss: 1.055947
tensor(0.0022, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(4.7380e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.787395
Average KL loss: 0.266872
Average total loss: 1.054267
tensor(0.0020, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.7156e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.788742
Average KL loss: 0.268234
Average total loss: 1.056976
tensor(0.0021, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.1712e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.793918
Average KL loss: 0.269649
Average total loss: 1.063567
tensor(0.0118, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.4196e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.783303
Average KL loss: 0.272551
Average total loss: 1.055854
tensor(0.0030, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(2.2711e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.785867
Average KL loss: 0.270644
Average total loss: 1.056511
tensor(0.0021, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.9203e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.782743
Average KL loss: 0.271768
Average total loss: 1.054510
tensor(0.0021, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.6951e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.778679
Average KL loss: 0.272573
Average total loss: 1.051252
tensor(0.0027, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(1.5713e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.789371
Average KL loss: 0.276293
Average total loss: 1.065663
tensor(0.0025, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(7.6208e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.775638
Average KL loss: 0.273481
Average total loss: 1.049119
tensor(0.0020, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.7278e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.780872
Average KL loss: 0.273116
Average total loss: 1.053988
tensor(0.0022, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-7.2007e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.782440
Average KL loss: 0.273916
Average total loss: 1.056356
tensor(0.0021, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-5.0574e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.777746
Average KL loss: 0.278332
Average total loss: 1.056078
tensor(0.0048, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(6.5018e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.777851
Average KL loss: 0.275679
Average total loss: 1.053531
tensor(0.0024, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(2.1297e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.775504
Average KL loss: 0.275632
Average total loss: 1.051136
tensor(0.0022, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-5.3540e-11, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.773643
Average KL loss: 0.276298
Average total loss: 1.049942
tensor(0.0022, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.4667e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.776061
Average KL loss: 0.277100
Average total loss: 1.053161
tensor(0.0084, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.5105e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.773679
Average KL loss: 0.280143
Average total loss: 1.053822
tensor(0.0013, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.4000e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.773135
Average KL loss: 0.277888
Average total loss: 1.051023
tensor(0.0024, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(2.5309e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.768034
Average KL loss: 0.277767
Average total loss: 1.045801
tensor(0.0023, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-7.3356e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.772402
Average KL loss: 0.277981
Average total loss: 1.050383
tensor(0.0032, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(2.2268e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.772062
Average KL loss: 0.281799
Average total loss: 1.053861
tensor(0.0032, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(2.1032e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.769130
Average KL loss: 0.278579
Average total loss: 1.047709
tensor(0.0023, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(1.1557e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.769562
Average KL loss: 0.278283
Average total loss: 1.047845
tensor(0.0023, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-2.5238e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.781681
Average KL loss: 0.278505
Average total loss: 1.060186
tensor(0.0023, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(4.0401e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.770969
Average KL loss: 0.281064
Average total loss: 1.052033
tensor(-0.0048, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.7970e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.766850
Average KL loss: 0.280993
Average total loss: 1.047844
tensor(0.0021, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-8.8197e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.764535
Average KL loss: 0.280806
Average total loss: 1.045342
tensor(0.0024, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(2.0102e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.767502
Average KL loss: 0.281401
Average total loss: 1.048903
tensor(0.0024, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-9.2714e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.764003
Average KL loss: 0.281660
Average total loss: 1.045663
tensor(0.0031, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(1.9412e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.765355
Average KL loss: 0.284577
Average total loss: 1.049933
tensor(0.0041, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(4.3605e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.768377
Average KL loss: 0.281489
Average total loss: 1.049866
tensor(0.0024, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(9.9394e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.765224
Average KL loss: 0.282220
Average total loss: 1.047444
tensor(0.0024, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-1.3654e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.764782
Average KL loss: 0.282543
Average total loss: 1.047325
tensor(0.0024, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-1.9861e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.769844
Average KL loss: 0.286124
Average total loss: 1.055968
tensor(0.0029, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(6.7580e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.761774
Average KL loss: 0.285086
Average total loss: 1.046861
tensor(0.0032, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(1.9480e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.762441
Average KL loss: 0.283761
Average total loss: 1.046202
tensor(0.0024, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-7.1635e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.763397
Average KL loss: 0.283737
Average total loss: 1.047134
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.1261e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.762364
Average KL loss: 0.283547
Average total loss: 1.045911
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(7.1738e-11, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.761765
Average KL loss: 0.283063
Average total loss: 1.044828
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(3.9921e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.761288
Average KL loss: 0.282218
Average total loss: 1.043506
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-3.7514e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.760057
Average KL loss: 0.281523
Average total loss: 1.041580
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.7111e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.759918
Average KL loss: 0.280958
Average total loss: 1.040875
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.6607e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.768728
Average KL loss: 0.280517
Average total loss: 1.049245
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-2.3305e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.758922
Average KL loss: 0.280120
Average total loss: 1.039042
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.0331e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.756509
Average KL loss: 0.279746
Average total loss: 1.036256
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(2.1288e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.759448
Average KL loss: 0.279455
Average total loss: 1.038902
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.0087e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.758999
Average KL loss: 0.279212
Average total loss: 1.038210
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.5853e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.758609
Average KL loss: 0.278917
Average total loss: 1.037526
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-5.8539e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.760957
Average KL loss: 0.278695
Average total loss: 1.039652
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.5579e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.759489
Average KL loss: 0.278513
Average total loss: 1.038002
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(2.0817e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.764789
Average KL loss: 0.278266
Average total loss: 1.043055
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-8.3633e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.757819
Average KL loss: 0.278082
Average total loss: 1.035902
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-9.5809e-11, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.758047
Average KL loss: 0.277907
Average total loss: 1.035954
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-4.7678e-11, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.757743
Average KL loss: 0.277805
Average total loss: 1.035548
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-9.3375e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.759704
Average KL loss: 0.277615
Average total loss: 1.037319
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.2018e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.756977
Average KL loss: 0.277423
Average total loss: 1.034400
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.1311e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.756716
Average KL loss: 0.277231
Average total loss: 1.033947
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.0920e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.752854
Average KL loss: 0.277060
Average total loss: 1.029914
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.0641e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.757233
Average KL loss: 0.276854
Average total loss: 1.034087
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(7.2950e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.759264
Average KL loss: 0.276680
Average total loss: 1.035944
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-9.7476e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.759364
Average KL loss: 0.276541
Average total loss: 1.035904
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(3.7481e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.757256
Average KL loss: 0.276407
Average total loss: 1.033664
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-3.5358e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.758114
Average KL loss: 0.276386
Average total loss: 1.034501
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.8768e-11, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.757361
Average KL loss: 0.276290
Average total loss: 1.033650
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(9.1017e-11, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.758549
Average KL loss: 0.276169
Average total loss: 1.034718
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(6.8546e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.764119
Average KL loss: 0.276081
Average total loss: 1.040200
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-3.7074e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.759766
Average KL loss: 0.275916
Average total loss: 1.035682
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-7.1371e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.761193
Average KL loss: 0.275747
Average total loss: 1.036940
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(2.0646e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.754692
Average KL loss: 0.275623
Average total loss: 1.030315
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.6040e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.759454
Average KL loss: 0.275573
Average total loss: 1.035026
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-2.8860e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.757939
Average KL loss: 0.275546
Average total loss: 1.033485
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.3542e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.757001
Average KL loss: 0.275529
Average total loss: 1.032530
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.3340e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.761323
Average KL loss: 0.275508
Average total loss: 1.036831
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(3.0603e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.758779
Average KL loss: 0.275489
Average total loss: 1.034268
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-2.3686e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.757987
Average KL loss: 0.275474
Average total loss: 1.033461
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(1.1172e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.765289
Average KL loss: 0.275456
Average total loss: 1.040745
tensor(0.0024, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(3.3348e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.760366
Average KL loss: 0.275440
Average total loss: 1.035806
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-9.5191e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.761266
Average KL loss: 0.275422
Average total loss: 1.036687
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(5.5257e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.762314
Average KL loss: 0.275400
Average total loss: 1.037713
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-4.4524e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.756557
Average KL loss: 0.275378
Average total loss: 1.031935
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.0754e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.760081
Average KL loss: 0.275370
Average total loss: 1.035451
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(2.6850e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.757652
Average KL loss: 0.275368
Average total loss: 1.033021
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.5937e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.756911
Average KL loss: 0.275367
Average total loss: 1.032278
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-9.6559e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.755036
Average KL loss: 0.275365
Average total loss: 1.030401
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(3.0747e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.756241
Average KL loss: 0.275362
Average total loss: 1.031603
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.2447e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.758444
Average KL loss: 0.275361
Average total loss: 1.033805
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.6062e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.757684
Average KL loss: 0.275359
Average total loss: 1.033043
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(6.5487e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.757664
Average KL loss: 0.275357
Average total loss: 1.033021
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(9.7409e-11, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.760117
Average KL loss: 0.275354
Average total loss: 1.035471
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(1.5842e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.759047
Average KL loss: 0.275351
Average total loss: 1.034399
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(7.1294e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.769445
Average KL loss: 0.275349
Average total loss: 1.044794
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.0294e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.756011
Average KL loss: 0.275348
Average total loss: 1.031359
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(6.4105e-11, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.759106
Average KL loss: 0.275348
Average total loss: 1.034453
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(3.8655e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.756452
Average KL loss: 0.275347
Average total loss: 1.031800
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(1.4060e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.756357
Average KL loss: 0.275347
Average total loss: 1.031704
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-3.3884e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.755766
Average KL loss: 0.275347
Average total loss: 1.031113
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(4.6993e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.758707
Average KL loss: 0.275347
Average total loss: 1.034054
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(4.4459e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.757498
Average KL loss: 0.275347
Average total loss: 1.032844
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(1.0802e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.758166
Average KL loss: 0.275346
Average total loss: 1.033513
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(3.2083e-11, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.759509
Average KL loss: 0.275346
Average total loss: 1.034855
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-4.1020e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.755489
Average KL loss: 0.275346
Average total loss: 1.030835
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(6.4783e-10, device='cuda:0')
 Percentile value: 8.165127240999936e-08
Non-zero model percentage: 2.251814603805542%, Non-zero mask percentage: 2.251814603805542%

--- Pruning Level [17/24]: ---
conv1.weight         | nonzeros =      59 /    1728             (  3.41%) | total_pruned =    1669 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       4 /   36864             (  0.01%) | total_pruned =   36860 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       1 /   36864             (  0.00%) | total_pruned =   36863 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      16 /   36864             (  0.04%) | total_pruned =   36848 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      48 /   36864             (  0.13%) | total_pruned =   36816 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     154 /   73728             (  0.21%) | total_pruned =   73574 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     274 /  147456             (  0.19%) | total_pruned =  147182 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      45 /     128             ( 35.16%) | total_pruned =      83 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      24 /    8192             (  0.29%) | total_pruned =    8168 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     321 /  147456             (  0.22%) | total_pruned =  147135 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     373 /  147456             (  0.25%) | total_pruned =  147083 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     780 /  294912             (  0.26%) | total_pruned =  294132 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     134 /     256             ( 52.34%) | total_pruned =     122 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1050 /  589824             (  0.18%) | total_pruned =  588774 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     125 /     256             ( 48.83%) | total_pruned =     131 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      37 /   32768             (  0.11%) | total_pruned =   32731 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     531 /  589824             (  0.09%) | total_pruned =  589293 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     318 /  589824             (  0.05%) | total_pruned =  589506 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      50 /     256             ( 19.53%) | total_pruned =     206 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     667 / 1179648             (  0.06%) | total_pruned = 1178981 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     141 /     512             ( 27.54%) | total_pruned =     371 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     759 / 2359296             (  0.03%) | total_pruned = 2358537 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      83 /     512             ( 16.21%) | total_pruned =     429 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      31 /  131072             (  0.02%) | total_pruned =  131041 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     511 / 2359296             (  0.02%) | total_pruned = 2358785 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      60 /     512             ( 11.72%) | total_pruned =     452 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  242992 / 2359296             ( 10.30%) | total_pruned = 2116304 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     212 /     512             ( 41.41%) | total_pruned =     300 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     127 /     512             ( 24.80%) | total_pruned =     385 | shape = torch.Size([512])
linear.weight        | nonzeros =    1250 /    5120             ( 24.41%) | total_pruned =    3870 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 251725, pruned : 10927037, total: 11178762, Compression rate :      44.41x  ( 97.75% pruned)
Train Epoch: 56/100 Loss: 0.730850 Accuracy: 68.85 73.09 % Best test Accuracy: 69.06%
tensor(0.0024, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.5827e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.089838
Average KL loss: 0.249893
Average total loss: 1.339731
tensor(-0.0017, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-9.0628e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.324713
Average KL loss: 0.178808
Average total loss: 1.503521
tensor(0.0008, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.9223e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.213720
Average KL loss: 0.180478
Average total loss: 1.394198
tensor(0.0011, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.4310e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.118907
Average KL loss: 0.184140
Average total loss: 1.303046
tensor(0.0011, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.3543e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.076997
Average KL loss: 0.186668
Average total loss: 1.263665
tensor(0.0011, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-3.3760e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.037764
Average KL loss: 0.189457
Average total loss: 1.227221
tensor(0.0011, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-6.6658e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.015854
Average KL loss: 0.192314
Average total loss: 1.208168
tensor(0.0012, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-3.7109e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.001820
Average KL loss: 0.194182
Average total loss: 1.196002
tensor(0.0012, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0460e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.982910
Average KL loss: 0.196616
Average total loss: 1.179526
tensor(0.0012, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-4.1398e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.970336
Average KL loss: 0.198875
Average total loss: 1.169211
tensor(0.0012, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-7.8303e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.950077
Average KL loss: 0.200920
Average total loss: 1.150997
tensor(0.0013, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-8.5515e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.951332
Average KL loss: 0.202110
Average total loss: 1.153442
tensor(0.0013, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-2.0202e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.931184
Average KL loss: 0.203900
Average total loss: 1.135084
tensor(0.0013, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.8587e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.926673
Average KL loss: 0.205068
Average total loss: 1.131742
tensor(0.0014, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.9512e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.938302
Average KL loss: 0.206773
Average total loss: 1.145076
tensor(0.0014, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.8456e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.917731
Average KL loss: 0.209602
Average total loss: 1.127333
tensor(-0.0073, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.1794e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.913745
Average KL loss: 0.210097
Average total loss: 1.123842
tensor(0.0022, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(1.8417e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.917560
Average KL loss: 0.209074
Average total loss: 1.126634
tensor(0.0014, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.3736e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.911915
Average KL loss: 0.210512
Average total loss: 1.122427
tensor(0.0015, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.9568e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.906216
Average KL loss: 0.211488
Average total loss: 1.117704
tensor(0.0014, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.0091e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.898493
Average KL loss: 0.215207
Average total loss: 1.113700
tensor(0.0030, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.6352e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.904737
Average KL loss: 0.213428
Average total loss: 1.118164
tensor(0.0015, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(6.0889e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.892205
Average KL loss: 0.213982
Average total loss: 1.106187
tensor(0.0015, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.6948e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.905858
Average KL loss: 0.215451
Average total loss: 1.121309
tensor(0.0016, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.7163e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.894919
Average KL loss: 0.219280
Average total loss: 1.114199
tensor(-0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.3017e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.888142
Average KL loss: 0.218499
Average total loss: 1.106641
tensor(0.0019, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(8.3441e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.878110
Average KL loss: 0.218854
Average total loss: 1.096964
tensor(0.0016, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.4969e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.884904
Average KL loss: 0.219366
Average total loss: 1.104270
tensor(0.0016, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.5306e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.876261
Average KL loss: 0.220705
Average total loss: 1.096966
tensor(9.3489e-05, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.1996e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.890314
Average KL loss: 0.226335
Average total loss: 1.116649
tensor(0.0018, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(2.0150e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.874777
Average KL loss: 0.222984
Average total loss: 1.097762
tensor(0.0017, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(1.6737e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.878854
Average KL loss: 0.223319
Average total loss: 1.102173
tensor(0.0017, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(5.7817e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.874119
Average KL loss: 0.224097
Average total loss: 1.098216
tensor(0.0017, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.6576e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.874414
Average KL loss: 0.225151
Average total loss: 1.099565
tensor(0.0017, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-2.3148e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.870907
Average KL loss: 0.228409
Average total loss: 1.099316
tensor(-0.0022, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-9.7204e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.868837
Average KL loss: 0.226649
Average total loss: 1.095487
tensor(0.0022, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(7.1381e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.871939
Average KL loss: 0.226528
Average total loss: 1.098466
tensor(0.0017, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-4.1068e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.866256
Average KL loss: 0.227184
Average total loss: 1.093440
tensor(0.0017, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(6.1086e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.870723
Average KL loss: 0.227603
Average total loss: 1.098326
tensor(0.0012, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.3816e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.863543
Average KL loss: 0.231270
Average total loss: 1.094814
tensor(0.0012, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.1596e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.865942
Average KL loss: 0.228123
Average total loss: 1.094065
tensor(0.0019, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(3.4365e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.867486
Average KL loss: 0.228567
Average total loss: 1.096054
tensor(0.0018, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-7.6179e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.862081
Average KL loss: 0.229031
Average total loss: 1.091111
tensor(0.0018, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.7615e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.862783
Average KL loss: 0.229596
Average total loss: 1.092379
tensor(0.0116, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(2.4024e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.864364
Average KL loss: 0.231510
Average total loss: 1.095874
tensor(0.0028, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(2.0956e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.865633
Average KL loss: 0.229301
Average total loss: 1.094934
tensor(0.0018, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(8.6141e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.860671
Average KL loss: 0.229569
Average total loss: 1.090240
tensor(0.0018, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-8.7853e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.862440
Average KL loss: 0.230278
Average total loss: 1.092717
tensor(0.0024, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.3348e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.862897
Average KL loss: 0.233992
Average total loss: 1.096889
tensor(0.0022, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(6.1237e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.859925
Average KL loss: 0.231052
Average total loss: 1.090977
tensor(0.0017, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.2749e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.863235
Average KL loss: 0.231194
Average total loss: 1.094429
tensor(0.0019, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-4.3156e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.859327
Average KL loss: 0.231413
Average total loss: 1.090741
tensor(0.0017, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-4.3981e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.856592
Average KL loss: 0.235174
Average total loss: 1.091766
tensor(0.0045, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(6.6006e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.862986
Average KL loss: 0.232258
Average total loss: 1.095244
tensor(0.0020, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.5314e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.859984
Average KL loss: 0.232530
Average total loss: 1.092514
tensor(0.0019, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.9336e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.855118
Average KL loss: 0.232889
Average total loss: 1.088007
tensor(0.0019, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.1630e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.860072
Average KL loss: 0.232747
Average total loss: 1.092820
tensor(0.0080, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(1.5231e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.860288
Average KL loss: 0.235602
Average total loss: 1.095889
tensor(0.0010, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.3805e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.859577
Average KL loss: 0.233094
Average total loss: 1.092672
tensor(0.0020, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(1.1226e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.854952
Average KL loss: 0.233541
Average total loss: 1.088493
tensor(0.0019, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(6.8214e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.853264
Average KL loss: 0.234194
Average total loss: 1.087458
tensor(0.0028, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(2.0334e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.852470
Average KL loss: 0.237426
Average total loss: 1.089897
tensor(0.0028, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(2.0360e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.854650
Average KL loss: 0.234371
Average total loss: 1.089021
tensor(0.0020, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(1.5295e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.860956
Average KL loss: 0.233779
Average total loss: 1.094735
tensor(0.0020, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-5.4972e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.855941
Average KL loss: 0.233946
Average total loss: 1.089887
tensor(0.0020, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(1.4623e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.856314
Average KL loss: 0.236479
Average total loss: 1.092793
tensor(-0.0052, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.7909e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.860691
Average KL loss: 0.236341
Average total loss: 1.097032
tensor(0.0017, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-6.1475e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.853198
Average KL loss: 0.235374
Average total loss: 1.088571
tensor(0.0020, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(3.6181e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.852518
Average KL loss: 0.235641
Average total loss: 1.088159
tensor(0.0020, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.8376e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.854226
Average KL loss: 0.235757
Average total loss: 1.089983
tensor(0.0028, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(1.8735e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.853762
Average KL loss: 0.239589
Average total loss: 1.093351
tensor(0.0037, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(4.2027e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.854166
Average KL loss: 0.237032
Average total loss: 1.091198
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.4647e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.854587
Average KL loss: 0.236875
Average total loss: 1.091463
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(4.1511e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.853924
Average KL loss: 0.236008
Average total loss: 1.089932
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.7368e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.860065
Average KL loss: 0.235375
Average total loss: 1.095440
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(5.9775e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.849250
Average KL loss: 0.234899
Average total loss: 1.084149
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(3.0066e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.847929
Average KL loss: 0.234465
Average total loss: 1.082393
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.9305e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.849180
Average KL loss: 0.234099
Average total loss: 1.083279
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.5840e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.848427
Average KL loss: 0.233811
Average total loss: 1.082238
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.0558e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.857423
Average KL loss: 0.233612
Average total loss: 1.091035
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.7523e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.847552
Average KL loss: 0.233376
Average total loss: 1.080928
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(1.4620e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.850019
Average KL loss: 0.233050
Average total loss: 1.083069
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.1155e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.848842
Average KL loss: 0.232776
Average total loss: 1.081618
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(1.5887e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.848625
Average KL loss: 0.232575
Average total loss: 1.081200
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-4.9253e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.846464
Average KL loss: 0.232338
Average total loss: 1.078802
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(1.0210e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.853620
Average KL loss: 0.232086
Average total loss: 1.085706
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-4.1395e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.852812
Average KL loss: 0.231862
Average total loss: 1.084674
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.1450e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.847654
Average KL loss: 0.231638
Average total loss: 1.079292
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(1.2615e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.849427
Average KL loss: 0.231510
Average total loss: 1.080937
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(1.3277e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.847319
Average KL loss: 0.231374
Average total loss: 1.078693
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-6.7683e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.849375
Average KL loss: 0.231174
Average total loss: 1.080548
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.9001e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.855417
Average KL loss: 0.231055
Average total loss: 1.086472
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(1.9045e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.847434
Average KL loss: 0.230861
Average total loss: 1.078295
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(8.9258e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.847764
Average KL loss: 0.230681
Average total loss: 1.078445
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.2192e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.846077
Average KL loss: 0.230499
Average total loss: 1.076576
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.0766e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.851963
Average KL loss: 0.230375
Average total loss: 1.082338
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-5.9771e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.849803
Average KL loss: 0.230231
Average total loss: 1.080033
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(1.1675e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.847825
Average KL loss: 0.230037
Average total loss: 1.077862
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-3.4875e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.850099
Average KL loss: 0.229875
Average total loss: 1.079974
tensor(0.0020, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-3.2438e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.847649
Average KL loss: 0.229740
Average total loss: 1.077388
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.3802e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.847359
Average KL loss: 0.229580
Average total loss: 1.076940
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-6.0395e-11, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.847687
Average KL loss: 0.229477
Average total loss: 1.077164
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(7.7010e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.853136
Average KL loss: 0.229380
Average total loss: 1.082516
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(8.6560e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.850555
Average KL loss: 0.229237
Average total loss: 1.079792
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.0149e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.846994
Average KL loss: 0.229079
Average total loss: 1.076073
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(4.2928e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.849091
Average KL loss: 0.228938
Average total loss: 1.078029
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(3.2198e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.850679
Average KL loss: 0.228849
Average total loss: 1.079528
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.2616e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.849952
Average KL loss: 0.228804
Average total loss: 1.078756
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-4.4565e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.849088
Average KL loss: 0.228777
Average total loss: 1.077866
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-8.6244e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.849442
Average KL loss: 0.228699
Average total loss: 1.078141
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(6.2339e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.849737
Average KL loss: 0.228525
Average total loss: 1.078262
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-7.0666e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.847413
Average KL loss: 0.228419
Average total loss: 1.075832
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.9615e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.853000
Average KL loss: 0.228353
Average total loss: 1.081353
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-7.3536e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.849748
Average KL loss: 0.228252
Average total loss: 1.078000
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.3054e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.850552
Average KL loss: 0.228178
Average total loss: 1.078730
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.1523e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.847225
Average KL loss: 0.228028
Average total loss: 1.075253
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-8.1065e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.848313
Average KL loss: 0.227863
Average total loss: 1.076176
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-4.4968e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.856282
Average KL loss: 0.227748
Average total loss: 1.084031
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(8.5475e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.849481
Average KL loss: 0.227667
Average total loss: 1.077148
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.6164e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.847641
Average KL loss: 0.227582
Average total loss: 1.075223
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-8.6679e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.850135
Average KL loss: 0.227552
Average total loss: 1.077687
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.0206e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.851504
Average KL loss: 0.227501
Average total loss: 1.079005
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(3.3758e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.854726
Average KL loss: 0.227367
Average total loss: 1.082093
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(8.8767e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.849646
Average KL loss: 0.227269
Average total loss: 1.076915
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.2213e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.853801
Average KL loss: 0.227171
Average total loss: 1.080972
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.8899e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.851427
Average KL loss: 0.227125
Average total loss: 1.078552
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-5.6374e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.849976
Average KL loss: 0.227025
Average total loss: 1.077001
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.8810e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.849041
Average KL loss: 0.226939
Average total loss: 1.075979
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(3.5921e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.850601
Average KL loss: 0.226923
Average total loss: 1.077524
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-8.1408e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.854400
Average KL loss: 0.226909
Average total loss: 1.081309
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.8001e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.851195
Average KL loss: 0.226887
Average total loss: 1.078082
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(3.3780e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.851975
Average KL loss: 0.226865
Average total loss: 1.078840
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-9.7194e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.851191
Average KL loss: 0.226849
Average total loss: 1.078040
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.0790e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.851974
Average KL loss: 0.226831
Average total loss: 1.078805
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-9.8655e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.851225
Average KL loss: 0.226813
Average total loss: 1.078038
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(9.2216e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.847836
Average KL loss: 0.226797
Average total loss: 1.074633
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.7826e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.849915
Average KL loss: 0.226783
Average total loss: 1.076698
tensor(0.0020, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.1979e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.852705
Average KL loss: 0.226768
Average total loss: 1.079472
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.4588e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.848755
Average KL loss: 0.226751
Average total loss: 1.075505
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(6.1409e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.856366
Average KL loss: 0.226741
Average total loss: 1.083107
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(4.0789e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.855010
Average KL loss: 0.226721
Average total loss: 1.081730
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(8.8206e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.848787
Average KL loss: 0.226703
Average total loss: 1.075491
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-6.8510e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.850925
Average KL loss: 0.226688
Average total loss: 1.077613
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(1.0586e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.850299
Average KL loss: 0.226672
Average total loss: 1.076971
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.5346e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.850032
Average KL loss: 0.226654
Average total loss: 1.076686
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.5023e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.849781
Average KL loss: 0.226645
Average total loss: 1.076426
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-4.0689e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.850426
Average KL loss: 0.226634
Average total loss: 1.077060
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(1.5324e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.851850
Average KL loss: 0.226628
Average total loss: 1.078477
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-3.1497e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.855657
Average KL loss: 0.226627
Average total loss: 1.082284
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(6.1664e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.853312
Average KL loss: 0.226626
Average total loss: 1.079938
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(7.9491e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.850355
Average KL loss: 0.226624
Average total loss: 1.076980
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(7.6907e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.849279
Average KL loss: 0.226623
Average total loss: 1.075902
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(4.1055e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.852211
Average KL loss: 0.226622
Average total loss: 1.078833
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(2.1458e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.851018
Average KL loss: 0.226620
Average total loss: 1.077638
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(7.9642e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.849671
Average KL loss: 0.226619
Average total loss: 1.076290
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.2694e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.866535
Average KL loss: 0.226617
Average total loss: 1.093152
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(1.2192e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.855247
Average KL loss: 0.226615
Average total loss: 1.081862
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.6423e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.852056
Average KL loss: 0.226613
Average total loss: 1.078670
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.4375e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.854435
Average KL loss: 0.226612
Average total loss: 1.081047
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-5.6908e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.850041
Average KL loss: 0.226612
Average total loss: 1.076653
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(1.0518e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.848642
Average KL loss: 0.226612
Average total loss: 1.075253
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.8853e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.853357
Average KL loss: 0.226612
Average total loss: 1.079968
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.2182e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.852543
Average KL loss: 0.226611
Average total loss: 1.079155
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-6.9773e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.850882
Average KL loss: 0.226611
Average total loss: 1.077493
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(1.8123e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.848306
Average KL loss: 0.226611
Average total loss: 1.074917
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(5.7540e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.849408
Average KL loss: 0.226611
Average total loss: 1.076019
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.6356e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.847986
Average KL loss: 0.226611
Average total loss: 1.074596
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-5.7943e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.851193
Average KL loss: 0.226611
Average total loss: 1.077803
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-4.3338e-10, device='cuda:0')
 Percentile value: 8.084018787712921e-08
Non-zero model percentage: 1.8014516830444336%, Non-zero mask percentage: 1.8014516830444336%

--- Pruning Level [18/24]: ---
conv1.weight         | nonzeros =      58 /    1728             (  3.36%) | total_pruned =    1670 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       4 /   36864             (  0.01%) | total_pruned =   36860 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       1 /   36864             (  0.00%) | total_pruned =   36863 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      14 /   36864             (  0.04%) | total_pruned =   36850 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      45 /   36864             (  0.12%) | total_pruned =   36819 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     123 /   73728             (  0.17%) | total_pruned =   73605 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     229 /  147456             (  0.16%) | total_pruned =  147227 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      22 /    8192             (  0.27%) | total_pruned =    8170 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     270 /  147456             (  0.18%) | total_pruned =  147186 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     304 /  147456             (  0.21%) | total_pruned =  147152 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     635 /  294912             (  0.22%) | total_pruned =  294277 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     121 /     256             ( 47.27%) | total_pruned =     135 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     871 /  589824             (  0.15%) | total_pruned =  588953 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     116 /     256             ( 45.31%) | total_pruned =     140 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      29 /   32768             (  0.09%) | total_pruned =   32739 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     441 /  589824             (  0.07%) | total_pruned =  589383 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      66 /     256             ( 25.78%) | total_pruned =     190 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     252 /  589824             (  0.04%) | total_pruned =  589572 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     537 / 1179648             (  0.05%) | total_pruned = 1179111 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     122 /     512             ( 23.83%) | total_pruned =     390 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     602 / 2359296             (  0.03%) | total_pruned = 2358694 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      76 /     512             ( 14.84%) | total_pruned =     436 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      28 /  131072             (  0.02%) | total_pruned =  131044 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     424 / 2359296             (  0.02%) | total_pruned = 2358872 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      57 /     512             ( 11.13%) | total_pruned =     455 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  193842 / 2359296             (  8.22%) | total_pruned = 2165454 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     209 /     512             ( 40.82%) | total_pruned =     303 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     120 /     512             ( 23.44%) | total_pruned =     392 | shape = torch.Size([512])
linear.weight        | nonzeros =    1219 /    5120             ( 23.81%) | total_pruned =    3901 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 201380, pruned : 10977382, total: 11178762, Compression rate :      55.51x  ( 98.20% pruned)
Train Epoch: 99/100 Loss: 0.729237 Accuracy: 69.31 74.30 % Best test Accuracy: 69.64%
tensor(0.0020, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.2889e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.028314
Average KL loss: 0.212010
Average total loss: 1.240323
tensor(-0.0018, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-8.4950e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.354126
Average KL loss: 0.166225
Average total loss: 1.520351
tensor(0.0007, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.1640e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.177138
Average KL loss: 0.173077
Average total loss: 1.350214
tensor(0.0010, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.7623e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.123089
Average KL loss: 0.177283
Average total loss: 1.300373
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.4140e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.056162
Average KL loss: 0.181133
Average total loss: 1.237295
tensor(0.0011, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-6.2205e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.042169
Average KL loss: 0.184628
Average total loss: 1.226797
tensor(0.0011, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-8.8237e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.994625
Average KL loss: 0.187381
Average total loss: 1.182006
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.2019e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.969185
Average KL loss: 0.189753
Average total loss: 1.158938
tensor(0.0012, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.1347e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.954796
Average KL loss: 0.192048
Average total loss: 1.146844
tensor(0.0012, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-5.3746e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.953066
Average KL loss: 0.194459
Average total loss: 1.147525
tensor(0.0012, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-6.7414e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.942124
Average KL loss: 0.196550
Average total loss: 1.138673
tensor(0.0013, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.2003e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.917121
Average KL loss: 0.198878
Average total loss: 1.115999
tensor(0.0013, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-3.5409e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.918729
Average KL loss: 0.201552
Average total loss: 1.120281
tensor(0.0013, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-8.9570e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.910550
Average KL loss: 0.203464
Average total loss: 1.114014
tensor(0.0014, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.1561e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.909554
Average KL loss: 0.204949
Average total loss: 1.114503
tensor(0.0014, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.0494e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.909040
Average KL loss: 0.207903
Average total loss: 1.116943
tensor(-0.0073, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.2096e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.890549
Average KL loss: 0.209512
Average total loss: 1.100061
tensor(0.0022, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.0199e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.894827
Average KL loss: 0.209975
Average total loss: 1.104802
tensor(0.0014, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.8792e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.878356
Average KL loss: 0.211099
Average total loss: 1.089455
tensor(0.0015, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.8424e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.877138
Average KL loss: 0.212422
Average total loss: 1.089560
tensor(0.0014, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.3626e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.874261
Average KL loss: 0.217023
Average total loss: 1.091284
tensor(0.0030, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.6294e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.872973
Average KL loss: 0.215230
Average total loss: 1.088204
tensor(0.0016, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.2954e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.863060
Average KL loss: 0.215967
Average total loss: 1.079027
tensor(0.0015, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.0516e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.866766
Average KL loss: 0.217212
Average total loss: 1.083977
tensor(0.0016, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.6489e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.857965
Average KL loss: 0.220999
Average total loss: 1.078964
tensor(-0.0036, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.3154e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.857630
Average KL loss: 0.219617
Average total loss: 1.077247
tensor(0.0020, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(8.7151e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.854118
Average KL loss: 0.220709
Average total loss: 1.074827
tensor(0.0016, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.4725e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.849834
Average KL loss: 0.221442
Average total loss: 1.071276
tensor(0.0017, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-3.3102e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.850242
Average KL loss: 0.222096
Average total loss: 1.072338
tensor(0.0001, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-4.2917e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.847368
Average KL loss: 0.227061
Average total loss: 1.074429
tensor(0.0018, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(3.2457e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.848620
Average KL loss: 0.223982
Average total loss: 1.072602
tensor(0.0018, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.4094e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.854341
Average KL loss: 0.225039
Average total loss: 1.079380
tensor(0.0017, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(5.1251e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.842768
Average KL loss: 0.225696
Average total loss: 1.068465
tensor(0.0017, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-3.1096e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.846381
Average KL loss: 0.226462
Average total loss: 1.072843
tensor(0.0017, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(2.0612e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.838423
Average KL loss: 0.229636
Average total loss: 1.068060
tensor(-0.0021, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-9.9149e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.839383
Average KL loss: 0.228087
Average total loss: 1.067470
tensor(0.0022, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(8.9598e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.837869
Average KL loss: 0.227958
Average total loss: 1.065827
tensor(0.0018, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.1585e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.838774
Average KL loss: 0.227965
Average total loss: 1.066739
tensor(0.0018, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.2889e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.834764
Average KL loss: 0.228486
Average total loss: 1.063250
tensor(0.0012, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.4211e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.833507
Average KL loss: 0.232787
Average total loss: 1.066294
tensor(0.0013, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.4326e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.834135
Average KL loss: 0.229961
Average total loss: 1.064097
tensor(0.0020, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(4.3338e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.833806
Average KL loss: 0.230625
Average total loss: 1.064431
tensor(0.0018, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-4.4686e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.830492
Average KL loss: 0.231424
Average total loss: 1.061915
tensor(0.0018, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.8339e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.830166
Average KL loss: 0.232109
Average total loss: 1.062275
tensor(0.0116, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.4159e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.828491
Average KL loss: 0.234912
Average total loss: 1.063403
tensor(0.0028, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.2121e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.829460
Average KL loss: 0.233449
Average total loss: 1.062908
tensor(0.0019, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.1564e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.828045
Average KL loss: 0.233630
Average total loss: 1.061675
tensor(0.0019, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-5.2580e-11, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.827155
Average KL loss: 0.233798
Average total loss: 1.060953
tensor(0.0025, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(8.6508e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.823423
Average KL loss: 0.237554
Average total loss: 1.060977
tensor(0.0022, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(6.2266e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.823032
Average KL loss: 0.235260
Average total loss: 1.058292
tensor(0.0018, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-4.7905e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.825380
Average KL loss: 0.235739
Average total loss: 1.061118
tensor(0.0019, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-7.0834e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.829795
Average KL loss: 0.235072
Average total loss: 1.064867
tensor(0.0018, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.3339e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.822227
Average KL loss: 0.238551
Average total loss: 1.060778
tensor(0.0046, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(6.3741e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.824654
Average KL loss: 0.235910
Average total loss: 1.060564
tensor(0.0021, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(2.7591e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.820675
Average KL loss: 0.236402
Average total loss: 1.057077
tensor(0.0020, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.5898e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.821098
Average KL loss: 0.236807
Average total loss: 1.057905
tensor(0.0020, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.1628e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.822286
Average KL loss: 0.237669
Average total loss: 1.059955
tensor(0.0081, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(1.5099e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.818277
Average KL loss: 0.240995
Average total loss: 1.059272
tensor(0.0011, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.2866e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.819367
Average KL loss: 0.238539
Average total loss: 1.057906
tensor(0.0021, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.9836e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.816565
Average KL loss: 0.238782
Average total loss: 1.055347
tensor(0.0020, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(1.2547e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.815402
Average KL loss: 0.239229
Average total loss: 1.054630
tensor(0.0029, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(1.8507e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.820489
Average KL loss: 0.242981
Average total loss: 1.063469
tensor(0.0029, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(2.0155e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.813523
Average KL loss: 0.239854
Average total loss: 1.053376
tensor(0.0021, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(3.3934e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.815009
Average KL loss: 0.239833
Average total loss: 1.054842
tensor(0.0020, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.8700e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.815551
Average KL loss: 0.239508
Average total loss: 1.055058
tensor(0.0021, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(5.5541e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.814191
Average KL loss: 0.241593
Average total loss: 1.055784
tensor(-0.0051, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.7935e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.817435
Average KL loss: 0.241063
Average total loss: 1.058498
tensor(0.0018, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-7.2826e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.815784
Average KL loss: 0.240560
Average total loss: 1.056343
tensor(0.0021, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(2.7223e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.816041
Average KL loss: 0.240426
Average total loss: 1.056466
tensor(0.0021, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.9683e-11, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.816577
Average KL loss: 0.240689
Average total loss: 1.057265
tensor(0.0029, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(1.7670e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.827147
Average KL loss: 0.244265
Average total loss: 1.071413
tensor(0.0038, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(4.1782e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.819050
Average KL loss: 0.241144
Average total loss: 1.060194
tensor(0.0021, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-9.6915e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.815242
Average KL loss: 0.240839
Average total loss: 1.056081
tensor(0.0021, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.2241e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.816849
Average KL loss: 0.240982
Average total loss: 1.057832
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.2471e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.813363
Average KL loss: 0.240717
Average total loss: 1.054079
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(2.4898e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.810919
Average KL loss: 0.240199
Average total loss: 1.051118
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.1307e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.811531
Average KL loss: 0.239865
Average total loss: 1.051397
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.0048e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.813258
Average KL loss: 0.239557
Average total loss: 1.052815
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.3707e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.816290
Average KL loss: 0.239280
Average total loss: 1.055570
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(4.8848e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.811029
Average KL loss: 0.239020
Average total loss: 1.050050
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(3.4122e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.813511
Average KL loss: 0.238786
Average total loss: 1.052298
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-5.1782e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.817954
Average KL loss: 0.238585
Average total loss: 1.056538
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.4867e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.812443
Average KL loss: 0.238367
Average total loss: 1.050809
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(7.3353e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.811421
Average KL loss: 0.238245
Average total loss: 1.049666
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.5199e-11, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.811343
Average KL loss: 0.238091
Average total loss: 1.049435
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.8288e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.811890
Average KL loss: 0.237910
Average total loss: 1.049799
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(3.6460e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.810981
Average KL loss: 0.237801
Average total loss: 1.048782
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(2.4828e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.812581
Average KL loss: 0.237638
Average total loss: 1.050220
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-2.3038e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.810908
Average KL loss: 0.237472
Average total loss: 1.048380
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.9242e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.809751
Average KL loss: 0.237318
Average total loss: 1.047069
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(5.6912e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.812757
Average KL loss: 0.237162
Average total loss: 1.049919
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(3.3352e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.812839
Average KL loss: 0.237010
Average total loss: 1.049850
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.5132e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.814535
Average KL loss: 0.236890
Average total loss: 1.051425
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-5.9582e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.810645
Average KL loss: 0.236775
Average total loss: 1.047420
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-6.8602e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.811932
Average KL loss: 0.236621
Average total loss: 1.048553
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.1495e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.811996
Average KL loss: 0.236491
Average total loss: 1.048487
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-3.1801e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.810893
Average KL loss: 0.236397
Average total loss: 1.047290
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-5.9813e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.810673
Average KL loss: 0.236333
Average total loss: 1.047007
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.1976e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.811517
Average KL loss: 0.236189
Average total loss: 1.047706
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(4.7969e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.810858
Average KL loss: 0.236037
Average total loss: 1.046894
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-9.5726e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.810465
Average KL loss: 0.235957
Average total loss: 1.046421
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(9.7057e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.815187
Average KL loss: 0.235833
Average total loss: 1.051020
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-9.8275e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.811269
Average KL loss: 0.235738
Average total loss: 1.047007
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.9764e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.812064
Average KL loss: 0.235639
Average total loss: 1.047704
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-9.9996e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.809427
Average KL loss: 0.235532
Average total loss: 1.044959
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-5.0805e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.815517
Average KL loss: 0.235469
Average total loss: 1.050986
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(4.4303e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.812733
Average KL loss: 0.235402
Average total loss: 1.048135
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(2.8545e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.817083
Average KL loss: 0.235260
Average total loss: 1.052343
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(5.8673e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.810552
Average KL loss: 0.235150
Average total loss: 1.045703
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(2.5437e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.816762
Average KL loss: 0.235068
Average total loss: 1.051830
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-7.7939e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.811917
Average KL loss: 0.235020
Average total loss: 1.046937
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.7264e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.812695
Average KL loss: 0.234959
Average total loss: 1.047654
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.6491e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.815917
Average KL loss: 0.234817
Average total loss: 1.050734
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(9.0246e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.812579
Average KL loss: 0.234746
Average total loss: 1.047325
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-3.4067e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.810902
Average KL loss: 0.234747
Average total loss: 1.045650
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-4.3845e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.813410
Average KL loss: 0.234709
Average total loss: 1.048119
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.8669e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.816414
Average KL loss: 0.234704
Average total loss: 1.051118
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(5.3334e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.813077
Average KL loss: 0.234690
Average total loss: 1.047767
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-6.2009e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.813161
Average KL loss: 0.234675
Average total loss: 1.047836
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(8.5509e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.810860
Average KL loss: 0.234661
Average total loss: 1.045522
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.1035e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.811318
Average KL loss: 0.234648
Average total loss: 1.045966
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.3861e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.811239
Average KL loss: 0.234633
Average total loss: 1.045872
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-3.9855e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.810995
Average KL loss: 0.234617
Average total loss: 1.045612
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-7.8111e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.810495
Average KL loss: 0.234604
Average total loss: 1.045099
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(4.6186e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.811407
Average KL loss: 0.234592
Average total loss: 1.045999
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(4.8690e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.816916
Average KL loss: 0.234576
Average total loss: 1.051492
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.2196e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.812494
Average KL loss: 0.234565
Average total loss: 1.047059
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-5.8264e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.823597
Average KL loss: 0.234558
Average total loss: 1.058155
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.4452e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.810015
Average KL loss: 0.234556
Average total loss: 1.044571
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(3.5950e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.812247
Average KL loss: 0.234555
Average total loss: 1.046802
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.4101e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.812942
Average KL loss: 0.234554
Average total loss: 1.047496
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.0721e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.812359
Average KL loss: 0.234554
Average total loss: 1.046913
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.4300e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.811820
Average KL loss: 0.234553
Average total loss: 1.046373
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.0590e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.811851
Average KL loss: 0.234551
Average total loss: 1.046402
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(8.7216e-12, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.810810
Average KL loss: 0.234550
Average total loss: 1.045360
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(3.8373e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.814110
Average KL loss: 0.234548
Average total loss: 1.048658
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.0249e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.812786
Average KL loss: 0.234546
Average total loss: 1.047332
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.5279e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.812831
Average KL loss: 0.234545
Average total loss: 1.047376
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-2.9975e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.813979
Average KL loss: 0.234544
Average total loss: 1.048523
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-6.7692e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.814277
Average KL loss: 0.234542
Average total loss: 1.048819
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-4.0824e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.811280
Average KL loss: 0.234542
Average total loss: 1.045821
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-4.7608e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.812684
Average KL loss: 0.234541
Average total loss: 1.047225
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(9.2253e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.812613
Average KL loss: 0.234541
Average total loss: 1.047155
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-2.7552e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.811466
Average KL loss: 0.234541
Average total loss: 1.046007
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.5784e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.813661
Average KL loss: 0.234541
Average total loss: 1.048202
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(4.9361e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.811044
Average KL loss: 0.234541
Average total loss: 1.045584
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.4957e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.813382
Average KL loss: 0.234541
Average total loss: 1.047922
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.0413e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.810694
Average KL loss: 0.234541
Average total loss: 1.045234
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(7.3870e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.810870
Average KL loss: 0.234540
Average total loss: 1.045410
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-8.6719e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.818325
Average KL loss: 0.234540
Average total loss: 1.052865
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(3.1527e-10, device='cuda:0')
 Percentile value: 8.210897561866659e-08
Non-zero model percentage: 1.4411613941192627%, Non-zero mask percentage: 1.4411613941192627%

--- Pruning Level [19/24]: ---
conv1.weight         | nonzeros =      57 /    1728             (  3.30%) | total_pruned =    1671 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      14 /   36864             (  0.04%) | total_pruned =   36850 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      40 /   36864             (  0.11%) | total_pruned =   36824 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     105 /   73728             (  0.14%) | total_pruned =   73623 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     194 /  147456             (  0.13%) | total_pruned =  147262 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      20 /    8192             (  0.24%) | total_pruned =    8172 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     231 /  147456             (  0.16%) | total_pruned =  147225 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     264 /  147456             (  0.18%) | total_pruned =  147192 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     564 /  294912             (  0.19%) | total_pruned =  294348 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     113 /     256             ( 44.14%) | total_pruned =     143 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     751 /  589824             (  0.13%) | total_pruned =  589073 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     111 /     256             ( 43.36%) | total_pruned =     145 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      20 /   32768             (  0.06%) | total_pruned =   32748 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     386 /  589824             (  0.07%) | total_pruned =  589438 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      57 /     256             ( 22.27%) | total_pruned =     199 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     208 /  589824             (  0.04%) | total_pruned =  589616 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     440 / 1179648             (  0.04%) | total_pruned = 1179208 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     112 /     512             ( 21.88%) | total_pruned =     400 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     493 / 2359296             (  0.02%) | total_pruned = 2358803 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      71 /     512             ( 13.87%) | total_pruned =     441 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      24 /  131072             (  0.02%) | total_pruned =  131048 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     348 / 2359296             (  0.01%) | total_pruned = 2358948 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      53 /     512             ( 10.35%) | total_pruned =     459 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  154402 / 2359296             (  6.54%) | total_pruned = 2204894 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     205 /     512             ( 40.04%) | total_pruned =     307 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     117 /     512             ( 22.85%) | total_pruned =     395 | shape = torch.Size([512])
linear.weight        | nonzeros =    1195 /    5120             ( 23.34%) | total_pruned =    3925 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 161104, pruned : 11017658, total: 11178762, Compression rate :      69.39x  ( 98.56% pruned)
Train Epoch: 56/100 Loss: 1.153779 Accuracy: 66.19 70.45 % Best test Accuracy: 67.09%
tensor(0.0021, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.1186e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.111131
Average KL loss: 0.217645
Average total loss: 1.328776
tensor(-0.0018, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-9.1906e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.358076
Average KL loss: 0.151912
Average total loss: 1.509989
tensor(0.0006, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.9478e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.244119
Average KL loss: 0.154373
Average total loss: 1.398492
tensor(0.0009, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.1281e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.179894
Average KL loss: 0.158785
Average total loss: 1.338679
tensor(0.0009, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-6.1422e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.122360
Average KL loss: 0.161317
Average total loss: 1.283677
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0150e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.067694
Average KL loss: 0.163508
Average total loss: 1.231202
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.3248e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.061949
Average KL loss: 0.166128
Average total loss: 1.228077
tensor(0.0010, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-6.7959e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.043066
Average KL loss: 0.168891
Average total loss: 1.211957
tensor(0.0011, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-6.7515e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.027420
Average KL loss: 0.171151
Average total loss: 1.198571
tensor(0.0011, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-4.7650e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.012100
Average KL loss: 0.172905
Average total loss: 1.185004
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-4.2333e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.033775
Average KL loss: 0.174884
Average total loss: 1.208659
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.0401e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.002736
Average KL loss: 0.176430
Average total loss: 1.179166
tensor(0.0012, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.4667e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.002730
Average KL loss: 0.177898
Average total loss: 1.180628
tensor(0.0012, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-5.3088e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.982625
Average KL loss: 0.179013
Average total loss: 1.161638
tensor(0.0012, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-2.4056e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.971351
Average KL loss: 0.180084
Average total loss: 1.151435
tensor(0.0012, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-2.5375e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.976629
Average KL loss: 0.182917
Average total loss: 1.159546
tensor(-0.0074, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.1997e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.980534
Average KL loss: 0.184127
Average total loss: 1.164661
tensor(0.0020, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.6077e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.951169
Average KL loss: 0.183567
Average total loss: 1.134736
tensor(0.0012, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-3.2929e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.945359
Average KL loss: 0.184789
Average total loss: 1.130148
tensor(0.0013, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(7.1109e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.945566
Average KL loss: 0.185817
Average total loss: 1.131382
tensor(0.0012, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.8581e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.944866
Average KL loss: 0.189935
Average total loss: 1.134800
tensor(0.0028, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(3.5006e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.941141
Average KL loss: 0.188171
Average total loss: 1.129312
tensor(0.0014, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.8608e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.934047
Average KL loss: 0.188290
Average total loss: 1.122337
tensor(0.0013, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.8513e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.932178
Average KL loss: 0.189230
Average total loss: 1.121408
tensor(0.0014, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4359e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.933363
Average KL loss: 0.192455
Average total loss: 1.125819
tensor(-0.0038, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.3070e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.927487
Average KL loss: 0.190746
Average total loss: 1.118232
tensor(0.0018, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(7.6446e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.929224
Average KL loss: 0.190742
Average total loss: 1.119966
tensor(0.0014, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.7700e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.925745
Average KL loss: 0.191589
Average total loss: 1.117334
tensor(0.0014, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.5912e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.921594
Average KL loss: 0.192115
Average total loss: 1.113709
tensor(-8.6235e-05, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.8790e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.926268
Average KL loss: 0.197140
Average total loss: 1.123407
tensor(0.0016, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(3.6250e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.919265
Average KL loss: 0.193027
Average total loss: 1.112293
tensor(0.0015, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.4007e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.914522
Average KL loss: 0.193249
Average total loss: 1.107771
tensor(0.0015, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.0146e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.937287
Average KL loss: 0.193793
Average total loss: 1.131080
tensor(0.0015, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.0187e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.918439
Average KL loss: 0.193922
Average total loss: 1.112361
tensor(0.0015, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.1777e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.914855
Average KL loss: 0.197052
Average total loss: 1.111907
tensor(-0.0024, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-9.8460e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.919093
Average KL loss: 0.195562
Average total loss: 1.114655
tensor(0.0020, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(1.0344e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.919712
Average KL loss: 0.195573
Average total loss: 1.115286
tensor(0.0015, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-2.9758e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.912674
Average KL loss: 0.196157
Average total loss: 1.108831
tensor(0.0015, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-4.0236e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.913032
Average KL loss: 0.196605
Average total loss: 1.109637
tensor(0.0010, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.3158e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.919491
Average KL loss: 0.200430
Average total loss: 1.119921
tensor(0.0010, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.4072e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.910338
Average KL loss: 0.197647
Average total loss: 1.107985
tensor(0.0017, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(2.5262e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.918080
Average KL loss: 0.198120
Average total loss: 1.116200
tensor(0.0016, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.8565e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.922958
Average KL loss: 0.198839
Average total loss: 1.121797
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(2.5938e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.920221
Average KL loss: 0.198698
Average total loss: 1.118919
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-5.6737e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.908479
Average KL loss: 0.198288
Average total loss: 1.106767
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.7645e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.909062
Average KL loss: 0.197929
Average total loss: 1.106991
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.1144e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.911417
Average KL loss: 0.197640
Average total loss: 1.109057
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.8589e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.912921
Average KL loss: 0.197416
Average total loss: 1.110337
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(5.0314e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.906025
Average KL loss: 0.197250
Average total loss: 1.103276
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.3170e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.907472
Average KL loss: 0.197113
Average total loss: 1.104584
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.7896e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.917651
Average KL loss: 0.197002
Average total loss: 1.114652
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.1251e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.905794
Average KL loss: 0.196900
Average total loss: 1.102694
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.1873e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.905207
Average KL loss: 0.196777
Average total loss: 1.101984
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.7067e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.905883
Average KL loss: 0.196673
Average total loss: 1.102556
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.5385e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.913428
Average KL loss: 0.196569
Average total loss: 1.109997
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(5.4135e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.909712
Average KL loss: 0.196419
Average total loss: 1.106131
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-3.9676e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.905294
Average KL loss: 0.196365
Average total loss: 1.101659
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.4361e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.908038
Average KL loss: 0.196298
Average total loss: 1.104337
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.1769e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.906112
Average KL loss: 0.196187
Average total loss: 1.102299
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(3.2369e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.912514
Average KL loss: 0.196063
Average total loss: 1.108576
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-4.6177e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.911033
Average KL loss: 0.195979
Average total loss: 1.107012
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(3.2775e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.914248
Average KL loss: 0.195964
Average total loss: 1.110212
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.9884e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.906501
Average KL loss: 0.195890
Average total loss: 1.102391
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-3.3760e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.917902
Average KL loss: 0.195805
Average total loss: 1.113707
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(6.7613e-11, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.906334
Average KL loss: 0.195720
Average total loss: 1.102054
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(4.0695e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.905097
Average KL loss: 0.195652
Average total loss: 1.100749
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.0466e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.912821
Average KL loss: 0.195599
Average total loss: 1.108421
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-4.4611e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.909033
Average KL loss: 0.195487
Average total loss: 1.104520
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(7.6019e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.905205
Average KL loss: 0.195411
Average total loss: 1.100616
tensor(0.0016, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-8.9064e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.907045
Average KL loss: 0.195381
Average total loss: 1.102426
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(1.1338e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.903325
Average KL loss: 0.195352
Average total loss: 1.098678
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-5.0860e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.905139
Average KL loss: 0.195292
Average total loss: 1.100431
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-3.7775e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.910271
Average KL loss: 0.195262
Average total loss: 1.105533
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-5.9828e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.904569
Average KL loss: 0.195216
Average total loss: 1.099785
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(2.4548e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.904495
Average KL loss: 0.195143
Average total loss: 1.099638
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(4.6717e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.904644
Average KL loss: 0.195107
Average total loss: 1.099751
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-8.5444e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.905254
Average KL loss: 0.195106
Average total loss: 1.100360
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-6.4768e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.906929
Average KL loss: 0.195046
Average total loss: 1.101975
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-5.9688e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.904418
Average KL loss: 0.194962
Average total loss: 1.099380
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(4.7886e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.911390
Average KL loss: 0.194846
Average total loss: 1.106236
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(3.9201e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.908640
Average KL loss: 0.194832
Average total loss: 1.103472
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.3435e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.907873
Average KL loss: 0.194801
Average total loss: 1.102674
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.6618e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.910136
Average KL loss: 0.194709
Average total loss: 1.104844
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.7064e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.903503
Average KL loss: 0.194697
Average total loss: 1.098200
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(3.0323e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.908540
Average KL loss: 0.194687
Average total loss: 1.103226
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.2583e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.905069
Average KL loss: 0.194671
Average total loss: 1.099740
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-4.3535e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.904110
Average KL loss: 0.194656
Average total loss: 1.098766
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(8.5034e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.906670
Average KL loss: 0.194646
Average total loss: 1.101316
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(3.8479e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.910117
Average KL loss: 0.194641
Average total loss: 1.104758
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(6.1036e-11, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.914507
Average KL loss: 0.194642
Average total loss: 1.109149
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-9.4560e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.909364
Average KL loss: 0.194636
Average total loss: 1.103999
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-8.4852e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.905957
Average KL loss: 0.194628
Average total loss: 1.100585
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-5.5125e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.912879
Average KL loss: 0.194622
Average total loss: 1.107501
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-9.5423e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.903161
Average KL loss: 0.194612
Average total loss: 1.097772
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-7.1043e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.911849
Average KL loss: 0.194604
Average total loss: 1.106453
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-3.1690e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.908448
Average KL loss: 0.194596
Average total loss: 1.103044
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-3.3450e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.906994
Average KL loss: 0.194592
Average total loss: 1.101586
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-4.1070e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.908157
Average KL loss: 0.194589
Average total loss: 1.102746
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-8.8374e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.909581
Average KL loss: 0.194579
Average total loss: 1.104161
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(6.3267e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.905926
Average KL loss: 0.194572
Average total loss: 1.100498
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(5.4530e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.908524
Average KL loss: 0.194566
Average total loss: 1.103090
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-4.1162e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.904334
Average KL loss: 0.194559
Average total loss: 1.098894
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-8.1279e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.904806
Average KL loss: 0.194556
Average total loss: 1.099361
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.7828e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.900642
Average KL loss: 0.194550
Average total loss: 1.095193
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.6395e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.907872
Average KL loss: 0.194546
Average total loss: 1.102418
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-6.9833e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.911466
Average KL loss: 0.194541
Average total loss: 1.106007
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.9005e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.906065
Average KL loss: 0.194536
Average total loss: 1.100601
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-7.3399e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.908822
Average KL loss: 0.194531
Average total loss: 1.103354
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(1.1339e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.908288
Average KL loss: 0.194526
Average total loss: 1.102814
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-7.2413e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.914120
Average KL loss: 0.194519
Average total loss: 1.108639
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-6.4943e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.903160
Average KL loss: 0.194508
Average total loss: 1.097668
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.7962e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.904646
Average KL loss: 0.194503
Average total loss: 1.099149
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-8.5766e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.904905
Average KL loss: 0.194498
Average total loss: 1.099403
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-6.6365e-11, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.906185
Average KL loss: 0.194492
Average total loss: 1.100677
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.1328e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.905520
Average KL loss: 0.194486
Average total loss: 1.100006
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.1701e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.905861
Average KL loss: 0.194480
Average total loss: 1.100341
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.3329e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.908536
Average KL loss: 0.194479
Average total loss: 1.103016
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.1026e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.909024
Average KL loss: 0.194478
Average total loss: 1.103502
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(1.0720e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.905981
Average KL loss: 0.194477
Average total loss: 1.100458
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.2831e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.906908
Average KL loss: 0.194476
Average total loss: 1.101384
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.0103e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.910964
Average KL loss: 0.194476
Average total loss: 1.105439
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.0732e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.909414
Average KL loss: 0.194475
Average total loss: 1.103889
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-5.4552e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.903682
Average KL loss: 0.194474
Average total loss: 1.098156
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-6.8091e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.908573
Average KL loss: 0.194474
Average total loss: 1.103046
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-3.1571e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.906340
Average KL loss: 0.194473
Average total loss: 1.100813
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.7914e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.904765
Average KL loss: 0.194472
Average total loss: 1.099237
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-7.4515e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.912798
Average KL loss: 0.194472
Average total loss: 1.107270
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(5.5884e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.908714
Average KL loss: 0.194472
Average total loss: 1.103185
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.1169e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.904780
Average KL loss: 0.194472
Average total loss: 1.099252
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(2.9919e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.903675
Average KL loss: 0.194471
Average total loss: 1.098146
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-4.0372e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.905513
Average KL loss: 0.194471
Average total loss: 1.099984
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.3825e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.903196
Average KL loss: 0.194471
Average total loss: 1.097667
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-8.9955e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.903689
Average KL loss: 0.194471
Average total loss: 1.098160
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-7.3746e-11, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.905623
Average KL loss: 0.194471
Average total loss: 1.100094
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(5.8872e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.903722
Average KL loss: 0.194471
Average total loss: 1.098193
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-9.5954e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.908733
Average KL loss: 0.194471
Average total loss: 1.103204
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-5.6098e-10, device='cuda:0')
 Percentile value: 8.109830673674878e-08
Non-zero model percentage: 1.1529362201690674%, Non-zero mask percentage: 1.1529362201690674%

--- Pruning Level [20/24]: ---
conv1.weight         | nonzeros =      56 /    1728             (  3.24%) | total_pruned =    1672 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      12 /   36864             (  0.03%) | total_pruned =   36852 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      36 /   36864             (  0.10%) | total_pruned =   36828 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =      90 /   73728             (  0.12%) | total_pruned =   73638 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     172 /  147456             (  0.12%) | total_pruned =  147284 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      20 /    8192             (  0.24%) | total_pruned =    8172 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     191 /  147456             (  0.13%) | total_pruned =  147265 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     224 /  147456             (  0.15%) | total_pruned =  147232 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     488 /  294912             (  0.17%) | total_pruned =  294424 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     111 /     256             ( 43.36%) | total_pruned =     145 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     636 /  589824             (  0.11%) | total_pruned =  589188 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     107 /     256             ( 41.80%) | total_pruned =     149 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      17 /   32768             (  0.05%) | total_pruned =   32751 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     338 /  589824             (  0.06%) | total_pruned =  589486 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      55 /     256             ( 21.48%) | total_pruned =     201 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     177 /  589824             (  0.03%) | total_pruned =  589647 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     389 / 1179648             (  0.03%) | total_pruned = 1179259 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     106 /     512             ( 20.70%) | total_pruned =     406 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     432 / 2359296             (  0.02%) | total_pruned = 2358864 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      68 /     512             ( 13.28%) | total_pruned =     444 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      22 /  131072             (  0.02%) | total_pruned =  131050 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     303 / 2359296             (  0.01%) | total_pruned = 2358993 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      50 /     512             (  9.77%) | total_pruned =     462 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  122800 / 2359296             (  5.20%) | total_pruned = 2236496 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     115 /     512             ( 22.46%) | total_pruned =     397 | shape = torch.Size([512])
linear.weight        | nonzeros =    1171 /    5120             ( 22.87%) | total_pruned =    3949 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 128884, pruned : 11049878, total: 11178762, Compression rate :      86.74x  ( 98.85% pruned)
Train Epoch: 94/100 Loss: 1.023628 Accuracy: 66.39 70.01 % Best test Accuracy: 66.50%
tensor(0.0016, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.5713e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.107791
Average KL loss: 0.181920
Average total loss: 1.289711
tensor(-0.0020, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-9.0842e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.377835
Average KL loss: 0.142769
Average total loss: 1.520604
tensor(0.0006, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.0458e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.234493
Average KL loss: 0.149305
Average total loss: 1.383799
tensor(0.0009, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.3351e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.149082
Average KL loss: 0.152893
Average total loss: 1.301975
tensor(0.0009, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-8.1120e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.090850
Average KL loss: 0.155981
Average total loss: 1.246831
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.7035e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.053622
Average KL loss: 0.159498
Average total loss: 1.213120
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.4690e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.050661
Average KL loss: 0.161886
Average total loss: 1.212548
tensor(0.0010, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-3.7709e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.050453
Average KL loss: 0.163935
Average total loss: 1.214389
tensor(0.0010, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.6701e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.017255
Average KL loss: 0.165175
Average total loss: 1.182429
tensor(0.0011, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-4.4162e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.013176
Average KL loss: 0.167401
Average total loss: 1.180577
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.0471e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.003107
Average KL loss: 0.169771
Average total loss: 1.172879
tensor(0.0011, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.9091e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.985279
Average KL loss: 0.170894
Average total loss: 1.156173
tensor(0.0011, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.6133e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.974351
Average KL loss: 0.171781
Average total loss: 1.146132
tensor(0.0012, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(1.7425e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.971152
Average KL loss: 0.173427
Average total loss: 1.144579
tensor(0.0012, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.5493e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.973985
Average KL loss: 0.174535
Average total loss: 1.148519
tensor(0.0012, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.8394e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.956377
Average KL loss: 0.177846
Average total loss: 1.134223
tensor(-0.0075, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.1938e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.955346
Average KL loss: 0.178452
Average total loss: 1.133798
tensor(0.0020, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.6453e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.954295
Average KL loss: 0.177990
Average total loss: 1.132285
tensor(0.0012, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.5062e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.947376
Average KL loss: 0.178502
Average total loss: 1.125879
tensor(0.0013, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.0554e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.951576
Average KL loss: 0.179644
Average total loss: 1.131220
tensor(0.0012, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.4708e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.942633
Average KL loss: 0.183581
Average total loss: 1.126214
tensor(0.0028, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(3.4460e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.938449
Average KL loss: 0.181277
Average total loss: 1.119726
tensor(0.0013, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(1.2559e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.941939
Average KL loss: 0.182349
Average total loss: 1.124288
tensor(0.0013, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.0637e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.943440
Average KL loss: 0.183150
Average total loss: 1.126590
tensor(0.0014, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.6411e-11, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.932041
Average KL loss: 0.186884
Average total loss: 1.118925
tensor(-0.0038, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.2998e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.927158
Average KL loss: 0.185593
Average total loss: 1.112752
tensor(0.0017, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(7.7361e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.927700
Average KL loss: 0.186195
Average total loss: 1.113895
tensor(0.0014, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.5496e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.922933
Average KL loss: 0.186768
Average total loss: 1.109701
tensor(0.0014, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.6201e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.922266
Average KL loss: 0.187139
Average total loss: 1.109405
tensor(-0.0001, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.8509e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.928273
Average KL loss: 0.191833
Average total loss: 1.120106
tensor(0.0016, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.8993e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.923476
Average KL loss: 0.188527
Average total loss: 1.112003
tensor(0.0015, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(6.3560e-11, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.920166
Average KL loss: 0.188901
Average total loss: 1.109067
tensor(0.0015, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.0214e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.920760
Average KL loss: 0.189205
Average total loss: 1.109965
tensor(0.0015, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(2.8336e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.916548
Average KL loss: 0.189729
Average total loss: 1.106277
tensor(0.0015, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.0914e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.924262
Average KL loss: 0.192366
Average total loss: 1.116627
tensor(-0.0024, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-9.8817e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.913957
Average KL loss: 0.191424
Average total loss: 1.105382
tensor(0.0020, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(1.0355e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.918611
Average KL loss: 0.191446
Average total loss: 1.110057
tensor(0.0015, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(2.7424e-11, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.914075
Average KL loss: 0.191583
Average total loss: 1.105659
tensor(0.0015, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-2.1499e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.913071
Average KL loss: 0.191884
Average total loss: 1.104955
tensor(0.0010, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.5254e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.911672
Average KL loss: 0.195962
Average total loss: 1.107634
tensor(0.0010, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.3094e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.914754
Average KL loss: 0.192955
Average total loss: 1.107709
tensor(0.0017, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(2.0211e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.920807
Average KL loss: 0.193128
Average total loss: 1.113935
tensor(0.0015, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-2.5011e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.907475
Average KL loss: 0.193634
Average total loss: 1.101109
tensor(0.0016, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-3.6751e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.911466
Average KL loss: 0.194435
Average total loss: 1.105901
tensor(0.0113, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(2.4398e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.912443
Average KL loss: 0.196669
Average total loss: 1.109112
tensor(0.0025, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(2.2426e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.905907
Average KL loss: 0.194119
Average total loss: 1.100026
tensor(0.0016, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.7246e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.911759
Average KL loss: 0.194008
Average total loss: 1.105767
tensor(0.0016, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-8.3291e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.908917
Average KL loss: 0.194659
Average total loss: 1.103577
tensor(0.0022, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(1.0781e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.907898
Average KL loss: 0.198010
Average total loss: 1.105908
tensor(0.0019, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(5.8372e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.906599
Average KL loss: 0.195642
Average total loss: 1.102240
tensor(0.0015, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.6147e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.904497
Average KL loss: 0.195906
Average total loss: 1.100403
tensor(0.0016, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(4.1102e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.905183
Average KL loss: 0.195752
Average total loss: 1.100935
tensor(0.0015, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-2.5322e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.905385
Average KL loss: 0.198978
Average total loss: 1.104363
tensor(0.0042, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(6.4263e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.902379
Average KL loss: 0.195963
Average total loss: 1.098342
tensor(0.0018, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(2.7096e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.902727
Average KL loss: 0.196236
Average total loss: 1.098963
tensor(0.0016, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.1420e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.905760
Average KL loss: 0.196401
Average total loss: 1.102161
tensor(0.0017, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.2388e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.910815
Average KL loss: 0.197126
Average total loss: 1.107941
tensor(0.0078, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.5373e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.905554
Average KL loss: 0.200168
Average total loss: 1.105722
tensor(0.0008, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.2817e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.901113
Average KL loss: 0.197986
Average total loss: 1.099098
tensor(0.0018, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.4424e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.902182
Average KL loss: 0.198226
Average total loss: 1.100408
tensor(0.0017, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.2776e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.900868
Average KL loss: 0.198296
Average total loss: 1.099163
tensor(0.0026, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.9787e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.900028
Average KL loss: 0.201972
Average total loss: 1.102000
tensor(0.0026, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(2.0483e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.903840
Average KL loss: 0.198966
Average total loss: 1.102805
tensor(0.0018, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-4.4654e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.900894
Average KL loss: 0.198644
Average total loss: 1.099539
tensor(0.0017, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.5277e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.901927
Average KL loss: 0.198957
Average total loss: 1.100884
tensor(0.0018, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(4.6210e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.902896
Average KL loss: 0.198751
Average total loss: 1.101647
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.1129e-11, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.897996
Average KL loss: 0.198507
Average total loss: 1.096503
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(2.4791e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.901044
Average KL loss: 0.198305
Average total loss: 1.099349
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.0509e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.896699
Average KL loss: 0.198116
Average total loss: 1.094815
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(6.1455e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.898240
Average KL loss: 0.198024
Average total loss: 1.096264
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.6562e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.898157
Average KL loss: 0.197925
Average total loss: 1.096082
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.1586e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.899888
Average KL loss: 0.197854
Average total loss: 1.097741
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.5634e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.895680
Average KL loss: 0.197756
Average total loss: 1.093436
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.9794e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.898316
Average KL loss: 0.197685
Average total loss: 1.096002
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.1799e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.898399
Average KL loss: 0.197631
Average total loss: 1.096029
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.8132e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.897444
Average KL loss: 0.197550
Average total loss: 1.094994
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.5442e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.899291
Average KL loss: 0.197423
Average total loss: 1.096713
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-8.5441e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.894321
Average KL loss: 0.197319
Average total loss: 1.091640
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.0621e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.896821
Average KL loss: 0.197174
Average total loss: 1.093995
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(5.8633e-11, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.895651
Average KL loss: 0.197121
Average total loss: 1.092772
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(6.6529e-11, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.897752
Average KL loss: 0.197065
Average total loss: 1.094817
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.8347e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.898165
Average KL loss: 0.196991
Average total loss: 1.095155
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.4444e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.898560
Average KL loss: 0.196892
Average total loss: 1.095452
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.3765e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.895667
Average KL loss: 0.196821
Average total loss: 1.092488
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.0268e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.897425
Average KL loss: 0.196747
Average total loss: 1.094172
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.4859e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.896367
Average KL loss: 0.196705
Average total loss: 1.093072
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(2.6719e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.895719
Average KL loss: 0.196636
Average total loss: 1.092356
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.3135e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.898542
Average KL loss: 0.196547
Average total loss: 1.095089
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.3671e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.897704
Average KL loss: 0.196475
Average total loss: 1.094179
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.1002e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.897087
Average KL loss: 0.196426
Average total loss: 1.093513
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(7.2724e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.896216
Average KL loss: 0.196414
Average total loss: 1.092630
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(4.6891e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.904862
Average KL loss: 0.196403
Average total loss: 1.101266
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.6929e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.901591
Average KL loss: 0.196393
Average total loss: 1.097984
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.7470e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.898664
Average KL loss: 0.196387
Average total loss: 1.095051
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.1302e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.897044
Average KL loss: 0.196378
Average total loss: 1.093422
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-8.9788e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.898631
Average KL loss: 0.196363
Average total loss: 1.094994
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(2.3114e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.897521
Average KL loss: 0.196353
Average total loss: 1.093874
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(5.5193e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.895187
Average KL loss: 0.196350
Average total loss: 1.091537
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.0276e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.896726
Average KL loss: 0.196342
Average total loss: 1.093067
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(5.5440e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.897078
Average KL loss: 0.196331
Average total loss: 1.093409
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(4.8367e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.896413
Average KL loss: 0.196326
Average total loss: 1.092739
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(5.7546e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.897050
Average KL loss: 0.196326
Average total loss: 1.093375
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(8.5720e-11, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.897610
Average KL loss: 0.196325
Average total loss: 1.093934
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(6.5171e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.896001
Average KL loss: 0.196325
Average total loss: 1.092326
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-8.6558e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.897240
Average KL loss: 0.196324
Average total loss: 1.093564
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-7.9539e-11, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.898421
Average KL loss: 0.196323
Average total loss: 1.094745
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(2.9138e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.898661
Average KL loss: 0.196323
Average total loss: 1.094984
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(6.2593e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.895843
Average KL loss: 0.196322
Average total loss: 1.092165
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-6.9578e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.895868
Average KL loss: 0.196321
Average total loss: 1.092189
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.9859e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.899366
Average KL loss: 0.196320
Average total loss: 1.095686
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(4.5829e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.898267
Average KL loss: 0.196319
Average total loss: 1.094586
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(7.9107e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.902938
Average KL loss: 0.196319
Average total loss: 1.099257
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.1887e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.899692
Average KL loss: 0.196319
Average total loss: 1.096011
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(3.1129e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.896098
Average KL loss: 0.196319
Average total loss: 1.092417
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-8.0073e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.904428
Average KL loss: 0.196319
Average total loss: 1.100746
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-5.5126e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.895740
Average KL loss: 0.196318
Average total loss: 1.092058
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.2938e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.895458
Average KL loss: 0.196318
Average total loss: 1.091777
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.5911e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.901563
Average KL loss: 0.196318
Average total loss: 1.097881
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.0740e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.894425
Average KL loss: 0.196318
Average total loss: 1.090743
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-6.1640e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.904135
Average KL loss: 0.196318
Average total loss: 1.100453
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.2440e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.896607
Average KL loss: 0.196318
Average total loss: 1.092925
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.6466e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.896490
Average KL loss: 0.196318
Average total loss: 1.092808
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.1115e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.898278
Average KL loss: 0.196318
Average total loss: 1.094595
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.1078e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.898479
Average KL loss: 0.196318
Average total loss: 1.094797
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(4.0957e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.896985
Average KL loss: 0.196317
Average total loss: 1.093302
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(5.0382e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.898781
Average KL loss: 0.196317
Average total loss: 1.095098
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(6.8369e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.895581
Average KL loss: 0.196317
Average total loss: 1.091898
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-8.5346e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.895393
Average KL loss: 0.196317
Average total loss: 1.091710
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(2.9047e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.899390
Average KL loss: 0.196317
Average total loss: 1.095707
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-7.0139e-10, device='cuda:0')
 Percentile value: 8.133299189694299e-08
Non-zero model percentage: 0.9223561882972717%, Non-zero mask percentage: 0.9223561882972717%

--- Pruning Level [21/24]: ---
conv1.weight         | nonzeros =      56 /    1728             (  3.24%) | total_pruned =    1672 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      12 /   36864             (  0.03%) | total_pruned =   36852 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      34 /   36864             (  0.09%) | total_pruned =   36830 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =      85 /   73728             (  0.12%) | total_pruned =   73643 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     158 /  147456             (  0.11%) | total_pruned =  147298 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      16 /    8192             (  0.20%) | total_pruned =    8176 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     169 /  147456             (  0.11%) | total_pruned =  147287 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     197 /  147456             (  0.13%) | total_pruned =  147259 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     438 /  294912             (  0.15%) | total_pruned =  294474 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     104 /     256             ( 40.62%) | total_pruned =     152 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     553 /  589824             (  0.09%) | total_pruned =  589271 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      15 /   32768             (  0.05%) | total_pruned =   32753 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     285 /  589824             (  0.05%) | total_pruned =  589539 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      52 /     256             ( 20.31%) | total_pruned =     204 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     153 /  589824             (  0.03%) | total_pruned =  589671 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      33 /     256             ( 12.89%) | total_pruned =     223 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     333 / 1179648             (  0.03%) | total_pruned = 1179315 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      97 /     512             ( 18.95%) | total_pruned =     415 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     367 / 2359296             (  0.02%) | total_pruned = 2358929 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      62 /     512             ( 12.11%) | total_pruned =     450 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      21 /  131072             (  0.02%) | total_pruned =  131051 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     255 / 2359296             (  0.01%) | total_pruned = 2359041 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      48 /     512             (  9.38%) | total_pruned =     464 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   97558 / 2359296             (  4.14%) | total_pruned = 2261738 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     202 /     512             ( 39.45%) | total_pruned =     310 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     113 /     512             ( 22.07%) | total_pruned =     399 | shape = torch.Size([512])
linear.weight        | nonzeros =    1154 /    5120             ( 22.54%) | total_pruned =    3966 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 103108, pruned : 11075654, total: 11178762, Compression rate :     108.42x  ( 99.08% pruned)
Train Epoch: 94/100 Loss: 0.874344 Accuracy: 65.81 69.16 % Best test Accuracy: 65.90%
tensor(0.0017, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.6794e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.063005
Average KL loss: 0.185140
Average total loss: 1.248145
tensor(-0.0020, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.4908e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.424168
Average KL loss: 0.136762
Average total loss: 1.560930
tensor(0.0006, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-5.4115e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.242149
Average KL loss: 0.141452
Average total loss: 1.383601
tensor(0.0009, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.0836e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.168596
Average KL loss: 0.145689
Average total loss: 1.314285
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2323e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.127488
Average KL loss: 0.148600
Average total loss: 1.276088
tensor(0.0009, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.7513e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.084115
Average KL loss: 0.150887
Average total loss: 1.235002
tensor(0.0009, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.1644e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.078245
Average KL loss: 0.153638
Average total loss: 1.231882
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-8.4986e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.056869
Average KL loss: 0.156105
Average total loss: 1.212973
tensor(0.0010, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-9.9047e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.027202
Average KL loss: 0.158054
Average total loss: 1.185256
tensor(0.0010, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-6.3957e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.014907
Average KL loss: 0.160004
Average total loss: 1.174911
tensor(0.0011, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.7227e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.998794
Average KL loss: 0.161548
Average total loss: 1.160342
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.7332e-11, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.008692
Average KL loss: 0.162498
Average total loss: 1.171190
tensor(0.0011, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.7824e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.992282
Average KL loss: 0.163951
Average total loss: 1.156233
tensor(0.0011, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.0187e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.985346
Average KL loss: 0.165199
Average total loss: 1.150545
tensor(0.0011, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(4.0948e-11, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.972930
Average KL loss: 0.166263
Average total loss: 1.139193
tensor(0.0012, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.0722e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.971660
Average KL loss: 0.169162
Average total loss: 1.140821
tensor(-0.0075, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.1878e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.960993
Average KL loss: 0.169473
Average total loss: 1.130466
tensor(0.0019, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(1.6013e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.965063
Average KL loss: 0.169163
Average total loss: 1.134226
tensor(0.0011, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.3228e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.964922
Average KL loss: 0.169973
Average total loss: 1.134895
tensor(0.0012, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-3.4237e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.953395
Average KL loss: 0.170938
Average total loss: 1.124333
tensor(0.0012, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.2559e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.952077
Average KL loss: 0.174694
Average total loss: 1.126771
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(3.4524e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.950238
Average KL loss: 0.172326
Average total loss: 1.122563
tensor(0.0013, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.5108e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.950027
Average KL loss: 0.172606
Average total loss: 1.122634
tensor(0.0013, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.2627e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.944950
Average KL loss: 0.173373
Average total loss: 1.118324
tensor(0.0013, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(8.7218e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.948455
Average KL loss: 0.176808
Average total loss: 1.125263
tensor(-0.0039, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.2983e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.940730
Average KL loss: 0.175054
Average total loss: 1.115784
tensor(0.0017, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(7.0612e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.950482
Average KL loss: 0.175343
Average total loss: 1.125825
tensor(0.0013, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.2014e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.939408
Average KL loss: 0.176180
Average total loss: 1.115587
tensor(0.0013, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.7410e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.941973
Average KL loss: 0.176819
Average total loss: 1.118791
tensor(-0.0002, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.8852e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.941255
Average KL loss: 0.180819
Average total loss: 1.122074
tensor(0.0015, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.8300e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.939063
Average KL loss: 0.176786
Average total loss: 1.115848
tensor(0.0014, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.5804e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.935740
Average KL loss: 0.176909
Average total loss: 1.112650
tensor(0.0014, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.1399e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.932224
Average KL loss: 0.177422
Average total loss: 1.109646
tensor(0.0014, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(7.5486e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.931448
Average KL loss: 0.177827
Average total loss: 1.109275
tensor(0.0014, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(2.0413e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.945254
Average KL loss: 0.181637
Average total loss: 1.126891
tensor(-0.0025, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-9.8072e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.930220
Average KL loss: 0.179714
Average total loss: 1.109933
tensor(0.0019, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(1.0084e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.928895
Average KL loss: 0.179539
Average total loss: 1.108433
tensor(0.0015, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-5.5480e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.927562
Average KL loss: 0.180316
Average total loss: 1.107878
tensor(0.0015, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-3.7239e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.928702
Average KL loss: 0.180375
Average total loss: 1.109077
tensor(0.0009, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.3742e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.929174
Average KL loss: 0.183951
Average total loss: 1.113125
tensor(0.0009, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.4732e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.926741
Average KL loss: 0.180887
Average total loss: 1.107628
tensor(0.0016, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(4.9066e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.924575
Average KL loss: 0.180836
Average total loss: 1.105410
tensor(0.0015, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.1083e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.926141
Average KL loss: 0.181000
Average total loss: 1.107141
tensor(0.0015, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-2.1627e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.927446
Average KL loss: 0.182059
Average total loss: 1.109505
tensor(0.0113, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(2.4320e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.933587
Average KL loss: 0.184052
Average total loss: 1.117639
tensor(0.0024, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(2.2076e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.924993
Average KL loss: 0.181130
Average total loss: 1.106124
tensor(0.0015, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-2.4878e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.923073
Average KL loss: 0.181894
Average total loss: 1.104967
tensor(0.0015, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-9.1916e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.924623
Average KL loss: 0.182059
Average total loss: 1.106682
tensor(0.0021, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(1.4289e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.923834
Average KL loss: 0.185191
Average total loss: 1.109025
tensor(0.0018, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(6.5491e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.922178
Average KL loss: 0.182289
Average total loss: 1.104467
tensor(0.0014, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-3.9201e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.921610
Average KL loss: 0.182629
Average total loss: 1.104239
tensor(0.0016, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(1.2445e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.922359
Average KL loss: 0.183006
Average total loss: 1.105365
tensor(0.0014, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-4.8622e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.920973
Average KL loss: 0.186477
Average total loss: 1.107450
tensor(0.0042, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(6.5326e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.921874
Average KL loss: 0.183463
Average total loss: 1.105337
tensor(0.0017, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(3.2247e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.928896
Average KL loss: 0.183403
Average total loss: 1.112299
tensor(0.0016, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.6347e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.919746
Average KL loss: 0.183480
Average total loss: 1.103226
tensor(0.0016, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-4.5058e-11, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.922456
Average KL loss: 0.184092
Average total loss: 1.106547
tensor(0.0077, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(1.5266e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.924615
Average KL loss: 0.186694
Average total loss: 1.111310
tensor(0.0007, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.3028e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.926747
Average KL loss: 0.184047
Average total loss: 1.110794
tensor(0.0017, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(1.8175e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.923606
Average KL loss: 0.183555
Average total loss: 1.107161
tensor(0.0016, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.4704e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.918491
Average KL loss: 0.183771
Average total loss: 1.102262
tensor(0.0025, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(2.2076e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.919981
Average KL loss: 0.187976
Average total loss: 1.107958
tensor(0.0025, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(1.9198e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.921639
Average KL loss: 0.184808
Average total loss: 1.106447
tensor(0.0017, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.4543e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.919119
Average KL loss: 0.184978
Average total loss: 1.104097
tensor(0.0016, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(4.4149e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.917905
Average KL loss: 0.184818
Average total loss: 1.102723
tensor(0.0017, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(3.5859e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.920841
Average KL loss: 0.187602
Average total loss: 1.108443
tensor(-0.0055, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.7864e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.920443
Average KL loss: 0.186315
Average total loss: 1.106758
tensor(0.0014, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-7.2837e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.917701
Average KL loss: 0.185291
Average total loss: 1.102991
tensor(0.0017, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(4.2142e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.918449
Average KL loss: 0.185916
Average total loss: 1.104365
tensor(0.0017, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.3733e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.916654
Average KL loss: 0.186161
Average total loss: 1.102816
tensor(0.0024, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(1.8240e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.918972
Average KL loss: 0.189364
Average total loss: 1.108336
tensor(0.0034, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(4.3495e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.919707
Average KL loss: 0.186265
Average total loss: 1.105971
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.4510e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.918640
Average KL loss: 0.186315
Average total loss: 1.104955
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.4010e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.913798
Average KL loss: 0.186060
Average total loss: 1.099858
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(9.1944e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.914891
Average KL loss: 0.185869
Average total loss: 1.100760
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(5.3609e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.914481
Average KL loss: 0.185674
Average total loss: 1.100155
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.1134e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.915429
Average KL loss: 0.185519
Average total loss: 1.100949
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(7.6683e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.913739
Average KL loss: 0.185382
Average total loss: 1.099122
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.3355e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.915233
Average KL loss: 0.185267
Average total loss: 1.100500
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(3.1125e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.914982
Average KL loss: 0.185134
Average total loss: 1.100116
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.8536e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.913754
Average KL loss: 0.185057
Average total loss: 1.098811
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.3310e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.921948
Average KL loss: 0.184990
Average total loss: 1.106937
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.1756e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.914417
Average KL loss: 0.184923
Average total loss: 1.099340
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.1579e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.914217
Average KL loss: 0.184801
Average total loss: 1.099018
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.6078e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.913280
Average KL loss: 0.184739
Average total loss: 1.098018
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.7245e-11, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.915111
Average KL loss: 0.184646
Average total loss: 1.099757
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(3.5925e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.920268
Average KL loss: 0.184598
Average total loss: 1.104866
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(4.0242e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.915955
Average KL loss: 0.184539
Average total loss: 1.100494
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(3.2119e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.914055
Average KL loss: 0.184477
Average total loss: 1.098532
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.9970e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.912000
Average KL loss: 0.184379
Average total loss: 1.096378
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-6.3816e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.912847
Average KL loss: 0.184280
Average total loss: 1.097127
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.4763e-11, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.913371
Average KL loss: 0.184221
Average total loss: 1.097592
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.0947e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.915019
Average KL loss: 0.184179
Average total loss: 1.099198
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(4.3227e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.915187
Average KL loss: 0.184115
Average total loss: 1.099302
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.1607e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.913679
Average KL loss: 0.184050
Average total loss: 1.097729
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.7115e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.914572
Average KL loss: 0.183996
Average total loss: 1.098568
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(3.5467e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.915805
Average KL loss: 0.183927
Average total loss: 1.099732
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(5.1726e-11, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.913509
Average KL loss: 0.183830
Average total loss: 1.097339
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.6016e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.924194
Average KL loss: 0.183757
Average total loss: 1.107951
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.3622e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.913920
Average KL loss: 0.183664
Average total loss: 1.097584
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-5.8867e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.914413
Average KL loss: 0.183628
Average total loss: 1.098040
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.8415e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.913120
Average KL loss: 0.183605
Average total loss: 1.096725
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(5.0596e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.915879
Average KL loss: 0.183598
Average total loss: 1.099477
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-8.1383e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.914196
Average KL loss: 0.183589
Average total loss: 1.097785
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-5.4119e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.914752
Average KL loss: 0.183578
Average total loss: 1.098329
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.9580e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.914957
Average KL loss: 0.183569
Average total loss: 1.098525
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(8.0150e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.918994
Average KL loss: 0.183557
Average total loss: 1.102551
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-9.3433e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.912801
Average KL loss: 0.183546
Average total loss: 1.096347
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.2208e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.917776
Average KL loss: 0.183542
Average total loss: 1.101319
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(3.4925e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.913529
Average KL loss: 0.183538
Average total loss: 1.097067
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.6993e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.915555
Average KL loss: 0.183532
Average total loss: 1.099088
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.1633e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.915623
Average KL loss: 0.183525
Average total loss: 1.099148
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.9799e-11, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.915201
Average KL loss: 0.183523
Average total loss: 1.098724
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.5039e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.916260
Average KL loss: 0.183522
Average total loss: 1.099782
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.0571e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.918237
Average KL loss: 0.183521
Average total loss: 1.101758
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.5970e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.914441
Average KL loss: 0.183520
Average total loss: 1.097961
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.2441e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.918426
Average KL loss: 0.183520
Average total loss: 1.101946
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(6.5576e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.914384
Average KL loss: 0.183519
Average total loss: 1.097903
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(7.4847e-11, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.915329
Average KL loss: 0.183518
Average total loss: 1.098847
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.6751e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.912761
Average KL loss: 0.183518
Average total loss: 1.096279
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.9115e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.920432
Average KL loss: 0.183517
Average total loss: 1.103948
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.1705e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.913500
Average KL loss: 0.183516
Average total loss: 1.097016
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(5.2319e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.914767
Average KL loss: 0.183515
Average total loss: 1.098282
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(9.3601e-11, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.914720
Average KL loss: 0.183515
Average total loss: 1.098235
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.0846e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.916027
Average KL loss: 0.183515
Average total loss: 1.099542
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(5.0693e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.915748
Average KL loss: 0.183515
Average total loss: 1.099262
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.2788e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.913724
Average KL loss: 0.183515
Average total loss: 1.097239
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.5736e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.914743
Average KL loss: 0.183515
Average total loss: 1.098258
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-5.5345e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.922886
Average KL loss: 0.183514
Average total loss: 1.106400
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.1057e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.912988
Average KL loss: 0.183514
Average total loss: 1.096502
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(4.1435e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.914104
Average KL loss: 0.183514
Average total loss: 1.097619
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.3735e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.913341
Average KL loss: 0.183514
Average total loss: 1.096856
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-8.7819e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.914521
Average KL loss: 0.183514
Average total loss: 1.098035
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(8.9316e-10, device='cuda:0')
 Percentile value: 8.249681826555388e-08
Non-zero model percentage: 0.7378903031349182%, Non-zero mask percentage: 0.7378903031349182%

--- Pruning Level [22/24]: ---
conv1.weight         | nonzeros =      56 /    1728             (  3.24%) | total_pruned =    1672 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      11 /   36864             (  0.03%) | total_pruned =   36853 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      30 /   36864             (  0.08%) | total_pruned =   36834 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =      76 /   73728             (  0.10%) | total_pruned =   73652 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     126 /  147456             (  0.09%) | total_pruned =  147330 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      12 /    8192             (  0.15%) | total_pruned =    8180 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     146 /  147456             (  0.10%) | total_pruned =  147310 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     164 /  147456             (  0.11%) | total_pruned =  147292 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     382 /  294912             (  0.13%) | total_pruned =  294530 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      95 /     256             ( 37.11%) | total_pruned =     161 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     483 /  589824             (  0.08%) | total_pruned =  589341 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      97 /     256             ( 37.89%) | total_pruned =     159 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      11 /   32768             (  0.03%) | total_pruned =   32757 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     255 /  589824             (  0.04%) | total_pruned =  589569 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     133 /  589824             (  0.02%) | total_pruned =  589691 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      28 /     256             ( 10.94%) | total_pruned =     228 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     297 / 1179648             (  0.03%) | total_pruned = 1179351 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      91 /     512             ( 17.77%) | total_pruned =     421 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     330 / 2359296             (  0.01%) | total_pruned = 2358966 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      59 /     512             ( 11.52%) | total_pruned =     453 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      21 /  131072             (  0.02%) | total_pruned =  131051 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     228 / 2359296             (  0.01%) | total_pruned = 2359068 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   77404 / 2359296             (  3.28%) | total_pruned = 2281892 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     201 /     512             ( 39.26%) | total_pruned =     311 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     108 /     512             ( 21.09%) | total_pruned =     404 | shape = torch.Size([512])
linear.weight        | nonzeros =    1139 /    5120             ( 22.25%) | total_pruned =    3981 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 82487, pruned : 11096275, total: 11178762, Compression rate :     135.52x  ( 99.26% pruned)
Train Epoch: 56/100 Loss: 1.189281 Accuracy: 65.13 68.14 % Best test Accuracy: 65.65%
tensor(0.0017, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.7676e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.083196
Average KL loss: 0.177128
Average total loss: 1.260324
tensor(-0.0020, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0911e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.387017
Average KL loss: 0.130740
Average total loss: 1.517757
tensor(0.0005, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.1564e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.253838
Average KL loss: 0.135359
Average total loss: 1.389196
tensor(0.0008, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.8516e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.141601
Average KL loss: 0.140739
Average total loss: 1.282340
tensor(0.0009, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.3668e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.144630
Average KL loss: 0.143677
Average total loss: 1.288307
tensor(0.0009, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-8.4210e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.094705
Average KL loss: 0.146215
Average total loss: 1.240920
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.3557e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.064402
Average KL loss: 0.148450
Average total loss: 1.212852
tensor(0.0009, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.5742e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.043879
Average KL loss: 0.150466
Average total loss: 1.194345
tensor(0.0010, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-6.0856e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.032580
Average KL loss: 0.152444
Average total loss: 1.185024
tensor(0.0010, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.5766e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.020690
Average KL loss: 0.153914
Average total loss: 1.174603
tensor(0.0010, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.1681e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.024524
Average KL loss: 0.155277
Average total loss: 1.179800
tensor(0.0010, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-3.4123e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.010242
Average KL loss: 0.156430
Average total loss: 1.166672
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.3165e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.001388
Average KL loss: 0.157690
Average total loss: 1.159078
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.7901e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.007887
Average KL loss: 0.158805
Average total loss: 1.166692
tensor(0.0011, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-3.0692e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.990611
Average KL loss: 0.159350
Average total loss: 1.149961
tensor(0.0011, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.0043e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.005747
Average KL loss: 0.161648
Average total loss: 1.167395
tensor(-0.0076, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.1828e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.992402
Average KL loss: 0.162433
Average total loss: 1.154835
tensor(0.0019, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(1.5032e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.978028
Average KL loss: 0.161711
Average total loss: 1.139739
tensor(0.0011, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.4188e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.970964
Average KL loss: 0.162479
Average total loss: 1.133443
tensor(0.0012, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(4.9980e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.982223
Average KL loss: 0.162914
Average total loss: 1.145137
tensor(0.0011, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.5764e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.971561
Average KL loss: 0.166522
Average total loss: 1.138083
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(3.6664e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.967026
Average KL loss: 0.164397
Average total loss: 1.131423
tensor(0.0012, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.1214e-12, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.963574
Average KL loss: 0.164972
Average total loss: 1.128547
tensor(0.0012, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.7864e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.963018
Average KL loss: 0.165188
Average total loss: 1.128206
tensor(0.0013, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.2386e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.963817
Average KL loss: 0.168348
Average total loss: 1.132165
tensor(-0.0039, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.3044e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.971285
Average KL loss: 0.166488
Average total loss: 1.137773
tensor(0.0016, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(8.4485e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.964550
Average KL loss: 0.166350
Average total loss: 1.130901
tensor(0.0013, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.2653e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.958665
Average KL loss: 0.166623
Average total loss: 1.125288
tensor(0.0013, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.2223e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.960522
Average KL loss: 0.166969
Average total loss: 1.127490
tensor(-0.0002, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.8095e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.962265
Average KL loss: 0.171857
Average total loss: 1.134122
tensor(0.0015, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.6212e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.956768
Average KL loss: 0.168170
Average total loss: 1.124939
tensor(0.0014, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.2081e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.956646
Average KL loss: 0.168859
Average total loss: 1.125505
tensor(0.0013, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.9200e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.953676
Average KL loss: 0.169323
Average total loss: 1.123000
tensor(0.0013, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.2994e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.954564
Average KL loss: 0.169704
Average total loss: 1.124268
tensor(0.0013, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.4163e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.954256
Average KL loss: 0.173243
Average total loss: 1.127499
tensor(-0.0025, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.8183e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.953789
Average KL loss: 0.171483
Average total loss: 1.125271
tensor(0.0018, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.1631e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.954647
Average KL loss: 0.170878
Average total loss: 1.125525
tensor(0.0014, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.6955e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.951708
Average KL loss: 0.171055
Average total loss: 1.122762
tensor(0.0014, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-8.6152e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.954244
Average KL loss: 0.171479
Average total loss: 1.125724
tensor(0.0008, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.4789e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.951105
Average KL loss: 0.175044
Average total loss: 1.126149
tensor(0.0008, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.4259e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.950765
Average KL loss: 0.171687
Average total loss: 1.122451
tensor(0.0016, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(4.0230e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.954674
Average KL loss: 0.171836
Average total loss: 1.126511
tensor(0.0014, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.3955e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.948698
Average KL loss: 0.172300
Average total loss: 1.120997
tensor(0.0014, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(6.6480e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.953673
Average KL loss: 0.173115
Average total loss: 1.126789
tensor(0.0112, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(2.4330e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.946292
Average KL loss: 0.175407
Average total loss: 1.121699
tensor(0.0024, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(2.2730e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.949206
Average KL loss: 0.173193
Average total loss: 1.122399
tensor(0.0014, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.0822e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.943794
Average KL loss: 0.173311
Average total loss: 1.117105
tensor(0.0015, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(2.3601e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.949370
Average KL loss: 0.172867
Average total loss: 1.122236
tensor(0.0021, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.4898e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.945594
Average KL loss: 0.176429
Average total loss: 1.122023
tensor(0.0018, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(6.3725e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.945238
Average KL loss: 0.173582
Average total loss: 1.118820
tensor(0.0013, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-4.2022e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.947873
Average KL loss: 0.173168
Average total loss: 1.121042
tensor(0.0015, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(7.5459e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.943028
Average KL loss: 0.173148
Average total loss: 1.116176
tensor(0.0013, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-2.0367e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.949503
Average KL loss: 0.176424
Average total loss: 1.125927
tensor(0.0041, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(6.4112e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.947900
Average KL loss: 0.173524
Average total loss: 1.121424
tensor(0.0017, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(3.2979e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.942480
Average KL loss: 0.173299
Average total loss: 1.115779
tensor(0.0015, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-6.3149e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.942867
Average KL loss: 0.173393
Average total loss: 1.116259
tensor(0.0015, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-2.6178e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.944552
Average KL loss: 0.174205
Average total loss: 1.118757
tensor(0.0076, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(1.5213e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.939385
Average KL loss: 0.177182
Average total loss: 1.116567
tensor(0.0006, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.2971e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.946968
Average KL loss: 0.174849
Average total loss: 1.121817
tensor(0.0016, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(1.7845e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.941356
Average KL loss: 0.174761
Average total loss: 1.116117
tensor(0.0015, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-8.4438e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.939754
Average KL loss: 0.175018
Average total loss: 1.114773
tensor(0.0024, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(2.2361e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.938595
Average KL loss: 0.178413
Average total loss: 1.117008
tensor(0.0024, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(2.1074e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.949926
Average KL loss: 0.174905
Average total loss: 1.124831
tensor(0.0016, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-3.0039e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.943236
Average KL loss: 0.174626
Average total loss: 1.117862
tensor(0.0015, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.0728e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.941248
Average KL loss: 0.174893
Average total loss: 1.116141
tensor(0.0016, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(6.2191e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.941958
Average KL loss: 0.177309
Average total loss: 1.119267
tensor(-0.0056, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.7835e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.937964
Average KL loss: 0.176486
Average total loss: 1.114450
tensor(0.0013, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-5.8826e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.942057
Average KL loss: 0.175584
Average total loss: 1.117641
tensor(0.0016, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-8.9468e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.943184
Average KL loss: 0.175798
Average total loss: 1.118983
tensor(0.0016, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-5.7684e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.941061
Average KL loss: 0.175898
Average total loss: 1.116959
tensor(0.0024, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(1.9402e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.940084
Average KL loss: 0.178693
Average total loss: 1.118777
tensor(0.0033, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(4.2960e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.937499
Average KL loss: 0.175310
Average total loss: 1.112809
tensor(0.0016, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.2372e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.944610
Average KL loss: 0.175152
Average total loss: 1.119763
tensor(0.0016, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.3833e-11, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.941428
Average KL loss: 0.175217
Average total loss: 1.116644
tensor(0.0016, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(6.6596e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.940040
Average KL loss: 0.177840
Average total loss: 1.117879
tensor(0.0021, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.2159e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.939676
Average KL loss: 0.176530
Average total loss: 1.116206
tensor(0.0024, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.7822e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.938310
Average KL loss: 0.175540
Average total loss: 1.113849
tensor(0.0016, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-4.5902e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.939210
Average KL loss: 0.175892
Average total loss: 1.115102
tensor(0.0016, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.3035e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.942802
Average KL loss: 0.175694
Average total loss: 1.118496
tensor(0.0016, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-7.6893e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.940689
Average KL loss: 0.176212
Average total loss: 1.116901
tensor(0.0007, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.3971e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.942856
Average KL loss: 0.178942
Average total loss: 1.121798
tensor(0.0004, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.1899e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.940410
Average KL loss: 0.176250
Average total loss: 1.116659
tensor(0.0018, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(3.2698e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.938963
Average KL loss: 0.175948
Average total loss: 1.114911
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-6.4165e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.938216
Average KL loss: 0.175647
Average total loss: 1.113864
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(3.1105e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.939276
Average KL loss: 0.175439
Average total loss: 1.114715
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.6471e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.936529
Average KL loss: 0.175322
Average total loss: 1.111851
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-7.0873e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.936998
Average KL loss: 0.175202
Average total loss: 1.112201
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-7.4467e-11, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.940311
Average KL loss: 0.175069
Average total loss: 1.115381
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(5.4695e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.943265
Average KL loss: 0.174991
Average total loss: 1.118256
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(7.9755e-11, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.942348
Average KL loss: 0.174919
Average total loss: 1.117267
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.4812e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.937333
Average KL loss: 0.174879
Average total loss: 1.112212
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.0597e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.940205
Average KL loss: 0.174857
Average total loss: 1.115062
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-5.8649e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.940585
Average KL loss: 0.174844
Average total loss: 1.115429
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.9742e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.938773
Average KL loss: 0.174791
Average total loss: 1.113564
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.9260e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.946069
Average KL loss: 0.174735
Average total loss: 1.120804
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(4.0537e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.936563
Average KL loss: 0.174665
Average total loss: 1.111228
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.4702e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.937832
Average KL loss: 0.174652
Average total loss: 1.112484
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(3.1726e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.937151
Average KL loss: 0.174634
Average total loss: 1.111785
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.3604e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.937995
Average KL loss: 0.174586
Average total loss: 1.112581
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.8838e-11, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.935846
Average KL loss: 0.174536
Average total loss: 1.110382
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.1868e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.937387
Average KL loss: 0.174508
Average total loss: 1.111894
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.9607e-11, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.936751
Average KL loss: 0.174439
Average total loss: 1.111190
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(1.0339e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.936429
Average KL loss: 0.174339
Average total loss: 1.110767
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.7289e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.937453
Average KL loss: 0.174262
Average total loss: 1.111715
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.7571e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.937751
Average KL loss: 0.174189
Average total loss: 1.111940
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(6.3863e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.938414
Average KL loss: 0.174120
Average total loss: 1.112534
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-9.6870e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.936306
Average KL loss: 0.174040
Average total loss: 1.110346
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(4.4914e-11, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.936167
Average KL loss: 0.173969
Average total loss: 1.110136
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-6.3954e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.935969
Average KL loss: 0.173918
Average total loss: 1.109887
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-5.0671e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.935679
Average KL loss: 0.173815
Average total loss: 1.109494
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.0689e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.937240
Average KL loss: 0.173789
Average total loss: 1.111029
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.4856e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.935861
Average KL loss: 0.173803
Average total loss: 1.109664
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-9.6435e-11, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.937860
Average KL loss: 0.173774
Average total loss: 1.111634
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(1.4523e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.936330
Average KL loss: 0.173740
Average total loss: 1.110070
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-9.4156e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.938851
Average KL loss: 0.173731
Average total loss: 1.112582
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.5021e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.940569
Average KL loss: 0.173716
Average total loss: 1.114285
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.9401e-11, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.939476
Average KL loss: 0.173699
Average total loss: 1.113175
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.0258e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.945420
Average KL loss: 0.173677
Average total loss: 1.119097
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-5.0915e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.936352
Average KL loss: 0.173674
Average total loss: 1.110026
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.0840e-11, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.937039
Average KL loss: 0.173631
Average total loss: 1.110670
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(3.3610e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.938253
Average KL loss: 0.173583
Average total loss: 1.111836
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(4.6610e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.935675
Average KL loss: 0.173556
Average total loss: 1.109231
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.6752e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.936572
Average KL loss: 0.173545
Average total loss: 1.110117
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(3.8622e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.935881
Average KL loss: 0.173540
Average total loss: 1.109420
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.4024e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.936325
Average KL loss: 0.173535
Average total loss: 1.109860
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.1478e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.938193
Average KL loss: 0.173529
Average total loss: 1.111722
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.6846e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.939884
Average KL loss: 0.173520
Average total loss: 1.113404
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.7033e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.938981
Average KL loss: 0.173512
Average total loss: 1.112493
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(3.2361e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.943360
Average KL loss: 0.173505
Average total loss: 1.116865
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.5154e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.936818
Average KL loss: 0.173503
Average total loss: 1.110321
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(6.4293e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.936073
Average KL loss: 0.173496
Average total loss: 1.109570
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.4052e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.936737
Average KL loss: 0.173489
Average total loss: 1.110226
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(8.7315e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.943399
Average KL loss: 0.173484
Average total loss: 1.116882
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-6.1143e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.940237
Average KL loss: 0.173481
Average total loss: 1.113718
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-6.5503e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.943228
Average KL loss: 0.173481
Average total loss: 1.116709
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(3.6157e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.939280
Average KL loss: 0.173480
Average total loss: 1.112760
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.8218e-11, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.936476
Average KL loss: 0.173480
Average total loss: 1.109956
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.1746e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.938120
Average KL loss: 0.173479
Average total loss: 1.111599
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-6.5174e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.935089
Average KL loss: 0.173479
Average total loss: 1.108568
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-7.7307e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.937727
Average KL loss: 0.173479
Average total loss: 1.111206
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.1424e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.936605
Average KL loss: 0.173478
Average total loss: 1.110083
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.7849e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.938909
Average KL loss: 0.173478
Average total loss: 1.112387
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.0908e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.938514
Average KL loss: 0.173477
Average total loss: 1.111991
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-8.6114e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.936156
Average KL loss: 0.173476
Average total loss: 1.109632
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-8.9801e-11, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.936670
Average KL loss: 0.173475
Average total loss: 1.110145
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(6.3004e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.937191
Average KL loss: 0.173475
Average total loss: 1.110665
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(5.5291e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.935824
Average KL loss: 0.173474
Average total loss: 1.109298
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-7.7221e-11, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.937400
Average KL loss: 0.173474
Average total loss: 1.110875
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.3107e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.938645
Average KL loss: 0.173474
Average total loss: 1.112119
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.0578e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.943606
Average KL loss: 0.173473
Average total loss: 1.117079
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-6.5308e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.937352
Average KL loss: 0.173472
Average total loss: 1.110824
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(6.6359e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.935389
Average KL loss: 0.173472
Average total loss: 1.108861
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.3638e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.937837
Average KL loss: 0.173472
Average total loss: 1.111309
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.3680e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.936015
Average KL loss: 0.173472
Average total loss: 1.109488
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(6.3783e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.938145
Average KL loss: 0.173472
Average total loss: 1.111617
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-8.7444e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.935908
Average KL loss: 0.173472
Average total loss: 1.109379
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(3.6775e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.937163
Average KL loss: 0.173472
Average total loss: 1.110635
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-7.0500e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.938972
Average KL loss: 0.173472
Average total loss: 1.112444
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.6048e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.935429
Average KL loss: 0.173472
Average total loss: 1.108901
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(4.1130e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.934973
Average KL loss: 0.173472
Average total loss: 1.108444
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.5137e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.942510
Average KL loss: 0.173472
Average total loss: 1.115982
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(1.0834e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.940766
Average KL loss: 0.173471
Average total loss: 1.114238
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.7042e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.942611
Average KL loss: 0.173471
Average total loss: 1.116082
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(1.6153e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.937140
Average KL loss: 0.173471
Average total loss: 1.110611
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.1473e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.935484
Average KL loss: 0.173471
Average total loss: 1.108956
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-5.5107e-11, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.938232
Average KL loss: 0.173471
Average total loss: 1.111703
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.2090e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.936201
Average KL loss: 0.173471
Average total loss: 1.109672
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(6.2910e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.938666
Average KL loss: 0.173471
Average total loss: 1.112137
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-6.4728e-11, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.936109
Average KL loss: 0.173471
Average total loss: 1.109580
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(4.0469e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.939888
Average KL loss: 0.173471
Average total loss: 1.113359
tensor(0.0016, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(6.8566e-10, device='cuda:0')
 Percentile value: 8.08684106345936e-08
Non-zero model percentage: 0.5903157591819763%, Non-zero mask percentage: 0.5903157591819763%

--- Pruning Level [23/24]: ---
conv1.weight         | nonzeros =      56 /    1728             (  3.24%) | total_pruned =    1672 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      11 /   36864             (  0.03%) | total_pruned =   36853 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      28 /   36864             (  0.08%) | total_pruned =   36836 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =      75 /   73728             (  0.10%) | total_pruned =   73653 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     121 /  147456             (  0.08%) | total_pruned =  147335 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      12 /    8192             (  0.15%) | total_pruned =    8180 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     136 /  147456             (  0.09%) | total_pruned =  147320 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     152 /  147456             (  0.10%) | total_pruned =  147304 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     355 /  294912             (  0.12%) | total_pruned =  294557 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      93 /     256             ( 36.33%) | total_pruned =     163 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     449 /  589824             (  0.08%) | total_pruned =  589375 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      96 /     256             ( 37.50%) | total_pruned =     160 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      11 /   32768             (  0.03%) | total_pruned =   32757 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     238 /  589824             (  0.04%) | total_pruned =  589586 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     128 /  589824             (  0.02%) | total_pruned =  589696 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      28 /     256             ( 10.94%) | total_pruned =     228 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     274 / 1179648             (  0.02%) | total_pruned = 1179374 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      88 /     512             ( 17.19%) | total_pruned =     424 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     297 / 2359296             (  0.01%) | total_pruned = 2358999 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      59 /     512             ( 11.52%) | total_pruned =     453 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      19 /  131072             (  0.01%) | total_pruned =  131053 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     212 / 2359296             (  0.01%) | total_pruned = 2359084 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   61122 / 2359296             (  2.59%) | total_pruned = 2298174 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     200 /     512             ( 39.06%) | total_pruned =     312 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     105 /     512             ( 20.51%) | total_pruned =     407 | shape = torch.Size([512])
linear.weight        | nonzeros =    1128 /    5120             ( 22.03%) | total_pruned =    3992 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 65990, pruned : 11112772, total: 11178762, Compression rate :     169.40x  ( 99.41% pruned)
Train Epoch: 56/100 Loss: 0.984652 Accuracy: 64.47 67.36 % Best test Accuracy: 64.98%
