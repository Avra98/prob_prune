Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/24]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/100 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(2.4786e-05, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.940430
Average KL loss: 497.196815
Average total loss: 499.137234
tensor(-0.4495, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(2.3638e-05, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.740915
Average KL loss: 382.591252
Average total loss: 384.332157
tensor(-0.8686, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(2.0581e-05, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.593838
Average KL loss: 290.750908
Average total loss: 292.344737
tensor(-1.2452, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(1.7086e-05, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.529572
Average KL loss: 223.251627
Average total loss: 224.781195
tensor(-1.5745, device='cuda:0') tensor(0.0826, device='cuda:0') tensor(1.4049e-05, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.520300
Average KL loss: 175.320470
Average total loss: 176.840766
tensor(-1.8600, device='cuda:0') tensor(0.1092, device='cuda:0') tensor(1.1595e-05, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.510421
Average KL loss: 141.173891
Average total loss: 142.684308
tensor(-2.1087, device='cuda:0') tensor(0.1326, device='cuda:0') tensor(9.6770e-06, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.516606
Average KL loss: 116.361584
Average total loss: 117.878188
tensor(-2.3271, device='cuda:0') tensor(0.1529, device='cuda:0') tensor(8.2109e-06, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.524042
Average KL loss: 97.875790
Average total loss: 99.399829
tensor(-2.5210, device='cuda:0') tensor(0.1707, device='cuda:0') tensor(7.0128e-06, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.522243
Average KL loss: 83.768948
Average total loss: 85.291190
tensor(-2.6946, device='cuda:0') tensor(0.1863, device='cuda:0') tensor(6.0908e-06, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.542791
Average KL loss: 72.745819
Average total loss: 74.288609
tensor(-2.8516, device='cuda:0') tensor(0.2001, device='cuda:0') tensor(5.3918e-06, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.545880
Average KL loss: 63.955064
Average total loss: 65.500943
tensor(-2.9949, device='cuda:0') tensor(0.2124, device='cuda:0') tensor(4.7591e-06, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.572343
Average KL loss: 56.823226
Average total loss: 58.395567
tensor(-3.1262, device='cuda:0') tensor(0.2238, device='cuda:0') tensor(4.2582e-06, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.560700
Average KL loss: 50.951890
Average total loss: 52.512587
tensor(-3.2476, device='cuda:0') tensor(0.2342, device='cuda:0') tensor(3.8515e-06, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.552316
Average KL loss: 46.043240
Average total loss: 47.595555
tensor(-3.3604, device='cuda:0') tensor(0.2437, device='cuda:0') tensor(3.5095e-06, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.567541
Average KL loss: 41.887307
Average total loss: 43.454846
tensor(-3.4659, device='cuda:0') tensor(0.2526, device='cuda:0') tensor(3.1946e-06, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.571494
Average KL loss: 38.335873
Average total loss: 39.907366
tensor(-3.5647, device='cuda:0') tensor(0.2611, device='cuda:0') tensor(2.9242e-06, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.556045
Average KL loss: 35.271340
Average total loss: 36.827383
tensor(-3.6579, device='cuda:0') tensor(0.2691, device='cuda:0') tensor(2.7025e-06, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.587805
Average KL loss: 32.604979
Average total loss: 34.192782
tensor(-3.7460, device='cuda:0') tensor(0.2768, device='cuda:0') tensor(2.5103e-06, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.591291
Average KL loss: 30.269555
Average total loss: 31.860845
tensor(-3.8295, device='cuda:0') tensor(0.2842, device='cuda:0') tensor(2.3322e-06, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.580419
Average KL loss: 28.209792
Average total loss: 29.790210
tensor(-3.9088, device='cuda:0') tensor(0.2915, device='cuda:0') tensor(2.1660e-06, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.584884
Average KL loss: 26.382687
Average total loss: 27.967570
tensor(-3.9845, device='cuda:0') tensor(0.2986, device='cuda:0') tensor(2.0561e-06, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.580085
Average KL loss: 24.749367
Average total loss: 26.329452
tensor(-4.0569, device='cuda:0') tensor(0.3054, device='cuda:0') tensor(1.8867e-06, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.579630
Average KL loss: 23.284456
Average total loss: 24.864085
tensor(-4.1262, device='cuda:0') tensor(0.3121, device='cuda:0') tensor(1.8325e-06, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.587773
Average KL loss: 21.963372
Average total loss: 23.551145
tensor(-4.1928, device='cuda:0') tensor(0.3187, device='cuda:0') tensor(1.6858e-06, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.579465
Average KL loss: 20.766926
Average total loss: 22.346391
tensor(-4.2568, device='cuda:0') tensor(0.3252, device='cuda:0') tensor(1.6087e-06, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.570536
Average KL loss: 19.680012
Average total loss: 21.250548
tensor(-4.3185, device='cuda:0') tensor(0.3317, device='cuda:0') tensor(1.5143e-06, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.578422
Average KL loss: 18.689397
Average total loss: 20.267819
tensor(-4.3780, device='cuda:0') tensor(0.3380, device='cuda:0') tensor(1.4552e-06, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.568958
Average KL loss: 17.779877
Average total loss: 19.348834
tensor(-4.4356, device='cuda:0') tensor(0.3443, device='cuda:0') tensor(1.3709e-06, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.574608
Average KL loss: 16.946285
Average total loss: 18.520893
tensor(-4.4913, device='cuda:0') tensor(0.3505, device='cuda:0') tensor(1.3016e-06, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.585844
Average KL loss: 16.179137
Average total loss: 17.764980
tensor(-4.5452, device='cuda:0') tensor(0.3568, device='cuda:0') tensor(1.2468e-06, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.579765
Average KL loss: 15.470410
Average total loss: 17.050174
tensor(-4.5976, device='cuda:0') tensor(0.3629, device='cuda:0') tensor(1.1891e-06, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.565208
Average KL loss: 14.813815
Average total loss: 16.379023
tensor(-4.6485, device='cuda:0') tensor(0.3690, device='cuda:0') tensor(1.1289e-06, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.575472
Average KL loss: 14.204426
Average total loss: 15.779897
tensor(-4.6979, device='cuda:0') tensor(0.3751, device='cuda:0') tensor(1.0992e-06, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.556956
Average KL loss: 13.637322
Average total loss: 15.194278
tensor(-4.7461, device='cuda:0') tensor(0.3811, device='cuda:0') tensor(1.0640e-06, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.582010
Average KL loss: 13.107720
Average total loss: 14.689729
tensor(-4.7931, device='cuda:0') tensor(0.3871, device='cuda:0') tensor(1.0024e-06, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.577257
Average KL loss: 12.613755
Average total loss: 14.191011
tensor(-4.8390, device='cuda:0') tensor(0.3931, device='cuda:0') tensor(9.5104e-07, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.577551
Average KL loss: 12.150977
Average total loss: 13.728528
tensor(-4.8837, device='cuda:0') tensor(0.3992, device='cuda:0') tensor(9.0284e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.563848
Average KL loss: 11.718181
Average total loss: 13.282029
tensor(-4.9274, device='cuda:0') tensor(0.4052, device='cuda:0') tensor(9.1835e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.561221
Average KL loss: 11.311717
Average total loss: 12.872938
tensor(-4.9702, device='cuda:0') tensor(0.4112, device='cuda:0') tensor(8.6293e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.546134
Average KL loss: 10.928841
Average total loss: 12.474975
tensor(-5.0120, device='cuda:0') tensor(0.4172, device='cuda:0') tensor(8.2099e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.536811
Average KL loss: 10.567259
Average total loss: 12.104069
tensor(-5.0530, device='cuda:0') tensor(0.4231, device='cuda:0') tensor(8.0922e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.541069
Average KL loss: 10.225803
Average total loss: 11.766871
tensor(-5.0932, device='cuda:0') tensor(0.4290, device='cuda:0') tensor(7.7869e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.544426
Average KL loss: 9.903213
Average total loss: 11.447639
tensor(-5.1326, device='cuda:0') tensor(0.4350, device='cuda:0') tensor(7.5688e-07, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.550940
Average KL loss: 9.597365
Average total loss: 11.148305
tensor(-5.1713, device='cuda:0') tensor(0.4409, device='cuda:0') tensor(7.1251e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.526121
Average KL loss: 9.307832
Average total loss: 10.833953
tensor(-5.2093, device='cuda:0') tensor(0.4469, device='cuda:0') tensor(6.9853e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.528410
Average KL loss: 9.032831
Average total loss: 10.561241
tensor(-5.2467, device='cuda:0') tensor(0.4527, device='cuda:0') tensor(6.8619e-07, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.549271
Average KL loss: 8.771377
Average total loss: 10.320648
tensor(-5.2834, device='cuda:0') tensor(0.4587, device='cuda:0') tensor(6.5885e-07, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.523916
Average KL loss: 8.522767
Average total loss: 10.046683
tensor(-5.3195, device='cuda:0') tensor(0.4646, device='cuda:0') tensor(6.6967e-07, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.511209
Average KL loss: 8.285485
Average total loss: 9.796694
tensor(-5.3551, device='cuda:0') tensor(0.4705, device='cuda:0') tensor(6.2660e-07, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.529004
Average KL loss: 8.059499
Average total loss: 9.588503
tensor(-5.3901, device='cuda:0') tensor(0.4765, device='cuda:0') tensor(5.9948e-07, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.514446
Average KL loss: 7.844027
Average total loss: 9.358473
tensor(-5.4247, device='cuda:0') tensor(0.4824, device='cuda:0') tensor(5.6387e-07, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.499398
Average KL loss: 7.637510
Average total loss: 9.136908
tensor(-5.4587, device='cuda:0') tensor(0.4882, device='cuda:0') tensor(5.6308e-07, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.519606
Average KL loss: 7.439900
Average total loss: 8.959506
tensor(-5.4923, device='cuda:0') tensor(0.4941, device='cuda:0') tensor(5.4653e-07, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.497700
Average KL loss: 7.250867
Average total loss: 8.748567
tensor(-5.5254, device='cuda:0') tensor(0.5000, device='cuda:0') tensor(5.3785e-07, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.490128
Average KL loss: 7.070078
Average total loss: 8.560206
tensor(-5.5581, device='cuda:0') tensor(0.5059, device='cuda:0') tensor(5.2794e-07, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.510130
Average KL loss: 6.896487
Average total loss: 8.406617
tensor(-5.5904, device='cuda:0') tensor(0.5118, device='cuda:0') tensor(5.0188e-07, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.494731
Average KL loss: 6.729733
Average total loss: 8.224463
tensor(-5.6223, device='cuda:0') tensor(0.5177, device='cuda:0') tensor(5.1912e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.489769
Average KL loss: 6.570016
Average total loss: 8.059786
tensor(-5.6538, device='cuda:0') tensor(0.5237, device='cuda:0') tensor(5.0867e-07, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.487566
Average KL loss: 6.416513
Average total loss: 7.904079
tensor(-5.6850, device='cuda:0') tensor(0.5296, device='cuda:0') tensor(4.7016e-07, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.487336
Average KL loss: 6.268661
Average total loss: 7.755997
tensor(-5.7158, device='cuda:0') tensor(0.5355, device='cuda:0') tensor(4.6325e-07, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.490617
Average KL loss: 6.126600
Average total loss: 7.617217
tensor(-5.7463, device='cuda:0') tensor(0.5415, device='cuda:0') tensor(4.4262e-07, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.475734
Average KL loss: 5.989728
Average total loss: 7.465462
tensor(-5.7764, device='cuda:0') tensor(0.5474, device='cuda:0') tensor(4.1620e-07, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.493400
Average KL loss: 5.857685
Average total loss: 7.351085
tensor(-5.8063, device='cuda:0') tensor(0.5534, device='cuda:0') tensor(4.4399e-07, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.469716
Average KL loss: 5.730242
Average total loss: 7.199958
tensor(-5.8358, device='cuda:0') tensor(0.5593, device='cuda:0') tensor(4.2083e-07, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.462749
Average KL loss: 5.607360
Average total loss: 7.070109
tensor(-5.8651, device='cuda:0') tensor(0.5653, device='cuda:0') tensor(4.1261e-07, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.461835
Average KL loss: 5.488711
Average total loss: 6.950546
tensor(-5.8941, device='cuda:0') tensor(0.5713, device='cuda:0') tensor(3.9879e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.460109
Average KL loss: 5.373491
Average total loss: 6.833600
tensor(-5.9229, device='cuda:0') tensor(0.5772, device='cuda:0') tensor(3.8723e-07, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.457188
Average KL loss: 5.262430
Average total loss: 6.719618
tensor(-5.9514, device='cuda:0') tensor(0.5832, device='cuda:0') tensor(3.6154e-07, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.463229
Average KL loss: 5.155459
Average total loss: 6.618688
tensor(-5.9797, device='cuda:0') tensor(0.5893, device='cuda:0') tensor(3.7609e-07, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.459733
Average KL loss: 5.052136
Average total loss: 6.511869
tensor(-6.0077, device='cuda:0') tensor(0.5953, device='cuda:0') tensor(3.3512e-07, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.452112
Average KL loss: 4.952350
Average total loss: 6.404462
tensor(-6.0355, device='cuda:0') tensor(0.6014, device='cuda:0') tensor(3.5562e-07, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.439267
Average KL loss: 4.855267
Average total loss: 6.294534
tensor(-6.0630, device='cuda:0') tensor(0.6075, device='cuda:0') tensor(3.7348e-07, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.450869
Average KL loss: 4.760955
Average total loss: 6.211824
tensor(-6.0904, device='cuda:0') tensor(0.6136, device='cuda:0') tensor(3.3594e-07, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.435716
Average KL loss: 4.669782
Average total loss: 6.105498
tensor(-6.1176, device='cuda:0') tensor(0.6197, device='cuda:0') tensor(3.3689e-07, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.448750
Average KL loss: 4.581601
Average total loss: 6.030351
tensor(-6.1446, device='cuda:0') tensor(0.6258, device='cuda:0') tensor(3.4426e-07, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.441551
Average KL loss: 4.495575
Average total loss: 5.937126
tensor(-6.1714, device='cuda:0') tensor(0.6319, device='cuda:0') tensor(3.2885e-07, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.417984
Average KL loss: 4.412183
Average total loss: 5.830166
tensor(-6.1980, device='cuda:0') tensor(0.6380, device='cuda:0') tensor(3.0801e-07, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.427829
Average KL loss: 4.331180
Average total loss: 5.759009
tensor(-6.2245, device='cuda:0') tensor(0.6441, device='cuda:0') tensor(3.3006e-07, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.428890
Average KL loss: 4.252719
Average total loss: 5.681608
tensor(-6.2508, device='cuda:0') tensor(0.6503, device='cuda:0') tensor(2.8939e-07, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.416177
Average KL loss: 4.176339
Average total loss: 5.592516
tensor(-6.2769, device='cuda:0') tensor(0.6565, device='cuda:0') tensor(2.9492e-07, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.415113
Average KL loss: 4.102161
Average total loss: 5.517274
tensor(-6.3029, device='cuda:0') tensor(0.6627, device='cuda:0') tensor(2.8774e-07, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.412947
Average KL loss: 4.029691
Average total loss: 5.442639
tensor(-6.3287, device='cuda:0') tensor(0.6688, device='cuda:0') tensor(2.8346e-07, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.414844
Average KL loss: 3.959614
Average total loss: 5.374458
tensor(-6.3544, device='cuda:0') tensor(0.6751, device='cuda:0') tensor(2.9148e-07, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.409013
Average KL loss: 3.891403
Average total loss: 5.300416
tensor(-6.3799, device='cuda:0') tensor(0.6813, device='cuda:0') tensor(2.6312e-07, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.398938
Average KL loss: 3.824878
Average total loss: 5.223817
tensor(-6.4054, device='cuda:0') tensor(0.6875, device='cuda:0') tensor(2.5958e-07, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.394064
Average KL loss: 3.759690
Average total loss: 5.153755
tensor(-6.4307, device='cuda:0') tensor(0.6938, device='cuda:0') tensor(2.6650e-07, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.411548
Average KL loss: 3.696754
Average total loss: 5.108302
tensor(-6.4558, device='cuda:0') tensor(0.7001, device='cuda:0') tensor(2.5542e-07, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.390093
Average KL loss: 3.635545
Average total loss: 5.025638
tensor(-6.4809, device='cuda:0') tensor(0.7063, device='cuda:0') tensor(2.6010e-07, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.400198
Average KL loss: 3.575193
Average total loss: 4.975391
tensor(-6.5058, device='cuda:0') tensor(0.7126, device='cuda:0') tensor(2.3601e-07, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.381594
Average KL loss: 3.516799
Average total loss: 4.898393
tensor(-6.5306, device='cuda:0') tensor(0.7190, device='cuda:0') tensor(2.3741e-07, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.384941
Average KL loss: 3.459704
Average total loss: 4.844645
tensor(-6.5553, device='cuda:0') tensor(0.7253, device='cuda:0') tensor(2.3907e-07, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.385717
Average KL loss: 3.403772
Average total loss: 4.789489
tensor(-6.5800, device='cuda:0') tensor(0.7316, device='cuda:0') tensor(2.3433e-07, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.386409
Average KL loss: 3.349192
Average total loss: 4.735601
tensor(-6.6045, device='cuda:0') tensor(0.7379, device='cuda:0') tensor(2.4686e-07, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.376168
Average KL loss: 3.296326
Average total loss: 4.672494
tensor(-6.6289, device='cuda:0') tensor(0.7443, device='cuda:0') tensor(2.3489e-07, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.377475
Average KL loss: 3.244446
Average total loss: 4.621921
tensor(-6.6532, device='cuda:0') tensor(0.7507, device='cuda:0') tensor(1.9913e-07, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.388670
Average KL loss: 3.193969
Average total loss: 4.582639
tensor(-6.6774, device='cuda:0') tensor(0.7571, device='cuda:0') tensor(2.0614e-07, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.379600
Average KL loss: 3.145048
Average total loss: 4.524649
tensor(-6.7016, device='cuda:0') tensor(0.7636, device='cuda:0') tensor(2.1460e-07, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.382124
Average KL loss: 3.097313
Average total loss: 4.479436
tensor(-6.7257, device='cuda:0') tensor(0.7701, device='cuda:0') tensor(1.9312e-07, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.373813
Average KL loss: 3.050732
Average total loss: 4.424545
tensor(-6.7496, device='cuda:0') tensor(0.7766, device='cuda:0') tensor(2.0175e-07, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.364700
Average KL loss: 3.004871
Average total loss: 4.369571
tensor(-6.7736, device='cuda:0') tensor(0.7831, device='cuda:0') tensor(2.0606e-07, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.359124
Average KL loss: 2.960021
Average total loss: 4.319145
tensor(-6.7974, device='cuda:0') tensor(0.7896, device='cuda:0') tensor(1.9031e-07, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.352006
Average KL loss: 2.916201
Average total loss: 4.268206
tensor(-6.8212, device='cuda:0') tensor(0.7961, device='cuda:0') tensor(1.7961e-07, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.361599
Average KL loss: 2.873423
Average total loss: 4.235022
tensor(-6.8448, device='cuda:0') tensor(0.8027, device='cuda:0') tensor(2.0171e-07, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.350057
Average KL loss: 2.831493
Average total loss: 4.181550
tensor(-6.8685, device='cuda:0') tensor(0.8092, device='cuda:0') tensor(1.9168e-07, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.352241
Average KL loss: 2.790439
Average total loss: 4.142680
tensor(-6.8920, device='cuda:0') tensor(0.8158, device='cuda:0') tensor(1.8576e-07, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.347856
Average KL loss: 2.750317
Average total loss: 4.098173
tensor(-6.9156, device='cuda:0') tensor(0.8223, device='cuda:0') tensor(1.7166e-07, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.351826
Average KL loss: 2.710990
Average total loss: 4.062816
tensor(-6.9390, device='cuda:0') tensor(0.8289, device='cuda:0') tensor(1.6826e-07, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.344304
Average KL loss: 2.672448
Average total loss: 4.016752
tensor(-6.9624, device='cuda:0') tensor(0.8355, device='cuda:0') tensor(1.8527e-07, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.340020
Average KL loss: 2.634711
Average total loss: 3.974731
tensor(-6.9857, device='cuda:0') tensor(0.8421, device='cuda:0') tensor(1.6175e-07, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.346052
Average KL loss: 2.597991
Average total loss: 3.944042
tensor(-7.0090, device='cuda:0') tensor(0.8488, device='cuda:0') tensor(1.5984e-07, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.333556
Average KL loss: 2.561823
Average total loss: 3.895379
tensor(-7.0322, device='cuda:0') tensor(0.8555, device='cuda:0') tensor(1.6393e-07, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.332045
Average KL loss: 2.526310
Average total loss: 3.858356
tensor(-7.0554, device='cuda:0') tensor(0.8621, device='cuda:0') tensor(1.6827e-07, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.330346
Average KL loss: 2.491791
Average total loss: 3.822137
tensor(-7.0785, device='cuda:0') tensor(0.8688, device='cuda:0') tensor(1.6414e-07, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.321500
Average KL loss: 2.457633
Average total loss: 3.779133
tensor(-7.1016, device='cuda:0') tensor(0.8755, device='cuda:0') tensor(1.6436e-07, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.332411
Average KL loss: 2.424217
Average total loss: 3.756628
tensor(-7.1247, device='cuda:0') tensor(0.8822, device='cuda:0') tensor(1.5697e-07, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.331179
Average KL loss: 2.391587
Average total loss: 3.722766
tensor(-7.1477, device='cuda:0') tensor(0.8890, device='cuda:0') tensor(1.4757e-07, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.317691
Average KL loss: 2.359699
Average total loss: 3.677390
tensor(-7.1706, device='cuda:0') tensor(0.8958, device='cuda:0') tensor(1.4625e-07, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.316484
Average KL loss: 2.328370
Average total loss: 3.644854
tensor(-7.1936, device='cuda:0') tensor(0.9025, device='cuda:0') tensor(1.5060e-07, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.313559
Average KL loss: 2.297787
Average total loss: 3.611346
tensor(-7.2164, device='cuda:0') tensor(0.9093, device='cuda:0') tensor(1.2416e-07, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.311324
Average KL loss: 2.267571
Average total loss: 3.578895
tensor(-7.2393, device='cuda:0') tensor(0.9161, device='cuda:0') tensor(1.4065e-07, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.312370
Average KL loss: 2.238117
Average total loss: 3.550487
tensor(-7.2621, device='cuda:0') tensor(0.9229, device='cuda:0') tensor(1.4876e-07, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.296377
Average KL loss: 2.209391
Average total loss: 3.505768
tensor(-7.2849, device='cuda:0') tensor(0.9297, device='cuda:0') tensor(1.3756e-07, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.302992
Average KL loss: 2.180977
Average total loss: 3.483968
tensor(-7.3076, device='cuda:0') tensor(0.9365, device='cuda:0') tensor(1.4016e-07, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.297431
Average KL loss: 2.153043
Average total loss: 3.450474
tensor(-7.3304, device='cuda:0') tensor(0.9434, device='cuda:0') tensor(1.4301e-07, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.300767
Average KL loss: 2.125673
Average total loss: 3.426440
tensor(-7.3531, device='cuda:0') tensor(0.9502, device='cuda:0') tensor(1.3386e-07, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.297690
Average KL loss: 2.098996
Average total loss: 3.396686
tensor(-7.3757, device='cuda:0') tensor(0.9571, device='cuda:0') tensor(1.2699e-07, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.293029
Average KL loss: 2.072754
Average total loss: 3.365783
tensor(-7.3984, device='cuda:0') tensor(0.9640, device='cuda:0') tensor(1.3035e-07, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.289112
Average KL loss: 2.046815
Average total loss: 3.335927
tensor(-7.4210, device='cuda:0') tensor(0.9708, device='cuda:0') tensor(1.1916e-07, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.291491
Average KL loss: 2.021397
Average total loss: 3.312888
tensor(-7.4436, device='cuda:0') tensor(0.9777, device='cuda:0') tensor(1.2732e-07, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.289855
Average KL loss: 1.996377
Average total loss: 3.286232
tensor(-7.4661, device='cuda:0') tensor(0.9846, device='cuda:0') tensor(1.1959e-07, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.287994
Average KL loss: 1.971733
Average total loss: 3.259728
tensor(-7.4887, device='cuda:0') tensor(0.9915, device='cuda:0') tensor(1.1639e-07, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.279029
Average KL loss: 1.947688
Average total loss: 3.226717
tensor(-7.5112, device='cuda:0') tensor(0.9984, device='cuda:0') tensor(1.2256e-07, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.276267
Average KL loss: 1.923976
Average total loss: 3.200243
tensor(-7.5337, device='cuda:0') tensor(1.0053, device='cuda:0') tensor(1.2381e-07, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.281280
Average KL loss: 1.900865
Average total loss: 3.182145
tensor(-7.5562, device='cuda:0') tensor(1.0123, device='cuda:0') tensor(1.1976e-07, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.274036
Average KL loss: 1.878064
Average total loss: 3.152100
tensor(-7.5786, device='cuda:0') tensor(1.0192, device='cuda:0') tensor(1.1350e-07, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.268178
Average KL loss: 1.855714
Average total loss: 3.123892
tensor(-7.6011, device='cuda:0') tensor(1.0261, device='cuda:0') tensor(1.1474e-07, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.263099
Average KL loss: 1.833744
Average total loss: 3.096844
tensor(-7.6235, device='cuda:0') tensor(1.0331, device='cuda:0') tensor(1.0422e-07, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.267380
Average KL loss: 1.812298
Average total loss: 3.079678
tensor(-7.6459, device='cuda:0') tensor(1.0401, device='cuda:0') tensor(1.1119e-07, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.264497
Average KL loss: 1.790933
Average total loss: 3.055430
tensor(-7.6684, device='cuda:0') tensor(1.0470, device='cuda:0') tensor(1.1153e-07, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.273731
Average KL loss: 1.770080
Average total loss: 3.043810
tensor(-7.6907, device='cuda:0') tensor(1.0540, device='cuda:0') tensor(1.0899e-07, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.258840
Average KL loss: 1.749805
Average total loss: 3.008646
tensor(-7.7131, device='cuda:0') tensor(1.0610, device='cuda:0') tensor(1.0274e-07, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.260984
Average KL loss: 1.729587
Average total loss: 2.990571
tensor(-7.7355, device='cuda:0') tensor(1.0679, device='cuda:0') tensor(9.9608e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.260642
Average KL loss: 1.709765
Average total loss: 2.970407
tensor(-7.7578, device='cuda:0') tensor(1.0749, device='cuda:0') tensor(1.0078e-07, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.260533
Average KL loss: 1.690173
Average total loss: 2.950706
tensor(-7.7802, device='cuda:0') tensor(1.0818, device='cuda:0') tensor(9.7399e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.250902
Average KL loss: 1.670894
Average total loss: 2.921795
tensor(-7.8025, device='cuda:0') tensor(1.0888, device='cuda:0') tensor(9.6639e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.255291
Average KL loss: 1.652152
Average total loss: 2.907443
tensor(-7.8248, device='cuda:0') tensor(1.0958, device='cuda:0') tensor(9.7757e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.245238
Average KL loss: 1.633624
Average total loss: 2.878863
tensor(-7.8471, device='cuda:0') tensor(1.1028, device='cuda:0') tensor(9.5869e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.247796
Average KL loss: 1.615393
Average total loss: 2.863189
tensor(-7.8694, device='cuda:0') tensor(1.1098, device='cuda:0') tensor(8.1961e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.246943
Average KL loss: 1.597598
Average total loss: 2.844541
tensor(-7.8917, device='cuda:0') tensor(1.1168, device='cuda:0') tensor(9.0555e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.235077
Average KL loss: 1.579789
Average total loss: 2.814865
tensor(-7.9140, device='cuda:0') tensor(1.1238, device='cuda:0') tensor(9.7662e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.238692
Average KL loss: 1.562423
Average total loss: 2.801114
tensor(-7.9362, device='cuda:0') tensor(1.1308, device='cuda:0') tensor(8.5140e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.237088
Average KL loss: 1.545341
Average total loss: 2.782429
tensor(-7.9585, device='cuda:0') tensor(1.1377, device='cuda:0') tensor(9.1277e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.247135
Average KL loss: 1.528418
Average total loss: 2.775553
tensor(-7.9807, device='cuda:0') tensor(1.1448, device='cuda:0') tensor(9.1637e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.239452
Average KL loss: 1.512086
Average total loss: 2.751537
tensor(-8.0030, device='cuda:0') tensor(1.1518, device='cuda:0') tensor(8.6652e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.236436
Average KL loss: 1.495930
Average total loss: 2.732366
tensor(-8.0252, device='cuda:0') tensor(1.1587, device='cuda:0') tensor(8.8760e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.225737
Average KL loss: 1.479978
Average total loss: 2.705716
tensor(-8.0475, device='cuda:0') tensor(1.1657, device='cuda:0') tensor(7.7059e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 1.237241
Average KL loss: 1.464419
Average total loss: 2.701660
tensor(-8.0697, device='cuda:0') tensor(1.1727, device='cuda:0') tensor(8.1404e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 1.225147
Average KL loss: 1.448962
Average total loss: 2.674108
tensor(-8.0919, device='cuda:0') tensor(1.1797, device='cuda:0') tensor(7.8849e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 1.222808
Average KL loss: 1.433711
Average total loss: 2.656520
tensor(-8.1142, device='cuda:0') tensor(1.1866, device='cuda:0') tensor(8.3603e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 1.225244
Average KL loss: 1.418697
Average total loss: 2.643941
tensor(-8.1364, device='cuda:0') tensor(1.1936, device='cuda:0') tensor(7.0832e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 1.222496
Average KL loss: 1.403936
Average total loss: 2.626432
tensor(-8.1586, device='cuda:0') tensor(1.2005, device='cuda:0') tensor(7.7629e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 1.214218
Average KL loss: 1.389418
Average total loss: 2.603636
tensor(-8.1808, device='cuda:0') tensor(1.2074, device='cuda:0') tensor(8.6912e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 1.220190
Average KL loss: 1.374924
Average total loss: 2.595114
tensor(-8.2030, device='cuda:0') tensor(1.2143, device='cuda:0') tensor(7.2441e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 1.221915
Average KL loss: 1.360653
Average total loss: 2.582569
tensor(-8.2252, device='cuda:0') tensor(1.2212, device='cuda:0') tensor(5.9957e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 1.211357
Average KL loss: 1.346618
Average total loss: 2.557975
tensor(-8.2474, device='cuda:0') tensor(1.2281, device='cuda:0') tensor(7.3136e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 1.209435
Average KL loss: 1.333033
Average total loss: 2.542468
tensor(-8.2696, device='cuda:0') tensor(1.2351, device='cuda:0') tensor(6.8708e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 1.213394
Average KL loss: 1.319709
Average total loss: 2.533103
tensor(-8.2918, device='cuda:0') tensor(1.2419, device='cuda:0') tensor(6.7365e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 1.205229
Average KL loss: 1.306604
Average total loss: 2.511833
tensor(-8.3140, device='cuda:0') tensor(1.2488, device='cuda:0') tensor(7.2894e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 1.204724
Average KL loss: 1.293695
Average total loss: 2.498418
tensor(-8.3362, device='cuda:0') tensor(1.2557, device='cuda:0') tensor(7.0408e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 1.210171
Average KL loss: 1.280964
Average total loss: 2.491135
tensor(-8.3583, device='cuda:0') tensor(1.2626, device='cuda:0') tensor(7.1049e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 1.204633
Average KL loss: 1.268447
Average total loss: 2.473079
tensor(-8.3805, device='cuda:0') tensor(1.2694, device='cuda:0') tensor(6.8870e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 1.202632
Average KL loss: 1.256002
Average total loss: 2.458634
tensor(-8.4027, device='cuda:0') tensor(1.2763, device='cuda:0') tensor(5.9530e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 1.200381
Average KL loss: 1.243784
Average total loss: 2.444165
tensor(-8.4249, device='cuda:0') tensor(1.2831, device='cuda:0') tensor(6.7841e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 1.200722
Average KL loss: 1.231639
Average total loss: 2.432361
tensor(-8.4470, device='cuda:0') tensor(1.2899, device='cuda:0') tensor(6.2389e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 1.200030
Average KL loss: 1.219906
Average total loss: 2.419936
tensor(-8.4692, device='cuda:0') tensor(1.2966, device='cuda:0') tensor(5.8476e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 1.188695
Average KL loss: 1.208393
Average total loss: 2.397088
tensor(-8.4914, device='cuda:0') tensor(1.3034, device='cuda:0') tensor(6.4657e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 1.193055
Average KL loss: 1.196848
Average total loss: 2.389903
tensor(-8.5135, device='cuda:0') tensor(1.3101, device='cuda:0') tensor(7.0998e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 1.190461
Average KL loss: 1.185359
Average total loss: 2.375820
tensor(-8.5357, device='cuda:0') tensor(1.3168, device='cuda:0') tensor(5.3807e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 1.188153
Average KL loss: 1.174288
Average total loss: 2.362442
tensor(-8.5578, device='cuda:0') tensor(1.3235, device='cuda:0') tensor(6.2099e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 1.188094
Average KL loss: 1.163338
Average total loss: 2.351431
tensor(-8.5800, device='cuda:0') tensor(1.3302, device='cuda:0') tensor(5.7722e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 1.184146
Average KL loss: 1.152494
Average total loss: 2.336640
tensor(-8.6021, device='cuda:0') tensor(1.3369, device='cuda:0') tensor(5.4931e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 1.182247
Average KL loss: 1.141857
Average total loss: 2.324103
tensor(-8.6243, device='cuda:0') tensor(1.3435, device='cuda:0') tensor(5.6091e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 1.185638
Average KL loss: 1.131251
Average total loss: 2.316888
tensor(-8.6464, device='cuda:0') tensor(1.3502, device='cuda:0') tensor(5.1199e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 1.183925
Average KL loss: 1.120908
Average total loss: 2.304833
tensor(-8.6686, device='cuda:0') tensor(1.3568, device='cuda:0') tensor(5.4298e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 1.182517
Average KL loss: 1.110602
Average total loss: 2.293120
tensor(-8.6907, device='cuda:0') tensor(1.3633, device='cuda:0') tensor(5.6832e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 1.185745
Average KL loss: 1.100625
Average total loss: 2.286370
tensor(-8.7129, device='cuda:0') tensor(1.3699, device='cuda:0') tensor(5.7266e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 1.173311
Average KL loss: 1.090802
Average total loss: 2.264113
tensor(-8.7350, device='cuda:0') tensor(1.3765, device='cuda:0') tensor(4.5257e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 1.176157
Average KL loss: 1.081178
Average total loss: 2.257335
tensor(-8.7571, device='cuda:0') tensor(1.3830, device='cuda:0') tensor(5.9118e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 1.172194
Average KL loss: 1.071603
Average total loss: 2.243798
tensor(-8.7792, device='cuda:0') tensor(1.3895, device='cuda:0') tensor(4.4333e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 1.172210
Average KL loss: 1.062140
Average total loss: 2.234350
tensor(-8.8014, device='cuda:0') tensor(1.3960, device='cuda:0') tensor(4.6984e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 1.169512
Average KL loss: 1.052858
Average total loss: 2.222370
tensor(-8.8235, device='cuda:0') tensor(1.4024, device='cuda:0') tensor(4.8201e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 1.170815
Average KL loss: 1.043754
Average total loss: 2.214569
tensor(-8.8456, device='cuda:0') tensor(1.4088, device='cuda:0') tensor(4.5250e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 1.169569
Average KL loss: 1.034784
Average total loss: 2.204353
tensor(-8.8677, device='cuda:0') tensor(1.4151, device='cuda:0') tensor(4.5663e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 1.165047
Average KL loss: 1.026023
Average total loss: 2.191069
tensor(-8.8898, device='cuda:0') tensor(1.4215, device='cuda:0') tensor(4.0924e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 1.161872
Average KL loss: 1.017324
Average total loss: 2.179197
tensor(-8.9119, device='cuda:0') tensor(1.4278, device='cuda:0') tensor(4.4087e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 1.167329
Average KL loss: 1.008864
Average total loss: 2.176192
tensor(-8.9340, device='cuda:0') tensor(1.4341, device='cuda:0') tensor(4.0183e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 1.158160
Average KL loss: 1.000552
Average total loss: 2.158712
tensor(-8.9561, device='cuda:0') tensor(1.4403, device='cuda:0') tensor(3.8633e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 1.162211
Average KL loss: 0.992292
Average total loss: 2.154503
tensor(-8.9782, device='cuda:0') tensor(1.4466, device='cuda:0') tensor(4.3614e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 1.157788
Average KL loss: 0.984245
Average total loss: 2.142033
tensor(-9.0003, device='cuda:0') tensor(1.4527, device='cuda:0') tensor(4.8463e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 1.158468
Average KL loss: 0.976185
Average total loss: 2.134653
 Percentile value: -9.79512882232666
Non-zero model percentage: 80.0%, Non-zero mask percentage: 80.0%

--- Pruning Level [1/24]: ---
conv1.weight         | nonzeros =    1724 /    1728             ( 99.77%) | total_pruned =       4 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36050 /   36864             ( 97.79%) | total_pruned =     814 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36064 /   36864             ( 97.83%) | total_pruned =     800 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   35824 /   36864             ( 97.18%) | total_pruned =    1040 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   35695 /   36864             ( 96.83%) | total_pruned =    1169 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   71528 /   73728             ( 97.02%) | total_pruned =    2200 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  140782 /  147456             ( 95.47%) | total_pruned =    6674 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8130 /    8192             ( 99.24%) | total_pruned =      62 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  139101 /  147456             ( 94.33%) | total_pruned =    8355 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  138283 /  147456             ( 93.78%) | total_pruned =    9173 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  276246 /  294912             ( 93.67%) | total_pruned =   18666 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  534103 /  589824             ( 90.55%) | total_pruned =   55721 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   31911 /   32768             ( 97.38%) | total_pruned =     857 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  500239 /  589824             ( 84.81%) | total_pruned =   89585 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  492436 /  589824             ( 83.49%) | total_pruned =   97388 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1022716 / 1179648             ( 86.70%) | total_pruned =  156932 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1870361 / 2359296             ( 79.28%) | total_pruned =  488935 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  124167 /  131072             ( 94.73%) | total_pruned =    6905 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1756606 / 2359296             ( 74.45%) | total_pruned =  602690 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1676331 / 2359296             ( 71.05%) | total_pruned =  682965 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5107 /    5120             ( 99.75%) | total_pruned =      13 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 8943010, pruned : 2235752, total: 11178762, Compression rate :       1.25x  ( 20.00% pruned)
Train Epoch: 30/100 Loss: 0.000009 Accuracy: 86.97 100.00 % Best test Accuracy: 87.00%
tensor(-9.0223, device='cuda:0') tensor(1.4589, device='cuda:0') tensor(5.2660e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.169654
Average KL loss: 0.893976
Average total loss: 2.063630
tensor(-9.2575, device='cuda:0') tensor(1.2710, device='cuda:0') tensor(3.8306e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.162560
Average KL loss: 0.797424
Average total loss: 1.959984
tensor(-9.4554, device='cuda:0') tensor(1.1525, device='cuda:0') tensor(2.5870e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.163026
Average KL loss: 0.744116
Average total loss: 1.907142
tensor(-9.6246, device='cuda:0') tensor(1.0734, device='cuda:0') tensor(2.4733e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.159476
Average KL loss: 0.709741
Average total loss: 1.869217
tensor(-9.7724, device='cuda:0') tensor(1.0174, device='cuda:0') tensor(1.5610e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.152461
Average KL loss: 0.685552
Average total loss: 1.838014
tensor(-9.9038, device='cuda:0') tensor(0.9762, device='cuda:0') tensor(1.9083e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.153135
Average KL loss: 0.667352
Average total loss: 1.820487
tensor(-10.0222, device='cuda:0') tensor(0.9447, device='cuda:0') tensor(1.7797e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.146100
Average KL loss: 0.653122
Average total loss: 1.799222
tensor(-10.1298, device='cuda:0') tensor(0.9203, device='cuda:0') tensor(1.6929e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.143765
Average KL loss: 0.641601
Average total loss: 1.785365
tensor(-10.2286, device='cuda:0') tensor(0.9009, device='cuda:0') tensor(1.4436e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.144743
Average KL loss: 0.632103
Average total loss: 1.776846
tensor(-10.3199, device='cuda:0') tensor(0.8853, device='cuda:0') tensor(1.5939e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.140925
Average KL loss: 0.623852
Average total loss: 1.764777
tensor(-10.4047, device='cuda:0') tensor(0.8726, device='cuda:0') tensor(8.2540e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.143406
Average KL loss: 0.616784
Average total loss: 1.760191
tensor(-10.4839, device='cuda:0') tensor(0.8621, device='cuda:0') tensor(1.2353e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.137361
Average KL loss: 0.610548
Average total loss: 1.747908
tensor(-10.5582, device='cuda:0') tensor(0.8533, device='cuda:0') tensor(1.7624e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.134697
Average KL loss: 0.604986
Average total loss: 1.739683
tensor(-10.6282, device='cuda:0') tensor(0.8460, device='cuda:0') tensor(1.2612e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.136577
Average KL loss: 0.600067
Average total loss: 1.736644
tensor(-10.6943, device='cuda:0') tensor(0.8398, device='cuda:0') tensor(9.4133e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.137215
Average KL loss: 0.595611
Average total loss: 1.732826
tensor(-10.7571, device='cuda:0') tensor(0.8345, device='cuda:0') tensor(8.9639e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.134634
Average KL loss: 0.591387
Average total loss: 1.726022
tensor(-10.8167, device='cuda:0') tensor(0.8300, device='cuda:0') tensor(7.8932e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.131861
Average KL loss: 0.587608
Average total loss: 1.719469
tensor(-10.8735, device='cuda:0') tensor(0.8261, device='cuda:0') tensor(1.0868e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.127419
Average KL loss: 0.583854
Average total loss: 1.711272
tensor(-10.9278, device='cuda:0') tensor(0.8227, device='cuda:0') tensor(9.1145e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.132001
Average KL loss: 0.580435
Average total loss: 1.712437
tensor(-10.9797, device='cuda:0') tensor(0.8198, device='cuda:0') tensor(1.1840e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.130088
Average KL loss: 0.577334
Average total loss: 1.707422
tensor(-11.0295, device='cuda:0') tensor(0.8173, device='cuda:0') tensor(8.5352e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.121562
Average KL loss: 0.574374
Average total loss: 1.695937
tensor(-11.0773, device='cuda:0') tensor(0.8151, device='cuda:0') tensor(1.2205e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.119057
Average KL loss: 0.571472
Average total loss: 1.690529
tensor(-11.1233, device='cuda:0') tensor(0.8131, device='cuda:0') tensor(1.0949e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.122017
Average KL loss: 0.568611
Average total loss: 1.690627
tensor(-11.1677, device='cuda:0') tensor(0.8113, device='cuda:0') tensor(9.7435e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.115254
Average KL loss: 0.565835
Average total loss: 1.681089
tensor(-11.2105, device='cuda:0') tensor(0.8098, device='cuda:0') tensor(1.0327e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.118941
Average KL loss: 0.563201
Average total loss: 1.682143
tensor(-11.2518, device='cuda:0') tensor(0.8084, device='cuda:0') tensor(1.2806e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.125570
Average KL loss: 0.560711
Average total loss: 1.686282
tensor(-11.2917, device='cuda:0') tensor(0.8071, device='cuda:0') tensor(1.1190e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.111174
Average KL loss: 0.558408
Average total loss: 1.669583
tensor(-11.3304, device='cuda:0') tensor(0.8060, device='cuda:0') tensor(9.8541e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.109981
Average KL loss: 0.556211
Average total loss: 1.666192
tensor(-11.3679, device='cuda:0') tensor(0.8051, device='cuda:0') tensor(1.1752e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.112948
Average KL loss: 0.554054
Average total loss: 1.667002
tensor(-11.4043, device='cuda:0') tensor(0.8042, device='cuda:0') tensor(8.7455e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.118269
Average KL loss: 0.551990
Average total loss: 1.670258
tensor(-11.4396, device='cuda:0') tensor(0.8033, device='cuda:0') tensor(1.1492e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.105172
Average KL loss: 0.550027
Average total loss: 1.655199
tensor(-11.4740, device='cuda:0') tensor(0.8026, device='cuda:0') tensor(3.6090e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.113426
Average KL loss: 0.548067
Average total loss: 1.661493
tensor(-11.5074, device='cuda:0') tensor(0.8019, device='cuda:0') tensor(8.1796e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.109628
Average KL loss: 0.546240
Average total loss: 1.655868
tensor(-11.5399, device='cuda:0') tensor(0.8013, device='cuda:0') tensor(6.3185e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.101035
Average KL loss: 0.544517
Average total loss: 1.645551
tensor(-11.5715, device='cuda:0') tensor(0.8008, device='cuda:0') tensor(9.3665e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.102577
Average KL loss: 0.542743
Average total loss: 1.645320
tensor(-11.6024, device='cuda:0') tensor(0.8002, device='cuda:0') tensor(7.2283e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.101616
Average KL loss: 0.541023
Average total loss: 1.642639
tensor(-11.6325, device='cuda:0') tensor(0.7997, device='cuda:0') tensor(9.8899e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.101806
Average KL loss: 0.539381
Average total loss: 1.641187
tensor(-11.6619, device='cuda:0') tensor(0.7992, device='cuda:0') tensor(6.1013e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.091388
Average KL loss: 0.537691
Average total loss: 1.629078
tensor(-11.6906, device='cuda:0') tensor(0.7987, device='cuda:0') tensor(6.8488e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.097153
Average KL loss: 0.536078
Average total loss: 1.633232
tensor(-11.7186, device='cuda:0') tensor(0.7983, device='cuda:0') tensor(1.6363e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.099494
Average KL loss: 0.534524
Average total loss: 1.634018
tensor(-11.7460, device='cuda:0') tensor(0.7978, device='cuda:0') tensor(7.0650e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.096924
Average KL loss: 0.532887
Average total loss: 1.629811
tensor(-11.7728, device='cuda:0') tensor(0.7974, device='cuda:0') tensor(1.1394e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.095789
Average KL loss: 0.531350
Average total loss: 1.627139
tensor(-11.7990, device='cuda:0') tensor(0.7969, device='cuda:0') tensor(9.3393e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.098474
Average KL loss: 0.529787
Average total loss: 1.628261
tensor(-11.8247, device='cuda:0') tensor(0.7966, device='cuda:0') tensor(7.7751e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.090928
Average KL loss: 0.528332
Average total loss: 1.619260
tensor(-11.8499, device='cuda:0') tensor(0.7962, device='cuda:0') tensor(3.0565e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.088684
Average KL loss: 0.526816
Average total loss: 1.615500
tensor(-11.8745, device='cuda:0') tensor(0.7958, device='cuda:0') tensor(5.0494e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.088848
Average KL loss: 0.525396
Average total loss: 1.614244
tensor(-11.8987, device='cuda:0') tensor(0.7954, device='cuda:0') tensor(6.6655e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.088546
Average KL loss: 0.524081
Average total loss: 1.612627
tensor(-11.9224, device='cuda:0') tensor(0.7950, device='cuda:0') tensor(9.8879e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.080783
Average KL loss: 0.522724
Average total loss: 1.603507
tensor(-11.9456, device='cuda:0') tensor(0.7946, device='cuda:0') tensor(6.6693e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.086134
Average KL loss: 0.521414
Average total loss: 1.607548
tensor(-11.9684, device='cuda:0') tensor(0.7942, device='cuda:0') tensor(9.1768e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.082703
Average KL loss: 0.520189
Average total loss: 1.602891
tensor(-11.9908, device='cuda:0') tensor(0.7938, device='cuda:0') tensor(8.6581e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.083248
Average KL loss: 0.518922
Average total loss: 1.602169
tensor(-12.0128, device='cuda:0') tensor(0.7934, device='cuda:0') tensor(9.5254e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.088692
Average KL loss: 0.517679
Average total loss: 1.606371
tensor(-12.0344, device='cuda:0') tensor(0.7930, device='cuda:0') tensor(6.7336e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.075102
Average KL loss: 0.516554
Average total loss: 1.591656
tensor(-12.0556, device='cuda:0') tensor(0.7926, device='cuda:0') tensor(2.2190e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.075019
Average KL loss: 0.515346
Average total loss: 1.590366
tensor(-12.0765, device='cuda:0') tensor(0.7922, device='cuda:0') tensor(7.8322e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.079503
Average KL loss: 0.514130
Average total loss: 1.593633
tensor(-12.0970, device='cuda:0') tensor(0.7918, device='cuda:0') tensor(2.6094e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.079683
Average KL loss: 0.512835
Average total loss: 1.592518
tensor(-12.1172, device='cuda:0') tensor(0.7914, device='cuda:0') tensor(1.0266e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.071832
Average KL loss: 0.511656
Average total loss: 1.583489
tensor(-12.1371, device='cuda:0') tensor(0.7909, device='cuda:0') tensor(4.0810e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.068020
Average KL loss: 0.510515
Average total loss: 1.578535
tensor(-12.1566, device='cuda:0') tensor(0.7905, device='cuda:0') tensor(6.3943e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.068115
Average KL loss: 0.509263
Average total loss: 1.577378
tensor(-12.1758, device='cuda:0') tensor(0.7901, device='cuda:0') tensor(8.9596e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.076595
Average KL loss: 0.508146
Average total loss: 1.584741
tensor(-12.1947, device='cuda:0') tensor(0.7897, device='cuda:0') tensor(1.1218e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.074265
Average KL loss: 0.507099
Average total loss: 1.581364
tensor(-12.2134, device='cuda:0') tensor(0.7892, device='cuda:0') tensor(-1.6249e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.068439
Average KL loss: 0.505955
Average total loss: 1.574394
tensor(-12.2317, device='cuda:0') tensor(0.7887, device='cuda:0') tensor(6.6115e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.069047
Average KL loss: 0.504869
Average total loss: 1.573917
tensor(-12.2498, device='cuda:0') tensor(0.7882, device='cuda:0') tensor(7.1475e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.072002
Average KL loss: 0.503900
Average total loss: 1.575902
tensor(-12.2677, device='cuda:0') tensor(0.7877, device='cuda:0') tensor(7.6963e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.065118
Average KL loss: 0.502870
Average total loss: 1.567988
tensor(-12.2852, device='cuda:0') tensor(0.7872, device='cuda:0') tensor(9.0107e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.059088
Average KL loss: 0.501865
Average total loss: 1.560953
tensor(-12.3025, device='cuda:0') tensor(0.7867, device='cuda:0') tensor(8.2242e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.065813
Average KL loss: 0.500913
Average total loss: 1.566726
tensor(-12.3196, device='cuda:0') tensor(0.7862, device='cuda:0') tensor(7.3678e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.065034
Average KL loss: 0.499884
Average total loss: 1.564918
tensor(-12.3365, device='cuda:0') tensor(0.7856, device='cuda:0') tensor(4.2281e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.059316
Average KL loss: 0.498811
Average total loss: 1.558127
tensor(-12.3531, device='cuda:0') tensor(0.7850, device='cuda:0') tensor(7.1069e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.059561
Average KL loss: 0.497731
Average total loss: 1.557291
tensor(-12.3695, device='cuda:0') tensor(0.7845, device='cuda:0') tensor(3.1947e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.057192
Average KL loss: 0.496757
Average total loss: 1.553949
tensor(-12.3856, device='cuda:0') tensor(0.7839, device='cuda:0') tensor(1.6281e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.058306
Average KL loss: 0.495847
Average total loss: 1.554153
tensor(-12.4016, device='cuda:0') tensor(0.7833, device='cuda:0') tensor(5.9588e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.061010
Average KL loss: 0.494825
Average total loss: 1.555835
tensor(-12.4173, device='cuda:0') tensor(0.7827, device='cuda:0') tensor(1.0065e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.059006
Average KL loss: 0.493943
Average total loss: 1.552950
tensor(-12.4329, device='cuda:0') tensor(0.7821, device='cuda:0') tensor(9.1833e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.049505
Average KL loss: 0.493051
Average total loss: 1.542556
tensor(-12.4482, device='cuda:0') tensor(0.7815, device='cuda:0') tensor(2.0313e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.051415
Average KL loss: 0.492053
Average total loss: 1.543467
tensor(-12.4634, device='cuda:0') tensor(0.7808, device='cuda:0') tensor(2.9366e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.049834
Average KL loss: 0.491011
Average total loss: 1.540845
tensor(-12.4783, device='cuda:0') tensor(0.7801, device='cuda:0') tensor(2.8716e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.047593
Average KL loss: 0.489992
Average total loss: 1.537584
tensor(-12.4931, device='cuda:0') tensor(0.7795, device='cuda:0') tensor(6.0869e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.046557
Average KL loss: 0.489085
Average total loss: 1.535642
tensor(-12.5077, device='cuda:0') tensor(0.7788, device='cuda:0') tensor(6.6491e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.046404
Average KL loss: 0.488200
Average total loss: 1.534604
tensor(-12.5222, device='cuda:0') tensor(0.7782, device='cuda:0') tensor(9.2198e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.052455
Average KL loss: 0.487275
Average total loss: 1.539729
tensor(-12.5364, device='cuda:0') tensor(0.7775, device='cuda:0') tensor(6.3693e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.040877
Average KL loss: 0.486329
Average total loss: 1.527206
tensor(-12.5505, device='cuda:0') tensor(0.7768, device='cuda:0') tensor(8.2753e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.045085
Average KL loss: 0.485494
Average total loss: 1.530579
tensor(-12.5645, device='cuda:0') tensor(0.7761, device='cuda:0') tensor(5.1473e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.043791
Average KL loss: 0.484719
Average total loss: 1.528510
tensor(-12.5782, device='cuda:0') tensor(0.7754, device='cuda:0') tensor(5.7996e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.044629
Average KL loss: 0.483862
Average total loss: 1.528491
tensor(-12.5918, device='cuda:0') tensor(0.7747, device='cuda:0') tensor(3.6416e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.048853
Average KL loss: 0.483060
Average total loss: 1.531914
tensor(-12.6053, device='cuda:0') tensor(0.7740, device='cuda:0') tensor(5.1813e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.038030
Average KL loss: 0.482211
Average total loss: 1.520240
tensor(-12.6186, device='cuda:0') tensor(0.7733, device='cuda:0') tensor(5.9118e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.041155
Average KL loss: 0.481334
Average total loss: 1.522489
tensor(-12.6318, device='cuda:0') tensor(0.7725, device='cuda:0') tensor(7.3672e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.041942
Average KL loss: 0.480479
Average total loss: 1.522421
tensor(-12.6448, device='cuda:0') tensor(0.7717, device='cuda:0') tensor(5.5913e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.042405
Average KL loss: 0.479625
Average total loss: 1.522030
tensor(-12.6577, device='cuda:0') tensor(0.7710, device='cuda:0') tensor(4.9211e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.039074
Average KL loss: 0.478814
Average total loss: 1.517888
tensor(-12.6704, device='cuda:0') tensor(0.7702, device='cuda:0') tensor(7.6068e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.040116
Average KL loss: 0.478023
Average total loss: 1.518140
tensor(-12.6831, device='cuda:0') tensor(0.7694, device='cuda:0') tensor(7.9979e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.034909
Average KL loss: 0.477311
Average total loss: 1.512220
tensor(-12.6955, device='cuda:0') tensor(0.7686, device='cuda:0') tensor(5.0389e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.036291
Average KL loss: 0.476612
Average total loss: 1.512903
tensor(-12.7079, device='cuda:0') tensor(0.7678, device='cuda:0') tensor(4.7062e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.031627
Average KL loss: 0.475905
Average total loss: 1.507532
tensor(-12.7201, device='cuda:0') tensor(0.7670, device='cuda:0') tensor(5.5549e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.026489
Average KL loss: 0.475084
Average total loss: 1.501572
tensor(-12.7322, device='cuda:0') tensor(0.7662, device='cuda:0') tensor(5.3745e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.030704
Average KL loss: 0.474261
Average total loss: 1.504965
tensor(-12.7442, device='cuda:0') tensor(0.7653, device='cuda:0') tensor(4.6032e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.030986
Average KL loss: 0.473606
Average total loss: 1.504592
tensor(-12.7560, device='cuda:0') tensor(0.7645, device='cuda:0') tensor(7.6995e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.028120
Average KL loss: 0.472938
Average total loss: 1.501058
tensor(-12.7678, device='cuda:0') tensor(0.7637, device='cuda:0') tensor(5.0639e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.027189
Average KL loss: 0.472177
Average total loss: 1.499366
tensor(-12.7794, device='cuda:0') tensor(0.7628, device='cuda:0') tensor(2.9848e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.030702
Average KL loss: 0.471464
Average total loss: 1.502165
tensor(-12.7909, device='cuda:0') tensor(0.7619, device='cuda:0') tensor(2.3431e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.024215
Average KL loss: 0.470737
Average total loss: 1.494952
tensor(-12.8023, device='cuda:0') tensor(0.7610, device='cuda:0') tensor(6.3509e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.028887
Average KL loss: 0.469953
Average total loss: 1.498840
tensor(-12.8136, device='cuda:0') tensor(0.7601, device='cuda:0') tensor(4.3510e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.021268
Average KL loss: 0.469307
Average total loss: 1.490575
tensor(-12.8248, device='cuda:0') tensor(0.7592, device='cuda:0') tensor(6.5169e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.022554
Average KL loss: 0.468559
Average total loss: 1.491113
tensor(-12.8359, device='cuda:0') tensor(0.7583, device='cuda:0') tensor(2.6123e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.024308
Average KL loss: 0.467850
Average total loss: 1.492158
tensor(-12.8468, device='cuda:0') tensor(0.7574, device='cuda:0') tensor(5.9197e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.022762
Average KL loss: 0.467093
Average total loss: 1.489855
tensor(-12.8577, device='cuda:0') tensor(0.7565, device='cuda:0') tensor(9.6949e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.020052
Average KL loss: 0.466364
Average total loss: 1.486416
tensor(-12.8685, device='cuda:0') tensor(0.7556, device='cuda:0') tensor(1.8224e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.019557
Average KL loss: 0.465660
Average total loss: 1.485217
tensor(-12.8792, device='cuda:0') tensor(0.7546, device='cuda:0') tensor(2.1384e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.020619
Average KL loss: 0.464969
Average total loss: 1.485588
tensor(-12.8897, device='cuda:0') tensor(0.7537, device='cuda:0') tensor(6.5259e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.018868
Average KL loss: 0.464385
Average total loss: 1.483252
tensor(-12.9002, device='cuda:0') tensor(0.7528, device='cuda:0') tensor(7.4092e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.020269
Average KL loss: 0.463770
Average total loss: 1.484040
tensor(-12.9106, device='cuda:0') tensor(0.7518, device='cuda:0') tensor(4.9256e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.017464
Average KL loss: 0.463112
Average total loss: 1.480576
tensor(-12.9209, device='cuda:0') tensor(0.7509, device='cuda:0') tensor(5.6234e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.016440
Average KL loss: 0.462429
Average total loss: 1.478870
tensor(-12.9311, device='cuda:0') tensor(0.7499, device='cuda:0') tensor(9.4054e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.012819
Average KL loss: 0.461753
Average total loss: 1.474571
tensor(-12.9412, device='cuda:0') tensor(0.7489, device='cuda:0') tensor(5.3766e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.013471
Average KL loss: 0.461136
Average total loss: 1.474606
tensor(-12.9513, device='cuda:0') tensor(0.7479, device='cuda:0') tensor(3.4879e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.012208
Average KL loss: 0.460478
Average total loss: 1.472686
tensor(-12.9612, device='cuda:0') tensor(0.7469, device='cuda:0') tensor(4.4854e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.016857
Average KL loss: 0.459883
Average total loss: 1.476740
tensor(-12.9711, device='cuda:0') tensor(0.7459, device='cuda:0') tensor(1.6624e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.009531
Average KL loss: 0.459290
Average total loss: 1.468821
tensor(-12.9809, device='cuda:0') tensor(0.7449, device='cuda:0') tensor(4.5745e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.012590
Average KL loss: 0.458570
Average total loss: 1.471159
tensor(-12.9906, device='cuda:0') tensor(0.7439, device='cuda:0') tensor(1.1080e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.009333
Average KL loss: 0.457977
Average total loss: 1.467310
tensor(-13.0002, device='cuda:0') tensor(0.7429, device='cuda:0') tensor(3.7069e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.009038
Average KL loss: 0.457430
Average total loss: 1.466468
tensor(-13.0097, device='cuda:0') tensor(0.7419, device='cuda:0') tensor(5.5205e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.008549
Average KL loss: 0.456875
Average total loss: 1.465424
tensor(-13.0192, device='cuda:0') tensor(0.7409, device='cuda:0') tensor(2.0336e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.007265
Average KL loss: 0.456315
Average total loss: 1.463580
tensor(-13.0286, device='cuda:0') tensor(0.7398, device='cuda:0') tensor(6.3428e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.006240
Average KL loss: 0.455693
Average total loss: 1.461933
tensor(-13.0379, device='cuda:0') tensor(0.7388, device='cuda:0') tensor(3.3801e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.006922
Average KL loss: 0.455114
Average total loss: 1.462036
tensor(-13.0471, device='cuda:0') tensor(0.7378, device='cuda:0') tensor(3.3097e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.005566
Average KL loss: 0.454505
Average total loss: 1.460071
tensor(-13.0563, device='cuda:0') tensor(0.7367, device='cuda:0') tensor(1.3999e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.000056
Average KL loss: 0.453941
Average total loss: 1.453997
tensor(-13.0654, device='cuda:0') tensor(0.7356, device='cuda:0') tensor(1.5479e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.002370
Average KL loss: 0.453376
Average total loss: 1.455746
tensor(-13.0744, device='cuda:0') tensor(0.7346, device='cuda:0') tensor(6.0310e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.000364
Average KL loss: 0.452809
Average total loss: 1.453173
tensor(-13.0833, device='cuda:0') tensor(0.7334, device='cuda:0') tensor(1.3460e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.999660
Average KL loss: 0.452239
Average total loss: 1.451900
tensor(-13.0922, device='cuda:0') tensor(0.7323, device='cuda:0') tensor(4.3723e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.998885
Average KL loss: 0.451657
Average total loss: 1.450543
tensor(-13.1010, device='cuda:0') tensor(0.7312, device='cuda:0') tensor(6.5380e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.000250
Average KL loss: 0.451035
Average total loss: 1.451285
tensor(-13.1098, device='cuda:0') tensor(0.7301, device='cuda:0') tensor(4.5583e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.997226
Average KL loss: 0.450509
Average total loss: 1.447734
tensor(-13.1184, device='cuda:0') tensor(0.7290, device='cuda:0') tensor(4.1824e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.998095
Average KL loss: 0.449944
Average total loss: 1.448039
tensor(-13.1270, device='cuda:0') tensor(0.7279, device='cuda:0') tensor(4.9056e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.997548
Average KL loss: 0.449356
Average total loss: 1.446904
tensor(-13.1356, device='cuda:0') tensor(0.7267, device='cuda:0') tensor(2.4947e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.998559
Average KL loss: 0.448789
Average total loss: 1.447347
tensor(-13.1441, device='cuda:0') tensor(0.7256, device='cuda:0') tensor(6.6143e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.992521
Average KL loss: 0.448253
Average total loss: 1.440774
tensor(-13.1525, device='cuda:0') tensor(0.7245, device='cuda:0') tensor(5.9277e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.994831
Average KL loss: 0.447771
Average total loss: 1.442602
tensor(-13.1609, device='cuda:0') tensor(0.7233, device='cuda:0') tensor(5.5458e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.991777
Average KL loss: 0.447228
Average total loss: 1.439006
tensor(-13.1692, device='cuda:0') tensor(0.7222, device='cuda:0') tensor(1.0194e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.989640
Average KL loss: 0.446660
Average total loss: 1.436300
tensor(-13.1774, device='cuda:0') tensor(0.7210, device='cuda:0') tensor(5.0927e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.990896
Average KL loss: 0.446152
Average total loss: 1.437048
tensor(-13.1856, device='cuda:0') tensor(0.7199, device='cuda:0') tensor(5.1636e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.994777
Average KL loss: 0.445618
Average total loss: 1.440395
tensor(-13.1937, device='cuda:0') tensor(0.7187, device='cuda:0') tensor(2.6034e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.985949
Average KL loss: 0.445132
Average total loss: 1.431081
tensor(-13.2018, device='cuda:0') tensor(0.7175, device='cuda:0') tensor(4.4418e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.988667
Average KL loss: 0.444666
Average total loss: 1.433332
tensor(-13.2098, device='cuda:0') tensor(0.7164, device='cuda:0') tensor(4.6003e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.989115
Average KL loss: 0.444142
Average total loss: 1.433257
tensor(-13.2177, device='cuda:0') tensor(0.7152, device='cuda:0') tensor(3.5978e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.989711
Average KL loss: 0.443660
Average total loss: 1.433372
tensor(-13.2256, device='cuda:0') tensor(0.7140, device='cuda:0') tensor(3.2665e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.988011
Average KL loss: 0.443149
Average total loss: 1.431160
tensor(-13.2335, device='cuda:0') tensor(0.7128, device='cuda:0') tensor(5.8522e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.986352
Average KL loss: 0.442664
Average total loss: 1.429016
tensor(-13.2412, device='cuda:0') tensor(0.7116, device='cuda:0') tensor(1.6595e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.986213
Average KL loss: 0.442254
Average total loss: 1.428467
tensor(-13.2490, device='cuda:0') tensor(0.7105, device='cuda:0') tensor(1.0965e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.984238
Average KL loss: 0.441822
Average total loss: 1.426060
tensor(-13.2567, device='cuda:0') tensor(0.7093, device='cuda:0') tensor(4.7983e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.984135
Average KL loss: 0.441307
Average total loss: 1.425442
tensor(-13.2643, device='cuda:0') tensor(0.7080, device='cuda:0') tensor(3.9078e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.983650
Average KL loss: 0.440798
Average total loss: 1.424448
tensor(-13.2719, device='cuda:0') tensor(0.7068, device='cuda:0') tensor(1.9662e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.985505
Average KL loss: 0.440306
Average total loss: 1.425811
tensor(-13.2794, device='cuda:0') tensor(0.7056, device='cuda:0') tensor(4.5881e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.982209
Average KL loss: 0.439806
Average total loss: 1.422015
tensor(-13.2869, device='cuda:0') tensor(0.7044, device='cuda:0') tensor(1.4286e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.980475
Average KL loss: 0.439335
Average total loss: 1.419810
tensor(-13.2943, device='cuda:0') tensor(0.7032, device='cuda:0') tensor(4.7531e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.984454
Average KL loss: 0.438858
Average total loss: 1.423313
tensor(-13.3017, device='cuda:0') tensor(0.7020, device='cuda:0') tensor(2.5630e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.981896
Average KL loss: 0.438451
Average total loss: 1.420346
tensor(-13.3090, device='cuda:0') tensor(0.7008, device='cuda:0') tensor(3.1582e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.977556
Average KL loss: 0.438054
Average total loss: 1.415610
tensor(-13.3163, device='cuda:0') tensor(0.6995, device='cuda:0') tensor(1.8766e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.978682
Average KL loss: 0.437617
Average total loss: 1.416299
tensor(-13.3235, device='cuda:0') tensor(0.6983, device='cuda:0') tensor(3.3284e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.977032
Average KL loss: 0.437202
Average total loss: 1.414233
tensor(-13.3307, device='cuda:0') tensor(0.6971, device='cuda:0') tensor(4.2643e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.977668
Average KL loss: 0.436791
Average total loss: 1.414459
tensor(-13.3379, device='cuda:0') tensor(0.6958, device='cuda:0') tensor(1.2642e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.980582
Average KL loss: 0.436348
Average total loss: 1.416931
tensor(-13.3450, device='cuda:0') tensor(0.6946, device='cuda:0') tensor(3.1214e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.979453
Average KL loss: 0.435917
Average total loss: 1.415370
tensor(-13.3520, device='cuda:0') tensor(0.6934, device='cuda:0') tensor(4.0150e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.976301
Average KL loss: 0.435514
Average total loss: 1.411815
tensor(-13.3590, device='cuda:0') tensor(0.6922, device='cuda:0') tensor(3.7265e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.972685
Average KL loss: 0.435108
Average total loss: 1.407793
tensor(-13.3660, device='cuda:0') tensor(0.6909, device='cuda:0') tensor(3.4505e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.978399
Average KL loss: 0.434597
Average total loss: 1.412996
tensor(-13.3729, device='cuda:0') tensor(0.6897, device='cuda:0') tensor(5.7796e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.977787
Average KL loss: 0.434139
Average total loss: 1.411926
tensor(-13.3798, device='cuda:0') tensor(0.6884, device='cuda:0') tensor(2.5215e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.972213
Average KL loss: 0.433708
Average total loss: 1.405922
tensor(-13.3866, device='cuda:0') tensor(0.6872, device='cuda:0') tensor(6.7886e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.973014
Average KL loss: 0.433295
Average total loss: 1.406309
tensor(-13.3934, device='cuda:0') tensor(0.6859, device='cuda:0') tensor(1.2935e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.975725
Average KL loss: 0.432900
Average total loss: 1.408625
tensor(-13.4002, device='cuda:0') tensor(0.6846, device='cuda:0') tensor(3.7131e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.973122
Average KL loss: 0.432510
Average total loss: 1.405633
tensor(-13.4069, device='cuda:0') tensor(0.6833, device='cuda:0') tensor(1.8553e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.969447
Average KL loss: 0.432116
Average total loss: 1.401564
tensor(-13.4136, device='cuda:0') tensor(0.6821, device='cuda:0') tensor(6.0827e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.974260
Average KL loss: 0.431714
Average total loss: 1.405974
tensor(-13.4202, device='cuda:0') tensor(0.6808, device='cuda:0') tensor(8.7195e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.971163
Average KL loss: 0.431335
Average total loss: 1.402498
tensor(-13.4268, device='cuda:0') tensor(0.6795, device='cuda:0') tensor(2.5473e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.969968
Average KL loss: 0.430977
Average total loss: 1.400945
tensor(-13.4334, device='cuda:0') tensor(0.6782, device='cuda:0') tensor(2.3458e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.974518
Average KL loss: 0.430593
Average total loss: 1.405111
tensor(-13.4399, device='cuda:0') tensor(0.6769, device='cuda:0') tensor(3.0645e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.968778
Average KL loss: 0.430207
Average total loss: 1.398985
tensor(-13.4464, device='cuda:0') tensor(0.6756, device='cuda:0') tensor(2.0317e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.966877
Average KL loss: 0.429805
Average total loss: 1.396681
tensor(-13.4528, device='cuda:0') tensor(0.6743, device='cuda:0') tensor(5.9722e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.970218
Average KL loss: 0.429394
Average total loss: 1.399612
tensor(-13.4593, device='cuda:0') tensor(0.6731, device='cuda:0') tensor(2.7756e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.966890
Average KL loss: 0.429121
Average total loss: 1.396011
tensor(-13.4656, device='cuda:0') tensor(0.6718, device='cuda:0') tensor(6.4237e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.965128
Average KL loss: 0.428763
Average total loss: 1.393891
tensor(-13.4720, device='cuda:0') tensor(0.6705, device='cuda:0') tensor(1.3191e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.967316
Average KL loss: 0.428288
Average total loss: 1.395604
tensor(-13.4783, device='cuda:0') tensor(0.6692, device='cuda:0') tensor(7.5104e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.967067
Average KL loss: 0.427932
Average total loss: 1.394999
tensor(-13.4845, device='cuda:0') tensor(0.6679, device='cuda:0') tensor(2.3581e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.964094
Average KL loss: 0.427539
Average total loss: 1.391633
tensor(-13.4908, device='cuda:0') tensor(0.6666, device='cuda:0') tensor(3.1528e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.963098
Average KL loss: 0.427246
Average total loss: 1.390343
tensor(-13.4970, device='cuda:0') tensor(0.6653, device='cuda:0') tensor(4.9509e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.967901
Average KL loss: 0.426868
Average total loss: 1.394769
tensor(-13.5031, device='cuda:0') tensor(0.6640, device='cuda:0') tensor(4.8591e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.962838
Average KL loss: 0.426462
Average total loss: 1.389299
tensor(-13.5092, device='cuda:0') tensor(0.6627, device='cuda:0') tensor(3.0686e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.962753
Average KL loss: 0.426134
Average total loss: 1.388886
tensor(-13.5153, device='cuda:0') tensor(0.6614, device='cuda:0') tensor(2.4641e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.962285
Average KL loss: 0.425795
Average total loss: 1.388080
tensor(-13.5214, device='cuda:0') tensor(0.6601, device='cuda:0') tensor(2.6311e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.959095
Average KL loss: 0.425491
Average total loss: 1.384587
tensor(-13.5274, device='cuda:0') tensor(0.6588, device='cuda:0') tensor(3.4515e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.960591
Average KL loss: 0.425206
Average total loss: 1.385798
tensor(-13.5334, device='cuda:0') tensor(0.6575, device='cuda:0') tensor(1.4642e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.959418
Average KL loss: 0.424899
Average total loss: 1.384316
tensor(-13.5394, device='cuda:0') tensor(0.6562, device='cuda:0') tensor(2.1381e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.960776
Average KL loss: 0.424560
Average total loss: 1.385336
tensor(-13.5453, device='cuda:0') tensor(0.6549, device='cuda:0') tensor(1.9454e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.957707
Average KL loss: 0.424226
Average total loss: 1.381933
tensor(-13.5512, device='cuda:0') tensor(0.6536, device='cuda:0') tensor(3.6373e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.957603
Average KL loss: 0.423937
Average total loss: 1.381540
tensor(-13.5571, device='cuda:0') tensor(0.6522, device='cuda:0') tensor(3.9554e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.960504
Average KL loss: 0.423688
Average total loss: 1.384192
tensor(-13.5629, device='cuda:0') tensor(0.6509, device='cuda:0') tensor(4.8376e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.957310
Average KL loss: 0.423466
Average total loss: 1.380776
tensor(-13.5687, device='cuda:0') tensor(0.6496, device='cuda:0') tensor(5.1923e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.956767
Average KL loss: 0.423162
Average total loss: 1.379929
tensor(-13.5745, device='cuda:0') tensor(0.6483, device='cuda:0') tensor(3.7272e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.956577
Average KL loss: 0.422861
Average total loss: 1.379439
 Percentile value: -13.72966480255127
Non-zero model percentage: 64.0%, Non-zero mask percentage: 64.0%

--- Pruning Level [2/24]: ---
conv1.weight         | nonzeros =    1721 /    1728             ( 99.59%) | total_pruned =       7 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   35154 /   36864             ( 95.36%) | total_pruned =    1710 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   35226 /   36864             ( 95.56%) | total_pruned =    1638 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   34721 /   36864             ( 94.19%) | total_pruned =    2143 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   34335 /   36864             ( 93.14%) | total_pruned =    2529 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   69216 /   73728             ( 93.88%) | total_pruned =    4512 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  133553 /  147456             ( 90.57%) | total_pruned =   13903 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8057 /    8192             ( 98.35%) | total_pruned =     135 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  130015 /  147456             ( 88.17%) | total_pruned =   17441 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  128064 /  147456             ( 86.85%) | total_pruned =   19392 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  255747 /  294912             ( 86.72%) | total_pruned =   39165 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  472733 /  589824             ( 80.15%) | total_pruned =  117091 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   30973 /   32768             ( 94.52%) | total_pruned =    1795 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  406827 /  589824             ( 68.97%) | total_pruned =  182997 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  394852 /  589824             ( 66.94%) | total_pruned =  194972 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  854148 / 1179648             ( 72.41%) | total_pruned =  325500 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1420897 / 2359296             ( 60.23%) | total_pruned =  938399 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  116510 /  131072             ( 88.89%) | total_pruned =   14562 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1312353 / 2359296             ( 55.62%) | total_pruned = 1046943 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1264606 / 2359296             ( 53.60%) | total_pruned = 1094690 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5096 /    5120             ( 99.53%) | total_pruned =      24 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 7154408, pruned : 4024354, total: 11178762, Compression rate :       1.56x  ( 36.00% pruned)
Train Epoch: 31/100 Loss: 0.000035 Accuracy: 86.61 100.00 % Best test Accuracy: 86.78%
tensor(-13.5802, device='cuda:0') tensor(0.6470, device='cuda:0') tensor(2.3071e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.974478
Average KL loss: 0.417694
Average total loss: 1.392172
tensor(-13.5901, device='cuda:0') tensor(0.5965, device='cuda:0') tensor(2.1989e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.971697
Average KL loss: 0.412595
Average total loss: 1.384292
tensor(-13.5990, device='cuda:0') tensor(0.5613, device='cuda:0') tensor(5.3187e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.971483
Average KL loss: 0.410061
Average total loss: 1.381544
tensor(-13.6072, device='cuda:0') tensor(0.5348, device='cuda:0') tensor(1.0003e-11, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.972593
Average KL loss: 0.408484
Average total loss: 1.381077
tensor(-13.6150, device='cuda:0') tensor(0.5139, device='cuda:0') tensor(-2.3515e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.971353
Average KL loss: 0.407370
Average total loss: 1.378723
tensor(-13.6224, device='cuda:0') tensor(0.4967, device='cuda:0') tensor(-2.7324e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.970099
Average KL loss: 0.406574
Average total loss: 1.376673
tensor(-13.6296, device='cuda:0') tensor(0.4821, device='cuda:0') tensor(3.8318e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.968501
Average KL loss: 0.405919
Average total loss: 1.374420
tensor(-13.6365, device='cuda:0') tensor(0.4696, device='cuda:0') tensor(-1.0700e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.970152
Average KL loss: 0.405451
Average total loss: 1.375603
tensor(-13.6434, device='cuda:0') tensor(0.4586, device='cuda:0') tensor(1.2147e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.968318
Average KL loss: 0.405053
Average total loss: 1.373371
tensor(-13.6500, device='cuda:0') tensor(0.4488, device='cuda:0') tensor(3.0624e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.967997
Average KL loss: 0.404673
Average total loss: 1.372669
tensor(-13.6565, device='cuda:0') tensor(0.4400, device='cuda:0') tensor(1.3435e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.963135
Average KL loss: 0.404331
Average total loss: 1.367466
tensor(-13.6629, device='cuda:0') tensor(0.4321, device='cuda:0') tensor(3.8097e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.963178
Average KL loss: 0.404061
Average total loss: 1.367238
tensor(-13.6692, device='cuda:0') tensor(0.4249, device='cuda:0') tensor(1.8591e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.964021
Average KL loss: 0.403745
Average total loss: 1.367766
tensor(-13.6755, device='cuda:0') tensor(0.4183, device='cuda:0') tensor(2.5700e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.961181
Average KL loss: 0.403459
Average total loss: 1.364640
tensor(-13.6816, device='cuda:0') tensor(0.4123, device='cuda:0') tensor(-2.2402e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.960767
Average KL loss: 0.403242
Average total loss: 1.364010
tensor(-13.6876, device='cuda:0') tensor(0.4067, device='cuda:0') tensor(-9.1012e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.958779
Average KL loss: 0.403043
Average total loss: 1.361822
tensor(-13.6936, device='cuda:0') tensor(0.4015, device='cuda:0') tensor(-2.0899e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.963638
Average KL loss: 0.402821
Average total loss: 1.366459
tensor(-13.6995, device='cuda:0') tensor(0.3967, device='cuda:0') tensor(-1.3742e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.958237
Average KL loss: 0.402556
Average total loss: 1.360792
tensor(-13.7054, device='cuda:0') tensor(0.3921, device='cuda:0') tensor(1.1125e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.955479
Average KL loss: 0.402331
Average total loss: 1.357810
tensor(-13.7112, device='cuda:0') tensor(0.3879, device='cuda:0') tensor(-5.6946e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.957588
Average KL loss: 0.402160
Average total loss: 1.359749
tensor(-13.7169, device='cuda:0') tensor(0.3839, device='cuda:0') tensor(1.3494e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.957963
Average KL loss: 0.402048
Average total loss: 1.360011
tensor(-13.7226, device='cuda:0') tensor(0.3802, device='cuda:0') tensor(-2.4749e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.955087
Average KL loss: 0.401902
Average total loss: 1.356989
tensor(-13.7282, device='cuda:0') tensor(0.3767, device='cuda:0') tensor(1.1856e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.956301
Average KL loss: 0.401768
Average total loss: 1.358069
tensor(-13.7338, device='cuda:0') tensor(0.3734, device='cuda:0') tensor(-1.1029e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.952670
Average KL loss: 0.401602
Average total loss: 1.354272
tensor(-13.7393, device='cuda:0') tensor(0.3702, device='cuda:0') tensor(-1.4769e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.956386
Average KL loss: 0.401402
Average total loss: 1.357788
tensor(-13.7448, device='cuda:0') tensor(0.3672, device='cuda:0') tensor(4.3407e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.958676
Average KL loss: 0.401268
Average total loss: 1.359944
tensor(-13.7502, device='cuda:0') tensor(0.3643, device='cuda:0') tensor(2.1496e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.953269
Average KL loss: 0.401077
Average total loss: 1.354345
tensor(-13.7556, device='cuda:0') tensor(0.3616, device='cuda:0') tensor(2.2748e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.955436
Average KL loss: 0.400896
Average total loss: 1.356332
tensor(-13.7609, device='cuda:0') tensor(0.3590, device='cuda:0') tensor(1.4976e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.952387
Average KL loss: 0.400753
Average total loss: 1.353140
tensor(-13.7662, device='cuda:0') tensor(0.3565, device='cuda:0') tensor(8.9142e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.950578
Average KL loss: 0.400622
Average total loss: 1.351200
tensor(-13.7715, device='cuda:0') tensor(0.3542, device='cuda:0') tensor(2.9163e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.950735
Average KL loss: 0.400486
Average total loss: 1.351220
tensor(-13.7768, device='cuda:0') tensor(0.3519, device='cuda:0') tensor(2.5072e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.952970
Average KL loss: 0.400323
Average total loss: 1.353293
tensor(-13.7820, device='cuda:0') tensor(0.3498, device='cuda:0') tensor(6.4999e-11, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.948607
Average KL loss: 0.400153
Average total loss: 1.348760
tensor(-13.7871, device='cuda:0') tensor(0.3477, device='cuda:0') tensor(8.3805e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.948908
Average KL loss: 0.400005
Average total loss: 1.348914
tensor(-13.7922, device='cuda:0') tensor(0.3457, device='cuda:0') tensor(2.9069e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.947427
Average KL loss: 0.399896
Average total loss: 1.347323
tensor(-13.7973, device='cuda:0') tensor(0.3438, device='cuda:0') tensor(-1.0685e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.950133
Average KL loss: 0.399772
Average total loss: 1.349905
tensor(-13.8024, device='cuda:0') tensor(0.3420, device='cuda:0') tensor(-8.3856e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.952618
Average KL loss: 0.399605
Average total loss: 1.352223
tensor(-13.8074, device='cuda:0') tensor(0.3402, device='cuda:0') tensor(-1.0834e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.948525
Average KL loss: 0.399460
Average total loss: 1.347986
tensor(-13.8124, device='cuda:0') tensor(0.3385, device='cuda:0') tensor(-3.3519e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.949086
Average KL loss: 0.399314
Average total loss: 1.348401
tensor(-13.8174, device='cuda:0') tensor(0.3369, device='cuda:0') tensor(-4.7072e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.943749
Average KL loss: 0.399170
Average total loss: 1.342919
tensor(-13.8223, device='cuda:0') tensor(0.3353, device='cuda:0') tensor(3.9512e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.945039
Average KL loss: 0.399044
Average total loss: 1.344083
tensor(-13.8272, device='cuda:0') tensor(0.3338, device='cuda:0') tensor(9.5542e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.943527
Average KL loss: 0.398904
Average total loss: 1.342431
tensor(-13.8321, device='cuda:0') tensor(0.3323, device='cuda:0') tensor(-6.7100e-12, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.944778
Average KL loss: 0.398763
Average total loss: 1.343541
tensor(-13.8370, device='cuda:0') tensor(0.3309, device='cuda:0') tensor(2.0714e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.944446
Average KL loss: 0.398596
Average total loss: 1.343043
tensor(-13.8418, device='cuda:0') tensor(0.3295, device='cuda:0') tensor(-1.6180e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.940995
Average KL loss: 0.398403
Average total loss: 1.339399
tensor(-13.8466, device='cuda:0') tensor(0.3281, device='cuda:0') tensor(-3.1218e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.941957
Average KL loss: 0.398271
Average total loss: 1.340228
tensor(-13.8513, device='cuda:0') tensor(0.3268, device='cuda:0') tensor(-4.9476e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.943270
Average KL loss: 0.398170
Average total loss: 1.341440
tensor(-13.8561, device='cuda:0') tensor(0.3256, device='cuda:0') tensor(-1.2524e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.938066
Average KL loss: 0.398026
Average total loss: 1.336092
tensor(-13.8608, device='cuda:0') tensor(0.3244, device='cuda:0') tensor(8.8292e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.938941
Average KL loss: 0.397882
Average total loss: 1.336824
tensor(-13.8655, device='cuda:0') tensor(0.3232, device='cuda:0') tensor(2.0857e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.940161
Average KL loss: 0.397739
Average total loss: 1.337900
tensor(-13.8702, device='cuda:0') tensor(0.3221, device='cuda:0') tensor(5.0381e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.939129
Average KL loss: 0.397632
Average total loss: 1.336760
tensor(-13.8748, device='cuda:0') tensor(0.3210, device='cuda:0') tensor(-2.0047e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.940284
Average KL loss: 0.397568
Average total loss: 1.337853
tensor(-13.8794, device='cuda:0') tensor(0.3199, device='cuda:0') tensor(5.5691e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.939246
Average KL loss: 0.397455
Average total loss: 1.336700
tensor(-13.8840, device='cuda:0') tensor(0.3189, device='cuda:0') tensor(-1.0414e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.938985
Average KL loss: 0.397303
Average total loss: 1.336288
tensor(-13.8886, device='cuda:0') tensor(0.3179, device='cuda:0') tensor(7.3323e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.941134
Average KL loss: 0.397177
Average total loss: 1.338311
tensor(-13.8931, device='cuda:0') tensor(0.3169, device='cuda:0') tensor(-9.2457e-11, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.938620
Average KL loss: 0.397125
Average total loss: 1.335745
tensor(-13.8976, device='cuda:0') tensor(0.3159, device='cuda:0') tensor(-5.5595e-11, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.939217
Average KL loss: 0.397084
Average total loss: 1.336301
tensor(-13.9021, device='cuda:0') tensor(0.3150, device='cuda:0') tensor(6.3913e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.939507
Average KL loss: 0.396980
Average total loss: 1.336487
tensor(-13.9066, device='cuda:0') tensor(0.3141, device='cuda:0') tensor(-5.0281e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.937760
Average KL loss: 0.396883
Average total loss: 1.334643
tensor(-13.9110, device='cuda:0') tensor(0.3132, device='cuda:0') tensor(-4.1016e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.938620
Average KL loss: 0.396755
Average total loss: 1.335376
tensor(-13.9155, device='cuda:0') tensor(0.3123, device='cuda:0') tensor(-1.2963e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.934809
Average KL loss: 0.396640
Average total loss: 1.331449
tensor(-13.9199, device='cuda:0') tensor(0.3115, device='cuda:0') tensor(7.7508e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.935338
Average KL loss: 0.396527
Average total loss: 1.331866
tensor(-13.9243, device='cuda:0') tensor(0.3107, device='cuda:0') tensor(-1.3697e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.935644
Average KL loss: 0.396385
Average total loss: 1.332029
tensor(-13.9286, device='cuda:0') tensor(0.3098, device='cuda:0') tensor(1.2852e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.933089
Average KL loss: 0.396230
Average total loss: 1.329319
tensor(-13.9330, device='cuda:0') tensor(0.3091, device='cuda:0') tensor(1.1251e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.934144
Average KL loss: 0.396130
Average total loss: 1.330274
tensor(-13.9373, device='cuda:0') tensor(0.3083, device='cuda:0') tensor(5.8430e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.935945
Average KL loss: 0.396031
Average total loss: 1.331976
tensor(-13.9416, device='cuda:0') tensor(0.3075, device='cuda:0') tensor(-1.3803e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.936099
Average KL loss: 0.395907
Average total loss: 1.332007
tensor(-13.9459, device='cuda:0') tensor(0.3068, device='cuda:0') tensor(1.9275e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.933944
Average KL loss: 0.395826
Average total loss: 1.329770
tensor(-13.9502, device='cuda:0') tensor(0.3061, device='cuda:0') tensor(3.0569e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.929986
Average KL loss: 0.395720
Average total loss: 1.325706
tensor(-13.9544, device='cuda:0') tensor(0.3053, device='cuda:0') tensor(1.7738e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.931270
Average KL loss: 0.395592
Average total loss: 1.326862
tensor(-13.9586, device='cuda:0') tensor(0.3047, device='cuda:0') tensor(1.5790e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.934475
Average KL loss: 0.395551
Average total loss: 1.330025
tensor(-13.9628, device='cuda:0') tensor(0.3040, device='cuda:0') tensor(9.9023e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.931214
Average KL loss: 0.395488
Average total loss: 1.326702
tensor(-13.9670, device='cuda:0') tensor(0.3034, device='cuda:0') tensor(-1.3039e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.930960
Average KL loss: 0.395407
Average total loss: 1.326367
tensor(-13.9712, device='cuda:0') tensor(0.3027, device='cuda:0') tensor(7.1889e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.931095
Average KL loss: 0.395316
Average total loss: 1.326410
tensor(-13.9753, device='cuda:0') tensor(0.3021, device='cuda:0') tensor(2.3923e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.930999
Average KL loss: 0.395207
Average total loss: 1.326206
tensor(-13.9795, device='cuda:0') tensor(0.3015, device='cuda:0') tensor(3.4490e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.933647
Average KL loss: 0.395118
Average total loss: 1.328765
tensor(-13.9836, device='cuda:0') tensor(0.3009, device='cuda:0') tensor(2.2392e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.929226
Average KL loss: 0.395099
Average total loss: 1.324325
tensor(-13.9877, device='cuda:0') tensor(0.3003, device='cuda:0') tensor(5.3315e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.928414
Average KL loss: 0.395094
Average total loss: 1.323508
tensor(-13.9918, device='cuda:0') tensor(0.2998, device='cuda:0') tensor(-1.1360e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.930294
Average KL loss: 0.394993
Average total loss: 1.325287
tensor(-13.9958, device='cuda:0') tensor(0.2992, device='cuda:0') tensor(1.1056e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.928266
Average KL loss: 0.394926
Average total loss: 1.323192
tensor(-13.9999, device='cuda:0') tensor(0.2987, device='cuda:0') tensor(4.5347e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.928754
Average KL loss: 0.394889
Average total loss: 1.323643
tensor(-14.0039, device='cuda:0') tensor(0.2982, device='cuda:0') tensor(2.5790e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.928803
Average KL loss: 0.394829
Average total loss: 1.323632
tensor(-14.0079, device='cuda:0') tensor(0.2976, device='cuda:0') tensor(3.5793e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.929662
Average KL loss: 0.394793
Average total loss: 1.324454
tensor(-14.0119, device='cuda:0') tensor(0.2971, device='cuda:0') tensor(1.5131e-12, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.926882
Average KL loss: 0.394706
Average total loss: 1.321588
tensor(-14.0159, device='cuda:0') tensor(0.2966, device='cuda:0') tensor(6.6448e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.930719
Average KL loss: 0.394634
Average total loss: 1.325353
tensor(-14.0198, device='cuda:0') tensor(0.2961, device='cuda:0') tensor(1.5607e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.930028
Average KL loss: 0.394542
Average total loss: 1.324570
tensor(-14.0238, device='cuda:0') tensor(0.2957, device='cuda:0') tensor(-8.1920e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.925387
Average KL loss: 0.394440
Average total loss: 1.319826
tensor(-14.0277, device='cuda:0') tensor(0.2952, device='cuda:0') tensor(1.0043e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.927359
Average KL loss: 0.394320
Average total loss: 1.321679
tensor(-14.0316, device='cuda:0') tensor(0.2947, device='cuda:0') tensor(7.1058e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.925834
Average KL loss: 0.394229
Average total loss: 1.320063
tensor(-14.0355, device='cuda:0') tensor(0.2942, device='cuda:0') tensor(4.2310e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.927694
Average KL loss: 0.394127
Average total loss: 1.321820
tensor(-14.0394, device='cuda:0') tensor(0.2938, device='cuda:0') tensor(1.5339e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.924451
Average KL loss: 0.394049
Average total loss: 1.318500
tensor(-14.0432, device='cuda:0') tensor(0.2934, device='cuda:0') tensor(9.5231e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.925221
Average KL loss: 0.393946
Average total loss: 1.319167
tensor(-14.0471, device='cuda:0') tensor(0.2929, device='cuda:0') tensor(4.3846e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.923335
Average KL loss: 0.393864
Average total loss: 1.317199
tensor(-14.0509, device='cuda:0') tensor(0.2925, device='cuda:0') tensor(-1.9378e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.924465
Average KL loss: 0.393833
Average total loss: 1.318299
tensor(-14.0547, device='cuda:0') tensor(0.2921, device='cuda:0') tensor(2.3024e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.923175
Average KL loss: 0.393738
Average total loss: 1.316913
tensor(-14.0585, device='cuda:0') tensor(0.2916, device='cuda:0') tensor(-1.2463e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.925920
Average KL loss: 0.393663
Average total loss: 1.319583
tensor(-14.0623, device='cuda:0') tensor(0.2912, device='cuda:0') tensor(4.3184e-11, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.921117
Average KL loss: 0.393568
Average total loss: 1.314685
tensor(-14.0661, device='cuda:0') tensor(0.2908, device='cuda:0') tensor(6.5968e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.920892
Average KL loss: 0.393443
Average total loss: 1.314335
tensor(-14.0698, device='cuda:0') tensor(0.2904, device='cuda:0') tensor(8.4099e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.921257
Average KL loss: 0.393327
Average total loss: 1.314584
tensor(-14.0736, device='cuda:0') tensor(0.2900, device='cuda:0') tensor(-1.7423e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.919929
Average KL loss: 0.393230
Average total loss: 1.313159
tensor(-14.0773, device='cuda:0') tensor(0.2896, device='cuda:0') tensor(1.5189e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.922755
Average KL loss: 0.393103
Average total loss: 1.315858
tensor(-14.0810, device='cuda:0') tensor(0.2892, device='cuda:0') tensor(3.4466e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.919094
Average KL loss: 0.392993
Average total loss: 1.312088
tensor(-14.0847, device='cuda:0') tensor(0.2888, device='cuda:0') tensor(-3.8104e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.923550
Average KL loss: 0.392938
Average total loss: 1.316488
tensor(-14.0884, device='cuda:0') tensor(0.2885, device='cuda:0') tensor(1.4099e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.924517
Average KL loss: 0.392862
Average total loss: 1.317379
tensor(-14.0921, device='cuda:0') tensor(0.2881, device='cuda:0') tensor(1.7677e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.919682
Average KL loss: 0.392877
Average total loss: 1.312559
tensor(-14.0957, device='cuda:0') tensor(0.2878, device='cuda:0') tensor(-1.7728e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.921586
Average KL loss: 0.392863
Average total loss: 1.314449
tensor(-14.0994, device='cuda:0') tensor(0.2874, device='cuda:0') tensor(4.6818e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.921902
Average KL loss: 0.392816
Average total loss: 1.314718
tensor(-14.1030, device='cuda:0') tensor(0.2870, device='cuda:0') tensor(1.9659e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.921741
Average KL loss: 0.392717
Average total loss: 1.314459
tensor(-14.1066, device='cuda:0') tensor(0.2867, device='cuda:0') tensor(1.2989e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.921143
Average KL loss: 0.392648
Average total loss: 1.313791
tensor(-14.1102, device='cuda:0') tensor(0.2863, device='cuda:0') tensor(2.4521e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.917285
Average KL loss: 0.392527
Average total loss: 1.309812
tensor(-14.1138, device='cuda:0') tensor(0.2860, device='cuda:0') tensor(1.6553e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.921438
Average KL loss: 0.392447
Average total loss: 1.313886
tensor(-14.1174, device='cuda:0') tensor(0.2856, device='cuda:0') tensor(5.9190e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.918541
Average KL loss: 0.392393
Average total loss: 1.310934
tensor(-14.1210, device='cuda:0') tensor(0.2853, device='cuda:0') tensor(9.6678e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.921110
Average KL loss: 0.392316
Average total loss: 1.313426
tensor(-14.1245, device='cuda:0') tensor(0.2850, device='cuda:0') tensor(8.2775e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.918142
Average KL loss: 0.392237
Average total loss: 1.310380
tensor(-14.1280, device='cuda:0') tensor(0.2847, device='cuda:0') tensor(-6.9177e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.919896
Average KL loss: 0.392182
Average total loss: 1.312078
tensor(-14.1316, device='cuda:0') tensor(0.2844, device='cuda:0') tensor(-5.0199e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.919443
Average KL loss: 0.392134
Average total loss: 1.311577
tensor(-14.1351, device='cuda:0') tensor(0.2841, device='cuda:0') tensor(-1.6129e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.917994
Average KL loss: 0.392075
Average total loss: 1.310068
tensor(-14.1386, device='cuda:0') tensor(0.2838, device='cuda:0') tensor(1.0055e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.917577
Average KL loss: 0.392008
Average total loss: 1.309585
tensor(-14.1421, device='cuda:0') tensor(0.2835, device='cuda:0') tensor(7.0295e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.917442
Average KL loss: 0.391937
Average total loss: 1.309378
tensor(-14.1455, device='cuda:0') tensor(0.2832, device='cuda:0') tensor(2.2467e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.918916
Average KL loss: 0.391846
Average total loss: 1.310762
tensor(-14.1490, device='cuda:0') tensor(0.2829, device='cuda:0') tensor(6.7159e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.915154
Average KL loss: 0.391758
Average total loss: 1.306912
tensor(-14.1525, device='cuda:0') tensor(0.2826, device='cuda:0') tensor(1.5989e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.917758
Average KL loss: 0.391677
Average total loss: 1.309435
tensor(-14.1559, device='cuda:0') tensor(0.2823, device='cuda:0') tensor(-1.8190e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.918857
Average KL loss: 0.391612
Average total loss: 1.310469
tensor(-14.1593, device='cuda:0') tensor(0.2821, device='cuda:0') tensor(5.1763e-11, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.917021
Average KL loss: 0.391534
Average total loss: 1.308555
tensor(-14.1627, device='cuda:0') tensor(0.2818, device='cuda:0') tensor(7.1226e-11, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.917968
Average KL loss: 0.391479
Average total loss: 1.309447
tensor(-14.1661, device='cuda:0') tensor(0.2815, device='cuda:0') tensor(2.8688e-11, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.915791
Average KL loss: 0.391429
Average total loss: 1.307220
tensor(-14.1695, device='cuda:0') tensor(0.2812, device='cuda:0') tensor(1.2926e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.913057
Average KL loss: 0.391370
Average total loss: 1.304427
tensor(-14.1729, device='cuda:0') tensor(0.2810, device='cuda:0') tensor(-3.1783e-12, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.914154
Average KL loss: 0.391311
Average total loss: 1.305465
tensor(-14.1763, device='cuda:0') tensor(0.2807, device='cuda:0') tensor(2.4282e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.916138
Average KL loss: 0.391250
Average total loss: 1.307388
tensor(-14.1796, device='cuda:0') tensor(0.2804, device='cuda:0') tensor(7.1113e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.912977
Average KL loss: 0.391184
Average total loss: 1.304161
tensor(-14.1830, device='cuda:0') tensor(0.2801, device='cuda:0') tensor(5.0509e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.913349
Average KL loss: 0.391100
Average total loss: 1.304449
tensor(-14.1863, device='cuda:0') tensor(0.2799, device='cuda:0') tensor(1.1878e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.914999
Average KL loss: 0.391068
Average total loss: 1.306067
tensor(-14.1896, device='cuda:0') tensor(0.2796, device='cuda:0') tensor(3.3918e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.913099
Average KL loss: 0.391014
Average total loss: 1.304113
tensor(-14.1929, device='cuda:0') tensor(0.2794, device='cuda:0') tensor(-7.7366e-11, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.912285
Average KL loss: 0.390928
Average total loss: 1.303213
tensor(-14.1962, device='cuda:0') tensor(0.2791, device='cuda:0') tensor(-5.1468e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.912826
Average KL loss: 0.390859
Average total loss: 1.303685
tensor(-14.1995, device='cuda:0') tensor(0.2789, device='cuda:0') tensor(-5.2618e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.911371
Average KL loss: 0.390813
Average total loss: 1.302185
tensor(-14.2028, device='cuda:0') tensor(0.2787, device='cuda:0') tensor(-1.0138e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.912903
Average KL loss: 0.390819
Average total loss: 1.303722
tensor(-14.2061, device='cuda:0') tensor(0.2784, device='cuda:0') tensor(1.6378e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.914479
Average KL loss: 0.390803
Average total loss: 1.305282
tensor(-14.2093, device='cuda:0') tensor(0.2782, device='cuda:0') tensor(6.6615e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.915734
Average KL loss: 0.390766
Average total loss: 1.306500
tensor(-14.2126, device='cuda:0') tensor(0.2779, device='cuda:0') tensor(3.1542e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.911204
Average KL loss: 0.390736
Average total loss: 1.301940
tensor(-14.2158, device='cuda:0') tensor(0.2777, device='cuda:0') tensor(-1.2929e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.910071
Average KL loss: 0.390723
Average total loss: 1.300794
tensor(-14.2190, device='cuda:0') tensor(0.2775, device='cuda:0') tensor(1.4669e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.911434
Average KL loss: 0.390686
Average total loss: 1.302120
tensor(-14.2222, device='cuda:0') tensor(0.2773, device='cuda:0') tensor(1.2559e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.912406
Average KL loss: 0.390645
Average total loss: 1.303052
tensor(-14.2254, device='cuda:0') tensor(0.2770, device='cuda:0') tensor(1.4966e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.909307
Average KL loss: 0.390595
Average total loss: 1.299902
tensor(-14.2286, device='cuda:0') tensor(0.2768, device='cuda:0') tensor(-4.3993e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.910922
Average KL loss: 0.390551
Average total loss: 1.301473
tensor(-14.2318, device='cuda:0') tensor(0.2766, device='cuda:0') tensor(-6.4105e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.909419
Average KL loss: 0.390481
Average total loss: 1.299901
tensor(-14.2350, device='cuda:0') tensor(0.2764, device='cuda:0') tensor(7.7707e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.911549
Average KL loss: 0.390404
Average total loss: 1.301953
tensor(-14.2381, device='cuda:0') tensor(0.2761, device='cuda:0') tensor(2.4822e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.912831
Average KL loss: 0.390369
Average total loss: 1.303201
tensor(-14.2413, device='cuda:0') tensor(0.2759, device='cuda:0') tensor(2.1543e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.910112
Average KL loss: 0.390308
Average total loss: 1.300420
tensor(-14.2444, device='cuda:0') tensor(0.2757, device='cuda:0') tensor(1.2773e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.907716
Average KL loss: 0.390266
Average total loss: 1.297982
tensor(-14.2476, device='cuda:0') tensor(0.2755, device='cuda:0') tensor(1.9352e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.910136
Average KL loss: 0.390222
Average total loss: 1.300358
tensor(-14.2507, device='cuda:0') tensor(0.2753, device='cuda:0') tensor(-7.1677e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.908476
Average KL loss: 0.390199
Average total loss: 1.298675
tensor(-14.2538, device='cuda:0') tensor(0.2751, device='cuda:0') tensor(8.0111e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.909779
Average KL loss: 0.390175
Average total loss: 1.299954
tensor(-14.2569, device='cuda:0') tensor(0.2749, device='cuda:0') tensor(-1.1810e-11, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.907634
Average KL loss: 0.390157
Average total loss: 1.297790
tensor(-14.2600, device='cuda:0') tensor(0.2747, device='cuda:0') tensor(4.8075e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.908744
Average KL loss: 0.390134
Average total loss: 1.298877
tensor(-14.2631, device='cuda:0') tensor(0.2745, device='cuda:0') tensor(6.8407e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.909975
Average KL loss: 0.390111
Average total loss: 1.300086
tensor(-14.2662, device='cuda:0') tensor(0.2743, device='cuda:0') tensor(9.1926e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.910029
Average KL loss: 0.390098
Average total loss: 1.300127
tensor(-14.2692, device='cuda:0') tensor(0.2741, device='cuda:0') tensor(-3.3870e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.907240
Average KL loss: 0.390043
Average total loss: 1.297283
tensor(-14.2723, device='cuda:0') tensor(0.2739, device='cuda:0') tensor(1.1266e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.908798
Average KL loss: 0.389982
Average total loss: 1.298781
tensor(-14.2753, device='cuda:0') tensor(0.2737, device='cuda:0') tensor(5.1972e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.908417
Average KL loss: 0.389976
Average total loss: 1.298393
tensor(-14.2784, device='cuda:0') tensor(0.2735, device='cuda:0') tensor(9.0326e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.906415
Average KL loss: 0.389967
Average total loss: 1.296382
tensor(-14.2814, device='cuda:0') tensor(0.2733, device='cuda:0') tensor(4.9289e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.905818
Average KL loss: 0.389941
Average total loss: 1.295759
tensor(-14.2844, device='cuda:0') tensor(0.2731, device='cuda:0') tensor(1.8115e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.907936
Average KL loss: 0.389897
Average total loss: 1.297833
tensor(-14.2874, device='cuda:0') tensor(0.2729, device='cuda:0') tensor(6.4514e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.905798
Average KL loss: 0.389856
Average total loss: 1.295655
tensor(-14.2904, device='cuda:0') tensor(0.2727, device='cuda:0') tensor(9.4605e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.903304
Average KL loss: 0.389822
Average total loss: 1.293126
tensor(-14.2934, device='cuda:0') tensor(0.2726, device='cuda:0') tensor(-1.0881e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.903895
Average KL loss: 0.389802
Average total loss: 1.293697
tensor(-14.2964, device='cuda:0') tensor(0.2724, device='cuda:0') tensor(-5.6455e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.905512
Average KL loss: 0.389765
Average total loss: 1.295277
tensor(-14.2993, device='cuda:0') tensor(0.2722, device='cuda:0') tensor(-8.7219e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.905628
Average KL loss: 0.389731
Average total loss: 1.295359
tensor(-14.3023, device='cuda:0') tensor(0.2720, device='cuda:0') tensor(4.4218e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.905779
Average KL loss: 0.389691
Average total loss: 1.295470
tensor(-14.3053, device='cuda:0') tensor(0.2718, device='cuda:0') tensor(-2.6765e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.906036
Average KL loss: 0.389682
Average total loss: 1.295717
tensor(-14.3082, device='cuda:0') tensor(0.2716, device='cuda:0') tensor(3.1577e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.905516
Average KL loss: 0.389659
Average total loss: 1.295175
tensor(-14.3111, device='cuda:0') tensor(0.2715, device='cuda:0') tensor(1.1574e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.905291
Average KL loss: 0.389625
Average total loss: 1.294916
tensor(-14.3141, device='cuda:0') tensor(0.2713, device='cuda:0') tensor(8.6507e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.903926
Average KL loss: 0.389574
Average total loss: 1.293500
tensor(-14.3170, device='cuda:0') tensor(0.2711, device='cuda:0') tensor(-1.2063e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.904289
Average KL loss: 0.389578
Average total loss: 1.293867
tensor(-14.3199, device='cuda:0') tensor(0.2709, device='cuda:0') tensor(6.9597e-11, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.902194
Average KL loss: 0.389552
Average total loss: 1.291746
tensor(-14.3228, device='cuda:0') tensor(0.2708, device='cuda:0') tensor(4.8037e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.904612
Average KL loss: 0.389501
Average total loss: 1.294114
tensor(-14.3257, device='cuda:0') tensor(0.2706, device='cuda:0') tensor(1.4831e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.904636
Average KL loss: 0.389485
Average total loss: 1.294121
tensor(-14.3286, device='cuda:0') tensor(0.2704, device='cuda:0') tensor(8.4745e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.905156
Average KL loss: 0.389466
Average total loss: 1.294622
tensor(-14.3315, device='cuda:0') tensor(0.2702, device='cuda:0') tensor(-3.8939e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.903153
Average KL loss: 0.389422
Average total loss: 1.292575
tensor(-14.3343, device='cuda:0') tensor(0.2701, device='cuda:0') tensor(7.9171e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.905829
Average KL loss: 0.389403
Average total loss: 1.295232
tensor(-14.3372, device='cuda:0') tensor(0.2699, device='cuda:0') tensor(2.6261e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.903091
Average KL loss: 0.389381
Average total loss: 1.292471
tensor(-14.3401, device='cuda:0') tensor(0.2697, device='cuda:0') tensor(6.9576e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.902458
Average KL loss: 0.389360
Average total loss: 1.291818
tensor(-14.3429, device='cuda:0') tensor(0.2696, device='cuda:0') tensor(5.0589e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.903576
Average KL loss: 0.389330
Average total loss: 1.292907
tensor(-14.3457, device='cuda:0') tensor(0.2694, device='cuda:0') tensor(-1.3200e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.902173
Average KL loss: 0.389322
Average total loss: 1.291495
tensor(-14.3486, device='cuda:0') tensor(0.2692, device='cuda:0') tensor(7.4070e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.902111
Average KL loss: 0.389272
Average total loss: 1.291383
tensor(-14.3514, device='cuda:0') tensor(0.2690, device='cuda:0') tensor(-8.1683e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.903678
Average KL loss: 0.389222
Average total loss: 1.292900
tensor(-14.3542, device='cuda:0') tensor(0.2688, device='cuda:0') tensor(-2.2686e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.902674
Average KL loss: 0.389195
Average total loss: 1.291869
tensor(-14.3570, device='cuda:0') tensor(0.2687, device='cuda:0') tensor(-4.6464e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.900926
Average KL loss: 0.389159
Average total loss: 1.290085
tensor(-14.3598, device='cuda:0') tensor(0.2685, device='cuda:0') tensor(3.5080e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.900830
Average KL loss: 0.389098
Average total loss: 1.289928
tensor(-14.3626, device='cuda:0') tensor(0.2683, device='cuda:0') tensor(-2.2497e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.903754
Average KL loss: 0.389088
Average total loss: 1.292842
tensor(-14.3654, device='cuda:0') tensor(0.2682, device='cuda:0') tensor(5.7577e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.900684
Average KL loss: 0.389078
Average total loss: 1.289761
tensor(-14.3682, device='cuda:0') tensor(0.2680, device='cuda:0') tensor(2.2524e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.900637
Average KL loss: 0.389073
Average total loss: 1.289711
tensor(-14.3709, device='cuda:0') tensor(0.2679, device='cuda:0') tensor(7.0435e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.903763
Average KL loss: 0.389043
Average total loss: 1.292807
tensor(-14.3737, device='cuda:0') tensor(0.2677, device='cuda:0') tensor(7.6647e-11, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.900627
Average KL loss: 0.389034
Average total loss: 1.289660
tensor(-14.3764, device='cuda:0') tensor(0.2675, device='cuda:0') tensor(-6.5512e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.899956
Average KL loss: 0.388992
Average total loss: 1.288948
tensor(-14.3792, device='cuda:0') tensor(0.2674, device='cuda:0') tensor(-1.1591e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.900548
Average KL loss: 0.388976
Average total loss: 1.289524
tensor(-14.3819, device='cuda:0') tensor(0.2672, device='cuda:0') tensor(3.4090e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.898983
Average KL loss: 0.389032
Average total loss: 1.288015
tensor(-14.3846, device='cuda:0') tensor(0.2671, device='cuda:0') tensor(-8.3000e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.898166
Average KL loss: 0.388991
Average total loss: 1.287157
tensor(-14.3874, device='cuda:0') tensor(0.2669, device='cuda:0') tensor(-1.1685e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.898628
Average KL loss: 0.388973
Average total loss: 1.287600
tensor(-14.3901, device='cuda:0') tensor(0.2668, device='cuda:0') tensor(1.3230e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.899098
Average KL loss: 0.388903
Average total loss: 1.288000
 Percentile value: -14.443354606628418
Non-zero model percentage: 51.200008392333984%, Non-zero mask percentage: 51.200008392333984%

--- Pruning Level [3/24]: ---
conv1.weight         | nonzeros =    1716 /    1728             ( 99.31%) | total_pruned =      12 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   34207 /   36864             ( 92.79%) | total_pruned =    2657 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   34280 /   36864             ( 92.99%) | total_pruned =    2584 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   33311 /   36864             ( 90.36%) | total_pruned =    3553 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   32858 /   36864             ( 89.13%) | total_pruned =    4006 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   66586 /   73728             ( 90.31%) | total_pruned =    7142 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  125655 /  147456             ( 85.22%) | total_pruned =   21801 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7953 /    8192             ( 97.08%) | total_pruned =     239 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  119914 /  147456             ( 81.32%) | total_pruned =   27542 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  117042 /  147456             ( 79.37%) | total_pruned =   30414 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  233354 /  294912             ( 79.13%) | total_pruned =   61558 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  409189 /  589824             ( 69.37%) | total_pruned =  180635 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   29939 /   32768             ( 91.37%) | total_pruned =    2829 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  320643 /  589824             ( 54.36%) | total_pruned =  269181 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  309370 /  589824             ( 52.45%) | total_pruned =  280454 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  690899 / 1179648             ( 58.57%) | total_pruned =  488749 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1065335 / 2359296             ( 45.15%) | total_pruned = 1293961 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  108329 /  131072             ( 82.65%) | total_pruned =   22743 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  983877 / 2359296             ( 41.70%) | total_pruned = 1375419 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  984394 / 2359296             ( 41.72%) | total_pruned = 1374902 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5074 /    5120             ( 99.10%) | total_pruned =      46 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 5723527, pruned : 5455235, total: 11178762, Compression rate :       1.95x  ( 48.80% pruned)
Train Epoch: 27/100 Loss: 0.002822 Accuracy: 86.53 100.00 % Best test Accuracy: 86.67%
tensor(-14.3928, device='cuda:0') tensor(0.2666, device='cuda:0') tensor(1.3734e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.926142
Average KL loss: 0.387505
Average total loss: 1.313647
tensor(-14.3963, device='cuda:0') tensor(0.2530, device='cuda:0') tensor(9.5859e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.928190
Average KL loss: 0.386085
Average total loss: 1.314275
tensor(-14.3996, device='cuda:0') tensor(0.2435, device='cuda:0') tensor(1.0144e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.929737
Average KL loss: 0.385217
Average total loss: 1.314954
tensor(-14.4027, device='cuda:0') tensor(0.2366, device='cuda:0') tensor(-1.3924e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.928061
Average KL loss: 0.384578
Average total loss: 1.312639
tensor(-14.4058, device='cuda:0') tensor(0.2315, device='cuda:0') tensor(-1.3535e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.931505
Average KL loss: 0.384094
Average total loss: 1.315599
tensor(-14.4088, device='cuda:0') tensor(0.2278, device='cuda:0') tensor(-4.1159e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.932339
Average KL loss: 0.383748
Average total loss: 1.316087
tensor(-14.4117, device='cuda:0') tensor(0.2249, device='cuda:0') tensor(-2.0294e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.930198
Average KL loss: 0.383562
Average total loss: 1.313760
tensor(-14.4146, device='cuda:0') tensor(0.2225, device='cuda:0') tensor(-8.7238e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.930950
Average KL loss: 0.383460
Average total loss: 1.314411
tensor(-14.4174, device='cuda:0') tensor(0.2204, device='cuda:0') tensor(-1.9730e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.926994
Average KL loss: 0.383345
Average total loss: 1.310339
tensor(-14.4203, device='cuda:0') tensor(0.2186, device='cuda:0') tensor(-2.5788e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.929579
Average KL loss: 0.383220
Average total loss: 1.312799
tensor(-14.4231, device='cuda:0') tensor(0.2170, device='cuda:0') tensor(-2.1487e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.924523
Average KL loss: 0.383130
Average total loss: 1.307652
tensor(-14.4258, device='cuda:0') tensor(0.2156, device='cuda:0') tensor(-6.5704e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.924531
Average KL loss: 0.383064
Average total loss: 1.307594
tensor(-14.4286, device='cuda:0') tensor(0.2143, device='cuda:0') tensor(-6.5918e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.923920
Average KL loss: 0.383015
Average total loss: 1.306936
tensor(-14.4314, device='cuda:0') tensor(0.2131, device='cuda:0') tensor(-1.9663e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.924887
Average KL loss: 0.382931
Average total loss: 1.307818
tensor(-14.4341, device='cuda:0') tensor(0.2120, device='cuda:0') tensor(-1.5545e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.922338
Average KL loss: 0.382896
Average total loss: 1.305234
tensor(-14.4368, device='cuda:0') tensor(0.2110, device='cuda:0') tensor(-2.2588e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.921953
Average KL loss: 0.382815
Average total loss: 1.304767
tensor(-14.4395, device='cuda:0') tensor(0.2100, device='cuda:0') tensor(4.1604e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.921341
Average KL loss: 0.382762
Average total loss: 1.304103
tensor(-14.4422, device='cuda:0') tensor(0.2091, device='cuda:0') tensor(-7.8118e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.920732
Average KL loss: 0.382741
Average total loss: 1.303473
tensor(-14.4449, device='cuda:0') tensor(0.2083, device='cuda:0') tensor(-7.8767e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.919028
Average KL loss: 0.382707
Average total loss: 1.301735
tensor(-14.4476, device='cuda:0') tensor(0.2075, device='cuda:0') tensor(-2.0590e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.921644
Average KL loss: 0.382637
Average total loss: 1.304281
tensor(-14.4502, device='cuda:0') tensor(0.2068, device='cuda:0') tensor(-9.5011e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.924380
Average KL loss: 0.382589
Average total loss: 1.306969
tensor(-14.4529, device='cuda:0') tensor(0.2061, device='cuda:0') tensor(7.0989e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.918290
Average KL loss: 0.382547
Average total loss: 1.300837
tensor(-14.4555, device='cuda:0') tensor(0.2055, device='cuda:0') tensor(-1.6391e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.916212
Average KL loss: 0.382488
Average total loss: 1.298700
tensor(-14.4581, device='cuda:0') tensor(0.2049, device='cuda:0') tensor(-1.2857e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.916830
Average KL loss: 0.382434
Average total loss: 1.299263
tensor(-14.4607, device='cuda:0') tensor(0.2043, device='cuda:0') tensor(-9.0273e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.915116
Average KL loss: 0.382384
Average total loss: 1.297500
tensor(-14.4633, device='cuda:0') tensor(0.2038, device='cuda:0') tensor(-2.4971e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.916063
Average KL loss: 0.382336
Average total loss: 1.298399
tensor(-14.4659, device='cuda:0') tensor(0.2033, device='cuda:0') tensor(-4.7825e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.913416
Average KL loss: 0.382297
Average total loss: 1.295713
tensor(-14.4685, device='cuda:0') tensor(0.2028, device='cuda:0') tensor(-1.5551e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.915214
Average KL loss: 0.382242
Average total loss: 1.297456
tensor(-14.4711, device='cuda:0') tensor(0.2024, device='cuda:0') tensor(-2.3505e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.915229
Average KL loss: 0.382212
Average total loss: 1.297441
tensor(-14.4737, device='cuda:0') tensor(0.2020, device='cuda:0') tensor(-6.1530e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.913792
Average KL loss: 0.382202
Average total loss: 1.295994
tensor(-14.4762, device='cuda:0') tensor(0.2016, device='cuda:0') tensor(-7.9476e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.913559
Average KL loss: 0.382235
Average total loss: 1.295794
tensor(-14.4788, device='cuda:0') tensor(0.2012, device='cuda:0') tensor(7.3378e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.915728
Average KL loss: 0.382205
Average total loss: 1.297934
tensor(-14.4813, device='cuda:0') tensor(0.2008, device='cuda:0') tensor(-1.7007e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.909840
Average KL loss: 0.382161
Average total loss: 1.292001
tensor(-14.4839, device='cuda:0') tensor(0.2004, device='cuda:0') tensor(-3.5292e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.910874
Average KL loss: 0.382104
Average total loss: 1.292979
tensor(-14.4864, device='cuda:0') tensor(0.2001, device='cuda:0') tensor(1.6825e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.910195
Average KL loss: 0.382064
Average total loss: 1.292259
tensor(-14.4889, device='cuda:0') tensor(0.1997, device='cuda:0') tensor(-2.8395e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.910204
Average KL loss: 0.382040
Average total loss: 1.292244
tensor(-14.4914, device='cuda:0') tensor(0.1994, device='cuda:0') tensor(3.4354e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.910925
Average KL loss: 0.381990
Average total loss: 1.292915
tensor(-14.4939, device='cuda:0') tensor(0.1991, device='cuda:0') tensor(-1.7637e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.912975
Average KL loss: 0.381954
Average total loss: 1.294929
tensor(-14.4964, device='cuda:0') tensor(0.1988, device='cuda:0') tensor(-2.0017e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.907729
Average KL loss: 0.381958
Average total loss: 1.289687
tensor(-14.4989, device='cuda:0') tensor(0.1985, device='cuda:0') tensor(-8.4114e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.906335
Average KL loss: 0.381929
Average total loss: 1.288264
tensor(-14.5014, device='cuda:0') tensor(0.1982, device='cuda:0') tensor(-4.0212e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.910905
Average KL loss: 0.381897
Average total loss: 1.292802
tensor(-14.5039, device='cuda:0') tensor(0.1980, device='cuda:0') tensor(8.1839e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.908816
Average KL loss: 0.381867
Average total loss: 1.290683
tensor(-14.5063, device='cuda:0') tensor(0.1977, device='cuda:0') tensor(3.7778e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.909318
Average KL loss: 0.381851
Average total loss: 1.291168
tensor(-14.5088, device='cuda:0') tensor(0.1975, device='cuda:0') tensor(-1.6166e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.905735
Average KL loss: 0.381825
Average total loss: 1.287560
tensor(-14.5112, device='cuda:0') tensor(0.1972, device='cuda:0') tensor(9.8144e-11, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.912283
Average KL loss: 0.381774
Average total loss: 1.294057
tensor(-14.5137, device='cuda:0') tensor(0.1970, device='cuda:0') tensor(-5.4104e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.906607
Average KL loss: 0.381741
Average total loss: 1.288348
tensor(-14.5161, device='cuda:0') tensor(0.1968, device='cuda:0') tensor(-1.1014e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.910128
Average KL loss: 0.381692
Average total loss: 1.291820
tensor(-14.5186, device='cuda:0') tensor(0.1966, device='cuda:0') tensor(-2.0336e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.908491
Average KL loss: 0.381661
Average total loss: 1.290153
tensor(-14.5210, device='cuda:0') tensor(0.1964, device='cuda:0') tensor(-1.6357e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.906214
Average KL loss: 0.381649
Average total loss: 1.287863
tensor(-14.5234, device='cuda:0') tensor(0.1962, device='cuda:0') tensor(1.2705e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.903437
Average KL loss: 0.381641
Average total loss: 1.285078
tensor(-14.5258, device='cuda:0') tensor(0.1960, device='cuda:0') tensor(-1.5763e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.907570
Average KL loss: 0.381635
Average total loss: 1.289205
tensor(-14.5282, device='cuda:0') tensor(0.1958, device='cuda:0') tensor(4.1092e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.906440
Average KL loss: 0.381652
Average total loss: 1.288092
tensor(-14.5306, device='cuda:0') tensor(0.1956, device='cuda:0') tensor(5.0970e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.906718
Average KL loss: 0.381632
Average total loss: 1.288349
tensor(-14.5330, device='cuda:0') tensor(0.1955, device='cuda:0') tensor(4.7251e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.904620
Average KL loss: 0.381615
Average total loss: 1.286235
tensor(-14.5354, device='cuda:0') tensor(0.1953, device='cuda:0') tensor(-5.6995e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.903186
Average KL loss: 0.381589
Average total loss: 1.284775
tensor(-14.5378, device='cuda:0') tensor(0.1952, device='cuda:0') tensor(-1.5183e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.904158
Average KL loss: 0.381558
Average total loss: 1.285716
tensor(-14.5402, device='cuda:0') tensor(0.1950, device='cuda:0') tensor(-1.7445e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.904463
Average KL loss: 0.381521
Average total loss: 1.285983
tensor(-14.5425, device='cuda:0') tensor(0.1948, device='cuda:0') tensor(-7.9480e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.906493
Average KL loss: 0.381486
Average total loss: 1.287979
tensor(-14.5449, device='cuda:0') tensor(0.1947, device='cuda:0') tensor(-6.7537e-11, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.902546
Average KL loss: 0.381517
Average total loss: 1.284063
tensor(-14.5473, device='cuda:0') tensor(0.1946, device='cuda:0') tensor(-8.9824e-11, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.902552
Average KL loss: 0.381506
Average total loss: 1.284058
tensor(-14.5496, device='cuda:0') tensor(0.1944, device='cuda:0') tensor(-5.9994e-11, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.903663
Average KL loss: 0.381498
Average total loss: 1.285161
tensor(-14.5519, device='cuda:0') tensor(0.1943, device='cuda:0') tensor(-1.6259e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.904287
Average KL loss: 0.381476
Average total loss: 1.285762
tensor(-14.5543, device='cuda:0') tensor(0.1942, device='cuda:0') tensor(-3.3220e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.903213
Average KL loss: 0.381451
Average total loss: 1.284664
tensor(-14.5566, device='cuda:0') tensor(0.1941, device='cuda:0') tensor(-3.1536e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.904956
Average KL loss: 0.381432
Average total loss: 1.286387
tensor(-14.5589, device='cuda:0') tensor(0.1940, device='cuda:0') tensor(-1.5204e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.901368
Average KL loss: 0.381390
Average total loss: 1.282758
tensor(-14.5613, device='cuda:0') tensor(0.1938, device='cuda:0') tensor(-3.3460e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.902649
Average KL loss: 0.381349
Average total loss: 1.283998
tensor(-14.5636, device='cuda:0') tensor(0.1938, device='cuda:0') tensor(-2.3590e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.902939
Average KL loss: 0.381329
Average total loss: 1.284268
tensor(-14.5659, device='cuda:0') tensor(0.1936, device='cuda:0') tensor(-1.0030e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.901531
Average KL loss: 0.381287
Average total loss: 1.282818
tensor(-14.5682, device='cuda:0') tensor(0.1935, device='cuda:0') tensor(8.7888e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.901655
Average KL loss: 0.381230
Average total loss: 1.282885
tensor(-14.5705, device='cuda:0') tensor(0.1934, device='cuda:0') tensor(-7.5409e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.899725
Average KL loss: 0.381200
Average total loss: 1.280925
tensor(-14.5728, device='cuda:0') tensor(0.1933, device='cuda:0') tensor(-6.1877e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.902473
Average KL loss: 0.381189
Average total loss: 1.283662
tensor(-14.5751, device='cuda:0') tensor(0.1932, device='cuda:0') tensor(-3.0687e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.902983
Average KL loss: 0.381170
Average total loss: 1.284152
tensor(-14.5773, device='cuda:0') tensor(0.1931, device='cuda:0') tensor(1.0180e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.901359
Average KL loss: 0.381136
Average total loss: 1.282494
tensor(-14.5796, device='cuda:0') tensor(0.1930, device='cuda:0') tensor(-8.9766e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.901060
Average KL loss: 0.381099
Average total loss: 1.282160
tensor(-14.5819, device='cuda:0') tensor(0.1929, device='cuda:0') tensor(-1.0384e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.903567
Average KL loss: 0.381035
Average total loss: 1.284602
tensor(-14.5842, device='cuda:0') tensor(0.1928, device='cuda:0') tensor(-1.2196e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.900568
Average KL loss: 0.380984
Average total loss: 1.281552
tensor(-14.5864, device='cuda:0') tensor(0.1927, device='cuda:0') tensor(-1.2661e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.899539
Average KL loss: 0.380957
Average total loss: 1.280496
tensor(-14.5887, device='cuda:0') tensor(0.1927, device='cuda:0') tensor(-1.0353e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.901806
Average KL loss: 0.380931
Average total loss: 1.282737
tensor(-14.5909, device='cuda:0') tensor(0.1926, device='cuda:0') tensor(5.4479e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.903628
Average KL loss: 0.380929
Average total loss: 1.284557
tensor(-14.5932, device='cuda:0') tensor(0.1925, device='cuda:0') tensor(7.0523e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.900110
Average KL loss: 0.380924
Average total loss: 1.281034
tensor(-14.5954, device='cuda:0') tensor(0.1925, device='cuda:0') tensor(6.5774e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.898045
Average KL loss: 0.380911
Average total loss: 1.278956
tensor(-14.5976, device='cuda:0') tensor(0.1924, device='cuda:0') tensor(-1.3483e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.899286
Average KL loss: 0.380899
Average total loss: 1.280185
tensor(-14.5999, device='cuda:0') tensor(0.1923, device='cuda:0') tensor(-8.7031e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.898654
Average KL loss: 0.380858
Average total loss: 1.279513
tensor(-14.6021, device='cuda:0') tensor(0.1923, device='cuda:0') tensor(-1.4780e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.894946
Average KL loss: 0.380800
Average total loss: 1.275746
tensor(-14.6043, device='cuda:0') tensor(0.1922, device='cuda:0') tensor(-2.8101e-12, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.899939
Average KL loss: 0.380774
Average total loss: 1.280714
tensor(-14.6065, device='cuda:0') tensor(0.1921, device='cuda:0') tensor(-1.3138e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.899654
Average KL loss: 0.380724
Average total loss: 1.280379
tensor(-14.6087, device='cuda:0') tensor(0.1921, device='cuda:0') tensor(-2.2982e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.900181
Average KL loss: 0.380675
Average total loss: 1.280855
tensor(-14.6109, device='cuda:0') tensor(0.1920, device='cuda:0') tensor(-2.3154e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.897886
Average KL loss: 0.380663
Average total loss: 1.278549
tensor(-14.6131, device='cuda:0') tensor(0.1920, device='cuda:0') tensor(1.7874e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.899038
Average KL loss: 0.380679
Average total loss: 1.279717
tensor(-14.6153, device='cuda:0') tensor(0.1919, device='cuda:0') tensor(-8.0925e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.896695
Average KL loss: 0.380668
Average total loss: 1.277363
tensor(-14.6175, device='cuda:0') tensor(0.1918, device='cuda:0') tensor(-3.6637e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.898046
Average KL loss: 0.380674
Average total loss: 1.278720
tensor(-14.6197, device='cuda:0') tensor(0.1918, device='cuda:0') tensor(-1.0050e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.897333
Average KL loss: 0.380671
Average total loss: 1.278005
tensor(-14.6218, device='cuda:0') tensor(0.1917, device='cuda:0') tensor(-6.9959e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.895207
Average KL loss: 0.380693
Average total loss: 1.275900
tensor(-14.6240, device='cuda:0') tensor(0.1917, device='cuda:0') tensor(-9.1334e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.895870
Average KL loss: 0.380659
Average total loss: 1.276529
tensor(-14.6262, device='cuda:0') tensor(0.1916, device='cuda:0') tensor(-4.2457e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.897947
Average KL loss: 0.380632
Average total loss: 1.278579
tensor(-14.6283, device='cuda:0') tensor(0.1916, device='cuda:0') tensor(2.1593e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.895172
Average KL loss: 0.380620
Average total loss: 1.275792
tensor(-14.6286, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(8.1085e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.894797
Average KL loss: 0.380618
Average total loss: 1.275415
tensor(-14.6288, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(-5.2389e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.894827
Average KL loss: 0.380615
Average total loss: 1.275442
tensor(-14.6290, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(1.0099e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.894266
Average KL loss: 0.380614
Average total loss: 1.274879
tensor(-14.6292, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(-1.8141e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.896405
Average KL loss: 0.380613
Average total loss: 1.277017
tensor(-14.6294, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(-4.2659e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.894564
Average KL loss: 0.380612
Average total loss: 1.275176
tensor(-14.6296, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(3.0382e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.896323
Average KL loss: 0.380610
Average total loss: 1.276933
tensor(-14.6298, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(-4.9100e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.897353
Average KL loss: 0.380606
Average total loss: 1.277960
tensor(-14.6300, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(2.3639e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.898229
Average KL loss: 0.380604
Average total loss: 1.278832
tensor(-14.6302, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(-1.5482e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.896768
Average KL loss: 0.380605
Average total loss: 1.277373
tensor(-14.6304, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(-2.5534e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.895978
Average KL loss: 0.380605
Average total loss: 1.276583
tensor(-14.6306, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(-1.0111e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.894371
Average KL loss: 0.380607
Average total loss: 1.274978
tensor(-14.6308, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(-1.2350e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.897415
Average KL loss: 0.380607
Average total loss: 1.278022
tensor(-14.6310, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(-2.0369e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.897210
Average KL loss: 0.380604
Average total loss: 1.277815
tensor(-14.6312, device='cuda:0') tensor(0.1915, device='cuda:0') tensor(1.8050e-12, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.896848
Average KL loss: 0.380602
Average total loss: 1.277450
tensor(-14.6314, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-2.5237e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.895866
Average KL loss: 0.380600
Average total loss: 1.276466
tensor(-14.6314, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-2.6749e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.896761
Average KL loss: 0.380600
Average total loss: 1.277362
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-8.8083e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.896040
Average KL loss: 0.380600
Average total loss: 1.276640
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(1.3927e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.898227
Average KL loss: 0.380601
Average total loss: 1.278827
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(5.2069e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.897189
Average KL loss: 0.380601
Average total loss: 1.277790
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-1.9199e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.897338
Average KL loss: 0.380601
Average total loss: 1.277939
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(9.8369e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.897891
Average KL loss: 0.380601
Average total loss: 1.278492
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-3.1613e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.895535
Average KL loss: 0.380600
Average total loss: 1.276136
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-1.3952e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.895763
Average KL loss: 0.380600
Average total loss: 1.276363
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(4.9416e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.895113
Average KL loss: 0.380600
Average total loss: 1.275713
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-6.5826e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.893892
Average KL loss: 0.380600
Average total loss: 1.274492
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(1.0365e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.895286
Average KL loss: 0.380600
Average total loss: 1.275887
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-2.3867e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.896545
Average KL loss: 0.380601
Average total loss: 1.277146
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-1.2502e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.898240
Average KL loss: 0.380601
Average total loss: 1.278841
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(6.8481e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.896680
Average KL loss: 0.380601
Average total loss: 1.277281
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-5.6984e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.895933
Average KL loss: 0.380601
Average total loss: 1.276534
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-6.9588e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.897564
Average KL loss: 0.380601
Average total loss: 1.278165
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-5.3757e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.896262
Average KL loss: 0.380600
Average total loss: 1.276862
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(2.2641e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.895403
Average KL loss: 0.380600
Average total loss: 1.276003
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-1.1740e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.895758
Average KL loss: 0.380600
Average total loss: 1.276358
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(1.5674e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.895814
Average KL loss: 0.380599
Average total loss: 1.276413
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-1.0566e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.895132
Average KL loss: 0.380599
Average total loss: 1.275731
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-1.4224e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.895768
Average KL loss: 0.380600
Average total loss: 1.276367
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(1.7772e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.899045
Average KL loss: 0.380600
Average total loss: 1.279645
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(5.2175e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.894268
Average KL loss: 0.380600
Average total loss: 1.274868
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-8.2339e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.893984
Average KL loss: 0.380600
Average total loss: 1.274583
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-5.5905e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.895225
Average KL loss: 0.380600
Average total loss: 1.275824
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-1.6620e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.897371
Average KL loss: 0.380600
Average total loss: 1.277970
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(3.9521e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.896143
Average KL loss: 0.380600
Average total loss: 1.276743
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(8.8293e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.897587
Average KL loss: 0.380600
Average total loss: 1.278187
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(3.2998e-11, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.895145
Average KL loss: 0.380600
Average total loss: 1.275745
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-1.5065e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.896355
Average KL loss: 0.380600
Average total loss: 1.276954
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-1.6360e-09, device='cuda:0')
 Percentile value: -14.658987998962402
Non-zero model percentage: 40.96000671386719%, Non-zero mask percentage: 40.96000671386719%

--- Pruning Level [4/24]: ---
conv1.weight         | nonzeros =    1712 /    1728             ( 99.07%) | total_pruned =      16 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   33134 /   36864             ( 89.88%) | total_pruned =    3730 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   33257 /   36864             ( 90.22%) | total_pruned =    3607 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   31900 /   36864             ( 86.53%) | total_pruned =    4964 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   31286 /   36864             ( 84.87%) | total_pruned =    5578 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   63768 /   73728             ( 86.49%) | total_pruned =    9960 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  117204 /  147456             ( 79.48%) | total_pruned =   30252 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7830 /    8192             ( 95.58%) | total_pruned =     362 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  109668 /  147456             ( 74.37%) | total_pruned =   37788 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  105878 /  147456             ( 71.80%) | total_pruned =   41578 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  210160 /  294912             ( 71.26%) | total_pruned =   84752 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  346442 /  589824             ( 58.74%) | total_pruned =  243382 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   28766 /   32768             ( 87.79%) | total_pruned =    4002 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  246302 /  589824             ( 41.76%) | total_pruned =  343522 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  237606 /  589824             ( 40.28%) | total_pruned =  352218 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  544043 / 1179648             ( 46.12%) | total_pruned =  635605 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  795757 / 2359296             ( 33.73%) | total_pruned = 1563539 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   99789 /  131072             ( 76.13%) | total_pruned =   31283 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  740898 / 2359296             ( 31.40%) | total_pruned = 1618398 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  778770 / 2359296             ( 33.01%) | total_pruned = 1580526 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5056 /    5120             ( 98.75%) | total_pruned =      64 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 4578822, pruned : 6599940, total: 11178762, Compression rate :       2.44x  ( 59.04% pruned)
Train Epoch: 26/100 Loss: 0.000033 Accuracy: 86.52 100.00 % Best test Accuracy: 86.54%
tensor(-14.6315, device='cuda:0') tensor(0.1914, device='cuda:0') tensor(-1.3441e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.923668
Average KL loss: 0.379624
Average total loss: 1.303292
tensor(-14.6340, device='cuda:0') tensor(0.1841, device='cuda:0') tensor(-2.3923e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.929260
Average KL loss: 0.378646
Average total loss: 1.307906
tensor(-14.6363, device='cuda:0') tensor(0.1795, device='cuda:0') tensor(-1.0182e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.928758
Average KL loss: 0.378047
Average total loss: 1.306804
tensor(-14.6386, device='cuda:0') tensor(0.1765, device='cuda:0') tensor(-2.8218e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.931167
Average KL loss: 0.377649
Average total loss: 1.308817
tensor(-14.6409, device='cuda:0') tensor(0.1745, device='cuda:0') tensor(-2.4191e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.932553
Average KL loss: 0.377410
Average total loss: 1.309963
tensor(-14.6431, device='cuda:0') tensor(0.1732, device='cuda:0') tensor(-8.1015e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.931132
Average KL loss: 0.377273
Average total loss: 1.308404
tensor(-14.6453, device='cuda:0') tensor(0.1723, device='cuda:0') tensor(-2.6429e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.928952
Average KL loss: 0.377183
Average total loss: 1.306134
tensor(-14.6475, device='cuda:0') tensor(0.1715, device='cuda:0') tensor(-1.6022e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.930423
Average KL loss: 0.377093
Average total loss: 1.307516
tensor(-14.6497, device='cuda:0') tensor(0.1709, device='cuda:0') tensor(-1.7311e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.925798
Average KL loss: 0.377059
Average total loss: 1.302857
tensor(-14.6519, device='cuda:0') tensor(0.1703, device='cuda:0') tensor(-1.5766e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.926252
Average KL loss: 0.377033
Average total loss: 1.303285
tensor(-14.6540, device='cuda:0') tensor(0.1698, device='cuda:0') tensor(-1.7808e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.926729
Average KL loss: 0.377009
Average total loss: 1.303738
tensor(-14.6562, device='cuda:0') tensor(0.1694, device='cuda:0') tensor(-6.8233e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.924415
Average KL loss: 0.376999
Average total loss: 1.301414
tensor(-14.6583, device='cuda:0') tensor(0.1690, device='cuda:0') tensor(-2.3120e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.921707
Average KL loss: 0.376987
Average total loss: 1.298695
tensor(-14.6604, device='cuda:0') tensor(0.1687, device='cuda:0') tensor(-1.6656e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.923359
Average KL loss: 0.376996
Average total loss: 1.300355
tensor(-14.6626, device='cuda:0') tensor(0.1684, device='cuda:0') tensor(-1.1191e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.921964
Average KL loss: 0.376972
Average total loss: 1.298937
tensor(-14.6647, device='cuda:0') tensor(0.1681, device='cuda:0') tensor(-6.9282e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.922302
Average KL loss: 0.376957
Average total loss: 1.299259
tensor(-14.6668, device='cuda:0') tensor(0.1678, device='cuda:0') tensor(-6.0809e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.920671
Average KL loss: 0.376942
Average total loss: 1.297613
tensor(-14.6689, device='cuda:0') tensor(0.1676, device='cuda:0') tensor(4.8812e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.917074
Average KL loss: 0.376957
Average total loss: 1.294030
tensor(-14.6710, device='cuda:0') tensor(0.1674, device='cuda:0') tensor(-2.3660e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.919184
Average KL loss: 0.376956
Average total loss: 1.296140
tensor(-14.6731, device='cuda:0') tensor(0.1672, device='cuda:0') tensor(-3.8334e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.920470
Average KL loss: 0.376987
Average total loss: 1.297457
tensor(-14.6752, device='cuda:0') tensor(0.1671, device='cuda:0') tensor(-7.3355e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.922109
Average KL loss: 0.377002
Average total loss: 1.299111
tensor(-14.6773, device='cuda:0') tensor(0.1669, device='cuda:0') tensor(-1.9072e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.917372
Average KL loss: 0.376981
Average total loss: 1.294353
tensor(-14.6794, device='cuda:0') tensor(0.1667, device='cuda:0') tensor(-1.7629e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.915722
Average KL loss: 0.376975
Average total loss: 1.292697
tensor(-14.6814, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-3.3019e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.917126
Average KL loss: 0.376980
Average total loss: 1.294106
tensor(-14.6835, device='cuda:0') tensor(0.1664, device='cuda:0') tensor(-1.2911e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.913299
Average KL loss: 0.376963
Average total loss: 1.290262
tensor(-14.6856, device='cuda:0') tensor(0.1663, device='cuda:0') tensor(-1.9345e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.917440
Average KL loss: 0.376956
Average total loss: 1.294396
tensor(-14.6876, device='cuda:0') tensor(0.1662, device='cuda:0') tensor(-1.1208e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.915579
Average KL loss: 0.376956
Average total loss: 1.292535
tensor(-14.6897, device='cuda:0') tensor(0.1661, device='cuda:0') tensor(-1.3606e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.914280
Average KL loss: 0.376938
Average total loss: 1.291219
tensor(-14.6917, device='cuda:0') tensor(0.1660, device='cuda:0') tensor(2.3009e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.912588
Average KL loss: 0.376920
Average total loss: 1.289508
tensor(-14.6938, device='cuda:0') tensor(0.1659, device='cuda:0') tensor(1.3253e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.911615
Average KL loss: 0.376916
Average total loss: 1.288531
tensor(-14.6958, device='cuda:0') tensor(0.1658, device='cuda:0') tensor(-6.5884e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.915268
Average KL loss: 0.376904
Average total loss: 1.292171
tensor(-14.6978, device='cuda:0') tensor(0.1657, device='cuda:0') tensor(-1.5466e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.915184
Average KL loss: 0.376873
Average total loss: 1.292057
tensor(-14.6999, device='cuda:0') tensor(0.1657, device='cuda:0') tensor(-1.9560e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.913252
Average KL loss: 0.376859
Average total loss: 1.290111
tensor(-14.7019, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(3.1590e-11, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.911504
Average KL loss: 0.376823
Average total loss: 1.288327
tensor(-14.7039, device='cuda:0') tensor(0.1655, device='cuda:0') tensor(4.3195e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.912649
Average KL loss: 0.376801
Average total loss: 1.289450
tensor(-14.7059, device='cuda:0') tensor(0.1655, device='cuda:0') tensor(-3.7450e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.909598
Average KL loss: 0.376787
Average total loss: 1.286384
tensor(-14.7079, device='cuda:0') tensor(0.1654, device='cuda:0') tensor(-9.4144e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.910383
Average KL loss: 0.376786
Average total loss: 1.287168
tensor(-14.7099, device='cuda:0') tensor(0.1653, device='cuda:0') tensor(9.7755e-11, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.909183
Average KL loss: 0.376763
Average total loss: 1.285946
tensor(-14.7119, device='cuda:0') tensor(0.1653, device='cuda:0') tensor(-1.9415e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.908593
Average KL loss: 0.376737
Average total loss: 1.285330
tensor(-14.7139, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-2.2934e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.908066
Average KL loss: 0.376768
Average total loss: 1.284835
tensor(-14.7159, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(1.5017e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.910470
Average KL loss: 0.376752
Average total loss: 1.287222
tensor(-14.7179, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(2.0481e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.908126
Average KL loss: 0.376744
Average total loss: 1.284870
tensor(-14.7199, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-2.2310e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.907868
Average KL loss: 0.376752
Average total loss: 1.284620
tensor(-14.7219, device='cuda:0') tensor(0.1651, device='cuda:0') tensor(-2.4490e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.909504
Average KL loss: 0.376743
Average total loss: 1.286247
tensor(-14.7238, device='cuda:0') tensor(0.1651, device='cuda:0') tensor(-2.2100e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.907874
Average KL loss: 0.376716
Average total loss: 1.284590
tensor(-14.7258, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-1.7587e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.908487
Average KL loss: 0.376678
Average total loss: 1.285165
tensor(-14.7278, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-2.6674e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.905040
Average KL loss: 0.376655
Average total loss: 1.281695
tensor(-14.7297, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-4.4034e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.908080
Average KL loss: 0.376672
Average total loss: 1.284752
tensor(-14.7317, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-8.6303e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.905031
Average KL loss: 0.376653
Average total loss: 1.281683
tensor(-14.7336, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-7.5571e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.907518
Average KL loss: 0.376630
Average total loss: 1.284148
tensor(-14.7356, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-7.2974e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.903212
Average KL loss: 0.376626
Average total loss: 1.279838
tensor(-14.7375, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-2.8904e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.906296
Average KL loss: 0.376609
Average total loss: 1.282905
tensor(-14.7395, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-7.7268e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.904327
Average KL loss: 0.376561
Average total loss: 1.280888
tensor(-14.7414, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-9.1726e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.902418
Average KL loss: 0.376527
Average total loss: 1.278945
tensor(-14.7434, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-7.0668e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.904415
Average KL loss: 0.376520
Average total loss: 1.280936
tensor(-14.7453, device='cuda:0') tensor(0.1649, device='cuda:0') tensor(8.7388e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.905575
Average KL loss: 0.376474
Average total loss: 1.282049
tensor(-14.7472, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-9.9983e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.900867
Average KL loss: 0.376477
Average total loss: 1.277344
tensor(-14.7491, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-2.6998e-11, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.902966
Average KL loss: 0.376468
Average total loss: 1.279434
tensor(-14.7510, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-8.7987e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.904240
Average KL loss: 0.376473
Average total loss: 1.280713
tensor(-14.7530, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-9.9844e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.902553
Average KL loss: 0.376475
Average total loss: 1.279028
tensor(-14.7549, device='cuda:0') tensor(0.1649, device='cuda:0') tensor(-1.7367e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.901067
Average KL loss: 0.376481
Average total loss: 1.277548
tensor(-14.7568, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(8.1516e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.899364
Average KL loss: 0.376466
Average total loss: 1.275829
tensor(-14.7587, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-1.1771e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.908233
Average KL loss: 0.376463
Average total loss: 1.284696
tensor(-14.7606, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-1.5340e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.901571
Average KL loss: 0.376450
Average total loss: 1.278021
tensor(-14.7625, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-6.3055e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.901183
Average KL loss: 0.376422
Average total loss: 1.277605
tensor(-14.7644, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-6.3348e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.901008
Average KL loss: 0.376417
Average total loss: 1.277425
tensor(-14.7662, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-3.0887e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.900597
Average KL loss: 0.376395
Average total loss: 1.276993
tensor(-14.7681, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-1.6912e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.897818
Average KL loss: 0.376369
Average total loss: 1.274186
tensor(-14.7700, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-1.5715e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.899394
Average KL loss: 0.376347
Average total loss: 1.275741
tensor(-14.7719, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(-1.7350e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.902500
Average KL loss: 0.376329
Average total loss: 1.278830
tensor(-14.7738, device='cuda:0') tensor(0.1650, device='cuda:0') tensor(3.8742e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.901238
Average KL loss: 0.376328
Average total loss: 1.277567
tensor(-14.7756, device='cuda:0') tensor(0.1651, device='cuda:0') tensor(-2.2903e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.898785
Average KL loss: 0.376316
Average total loss: 1.275101
tensor(-14.7775, device='cuda:0') tensor(0.1651, device='cuda:0') tensor(-1.6768e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.900653
Average KL loss: 0.376303
Average total loss: 1.276956
tensor(-14.7793, device='cuda:0') tensor(0.1651, device='cuda:0') tensor(-5.5080e-11, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.899079
Average KL loss: 0.376263
Average total loss: 1.275342
tensor(-14.7812, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-1.8354e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.897860
Average KL loss: 0.376206
Average total loss: 1.274066
tensor(-14.7830, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(8.3222e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.896748
Average KL loss: 0.376165
Average total loss: 1.272914
tensor(-14.7849, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-2.3961e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.898898
Average KL loss: 0.376117
Average total loss: 1.275015
tensor(-14.7867, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-8.0754e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.898292
Average KL loss: 0.376083
Average total loss: 1.274375
tensor(-14.7886, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-1.2847e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.896734
Average KL loss: 0.376052
Average total loss: 1.272786
tensor(-14.7904, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-4.5352e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.896848
Average KL loss: 0.376039
Average total loss: 1.272887
tensor(-14.7923, device='cuda:0') tensor(0.1652, device='cuda:0') tensor(-1.4366e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.897628
Average KL loss: 0.376026
Average total loss: 1.273653
tensor(-14.7941, device='cuda:0') tensor(0.1653, device='cuda:0') tensor(9.7875e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.897135
Average KL loss: 0.375983
Average total loss: 1.273118
tensor(-14.7959, device='cuda:0') tensor(0.1653, device='cuda:0') tensor(4.7639e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.896908
Average KL loss: 0.375948
Average total loss: 1.272856
tensor(-14.7978, device='cuda:0') tensor(0.1653, device='cuda:0') tensor(-1.2075e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.896593
Average KL loss: 0.375959
Average total loss: 1.272552
tensor(-14.7996, device='cuda:0') tensor(0.1653, device='cuda:0') tensor(3.4263e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.897512
Average KL loss: 0.375978
Average total loss: 1.273489
tensor(-14.8014, device='cuda:0') tensor(0.1654, device='cuda:0') tensor(2.0446e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.897840
Average KL loss: 0.375968
Average total loss: 1.273807
tensor(-14.8032, device='cuda:0') tensor(0.1654, device='cuda:0') tensor(2.8355e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.894550
Average KL loss: 0.375940
Average total loss: 1.270490
tensor(-14.8050, device='cuda:0') tensor(0.1654, device='cuda:0') tensor(-5.9416e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.896442
Average KL loss: 0.375891
Average total loss: 1.272333
tensor(-14.8068, device='cuda:0') tensor(0.1654, device='cuda:0') tensor(6.1781e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.896441
Average KL loss: 0.375857
Average total loss: 1.272298
tensor(-14.8086, device='cuda:0') tensor(0.1654, device='cuda:0') tensor(-5.4755e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.896565
Average KL loss: 0.375855
Average total loss: 1.272420
tensor(-14.8104, device='cuda:0') tensor(0.1655, device='cuda:0') tensor(-1.4996e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.896118
Average KL loss: 0.375804
Average total loss: 1.271922
tensor(-14.8122, device='cuda:0') tensor(0.1655, device='cuda:0') tensor(-3.8390e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.898492
Average KL loss: 0.375753
Average total loss: 1.274245
tensor(-14.8140, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(-2.7724e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.896601
Average KL loss: 0.375709
Average total loss: 1.272311
tensor(-14.8158, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(1.2403e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.897159
Average KL loss: 0.375714
Average total loss: 1.272873
tensor(-14.8176, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(-3.0104e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.894784
Average KL loss: 0.375675
Average total loss: 1.270459
tensor(-14.8194, device='cuda:0') tensor(0.1656, device='cuda:0') tensor(-3.5726e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.895421
Average KL loss: 0.375662
Average total loss: 1.271082
tensor(-14.8212, device='cuda:0') tensor(0.1657, device='cuda:0') tensor(-4.7346e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.896449
Average KL loss: 0.375611
Average total loss: 1.272060
tensor(-14.8230, device='cuda:0') tensor(0.1657, device='cuda:0') tensor(-2.0906e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.893862
Average KL loss: 0.375565
Average total loss: 1.269427
tensor(-14.8248, device='cuda:0') tensor(0.1657, device='cuda:0') tensor(-1.1627e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.897401
Average KL loss: 0.375514
Average total loss: 1.272916
tensor(-14.8265, device='cuda:0') tensor(0.1658, device='cuda:0') tensor(3.0495e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.892112
Average KL loss: 0.375478
Average total loss: 1.267591
tensor(-14.8283, device='cuda:0') tensor(0.1658, device='cuda:0') tensor(2.8176e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.892764
Average KL loss: 0.375462
Average total loss: 1.268226
tensor(-14.8301, device='cuda:0') tensor(0.1658, device='cuda:0') tensor(1.0049e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.895035
Average KL loss: 0.375440
Average total loss: 1.270475
tensor(-14.8318, device='cuda:0') tensor(0.1659, device='cuda:0') tensor(-1.6623e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.895118
Average KL loss: 0.375409
Average total loss: 1.270527
tensor(-14.8336, device='cuda:0') tensor(0.1659, device='cuda:0') tensor(-9.9203e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.894259
Average KL loss: 0.375343
Average total loss: 1.269602
tensor(-14.8353, device='cuda:0') tensor(0.1659, device='cuda:0') tensor(1.6261e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.893366
Average KL loss: 0.375311
Average total loss: 1.268677
tensor(-14.8371, device='cuda:0') tensor(0.1659, device='cuda:0') tensor(3.5203e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.892945
Average KL loss: 0.375306
Average total loss: 1.268251
tensor(-14.8388, device='cuda:0') tensor(0.1660, device='cuda:0') tensor(4.2685e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.890803
Average KL loss: 0.375286
Average total loss: 1.266089
tensor(-14.8406, device='cuda:0') tensor(0.1660, device='cuda:0') tensor(-2.5660e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.891990
Average KL loss: 0.375267
Average total loss: 1.267256
tensor(-14.8423, device='cuda:0') tensor(0.1660, device='cuda:0') tensor(-8.6560e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.891467
Average KL loss: 0.375223
Average total loss: 1.266690
tensor(-14.8441, device='cuda:0') tensor(0.1661, device='cuda:0') tensor(-8.5447e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.892796
Average KL loss: 0.375190
Average total loss: 1.267986
tensor(-14.8458, device='cuda:0') tensor(0.1661, device='cuda:0') tensor(-1.3874e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.892050
Average KL loss: 0.375205
Average total loss: 1.267255
tensor(-14.8475, device='cuda:0') tensor(0.1662, device='cuda:0') tensor(-1.8789e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.893960
Average KL loss: 0.375201
Average total loss: 1.269160
tensor(-14.8493, device='cuda:0') tensor(0.1662, device='cuda:0') tensor(-1.4114e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.892680
Average KL loss: 0.375178
Average total loss: 1.267858
tensor(-14.8510, device='cuda:0') tensor(0.1662, device='cuda:0') tensor(-1.3464e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.892538
Average KL loss: 0.375162
Average total loss: 1.267699
tensor(-14.8527, device='cuda:0') tensor(0.1663, device='cuda:0') tensor(-5.9186e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.893881
Average KL loss: 0.375177
Average total loss: 1.269059
tensor(-14.8545, device='cuda:0') tensor(0.1664, device='cuda:0') tensor(-3.4173e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.891583
Average KL loss: 0.375176
Average total loss: 1.266759
tensor(-14.8562, device='cuda:0') tensor(0.1664, device='cuda:0') tensor(-1.4280e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.891769
Average KL loss: 0.375164
Average total loss: 1.266933
tensor(-14.8579, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(1.8778e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.891142
Average KL loss: 0.375137
Average total loss: 1.266279
tensor(-14.8596, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(-9.5602e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.892244
Average KL loss: 0.375114
Average total loss: 1.267358
tensor(-14.8598, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(-1.2344e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.894056
Average KL loss: 0.375111
Average total loss: 1.269168
tensor(-14.8600, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(5.3328e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.891522
Average KL loss: 0.375113
Average total loss: 1.266634
tensor(-14.8602, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(-8.2272e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.891855
Average KL loss: 0.375115
Average total loss: 1.266970
tensor(-14.8604, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(-4.5216e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.890239
Average KL loss: 0.375115
Average total loss: 1.265353
tensor(-14.8605, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(-5.2443e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.891049
Average KL loss: 0.375114
Average total loss: 1.266163
tensor(-14.8607, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(-3.3426e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.891027
Average KL loss: 0.375112
Average total loss: 1.266139
tensor(-14.8609, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(-2.6146e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.891738
Average KL loss: 0.375111
Average total loss: 1.266849
tensor(-14.8611, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(7.5008e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.892256
Average KL loss: 0.375111
Average total loss: 1.267368
tensor(-14.8613, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(3.9692e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.893379
Average KL loss: 0.375111
Average total loss: 1.268491
tensor(-14.8615, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(-9.9143e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.891995
Average KL loss: 0.375110
Average total loss: 1.267105
tensor(-14.8617, device='cuda:0') tensor(0.1665, device='cuda:0') tensor(-3.0163e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.893333
Average KL loss: 0.375113
Average total loss: 1.268446
tensor(-14.8619, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(2.3933e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.890293
Average KL loss: 0.375113
Average total loss: 1.265406
tensor(-14.8621, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-9.2055e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.892666
Average KL loss: 0.375110
Average total loss: 1.267776
tensor(-14.8622, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-1.2709e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.890865
Average KL loss: 0.375105
Average total loss: 1.265971
tensor(-14.8624, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-5.0237e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.891943
Average KL loss: 0.375103
Average total loss: 1.267046
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-3.1607e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.891873
Average KL loss: 0.375102
Average total loss: 1.266975
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(9.4019e-11, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.890459
Average KL loss: 0.375101
Average total loss: 1.265561
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-1.7011e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.893289
Average KL loss: 0.375101
Average total loss: 1.268391
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-2.9694e-11, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.894494
Average KL loss: 0.375101
Average total loss: 1.269595
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-1.3237e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.891801
Average KL loss: 0.375101
Average total loss: 1.266902
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-9.2326e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.892976
Average KL loss: 0.375101
Average total loss: 1.268077
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-8.1252e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.890555
Average KL loss: 0.375101
Average total loss: 1.265655
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-1.3355e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.891260
Average KL loss: 0.375100
Average total loss: 1.266360
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(2.8847e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.892517
Average KL loss: 0.375100
Average total loss: 1.267618
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(4.4079e-11, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.891875
Average KL loss: 0.375100
Average total loss: 1.266975
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-1.4797e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.892193
Average KL loss: 0.375100
Average total loss: 1.267293
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-5.3345e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.890339
Average KL loss: 0.375100
Average total loss: 1.265438
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(6.0750e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.892162
Average KL loss: 0.375100
Average total loss: 1.267262
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-7.3742e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.893024
Average KL loss: 0.375100
Average total loss: 1.268124
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(5.9406e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.892556
Average KL loss: 0.375100
Average total loss: 1.267656
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-2.3631e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.893947
Average KL loss: 0.375100
Average total loss: 1.269047
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(2.0164e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.891384
Average KL loss: 0.375100
Average total loss: 1.266484
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-2.0867e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.892055
Average KL loss: 0.375100
Average total loss: 1.267155
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(1.2021e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.890579
Average KL loss: 0.375100
Average total loss: 1.265678
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-4.6199e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.891483
Average KL loss: 0.375100
Average total loss: 1.266583
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(7.8196e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.892195
Average KL loss: 0.375100
Average total loss: 1.267295
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(9.8623e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.888913
Average KL loss: 0.375100
Average total loss: 1.264012
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-1.3954e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.893320
Average KL loss: 0.375100
Average total loss: 1.268420
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-3.1805e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.889844
Average KL loss: 0.375100
Average total loss: 1.264944
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(4.4695e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.889695
Average KL loss: 0.375100
Average total loss: 1.264795
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-1.5425e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.889670
Average KL loss: 0.375100
Average total loss: 1.264770
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-9.9828e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.891670
Average KL loss: 0.375100
Average total loss: 1.266770
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(1.0127e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.891797
Average KL loss: 0.375100
Average total loss: 1.266897
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(8.9666e-12, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.890646
Average KL loss: 0.375100
Average total loss: 1.265746
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-9.1806e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.894284
Average KL loss: 0.375100
Average total loss: 1.269384
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-1.3710e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.891672
Average KL loss: 0.375100
Average total loss: 1.266772
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-1.3706e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.894608
Average KL loss: 0.375100
Average total loss: 1.269708
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-3.9185e-10, device='cuda:0')
 Percentile value: -14.876290321350098
Non-zero model percentage: 32.76801300048828%, Non-zero mask percentage: 32.76801300048828%

--- Pruning Level [5/24]: ---
conv1.weight         | nonzeros =    1708 /    1728             ( 98.84%) | total_pruned =      20 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   31954 /   36864             ( 86.68%) | total_pruned =    4910 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   32102 /   36864             ( 87.08%) | total_pruned =    4762 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   30404 /   36864             ( 82.48%) | total_pruned =    6460 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   29609 /   36864             ( 80.32%) | total_pruned =    7255 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   60813 /   73728             ( 82.48%) | total_pruned =   12915 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  108412 /  147456             ( 73.52%) | total_pruned =   39044 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7716 /    8192             ( 94.19%) | total_pruned =     476 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   99196 /  147456             ( 67.27%) | total_pruned =   48260 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   94822 /  147456             ( 64.31%) | total_pruned =   52634 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  186808 /  294912             ( 63.34%) | total_pruned =  108104 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  287485 /  589824             ( 48.74%) | total_pruned =  302339 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   27454 /   32768             ( 83.78%) | total_pruned =    5314 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  185615 /  589824             ( 31.47%) | total_pruned =  404209 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  180285 /  589824             ( 30.57%) | total_pruned =  409539 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  418493 / 1179648             ( 35.48%) | total_pruned =  761155 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  595399 / 2359296             ( 25.24%) | total_pruned = 1763897 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   91227 /  131072             ( 69.60%) | total_pruned =   39845 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  558571 / 2359296             ( 23.68%) | total_pruned = 1800725 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  620361 / 2359296             ( 26.29%) | total_pruned = 1738935 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
linear.weight        | nonzeros =    5043 /    5120             ( 98.50%) | total_pruned =      77 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 3663058, pruned : 7515704, total: 11178762, Compression rate :       3.05x  ( 67.23% pruned)
Train Epoch: 24/100 Loss: 0.000052 Accuracy: 86.54 100.00 % Best test Accuracy: 86.54%
tensor(-14.8626, device='cuda:0') tensor(0.1666, device='cuda:0') tensor(-1.4214e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.923443
Average KL loss: 0.374305
Average total loss: 1.297748
tensor(-14.8645, device='cuda:0') tensor(0.1610, device='cuda:0') tensor(2.9142e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.925986
Average KL loss: 0.373395
Average total loss: 1.299381
tensor(-14.8663, device='cuda:0') tensor(0.1574, device='cuda:0') tensor(-2.7209e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.929741
Average KL loss: 0.372802
Average total loss: 1.302543
tensor(-14.8681, device='cuda:0') tensor(0.1551, device='cuda:0') tensor(-7.6530e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.927178
Average KL loss: 0.372349
Average total loss: 1.299527
tensor(-14.8699, device='cuda:0') tensor(0.1538, device='cuda:0') tensor(-1.4734e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.928020
Average KL loss: 0.372014
Average total loss: 1.300033
tensor(-14.8716, device='cuda:0') tensor(0.1531, device='cuda:0') tensor(-6.3576e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.926906
Average KL loss: 0.371779
Average total loss: 1.298685
tensor(-14.8733, device='cuda:0') tensor(0.1527, device='cuda:0') tensor(-8.0439e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.927312
Average KL loss: 0.371563
Average total loss: 1.298874
tensor(-14.8750, device='cuda:0') tensor(0.1524, device='cuda:0') tensor(-5.6091e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.927966
Average KL loss: 0.371395
Average total loss: 1.299361
tensor(-14.8767, device='cuda:0') tensor(0.1522, device='cuda:0') tensor(-1.6032e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.923968
Average KL loss: 0.371257
Average total loss: 1.295224
tensor(-14.8784, device='cuda:0') tensor(0.1521, device='cuda:0') tensor(-4.3886e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.927256
Average KL loss: 0.371115
Average total loss: 1.298371
tensor(-14.8801, device='cuda:0') tensor(0.1519, device='cuda:0') tensor(-1.7720e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.920645
Average KL loss: 0.371043
Average total loss: 1.291688
tensor(-14.8818, device='cuda:0') tensor(0.1518, device='cuda:0') tensor(-1.3519e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.919088
Average KL loss: 0.370966
Average total loss: 1.290054
tensor(-14.8835, device='cuda:0') tensor(0.1517, device='cuda:0') tensor(-8.4918e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.919368
Average KL loss: 0.370891
Average total loss: 1.290259
tensor(-14.8852, device='cuda:0') tensor(0.1517, device='cuda:0') tensor(-5.3112e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.920342
Average KL loss: 0.370855
Average total loss: 1.291196
tensor(-14.8869, device='cuda:0') tensor(0.1516, device='cuda:0') tensor(-1.2962e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.916893
Average KL loss: 0.370775
Average total loss: 1.287668
tensor(-14.8886, device='cuda:0') tensor(0.1516, device='cuda:0') tensor(-6.0113e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.921275
Average KL loss: 0.370710
Average total loss: 1.291985
tensor(-14.8902, device='cuda:0') tensor(0.1516, device='cuda:0') tensor(-1.2549e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.913209
Average KL loss: 0.370632
Average total loss: 1.283841
tensor(-14.8919, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(-5.2037e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.915732
Average KL loss: 0.370542
Average total loss: 1.286274
tensor(-14.8936, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(-1.2959e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.915707
Average KL loss: 0.370482
Average total loss: 1.286188
tensor(-14.8952, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(4.1688e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.912626
Average KL loss: 0.370413
Average total loss: 1.283039
tensor(-14.8969, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(6.5527e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.911752
Average KL loss: 0.370368
Average total loss: 1.282121
tensor(-14.8985, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(-2.4112e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.913389
Average KL loss: 0.370348
Average total loss: 1.283737
tensor(-14.9002, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(-1.7377e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.913447
Average KL loss: 0.370284
Average total loss: 1.283731
tensor(-14.9018, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(5.6272e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.911519
Average KL loss: 0.370244
Average total loss: 1.281763
tensor(-14.9035, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(-6.6423e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.911537
Average KL loss: 0.370220
Average total loss: 1.281757
tensor(-14.9051, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(-6.2484e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.912244
Average KL loss: 0.370190
Average total loss: 1.282434
tensor(-14.9068, device='cuda:0') tensor(0.1516, device='cuda:0') tensor(1.1176e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.908966
Average KL loss: 0.370156
Average total loss: 1.279122
tensor(-14.9084, device='cuda:0') tensor(0.1516, device='cuda:0') tensor(-1.8114e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.908944
Average KL loss: 0.370089
Average total loss: 1.279032
tensor(-14.9100, device='cuda:0') tensor(0.1516, device='cuda:0') tensor(-1.9851e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.907993
Average KL loss: 0.370031
Average total loss: 1.278024
tensor(-14.9117, device='cuda:0') tensor(0.1516, device='cuda:0') tensor(-2.2747e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.911174
Average KL loss: 0.369981
Average total loss: 1.281155
tensor(-14.9133, device='cuda:0') tensor(0.1517, device='cuda:0') tensor(-1.1173e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.909342
Average KL loss: 0.369932
Average total loss: 1.279274
tensor(-14.9150, device='cuda:0') tensor(0.1517, device='cuda:0') tensor(-3.3126e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.907238
Average KL loss: 0.369858
Average total loss: 1.277096
tensor(-14.9166, device='cuda:0') tensor(0.1517, device='cuda:0') tensor(-2.2867e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.907260
Average KL loss: 0.369801
Average total loss: 1.277061
tensor(-14.9182, device='cuda:0') tensor(0.1517, device='cuda:0') tensor(1.1088e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.911776
Average KL loss: 0.369754
Average total loss: 1.281529
tensor(-14.9198, device='cuda:0') tensor(0.1518, device='cuda:0') tensor(-1.9069e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.909958
Average KL loss: 0.369716
Average total loss: 1.279674
tensor(-14.9214, device='cuda:0') tensor(0.1518, device='cuda:0') tensor(-3.2694e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.908042
Average KL loss: 0.369680
Average total loss: 1.277722
tensor(-14.9230, device='cuda:0') tensor(0.1519, device='cuda:0') tensor(7.6265e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.906964
Average KL loss: 0.369636
Average total loss: 1.276600
tensor(-14.9246, device='cuda:0') tensor(0.1519, device='cuda:0') tensor(-1.8698e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.904217
Average KL loss: 0.369560
Average total loss: 1.273777
tensor(-14.9262, device='cuda:0') tensor(0.1519, device='cuda:0') tensor(-1.3011e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.906431
Average KL loss: 0.369507
Average total loss: 1.275937
tensor(-14.9278, device='cuda:0') tensor(0.1519, device='cuda:0') tensor(-1.7297e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.908826
Average KL loss: 0.369459
Average total loss: 1.278285
tensor(-14.9294, device='cuda:0') tensor(0.1520, device='cuda:0') tensor(-4.5782e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.906664
Average KL loss: 0.369403
Average total loss: 1.276067
tensor(-14.9310, device='cuda:0') tensor(0.1520, device='cuda:0') tensor(-2.3861e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.904334
Average KL loss: 0.369342
Average total loss: 1.273676
tensor(-14.9326, device='cuda:0') tensor(0.1521, device='cuda:0') tensor(-6.5912e-11, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.908756
Average KL loss: 0.369288
Average total loss: 1.278044
tensor(-14.9342, device='cuda:0') tensor(0.1521, device='cuda:0') tensor(-7.7137e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.901271
Average KL loss: 0.369262
Average total loss: 1.270532
tensor(-14.9358, device='cuda:0') tensor(0.1521, device='cuda:0') tensor(1.0068e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.901129
Average KL loss: 0.369206
Average total loss: 1.270336
tensor(-14.9374, device='cuda:0') tensor(0.1522, device='cuda:0') tensor(5.1423e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.903799
Average KL loss: 0.369137
Average total loss: 1.272936
tensor(-14.9390, device='cuda:0') tensor(0.1522, device='cuda:0') tensor(4.5098e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.902899
Average KL loss: 0.369099
Average total loss: 1.271998
tensor(-14.9406, device='cuda:0') tensor(0.1523, device='cuda:0') tensor(-2.5108e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.901990
Average KL loss: 0.369060
Average total loss: 1.271049
tensor(-14.9422, device='cuda:0') tensor(0.1523, device='cuda:0') tensor(-1.5575e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.901410
Average KL loss: 0.369008
Average total loss: 1.270419
tensor(-14.9437, device='cuda:0') tensor(0.1524, device='cuda:0') tensor(-1.2138e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.902552
Average KL loss: 0.368949
Average total loss: 1.271500
tensor(-14.9453, device='cuda:0') tensor(0.1524, device='cuda:0') tensor(-2.2756e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.903376
Average KL loss: 0.368894
Average total loss: 1.272270
tensor(-14.9469, device='cuda:0') tensor(0.1525, device='cuda:0') tensor(2.8988e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.903520
Average KL loss: 0.368820
Average total loss: 1.272340
tensor(-14.9485, device='cuda:0') tensor(0.1525, device='cuda:0') tensor(-8.5246e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.906215
Average KL loss: 0.368821
Average total loss: 1.275036
tensor(-14.9500, device='cuda:0') tensor(0.1526, device='cuda:0') tensor(-6.4711e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.900694
Average KL loss: 0.368819
Average total loss: 1.269513
tensor(-14.9516, device='cuda:0') tensor(0.1527, device='cuda:0') tensor(-3.0947e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.902539
Average KL loss: 0.368837
Average total loss: 1.271376
tensor(-14.9531, device='cuda:0') tensor(0.1527, device='cuda:0') tensor(-1.4903e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.906022
Average KL loss: 0.368788
Average total loss: 1.274810
tensor(-14.9547, device='cuda:0') tensor(0.1528, device='cuda:0') tensor(7.7431e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.901283
Average KL loss: 0.368765
Average total loss: 1.270048
tensor(-14.9563, device='cuda:0') tensor(0.1528, device='cuda:0') tensor(1.9401e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.896933
Average KL loss: 0.368718
Average total loss: 1.265651
tensor(-14.9578, device='cuda:0') tensor(0.1529, device='cuda:0') tensor(1.3986e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.898634
Average KL loss: 0.368676
Average total loss: 1.267310
tensor(-14.9594, device='cuda:0') tensor(0.1529, device='cuda:0') tensor(-8.2105e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.899350
Average KL loss: 0.368658
Average total loss: 1.268008
tensor(-14.9609, device='cuda:0') tensor(0.1530, device='cuda:0') tensor(1.6460e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.900740
Average KL loss: 0.368643
Average total loss: 1.269383
tensor(-14.9624, device='cuda:0') tensor(0.1530, device='cuda:0') tensor(1.1441e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.898348
Average KL loss: 0.368644
Average total loss: 1.266992
tensor(-14.9640, device='cuda:0') tensor(0.1531, device='cuda:0') tensor(-1.0060e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.898778
Average KL loss: 0.368595
Average total loss: 1.267373
tensor(-14.9655, device='cuda:0') tensor(0.1532, device='cuda:0') tensor(-2.8411e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.898621
Average KL loss: 0.368539
Average total loss: 1.267161
tensor(-14.9671, device='cuda:0') tensor(0.1532, device='cuda:0') tensor(-1.9244e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.897139
Average KL loss: 0.368490
Average total loss: 1.265629
tensor(-14.9686, device='cuda:0') tensor(0.1533, device='cuda:0') tensor(-1.2519e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.900217
Average KL loss: 0.368434
Average total loss: 1.268651
tensor(-14.9701, device='cuda:0') tensor(0.1533, device='cuda:0') tensor(-8.5204e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.896237
Average KL loss: 0.368424
Average total loss: 1.264661
tensor(-14.9717, device='cuda:0') tensor(0.1534, device='cuda:0') tensor(-1.5168e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.897274
Average KL loss: 0.368386
Average total loss: 1.265660
tensor(-14.9732, device='cuda:0') tensor(0.1534, device='cuda:0') tensor(-1.2625e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.899270
Average KL loss: 0.368346
Average total loss: 1.267617
tensor(-14.9748, device='cuda:0') tensor(0.1535, device='cuda:0') tensor(3.6774e-11, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.898144
Average KL loss: 0.368336
Average total loss: 1.266481
tensor(-14.9763, device='cuda:0') tensor(0.1536, device='cuda:0') tensor(4.1748e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.897279
Average KL loss: 0.368315
Average total loss: 1.265594
tensor(-14.9778, device='cuda:0') tensor(0.1536, device='cuda:0') tensor(4.5220e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.900163
Average KL loss: 0.368283
Average total loss: 1.268446
tensor(-14.9793, device='cuda:0') tensor(0.1537, device='cuda:0') tensor(-7.7764e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.897158
Average KL loss: 0.368249
Average total loss: 1.265407
tensor(-14.9809, device='cuda:0') tensor(0.1538, device='cuda:0') tensor(-2.4640e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.896062
Average KL loss: 0.368232
Average total loss: 1.264293
tensor(-14.9824, device='cuda:0') tensor(0.1538, device='cuda:0') tensor(-1.3706e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.895795
Average KL loss: 0.368220
Average total loss: 1.264015
tensor(-14.9839, device='cuda:0') tensor(0.1539, device='cuda:0') tensor(-8.5782e-11, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.898184
Average KL loss: 0.368189
Average total loss: 1.266373
tensor(-14.9854, device='cuda:0') tensor(0.1539, device='cuda:0') tensor(-3.4026e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.896993
Average KL loss: 0.368162
Average total loss: 1.265155
tensor(-14.9869, device='cuda:0') tensor(0.1540, device='cuda:0') tensor(-1.4973e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.896088
Average KL loss: 0.368120
Average total loss: 1.264208
tensor(-14.9884, device='cuda:0') tensor(0.1541, device='cuda:0') tensor(-1.3461e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.898589
Average KL loss: 0.368088
Average total loss: 1.266678
tensor(-14.9899, device='cuda:0') tensor(0.1541, device='cuda:0') tensor(1.2321e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.896668
Average KL loss: 0.368030
Average total loss: 1.264698
tensor(-14.9914, device='cuda:0') tensor(0.1542, device='cuda:0') tensor(4.8232e-11, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.897334
Average KL loss: 0.368008
Average total loss: 1.265341
tensor(-14.9929, device='cuda:0') tensor(0.1543, device='cuda:0') tensor(6.1292e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.896946
Average KL loss: 0.367993
Average total loss: 1.264939
tensor(-14.9944, device='cuda:0') tensor(0.1543, device='cuda:0') tensor(-4.3893e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.894095
Average KL loss: 0.367952
Average total loss: 1.262047
tensor(-14.9959, device='cuda:0') tensor(0.1544, device='cuda:0') tensor(2.0251e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.898172
Average KL loss: 0.367876
Average total loss: 1.266048
tensor(-14.9974, device='cuda:0') tensor(0.1544, device='cuda:0') tensor(7.1737e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.896824
Average KL loss: 0.367829
Average total loss: 1.264653
tensor(-14.9989, device='cuda:0') tensor(0.1545, device='cuda:0') tensor(-5.2112e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.893765
Average KL loss: 0.367773
Average total loss: 1.261537
tensor(-15.0003, device='cuda:0') tensor(0.1545, device='cuda:0') tensor(-2.2636e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.895622
Average KL loss: 0.367727
Average total loss: 1.263349
tensor(-15.0018, device='cuda:0') tensor(0.1546, device='cuda:0') tensor(-1.8331e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.894435
Average KL loss: 0.367695
Average total loss: 1.262130
tensor(-15.0033, device='cuda:0') tensor(0.1547, device='cuda:0') tensor(-1.2028e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.894957
Average KL loss: 0.367678
Average total loss: 1.262635
tensor(-15.0048, device='cuda:0') tensor(0.1547, device='cuda:0') tensor(-1.8462e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.896945
Average KL loss: 0.367655
Average total loss: 1.264599
tensor(-15.0063, device='cuda:0') tensor(0.1548, device='cuda:0') tensor(-5.5864e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.894313
Average KL loss: 0.367663
Average total loss: 1.261976
tensor(-15.0078, device='cuda:0') tensor(0.1548, device='cuda:0') tensor(-1.1606e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.894107
Average KL loss: 0.367658
Average total loss: 1.261765
tensor(-15.0093, device='cuda:0') tensor(0.1549, device='cuda:0') tensor(-1.7101e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.893396
Average KL loss: 0.367658
Average total loss: 1.261054
tensor(-15.0107, device='cuda:0') tensor(0.1550, device='cuda:0') tensor(6.4003e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.892895
Average KL loss: 0.367665
Average total loss: 1.260560
tensor(-15.0122, device='cuda:0') tensor(0.1550, device='cuda:0') tensor(-1.3258e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.893876
Average KL loss: 0.367667
Average total loss: 1.261543
tensor(-15.0137, device='cuda:0') tensor(0.1551, device='cuda:0') tensor(-3.2027e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.892622
Average KL loss: 0.367644
Average total loss: 1.260266
tensor(-15.0151, device='cuda:0') tensor(0.1551, device='cuda:0') tensor(8.4081e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.891474
Average KL loss: 0.367617
Average total loss: 1.259091
tensor(-15.0166, device='cuda:0') tensor(0.1552, device='cuda:0') tensor(-5.7560e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.891677
Average KL loss: 0.367600
Average total loss: 1.259277
tensor(-15.0181, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-8.5719e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.894445
Average KL loss: 0.367586
Average total loss: 1.262031
tensor(-15.0195, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-1.3469e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.894436
Average KL loss: 0.367566
Average total loss: 1.262003
tensor(-15.0210, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-1.5205e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.892468
Average KL loss: 0.367548
Average total loss: 1.260016
tensor(-15.0224, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-5.9392e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.891808
Average KL loss: 0.367529
Average total loss: 1.259337
tensor(-15.0239, device='cuda:0') tensor(0.1555, device='cuda:0') tensor(-3.9541e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.892309
Average KL loss: 0.367518
Average total loss: 1.259826
tensor(-15.0253, device='cuda:0') tensor(0.1556, device='cuda:0') tensor(-1.4483e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.892991
Average KL loss: 0.367497
Average total loss: 1.260488
tensor(-15.0268, device='cuda:0') tensor(0.1556, device='cuda:0') tensor(-3.0533e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.895268
Average KL loss: 0.367439
Average total loss: 1.262707
tensor(-15.0282, device='cuda:0') tensor(0.1557, device='cuda:0') tensor(-7.9396e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.894518
Average KL loss: 0.367397
Average total loss: 1.261915
tensor(-15.0296, device='cuda:0') tensor(0.1557, device='cuda:0') tensor(1.4865e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.889888
Average KL loss: 0.367398
Average total loss: 1.257286
tensor(-15.0311, device='cuda:0') tensor(0.1558, device='cuda:0') tensor(-6.6250e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.892430
Average KL loss: 0.367403
Average total loss: 1.259833
tensor(-15.0325, device='cuda:0') tensor(0.1559, device='cuda:0') tensor(2.6886e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.894339
Average KL loss: 0.367383
Average total loss: 1.261723
tensor(-15.0340, device='cuda:0') tensor(0.1559, device='cuda:0') tensor(-1.3877e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.891558
Average KL loss: 0.367373
Average total loss: 1.258931
tensor(-15.0354, device='cuda:0') tensor(0.1560, device='cuda:0') tensor(-3.3083e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.891968
Average KL loss: 0.367350
Average total loss: 1.259318
tensor(-15.0368, device='cuda:0') tensor(0.1561, device='cuda:0') tensor(9.0983e-11, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.892105
Average KL loss: 0.367327
Average total loss: 1.259431
tensor(-15.0383, device='cuda:0') tensor(0.1561, device='cuda:0') tensor(-1.1748e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.891554
Average KL loss: 0.367285
Average total loss: 1.258839
tensor(-15.0397, device='cuda:0') tensor(0.1562, device='cuda:0') tensor(-1.0407e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.894771
Average KL loss: 0.367240
Average total loss: 1.262010
tensor(-15.0411, device='cuda:0') tensor(0.1562, device='cuda:0') tensor(-5.8834e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.890550
Average KL loss: 0.367205
Average total loss: 1.257755
tensor(-15.0426, device='cuda:0') tensor(0.1563, device='cuda:0') tensor(-1.6677e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.891986
Average KL loss: 0.367150
Average total loss: 1.259135
tensor(-15.0440, device='cuda:0') tensor(0.1564, device='cuda:0') tensor(-2.3636e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.889382
Average KL loss: 0.367119
Average total loss: 1.256501
tensor(-15.0454, device='cuda:0') tensor(0.1564, device='cuda:0') tensor(-1.3384e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.890089
Average KL loss: 0.367108
Average total loss: 1.257197
tensor(-15.0469, device='cuda:0') tensor(0.1565, device='cuda:0') tensor(-3.4032e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.890425
Average KL loss: 0.367073
Average total loss: 1.257499
tensor(-15.0483, device='cuda:0') tensor(0.1566, device='cuda:0') tensor(-6.7484e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.890857
Average KL loss: 0.367027
Average total loss: 1.257884
tensor(-15.0497, device='cuda:0') tensor(0.1566, device='cuda:0') tensor(-1.3250e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.890548
Average KL loss: 0.367004
Average total loss: 1.257552
tensor(-15.0511, device='cuda:0') tensor(0.1567, device='cuda:0') tensor(7.4833e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.889664
Average KL loss: 0.366944
Average total loss: 1.256608
tensor(-15.0525, device='cuda:0') tensor(0.1567, device='cuda:0') tensor(-2.6120e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.888840
Average KL loss: 0.366901
Average total loss: 1.255741
tensor(-15.0539, device='cuda:0') tensor(0.1568, device='cuda:0') tensor(-4.5401e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.888488
Average KL loss: 0.366904
Average total loss: 1.255392
tensor(-15.0553, device='cuda:0') tensor(0.1569, device='cuda:0') tensor(-1.5820e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.889933
Average KL loss: 0.366896
Average total loss: 1.256829
tensor(-15.0567, device='cuda:0') tensor(0.1570, device='cuda:0') tensor(7.9130e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.891233
Average KL loss: 0.366866
Average total loss: 1.258098
tensor(-15.0581, device='cuda:0') tensor(0.1570, device='cuda:0') tensor(-1.4237e-11, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.890825
Average KL loss: 0.366831
Average total loss: 1.257656
tensor(-15.0595, device='cuda:0') tensor(0.1571, device='cuda:0') tensor(6.3091e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.888923
Average KL loss: 0.366811
Average total loss: 1.255734
tensor(-15.0609, device='cuda:0') tensor(0.1571, device='cuda:0') tensor(4.2764e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.887220
Average KL loss: 0.366810
Average total loss: 1.254030
tensor(-15.0623, device='cuda:0') tensor(0.1572, device='cuda:0') tensor(-5.0772e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.889673
Average KL loss: 0.366818
Average total loss: 1.256492
tensor(-15.0637, device='cuda:0') tensor(0.1573, device='cuda:0') tensor(5.1948e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.888969
Average KL loss: 0.366804
Average total loss: 1.255773
tensor(-15.0651, device='cuda:0') tensor(0.1574, device='cuda:0') tensor(-4.1734e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.889436
Average KL loss: 0.366774
Average total loss: 1.256210
tensor(-15.0665, device='cuda:0') tensor(0.1574, device='cuda:0') tensor(-2.9231e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.889738
Average KL loss: 0.366749
Average total loss: 1.256487
tensor(-15.0679, device='cuda:0') tensor(0.1575, device='cuda:0') tensor(-4.5653e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.887944
Average KL loss: 0.366726
Average total loss: 1.254670
tensor(-15.0692, device='cuda:0') tensor(0.1575, device='cuda:0') tensor(1.2785e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.888221
Average KL loss: 0.366696
Average total loss: 1.254917
tensor(-15.0706, device='cuda:0') tensor(0.1576, device='cuda:0') tensor(-1.3734e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.888854
Average KL loss: 0.366674
Average total loss: 1.255528
tensor(-15.0720, device='cuda:0') tensor(0.1577, device='cuda:0') tensor(-1.7190e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.888740
Average KL loss: 0.366647
Average total loss: 1.255387
tensor(-15.0734, device='cuda:0') tensor(0.1577, device='cuda:0') tensor(-3.2460e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.889738
Average KL loss: 0.366632
Average total loss: 1.256370
tensor(-15.0748, device='cuda:0') tensor(0.1578, device='cuda:0') tensor(-1.6680e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.887965
Average KL loss: 0.366602
Average total loss: 1.254568
tensor(-15.0762, device='cuda:0') tensor(0.1578, device='cuda:0') tensor(-1.1757e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.888868
Average KL loss: 0.366567
Average total loss: 1.255435
tensor(-15.0776, device='cuda:0') tensor(0.1579, device='cuda:0') tensor(-1.8168e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.887396
Average KL loss: 0.366554
Average total loss: 1.253950
tensor(-15.0777, device='cuda:0') tensor(0.1579, device='cuda:0') tensor(-6.7152e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.890404
Average KL loss: 0.366554
Average total loss: 1.256958
tensor(-15.0778, device='cuda:0') tensor(0.1579, device='cuda:0') tensor(7.9051e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.886520
Average KL loss: 0.366553
Average total loss: 1.253072
tensor(-15.0780, device='cuda:0') tensor(0.1579, device='cuda:0') tensor(2.0086e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.887504
Average KL loss: 0.366552
Average total loss: 1.254056
tensor(-15.0781, device='cuda:0') tensor(0.1579, device='cuda:0') tensor(1.8039e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.887597
Average KL loss: 0.366551
Average total loss: 1.254148
tensor(-15.0783, device='cuda:0') tensor(0.1579, device='cuda:0') tensor(6.1037e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.888160
Average KL loss: 0.366547
Average total loss: 1.254707
tensor(-15.0784, device='cuda:0') tensor(0.1579, device='cuda:0') tensor(-3.3630e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.887672
Average KL loss: 0.366545
Average total loss: 1.254217
tensor(-15.0785, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-8.7032e-11, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.887210
Average KL loss: 0.366543
Average total loss: 1.253753
tensor(-15.0787, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(3.0673e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.890002
Average KL loss: 0.366541
Average total loss: 1.256543
tensor(-15.0788, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-1.0105e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.888938
Average KL loss: 0.366540
Average total loss: 1.255478
tensor(-15.0790, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-5.8299e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.886198
Average KL loss: 0.366539
Average total loss: 1.252737
tensor(-15.0791, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-5.2557e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.887609
Average KL loss: 0.366537
Average total loss: 1.254146
tensor(-15.0793, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-8.2314e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.887696
Average KL loss: 0.366536
Average total loss: 1.254232
tensor(-15.0794, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(6.8150e-12, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.886553
Average KL loss: 0.366530
Average total loss: 1.253083
tensor(-15.0795, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-8.2653e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.886835
Average KL loss: 0.366526
Average total loss: 1.253361
tensor(-15.0797, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-8.6707e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.886909
Average KL loss: 0.366522
Average total loss: 1.253431
tensor(-15.0798, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(1.5410e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.887557
Average KL loss: 0.366518
Average total loss: 1.254074
tensor(-15.0800, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-2.0411e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.888524
Average KL loss: 0.366517
Average total loss: 1.255041
tensor(-15.0801, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(5.3461e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.889430
Average KL loss: 0.366516
Average total loss: 1.255946
tensor(-15.0802, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-7.6659e-11, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.888840
Average KL loss: 0.366515
Average total loss: 1.255355
tensor(-15.0804, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-8.7729e-11, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.887022
Average KL loss: 0.366512
Average total loss: 1.253534
tensor(-15.0805, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-1.7928e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.888318
Average KL loss: 0.366510
Average total loss: 1.254828
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(4.6663e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.887263
Average KL loss: 0.366509
Average total loss: 1.253772
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-5.0233e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.888274
Average KL loss: 0.366509
Average total loss: 1.254783
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(8.7278e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.888356
Average KL loss: 0.366509
Average total loss: 1.254865
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-5.9941e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.887097
Average KL loss: 0.366509
Average total loss: 1.253606
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-4.6138e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.887667
Average KL loss: 0.366508
Average total loss: 1.254175
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(4.8799e-11, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.887705
Average KL loss: 0.366508
Average total loss: 1.254213
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-1.0350e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.891397
Average KL loss: 0.366508
Average total loss: 1.257905
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(2.8467e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.887983
Average KL loss: 0.366508
Average total loss: 1.254491
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-2.5468e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.887163
Average KL loss: 0.366508
Average total loss: 1.253670
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-2.8968e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.886928
Average KL loss: 0.366507
Average total loss: 1.253435
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-1.0528e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.889270
Average KL loss: 0.366507
Average total loss: 1.255776
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-3.4887e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.887560
Average KL loss: 0.366507
Average total loss: 1.254066
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-3.0793e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.887485
Average KL loss: 0.366507
Average total loss: 1.253992
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-1.5156e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.886443
Average KL loss: 0.366507
Average total loss: 1.252950
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(9.0410e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.886588
Average KL loss: 0.366507
Average total loss: 1.253095
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-2.4579e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.885293
Average KL loss: 0.366507
Average total loss: 1.251800
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-4.7419e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.887352
Average KL loss: 0.366507
Average total loss: 1.253859
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-9.7996e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.890202
Average KL loss: 0.366507
Average total loss: 1.256709
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(9.2186e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.887248
Average KL loss: 0.366507
Average total loss: 1.253755
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-4.2401e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.886535
Average KL loss: 0.366506
Average total loss: 1.253041
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-1.7515e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.887954
Average KL loss: 0.366506
Average total loss: 1.254461
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(6.0690e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.888880
Average KL loss: 0.366506
Average total loss: 1.255386
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-9.6103e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.887123
Average KL loss: 0.366506
Average total loss: 1.253630
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-5.0197e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.886569
Average KL loss: 0.366506
Average total loss: 1.253075
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-1.3415e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.889470
Average KL loss: 0.366506
Average total loss: 1.255976
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(4.9742e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.887426
Average KL loss: 0.366506
Average total loss: 1.253932
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-6.3238e-10, device='cuda:0')
 Percentile value: -15.085136413574219
Non-zero model percentage: 26.214414596557617%, Non-zero mask percentage: 26.214414596557617%

--- Pruning Level [6/24]: ---
conv1.weight         | nonzeros =    1704 /    1728             ( 98.61%) | total_pruned =      24 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   30747 /   36864             ( 83.41%) | total_pruned =    6117 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   30880 /   36864             ( 83.77%) | total_pruned =    5984 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   28762 /   36864             ( 78.02%) | total_pruned =    8102 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   27884 /   36864             ( 75.64%) | total_pruned =    8980 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   57702 /   73728             ( 78.26%) | total_pruned =   16026 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   99690 /  147456             ( 67.61%) | total_pruned =   47766 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7592 /    8192             ( 92.68%) | total_pruned =     600 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   88968 /  147456             ( 60.34%) | total_pruned =   58488 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   83995 /  147456             ( 56.96%) | total_pruned =   63461 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  163484 /  294912             ( 55.43%) | total_pruned =  131428 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  234453 /  589824             ( 39.75%) | total_pruned =  355371 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   25992 /   32768             ( 79.32%) | total_pruned =    6776 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  138476 /  589824             ( 23.48%) | total_pruned =  451348 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  135337 /  589824             ( 22.95%) | total_pruned =  454487 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  316851 / 1179648             ( 26.86%) | total_pruned =  862797 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  446005 / 2359296             ( 18.90%) | total_pruned = 1913291 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   82834 /  131072             ( 63.20%) | total_pruned =   48238 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  420202 / 2359296             ( 17.81%) | total_pruned = 1939094 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     472 /     512             ( 92.19%) | total_pruned =      40 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  494311 / 2359296             ( 20.95%) | total_pruned = 1864985 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
linear.weight        | nonzeros =    5020 /    5120             ( 98.05%) | total_pruned =     100 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 2930447, pruned : 8248315, total: 11178762, Compression rate :       3.81x  ( 73.79% pruned)
Train Epoch: 24/100 Loss: 0.000014 Accuracy: 86.56 100.00 % Best test Accuracy: 86.57%
tensor(-15.0807, device='cuda:0') tensor(0.1580, device='cuda:0') tensor(-5.1934e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.934285
Average KL loss: 0.365847
Average total loss: 1.300132
tensor(-15.0822, device='cuda:0') tensor(0.1529, device='cuda:0') tensor(-1.0977e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.933294
Average KL loss: 0.365125
Average total loss: 1.298419
tensor(-15.0837, device='cuda:0') tensor(0.1495, device='cuda:0') tensor(1.1840e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.933539
Average KL loss: 0.364617
Average total loss: 1.298156
tensor(-15.0851, device='cuda:0') tensor(0.1473, device='cuda:0') tensor(-2.3133e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.937180
Average KL loss: 0.364242
Average total loss: 1.301421
tensor(-15.0865, device='cuda:0') tensor(0.1461, device='cuda:0') tensor(-2.7010e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.937740
Average KL loss: 0.363978
Average total loss: 1.301718
tensor(-15.0879, device='cuda:0') tensor(0.1455, device='cuda:0') tensor(-1.0148e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.938010
Average KL loss: 0.363797
Average total loss: 1.301808
tensor(-15.0892, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(-2.7472e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.934614
Average KL loss: 0.363708
Average total loss: 1.298321
tensor(-15.0906, device='cuda:0') tensor(0.1451, device='cuda:0') tensor(-7.0170e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.937627
Average KL loss: 0.363621
Average total loss: 1.301248
tensor(-15.0920, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(-1.8209e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.939839
Average KL loss: 0.363561
Average total loss: 1.303400
tensor(-15.0933, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(5.1680e-12, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.934326
Average KL loss: 0.363501
Average total loss: 1.297827
tensor(-15.0947, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(-1.9624e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.935032
Average KL loss: 0.363470
Average total loss: 1.298502
tensor(-15.0960, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(1.0119e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.932506
Average KL loss: 0.363412
Average total loss: 1.295917
tensor(-15.0974, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(-5.3983e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.933025
Average KL loss: 0.363346
Average total loss: 1.296370
tensor(-15.0987, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(4.7230e-11, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.926994
Average KL loss: 0.363283
Average total loss: 1.290277
tensor(-15.1001, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(-5.2498e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.930067
Average KL loss: 0.363230
Average total loss: 1.293297
tensor(-15.1014, device='cuda:0') tensor(0.1451, device='cuda:0') tensor(-1.1596e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.926778
Average KL loss: 0.363187
Average total loss: 1.289965
tensor(-15.1028, device='cuda:0') tensor(0.1451, device='cuda:0') tensor(-3.1072e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.928529
Average KL loss: 0.363142
Average total loss: 1.291671
tensor(-15.1041, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(-1.7256e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.926454
Average KL loss: 0.363097
Average total loss: 1.289551
tensor(-15.1054, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(-7.2753e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.925841
Average KL loss: 0.363057
Average total loss: 1.288898
tensor(-15.1068, device='cuda:0') tensor(0.1453, device='cuda:0') tensor(-1.2683e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.925371
Average KL loss: 0.363014
Average total loss: 1.288386
tensor(-15.1081, device='cuda:0') tensor(0.1453, device='cuda:0') tensor(-2.8650e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.924300
Average KL loss: 0.362946
Average total loss: 1.287246
tensor(-15.1095, device='cuda:0') tensor(0.1454, device='cuda:0') tensor(-1.6878e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.921887
Average KL loss: 0.362884
Average total loss: 1.284771
tensor(-15.1108, device='cuda:0') tensor(0.1454, device='cuda:0') tensor(-1.2324e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.921617
Average KL loss: 0.362848
Average total loss: 1.284464
tensor(-15.1121, device='cuda:0') tensor(0.1455, device='cuda:0') tensor(-3.4296e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.922530
Average KL loss: 0.362836
Average total loss: 1.285366
tensor(-15.1135, device='cuda:0') tensor(0.1456, device='cuda:0') tensor(-2.2603e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.920591
Average KL loss: 0.362807
Average total loss: 1.283398
tensor(-15.1148, device='cuda:0') tensor(0.1456, device='cuda:0') tensor(-1.1838e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.917849
Average KL loss: 0.362779
Average total loss: 1.280628
tensor(-15.1161, device='cuda:0') tensor(0.1457, device='cuda:0') tensor(-1.1847e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.919377
Average KL loss: 0.362726
Average total loss: 1.282103
tensor(-15.1175, device='cuda:0') tensor(0.1458, device='cuda:0') tensor(-2.8656e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.920280
Average KL loss: 0.362700
Average total loss: 1.282980
tensor(-15.1188, device='cuda:0') tensor(0.1458, device='cuda:0') tensor(-2.4390e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.918005
Average KL loss: 0.362645
Average total loss: 1.280650
tensor(-15.1201, device='cuda:0') tensor(0.1459, device='cuda:0') tensor(-9.0851e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.920272
Average KL loss: 0.362590
Average total loss: 1.282862
tensor(-15.1214, device='cuda:0') tensor(0.1460, device='cuda:0') tensor(-4.0201e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.916962
Average KL loss: 0.362547
Average total loss: 1.279509
tensor(-15.1228, device='cuda:0') tensor(0.1460, device='cuda:0') tensor(-8.1159e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.915437
Average KL loss: 0.362519
Average total loss: 1.277956
tensor(-15.1241, device='cuda:0') tensor(0.1461, device='cuda:0') tensor(6.1328e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.918107
Average KL loss: 0.362458
Average total loss: 1.280565
tensor(-15.1254, device='cuda:0') tensor(0.1461, device='cuda:0') tensor(-1.1756e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.918037
Average KL loss: 0.362410
Average total loss: 1.280447
tensor(-15.1267, device='cuda:0') tensor(0.1462, device='cuda:0') tensor(-3.9711e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.917379
Average KL loss: 0.362376
Average total loss: 1.279755
tensor(-15.1280, device='cuda:0') tensor(0.1463, device='cuda:0') tensor(-5.4363e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.917084
Average KL loss: 0.362355
Average total loss: 1.279439
tensor(-15.1293, device='cuda:0') tensor(0.1464, device='cuda:0') tensor(-2.0620e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.916056
Average KL loss: 0.362296
Average total loss: 1.278353
tensor(-15.1306, device='cuda:0') tensor(0.1464, device='cuda:0') tensor(-8.9973e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.917520
Average KL loss: 0.362234
Average total loss: 1.279754
tensor(-15.1319, device='cuda:0') tensor(0.1465, device='cuda:0') tensor(-1.1844e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.914527
Average KL loss: 0.362163
Average total loss: 1.276690
tensor(-15.1332, device='cuda:0') tensor(0.1466, device='cuda:0') tensor(1.4517e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.917253
Average KL loss: 0.362080
Average total loss: 1.279333
tensor(-15.1345, device='cuda:0') tensor(0.1466, device='cuda:0') tensor(-4.5002e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.915971
Average KL loss: 0.362002
Average total loss: 1.277974
tensor(-15.1358, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-2.2806e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.913776
Average KL loss: 0.361958
Average total loss: 1.275734
tensor(-15.1371, device='cuda:0') tensor(0.1468, device='cuda:0') tensor(-9.4895e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.913812
Average KL loss: 0.361926
Average total loss: 1.275738
tensor(-15.1384, device='cuda:0') tensor(0.1469, device='cuda:0') tensor(-1.3639e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.912269
Average KL loss: 0.361914
Average total loss: 1.274184
tensor(-15.1397, device='cuda:0') tensor(0.1469, device='cuda:0') tensor(4.9743e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.910959
Average KL loss: 0.361898
Average total loss: 1.272857
tensor(-15.1410, device='cuda:0') tensor(0.1470, device='cuda:0') tensor(-7.7379e-11, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.908929
Average KL loss: 0.361859
Average total loss: 1.270788
tensor(-15.1422, device='cuda:0') tensor(0.1471, device='cuda:0') tensor(-4.4734e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.912031
Average KL loss: 0.361808
Average total loss: 1.273839
tensor(-15.1435, device='cuda:0') tensor(0.1471, device='cuda:0') tensor(-6.0802e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.912996
Average KL loss: 0.361751
Average total loss: 1.274747
tensor(-15.1448, device='cuda:0') tensor(0.1472, device='cuda:0') tensor(-2.2574e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.911959
Average KL loss: 0.361669
Average total loss: 1.273628
tensor(-15.1461, device='cuda:0') tensor(0.1473, device='cuda:0') tensor(4.9012e-11, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.909633
Average KL loss: 0.361623
Average total loss: 1.271256
tensor(-15.1474, device='cuda:0') tensor(0.1473, device='cuda:0') tensor(1.7987e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.908819
Average KL loss: 0.361596
Average total loss: 1.270415
tensor(-15.1487, device='cuda:0') tensor(0.1474, device='cuda:0') tensor(-3.0440e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.909612
Average KL loss: 0.361545
Average total loss: 1.271157
tensor(-15.1500, device='cuda:0') tensor(0.1475, device='cuda:0') tensor(-1.3585e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.908517
Average KL loss: 0.361519
Average total loss: 1.270036
tensor(-15.1513, device='cuda:0') tensor(0.1476, device='cuda:0') tensor(-2.0200e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.909838
Average KL loss: 0.361478
Average total loss: 1.271315
tensor(-15.1525, device='cuda:0') tensor(0.1477, device='cuda:0') tensor(-3.8563e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.906133
Average KL loss: 0.361424
Average total loss: 1.267557
tensor(-15.1538, device='cuda:0') tensor(0.1478, device='cuda:0') tensor(-4.7667e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.910763
Average KL loss: 0.361385
Average total loss: 1.272148
tensor(-15.1551, device='cuda:0') tensor(0.1479, device='cuda:0') tensor(4.3461e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.908965
Average KL loss: 0.361340
Average total loss: 1.270305
tensor(-15.1564, device='cuda:0') tensor(0.1479, device='cuda:0') tensor(-8.4184e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.906301
Average KL loss: 0.361277
Average total loss: 1.267579
tensor(-15.1577, device='cuda:0') tensor(0.1480, device='cuda:0') tensor(-1.0692e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.905292
Average KL loss: 0.361223
Average total loss: 1.266515
tensor(-15.1589, device='cuda:0') tensor(0.1481, device='cuda:0') tensor(-7.0666e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.906331
Average KL loss: 0.361149
Average total loss: 1.267480
tensor(-15.1602, device='cuda:0') tensor(0.1482, device='cuda:0') tensor(-2.4910e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.905084
Average KL loss: 0.361128
Average total loss: 1.266212
tensor(-15.1615, device='cuda:0') tensor(0.1482, device='cuda:0') tensor(5.6337e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.905309
Average KL loss: 0.361093
Average total loss: 1.266402
tensor(-15.1627, device='cuda:0') tensor(0.1483, device='cuda:0') tensor(-7.2741e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.908271
Average KL loss: 0.361031
Average total loss: 1.269302
tensor(-15.1640, device='cuda:0') tensor(0.1484, device='cuda:0') tensor(-7.2802e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.904223
Average KL loss: 0.360982
Average total loss: 1.265205
tensor(-15.1652, device='cuda:0') tensor(0.1484, device='cuda:0') tensor(-1.5704e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.904048
Average KL loss: 0.360939
Average total loss: 1.264987
tensor(-15.1665, device='cuda:0') tensor(0.1485, device='cuda:0') tensor(1.1108e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.908066
Average KL loss: 0.360900
Average total loss: 1.268967
tensor(-15.1677, device='cuda:0') tensor(0.1486, device='cuda:0') tensor(-7.2310e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.909645
Average KL loss: 0.360881
Average total loss: 1.270526
tensor(-15.1690, device='cuda:0') tensor(0.1487, device='cuda:0') tensor(9.1031e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.904721
Average KL loss: 0.360816
Average total loss: 1.265536
tensor(-15.1702, device='cuda:0') tensor(0.1488, device='cuda:0') tensor(-1.1431e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.904121
Average KL loss: 0.360758
Average total loss: 1.264878
tensor(-15.1715, device='cuda:0') tensor(0.1489, device='cuda:0') tensor(-7.2839e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.907199
Average KL loss: 0.360709
Average total loss: 1.267907
tensor(-15.1727, device='cuda:0') tensor(0.1490, device='cuda:0') tensor(-9.0439e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.906527
Average KL loss: 0.360697
Average total loss: 1.267224
tensor(-15.1740, device='cuda:0') tensor(0.1490, device='cuda:0') tensor(-1.8973e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.903702
Average KL loss: 0.360665
Average total loss: 1.264367
tensor(-15.1752, device='cuda:0') tensor(0.1491, device='cuda:0') tensor(-2.9274e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.906174
Average KL loss: 0.360612
Average total loss: 1.266786
tensor(-15.1765, device='cuda:0') tensor(0.1492, device='cuda:0') tensor(1.5887e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.903730
Average KL loss: 0.360579
Average total loss: 1.264308
tensor(-15.1777, device='cuda:0') tensor(0.1493, device='cuda:0') tensor(-1.5357e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.902040
Average KL loss: 0.360542
Average total loss: 1.262582
tensor(-15.1789, device='cuda:0') tensor(0.1493, device='cuda:0') tensor(-6.7754e-11, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.903757
Average KL loss: 0.360492
Average total loss: 1.264250
tensor(-15.1802, device='cuda:0') tensor(0.1494, device='cuda:0') tensor(1.0159e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.902591
Average KL loss: 0.360452
Average total loss: 1.263043
tensor(-15.1814, device='cuda:0') tensor(0.1495, device='cuda:0') tensor(-7.2133e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.900361
Average KL loss: 0.360403
Average total loss: 1.260764
tensor(-15.1827, device='cuda:0') tensor(0.1496, device='cuda:0') tensor(-1.0144e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.902947
Average KL loss: 0.360375
Average total loss: 1.263322
tensor(-15.1839, device='cuda:0') tensor(0.1497, device='cuda:0') tensor(-9.7995e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.902537
Average KL loss: 0.360352
Average total loss: 1.262889
tensor(-15.1851, device='cuda:0') tensor(0.1498, device='cuda:0') tensor(-1.0126e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.902833
Average KL loss: 0.360339
Average total loss: 1.263172
tensor(-15.1864, device='cuda:0') tensor(0.1498, device='cuda:0') tensor(-1.4111e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.902775
Average KL loss: 0.360333
Average total loss: 1.263108
tensor(-15.1876, device='cuda:0') tensor(0.1499, device='cuda:0') tensor(-1.0602e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.899344
Average KL loss: 0.360289
Average total loss: 1.259633
tensor(-15.1889, device='cuda:0') tensor(0.1499, device='cuda:0') tensor(5.0147e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.902280
Average KL loss: 0.360226
Average total loss: 1.262506
tensor(-15.1901, device='cuda:0') tensor(0.1500, device='cuda:0') tensor(-3.7852e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.900293
Average KL loss: 0.360155
Average total loss: 1.260448
tensor(-15.1913, device='cuda:0') tensor(0.1500, device='cuda:0') tensor(3.7348e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.899427
Average KL loss: 0.360090
Average total loss: 1.259517
tensor(-15.1926, device='cuda:0') tensor(0.1501, device='cuda:0') tensor(-7.6398e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.903061
Average KL loss: 0.360046
Average total loss: 1.263106
tensor(-15.1938, device='cuda:0') tensor(0.1502, device='cuda:0') tensor(-7.8984e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.901771
Average KL loss: 0.360034
Average total loss: 1.261804
tensor(-15.1950, device='cuda:0') tensor(0.1503, device='cuda:0') tensor(-6.3316e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.900448
Average KL loss: 0.360040
Average total loss: 1.260488
tensor(-15.1963, device='cuda:0') tensor(0.1504, device='cuda:0') tensor(-9.0228e-11, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.899732
Average KL loss: 0.360026
Average total loss: 1.259758
tensor(-15.1975, device='cuda:0') tensor(0.1504, device='cuda:0') tensor(9.7516e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.902156
Average KL loss: 0.359982
Average total loss: 1.262138
tensor(-15.1987, device='cuda:0') tensor(0.1505, device='cuda:0') tensor(7.1746e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.900574
Average KL loss: 0.359951
Average total loss: 1.260526
tensor(-15.1999, device='cuda:0') tensor(0.1506, device='cuda:0') tensor(-5.9128e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.899083
Average KL loss: 0.359900
Average total loss: 1.258983
tensor(-15.2011, device='cuda:0') tensor(0.1507, device='cuda:0') tensor(3.6579e-11, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.898928
Average KL loss: 0.359864
Average total loss: 1.258791
tensor(-15.2023, device='cuda:0') tensor(0.1507, device='cuda:0') tensor(-2.7858e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.900047
Average KL loss: 0.359830
Average total loss: 1.259877
tensor(-15.2035, device='cuda:0') tensor(0.1508, device='cuda:0') tensor(-1.0341e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.898626
Average KL loss: 0.359771
Average total loss: 1.258398
tensor(-15.2048, device='cuda:0') tensor(0.1509, device='cuda:0') tensor(-3.4101e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.899539
Average KL loss: 0.359747
Average total loss: 1.259286
tensor(-15.2060, device='cuda:0') tensor(0.1510, device='cuda:0') tensor(4.4169e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.899703
Average KL loss: 0.359723
Average total loss: 1.259426
tensor(-15.2072, device='cuda:0') tensor(0.1510, device='cuda:0') tensor(-2.0386e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.898199
Average KL loss: 0.359709
Average total loss: 1.257908
tensor(-15.2084, device='cuda:0') tensor(0.1511, device='cuda:0') tensor(1.1874e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.898122
Average KL loss: 0.359671
Average total loss: 1.257794
tensor(-15.2096, device='cuda:0') tensor(0.1512, device='cuda:0') tensor(-5.7851e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.896679
Average KL loss: 0.359630
Average total loss: 1.256310
tensor(-15.2108, device='cuda:0') tensor(0.1512, device='cuda:0') tensor(-1.3436e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.900362
Average KL loss: 0.359596
Average total loss: 1.259958
tensor(-15.2120, device='cuda:0') tensor(0.1513, device='cuda:0') tensor(1.9005e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.899254
Average KL loss: 0.359565
Average total loss: 1.258818
tensor(-15.2132, device='cuda:0') tensor(0.1514, device='cuda:0') tensor(-5.2962e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.897300
Average KL loss: 0.359506
Average total loss: 1.256807
tensor(-15.2143, device='cuda:0') tensor(0.1514, device='cuda:0') tensor(-1.8334e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.898982
Average KL loss: 0.359460
Average total loss: 1.258442
tensor(-15.2155, device='cuda:0') tensor(0.1515, device='cuda:0') tensor(4.1949e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.898806
Average KL loss: 0.359452
Average total loss: 1.258259
tensor(-15.2167, device='cuda:0') tensor(0.1516, device='cuda:0') tensor(2.7056e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.898340
Average KL loss: 0.359448
Average total loss: 1.257787
tensor(-15.2179, device='cuda:0') tensor(0.1517, device='cuda:0') tensor(-1.9380e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.898106
Average KL loss: 0.359419
Average total loss: 1.257525
tensor(-15.2191, device='cuda:0') tensor(0.1518, device='cuda:0') tensor(-6.9398e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.896971
Average KL loss: 0.359375
Average total loss: 1.256345
tensor(-15.2203, device='cuda:0') tensor(0.1518, device='cuda:0') tensor(7.7407e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.896783
Average KL loss: 0.359366
Average total loss: 1.256148
tensor(-15.2215, device='cuda:0') tensor(0.1519, device='cuda:0') tensor(-5.5379e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.898694
Average KL loss: 0.359344
Average total loss: 1.258037
tensor(-15.2227, device='cuda:0') tensor(0.1520, device='cuda:0') tensor(-3.6969e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.894273
Average KL loss: 0.359290
Average total loss: 1.253562
tensor(-15.2239, device='cuda:0') tensor(0.1521, device='cuda:0') tensor(5.0201e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.894829
Average KL loss: 0.359246
Average total loss: 1.254075
tensor(-15.2251, device='cuda:0') tensor(0.1521, device='cuda:0') tensor(-2.2309e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.896446
Average KL loss: 0.359218
Average total loss: 1.255664
tensor(-15.2263, device='cuda:0') tensor(0.1522, device='cuda:0') tensor(6.3754e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.896294
Average KL loss: 0.359183
Average total loss: 1.255477
tensor(-15.2274, device='cuda:0') tensor(0.1523, device='cuda:0') tensor(4.7030e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.896108
Average KL loss: 0.359173
Average total loss: 1.255281
tensor(-15.2286, device='cuda:0') tensor(0.1524, device='cuda:0') tensor(4.9543e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.897094
Average KL loss: 0.359154
Average total loss: 1.256248
tensor(-15.2298, device='cuda:0') tensor(0.1524, device='cuda:0') tensor(-9.9861e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.896667
Average KL loss: 0.359103
Average total loss: 1.255770
tensor(-15.2310, device='cuda:0') tensor(0.1525, device='cuda:0') tensor(-5.0307e-11, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.896601
Average KL loss: 0.359062
Average total loss: 1.255663
tensor(-15.2322, device='cuda:0') tensor(0.1526, device='cuda:0') tensor(-9.8315e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.895368
Average KL loss: 0.359039
Average total loss: 1.254406
tensor(-15.2334, device='cuda:0') tensor(0.1527, device='cuda:0') tensor(-5.3212e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.893375
Average KL loss: 0.359011
Average total loss: 1.252386
tensor(-15.2346, device='cuda:0') tensor(0.1528, device='cuda:0') tensor(-6.5855e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.893741
Average KL loss: 0.358983
Average total loss: 1.252724
tensor(-15.2357, device='cuda:0') tensor(0.1528, device='cuda:0') tensor(-2.8269e-11, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.894404
Average KL loss: 0.358951
Average total loss: 1.253355
tensor(-15.2369, device='cuda:0') tensor(0.1529, device='cuda:0') tensor(-3.5581e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.893762
Average KL loss: 0.358956
Average total loss: 1.252718
tensor(-15.2381, device='cuda:0') tensor(0.1529, device='cuda:0') tensor(-3.3598e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.894817
Average KL loss: 0.358941
Average total loss: 1.253759
tensor(-15.2393, device='cuda:0') tensor(0.1530, device='cuda:0') tensor(-5.8328e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.897104
Average KL loss: 0.358916
Average total loss: 1.256020
tensor(-15.2404, device='cuda:0') tensor(0.1531, device='cuda:0') tensor(-3.9715e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.894064
Average KL loss: 0.358899
Average total loss: 1.252963
tensor(-15.2416, device='cuda:0') tensor(0.1532, device='cuda:0') tensor(6.5845e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.893586
Average KL loss: 0.358889
Average total loss: 1.252475
tensor(-15.2428, device='cuda:0') tensor(0.1532, device='cuda:0') tensor(3.8534e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.895939
Average KL loss: 0.358833
Average total loss: 1.254772
tensor(-15.2439, device='cuda:0') tensor(0.1533, device='cuda:0') tensor(5.0856e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.892473
Average KL loss: 0.358783
Average total loss: 1.251256
tensor(-15.2451, device='cuda:0') tensor(0.1534, device='cuda:0') tensor(6.6838e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.894336
Average KL loss: 0.358717
Average total loss: 1.253053
tensor(-15.2462, device='cuda:0') tensor(0.1534, device='cuda:0') tensor(-3.3204e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.894263
Average KL loss: 0.358680
Average total loss: 1.252943
tensor(-15.2474, device='cuda:0') tensor(0.1535, device='cuda:0') tensor(1.1882e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.894208
Average KL loss: 0.358635
Average total loss: 1.252843
tensor(-15.2486, device='cuda:0') tensor(0.1535, device='cuda:0') tensor(-1.3081e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.893389
Average KL loss: 0.358609
Average total loss: 1.251998
tensor(-15.2497, device='cuda:0') tensor(0.1536, device='cuda:0') tensor(-7.4073e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.895627
Average KL loss: 0.358594
Average total loss: 1.254221
tensor(-15.2509, device='cuda:0') tensor(0.1537, device='cuda:0') tensor(-4.4810e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.895001
Average KL loss: 0.358579
Average total loss: 1.253581
tensor(-15.2520, device='cuda:0') tensor(0.1537, device='cuda:0') tensor(-2.7396e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.894279
Average KL loss: 0.358579
Average total loss: 1.252857
tensor(-15.2532, device='cuda:0') tensor(0.1538, device='cuda:0') tensor(2.8995e-12, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.893020
Average KL loss: 0.358561
Average total loss: 1.251582
tensor(-15.2543, device='cuda:0') tensor(0.1539, device='cuda:0') tensor(-1.1477e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.892190
Average KL loss: 0.358544
Average total loss: 1.250734
tensor(-15.2555, device='cuda:0') tensor(0.1539, device='cuda:0') tensor(-1.1051e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.893621
Average KL loss: 0.358520
Average total loss: 1.252141
tensor(-15.2566, device='cuda:0') tensor(0.1540, device='cuda:0') tensor(3.7773e-11, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.891782
Average KL loss: 0.358503
Average total loss: 1.250285
tensor(-15.2577, device='cuda:0') tensor(0.1541, device='cuda:0') tensor(-1.0930e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.893061
Average KL loss: 0.358503
Average total loss: 1.251564
tensor(-15.2589, device='cuda:0') tensor(0.1541, device='cuda:0') tensor(-2.0495e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.891930
Average KL loss: 0.358464
Average total loss: 1.250394
tensor(-15.2600, device='cuda:0') tensor(0.1542, device='cuda:0') tensor(4.1066e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.893319
Average KL loss: 0.358441
Average total loss: 1.251761
tensor(-15.2612, device='cuda:0') tensor(0.1543, device='cuda:0') tensor(6.9719e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.892196
Average KL loss: 0.358433
Average total loss: 1.250629
tensor(-15.2623, device='cuda:0') tensor(0.1544, device='cuda:0') tensor(-3.6449e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.893995
Average KL loss: 0.358417
Average total loss: 1.252412
tensor(-15.2635, device='cuda:0') tensor(0.1544, device='cuda:0') tensor(-1.2586e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.890077
Average KL loss: 0.358385
Average total loss: 1.248462
tensor(-15.2646, device='cuda:0') tensor(0.1545, device='cuda:0') tensor(-3.7820e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.894793
Average KL loss: 0.358355
Average total loss: 1.253148
tensor(-15.2657, device='cuda:0') tensor(0.1545, device='cuda:0') tensor(-1.1761e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.890919
Average KL loss: 0.358312
Average total loss: 1.249231
tensor(-15.2669, device='cuda:0') tensor(0.1546, device='cuda:0') tensor(-8.4439e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.891013
Average KL loss: 0.358301
Average total loss: 1.249314
tensor(-15.2680, device='cuda:0') tensor(0.1547, device='cuda:0') tensor(-4.8382e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.892889
Average KL loss: 0.358282
Average total loss: 1.251170
tensor(-15.2692, device='cuda:0') tensor(0.1547, device='cuda:0') tensor(3.7470e-11, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.892164
Average KL loss: 0.358291
Average total loss: 1.250455
tensor(-15.2703, device='cuda:0') tensor(0.1548, device='cuda:0') tensor(-1.4325e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.894246
Average KL loss: 0.358291
Average total loss: 1.252536
tensor(-15.2714, device='cuda:0') tensor(0.1549, device='cuda:0') tensor(-5.1880e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.891087
Average KL loss: 0.358269
Average total loss: 1.249356
tensor(-15.2726, device='cuda:0') tensor(0.1549, device='cuda:0') tensor(-5.0606e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.893590
Average KL loss: 0.358248
Average total loss: 1.251838
tensor(-15.2737, device='cuda:0') tensor(0.1550, device='cuda:0') tensor(-5.5540e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.890349
Average KL loss: 0.358230
Average total loss: 1.248579
tensor(-15.2748, device='cuda:0') tensor(0.1551, device='cuda:0') tensor(-5.8528e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.895104
Average KL loss: 0.358212
Average total loss: 1.253315
tensor(-15.2760, device='cuda:0') tensor(0.1552, device='cuda:0') tensor(7.9956e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.890781
Average KL loss: 0.358194
Average total loss: 1.248975
tensor(-15.2771, device='cuda:0') tensor(0.1552, device='cuda:0') tensor(2.1223e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.893264
Average KL loss: 0.358185
Average total loss: 1.251449
tensor(-15.2772, device='cuda:0') tensor(0.1552, device='cuda:0') tensor(-1.1742e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.890926
Average KL loss: 0.358183
Average total loss: 1.249109
tensor(-15.2773, device='cuda:0') tensor(0.1552, device='cuda:0') tensor(9.8201e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.890990
Average KL loss: 0.358180
Average total loss: 1.249171
tensor(-15.2774, device='cuda:0') tensor(0.1552, device='cuda:0') tensor(-4.6155e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.891260
Average KL loss: 0.358180
Average total loss: 1.249440
tensor(-15.2775, device='cuda:0') tensor(0.1552, device='cuda:0') tensor(-1.5704e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.892875
Average KL loss: 0.358181
Average total loss: 1.251056
tensor(-15.2776, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-7.1092e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.892419
Average KL loss: 0.358179
Average total loss: 1.250598
tensor(-15.2777, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-4.4173e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.892104
Average KL loss: 0.358176
Average total loss: 1.250280
tensor(-15.2778, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-2.9802e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.890120
Average KL loss: 0.358172
Average total loss: 1.248292
tensor(-15.2779, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-3.8426e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.892932
Average KL loss: 0.358169
Average total loss: 1.251102
tensor(-15.2780, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(2.3529e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.892660
Average KL loss: 0.358166
Average total loss: 1.250827
tensor(-15.2781, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(4.3420e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.891440
Average KL loss: 0.358164
Average total loss: 1.249604
tensor(-15.2782, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-1.4617e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.892492
Average KL loss: 0.358162
Average total loss: 1.250654
tensor(-15.2783, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-9.1843e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.890020
Average KL loss: 0.358161
Average total loss: 1.248181
tensor(-15.2784, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-4.9044e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.889170
Average KL loss: 0.358158
Average total loss: 1.247328
tensor(-15.2785, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-3.5642e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.889458
Average KL loss: 0.358154
Average total loss: 1.247612
tensor(-15.2786, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-1.5289e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.891232
Average KL loss: 0.358151
Average total loss: 1.249383
tensor(-15.2787, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-1.9357e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.892592
Average KL loss: 0.358147
Average total loss: 1.250739
tensor(-15.2788, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-1.0053e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.893247
Average KL loss: 0.358145
Average total loss: 1.251392
tensor(-15.2789, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-6.8667e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.889984
Average KL loss: 0.358142
Average total loss: 1.248126
tensor(-15.2790, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-3.0448e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.891061
Average KL loss: 0.358140
Average total loss: 1.249201
tensor(-15.2791, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(-1.5366e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.890269
Average KL loss: 0.358139
Average total loss: 1.248408
tensor(-15.2791, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(4.0591e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.892017
Average KL loss: 0.358137
Average total loss: 1.250154
tensor(-15.2792, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(8.7334e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.890143
Average KL loss: 0.358133
Average total loss: 1.248276
tensor(-15.2793, device='cuda:0') tensor(0.1553, device='cuda:0') tensor(8.3716e-12, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.892134
Average KL loss: 0.358130
Average total loss: 1.250264
tensor(-15.2794, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-7.8203e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.890188
Average KL loss: 0.358126
Average total loss: 1.248314
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-6.5602e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.891457
Average KL loss: 0.358124
Average total loss: 1.249581
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-6.5228e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.892068
Average KL loss: 0.358124
Average total loss: 1.250191
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(2.7913e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.890968
Average KL loss: 0.358123
Average total loss: 1.249092
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-2.2556e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.890728
Average KL loss: 0.358123
Average total loss: 1.248851
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-2.9827e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.890717
Average KL loss: 0.358123
Average total loss: 1.248840
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-1.4390e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.891568
Average KL loss: 0.358123
Average total loss: 1.249691
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-3.7018e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.892081
Average KL loss: 0.358122
Average total loss: 1.250203
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(6.9244e-11, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.890912
Average KL loss: 0.358122
Average total loss: 1.249034
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(5.6698e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.892591
Average KL loss: 0.358122
Average total loss: 1.250712
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-1.1447e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.890901
Average KL loss: 0.358122
Average total loss: 1.249023
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-6.0613e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.891201
Average KL loss: 0.358121
Average total loss: 1.249322
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(1.4449e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.893255
Average KL loss: 0.358121
Average total loss: 1.251376
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-1.2858e-11, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.891079
Average KL loss: 0.358121
Average total loss: 1.249201
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-1.3918e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.891558
Average KL loss: 0.358121
Average total loss: 1.249679
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(3.2278e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.891424
Average KL loss: 0.358121
Average total loss: 1.249545
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-6.1590e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.889470
Average KL loss: 0.358121
Average total loss: 1.247591
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(1.4566e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.892184
Average KL loss: 0.358121
Average total loss: 1.250305
 Percentile value: -15.277588844299316
Non-zero model percentage: 20.971534729003906%, Non-zero mask percentage: 20.971534729003906%

--- Pruning Level [7/24]: ---
conv1.weight         | nonzeros =    1695 /    1728             ( 98.09%) | total_pruned =      33 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   29458 /   36864             ( 79.91%) | total_pruned =    7406 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   29577 /   36864             ( 80.23%) | total_pruned =    7287 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   27144 /   36864             ( 73.63%) | total_pruned =    9720 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   26114 /   36864             ( 70.84%) | total_pruned =   10750 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   54570 /   73728             ( 74.02%) | total_pruned =   19158 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   90779 /  147456             ( 61.56%) | total_pruned =   56677 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7449 /    8192             ( 90.93%) | total_pruned =     743 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   79104 /  147456             ( 53.65%) | total_pruned =   68352 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   73422 /  147456             ( 49.79%) | total_pruned =   74034 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  140957 /  294912             ( 47.80%) | total_pruned =  153955 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  188365 /  589824             ( 31.94%) | total_pruned =  401459 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   24445 /   32768             ( 74.60%) | total_pruned =    8323 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  102246 /  589824             ( 17.34%) | total_pruned =  487578 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  100498 /  589824             ( 17.04%) | total_pruned =  489326 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  237102 / 1179648             ( 20.10%) | total_pruned =  942546 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  334765 / 2359296             ( 14.19%) | total_pruned = 2024531 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   74434 /  131072             ( 56.79%) | total_pruned =   56638 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  315348 / 2359296             ( 13.37%) | total_pruned = 2043948 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     414 /     512             ( 80.86%) | total_pruned =      98 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  392416 / 2359296             ( 16.63%) | total_pruned = 1966880 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
linear.weight        | nonzeros =    4975 /    5120             ( 97.17%) | total_pruned =     145 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 2344358, pruned : 8834404, total: 11178762, Compression rate :       4.77x  ( 79.03% pruned)
Train Epoch: 24/100 Loss: 0.002296 Accuracy: 86.30 100.00 % Best test Accuracy: 86.54%
tensor(-15.2795, device='cuda:0') tensor(0.1554, device='cuda:0') tensor(-1.0615e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.921405
Average KL loss: 0.357583
Average total loss: 1.278988
tensor(-15.2808, device='cuda:0') tensor(0.1502, device='cuda:0') tensor(-1.2390e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.919701
Average KL loss: 0.356912
Average total loss: 1.276613
tensor(-15.2820, device='cuda:0') tensor(0.1466, device='cuda:0') tensor(-1.2462e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.922141
Average KL loss: 0.356402
Average total loss: 1.278544
tensor(-15.2832, device='cuda:0') tensor(0.1440, device='cuda:0') tensor(-1.6429e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.925806
Average KL loss: 0.355939
Average total loss: 1.281745
tensor(-15.2844, device='cuda:0') tensor(0.1425, device='cuda:0') tensor(-1.3196e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.930442
Average KL loss: 0.355587
Average total loss: 1.286029
tensor(-15.2855, device='cuda:0') tensor(0.1418, device='cuda:0') tensor(-1.5573e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.930854
Average KL loss: 0.355355
Average total loss: 1.286209
tensor(-15.2866, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(8.2476e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.928301
Average KL loss: 0.355204
Average total loss: 1.283504
tensor(-15.2877, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-3.7087e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.931367
Average KL loss: 0.355107
Average total loss: 1.286474
tensor(-15.2889, device='cuda:0') tensor(0.1413, device='cuda:0') tensor(-1.9746e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.930962
Average KL loss: 0.355027
Average total loss: 1.285989
tensor(-15.2900, device='cuda:0') tensor(0.1413, device='cuda:0') tensor(8.4109e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.929624
Average KL loss: 0.354965
Average total loss: 1.284588
tensor(-15.2911, device='cuda:0') tensor(0.1413, device='cuda:0') tensor(-1.8809e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.925353
Average KL loss: 0.354902
Average total loss: 1.280255
tensor(-15.2922, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-1.0721e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.926127
Average KL loss: 0.354795
Average total loss: 1.280922
tensor(-15.2933, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(6.4746e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.927017
Average KL loss: 0.354703
Average total loss: 1.281720
tensor(-15.2944, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-1.7035e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.927057
Average KL loss: 0.354668
Average total loss: 1.281725
tensor(-15.2945, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-9.9496e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.926361
Average KL loss: 0.354662
Average total loss: 1.281024
tensor(-15.2946, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-7.8310e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.927191
Average KL loss: 0.354655
Average total loss: 1.281845
tensor(-15.2947, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(3.0451e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.926716
Average KL loss: 0.354650
Average total loss: 1.281366
tensor(-15.2948, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-1.0655e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.928920
Average KL loss: 0.354646
Average total loss: 1.283565
tensor(-15.2949, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-1.1515e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.929312
Average KL loss: 0.354640
Average total loss: 1.283952
tensor(-15.2950, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-2.0135e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.927560
Average KL loss: 0.354634
Average total loss: 1.282194
tensor(-15.2951, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-5.8366e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.925543
Average KL loss: 0.354630
Average total loss: 1.280173
tensor(-15.2952, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-9.9202e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.922751
Average KL loss: 0.354625
Average total loss: 1.277376
tensor(-15.2953, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-1.5115e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.925278
Average KL loss: 0.354621
Average total loss: 1.279899
tensor(-15.2954, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-2.5166e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.925003
Average KL loss: 0.354617
Average total loss: 1.279620
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-7.6110e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.925177
Average KL loss: 0.354615
Average total loss: 1.279791
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-4.2713e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.925391
Average KL loss: 0.354614
Average total loss: 1.280005
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-1.1964e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.927217
Average KL loss: 0.354614
Average total loss: 1.281831
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-1.2960e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.927956
Average KL loss: 0.354614
Average total loss: 1.282570
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-4.9499e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.925717
Average KL loss: 0.354613
Average total loss: 1.280330
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(3.1749e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.924497
Average KL loss: 0.354613
Average total loss: 1.279109
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-5.5488e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.925171
Average KL loss: 0.354612
Average total loss: 1.279783
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-2.8510e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.922060
Average KL loss: 0.354612
Average total loss: 1.276672
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-6.6312e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.924741
Average KL loss: 0.354612
Average total loss: 1.279353
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-1.5371e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.924063
Average KL loss: 0.354612
Average total loss: 1.278675
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-7.7229e-11, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.923818
Average KL loss: 0.354611
Average total loss: 1.278429
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-3.4718e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.923628
Average KL loss: 0.354611
Average total loss: 1.278240
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-2.2321e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.927555
Average KL loss: 0.354611
Average total loss: 1.282167
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-4.4766e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.927738
Average KL loss: 0.354611
Average total loss: 1.282349
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-2.1928e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.921978
Average KL loss: 0.354611
Average total loss: 1.276589
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-2.7111e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.927373
Average KL loss: 0.354611
Average total loss: 1.281984
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-1.2363e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.922642
Average KL loss: 0.354611
Average total loss: 1.277253
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-1.8049e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.928716
Average KL loss: 0.354611
Average total loss: 1.283327
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(9.2423e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.925694
Average KL loss: 0.354611
Average total loss: 1.280305
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-9.8630e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.924206
Average KL loss: 0.354611
Average total loss: 1.278817
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(1.2859e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.926365
Average KL loss: 0.354611
Average total loss: 1.280976
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-3.1695e-10, device='cuda:0')
 Percentile value: -15.28651237487793
Non-zero model percentage: 16.777233123779297%, Non-zero mask percentage: 16.777233123779297%

--- Pruning Level [8/24]: ---
conv1.weight         | nonzeros =    1692 /    1728             ( 97.92%) | total_pruned =      36 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   28161 /   36864             ( 76.39%) | total_pruned =    8703 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   28190 /   36864             ( 76.47%) | total_pruned =    8674 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   25499 /   36864             ( 69.17%) | total_pruned =   11365 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   24250 /   36864             ( 65.78%) | total_pruned =   12614 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   51351 /   73728             ( 69.65%) | total_pruned =   22377 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   81908 /  147456             ( 55.55%) | total_pruned =   65548 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7294 /    8192             ( 89.04%) | total_pruned =     898 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   69604 /  147456             ( 47.20%) | total_pruned =   77852 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   63783 /  147456             ( 43.26%) | total_pruned =   83673 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  120082 /  294912             ( 40.72%) | total_pruned =  174830 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  149386 /  589824             ( 25.33%) | total_pruned =  440438 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   22851 /   32768             ( 69.74%) | total_pruned =    9917 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   74994 /  589824             ( 12.71%) | total_pruned =  514830 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   73909 /  589824             ( 12.53%) | total_pruned =  515915 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  175860 / 1179648             ( 14.91%) | total_pruned = 1003788 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  250625 / 2359296             ( 10.62%) | total_pruned = 2108671 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   65996 /  131072             ( 50.35%) | total_pruned =   65076 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  236347 / 2359296             ( 10.02%) | total_pruned = 2122949 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     338 /     512             ( 66.02%) | total_pruned =     174 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  309338 / 2359296             ( 13.11%) | total_pruned = 2049958 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
linear.weight        | nonzeros =    4949 /    5120             ( 96.66%) | total_pruned =     171 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 1875487, pruned : 9303275, total: 11178762, Compression rate :       5.96x  ( 83.22% pruned)
Train Epoch: 23/100 Loss: 0.000085 Accuracy: 85.39 99.98 % Best test Accuracy: 86.15%
tensor(-15.2955, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-3.9786e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.970464
Average KL loss: 0.353841
Average total loss: 1.324305
tensor(-15.2967, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(-2.6261e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.968066
Average KL loss: 0.353028
Average total loss: 1.321093
tensor(-15.2978, device='cuda:0') tensor(0.1356, device='cuda:0') tensor(-4.8382e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.980029
Average KL loss: 0.352603
Average total loss: 1.332632
tensor(-15.2989, device='cuda:0') tensor(0.1347, device='cuda:0') tensor(-3.2406e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.978057
Average KL loss: 0.352322
Average total loss: 1.330379
tensor(-15.3001, device='cuda:0') tensor(0.1343, device='cuda:0') tensor(-1.6656e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.973151
Average KL loss: 0.352164
Average total loss: 1.325315
tensor(-15.3012, device='cuda:0') tensor(0.1342, device='cuda:0') tensor(1.4426e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.968741
Average KL loss: 0.352054
Average total loss: 1.320795
tensor(-15.3023, device='cuda:0') tensor(0.1342, device='cuda:0') tensor(-1.4117e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.973233
Average KL loss: 0.351943
Average total loss: 1.325176
tensor(-15.3034, device='cuda:0') tensor(0.1341, device='cuda:0') tensor(-4.3282e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.964897
Average KL loss: 0.351814
Average total loss: 1.316711
tensor(-15.3045, device='cuda:0') tensor(0.1341, device='cuda:0') tensor(-4.0057e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.973132
Average KL loss: 0.351698
Average total loss: 1.324830
tensor(-15.3056, device='cuda:0') tensor(0.1342, device='cuda:0') tensor(-3.8817e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.963663
Average KL loss: 0.351592
Average total loss: 1.315255
tensor(-15.3067, device='cuda:0') tensor(0.1342, device='cuda:0') tensor(-9.2200e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.966273
Average KL loss: 0.351470
Average total loss: 1.317743
tensor(-15.3077, device='cuda:0') tensor(0.1342, device='cuda:0') tensor(-5.2253e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.960279
Average KL loss: 0.351371
Average total loss: 1.311650
tensor(-15.3088, device='cuda:0') tensor(0.1343, device='cuda:0') tensor(-3.5228e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.960914
Average KL loss: 0.351314
Average total loss: 1.312228
tensor(-15.3099, device='cuda:0') tensor(0.1343, device='cuda:0') tensor(-3.8542e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.960802
Average KL loss: 0.351241
Average total loss: 1.312044
tensor(-15.3110, device='cuda:0') tensor(0.1344, device='cuda:0') tensor(-6.8140e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.965327
Average KL loss: 0.351130
Average total loss: 1.316457
tensor(-15.3121, device='cuda:0') tensor(0.1344, device='cuda:0') tensor(2.4074e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.959718
Average KL loss: 0.350991
Average total loss: 1.310710
tensor(-15.3132, device='cuda:0') tensor(0.1345, device='cuda:0') tensor(-2.0473e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.957517
Average KL loss: 0.350832
Average total loss: 1.308349
tensor(-15.3143, device='cuda:0') tensor(0.1346, device='cuda:0') tensor(-5.7874e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.958421
Average KL loss: 0.350696
Average total loss: 1.309117
tensor(-15.3154, device='cuda:0') tensor(0.1347, device='cuda:0') tensor(8.1651e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.954971
Average KL loss: 0.350541
Average total loss: 1.305511
tensor(-15.3165, device='cuda:0') tensor(0.1347, device='cuda:0') tensor(-7.4809e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.951596
Average KL loss: 0.350379
Average total loss: 1.301975
tensor(-15.3176, device='cuda:0') tensor(0.1348, device='cuda:0') tensor(-9.6304e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.950499
Average KL loss: 0.350236
Average total loss: 1.300735
tensor(-15.3187, device='cuda:0') tensor(0.1349, device='cuda:0') tensor(-1.5981e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.950176
Average KL loss: 0.350089
Average total loss: 1.300265
tensor(-15.3198, device='cuda:0') tensor(0.1349, device='cuda:0') tensor(1.0351e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.949471
Average KL loss: 0.349948
Average total loss: 1.299419
tensor(-15.3208, device='cuda:0') tensor(0.1350, device='cuda:0') tensor(4.9781e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.949944
Average KL loss: 0.349834
Average total loss: 1.299779
tensor(-15.3219, device='cuda:0') tensor(0.1351, device='cuda:0') tensor(-2.7078e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.949796
Average KL loss: 0.349752
Average total loss: 1.299548
tensor(-15.3230, device='cuda:0') tensor(0.1352, device='cuda:0') tensor(-2.1530e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.945397
Average KL loss: 0.349642
Average total loss: 1.295040
tensor(-15.3241, device='cuda:0') tensor(0.1352, device='cuda:0') tensor(-7.6131e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.948502
Average KL loss: 0.349526
Average total loss: 1.298028
tensor(-15.3252, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.6877e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.945588
Average KL loss: 0.349416
Average total loss: 1.295005
tensor(-15.3263, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(-4.0132e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.944499
Average KL loss: 0.349322
Average total loss: 1.293821
tensor(-15.3273, device='cuda:0') tensor(0.1355, device='cuda:0') tensor(-3.8983e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.943767
Average KL loss: 0.349224
Average total loss: 1.292991
tensor(-15.3284, device='cuda:0') tensor(0.1356, device='cuda:0') tensor(-3.8701e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.942131
Average KL loss: 0.349105
Average total loss: 1.291236
tensor(-15.3295, device='cuda:0') tensor(0.1356, device='cuda:0') tensor(-9.8627e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.940822
Average KL loss: 0.348967
Average total loss: 1.289789
tensor(-15.3305, device='cuda:0') tensor(0.1357, device='cuda:0') tensor(-2.1821e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.942973
Average KL loss: 0.348865
Average total loss: 1.291838
tensor(-15.3316, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(1.4457e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.941951
Average KL loss: 0.348762
Average total loss: 1.290714
tensor(-15.3327, device='cuda:0') tensor(0.1359, device='cuda:0') tensor(1.5009e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.939308
Average KL loss: 0.348625
Average total loss: 1.287933
tensor(-15.3337, device='cuda:0') tensor(0.1359, device='cuda:0') tensor(-2.1763e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.938858
Average KL loss: 0.348523
Average total loss: 1.287381
tensor(-15.3348, device='cuda:0') tensor(0.1360, device='cuda:0') tensor(-1.2399e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.941169
Average KL loss: 0.348426
Average total loss: 1.289595
tensor(-15.3358, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(4.6851e-11, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.937209
Average KL loss: 0.348352
Average total loss: 1.285561
tensor(-15.3369, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(-1.7637e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.939526
Average KL loss: 0.348254
Average total loss: 1.287780
tensor(-15.3380, device='cuda:0') tensor(0.1362, device='cuda:0') tensor(-1.5995e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.934721
Average KL loss: 0.348155
Average total loss: 1.282876
tensor(-15.3390, device='cuda:0') tensor(0.1363, device='cuda:0') tensor(-1.8432e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.938384
Average KL loss: 0.348073
Average total loss: 1.286457
tensor(-15.3401, device='cuda:0') tensor(0.1364, device='cuda:0') tensor(-8.8255e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.933678
Average KL loss: 0.348030
Average total loss: 1.281708
tensor(-15.3411, device='cuda:0') tensor(0.1365, device='cuda:0') tensor(-1.2746e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.939017
Average KL loss: 0.347948
Average total loss: 1.286965
tensor(-15.3422, device='cuda:0') tensor(0.1366, device='cuda:0') tensor(-2.3943e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.935214
Average KL loss: 0.347881
Average total loss: 1.283095
tensor(-15.3432, device='cuda:0') tensor(0.1367, device='cuda:0') tensor(6.1196e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.937384
Average KL loss: 0.347828
Average total loss: 1.285212
tensor(-15.3443, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-5.8969e-11, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.938365
Average KL loss: 0.347733
Average total loss: 1.286098
tensor(-15.3453, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-1.8590e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.934814
Average KL loss: 0.347668
Average total loss: 1.282482
tensor(-15.3464, device='cuda:0') tensor(0.1369, device='cuda:0') tensor(-9.5383e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.933928
Average KL loss: 0.347612
Average total loss: 1.281541
tensor(-15.3474, device='cuda:0') tensor(0.1370, device='cuda:0') tensor(-9.9381e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.933220
Average KL loss: 0.347537
Average total loss: 1.280756
tensor(-15.3484, device='cuda:0') tensor(0.1371, device='cuda:0') tensor(2.1986e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.934137
Average KL loss: 0.347459
Average total loss: 1.281595
tensor(-15.3495, device='cuda:0') tensor(0.1372, device='cuda:0') tensor(-6.4532e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.929475
Average KL loss: 0.347397
Average total loss: 1.276872
tensor(-15.3505, device='cuda:0') tensor(0.1373, device='cuda:0') tensor(-3.2573e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.927381
Average KL loss: 0.347319
Average total loss: 1.274700
tensor(-15.3516, device='cuda:0') tensor(0.1374, device='cuda:0') tensor(-1.7143e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.930348
Average KL loss: 0.347275
Average total loss: 1.277623
tensor(-15.3526, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(-6.8393e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.929981
Average KL loss: 0.347238
Average total loss: 1.277218
tensor(-15.3537, device='cuda:0') tensor(0.1376, device='cuda:0') tensor(6.9761e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.930811
Average KL loss: 0.347182
Average total loss: 1.277993
tensor(-15.3547, device='cuda:0') tensor(0.1377, device='cuda:0') tensor(-1.6429e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.926284
Average KL loss: 0.347115
Average total loss: 1.273399
tensor(-15.3558, device='cuda:0') tensor(0.1378, device='cuda:0') tensor(-1.3063e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.932884
Average KL loss: 0.347016
Average total loss: 1.279900
tensor(-15.3568, device='cuda:0') tensor(0.1378, device='cuda:0') tensor(-1.3554e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.931696
Average KL loss: 0.346945
Average total loss: 1.278640
tensor(-15.3578, device='cuda:0') tensor(0.1379, device='cuda:0') tensor(-8.0873e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.930986
Average KL loss: 0.346887
Average total loss: 1.277873
tensor(-15.3589, device='cuda:0') tensor(0.1380, device='cuda:0') tensor(1.1145e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.930216
Average KL loss: 0.346844
Average total loss: 1.277060
tensor(-15.3599, device='cuda:0') tensor(0.1381, device='cuda:0') tensor(-1.0986e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.925193
Average KL loss: 0.346785
Average total loss: 1.271978
tensor(-15.3610, device='cuda:0') tensor(0.1382, device='cuda:0') tensor(-2.0103e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.927624
Average KL loss: 0.346750
Average total loss: 1.274374
tensor(-15.3620, device='cuda:0') tensor(0.1383, device='cuda:0') tensor(-1.6201e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.925327
Average KL loss: 0.346700
Average total loss: 1.272027
tensor(-15.3630, device='cuda:0') tensor(0.1384, device='cuda:0') tensor(-1.2192e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.927253
Average KL loss: 0.346639
Average total loss: 1.273891
tensor(-15.3641, device='cuda:0') tensor(0.1385, device='cuda:0') tensor(6.8879e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.929725
Average KL loss: 0.346571
Average total loss: 1.276296
tensor(-15.3651, device='cuda:0') tensor(0.1386, device='cuda:0') tensor(1.4400e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.922898
Average KL loss: 0.346500
Average total loss: 1.269398
tensor(-15.3662, device='cuda:0') tensor(0.1387, device='cuda:0') tensor(1.5008e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.927149
Average KL loss: 0.346449
Average total loss: 1.273599
tensor(-15.3672, device='cuda:0') tensor(0.1387, device='cuda:0') tensor(-6.9657e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.928133
Average KL loss: 0.346380
Average total loss: 1.274513
tensor(-15.3682, device='cuda:0') tensor(0.1388, device='cuda:0') tensor(-1.1599e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.923233
Average KL loss: 0.346312
Average total loss: 1.269545
tensor(-15.3693, device='cuda:0') tensor(0.1389, device='cuda:0') tensor(-7.9484e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.925408
Average KL loss: 0.346244
Average total loss: 1.271652
tensor(-15.3703, device='cuda:0') tensor(0.1390, device='cuda:0') tensor(-4.7866e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.925325
Average KL loss: 0.346181
Average total loss: 1.271506
tensor(-15.3713, device='cuda:0') tensor(0.1391, device='cuda:0') tensor(-3.8922e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.924114
Average KL loss: 0.346101
Average total loss: 1.270215
tensor(-15.3724, device='cuda:0') tensor(0.1391, device='cuda:0') tensor(-2.6747e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.924004
Average KL loss: 0.346064
Average total loss: 1.270068
tensor(-15.3734, device='cuda:0') tensor(0.1392, device='cuda:0') tensor(6.6465e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.926796
Average KL loss: 0.346027
Average total loss: 1.272823
tensor(-15.3744, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(-7.2270e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.927571
Average KL loss: 0.345992
Average total loss: 1.273563
tensor(-15.3754, device='cuda:0') tensor(0.1394, device='cuda:0') tensor(-1.0862e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.921896
Average KL loss: 0.345942
Average total loss: 1.267839
tensor(-15.3765, device='cuda:0') tensor(0.1395, device='cuda:0') tensor(-8.8016e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.921992
Average KL loss: 0.345889
Average total loss: 1.267881
tensor(-15.3775, device='cuda:0') tensor(0.1396, device='cuda:0') tensor(-6.2109e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.924214
Average KL loss: 0.345831
Average total loss: 1.270045
tensor(-15.3785, device='cuda:0') tensor(0.1397, device='cuda:0') tensor(-2.3347e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.921865
Average KL loss: 0.345797
Average total loss: 1.267661
tensor(-15.3795, device='cuda:0') tensor(0.1398, device='cuda:0') tensor(-7.0037e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.922242
Average KL loss: 0.345775
Average total loss: 1.268018
tensor(-15.3805, device='cuda:0') tensor(0.1398, device='cuda:0') tensor(5.4977e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.924975
Average KL loss: 0.345716
Average total loss: 1.270691
tensor(-15.3815, device='cuda:0') tensor(0.1399, device='cuda:0') tensor(-2.5258e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.922626
Average KL loss: 0.345639
Average total loss: 1.268265
tensor(-15.3825, device='cuda:0') tensor(0.1400, device='cuda:0') tensor(5.2514e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.921295
Average KL loss: 0.345549
Average total loss: 1.266843
tensor(-15.3835, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(-1.6046e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.920901
Average KL loss: 0.345502
Average total loss: 1.266403
tensor(-15.3845, device='cuda:0') tensor(0.1402, device='cuda:0') tensor(-1.6252e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.921439
Average KL loss: 0.345467
Average total loss: 1.266906
tensor(-15.3855, device='cuda:0') tensor(0.1402, device='cuda:0') tensor(-7.5712e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.923587
Average KL loss: 0.345418
Average total loss: 1.269005
tensor(-15.3865, device='cuda:0') tensor(0.1403, device='cuda:0') tensor(-6.2788e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.920941
Average KL loss: 0.345377
Average total loss: 1.266318
tensor(-15.3875, device='cuda:0') tensor(0.1404, device='cuda:0') tensor(-4.6454e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.920085
Average KL loss: 0.345325
Average total loss: 1.265410
tensor(-15.3885, device='cuda:0') tensor(0.1405, device='cuda:0') tensor(-1.1785e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.920187
Average KL loss: 0.345271
Average total loss: 1.265458
tensor(-15.3895, device='cuda:0') tensor(0.1406, device='cuda:0') tensor(-8.9416e-11, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.920283
Average KL loss: 0.345242
Average total loss: 1.265525
tensor(-15.3905, device='cuda:0') tensor(0.1407, device='cuda:0') tensor(-1.0626e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.921456
Average KL loss: 0.345218
Average total loss: 1.266674
tensor(-15.3915, device='cuda:0') tensor(0.1408, device='cuda:0') tensor(-1.5401e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.924899
Average KL loss: 0.345174
Average total loss: 1.270073
tensor(-15.3925, device='cuda:0') tensor(0.1408, device='cuda:0') tensor(5.8040e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.917626
Average KL loss: 0.345115
Average total loss: 1.262741
tensor(-15.3935, device='cuda:0') tensor(0.1409, device='cuda:0') tensor(-5.2261e-11, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.916916
Average KL loss: 0.345066
Average total loss: 1.261982
tensor(-15.3945, device='cuda:0') tensor(0.1410, device='cuda:0') tensor(-2.9694e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.921460
Average KL loss: 0.345018
Average total loss: 1.266478
tensor(-15.3955, device='cuda:0') tensor(0.1411, device='cuda:0') tensor(-3.0762e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.921329
Average KL loss: 0.344982
Average total loss: 1.266311
tensor(-15.3965, device='cuda:0') tensor(0.1412, device='cuda:0') tensor(-2.2774e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.921116
Average KL loss: 0.344975
Average total loss: 1.266090
tensor(-15.3975, device='cuda:0') tensor(0.1413, device='cuda:0') tensor(4.0791e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.917443
Average KL loss: 0.344913
Average total loss: 1.262356
tensor(-15.3985, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(3.7014e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.917990
Average KL loss: 0.344881
Average total loss: 1.262871
tensor(-15.3995, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-6.7454e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.918804
Average KL loss: 0.344837
Average total loss: 1.263640
tensor(-15.4005, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(8.8449e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.917132
Average KL loss: 0.344803
Average total loss: 1.261935
tensor(-15.4015, device='cuda:0') tensor(0.1416, device='cuda:0') tensor(5.6796e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.918885
Average KL loss: 0.344787
Average total loss: 1.263672
tensor(-15.4025, device='cuda:0') tensor(0.1417, device='cuda:0') tensor(4.2438e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.919706
Average KL loss: 0.344763
Average total loss: 1.264469
tensor(-15.4035, device='cuda:0') tensor(0.1418, device='cuda:0') tensor(3.2462e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.917420
Average KL loss: 0.344734
Average total loss: 1.262153
tensor(-15.4045, device='cuda:0') tensor(0.1418, device='cuda:0') tensor(-7.2418e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.919658
Average KL loss: 0.344722
Average total loss: 1.264381
tensor(-15.4055, device='cuda:0') tensor(0.1419, device='cuda:0') tensor(6.9172e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.915439
Average KL loss: 0.344701
Average total loss: 1.260140
tensor(-15.4056, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(-9.3021e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.918358
Average KL loss: 0.344698
Average total loss: 1.263056
tensor(-15.4057, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(-5.6636e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.915079
Average KL loss: 0.344693
Average total loss: 1.259772
tensor(-15.4058, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(4.9985e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.917068
Average KL loss: 0.344689
Average total loss: 1.261757
tensor(-15.4059, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(-3.7242e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.917263
Average KL loss: 0.344683
Average total loss: 1.261946
tensor(-15.4060, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(9.6501e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.916022
Average KL loss: 0.344680
Average total loss: 1.260703
tensor(-15.4060, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(-1.1932e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.917325
Average KL loss: 0.344675
Average total loss: 1.261999
tensor(-15.4061, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(-1.6824e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.919301
Average KL loss: 0.344672
Average total loss: 1.263973
tensor(-15.4062, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(-2.8450e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.917414
Average KL loss: 0.344672
Average total loss: 1.262086
tensor(-15.4063, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(-2.4776e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.917017
Average KL loss: 0.344669
Average total loss: 1.261687
tensor(-15.4064, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(-7.4541e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.916058
Average KL loss: 0.344665
Average total loss: 1.260723
tensor(-15.4065, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(4.0037e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.917082
Average KL loss: 0.344662
Average total loss: 1.261744
tensor(-15.4066, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(1.1811e-11, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.919440
Average KL loss: 0.344658
Average total loss: 1.264098
tensor(-15.4067, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(5.9952e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.916114
Average KL loss: 0.344654
Average total loss: 1.260769
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-8.6414e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.917635
Average KL loss: 0.344653
Average total loss: 1.262288
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-1.2860e-11, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.919340
Average KL loss: 0.344652
Average total loss: 1.263992
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(1.7498e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.917951
Average KL loss: 0.344652
Average total loss: 1.262603
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-8.3485e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.917300
Average KL loss: 0.344652
Average total loss: 1.261952
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-2.4297e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.915907
Average KL loss: 0.344652
Average total loss: 1.260558
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-6.2091e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.913987
Average KL loss: 0.344651
Average total loss: 1.258638
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-1.1331e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.918572
Average KL loss: 0.344651
Average total loss: 1.263222
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(1.1669e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.917200
Average KL loss: 0.344650
Average total loss: 1.261850
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(1.1645e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.918478
Average KL loss: 0.344650
Average total loss: 1.263128
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-4.4414e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.916998
Average KL loss: 0.344649
Average total loss: 1.261648
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(5.6755e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.914855
Average KL loss: 0.344649
Average total loss: 1.259504
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-6.6613e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.917144
Average KL loss: 0.344648
Average total loss: 1.261793
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-1.0587e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.916226
Average KL loss: 0.344648
Average total loss: 1.260874
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(6.7499e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.916086
Average KL loss: 0.344648
Average total loss: 1.260734
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(7.0601e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.917234
Average KL loss: 0.344648
Average total loss: 1.261881
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-2.1637e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.915515
Average KL loss: 0.344647
Average total loss: 1.260162
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(5.0738e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.918322
Average KL loss: 0.344647
Average total loss: 1.262969
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-1.5390e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.916822
Average KL loss: 0.344647
Average total loss: 1.261469
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-4.0432e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.916320
Average KL loss: 0.344647
Average total loss: 1.260967
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(6.1941e-11, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.915564
Average KL loss: 0.344647
Average total loss: 1.260212
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(4.8609e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.915564
Average KL loss: 0.344647
Average total loss: 1.260211
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-9.6667e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.915996
Average KL loss: 0.344647
Average total loss: 1.260643
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-1.4126e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.917355
Average KL loss: 0.344647
Average total loss: 1.262002
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-1.3566e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.915988
Average KL loss: 0.344647
Average total loss: 1.260635
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-1.1368e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.917032
Average KL loss: 0.344647
Average total loss: 1.261679
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-1.0014e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.918707
Average KL loss: 0.344647
Average total loss: 1.263353
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-5.1120e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.918077
Average KL loss: 0.344647
Average total loss: 1.262724
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-6.8558e-10, device='cuda:0')
 Percentile value: -15.392743110656738
Non-zero model percentage: 13.42179012298584%, Non-zero mask percentage: 13.42179012298584%

--- Pruning Level [9/24]: ---
conv1.weight         | nonzeros =    1684 /    1728             ( 97.45%) | total_pruned =      44 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   26842 /   36864             ( 72.81%) | total_pruned =   10022 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   26775 /   36864             ( 72.63%) | total_pruned =   10089 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   23690 /   36864             ( 64.26%) | total_pruned =   13174 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   22281 /   36864             ( 60.44%) | total_pruned =   14583 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   47870 /   73728             ( 64.93%) | total_pruned =   25858 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   73367 /  147456             ( 49.76%) | total_pruned =   74089 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7116 /    8192             ( 86.87%) | total_pruned =    1076 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   60559 /  147456             ( 41.07%) | total_pruned =   86897 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   54700 /  147456             ( 37.10%) | total_pruned =   92756 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  100965 /  294912             ( 34.24%) | total_pruned =  193947 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  117577 /  589824             ( 19.93%) | total_pruned =  472247 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   21010 /   32768             ( 64.12%) | total_pruned =   11758 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   54681 /  589824             (  9.27%) | total_pruned =  535143 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   53807 /  589824             (  9.12%) | total_pruned =  536017 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  129722 / 1179648             ( 11.00%) | total_pruned = 1049926 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  187165 / 2359296             (  7.93%) | total_pruned = 2172131 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   57959 /  131072             ( 44.22%) | total_pruned =   73113 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  176407 / 2359296             (  7.48%) | total_pruned = 2182889 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     276 /     512             ( 53.91%) | total_pruned =     236 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  241955 / 2359296             ( 10.26%) | total_pruned = 2117341 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     501 /     512             ( 97.85%) | total_pruned =      11 | shape = torch.Size([512])
linear.weight        | nonzeros =    4909 /    5120             ( 95.88%) | total_pruned =     211 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 1500390, pruned : 9678372, total: 11178762, Compression rate :       7.45x  ( 86.58% pruned)
Train Epoch: 21/100 Loss: 0.000006 Accuracy: 86.61 100.00 % Best test Accuracy: 86.61%
tensor(-15.4068, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-4.1658e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.953406
Average KL loss: 0.344040
Average total loss: 1.297446
tensor(-15.4079, device='cuda:0') tensor(0.1378, device='cuda:0') tensor(1.4629e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.955294
Average KL loss: 0.343360
Average total loss: 1.298655
tensor(-15.4090, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(2.4153e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.957742
Average KL loss: 0.342906
Average total loss: 1.300648
tensor(-15.4100, device='cuda:0') tensor(0.1341, device='cuda:0') tensor(-1.6619e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.959684
Average KL loss: 0.342601
Average total loss: 1.302284
tensor(-15.4110, device='cuda:0') tensor(0.1334, device='cuda:0') tensor(-1.5035e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.960882
Average KL loss: 0.342416
Average total loss: 1.303298
tensor(-15.4120, device='cuda:0') tensor(0.1332, device='cuda:0') tensor(-2.2459e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.964219
Average KL loss: 0.342338
Average total loss: 1.306557
tensor(-15.4130, device='cuda:0') tensor(0.1332, device='cuda:0') tensor(-6.2970e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.959345
Average KL loss: 0.342280
Average total loss: 1.301626
tensor(-15.4140, device='cuda:0') tensor(0.1332, device='cuda:0') tensor(9.2850e-11, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.960777
Average KL loss: 0.342206
Average total loss: 1.302984
tensor(-15.4150, device='cuda:0') tensor(0.1332, device='cuda:0') tensor(-1.9894e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.954431
Average KL loss: 0.342178
Average total loss: 1.296609
tensor(-15.4160, device='cuda:0') tensor(0.1333, device='cuda:0') tensor(-3.0475e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.954765
Average KL loss: 0.342143
Average total loss: 1.296909
tensor(-15.4170, device='cuda:0') tensor(0.1334, device='cuda:0') tensor(-1.2523e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.953061
Average KL loss: 0.342118
Average total loss: 1.295179
tensor(-15.4180, device='cuda:0') tensor(0.1334, device='cuda:0') tensor(-2.3035e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.955501
Average KL loss: 0.342086
Average total loss: 1.297587
tensor(-15.4189, device='cuda:0') tensor(0.1335, device='cuda:0') tensor(-5.0639e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.953549
Average KL loss: 0.342066
Average total loss: 1.295615
tensor(-15.4199, device='cuda:0') tensor(0.1336, device='cuda:0') tensor(-2.5597e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.951814
Average KL loss: 0.342076
Average total loss: 1.293891
tensor(-15.4209, device='cuda:0') tensor(0.1337, device='cuda:0') tensor(-9.4594e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.949794
Average KL loss: 0.342056
Average total loss: 1.291849
tensor(-15.4219, device='cuda:0') tensor(0.1338, device='cuda:0') tensor(-5.5006e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.949487
Average KL loss: 0.342012
Average total loss: 1.291499
tensor(-15.4229, device='cuda:0') tensor(0.1339, device='cuda:0') tensor(-2.1425e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.953100
Average KL loss: 0.341976
Average total loss: 1.295076
tensor(-15.4238, device='cuda:0') tensor(0.1340, device='cuda:0') tensor(-8.3518e-11, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.948615
Average KL loss: 0.341930
Average total loss: 1.290546
tensor(-15.4248, device='cuda:0') tensor(0.1341, device='cuda:0') tensor(-3.7225e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.951647
Average KL loss: 0.341875
Average total loss: 1.293521
tensor(-15.4258, device='cuda:0') tensor(0.1342, device='cuda:0') tensor(-8.1965e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.944119
Average KL loss: 0.341811
Average total loss: 1.285930
tensor(-15.4267, device='cuda:0') tensor(0.1343, device='cuda:0') tensor(-5.7052e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.948024
Average KL loss: 0.341752
Average total loss: 1.289775
tensor(-15.4277, device='cuda:0') tensor(0.1344, device='cuda:0') tensor(-3.0719e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.943702
Average KL loss: 0.341694
Average total loss: 1.285397
tensor(-15.4287, device='cuda:0') tensor(0.1345, device='cuda:0') tensor(-3.7827e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.946251
Average KL loss: 0.341626
Average total loss: 1.287876
tensor(-15.4296, device='cuda:0') tensor(0.1346, device='cuda:0') tensor(-6.2606e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.943992
Average KL loss: 0.341570
Average total loss: 1.285562
tensor(-15.4306, device='cuda:0') tensor(0.1347, device='cuda:0') tensor(-5.6367e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.945362
Average KL loss: 0.341516
Average total loss: 1.286878
tensor(-15.4316, device='cuda:0') tensor(0.1348, device='cuda:0') tensor(-2.3729e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.945445
Average KL loss: 0.341481
Average total loss: 1.286926
tensor(-15.4325, device='cuda:0') tensor(0.1349, device='cuda:0') tensor(-4.8874e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.946267
Average KL loss: 0.341453
Average total loss: 1.287720
tensor(-15.4335, device='cuda:0') tensor(0.1350, device='cuda:0') tensor(-1.0040e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.946271
Average KL loss: 0.341435
Average total loss: 1.287706
tensor(-15.4344, device='cuda:0') tensor(0.1351, device='cuda:0') tensor(-8.4371e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.942392
Average KL loss: 0.341391
Average total loss: 1.283783
tensor(-15.4354, device='cuda:0') tensor(0.1352, device='cuda:0') tensor(1.2213e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.942168
Average KL loss: 0.341342
Average total loss: 1.283510
tensor(-15.4363, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-1.7180e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.941406
Average KL loss: 0.341304
Average total loss: 1.282710
tensor(-15.4373, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(-1.0586e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.940089
Average KL loss: 0.341254
Average total loss: 1.281343
tensor(-15.4382, device='cuda:0') tensor(0.1355, device='cuda:0') tensor(-1.4422e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.941298
Average KL loss: 0.341229
Average total loss: 1.282527
tensor(-15.4392, device='cuda:0') tensor(0.1356, device='cuda:0') tensor(-7.2214e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.938861
Average KL loss: 0.341177
Average total loss: 1.280039
tensor(-15.4401, device='cuda:0') tensor(0.1357, device='cuda:0') tensor(-3.3110e-12, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.941543
Average KL loss: 0.341130
Average total loss: 1.282674
tensor(-15.4411, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-3.1266e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.940045
Average KL loss: 0.341090
Average total loss: 1.281134
tensor(-15.4420, device='cuda:0') tensor(0.1359, device='cuda:0') tensor(-2.4276e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.939387
Average KL loss: 0.341065
Average total loss: 1.280451
tensor(-15.4430, device='cuda:0') tensor(0.1360, device='cuda:0') tensor(7.2663e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.938643
Average KL loss: 0.341016
Average total loss: 1.279660
tensor(-15.4439, device='cuda:0') tensor(0.1360, device='cuda:0') tensor(-1.9536e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.937319
Average KL loss: 0.340963
Average total loss: 1.278283
tensor(-15.4449, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(4.0594e-11, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.938739
Average KL loss: 0.340925
Average total loss: 1.279665
tensor(-15.4458, device='cuda:0') tensor(0.1362, device='cuda:0') tensor(-5.6022e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.937767
Average KL loss: 0.340853
Average total loss: 1.278620
tensor(-15.4468, device='cuda:0') tensor(0.1363, device='cuda:0') tensor(-1.3439e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.936864
Average KL loss: 0.340788
Average total loss: 1.277652
tensor(-15.4477, device='cuda:0') tensor(0.1364, device='cuda:0') tensor(-1.1105e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.935877
Average KL loss: 0.340747
Average total loss: 1.276625
tensor(-15.4487, device='cuda:0') tensor(0.1364, device='cuda:0') tensor(-1.7125e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.936805
Average KL loss: 0.340721
Average total loss: 1.277526
tensor(-15.4496, device='cuda:0') tensor(0.1366, device='cuda:0') tensor(-4.9013e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.933687
Average KL loss: 0.340696
Average total loss: 1.274383
tensor(-15.4506, device='cuda:0') tensor(0.1366, device='cuda:0') tensor(-2.3524e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.934740
Average KL loss: 0.340650
Average total loss: 1.275390
tensor(-15.4515, device='cuda:0') tensor(0.1367, device='cuda:0') tensor(-1.3316e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.935065
Average KL loss: 0.340593
Average total loss: 1.275657
tensor(-15.4525, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-1.4833e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.934753
Average KL loss: 0.340547
Average total loss: 1.275299
tensor(-15.4534, device='cuda:0') tensor(0.1369, device='cuda:0') tensor(1.2307e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.934186
Average KL loss: 0.340496
Average total loss: 1.274682
tensor(-15.4543, device='cuda:0') tensor(0.1370, device='cuda:0') tensor(2.9826e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.934733
Average KL loss: 0.340435
Average total loss: 1.275168
tensor(-15.4553, device='cuda:0') tensor(0.1371, device='cuda:0') tensor(-2.6912e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.934012
Average KL loss: 0.340376
Average total loss: 1.274388
tensor(-15.4562, device='cuda:0') tensor(0.1372, device='cuda:0') tensor(-1.7077e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.933323
Average KL loss: 0.340329
Average total loss: 1.273652
tensor(-15.4572, device='cuda:0') tensor(0.1373, device='cuda:0') tensor(-4.0094e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.930172
Average KL loss: 0.340284
Average total loss: 1.270456
tensor(-15.4581, device='cuda:0') tensor(0.1374, device='cuda:0') tensor(1.0821e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.935352
Average KL loss: 0.340211
Average total loss: 1.275563
tensor(-15.4591, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(1.0117e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.930784
Average KL loss: 0.340151
Average total loss: 1.270935
tensor(-15.4600, device='cuda:0') tensor(0.1376, device='cuda:0') tensor(4.7175e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.930723
Average KL loss: 0.340101
Average total loss: 1.270824
tensor(-15.4610, device='cuda:0') tensor(0.1376, device='cuda:0') tensor(3.2070e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.929295
Average KL loss: 0.340049
Average total loss: 1.269344
tensor(-15.4619, device='cuda:0') tensor(0.1377, device='cuda:0') tensor(-2.0158e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.932083
Average KL loss: 0.339999
Average total loss: 1.272082
tensor(-15.4628, device='cuda:0') tensor(0.1378, device='cuda:0') tensor(1.7594e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.934403
Average KL loss: 0.339926
Average total loss: 1.274329
tensor(-15.4638, device='cuda:0') tensor(0.1379, device='cuda:0') tensor(-3.5122e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.933593
Average KL loss: 0.339864
Average total loss: 1.273457
tensor(-15.4647, device='cuda:0') tensor(0.1380, device='cuda:0') tensor(-1.2414e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.926760
Average KL loss: 0.339795
Average total loss: 1.266555
tensor(-15.4657, device='cuda:0') tensor(0.1381, device='cuda:0') tensor(-6.7488e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.930223
Average KL loss: 0.339752
Average total loss: 1.269975
tensor(-15.4666, device='cuda:0') tensor(0.1382, device='cuda:0') tensor(-2.2639e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.929575
Average KL loss: 0.339666
Average total loss: 1.269241
tensor(-15.4676, device='cuda:0') tensor(0.1383, device='cuda:0') tensor(-1.2153e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.928721
Average KL loss: 0.339617
Average total loss: 1.268338
tensor(-15.4685, device='cuda:0') tensor(0.1384, device='cuda:0') tensor(-4.5003e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.929825
Average KL loss: 0.339559
Average total loss: 1.269384
tensor(-15.4694, device='cuda:0') tensor(0.1385, device='cuda:0') tensor(5.9818e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.926871
Average KL loss: 0.339507
Average total loss: 1.266377
tensor(-15.4704, device='cuda:0') tensor(0.1385, device='cuda:0') tensor(-1.3054e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.930464
Average KL loss: 0.339446
Average total loss: 1.269910
tensor(-15.4713, device='cuda:0') tensor(0.1386, device='cuda:0') tensor(3.1290e-11, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.930188
Average KL loss: 0.339373
Average total loss: 1.269561
tensor(-15.4723, device='cuda:0') tensor(0.1387, device='cuda:0') tensor(-2.0978e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.928111
Average KL loss: 0.339317
Average total loss: 1.267429
tensor(-15.4732, device='cuda:0') tensor(0.1388, device='cuda:0') tensor(-1.2766e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.926441
Average KL loss: 0.339252
Average total loss: 1.265692
tensor(-15.4741, device='cuda:0') tensor(0.1389, device='cuda:0') tensor(-1.2976e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.926557
Average KL loss: 0.339204
Average total loss: 1.265761
tensor(-15.4750, device='cuda:0') tensor(0.1389, device='cuda:0') tensor(2.0113e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.927053
Average KL loss: 0.339158
Average total loss: 1.266211
tensor(-15.4759, device='cuda:0') tensor(0.1390, device='cuda:0') tensor(-3.4535e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.925994
Average KL loss: 0.339112
Average total loss: 1.265106
tensor(-15.4769, device='cuda:0') tensor(0.1391, device='cuda:0') tensor(-1.7995e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.926567
Average KL loss: 0.339053
Average total loss: 1.265620
tensor(-15.4778, device='cuda:0') tensor(0.1392, device='cuda:0') tensor(6.7811e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.928177
Average KL loss: 0.339000
Average total loss: 1.267177
tensor(-15.4787, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(-8.1899e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.927021
Average KL loss: 0.338944
Average total loss: 1.265965
tensor(-15.4796, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(1.4315e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.926296
Average KL loss: 0.338870
Average total loss: 1.265165
tensor(-15.4805, device='cuda:0') tensor(0.1394, device='cuda:0') tensor(-1.7161e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.928542
Average KL loss: 0.338842
Average total loss: 1.267384
tensor(-15.4814, device='cuda:0') tensor(0.1395, device='cuda:0') tensor(-2.9521e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.927123
Average KL loss: 0.338792
Average total loss: 1.265915
tensor(-15.4823, device='cuda:0') tensor(0.1396, device='cuda:0') tensor(3.7501e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.923721
Average KL loss: 0.338760
Average total loss: 1.262481
tensor(-15.4833, device='cuda:0') tensor(0.1397, device='cuda:0') tensor(1.1857e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.923672
Average KL loss: 0.338716
Average total loss: 1.262388
tensor(-15.4842, device='cuda:0') tensor(0.1397, device='cuda:0') tensor(3.4802e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.925498
Average KL loss: 0.338669
Average total loss: 1.264166
tensor(-15.4851, device='cuda:0') tensor(0.1398, device='cuda:0') tensor(1.0832e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.927045
Average KL loss: 0.338614
Average total loss: 1.265660
tensor(-15.4860, device='cuda:0') tensor(0.1399, device='cuda:0') tensor(-4.6136e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.922930
Average KL loss: 0.338571
Average total loss: 1.261501
tensor(-15.4869, device='cuda:0') tensor(0.1400, device='cuda:0') tensor(-4.5555e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.925542
Average KL loss: 0.338537
Average total loss: 1.264079
tensor(-15.4878, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(-1.2451e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.922464
Average KL loss: 0.338494
Average total loss: 1.260958
tensor(-15.4887, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(2.0950e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.921742
Average KL loss: 0.338437
Average total loss: 1.260179
tensor(-15.4896, device='cuda:0') tensor(0.1402, device='cuda:0') tensor(-2.1018e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.923223
Average KL loss: 0.338374
Average total loss: 1.261598
tensor(-15.4905, device='cuda:0') tensor(0.1403, device='cuda:0') tensor(1.9397e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.924893
Average KL loss: 0.338329
Average total loss: 1.263222
tensor(-15.4914, device='cuda:0') tensor(0.1404, device='cuda:0') tensor(-9.3557e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.922828
Average KL loss: 0.338265
Average total loss: 1.261092
tensor(-15.4923, device='cuda:0') tensor(0.1405, device='cuda:0') tensor(1.6172e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.921727
Average KL loss: 0.338184
Average total loss: 1.259911
tensor(-15.4932, device='cuda:0') tensor(0.1405, device='cuda:0') tensor(1.7369e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.920814
Average KL loss: 0.338122
Average total loss: 1.258937
tensor(-15.4941, device='cuda:0') tensor(0.1406, device='cuda:0') tensor(-7.6337e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.923227
Average KL loss: 0.338066
Average total loss: 1.261293
tensor(-15.4950, device='cuda:0') tensor(0.1407, device='cuda:0') tensor(-4.3271e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.922056
Average KL loss: 0.338017
Average total loss: 1.260073
tensor(-15.4959, device='cuda:0') tensor(0.1408, device='cuda:0') tensor(9.6212e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.922627
Average KL loss: 0.337961
Average total loss: 1.260588
tensor(-15.4968, device='cuda:0') tensor(0.1409, device='cuda:0') tensor(-8.7089e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.922945
Average KL loss: 0.337880
Average total loss: 1.260825
tensor(-15.4977, device='cuda:0') tensor(0.1409, device='cuda:0') tensor(-7.0987e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.923452
Average KL loss: 0.337847
Average total loss: 1.261299
tensor(-15.4986, device='cuda:0') tensor(0.1410, device='cuda:0') tensor(-8.5938e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.921901
Average KL loss: 0.337822
Average total loss: 1.259722
tensor(-15.4995, device='cuda:0') tensor(0.1411, device='cuda:0') tensor(-1.1218e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.923438
Average KL loss: 0.337787
Average total loss: 1.261225
tensor(-15.5004, device='cuda:0') tensor(0.1412, device='cuda:0') tensor(-6.6894e-11, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.921259
Average KL loss: 0.337723
Average total loss: 1.258982
tensor(-15.5013, device='cuda:0') tensor(0.1413, device='cuda:0') tensor(-1.1794e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.922692
Average KL loss: 0.337663
Average total loss: 1.260355
tensor(-15.5022, device='cuda:0') tensor(0.1413, device='cuda:0') tensor(-1.2003e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.918825
Average KL loss: 0.337612
Average total loss: 1.256437
tensor(-15.5031, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(3.8016e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.922717
Average KL loss: 0.337577
Average total loss: 1.260294
tensor(-15.5040, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-1.7227e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.918937
Average KL loss: 0.337559
Average total loss: 1.256496
tensor(-15.5049, device='cuda:0') tensor(0.1416, device='cuda:0') tensor(-1.1926e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.919413
Average KL loss: 0.337536
Average total loss: 1.256949
tensor(-15.5058, device='cuda:0') tensor(0.1417, device='cuda:0') tensor(-2.2086e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.920497
Average KL loss: 0.337492
Average total loss: 1.257989
tensor(-15.5067, device='cuda:0') tensor(0.1418, device='cuda:0') tensor(-4.0014e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.921900
Average KL loss: 0.337446
Average total loss: 1.259346
tensor(-15.5076, device='cuda:0') tensor(0.1418, device='cuda:0') tensor(-1.4687e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.920555
Average KL loss: 0.337414
Average total loss: 1.257969
tensor(-15.5085, device='cuda:0') tensor(0.1419, device='cuda:0') tensor(-4.5409e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.921993
Average KL loss: 0.337413
Average total loss: 1.259406
tensor(-15.5094, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(-1.9931e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.920199
Average KL loss: 0.337393
Average total loss: 1.257591
tensor(-15.5103, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-1.5639e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.917031
Average KL loss: 0.337352
Average total loss: 1.254383
tensor(-15.5112, device='cuda:0') tensor(0.1422, device='cuda:0') tensor(-1.1448e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.923001
Average KL loss: 0.337303
Average total loss: 1.260304
tensor(-15.5121, device='cuda:0') tensor(0.1422, device='cuda:0') tensor(-1.8377e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.918921
Average KL loss: 0.337248
Average total loss: 1.256169
tensor(-15.5129, device='cuda:0') tensor(0.1423, device='cuda:0') tensor(-2.0212e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.920665
Average KL loss: 0.337194
Average total loss: 1.257858
tensor(-15.5138, device='cuda:0') tensor(0.1424, device='cuda:0') tensor(6.9820e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.917012
Average KL loss: 0.337133
Average total loss: 1.254146
tensor(-15.5147, device='cuda:0') tensor(0.1424, device='cuda:0') tensor(-4.6906e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.918632
Average KL loss: 0.337081
Average total loss: 1.255713
tensor(-15.5156, device='cuda:0') tensor(0.1425, device='cuda:0') tensor(9.4826e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.917480
Average KL loss: 0.337038
Average total loss: 1.254519
tensor(-15.5165, device='cuda:0') tensor(0.1426, device='cuda:0') tensor(6.4188e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.920001
Average KL loss: 0.336993
Average total loss: 1.256994
tensor(-15.5174, device='cuda:0') tensor(0.1426, device='cuda:0') tensor(-3.7197e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.918933
Average KL loss: 0.336944
Average total loss: 1.255877
tensor(-15.5183, device='cuda:0') tensor(0.1427, device='cuda:0') tensor(-9.3811e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.919677
Average KL loss: 0.336895
Average total loss: 1.256572
tensor(-15.5192, device='cuda:0') tensor(0.1428, device='cuda:0') tensor(1.7399e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.920573
Average KL loss: 0.336859
Average total loss: 1.257432
tensor(-15.5201, device='cuda:0') tensor(0.1429, device='cuda:0') tensor(-2.4877e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.918279
Average KL loss: 0.336833
Average total loss: 1.255112
tensor(-15.5210, device='cuda:0') tensor(0.1429, device='cuda:0') tensor(2.7153e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.922226
Average KL loss: 0.336814
Average total loss: 1.259040
tensor(-15.5219, device='cuda:0') tensor(0.1430, device='cuda:0') tensor(-1.6109e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.916661
Average KL loss: 0.336767
Average total loss: 1.253428
tensor(-15.5228, device='cuda:0') tensor(0.1431, device='cuda:0') tensor(-1.7011e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.917487
Average KL loss: 0.336730
Average total loss: 1.254216
tensor(-15.5237, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(2.3817e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.918521
Average KL loss: 0.336683
Average total loss: 1.255204
tensor(-15.5246, device='cuda:0') tensor(0.1432, device='cuda:0') tensor(7.0027e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.916761
Average KL loss: 0.336656
Average total loss: 1.253417
tensor(-15.5255, device='cuda:0') tensor(0.1433, device='cuda:0') tensor(-1.7891e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.918679
Average KL loss: 0.336628
Average total loss: 1.255307
tensor(-15.5263, device='cuda:0') tensor(0.1434, device='cuda:0') tensor(-2.3234e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.919350
Average KL loss: 0.336612
Average total loss: 1.255962
tensor(-15.5272, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(3.6089e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.916772
Average KL loss: 0.336596
Average total loss: 1.253368
tensor(-15.5281, device='cuda:0') tensor(0.1435, device='cuda:0') tensor(-1.4243e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.916255
Average KL loss: 0.336581
Average total loss: 1.252836
tensor(-15.5290, device='cuda:0') tensor(0.1437, device='cuda:0') tensor(-7.2742e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.917609
Average KL loss: 0.336571
Average total loss: 1.254180
tensor(-15.5298, device='cuda:0') tensor(0.1437, device='cuda:0') tensor(-1.0205e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.918116
Average KL loss: 0.336532
Average total loss: 1.254648
tensor(-15.5307, device='cuda:0') tensor(0.1438, device='cuda:0') tensor(-4.3960e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.916035
Average KL loss: 0.336504
Average total loss: 1.252539
tensor(-15.5316, device='cuda:0') tensor(0.1439, device='cuda:0') tensor(-4.6725e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.918564
Average KL loss: 0.336487
Average total loss: 1.255051
tensor(-15.5324, device='cuda:0') tensor(0.1440, device='cuda:0') tensor(-2.2700e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.916459
Average KL loss: 0.336470
Average total loss: 1.252930
tensor(-15.5333, device='cuda:0') tensor(0.1440, device='cuda:0') tensor(-8.9757e-11, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.917292
Average KL loss: 0.336454
Average total loss: 1.253746
tensor(-15.5342, device='cuda:0') tensor(0.1441, device='cuda:0') tensor(8.0727e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.916179
Average KL loss: 0.336409
Average total loss: 1.252587
tensor(-15.5350, device='cuda:0') tensor(0.1442, device='cuda:0') tensor(-3.6896e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.915402
Average KL loss: 0.336390
Average total loss: 1.251792
tensor(-15.5359, device='cuda:0') tensor(0.1442, device='cuda:0') tensor(7.5814e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.916928
Average KL loss: 0.336364
Average total loss: 1.253291
tensor(-15.5368, device='cuda:0') tensor(0.1443, device='cuda:0') tensor(-2.0098e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.915937
Average KL loss: 0.336337
Average total loss: 1.252274
tensor(-15.5376, device='cuda:0') tensor(0.1444, device='cuda:0') tensor(1.0718e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.916898
Average KL loss: 0.336320
Average total loss: 1.253219
tensor(-15.5385, device='cuda:0') tensor(0.1444, device='cuda:0') tensor(5.0463e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.914584
Average KL loss: 0.336292
Average total loss: 1.250876
tensor(-15.5393, device='cuda:0') tensor(0.1445, device='cuda:0') tensor(2.5764e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.915925
Average KL loss: 0.336263
Average total loss: 1.252188
tensor(-15.5402, device='cuda:0') tensor(0.1446, device='cuda:0') tensor(-6.6031e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.915996
Average KL loss: 0.336239
Average total loss: 1.252235
tensor(-15.5411, device='cuda:0') tensor(0.1446, device='cuda:0') tensor(-9.7058e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.913501
Average KL loss: 0.336216
Average total loss: 1.249717
tensor(-15.5419, device='cuda:0') tensor(0.1447, device='cuda:0') tensor(-1.2093e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.917065
Average KL loss: 0.336185
Average total loss: 1.253250
tensor(-15.5428, device='cuda:0') tensor(0.1448, device='cuda:0') tensor(7.2360e-11, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.914710
Average KL loss: 0.336175
Average total loss: 1.250885
tensor(-15.5436, device='cuda:0') tensor(0.1448, device='cuda:0') tensor(-8.5132e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.915686
Average KL loss: 0.336150
Average total loss: 1.251836
tensor(-15.5445, device='cuda:0') tensor(0.1449, device='cuda:0') tensor(-1.0847e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.914794
Average KL loss: 0.336097
Average total loss: 1.250891
tensor(-15.5453, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(-4.3009e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.914371
Average KL loss: 0.336036
Average total loss: 1.250408
tensor(-15.5462, device='cuda:0') tensor(0.1450, device='cuda:0') tensor(3.3759e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.916140
Average KL loss: 0.336002
Average total loss: 1.252142
tensor(-15.5470, device='cuda:0') tensor(0.1451, device='cuda:0') tensor(-3.4162e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.914837
Average KL loss: 0.335965
Average total loss: 1.250801
tensor(-15.5479, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(-1.0492e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.915595
Average KL loss: 0.335909
Average total loss: 1.251504
tensor(-15.5487, device='cuda:0') tensor(0.1452, device='cuda:0') tensor(-2.5731e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.913747
Average KL loss: 0.335874
Average total loss: 1.249621
tensor(-15.5496, device='cuda:0') tensor(0.1453, device='cuda:0') tensor(-1.6648e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.914468
Average KL loss: 0.335850
Average total loss: 1.250318
tensor(-15.5504, device='cuda:0') tensor(0.1454, device='cuda:0') tensor(-8.7460e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.913370
Average KL loss: 0.335815
Average total loss: 1.249186
tensor(-15.5513, device='cuda:0') tensor(0.1455, device='cuda:0') tensor(2.5875e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.914086
Average KL loss: 0.335778
Average total loss: 1.249864
tensor(-15.5521, device='cuda:0') tensor(0.1455, device='cuda:0') tensor(-3.9078e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.911769
Average KL loss: 0.335749
Average total loss: 1.247519
tensor(-15.5530, device='cuda:0') tensor(0.1456, device='cuda:0') tensor(-2.3008e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.915038
Average KL loss: 0.335733
Average total loss: 1.250771
tensor(-15.5538, device='cuda:0') tensor(0.1457, device='cuda:0') tensor(-1.9491e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.913936
Average KL loss: 0.335693
Average total loss: 1.249630
tensor(-15.5547, device='cuda:0') tensor(0.1457, device='cuda:0') tensor(-1.4199e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.912257
Average KL loss: 0.335651
Average total loss: 1.247908
tensor(-15.5555, device='cuda:0') tensor(0.1458, device='cuda:0') tensor(-3.5128e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.912310
Average KL loss: 0.335596
Average total loss: 1.247906
tensor(-15.5564, device='cuda:0') tensor(0.1458, device='cuda:0') tensor(-3.6384e-11, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.912901
Average KL loss: 0.335561
Average total loss: 1.248462
tensor(-15.5572, device='cuda:0') tensor(0.1459, device='cuda:0') tensor(-2.4254e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.910420
Average KL loss: 0.335526
Average total loss: 1.245946
tensor(-15.5581, device='cuda:0') tensor(0.1460, device='cuda:0') tensor(-4.9979e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.912563
Average KL loss: 0.335468
Average total loss: 1.248031
tensor(-15.5589, device='cuda:0') tensor(0.1460, device='cuda:0') tensor(2.0794e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.913943
Average KL loss: 0.335379
Average total loss: 1.249322
tensor(-15.5598, device='cuda:0') tensor(0.1461, device='cuda:0') tensor(2.7719e-11, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.912084
Average KL loss: 0.335296
Average total loss: 1.247380
tensor(-15.5606, device='cuda:0') tensor(0.1461, device='cuda:0') tensor(-2.8910e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.912875
Average KL loss: 0.335239
Average total loss: 1.248114
tensor(-15.5615, device='cuda:0') tensor(0.1462, device='cuda:0') tensor(3.4476e-11, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.911885
Average KL loss: 0.335196
Average total loss: 1.247082
tensor(-15.5623, device='cuda:0') tensor(0.1462, device='cuda:0') tensor(-1.0012e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.914993
Average KL loss: 0.335186
Average total loss: 1.250179
tensor(-15.5632, device='cuda:0') tensor(0.1463, device='cuda:0') tensor(3.5058e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.913384
Average KL loss: 0.335167
Average total loss: 1.248551
tensor(-15.5640, device='cuda:0') tensor(0.1464, device='cuda:0') tensor(-7.5715e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.913202
Average KL loss: 0.335126
Average total loss: 1.248328
tensor(-15.5649, device='cuda:0') tensor(0.1464, device='cuda:0') tensor(-7.4032e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.910969
Average KL loss: 0.335078
Average total loss: 1.246047
tensor(-15.5657, device='cuda:0') tensor(0.1465, device='cuda:0') tensor(-3.9600e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.912450
Average KL loss: 0.335020
Average total loss: 1.247470
tensor(-15.5666, device='cuda:0') tensor(0.1466, device='cuda:0') tensor(-2.5263e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.911684
Average KL loss: 0.334994
Average total loss: 1.246678
tensor(-15.5674, device='cuda:0') tensor(0.1466, device='cuda:0') tensor(-6.0403e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.911194
Average KL loss: 0.334985
Average total loss: 1.246178
tensor(-15.5675, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(4.2183e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.911275
Average KL loss: 0.334981
Average total loss: 1.246255
tensor(-15.5676, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-4.3809e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.913016
Average KL loss: 0.334977
Average total loss: 1.247993
tensor(-15.5677, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-1.0972e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.910315
Average KL loss: 0.334975
Average total loss: 1.245290
tensor(-15.5678, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(4.5354e-11, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.911547
Average KL loss: 0.334971
Average total loss: 1.246518
tensor(-15.5679, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(4.1714e-11, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.911170
Average KL loss: 0.334967
Average total loss: 1.246137
tensor(-15.5680, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-3.5844e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.915393
Average KL loss: 0.334965
Average total loss: 1.250358
tensor(-15.5681, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(5.6673e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.911659
Average KL loss: 0.334961
Average total loss: 1.246620
tensor(-15.5682, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(6.5967e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.912869
Average KL loss: 0.334959
Average total loss: 1.247828
tensor(-15.5683, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(9.1465e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.911485
Average KL loss: 0.334955
Average total loss: 1.246440
tensor(-15.5684, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-2.9841e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.911887
Average KL loss: 0.334954
Average total loss: 1.246841
tensor(-15.5685, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-7.9543e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.911812
Average KL loss: 0.334951
Average total loss: 1.246763
tensor(-15.5686, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(1.7969e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.910872
Average KL loss: 0.334948
Average total loss: 1.245820
tensor(-15.5686, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(7.8225e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.912851
Average KL loss: 0.334944
Average total loss: 1.247795
tensor(-15.5687, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-1.3446e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.913025
Average KL loss: 0.334940
Average total loss: 1.247965
tensor(-15.5688, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-1.7469e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.912993
Average KL loss: 0.334938
Average total loss: 1.247931
tensor(-15.5688, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(1.0691e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.911257
Average KL loss: 0.334937
Average total loss: 1.246194
tensor(-15.5688, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-5.5394e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.912934
Average KL loss: 0.334937
Average total loss: 1.247871
tensor(-15.5688, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-1.4617e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.911992
Average KL loss: 0.334937
Average total loss: 1.246929
tensor(-15.5688, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-6.0666e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.914638
Average KL loss: 0.334937
Average total loss: 1.249575
tensor(-15.5688, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(3.2405e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.911891
Average KL loss: 0.334936
Average total loss: 1.246828
tensor(-15.5688, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(7.8360e-11, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.911140
Average KL loss: 0.334936
Average total loss: 1.246077
tensor(-15.5688, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-6.4767e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.912743
Average KL loss: 0.334936
Average total loss: 1.247679
tensor(-15.5688, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(2.2064e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.912004
Average KL loss: 0.334936
Average total loss: 1.246940
 Percentile value: -15.55183219909668
Non-zero model percentage: 10.737431526184082%, Non-zero mask percentage: 10.737431526184082%

--- Pruning Level [10/24]: ---
conv1.weight         | nonzeros =    1677 /    1728             ( 97.05%) | total_pruned =      51 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   25446 /   36864             ( 69.03%) | total_pruned =   11418 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   25360 /   36864             ( 68.79%) | total_pruned =   11504 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   21869 /   36864             ( 59.32%) | total_pruned =   14995 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   20329 /   36864             ( 55.15%) | total_pruned =   16535 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   44356 /   73728             ( 60.16%) | total_pruned =   29372 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   65029 /  147456             ( 44.10%) | total_pruned =   82427 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    6893 /    8192             ( 84.14%) | total_pruned =    1299 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   52110 /  147456             ( 35.34%) | total_pruned =   95346 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   46375 /  147456             ( 31.45%) | total_pruned =  101081 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   83967 /  294912             ( 28.47%) | total_pruned =  210945 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   91384 /  589824             ( 15.49%) | total_pruned =  498440 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   18975 /   32768             ( 57.91%) | total_pruned =   13793 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   39689 /  589824             (  6.73%) | total_pruned =  550135 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     241 /     256             ( 94.14%) | total_pruned =      15 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   38764 /  589824             (  6.57%) | total_pruned =  551060 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   94846 / 1179648             (  8.04%) | total_pruned = 1084802 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  139211 / 2359296             (  5.90%) | total_pruned = 2220085 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   50140 /  131072             ( 38.25%) | total_pruned =   80932 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  132199 / 2359296             (  5.60%) | total_pruned = 2227097 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  187575 / 2359296             (  7.95%) | total_pruned = 2171721 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4873 /    5120             ( 95.18%) | total_pruned =     247 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 1200312, pruned : 9978450, total: 11178762, Compression rate :       9.31x  ( 89.26% pruned)
Train Epoch: 22/100 Loss: 0.000024 Accuracy: 85.93 100.00 % Best test Accuracy: 85.98%
tensor(-15.5688, device='cuda:0') tensor(0.1467, device='cuda:0') tensor(-3.6906e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.990442
Average KL loss: 0.334500
Average total loss: 1.324942
tensor(-15.5698, device='cuda:0') tensor(0.1419, device='cuda:0') tensor(-8.5792e-11, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.987862
Average KL loss: 0.333918
Average total loss: 1.321780
tensor(-15.5707, device='cuda:0') tensor(0.1385, device='cuda:0') tensor(-4.9749e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.995695
Average KL loss: 0.333491
Average total loss: 1.329186
tensor(-15.5716, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(-2.0604e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.997351
Average KL loss: 0.333090
Average total loss: 1.330440
tensor(-15.5725, device='cuda:0') tensor(0.1347, device='cuda:0') tensor(-6.4921e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.996841
Average KL loss: 0.332757
Average total loss: 1.329598
tensor(-15.5734, device='cuda:0') tensor(0.1341, device='cuda:0') tensor(-7.7608e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.997806
Average KL loss: 0.332543
Average total loss: 1.330348
tensor(-15.5742, device='cuda:0') tensor(0.1339, device='cuda:0') tensor(-2.0585e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.995910
Average KL loss: 0.332397
Average total loss: 1.328307
tensor(-15.5751, device='cuda:0') tensor(0.1338, device='cuda:0') tensor(-1.9694e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.997113
Average KL loss: 0.332265
Average total loss: 1.329377
tensor(-15.5759, device='cuda:0') tensor(0.1337, device='cuda:0') tensor(-3.2344e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.984377
Average KL loss: 0.332139
Average total loss: 1.316516
tensor(-15.5768, device='cuda:0') tensor(0.1338, device='cuda:0') tensor(4.9683e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.987750
Average KL loss: 0.332041
Average total loss: 1.319791
tensor(-15.5776, device='cuda:0') tensor(0.1338, device='cuda:0') tensor(-8.2452e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.979275
Average KL loss: 0.331950
Average total loss: 1.311225
tensor(-15.5785, device='cuda:0') tensor(0.1338, device='cuda:0') tensor(-3.2781e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.980319
Average KL loss: 0.331907
Average total loss: 1.312226
tensor(-15.5793, device='cuda:0') tensor(0.1339, device='cuda:0') tensor(-3.4847e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.979843
Average KL loss: 0.331880
Average total loss: 1.311723
tensor(-15.5802, device='cuda:0') tensor(0.1339, device='cuda:0') tensor(-1.3650e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.975143
Average KL loss: 0.331852
Average total loss: 1.306994
tensor(-15.5810, device='cuda:0') tensor(0.1340, device='cuda:0') tensor(-2.3212e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.973159
Average KL loss: 0.331816
Average total loss: 1.304975
tensor(-15.5819, device='cuda:0') tensor(0.1341, device='cuda:0') tensor(-1.5490e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.972269
Average KL loss: 0.331774
Average total loss: 1.304043
tensor(-15.5827, device='cuda:0') tensor(0.1341, device='cuda:0') tensor(-5.3753e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.972130
Average KL loss: 0.331745
Average total loss: 1.303876
tensor(-15.5835, device='cuda:0') tensor(0.1342, device='cuda:0') tensor(-1.8348e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.967771
Average KL loss: 0.331722
Average total loss: 1.299492
tensor(-15.5844, device='cuda:0') tensor(0.1343, device='cuda:0') tensor(-4.7321e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.966833
Average KL loss: 0.331676
Average total loss: 1.298509
tensor(-15.5852, device='cuda:0') tensor(0.1344, device='cuda:0') tensor(-5.5813e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.970911
Average KL loss: 0.331613
Average total loss: 1.302524
tensor(-15.5860, device='cuda:0') tensor(0.1344, device='cuda:0') tensor(-1.9089e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.963973
Average KL loss: 0.331545
Average total loss: 1.295518
tensor(-15.5869, device='cuda:0') tensor(0.1345, device='cuda:0') tensor(-2.6350e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.961267
Average KL loss: 0.331474
Average total loss: 1.292741
tensor(-15.5877, device='cuda:0') tensor(0.1346, device='cuda:0') tensor(-1.3516e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.963769
Average KL loss: 0.331431
Average total loss: 1.295201
tensor(-15.5885, device='cuda:0') tensor(0.1347, device='cuda:0') tensor(-5.9139e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.966814
Average KL loss: 0.331379
Average total loss: 1.298193
tensor(-15.5893, device='cuda:0') tensor(0.1348, device='cuda:0') tensor(-2.5723e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.959961
Average KL loss: 0.331328
Average total loss: 1.291289
tensor(-15.5901, device='cuda:0') tensor(0.1348, device='cuda:0') tensor(-1.7991e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.961071
Average KL loss: 0.331289
Average total loss: 1.292359
tensor(-15.5909, device='cuda:0') tensor(0.1349, device='cuda:0') tensor(-7.8688e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.960794
Average KL loss: 0.331266
Average total loss: 1.292060
tensor(-15.5918, device='cuda:0') tensor(0.1350, device='cuda:0') tensor(-2.7300e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.954985
Average KL loss: 0.331248
Average total loss: 1.286234
tensor(-15.5926, device='cuda:0') tensor(0.1351, device='cuda:0') tensor(-3.1653e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.959587
Average KL loss: 0.331206
Average total loss: 1.290792
tensor(-15.5934, device='cuda:0') tensor(0.1352, device='cuda:0') tensor(-1.5822e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.956501
Average KL loss: 0.331159
Average total loss: 1.287661
tensor(-15.5942, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-1.2101e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.959039
Average KL loss: 0.331129
Average total loss: 1.290168
tensor(-15.5950, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(-2.8567e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.954263
Average KL loss: 0.331115
Average total loss: 1.285378
tensor(-15.5958, device='cuda:0') tensor(0.1355, device='cuda:0') tensor(-4.9703e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.951491
Average KL loss: 0.331092
Average total loss: 1.282583
tensor(-15.5966, device='cuda:0') tensor(0.1355, device='cuda:0') tensor(-3.3849e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.959449
Average KL loss: 0.331074
Average total loss: 1.290522
tensor(-15.5974, device='cuda:0') tensor(0.1356, device='cuda:0') tensor(5.0197e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.961194
Average KL loss: 0.331031
Average total loss: 1.292225
tensor(-15.5982, device='cuda:0') tensor(0.1357, device='cuda:0') tensor(-2.3220e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.957960
Average KL loss: 0.331017
Average total loss: 1.288977
tensor(-15.5991, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-1.5222e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.954351
Average KL loss: 0.330976
Average total loss: 1.285327
tensor(-15.5999, device='cuda:0') tensor(0.1359, device='cuda:0') tensor(-1.2214e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.950804
Average KL loss: 0.330923
Average total loss: 1.281728
tensor(-15.6007, device='cuda:0') tensor(0.1360, device='cuda:0') tensor(-2.9685e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.954362
Average KL loss: 0.330896
Average total loss: 1.285258
tensor(-15.6015, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(-3.1256e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.951310
Average KL loss: 0.330858
Average total loss: 1.282168
tensor(-15.6023, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(-3.4987e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.952238
Average KL loss: 0.330819
Average total loss: 1.283057
tensor(-15.6031, device='cuda:0') tensor(0.1362, device='cuda:0') tensor(-2.0738e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.951731
Average KL loss: 0.330782
Average total loss: 1.282514
tensor(-15.6039, device='cuda:0') tensor(0.1363, device='cuda:0') tensor(5.2597e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.953307
Average KL loss: 0.330761
Average total loss: 1.284068
tensor(-15.6047, device='cuda:0') tensor(0.1364, device='cuda:0') tensor(-2.2323e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.950996
Average KL loss: 0.330744
Average total loss: 1.281740
tensor(-15.6055, device='cuda:0') tensor(0.1365, device='cuda:0') tensor(-2.3249e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.950731
Average KL loss: 0.330702
Average total loss: 1.281432
tensor(-15.6063, device='cuda:0') tensor(0.1366, device='cuda:0') tensor(-1.2074e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.946884
Average KL loss: 0.330660
Average total loss: 1.277544
tensor(-15.6071, device='cuda:0') tensor(0.1366, device='cuda:0') tensor(-2.2188e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.949879
Average KL loss: 0.330625
Average total loss: 1.280504
tensor(-15.6079, device='cuda:0') tensor(0.1367, device='cuda:0') tensor(6.6787e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.947718
Average KL loss: 0.330612
Average total loss: 1.278330
tensor(-15.6087, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-2.6427e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.952587
Average KL loss: 0.330595
Average total loss: 1.283183
tensor(-15.6095, device='cuda:0') tensor(0.1369, device='cuda:0') tensor(-1.7807e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.948977
Average KL loss: 0.330575
Average total loss: 1.279552
tensor(-15.6103, device='cuda:0') tensor(0.1370, device='cuda:0') tensor(-1.3123e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.944140
Average KL loss: 0.330555
Average total loss: 1.274695
tensor(-15.6111, device='cuda:0') tensor(0.1372, device='cuda:0') tensor(-8.0632e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.946320
Average KL loss: 0.330539
Average total loss: 1.276860
tensor(-15.6119, device='cuda:0') tensor(0.1373, device='cuda:0') tensor(4.7209e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.945678
Average KL loss: 0.330505
Average total loss: 1.276183
tensor(-15.6127, device='cuda:0') tensor(0.1374, device='cuda:0') tensor(-1.9665e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.944210
Average KL loss: 0.330463
Average total loss: 1.274673
tensor(-15.6135, device='cuda:0') tensor(0.1374, device='cuda:0') tensor(2.6086e-12, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.944032
Average KL loss: 0.330415
Average total loss: 1.274447
tensor(-15.6143, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(-2.0960e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.943448
Average KL loss: 0.330389
Average total loss: 1.273837
tensor(-15.6151, device='cuda:0') tensor(0.1376, device='cuda:0') tensor(-2.5310e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.947817
Average KL loss: 0.330368
Average total loss: 1.278186
tensor(-15.6159, device='cuda:0') tensor(0.1377, device='cuda:0') tensor(-1.8892e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.949113
Average KL loss: 0.330356
Average total loss: 1.279469
tensor(-15.6167, device='cuda:0') tensor(0.1378, device='cuda:0') tensor(-3.3790e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.945549
Average KL loss: 0.330348
Average total loss: 1.275898
tensor(-15.6175, device='cuda:0') tensor(0.1379, device='cuda:0') tensor(-9.5158e-11, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.947365
Average KL loss: 0.330321
Average total loss: 1.277686
tensor(-15.6183, device='cuda:0') tensor(0.1380, device='cuda:0') tensor(-6.2043e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.944898
Average KL loss: 0.330319
Average total loss: 1.275216
tensor(-15.6191, device='cuda:0') tensor(0.1381, device='cuda:0') tensor(-2.6098e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.942264
Average KL loss: 0.330289
Average total loss: 1.272553
tensor(-15.6199, device='cuda:0') tensor(0.1382, device='cuda:0') tensor(1.1487e-12, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.942940
Average KL loss: 0.330255
Average total loss: 1.273196
tensor(-15.6207, device='cuda:0') tensor(0.1383, device='cuda:0') tensor(4.0813e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.947559
Average KL loss: 0.330238
Average total loss: 1.277798
tensor(-15.6215, device='cuda:0') tensor(0.1384, device='cuda:0') tensor(-2.0740e-11, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.943072
Average KL loss: 0.330204
Average total loss: 1.273276
tensor(-15.6223, device='cuda:0') tensor(0.1385, device='cuda:0') tensor(1.2900e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.940582
Average KL loss: 0.330162
Average total loss: 1.270744
tensor(-15.6231, device='cuda:0') tensor(0.1386, device='cuda:0') tensor(-8.6005e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.939449
Average KL loss: 0.330152
Average total loss: 1.269601
tensor(-15.6239, device='cuda:0') tensor(0.1386, device='cuda:0') tensor(-1.0180e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.941119
Average KL loss: 0.330118
Average total loss: 1.271237
tensor(-15.6247, device='cuda:0') tensor(0.1387, device='cuda:0') tensor(-2.8987e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.942717
Average KL loss: 0.330092
Average total loss: 1.272808
tensor(-15.6255, device='cuda:0') tensor(0.1388, device='cuda:0') tensor(-6.8493e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.940566
Average KL loss: 0.330077
Average total loss: 1.270642
tensor(-15.6263, device='cuda:0') tensor(0.1389, device='cuda:0') tensor(6.3887e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.939003
Average KL loss: 0.330027
Average total loss: 1.269030
tensor(-15.6271, device='cuda:0') tensor(0.1390, device='cuda:0') tensor(-4.1516e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.941692
Average KL loss: 0.330001
Average total loss: 1.271693
tensor(-15.6279, device='cuda:0') tensor(0.1391, device='cuda:0') tensor(-1.1611e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.937486
Average KL loss: 0.329996
Average total loss: 1.267481
tensor(-15.6287, device='cuda:0') tensor(0.1391, device='cuda:0') tensor(-1.8024e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.938939
Average KL loss: 0.329982
Average total loss: 1.268921
tensor(-15.6295, device='cuda:0') tensor(0.1392, device='cuda:0') tensor(-6.1694e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.935335
Average KL loss: 0.329966
Average total loss: 1.265301
tensor(-15.6303, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(-6.2822e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.937377
Average KL loss: 0.329954
Average total loss: 1.267332
tensor(-15.6311, device='cuda:0') tensor(0.1394, device='cuda:0') tensor(-1.7842e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.938175
Average KL loss: 0.329943
Average total loss: 1.268118
tensor(-15.6319, device='cuda:0') tensor(0.1395, device='cuda:0') tensor(-2.5607e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.937183
Average KL loss: 0.329919
Average total loss: 1.267102
tensor(-15.6327, device='cuda:0') tensor(0.1395, device='cuda:0') tensor(-4.0913e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.937855
Average KL loss: 0.329903
Average total loss: 1.267759
tensor(-15.6335, device='cuda:0') tensor(0.1396, device='cuda:0') tensor(-3.3364e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.935283
Average KL loss: 0.329868
Average total loss: 1.265151
tensor(-15.6343, device='cuda:0') tensor(0.1397, device='cuda:0') tensor(-1.2337e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.936405
Average KL loss: 0.329847
Average total loss: 1.266252
tensor(-15.6351, device='cuda:0') tensor(0.1397, device='cuda:0') tensor(-1.7310e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.940200
Average KL loss: 0.329818
Average total loss: 1.270018
tensor(-15.6359, device='cuda:0') tensor(0.1398, device='cuda:0') tensor(-4.5530e-11, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.937834
Average KL loss: 0.329794
Average total loss: 1.267627
tensor(-15.6367, device='cuda:0') tensor(0.1399, device='cuda:0') tensor(-5.9382e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.936062
Average KL loss: 0.329762
Average total loss: 1.265824
tensor(-15.6375, device='cuda:0') tensor(0.1400, device='cuda:0') tensor(1.4673e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.937519
Average KL loss: 0.329744
Average total loss: 1.267263
tensor(-15.6383, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(-4.9076e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.937269
Average KL loss: 0.329740
Average total loss: 1.267009
tensor(-15.6391, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(-9.6737e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.937415
Average KL loss: 0.329732
Average total loss: 1.267147
tensor(-15.6399, device='cuda:0') tensor(0.1402, device='cuda:0') tensor(2.1265e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.932970
Average KL loss: 0.329706
Average total loss: 1.262677
tensor(-15.6407, device='cuda:0') tensor(0.1403, device='cuda:0') tensor(-1.8058e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.937844
Average KL loss: 0.329690
Average total loss: 1.267533
tensor(-15.6415, device='cuda:0') tensor(0.1404, device='cuda:0') tensor(-4.1970e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.935664
Average KL loss: 0.329684
Average total loss: 1.265348
tensor(-15.6423, device='cuda:0') tensor(0.1405, device='cuda:0') tensor(-7.5568e-12, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.931780
Average KL loss: 0.329665
Average total loss: 1.261445
tensor(-15.6431, device='cuda:0') tensor(0.1405, device='cuda:0') tensor(-1.0310e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.935505
Average KL loss: 0.329635
Average total loss: 1.265140
tensor(-15.6439, device='cuda:0') tensor(0.1406, device='cuda:0') tensor(-1.0641e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.937164
Average KL loss: 0.329626
Average total loss: 1.266789
tensor(-15.6446, device='cuda:0') tensor(0.1407, device='cuda:0') tensor(-1.9381e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.934716
Average KL loss: 0.329617
Average total loss: 1.264334
tensor(-15.6454, device='cuda:0') tensor(0.1408, device='cuda:0') tensor(-1.3020e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.934801
Average KL loss: 0.329608
Average total loss: 1.264408
tensor(-15.6462, device='cuda:0') tensor(0.1409, device='cuda:0') tensor(-4.7762e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.934892
Average KL loss: 0.329611
Average total loss: 1.264503
tensor(-15.6470, device='cuda:0') tensor(0.1410, device='cuda:0') tensor(4.9626e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.936760
Average KL loss: 0.329587
Average total loss: 1.266347
tensor(-15.6477, device='cuda:0') tensor(0.1411, device='cuda:0') tensor(3.5439e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.934062
Average KL loss: 0.329554
Average total loss: 1.263615
tensor(-15.6485, device='cuda:0') tensor(0.1411, device='cuda:0') tensor(-9.6346e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 100
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 101
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 102
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 103
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 104
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 105
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 106
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 107
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 108
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 109
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 110
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 111
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 112
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 113
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 114
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 115
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 116
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 117
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 118
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 119
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 120
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 121
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 122
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 123
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 124
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 125
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 126
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 127
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 128
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 129
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 130
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 131
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 132
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 133
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 134
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 8.589949607849121%, Non-zero mask percentage: 8.589949607849121%

--- Pruning Level [11/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   24397 /  147456             ( 16.55%) | total_pruned =  123059 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   46375 /  147456             ( 31.45%) | total_pruned =  101081 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   83967 /  294912             ( 28.47%) | total_pruned =  210945 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   91384 /  589824             ( 15.49%) | total_pruned =  498440 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   18975 /   32768             ( 57.91%) | total_pruned =   13793 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   39689 /  589824             (  6.73%) | total_pruned =  550135 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     241 /     256             ( 94.14%) | total_pruned =      15 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   38764 /  589824             (  6.57%) | total_pruned =  551060 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   94846 / 1179648             (  8.04%) | total_pruned = 1084802 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  139211 / 2359296             (  5.90%) | total_pruned = 2220085 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   50140 /  131072             ( 38.25%) | total_pruned =   80932 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  132199 / 2359296             (  5.60%) | total_pruned = 2227097 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  187575 / 2359296             (  7.95%) | total_pruned = 2171721 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4873 /    5120             ( 95.18%) | total_pruned =     247 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 960250, pruned : 10218512, total: 11178762, Compression rate :      11.64x  ( 91.41% pruned)
Train Epoch: 34/100 Loss: 2.305768 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 6.871959686279297%, Non-zero mask percentage: 6.871959686279297%

--- Pruning Level [12/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   55095 /  589824             (  9.34%) | total_pruned =  534729 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   18975 /   32768             ( 57.91%) | total_pruned =   13793 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   39689 /  589824             (  6.73%) | total_pruned =  550135 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     241 /     256             ( 94.14%) | total_pruned =      15 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   38764 /  589824             (  6.57%) | total_pruned =  551060 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   94846 / 1179648             (  8.04%) | total_pruned = 1084802 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  139211 / 2359296             (  5.90%) | total_pruned = 2220085 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   50140 /  131072             ( 38.25%) | total_pruned =   80932 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  132199 / 2359296             (  5.60%) | total_pruned = 2227097 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  187575 / 2359296             (  7.95%) | total_pruned = 2171721 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4873 /    5120             ( 95.18%) | total_pruned =     247 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 768200, pruned : 10410562, total: 11178762, Compression rate :      14.55x  ( 93.13% pruned)
Train Epoch: 34/100 Loss: 2.303233 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 5.497567176818848%, Non-zero mask percentage: 5.497567176818848%

--- Pruning Level [13/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     402 /  589824             (  0.07%) | total_pruned =  589422 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   94846 / 1179648             (  8.04%) | total_pruned = 1084802 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  139211 / 2359296             (  5.90%) | total_pruned = 2220085 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   50140 /  131072             ( 38.25%) | total_pruned =   80932 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  132199 / 2359296             (  5.60%) | total_pruned = 2227097 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  187575 / 2359296             (  7.95%) | total_pruned = 2171721 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4873 /    5120             ( 95.18%) | total_pruned =     247 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 614560, pruned : 10564202, total: 11178762, Compression rate :      18.19x  ( 94.50% pruned)
Train Epoch: 67/100 Loss: 2.302696 Accuracy: 10.00 10.00 % Best test Accuracy: 10.03%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 4.398054122924805%, Non-zero mask percentage: 4.398054122924805%

--- Pruning Level [14/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  113083 / 2359296             (  4.79%) | total_pruned = 2246213 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   50140 /  131072             ( 38.25%) | total_pruned =   80932 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  132199 / 2359296             (  5.60%) | total_pruned = 2227097 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  187575 / 2359296             (  7.95%) | total_pruned = 2171721 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4873 /    5120             ( 95.18%) | total_pruned =     247 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 491648, pruned : 10687114, total: 11178762, Compression rate :      22.74x  ( 95.60% pruned)
Train Epoch: 34/100 Loss: 2.302296 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 3.5184483528137207%, Non-zero mask percentage: 3.5184483528137207%

--- Pruning Level [15/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   14754 / 2359296             (  0.63%) | total_pruned = 2344542 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   50140 /  131072             ( 38.25%) | total_pruned =   80932 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  132199 / 2359296             (  5.60%) | total_pruned = 2227097 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  187575 / 2359296             (  7.95%) | total_pruned = 2171721 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4873 /    5120             ( 95.18%) | total_pruned =     247 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 393319, pruned : 10785443, total: 11178762, Compression rate :      28.42x  ( 96.48% pruned)
Train Epoch: 34/100 Loss: 2.303094 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 2.8147659301757812%, Non-zero mask percentage: 2.8147659301757812%

--- Pruning Level [16/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  120478 / 2359296             (  5.11%) | total_pruned = 2238818 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  187575 / 2359296             (  7.95%) | total_pruned = 2171721 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4873 /    5120             ( 95.18%) | total_pruned =     247 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 314656, pruned : 10864106, total: 11178762, Compression rate :      35.53x  ( 97.19% pruned)
Train Epoch: 34/100 Loss: 2.302581 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 2.251814603805542%, Non-zero mask percentage: 2.251814603805542%

--- Pruning Level [17/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   57547 / 2359296             (  2.44%) | total_pruned = 2301749 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  187575 / 2359296             (  7.95%) | total_pruned = 2171721 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4873 /    5120             ( 95.18%) | total_pruned =     247 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 251725, pruned : 10927037, total: 11178762, Compression rate :      44.41x  ( 97.75% pruned)
Train Epoch: 34/100 Loss: 2.302584 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 1.8014516830444336%, Non-zero mask percentage: 1.8014516830444336%

--- Pruning Level [18/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    7202 / 2359296             (  0.31%) | total_pruned = 2352094 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  187575 / 2359296             (  7.95%) | total_pruned = 2171721 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4873 /    5120             ( 95.18%) | total_pruned =     247 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 201380, pruned : 10977382, total: 11178762, Compression rate :      55.51x  ( 98.20% pruned)
Train Epoch: 34/100 Loss: 2.302804 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 1.4411613941192627%, Non-zero mask percentage: 1.4411613941192627%

--- Pruning Level [19/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  155211 / 2359296             (  6.58%) | total_pruned = 2204085 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4873 /    5120             ( 95.18%) | total_pruned =     247 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 161104, pruned : 11017658, total: 11178762, Compression rate :      69.39x  ( 98.56% pruned)
Train Epoch: 34/100 Loss: 2.302657 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 1.1529362201690674%, Non-zero mask percentage: 1.1529362201690674%

--- Pruning Level [20/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  122991 / 2359296             (  5.21%) | total_pruned = 2236305 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4873 /    5120             ( 95.18%) | total_pruned =     247 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 128884, pruned : 11049878, total: 11178762, Compression rate :      86.74x  ( 98.85% pruned)
Train Epoch: 34/100 Loss: 2.302514 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.9223561882972717%, Non-zero mask percentage: 0.9223561882972717%

--- Pruning Level [21/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   97215 / 2359296             (  4.12%) | total_pruned = 2262081 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4873 /    5120             ( 95.18%) | total_pruned =     247 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 103108, pruned : 11075654, total: 11178762, Compression rate :     108.42x  ( 99.08% pruned)
Train Epoch: 34/100 Loss: 2.302460 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.7378903031349182%, Non-zero mask percentage: 0.7378903031349182%

--- Pruning Level [22/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   76594 / 2359296             (  3.25%) | total_pruned = 2282702 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4873 /    5120             ( 95.18%) | total_pruned =     247 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 82487, pruned : 11096275, total: 11178762, Compression rate :     135.52x  ( 99.26% pruned)
Train Epoch: 34/100 Loss: 2.302521 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 0.5903157591819763%, Non-zero mask percentage: 0.5903157591819763%

--- Pruning Level [23/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   60097 / 2359296             (  2.55%) | total_pruned = 2299199 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4873 /    5120             ( 95.18%) | total_pruned =     247 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 65990, pruned : 11112772, total: 11178762, Compression rate :     169.40x  ( 99.41% pruned)
Train Epoch: 34/100 Loss: 2.302750 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
