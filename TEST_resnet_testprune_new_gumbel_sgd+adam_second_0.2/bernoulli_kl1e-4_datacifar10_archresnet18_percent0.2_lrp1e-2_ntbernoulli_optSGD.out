Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/24]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2827e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302672
Average KL loss: 0.002684
Average total loss: 2.305356
tensor(2.6577e-05, device='cuda:0') tensor(4.0590e-06, device='cuda:0') tensor(2.5648e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.302747
Average KL loss: 0.002979
Average total loss: 2.305725
tensor(1.1998e-05, device='cuda:0') tensor(5.8761e-06, device='cuda:0') tensor(-3.2052e-12, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.301992
Average KL loss: 0.003515
Average total loss: 2.305508
tensor(2.8506e-05, device='cuda:0') tensor(1.2379e-05, device='cuda:0') tensor(-3.4651e-11, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.300801
Average KL loss: 0.004661
Average total loss: 2.305462
tensor(6.8023e-05, device='cuda:0') tensor(2.7850e-05, device='cuda:0') tensor(3.0066e-13, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.296340
Average KL loss: 0.008573
Average total loss: 2.304913
tensor(0.0002, device='cuda:0') tensor(7.7966e-05, device='cuda:0') tensor(-5.9129e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.242151
Average KL loss: 0.030764
Average total loss: 2.272915
tensor(0.0009, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.3138e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.904220
Average KL loss: 0.124509
Average total loss: 2.028728
tensor(0.0026, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-8.4956e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.381591
Average KL loss: 0.250861
Average total loss: 1.632452
tensor(0.0031, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.8293e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.031771
Average KL loss: 0.302618
Average total loss: 1.334389
tensor(0.0030, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.9341e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.881427
Average KL loss: 0.308868
Average total loss: 1.190295
tensor(0.0029, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-5.1496e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.798027
Average KL loss: 0.309036
Average total loss: 1.107063
tensor(0.0029, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.4536e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.754729
Average KL loss: 0.311400
Average total loss: 1.066129
tensor(0.0028, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.2742e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.695266
Average KL loss: 0.309724
Average total loss: 1.004990
tensor(0.0028, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.3761e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.644160
Average KL loss: 0.305798
Average total loss: 0.949959
tensor(0.0028, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-6.8511e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.616043
Average KL loss: 0.304813
Average total loss: 0.920857
tensor(0.0028, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.6214e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.595678
Average KL loss: 0.303582
Average total loss: 0.899260
tensor(0.0028, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.1181e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.571360
Average KL loss: 0.301201
Average total loss: 0.872560
tensor(0.0028, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.7522e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.553082
Average KL loss: 0.300057
Average total loss: 0.853139
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.0667e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.543076
Average KL loss: 0.299864
Average total loss: 0.842941
tensor(0.0028, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2289e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.520515
Average KL loss: 0.298806
Average total loss: 0.819322
tensor(0.0028, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2023e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.515513
Average KL loss: 0.299252
Average total loss: 0.814765
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.2000e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.499175
Average KL loss: 0.298311
Average total loss: 0.797486
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.2749e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.495127
Average KL loss: 0.301150
Average total loss: 0.796278
tensor(0.0028, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.7852e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.478750
Average KL loss: 0.299744
Average total loss: 0.778495
tensor(0.0028, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.5389e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.477695
Average KL loss: 0.299493
Average total loss: 0.777188
tensor(0.0028, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.4146e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.462231
Average KL loss: 0.298533
Average total loss: 0.760764
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.1999e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.455008
Average KL loss: 0.300123
Average total loss: 0.755131
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.1936e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.454331
Average KL loss: 0.299698
Average total loss: 0.754029
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.0792e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.430505
Average KL loss: 0.298222
Average total loss: 0.728727
tensor(0.0028, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.7253e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.441425
Average KL loss: 0.299654
Average total loss: 0.741079
tensor(0.0028, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2778e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.429539
Average KL loss: 0.299546
Average total loss: 0.729085
tensor(0.0028, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3964e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.421279
Average KL loss: 0.299815
Average total loss: 0.721094
tensor(0.0028, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.1763e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.418745
Average KL loss: 0.299948
Average total loss: 0.718693
tensor(0.0029, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.3651e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.417771
Average KL loss: 0.301744
Average total loss: 0.719515
tensor(0.0029, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.0321e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.408453
Average KL loss: 0.301415
Average total loss: 0.709869
tensor(0.0029, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2605e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.406461
Average KL loss: 0.302058
Average total loss: 0.708519
tensor(0.0029, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2266e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.400730
Average KL loss: 0.301606
Average total loss: 0.702336
tensor(0.0029, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-7.6823e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.397688
Average KL loss: 0.301894
Average total loss: 0.699583
tensor(0.0029, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.6183e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.390997
Average KL loss: 0.302276
Average total loss: 0.693273
tensor(0.0029, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.5471e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.396720
Average KL loss: 0.303744
Average total loss: 0.700464
tensor(0.0029, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.4151e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.384471
Average KL loss: 0.303673
Average total loss: 0.688143
tensor(0.0029, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-5.6547e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.383196
Average KL loss: 0.303071
Average total loss: 0.686267
tensor(0.0029, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.3213e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.378353
Average KL loss: 0.302777
Average total loss: 0.681130
tensor(0.0029, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.0410e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.382397
Average KL loss: 0.304443
Average total loss: 0.686840
tensor(0.0029, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.0742e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.372872
Average KL loss: 0.303917
Average total loss: 0.676789
tensor(0.0029, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.8271e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.368683
Average KL loss: 0.303230
Average total loss: 0.671913
tensor(0.0029, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.5151e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.373898
Average KL loss: 0.304088
Average total loss: 0.677987
tensor(0.0030, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.3642e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.366455
Average KL loss: 0.306385
Average total loss: 0.672841
tensor(0.0030, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.4247e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.369430
Average KL loss: 0.305466
Average total loss: 0.674896
tensor(0.0030, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.9913e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.355943
Average KL loss: 0.304933
Average total loss: 0.660876
tensor(0.0029, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.2284e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.361495
Average KL loss: 0.305657
Average total loss: 0.667152
tensor(0.0029, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-7.0756e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.359149
Average KL loss: 0.305430
Average total loss: 0.664579
tensor(0.0030, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.2929e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.357564
Average KL loss: 0.306753
Average total loss: 0.664317
tensor(0.0030, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-9.5667e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.352447
Average KL loss: 0.306648
Average total loss: 0.659095
tensor(0.0030, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.9713e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.348188
Average KL loss: 0.305937
Average total loss: 0.654125
tensor(0.0030, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-5.0642e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.350813
Average KL loss: 0.307290
Average total loss: 0.658103
tensor(0.0030, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-7.4972e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.348743
Average KL loss: 0.306650
Average total loss: 0.655393
tensor(0.0030, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.5554e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.344358
Average KL loss: 0.306008
Average total loss: 0.650366
tensor(0.0030, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.8567e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.344477
Average KL loss: 0.307396
Average total loss: 0.651873
tensor(0.0030, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.5832e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.347760
Average KL loss: 0.307994
Average total loss: 0.655754
tensor(0.0030, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.6681e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.339191
Average KL loss: 0.308534
Average total loss: 0.647725
tensor(0.0030, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.7072e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.341612
Average KL loss: 0.308409
Average total loss: 0.650021
tensor(0.0030, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-6.2547e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.339154
Average KL loss: 0.309087
Average total loss: 0.648240
tensor(0.0030, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.9382e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.334873
Average KL loss: 0.309406
Average total loss: 0.644279
tensor(0.0030, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.3912e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.334543
Average KL loss: 0.308697
Average total loss: 0.643240
tensor(0.0030, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-6.5834e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.334045
Average KL loss: 0.308845
Average total loss: 0.642890
tensor(0.0030, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(3.2238e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.328669
Average KL loss: 0.307674
Average total loss: 0.636343
tensor(0.0030, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-3.1677e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.330733
Average KL loss: 0.309187
Average total loss: 0.639920
tensor(0.0030, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.4925e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.330107
Average KL loss: 0.308965
Average total loss: 0.639072
tensor(0.0030, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.3198e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.332467
Average KL loss: 0.310391
Average total loss: 0.642858
tensor(0.0030, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1547e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.332513
Average KL loss: 0.311353
Average total loss: 0.643866
tensor(0.0030, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(4.7039e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.328166
Average KL loss: 0.311207
Average total loss: 0.639373
tensor(0.0030, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.4217e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.331470
Average KL loss: 0.311498
Average total loss: 0.642968
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.1813e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.325514
Average KL loss: 0.311096
Average total loss: 0.636609
tensor(0.0030, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.6673e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.322756
Average KL loss: 0.310572
Average total loss: 0.633328
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(9.3856e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.324293
Average KL loss: 0.310967
Average total loss: 0.635261
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.8980e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.322791
Average KL loss: 0.311973
Average total loss: 0.634764
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.0939e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.322608
Average KL loss: 0.311570
Average total loss: 0.634178
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.6271e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.322892
Average KL loss: 0.313285
Average total loss: 0.636178
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(6.9156e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.320143
Average KL loss: 0.313006
Average total loss: 0.633149
tensor(0.0031, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.8358e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.318661
Average KL loss: 0.313077
Average total loss: 0.631738
tensor(0.0031, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.2900e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.321448
Average KL loss: 0.313067
Average total loss: 0.634515
tensor(0.0031, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.8174e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.318586
Average KL loss: 0.313321
Average total loss: 0.631908
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-5.8857e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.318531
Average KL loss: 0.313399
Average total loss: 0.631930
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.5323e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.315570
Average KL loss: 0.313156
Average total loss: 0.628726
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-4.2423e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.318805
Average KL loss: 0.313512
Average total loss: 0.632317
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.7784e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.316196
Average KL loss: 0.314286
Average total loss: 0.630482
tensor(0.0031, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.3620e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.314958
Average KL loss: 0.313336
Average total loss: 0.628294
tensor(0.0031, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.9559e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.312144
Average KL loss: 0.313444
Average total loss: 0.625588
tensor(0.0031, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-5.9755e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.315220
Average KL loss: 0.313748
Average total loss: 0.628968
tensor(0.0031, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-4.7535e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.314807
Average KL loss: 0.314898
Average total loss: 0.629704
tensor(0.0031, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-6.9040e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.311816
Average KL loss: 0.314734
Average total loss: 0.626550
tensor(0.0031, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(4.5258e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.310645
Average KL loss: 0.314392
Average total loss: 0.625036
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.0594e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.311993
Average KL loss: 0.315058
Average total loss: 0.627051
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.6422e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.311613
Average KL loss: 0.315098
Average total loss: 0.626711
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.9490e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.309061
Average KL loss: 0.314885
Average total loss: 0.623946
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.3461e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.310720
Average KL loss: 0.315092
Average total loss: 0.625812
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(2.1839e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.310587
Average KL loss: 0.315305
Average total loss: 0.625891
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-4.7079e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.307078
Average KL loss: 0.314877
Average total loss: 0.621956
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.1982e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.310115
Average KL loss: 0.315148
Average total loss: 0.625263
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-9.0616e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.306154
Average KL loss: 0.314411
Average total loss: 0.620566
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(1.6405e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.308740
Average KL loss: 0.315252
Average total loss: 0.623992
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.1401e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.305619
Average KL loss: 0.315246
Average total loss: 0.620865
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.0127e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.310232
Average KL loss: 0.316691
Average total loss: 0.626922
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.4810e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.301800
Average KL loss: 0.316424
Average total loss: 0.618224
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.3429e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.303254
Average KL loss: 0.315679
Average total loss: 0.618933
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(8.2033e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.303851
Average KL loss: 0.315579
Average total loss: 0.619431
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.8590e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.306397
Average KL loss: 0.316086
Average total loss: 0.622483
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(2.6833e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.304565
Average KL loss: 0.317610
Average total loss: 0.622175
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.0165e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.303958
Average KL loss: 0.317102
Average total loss: 0.621061
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.3028e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.302356
Average KL loss: 0.316738
Average total loss: 0.619093
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.0874e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.301272
Average KL loss: 0.317020
Average total loss: 0.618293
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.5851e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.302122
Average KL loss: 0.316443
Average total loss: 0.618565
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(5.9515e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.302712
Average KL loss: 0.317099
Average total loss: 0.619811
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(6.5320e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.301318
Average KL loss: 0.317207
Average total loss: 0.618525
tensor(0.0032, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(3.9346e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.303331
Average KL loss: 0.317486
Average total loss: 0.620817
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.2038e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.302171
Average KL loss: 0.311490
Average total loss: 0.613661
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.3115e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.297085
Average KL loss: 0.303492
Average total loss: 0.600577
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.1054e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.296952
Average KL loss: 0.299613
Average total loss: 0.596565
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.3049e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.296429
Average KL loss: 0.297289
Average total loss: 0.593718
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(4.3097e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.303861
Average KL loss: 0.295690
Average total loss: 0.599551
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.7434e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.299297
Average KL loss: 0.294589
Average total loss: 0.593885
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(5.5730e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.299572
Average KL loss: 0.293731
Average total loss: 0.593302
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.6080e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.297962
Average KL loss: 0.293067
Average total loss: 0.591029
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.9358e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.300435
Average KL loss: 0.292598
Average total loss: 0.593033
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-8.4561e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.300297
Average KL loss: 0.292253
Average total loss: 0.592550
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.4206e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.303111
Average KL loss: 0.291910
Average total loss: 0.595021
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.1833e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.300009
Average KL loss: 0.291737
Average total loss: 0.591746
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.0906e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.298371
Average KL loss: 0.291403
Average total loss: 0.589775
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-5.0561e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.300339
Average KL loss: 0.291098
Average total loss: 0.591437
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(6.0543e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.301461
Average KL loss: 0.290967
Average total loss: 0.592428
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(6.0308e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.301101
Average KL loss: 0.290740
Average total loss: 0.591840
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(8.6308e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.299242
Average KL loss: 0.290556
Average total loss: 0.589798
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.5625e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.299013
Average KL loss: 0.290444
Average total loss: 0.589457
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.0136e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.299418
Average KL loss: 0.290282
Average total loss: 0.589700
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.3191e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.299462
Average KL loss: 0.290224
Average total loss: 0.589685
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.0240e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.300726
Average KL loss: 0.290216
Average total loss: 0.590942
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.9843e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.297846
Average KL loss: 0.290020
Average total loss: 0.587866
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.2266e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.298812
Average KL loss: 0.289880
Average total loss: 0.588692
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(2.3254e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.295722
Average KL loss: 0.289853
Average total loss: 0.585575
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.3492e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.300447
Average KL loss: 0.289835
Average total loss: 0.590281
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(5.2945e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.298634
Average KL loss: 0.289771
Average total loss: 0.588405
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.8410e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.299482
Average KL loss: 0.289720
Average total loss: 0.589202
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.5690e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.298981
Average KL loss: 0.289695
Average total loss: 0.588676
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(3.3160e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.298836
Average KL loss: 0.289661
Average total loss: 0.588497
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.4229e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.298603
Average KL loss: 0.289579
Average total loss: 0.588182
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.6243e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.299793
Average KL loss: 0.289523
Average total loss: 0.589316
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.6452e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.297734
Average KL loss: 0.289438
Average total loss: 0.587171
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.9939e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.295528
Average KL loss: 0.289406
Average total loss: 0.584934
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.8764e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.297291
Average KL loss: 0.289461
Average total loss: 0.586752
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.3630e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.298736
Average KL loss: 0.289337
Average total loss: 0.588074
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.4711e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.298988
Average KL loss: 0.289242
Average total loss: 0.588230
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.0883e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.298516
Average KL loss: 0.289197
Average total loss: 0.587714
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.1816e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.299162
Average KL loss: 0.289323
Average total loss: 0.588485
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.6868e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.296932
Average KL loss: 0.289342
Average total loss: 0.586274
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.7322e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.294781
Average KL loss: 0.289319
Average total loss: 0.584101
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.0525e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.295517
Average KL loss: 0.289128
Average total loss: 0.584645
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0918e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.298547
Average KL loss: 0.289096
Average total loss: 0.587642
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(4.0567e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.301097
Average KL loss: 0.289173
Average total loss: 0.590269
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.3429e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.297061
Average KL loss: 0.289244
Average total loss: 0.586305
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.3445e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.295213
Average KL loss: 0.289223
Average total loss: 0.584436
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.4253e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.293798
Average KL loss: 0.289093
Average total loss: 0.582891
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.3094e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.295295
Average KL loss: 0.288935
Average total loss: 0.584230
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.0817e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.298816
Average KL loss: 0.288934
Average total loss: 0.587750
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.0890e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.299009
Average KL loss: 0.289056
Average total loss: 0.588065
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.7580e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.299208
Average KL loss: 0.289138
Average total loss: 0.588346
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.7396e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.298439
Average KL loss: 0.289153
Average total loss: 0.587592
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.2199e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.294563
Average KL loss: 0.289111
Average total loss: 0.583674
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.1560e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.302569
Average KL loss: 0.289086
Average total loss: 0.591656
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0593e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.297357
Average KL loss: 0.289210
Average total loss: 0.586567
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.3717e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.296936
Average KL loss: 0.289177
Average total loss: 0.586114
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.8442e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.300125
Average KL loss: 0.289271
Average total loss: 0.589396
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.0999e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.299169
Average KL loss: 0.289313
Average total loss: 0.588482
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.2752e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.292199
Average KL loss: 0.289241
Average total loss: 0.581441
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.8882e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.298745
Average KL loss: 0.288986
Average total loss: 0.587731
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.0302e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.298329
Average KL loss: 0.288815
Average total loss: 0.587143
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.3348e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.295989
Average KL loss: 0.288666
Average total loss: 0.584655
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.4154e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.297100
Average KL loss: 0.288538
Average total loss: 0.585638
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.6435e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.296065
Average KL loss: 0.288427
Average total loss: 0.584491
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.3132e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.300114
Average KL loss: 0.288328
Average total loss: 0.588443
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.3388e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.296444
Average KL loss: 0.288237
Average total loss: 0.584681
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.5738e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.297537
Average KL loss: 0.288149
Average total loss: 0.585686
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5993e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.296707
Average KL loss: 0.288081
Average total loss: 0.584787
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.2960e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.298621
Average KL loss: 0.288018
Average total loss: 0.586639
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.3165e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.298793
Average KL loss: 0.287961
Average total loss: 0.586754
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.6959e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.298290
Average KL loss: 0.287925
Average total loss: 0.586215
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.3860e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.298897
Average KL loss: 0.287915
Average total loss: 0.586812
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.3096e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.297919
Average KL loss: 0.287906
Average total loss: 0.585825
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.1511e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.296225
Average KL loss: 0.287897
Average total loss: 0.584122
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.0544e-12, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.298449
Average KL loss: 0.287887
Average total loss: 0.586336
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.2273e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.297753
Average KL loss: 0.287879
Average total loss: 0.585631
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.9166e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.297042
Average KL loss: 0.287870
Average total loss: 0.584912
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5891e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.296852
Average KL loss: 0.287861
Average total loss: 0.584713
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.1500e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.295027
Average KL loss: 0.287853
Average total loss: 0.582880
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.5896e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.294179
Average KL loss: 0.287845
Average total loss: 0.582024
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.4734e-09, device='cuda:0')
 Percentile value: -9.275619049731173e-07
Non-zero model percentage: 80.0%, Non-zero mask percentage: 80.0%

--- Pruning Level [1/24]: ---
conv1.weight         | nonzeros =    1604 /    1728             ( 92.82%) | total_pruned =     124 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   33391 /   36864             ( 90.58%) | total_pruned =    3473 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   29533 /   36864             ( 80.11%) | total_pruned =    7331 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   27233 /   36864             ( 73.87%) | total_pruned =    9631 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   28057 /   36864             ( 76.11%) | total_pruned =    8807 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   46961 /   73728             ( 63.69%) | total_pruned =   26767 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   91470 /  147456             ( 62.03%) | total_pruned =   55986 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5670 /    8192             ( 69.21%) | total_pruned =    2522 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  102478 /  147456             ( 69.50%) | total_pruned =   44978 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  110778 /  147456             ( 75.13%) | total_pruned =   36678 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  171849 /  294912             ( 58.27%) | total_pruned =  123063 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  350548 /  589824             ( 59.43%) | total_pruned =  239276 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   21462 /   32768             ( 65.50%) | total_pruned =   11306 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      77 /     256             ( 30.08%) | total_pruned =     179 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  383373 /  589824             ( 65.00%) | total_pruned =  206451 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  434089 /  589824             ( 73.60%) | total_pruned =  155735 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  768122 / 1179648             ( 65.11%) | total_pruned =  411526 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     119 /     512             ( 23.24%) | total_pruned =     393 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1929922 / 2359296             ( 81.80%) | total_pruned =  429374 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     482 /     512             ( 94.14%) | total_pruned =      30 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     283 /     512             ( 55.27%) | total_pruned =     229 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  113304 /  131072             ( 86.44%) | total_pruned =   17768 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     501 /     512             ( 97.85%) | total_pruned =      11 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     278 /     512             ( 54.30%) | total_pruned =     234 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1944423 / 2359296             ( 82.42%) | total_pruned =  414873 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2331995 / 2359296             ( 98.84%) | total_pruned =   27301 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5097 /    5120             ( 99.55%) | total_pruned =      23 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 8943010, pruned : 2235752, total: 11178762, Compression rate :       1.25x  ( 20.00% pruned)
Train Epoch: 51/100 Loss: 0.016748 Accuracy: 88.77 100.00 % Best test Accuracy: 89.08%
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5426e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.892634
Average KL loss: 0.314635
Average total loss: 1.207269
tensor(0.0038, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-3.9192e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.708914
Average KL loss: 0.342563
Average total loss: 1.051477
tensor(0.0039, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.1266e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.630375
Average KL loss: 0.345794
Average total loss: 0.976169
tensor(0.0038, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.0803e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.596361
Average KL loss: 0.345095
Average total loss: 0.941456
tensor(0.0038, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.2721e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.565835
Average KL loss: 0.341222
Average total loss: 0.907057
tensor(0.0037, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.8782e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.549332
Average KL loss: 0.338309
Average total loss: 0.887641
tensor(0.0037, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.7461e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.531850
Average KL loss: 0.336661
Average total loss: 0.868512
tensor(0.0037, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.3835e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.505976
Average KL loss: 0.335523
Average total loss: 0.841499
tensor(0.0037, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.1996e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.499471
Average KL loss: 0.334314
Average total loss: 0.833785
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.9544e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.495432
Average KL loss: 0.333571
Average total loss: 0.829002
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-4.0951e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.476032
Average KL loss: 0.333785
Average total loss: 0.809817
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.3253e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.467087
Average KL loss: 0.332420
Average total loss: 0.799507
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.2189e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.466419
Average KL loss: 0.331546
Average total loss: 0.797965
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.1492e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.452314
Average KL loss: 0.330975
Average total loss: 0.783289
tensor(0.0036, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.0432e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.456270
Average KL loss: 0.331209
Average total loss: 0.787479
tensor(0.0036, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.0976e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.447026
Average KL loss: 0.331598
Average total loss: 0.778624
tensor(0.0036, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.2306e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.438905
Average KL loss: 0.332147
Average total loss: 0.771052
tensor(0.0035, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.2249e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.432181
Average KL loss: 0.330148
Average total loss: 0.762329
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.3317e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.431985
Average KL loss: 0.330675
Average total loss: 0.762660
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.2699e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.422002
Average KL loss: 0.330451
Average total loss: 0.752453
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-3.7267e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.427577
Average KL loss: 0.330883
Average total loss: 0.758459
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-4.3946e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.417796
Average KL loss: 0.329993
Average total loss: 0.747789
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-9.2700e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.418898
Average KL loss: 0.330835
Average total loss: 0.749733
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.9842e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.412953
Average KL loss: 0.330889
Average total loss: 0.743842
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-7.1162e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.416519
Average KL loss: 0.331110
Average total loss: 0.747629
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.2335e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.408320
Average KL loss: 0.332257
Average total loss: 0.740578
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.7439e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.399781
Average KL loss: 0.330585
Average total loss: 0.730366
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-5.1441e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.398070
Average KL loss: 0.330741
Average total loss: 0.728812
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(7.4131e-11, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.395894
Average KL loss: 0.329899
Average total loss: 0.725793
tensor(0.0035, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-2.0777e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.390554
Average KL loss: 0.331153
Average total loss: 0.721707
tensor(0.0035, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.7639e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.389574
Average KL loss: 0.330964
Average total loss: 0.720538
tensor(0.0035, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.4769e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.391851
Average KL loss: 0.330820
Average total loss: 0.722672
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-7.2534e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.385175
Average KL loss: 0.330918
Average total loss: 0.716093
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.4220e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.384591
Average KL loss: 0.330269
Average total loss: 0.714859
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.1904e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.386785
Average KL loss: 0.331624
Average total loss: 0.718409
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.3296e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.383396
Average KL loss: 0.331091
Average total loss: 0.714488
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(1.2599e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.381206
Average KL loss: 0.330684
Average total loss: 0.711890
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-5.7222e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.374407
Average KL loss: 0.331044
Average total loss: 0.705451
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.0367e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.374710
Average KL loss: 0.331029
Average total loss: 0.705739
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.1544e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.363529
Average KL loss: 0.329637
Average total loss: 0.693166
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.4083e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.373555
Average KL loss: 0.329776
Average total loss: 0.703331
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.7071e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.371041
Average KL loss: 0.331223
Average total loss: 0.702263
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-7.6447e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.370520
Average KL loss: 0.331022
Average total loss: 0.701542
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.3683e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.360652
Average KL loss: 0.330974
Average total loss: 0.691626
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.2667e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.361573
Average KL loss: 0.330765
Average total loss: 0.692338
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.3229e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.362022
Average KL loss: 0.330542
Average total loss: 0.692564
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(4.6287e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.363708
Average KL loss: 0.330922
Average total loss: 0.694630
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.6124e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.357475
Average KL loss: 0.330651
Average total loss: 0.688125
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(4.7876e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.366065
Average KL loss: 0.330480
Average total loss: 0.696545
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(4.8592e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.367647
Average KL loss: 0.332355
Average total loss: 0.700001
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(1.7803e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.355623
Average KL loss: 0.333088
Average total loss: 0.688712
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.0417e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.358457
Average KL loss: 0.332017
Average total loss: 0.690474
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.2360e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.352272
Average KL loss: 0.332516
Average total loss: 0.684788
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.9201e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.356772
Average KL loss: 0.332206
Average total loss: 0.688978
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.2144e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.354966
Average KL loss: 0.332267
Average total loss: 0.687233
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.5014e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.354220
Average KL loss: 0.332745
Average total loss: 0.686965
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.5651e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.351657
Average KL loss: 0.331990
Average total loss: 0.683648
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(5.4931e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.348955
Average KL loss: 0.331774
Average total loss: 0.680729
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.6898e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.352218
Average KL loss: 0.333040
Average total loss: 0.685258
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(1.0236e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.350193
Average KL loss: 0.331760
Average total loss: 0.681953
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.9883e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.346513
Average KL loss: 0.332913
Average total loss: 0.679425
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-9.6636e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.342498
Average KL loss: 0.331894
Average total loss: 0.674392
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(2.7690e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.344568
Average KL loss: 0.332099
Average total loss: 0.676667
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.9519e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.350618
Average KL loss: 0.332977
Average total loss: 0.683595
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.1457e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.346341
Average KL loss: 0.334115
Average total loss: 0.680456
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.7666e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.344078
Average KL loss: 0.333601
Average total loss: 0.677679
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.7288e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.342088
Average KL loss: 0.333271
Average total loss: 0.675359
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.9577e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.340266
Average KL loss: 0.333153
Average total loss: 0.673419
tensor(0.0036, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.8141e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.337694
Average KL loss: 0.333550
Average total loss: 0.671244
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(2.4959e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.345290
Average KL loss: 0.332353
Average total loss: 0.677643
tensor(0.0036, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.9380e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.341725
Average KL loss: 0.334258
Average total loss: 0.675983
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(1.8456e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.339693
Average KL loss: 0.334493
Average total loss: 0.674187
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.8670e-11, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.345545
Average KL loss: 0.333998
Average total loss: 0.679543
tensor(0.0036, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.0738e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.340846
Average KL loss: 0.334962
Average total loss: 0.675808
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.6758e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.339598
Average KL loss: 0.334734
Average total loss: 0.674332
tensor(0.0036, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(2.4225e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.341848
Average KL loss: 0.335354
Average total loss: 0.677202
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(1.4507e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.334453
Average KL loss: 0.335263
Average total loss: 0.669716
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.2140e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.335379
Average KL loss: 0.335478
Average total loss: 0.670857
tensor(0.0036, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.0916e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.330935
Average KL loss: 0.335424
Average total loss: 0.666359
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.7479e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.334729
Average KL loss: 0.334497
Average total loss: 0.669226
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(5.1204e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.331517
Average KL loss: 0.334022
Average total loss: 0.665539
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-8.2457e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.330446
Average KL loss: 0.333948
Average total loss: 0.664394
tensor(0.0036, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(4.0601e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.332428
Average KL loss: 0.334572
Average total loss: 0.667000
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(9.3597e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.332530
Average KL loss: 0.334608
Average total loss: 0.667138
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(2.7379e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.331746
Average KL loss: 0.334880
Average total loss: 0.666626
tensor(0.0036, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.1886e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.334150
Average KL loss: 0.335115
Average total loss: 0.669264
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.8476e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.327727
Average KL loss: 0.335967
Average total loss: 0.663694
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(2.1051e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.326407
Average KL loss: 0.334823
Average total loss: 0.661230
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.1891e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.331257
Average KL loss: 0.334299
Average total loss: 0.665556
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(4.3871e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.329723
Average KL loss: 0.335275
Average total loss: 0.664998
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(4.9484e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.329933
Average KL loss: 0.336068
Average total loss: 0.666001
tensor(0.0036, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.7366e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.329240
Average KL loss: 0.336709
Average total loss: 0.665949
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.5301e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.329363
Average KL loss: 0.336434
Average total loss: 0.665797
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.6324e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.330940
Average KL loss: 0.336698
Average total loss: 0.667638
tensor(0.0036, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9077e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.330090
Average KL loss: 0.336128
Average total loss: 0.666217
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(4.0787e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.324420
Average KL loss: 0.335470
Average total loss: 0.659890
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.0807e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.325760
Average KL loss: 0.334892
Average total loss: 0.660652
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(6.5881e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.329509
Average KL loss: 0.335336
Average total loss: 0.664845
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.5244e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.327806
Average KL loss: 0.336282
Average total loss: 0.664088
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.2033e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.327138
Average KL loss: 0.336734
Average total loss: 0.663872
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.0815e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.326069
Average KL loss: 0.336279
Average total loss: 0.662348
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.3587e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.321999
Average KL loss: 0.335771
Average total loss: 0.657770
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.5253e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.326157
Average KL loss: 0.336118
Average total loss: 0.662276
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.8186e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.322730
Average KL loss: 0.335769
Average total loss: 0.658499
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.8650e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.321153
Average KL loss: 0.335533
Average total loss: 0.656686
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.6502e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.323163
Average KL loss: 0.335894
Average total loss: 0.659057
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.6211e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.322662
Average KL loss: 0.336218
Average total loss: 0.658880
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.1534e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.327172
Average KL loss: 0.335925
Average total loss: 0.663098
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.0195e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.325384
Average KL loss: 0.336933
Average total loss: 0.662317
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(3.4906e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.321112
Average KL loss: 0.335473
Average total loss: 0.656585
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.5247e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.322780
Average KL loss: 0.336747
Average total loss: 0.659527
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.1757e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.319426
Average KL loss: 0.336813
Average total loss: 0.656239
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.6012e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.321218
Average KL loss: 0.336170
Average total loss: 0.657387
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.7579e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.322716
Average KL loss: 0.336895
Average total loss: 0.659611
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.7361e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.321813
Average KL loss: 0.336617
Average total loss: 0.658430
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.5732e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.320085
Average KL loss: 0.336588
Average total loss: 0.656673
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-9.2762e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.319563
Average KL loss: 0.336642
Average total loss: 0.656205
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(4.6047e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.321738
Average KL loss: 0.336882
Average total loss: 0.658620
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(4.7279e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.320061
Average KL loss: 0.337424
Average total loss: 0.657485
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-9.1422e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.319930
Average KL loss: 0.337651
Average total loss: 0.657581
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.2116e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.320458
Average KL loss: 0.337202
Average total loss: 0.657659
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.0603e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.317355
Average KL loss: 0.337362
Average total loss: 0.654716
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.4815e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.315817
Average KL loss: 0.336481
Average total loss: 0.652297
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.0139e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.315601
Average KL loss: 0.336880
Average total loss: 0.652480
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.3888e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.317276
Average KL loss: 0.336683
Average total loss: 0.653959
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.2809e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.317987
Average KL loss: 0.336696
Average total loss: 0.654683
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.4237e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.319615
Average KL loss: 0.337892
Average total loss: 0.657506
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.7624e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.318750
Average KL loss: 0.337191
Average total loss: 0.655941
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(6.1505e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.310408
Average KL loss: 0.337499
Average total loss: 0.647907
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.2967e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.320334
Average KL loss: 0.336922
Average total loss: 0.657256
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.5612e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.315763
Average KL loss: 0.337759
Average total loss: 0.653522
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.7561e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.316754
Average KL loss: 0.337180
Average total loss: 0.653934
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.2466e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.316577
Average KL loss: 0.337147
Average total loss: 0.653724
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(3.8393e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.312404
Average KL loss: 0.337443
Average total loss: 0.649847
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.8868e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.314948
Average KL loss: 0.336929
Average total loss: 0.651878
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.1658e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.316703
Average KL loss: 0.336816
Average total loss: 0.653520
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.6697e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.319925
Average KL loss: 0.337795
Average total loss: 0.657720
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.2677e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.314709
Average KL loss: 0.337541
Average total loss: 0.652250
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.0461e-11, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.314415
Average KL loss: 0.337880
Average total loss: 0.652295
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.7654e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.314315
Average KL loss: 0.337308
Average total loss: 0.651623
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.8064e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.314126
Average KL loss: 0.333623
Average total loss: 0.647749
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(5.8226e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.312363
Average KL loss: 0.327942
Average total loss: 0.640306
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.8787e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.315878
Average KL loss: 0.324663
Average total loss: 0.640540
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.6799e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.312575
Average KL loss: 0.322359
Average total loss: 0.634934
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.0409e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.313695
Average KL loss: 0.320747
Average total loss: 0.634442
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.0707e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.309449
Average KL loss: 0.319319
Average total loss: 0.628767
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.2303e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.310263
Average KL loss: 0.318024
Average total loss: 0.628287
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.3387e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.310392
Average KL loss: 0.317043
Average total loss: 0.627435
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.9491e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.310982
Average KL loss: 0.316160
Average total loss: 0.627142
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.2564e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.309960
Average KL loss: 0.315441
Average total loss: 0.625401
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.4360e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.315507
Average KL loss: 0.314856
Average total loss: 0.630363
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-7.6067e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.310534
Average KL loss: 0.314418
Average total loss: 0.624951
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(8.5744e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.312664
Average KL loss: 0.314037
Average total loss: 0.626701
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.4783e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.308570
Average KL loss: 0.313648
Average total loss: 0.622218
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.2163e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.309501
Average KL loss: 0.313247
Average total loss: 0.622748
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.3668e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.312780
Average KL loss: 0.312899
Average total loss: 0.625679
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.2414e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.311341
Average KL loss: 0.312682
Average total loss: 0.624022
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.0031e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.312284
Average KL loss: 0.312456
Average total loss: 0.624740
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.6086e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.312475
Average KL loss: 0.312203
Average total loss: 0.624678
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.7287e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.308129
Average KL loss: 0.311930
Average total loss: 0.620059
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.8315e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.313613
Average KL loss: 0.311664
Average total loss: 0.625277
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.0395e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.314341
Average KL loss: 0.311425
Average total loss: 0.625767
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(3.5500e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.310522
Average KL loss: 0.311268
Average total loss: 0.621790
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.7742e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.315992
Average KL loss: 0.311045
Average total loss: 0.627037
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(3.0297e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.315080
Average KL loss: 0.310980
Average total loss: 0.626061
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.4157e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.309974
Average KL loss: 0.310921
Average total loss: 0.620895
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.0054e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.309124
Average KL loss: 0.310790
Average total loss: 0.619914
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.6355e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.311111
Average KL loss: 0.310645
Average total loss: 0.621756
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.7382e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.312040
Average KL loss: 0.310577
Average total loss: 0.622617
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(6.3788e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.312757
Average KL loss: 0.310426
Average total loss: 0.623183
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.2749e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.314010
Average KL loss: 0.310299
Average total loss: 0.624308
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.6166e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.313128
Average KL loss: 0.310263
Average total loss: 0.623391
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.6942e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.310925
Average KL loss: 0.310229
Average total loss: 0.621153
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.4975e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.313997
Average KL loss: 0.310177
Average total loss: 0.624174
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(9.2473e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.313956
Average KL loss: 0.310213
Average total loss: 0.624169
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-7.6914e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.312120
Average KL loss: 0.310300
Average total loss: 0.622420
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.1920e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.313756
Average KL loss: 0.310218
Average total loss: 0.623974
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.6141e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.310857
Average KL loss: 0.310041
Average total loss: 0.620898
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.3392e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.310830
Average KL loss: 0.309917
Average total loss: 0.620747
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.0653e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.308533
Average KL loss: 0.309771
Average total loss: 0.618304
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.7139e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.309270
Average KL loss: 0.309654
Average total loss: 0.618924
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(5.6039e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.313813
Average KL loss: 0.309550
Average total loss: 0.623363
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.3966e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.310327
Average KL loss: 0.309456
Average total loss: 0.619783
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.1675e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.309083
Average KL loss: 0.309362
Average total loss: 0.618444
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.8651e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.312834
Average KL loss: 0.309281
Average total loss: 0.622115
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.2780e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.310382
Average KL loss: 0.309204
Average total loss: 0.619586
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.0314e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.313426
Average KL loss: 0.309134
Average total loss: 0.622560
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.8317e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.312771
Average KL loss: 0.309081
Average total loss: 0.621851
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.4088e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.310266
Average KL loss: 0.309039
Average total loss: 0.619305
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(6.3862e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.312196
Average KL loss: 0.308983
Average total loss: 0.621179
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.1155e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.311078
Average KL loss: 0.308934
Average total loss: 0.620012
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-9.0931e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.312965
Average KL loss: 0.308903
Average total loss: 0.621868
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.1634e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.312397
Average KL loss: 0.308897
Average total loss: 0.621293
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.1522e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.314410
Average KL loss: 0.308891
Average total loss: 0.623300
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.3381e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.309239
Average KL loss: 0.308884
Average total loss: 0.618124
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.8527e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.311048
Average KL loss: 0.308878
Average total loss: 0.619926
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.6066e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.311273
Average KL loss: 0.308871
Average total loss: 0.620143
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.8175e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.309270
Average KL loss: 0.308863
Average total loss: 0.618133
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.0154e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.311934
Average KL loss: 0.308856
Average total loss: 0.620789
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.3988e-11, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.308444
Average KL loss: 0.308850
Average total loss: 0.617293
 Percentile value: 8.015941261874105e-08
Non-zero model percentage: 64.0%, Non-zero mask percentage: 64.0%

--- Pruning Level [2/24]: ---
conv1.weight         | nonzeros =    1565 /    1728             ( 90.57%) | total_pruned =     163 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   32468 /   36864             ( 88.08%) | total_pruned =    4396 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   27055 /   36864             ( 73.39%) | total_pruned =    9809 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   23123 /   36864             ( 62.73%) | total_pruned =   13741 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   23193 /   36864             ( 62.92%) | total_pruned =   13671 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   31867 /   73728             ( 43.22%) | total_pruned =   41861 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   60566 /  147456             ( 41.07%) | total_pruned =   86890 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4183 /    8192             ( 51.06%) | total_pruned =    4009 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   77102 /  147456             ( 52.29%) | total_pruned =   70354 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   87786 /  147456             ( 59.53%) | total_pruned =   59670 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  111713 /  294912             ( 37.88%) | total_pruned =  183199 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      90 /     256             ( 35.16%) | total_pruned =     166 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  231861 /  589824             ( 39.31%) | total_pruned =  357963 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   15042 /   32768             ( 45.90%) | total_pruned =   17726 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     238 /     256             ( 92.97%) | total_pruned =      18 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      52 /     256             ( 20.31%) | total_pruned =     204 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  265752 /  589824             ( 45.06%) | total_pruned =  324072 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  325164 /  589824             ( 55.13%) | total_pruned =  264660 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  491386 / 1179648             ( 41.66%) | total_pruned =  688262 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     100 /     512             ( 19.53%) | total_pruned =     412 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1421879 / 2359296             ( 60.27%) | total_pruned =  937417 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     469 /     512             ( 91.60%) | total_pruned =      43 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     138 /     512             ( 26.95%) | total_pruned =     374 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   87928 /  131072             ( 67.08%) | total_pruned =   43144 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     471 /     512             ( 91.99%) | total_pruned =      41 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     142 /     512             ( 27.73%) | total_pruned =     370 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1621371 / 2359296             ( 68.72%) | total_pruned =  737925 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2197353 / 2359296             ( 93.14%) | total_pruned =  161943 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5082 /    5120             ( 99.26%) | total_pruned =      38 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 7154408, pruned : 4024354, total: 11178762, Compression rate :       1.56x  ( 36.00% pruned)
Train Epoch: 57/100 Loss: 0.015541 Accuracy: 88.53 100.00 % Best test Accuracy: 88.74%
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.3174e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.817340
Average KL loss: 0.314684
Average total loss: 1.132024
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.3647e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.634664
Average KL loss: 0.336335
Average total loss: 0.970999
tensor(0.0036, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.5865e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.572399
Average KL loss: 0.339704
Average total loss: 0.912103
tensor(0.0036, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.8211e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.548934
Average KL loss: 0.339808
Average total loss: 0.888742
tensor(0.0036, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.7856e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.514576
Average KL loss: 0.338682
Average total loss: 0.853258
tensor(0.0036, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.0796e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.496711
Average KL loss: 0.336834
Average total loss: 0.833545
tensor(0.0036, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.6859e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.487578
Average KL loss: 0.334828
Average total loss: 0.822406
tensor(0.0036, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.7336e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.469601
Average KL loss: 0.334341
Average total loss: 0.803942
tensor(0.0036, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.2854e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.462719
Average KL loss: 0.335124
Average total loss: 0.797843
tensor(0.0036, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-8.3663e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.455008
Average KL loss: 0.335437
Average total loss: 0.790445
tensor(0.0036, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-5.8633e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.443444
Average KL loss: 0.334189
Average total loss: 0.777633
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-8.7910e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.440187
Average KL loss: 0.335009
Average total loss: 0.775195
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.1940e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.432329
Average KL loss: 0.335367
Average total loss: 0.767696
tensor(0.0036, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.3941e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.422980
Average KL loss: 0.335170
Average total loss: 0.758149
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.0658e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.417033
Average KL loss: 0.334193
Average total loss: 0.751226
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.6565e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.421003
Average KL loss: 0.335095
Average total loss: 0.756098
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.0660e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.407790
Average KL loss: 0.334663
Average total loss: 0.742453
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.4112e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.407532
Average KL loss: 0.334600
Average total loss: 0.742133
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.9321e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.405535
Average KL loss: 0.334245
Average total loss: 0.739780
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0102e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.397796
Average KL loss: 0.334456
Average total loss: 0.732252
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.6827e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.393943
Average KL loss: 0.333568
Average total loss: 0.727511
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.2392e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.391256
Average KL loss: 0.333520
Average total loss: 0.724776
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.4269e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.389513
Average KL loss: 0.333795
Average total loss: 0.723309
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0290e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.393343
Average KL loss: 0.333886
Average total loss: 0.727229
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.1627e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.388240
Average KL loss: 0.334986
Average total loss: 0.723226
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.4899e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.385543
Average KL loss: 0.333936
Average total loss: 0.719479
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.7372e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.386342
Average KL loss: 0.334825
Average total loss: 0.721168
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.0335e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.378889
Average KL loss: 0.334454
Average total loss: 0.713343
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(3.8323e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.380380
Average KL loss: 0.334945
Average total loss: 0.715325
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.9939e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.377315
Average KL loss: 0.334640
Average total loss: 0.711955
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.1984e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.373305
Average KL loss: 0.334133
Average total loss: 0.707437
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(2.1240e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.375210
Average KL loss: 0.334862
Average total loss: 0.710072
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.7437e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.376141
Average KL loss: 0.335336
Average total loss: 0.711477
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.3046e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.371784
Average KL loss: 0.334863
Average total loss: 0.706647
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.7696e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.366959
Average KL loss: 0.335078
Average total loss: 0.702037
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.0116e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.365545
Average KL loss: 0.334458
Average total loss: 0.700002
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.5871e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.365497
Average KL loss: 0.334695
Average total loss: 0.700192
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.5736e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.364834
Average KL loss: 0.334722
Average total loss: 0.699556
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.2823e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.362899
Average KL loss: 0.334820
Average total loss: 0.697718
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.2510e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.356320
Average KL loss: 0.335064
Average total loss: 0.691384
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.5939e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.358781
Average KL loss: 0.334155
Average total loss: 0.692936
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(9.9530e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.356055
Average KL loss: 0.333266
Average total loss: 0.689321
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.9952e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.359736
Average KL loss: 0.334043
Average total loss: 0.693779
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.8517e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.357591
Average KL loss: 0.335189
Average total loss: 0.692779
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.9923e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.356696
Average KL loss: 0.335128
Average total loss: 0.691824
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.8706e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.352186
Average KL loss: 0.335225
Average total loss: 0.687411
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.1627e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.355288
Average KL loss: 0.334614
Average total loss: 0.689902
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.6165e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.357792
Average KL loss: 0.335583
Average total loss: 0.693375
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(5.2745e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.352587
Average KL loss: 0.335162
Average total loss: 0.687748
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(1.0002e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.352443
Average KL loss: 0.335421
Average total loss: 0.687863
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.3384e-11, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.350915
Average KL loss: 0.336180
Average total loss: 0.687095
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.6669e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.346852
Average KL loss: 0.335359
Average total loss: 0.682211
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.6419e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.354157
Average KL loss: 0.335179
Average total loss: 0.689336
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.4916e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.345098
Average KL loss: 0.336155
Average total loss: 0.681253
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(1.4551e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.345863
Average KL loss: 0.335376
Average total loss: 0.681239
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.6761e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.347329
Average KL loss: 0.334685
Average total loss: 0.682014
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(4.1441e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.347859
Average KL loss: 0.334504
Average total loss: 0.682364
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.9331e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.349589
Average KL loss: 0.335069
Average total loss: 0.684657
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-8.7767e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.345337
Average KL loss: 0.334887
Average total loss: 0.680224
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.7031e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.346908
Average KL loss: 0.335088
Average total loss: 0.681996
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.9738e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.346209
Average KL loss: 0.335625
Average total loss: 0.681833
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.2404e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.342118
Average KL loss: 0.335561
Average total loss: 0.677679
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.2432e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.345505
Average KL loss: 0.335375
Average total loss: 0.680880
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.6612e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.343214
Average KL loss: 0.335497
Average total loss: 0.678711
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.1722e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.344039
Average KL loss: 0.335834
Average total loss: 0.679873
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(7.1381e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.341781
Average KL loss: 0.335411
Average total loss: 0.677191
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.0989e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.348863
Average KL loss: 0.336693
Average total loss: 0.685556
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(6.2602e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.339582
Average KL loss: 0.335735
Average total loss: 0.675318
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.4712e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.340293
Average KL loss: 0.335935
Average total loss: 0.676228
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.4466e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.337804
Average KL loss: 0.336362
Average total loss: 0.674166
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.3371e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.340801
Average KL loss: 0.336411
Average total loss: 0.677212
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(1.4851e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.341475
Average KL loss: 0.336591
Average total loss: 0.678066
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.9761e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.340181
Average KL loss: 0.336665
Average total loss: 0.676846
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(4.0392e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.337724
Average KL loss: 0.335204
Average total loss: 0.672928
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.8976e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.339459
Average KL loss: 0.336894
Average total loss: 0.676352
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.2393e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.339542
Average KL loss: 0.336626
Average total loss: 0.676168
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.5947e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.339549
Average KL loss: 0.336628
Average total loss: 0.676178
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.1505e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.336795
Average KL loss: 0.336528
Average total loss: 0.673323
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.6899e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.341784
Average KL loss: 0.336197
Average total loss: 0.677981
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.1763e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.336141
Average KL loss: 0.337325
Average total loss: 0.673466
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.0142e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.340263
Average KL loss: 0.336867
Average total loss: 0.677129
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.8502e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.335649
Average KL loss: 0.337085
Average total loss: 0.672734
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.8279e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.335513
Average KL loss: 0.336577
Average total loss: 0.672090
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.8146e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.333990
Average KL loss: 0.336515
Average total loss: 0.670505
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.4994e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.337401
Average KL loss: 0.336797
Average total loss: 0.674198
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.8655e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.334166
Average KL loss: 0.336883
Average total loss: 0.671049
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.7753e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.337877
Average KL loss: 0.337531
Average total loss: 0.675408
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.8513e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.329455
Average KL loss: 0.337087
Average total loss: 0.666542
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(3.7791e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.334971
Average KL loss: 0.336102
Average total loss: 0.671073
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.3104e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.340417
Average KL loss: 0.336615
Average total loss: 0.677033
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.3118e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.334619
Average KL loss: 0.336967
Average total loss: 0.671586
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.2592e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.333783
Average KL loss: 0.336787
Average total loss: 0.670570
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.3424e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.328136
Average KL loss: 0.337087
Average total loss: 0.665224
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.4643e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.332050
Average KL loss: 0.336422
Average total loss: 0.668472
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.8407e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.330000
Average KL loss: 0.336560
Average total loss: 0.666560
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.4578e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.329968
Average KL loss: 0.336241
Average total loss: 0.666209
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.8472e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.335157
Average KL loss: 0.337155
Average total loss: 0.672312
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.4718e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.332437
Average KL loss: 0.336995
Average total loss: 0.669432
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.8119e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.335173
Average KL loss: 0.337593
Average total loss: 0.672766
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.5655e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.336814
Average KL loss: 0.337847
Average total loss: 0.674662
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.1657e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.334505
Average KL loss: 0.338502
Average total loss: 0.673007
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.7278e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.330296
Average KL loss: 0.338105
Average total loss: 0.668400
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.7501e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.327813
Average KL loss: 0.337115
Average total loss: 0.664928
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.0747e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.332548
Average KL loss: 0.337088
Average total loss: 0.669636
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.9016e-11, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.329583
Average KL loss: 0.337499
Average total loss: 0.667082
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.1379e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.330889
Average KL loss: 0.337951
Average total loss: 0.668840
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.9391e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.331699
Average KL loss: 0.337777
Average total loss: 0.669477
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.9072e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.326377
Average KL loss: 0.337731
Average total loss: 0.664108
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.2260e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.332356
Average KL loss: 0.337934
Average total loss: 0.670291
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.0159e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.330171
Average KL loss: 0.338501
Average total loss: 0.668672
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.0022e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.329720
Average KL loss: 0.338615
Average total loss: 0.668334
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.0552e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.327139
Average KL loss: 0.337797
Average total loss: 0.664936
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.5601e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.326935
Average KL loss: 0.337333
Average total loss: 0.664268
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.0972e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.323867
Average KL loss: 0.337263
Average total loss: 0.661130
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.5575e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.328701
Average KL loss: 0.337852
Average total loss: 0.666553
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.5990e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.327274
Average KL loss: 0.337969
Average total loss: 0.665244
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.7560e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.325096
Average KL loss: 0.337972
Average total loss: 0.663068
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.2673e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.329843
Average KL loss: 0.338349
Average total loss: 0.668192
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.7266e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.328699
Average KL loss: 0.338141
Average total loss: 0.666840
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.7718e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.328900
Average KL loss: 0.337591
Average total loss: 0.666491
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.9418e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.327538
Average KL loss: 0.338028
Average total loss: 0.665565
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.7023e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.329530
Average KL loss: 0.338045
Average total loss: 0.667574
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.5850e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.329405
Average KL loss: 0.337590
Average total loss: 0.666996
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.8237e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.326397
Average KL loss: 0.337508
Average total loss: 0.663904
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.2438e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.322558
Average KL loss: 0.337649
Average total loss: 0.660207
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.9862e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.326705
Average KL loss: 0.337546
Average total loss: 0.664251
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.3100e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.326300
Average KL loss: 0.338050
Average total loss: 0.664350
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.8299e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.328283
Average KL loss: 0.337829
Average total loss: 0.666112
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.6306e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.327593
Average KL loss: 0.338207
Average total loss: 0.665800
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.0217e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.330627
Average KL loss: 0.338083
Average total loss: 0.668709
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.3357e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.327774
Average KL loss: 0.338406
Average total loss: 0.666181
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.0859e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.327262
Average KL loss: 0.337651
Average total loss: 0.664913
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.4579e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.322850
Average KL loss: 0.337554
Average total loss: 0.660403
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.8127e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.328161
Average KL loss: 0.338050
Average total loss: 0.666211
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.1672e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.328141
Average KL loss: 0.338418
Average total loss: 0.666559
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.4712e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.326871
Average KL loss: 0.338996
Average total loss: 0.665867
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.9182e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.325314
Average KL loss: 0.336452
Average total loss: 0.661766
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.3584e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.326648
Average KL loss: 0.332004
Average total loss: 0.658652
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.7065e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.319553
Average KL loss: 0.329146
Average total loss: 0.648699
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.1069e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.322557
Average KL loss: 0.326950
Average total loss: 0.649506
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(8.9381e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.324520
Average KL loss: 0.325230
Average total loss: 0.649750
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-7.5378e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.321873
Average KL loss: 0.323902
Average total loss: 0.645775
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.4768e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.325220
Average KL loss: 0.322652
Average total loss: 0.647872
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-8.0050e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.322645
Average KL loss: 0.321584
Average total loss: 0.644230
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.7816e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.323207
Average KL loss: 0.320749
Average total loss: 0.643956
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(5.5096e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.325023
Average KL loss: 0.320055
Average total loss: 0.645079
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.8202e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.326046
Average KL loss: 0.319468
Average total loss: 0.645514
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.6863e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.321251
Average KL loss: 0.318857
Average total loss: 0.640108
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(4.1099e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.326820
Average KL loss: 0.318241
Average total loss: 0.645060
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.6357e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.322190
Average KL loss: 0.317819
Average total loss: 0.640009
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-9.6868e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.323449
Average KL loss: 0.317318
Average total loss: 0.640767
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.1705e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.322748
Average KL loss: 0.316955
Average total loss: 0.639702
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.7106e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.328414
Average KL loss: 0.316606
Average total loss: 0.645020
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-8.6593e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.325633
Average KL loss: 0.316444
Average total loss: 0.642076
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.5761e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.324550
Average KL loss: 0.316124
Average total loss: 0.640674
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.9502e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.321941
Average KL loss: 0.315767
Average total loss: 0.637708
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.9158e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.326105
Average KL loss: 0.315547
Average total loss: 0.641652
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.0215e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.324017
Average KL loss: 0.315245
Average total loss: 0.639261
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.6606e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.326728
Average KL loss: 0.315041
Average total loss: 0.641769
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.0996e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.322320
Average KL loss: 0.314829
Average total loss: 0.637148
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.4417e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.317856
Average KL loss: 0.314702
Average total loss: 0.632558
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.1496e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.324491
Average KL loss: 0.314441
Average total loss: 0.638932
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.5299e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.322426
Average KL loss: 0.314310
Average total loss: 0.636736
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.8201e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.322749
Average KL loss: 0.314131
Average total loss: 0.636880
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.4726e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.324994
Average KL loss: 0.314025
Average total loss: 0.639020
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.1846e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.320306
Average KL loss: 0.313878
Average total loss: 0.634184
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.5294e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.321632
Average KL loss: 0.313742
Average total loss: 0.635373
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.6986e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.322621
Average KL loss: 0.313558
Average total loss: 0.636179
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.1255e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.320098
Average KL loss: 0.313513
Average total loss: 0.633611
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(7.2725e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.324428
Average KL loss: 0.313444
Average total loss: 0.637872
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.3742e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.325493
Average KL loss: 0.313321
Average total loss: 0.638814
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.3016e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.324357
Average KL loss: 0.313260
Average total loss: 0.637617
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.4979e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.321520
Average KL loss: 0.313260
Average total loss: 0.634780
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.2487e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.324795
Average KL loss: 0.313160
Average total loss: 0.637955
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.2135e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.324719
Average KL loss: 0.313072
Average total loss: 0.637791
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.1664e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.324684
Average KL loss: 0.312998
Average total loss: 0.637681
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.5755e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.321629
Average KL loss: 0.312927
Average total loss: 0.634556
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.8442e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.326225
Average KL loss: 0.312862
Average total loss: 0.639088
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.4869e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.323237
Average KL loss: 0.312799
Average total loss: 0.636036
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.3728e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.322028
Average KL loss: 0.312737
Average total loss: 0.634765
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.2078e-11, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.328059
Average KL loss: 0.312686
Average total loss: 0.640744
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(8.6063e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.321741
Average KL loss: 0.312629
Average total loss: 0.634370
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.5904e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.319908
Average KL loss: 0.312576
Average total loss: 0.632484
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(8.8201e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.323684
Average KL loss: 0.312520
Average total loss: 0.636204
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.7018e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.322437
Average KL loss: 0.312472
Average total loss: 0.634909
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.7787e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.319945
Average KL loss: 0.312417
Average total loss: 0.632362
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.4111e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.323225
Average KL loss: 0.312376
Average total loss: 0.635601
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.0014e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.321818
Average KL loss: 0.312334
Average total loss: 0.634153
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.4337e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.321485
Average KL loss: 0.312294
Average total loss: 0.633778
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.2578e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.321596
Average KL loss: 0.312247
Average total loss: 0.633843
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.3421e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.326450
Average KL loss: 0.312202
Average total loss: 0.638653
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.3246e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.323869
Average KL loss: 0.312169
Average total loss: 0.636038
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.5213e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.320095
Average KL loss: 0.312130
Average total loss: 0.632225
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.2958e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.321305
Average KL loss: 0.312086
Average total loss: 0.633391
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.5867e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.322596
Average KL loss: 0.312060
Average total loss: 0.634656
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.3218e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.324928
Average KL loss: 0.312028
Average total loss: 0.636956
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.4684e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.319748
Average KL loss: 0.311989
Average total loss: 0.631737
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(4.2207e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.325968
Average KL loss: 0.311950
Average total loss: 0.637918
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.0007e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.326290
Average KL loss: 0.311922
Average total loss: 0.638212
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.8062e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.322202
Average KL loss: 0.311903
Average total loss: 0.634105
 Percentile value: 5.600681163286936e-08
Non-zero model percentage: 51.200008392333984%, Non-zero mask percentage: 51.200008392333984%

--- Pruning Level [3/24]: ---
conv1.weight         | nonzeros =    1516 /    1728             ( 87.73%) | total_pruned =     212 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   31957 /   36864             ( 86.69%) | total_pruned =    4907 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   25473 /   36864             ( 69.10%) | total_pruned =   11391 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   21497 /   36864             ( 58.31%) | total_pruned =   15367 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   20635 /   36864             ( 55.98%) | total_pruned =   16229 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   23842 /   73728             ( 32.34%) | total_pruned =   49886 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   44915 /  147456             ( 30.46%) | total_pruned =  102541 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3407 /    8192             ( 41.59%) | total_pruned =    4785 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   60546 /  147456             ( 41.06%) | total_pruned =   86910 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   70595 /  147456             ( 47.88%) | total_pruned =   76861 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   79433 /  294912             ( 26.93%) | total_pruned =  215479 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  165795 /  589824             ( 28.11%) | total_pruned =  424029 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   11453 /   32768             ( 34.95%) | total_pruned =   21315 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      51 /     256             ( 19.92%) | total_pruned =     205 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  183873 /  589824             ( 31.17%) | total_pruned =  405951 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  223877 /  589824             ( 37.96%) | total_pruned =  365947 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  325737 / 1179648             ( 27.61%) | total_pruned =  853911 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      92 /     512             ( 17.97%) | total_pruned =     420 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  964245 / 2359296             ( 40.87%) | total_pruned = 1395051 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     434 /     512             ( 84.77%) | total_pruned =      78 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     112 /     512             ( 21.88%) | total_pruned =     400 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   60975 /  131072             ( 46.52%) | total_pruned =   70097 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     429 /     512             ( 83.79%) | total_pruned =      83 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1380279 / 2359296             ( 58.50%) | total_pruned =  979017 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2007750 / 2359296             ( 85.10%) | total_pruned =  351546 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
linear.weight        | nonzeros =    5014 /    5120             ( 97.93%) | total_pruned =     106 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 5723527, pruned : 5455235, total: 11178762, Compression rate :       1.95x  ( 48.80% pruned)
Train Epoch: 48/100 Loss: 0.015917 Accuracy: 88.05 100.00 % Best test Accuracy: 88.39%
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-8.8542e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.626570
Average KL loss: 0.317071
Average total loss: 0.943641
tensor(0.0038, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.3818e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.514524
Average KL loss: 0.341816
Average total loss: 0.856339
tensor(0.0038, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.2481e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.485626
Average KL loss: 0.350048
Average total loss: 0.835674
tensor(0.0038, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.6581e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.465048
Average KL loss: 0.353764
Average total loss: 0.818812
tensor(0.0038, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.1989e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.460004
Average KL loss: 0.356041
Average total loss: 0.816046
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.1891e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.448617
Average KL loss: 0.357755
Average total loss: 0.806372
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.0886e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.445083
Average KL loss: 0.358576
Average total loss: 0.803658
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.2633e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.432394
Average KL loss: 0.360214
Average total loss: 0.792608
tensor(0.0037, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.5636e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.439573
Average KL loss: 0.361446
Average total loss: 0.801019
tensor(0.0037, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.3621e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.432262
Average KL loss: 0.361985
Average total loss: 0.794246
tensor(0.0037, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.0186e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.422907
Average KL loss: 0.362769
Average total loss: 0.785675
tensor(0.0037, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(4.0919e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.417266
Average KL loss: 0.363420
Average total loss: 0.780686
tensor(0.0037, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.4005e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.417230
Average KL loss: 0.364166
Average total loss: 0.781396
tensor(0.0037, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.5083e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.412551
Average KL loss: 0.364597
Average total loss: 0.777148
tensor(0.0037, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.0002e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.407743
Average KL loss: 0.363889
Average total loss: 0.771632
tensor(0.0037, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.0218e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.415822
Average KL loss: 0.364963
Average total loss: 0.780785
tensor(0.0037, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(3.0222e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.407926
Average KL loss: 0.366243
Average total loss: 0.774169
tensor(0.0037, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-9.1892e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.403892
Average KL loss: 0.365410
Average total loss: 0.769302
tensor(0.0037, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(2.1755e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.403206
Average KL loss: 0.365713
Average total loss: 0.768919
tensor(0.0037, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-7.3390e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.408558
Average KL loss: 0.365669
Average total loss: 0.774227
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.3852e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.400452
Average KL loss: 0.367342
Average total loss: 0.767793
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.5234e-11, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.399018
Average KL loss: 0.367537
Average total loss: 0.766555
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-8.8141e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.403489
Average KL loss: 0.367019
Average total loss: 0.770508
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(2.7176e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.398490
Average KL loss: 0.367145
Average total loss: 0.765635
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.6534e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.399888
Average KL loss: 0.367693
Average total loss: 0.767581
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.0283e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.397513
Average KL loss: 0.367770
Average total loss: 0.765283
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.0046e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.396958
Average KL loss: 0.368243
Average total loss: 0.765201
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.5658e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.395860
Average KL loss: 0.368248
Average total loss: 0.764108
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-9.3837e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.389794
Average KL loss: 0.367730
Average total loss: 0.757524
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(9.9658e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.393878
Average KL loss: 0.367144
Average total loss: 0.761022
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.8947e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.394708
Average KL loss: 0.368278
Average total loss: 0.762985
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-6.0846e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.394091
Average KL loss: 0.368115
Average total loss: 0.762205
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(7.7727e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.392760
Average KL loss: 0.369335
Average total loss: 0.762095
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.9891e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.390566
Average KL loss: 0.368529
Average total loss: 0.759094
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.2742e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.392695
Average KL loss: 0.368747
Average total loss: 0.761442
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.2341e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.392240
Average KL loss: 0.368985
Average total loss: 0.761226
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(4.8193e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.383642
Average KL loss: 0.368888
Average total loss: 0.752530
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.0142e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.383163
Average KL loss: 0.368603
Average total loss: 0.751766
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.7491e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.387862
Average KL loss: 0.368288
Average total loss: 0.756150
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.2818e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.386166
Average KL loss: 0.368963
Average total loss: 0.755129
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.5796e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.382332
Average KL loss: 0.368185
Average total loss: 0.750517
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.4817e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.393507
Average KL loss: 0.368443
Average total loss: 0.761950
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.2808e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.389347
Average KL loss: 0.369092
Average total loss: 0.758439
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.9803e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.383055
Average KL loss: 0.368531
Average total loss: 0.751586
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.6872e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.387739
Average KL loss: 0.368123
Average total loss: 0.755861
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.0983e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.385629
Average KL loss: 0.368536
Average total loss: 0.754165
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.8765e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.386669
Average KL loss: 0.369515
Average total loss: 0.756184
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.9099e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.385931
Average KL loss: 0.369937
Average total loss: 0.755869
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.2776e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.383867
Average KL loss: 0.369034
Average total loss: 0.752901
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.7449e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.378778
Average KL loss: 0.369252
Average total loss: 0.748030
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.2151e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.382894
Average KL loss: 0.368949
Average total loss: 0.751843
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-8.4245e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.381774
Average KL loss: 0.369151
Average total loss: 0.750925
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.9727e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.375908
Average KL loss: 0.369447
Average total loss: 0.745355
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.5719e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.377189
Average KL loss: 0.369115
Average total loss: 0.746304
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.1852e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.379203
Average KL loss: 0.369238
Average total loss: 0.748442
tensor(0.0038, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.5069e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.381201
Average KL loss: 0.369739
Average total loss: 0.750940
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.8888e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.377864
Average KL loss: 0.369081
Average total loss: 0.746945
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(8.4392e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.383480
Average KL loss: 0.369660
Average total loss: 0.753140
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.9229e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.377768
Average KL loss: 0.369342
Average total loss: 0.747110
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.7224e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.380701
Average KL loss: 0.369644
Average total loss: 0.750345
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.2816e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.381515
Average KL loss: 0.369568
Average total loss: 0.751083
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.0318e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.379186
Average KL loss: 0.369480
Average total loss: 0.748666
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.2804e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.377003
Average KL loss: 0.369185
Average total loss: 0.746188
tensor(0.0038, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.7035e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.378066
Average KL loss: 0.368721
Average total loss: 0.746788
tensor(0.0038, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.5157e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.375924
Average KL loss: 0.367249
Average total loss: 0.743173
tensor(0.0038, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.5000e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.379800
Average KL loss: 0.364168
Average total loss: 0.743968
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.2984e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.379243
Average KL loss: 0.362016
Average total loss: 0.741259
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.5284e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.376710
Average KL loss: 0.360296
Average total loss: 0.737005
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.9848e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.373869
Average KL loss: 0.358771
Average total loss: 0.732640
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.6624e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.371239
Average KL loss: 0.357588
Average total loss: 0.728827
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(8.5782e-11, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.376579
Average KL loss: 0.356548
Average total loss: 0.733127
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.8449e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.376469
Average KL loss: 0.355689
Average total loss: 0.732158
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.4678e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.375143
Average KL loss: 0.354997
Average total loss: 0.730140
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.9130e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.375905
Average KL loss: 0.354463
Average total loss: 0.730367
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.0636e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.376194
Average KL loss: 0.353815
Average total loss: 0.730009
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.0169e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.380494
Average KL loss: 0.353246
Average total loss: 0.733741
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.7860e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.376466
Average KL loss: 0.352728
Average total loss: 0.729194
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.4846e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.377460
Average KL loss: 0.352278
Average total loss: 0.729738
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.2159e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.372341
Average KL loss: 0.351880
Average total loss: 0.724222
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.8941e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.381202
Average KL loss: 0.351387
Average total loss: 0.732588
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.9341e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.379886
Average KL loss: 0.351052
Average total loss: 0.730939
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.0716e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.376516
Average KL loss: 0.350765
Average total loss: 0.727281
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-6.0637e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.377705
Average KL loss: 0.350514
Average total loss: 0.728219
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.3695e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.377039
Average KL loss: 0.350295
Average total loss: 0.727334
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.4241e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.380229
Average KL loss: 0.350109
Average total loss: 0.730338
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.0105e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.375912
Average KL loss: 0.349878
Average total loss: 0.725790
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.8598e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.372647
Average KL loss: 0.349523
Average total loss: 0.722169
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.4093e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.384607
Average KL loss: 0.349251
Average total loss: 0.733858
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.1157e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.377532
Average KL loss: 0.349101
Average total loss: 0.726632
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.4069e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.378198
Average KL loss: 0.349025
Average total loss: 0.727223
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.9383e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.373017
Average KL loss: 0.348769
Average total loss: 0.721786
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-8.6120e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.378686
Average KL loss: 0.348527
Average total loss: 0.727213
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.6786e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.373680
Average KL loss: 0.348296
Average total loss: 0.721976
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-8.6126e-11, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.373673
Average KL loss: 0.348078
Average total loss: 0.721750
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.1043e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.377192
Average KL loss: 0.347858
Average total loss: 0.725050
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.3619e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.375318
Average KL loss: 0.347823
Average total loss: 0.723141
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(4.0524e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.379278
Average KL loss: 0.347732
Average total loss: 0.727010
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.3819e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.375528
Average KL loss: 0.347610
Average total loss: 0.723138
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(4.4649e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.376884
Average KL loss: 0.347514
Average total loss: 0.724398
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.7504e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.373319
Average KL loss: 0.347266
Average total loss: 0.720585
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-6.5799e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.376983
Average KL loss: 0.347123
Average total loss: 0.724106
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-9.0194e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.373717
Average KL loss: 0.347006
Average total loss: 0.720723
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.9821e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.374330
Average KL loss: 0.346864
Average total loss: 0.721193
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(4.3172e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.378195
Average KL loss: 0.346689
Average total loss: 0.724884
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.6173e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.374234
Average KL loss: 0.346647
Average total loss: 0.720882
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.1015e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.378312
Average KL loss: 0.346557
Average total loss: 0.724870
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.6503e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.372150
Average KL loss: 0.346452
Average total loss: 0.718602
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.0859e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.378185
Average KL loss: 0.346254
Average total loss: 0.724439
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.1530e-11, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.378822
Average KL loss: 0.346177
Average total loss: 0.724999
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(6.4235e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.376241
Average KL loss: 0.346088
Average total loss: 0.722328
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.6650e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.376794
Average KL loss: 0.345968
Average total loss: 0.722762
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.5990e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.375003
Average KL loss: 0.345897
Average total loss: 0.720899
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(5.5685e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.377499
Average KL loss: 0.345820
Average total loss: 0.723319
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.0514e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.374413
Average KL loss: 0.345794
Average total loss: 0.720207
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.3025e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.376262
Average KL loss: 0.345751
Average total loss: 0.722013
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.4327e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.379232
Average KL loss: 0.345621
Average total loss: 0.724853
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.5796e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.374032
Average KL loss: 0.345439
Average total loss: 0.719472
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.1148e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.378964
Average KL loss: 0.345348
Average total loss: 0.724312
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.3421e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.377275
Average KL loss: 0.345307
Average total loss: 0.722582
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.8485e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.376528
Average KL loss: 0.345247
Average total loss: 0.721776
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.3682e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.379642
Average KL loss: 0.345197
Average total loss: 0.724838
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.2938e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.376396
Average KL loss: 0.345156
Average total loss: 0.721552
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(5.4530e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.380007
Average KL loss: 0.345113
Average total loss: 0.725119
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(6.8432e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.375951
Average KL loss: 0.345077
Average total loss: 0.721028
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.5537e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.381401
Average KL loss: 0.345034
Average total loss: 0.726435
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.0436e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.378061
Average KL loss: 0.345008
Average total loss: 0.723070
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(9.0328e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.379736
Average KL loss: 0.344979
Average total loss: 0.724715
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.4583e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.376877
Average KL loss: 0.344955
Average total loss: 0.721831
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.1693e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.375524
Average KL loss: 0.344915
Average total loss: 0.720439
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.4866e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.376930
Average KL loss: 0.344891
Average total loss: 0.721821
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.8442e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.384244
Average KL loss: 0.344888
Average total loss: 0.729133
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.5407e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.373886
Average KL loss: 0.344884
Average total loss: 0.718770
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.6622e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.373292
Average KL loss: 0.344880
Average total loss: 0.718172
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2935e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.379239
Average KL loss: 0.344877
Average total loss: 0.724116
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.0146e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.377217
Average KL loss: 0.344875
Average total loss: 0.722092
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.7657e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.379555
Average KL loss: 0.344871
Average total loss: 0.724426
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.9071e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.375138
Average KL loss: 0.344868
Average total loss: 0.720006
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.4328e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.381145
Average KL loss: 0.344865
Average total loss: 0.726011
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.8560e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.380406
Average KL loss: 0.344862
Average total loss: 0.725267
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.8635e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.374639
Average KL loss: 0.344859
Average total loss: 0.719498
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.8254e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.376687
Average KL loss: 0.344856
Average total loss: 0.721543
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.0822e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.371416
Average KL loss: 0.344852
Average total loss: 0.716268
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(5.9856e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.374930
Average KL loss: 0.344847
Average total loss: 0.719777
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.1537e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.375400
Average KL loss: 0.344843
Average total loss: 0.720243
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.7449e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.377269
Average KL loss: 0.344840
Average total loss: 0.722109
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.2525e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.373791
Average KL loss: 0.344837
Average total loss: 0.718628
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.9416e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.376028
Average KL loss: 0.344834
Average total loss: 0.720862
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.3903e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.376878
Average KL loss: 0.344833
Average total loss: 0.721711
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.3634e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.375856
Average KL loss: 0.344830
Average total loss: 0.720686
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.5809e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.377184
Average KL loss: 0.344828
Average total loss: 0.722012
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.0172e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.381349
Average KL loss: 0.344825
Average total loss: 0.726174
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.3003e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.371482
Average KL loss: 0.344822
Average total loss: 0.716303
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-9.2264e-09, device='cuda:0')
 Percentile value: 8.02192374749211e-08
Non-zero model percentage: 40.96000671386719%, Non-zero mask percentage: 40.96000671386719%

--- Pruning Level [4/24]: ---
conv1.weight         | nonzeros =    1324 /    1728             ( 76.62%) | total_pruned =     404 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
bn1.weight           | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
bn1.bias             | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   29414 /   36864             ( 79.79%) | total_pruned =    7450 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   21730 /   36864             ( 58.95%) | total_pruned =   15134 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   18416 /   36864             ( 49.96%) | total_pruned =   18448 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   17384 /   36864             ( 47.16%) | total_pruned =   19480 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   17980 /   73728             ( 24.39%) | total_pruned =   55748 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   33704 /  147456             ( 22.86%) | total_pruned =  113752 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2755 /    8192             ( 33.63%) | total_pruned =    5437 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   46662 /  147456             ( 31.64%) | total_pruned =  100794 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   55244 /  147456             ( 37.46%) | total_pruned =   92212 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   57582 /  294912             ( 19.53%) | total_pruned =  237330 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      59 /     256             ( 23.05%) | total_pruned =     197 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  118880 /  589824             ( 20.16%) | total_pruned =  470944 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      43 /     256             ( 16.80%) | total_pruned =     213 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    8648 /   32768             ( 26.39%) | total_pruned =   24120 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      41 /     256             ( 16.02%) | total_pruned =     215 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  129833 /  589824             ( 22.01%) | total_pruned =  459991 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  159730 /  589824             ( 27.08%) | total_pruned =  430094 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  222251 / 1179648             ( 18.84%) | total_pruned =  957397 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     471 /     512             ( 91.99%) | total_pruned =      41 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      77 /     512             ( 15.04%) | total_pruned =     435 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  681459 / 2359296             ( 28.88%) | total_pruned = 1677837 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     468 /     512             ( 91.41%) | total_pruned =      44 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     401 /     512             ( 78.32%) | total_pruned =     111 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     108 /     512             ( 21.09%) | total_pruned =     404 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   43662 /  131072             ( 33.31%) | total_pruned =   87410 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     460 /     512             ( 89.84%) | total_pruned =      52 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     108 /     512             ( 21.09%) | total_pruned =     404 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1141262 / 2359296             ( 48.37%) | total_pruned = 1218034 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     441 /     512             ( 86.13%) | total_pruned =      71 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1756061 / 2359296             ( 74.43%) | total_pruned =  603235 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     470 /     512             ( 91.80%) | total_pruned =      42 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     483 /     512             ( 94.34%) | total_pruned =      29 | shape = torch.Size([512])
linear.weight        | nonzeros =    4844 /    5120             ( 94.61%) | total_pruned =     276 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 4578822, pruned : 6599940, total: 11178762, Compression rate :       2.44x  ( 59.04% pruned)
Train Epoch: 55/100 Loss: 0.039590 Accuracy: 88.62 100.00 % Best test Accuracy: 88.72%
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.3822e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.664272
Average KL loss: 0.330209
Average total loss: 0.994481
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.6364e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.571938
Average KL loss: 0.340610
Average total loss: 0.912548
tensor(0.0036, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.8113e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.544838
Average KL loss: 0.346577
Average total loss: 0.891415
tensor(0.0036, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.3915e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.523836
Average KL loss: 0.351312
Average total loss: 0.875148
tensor(0.0036, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.1340e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.511882
Average KL loss: 0.354002
Average total loss: 0.865884
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.2229e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.507253
Average KL loss: 0.355007
Average total loss: 0.862260
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(6.8648e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.495493
Average KL loss: 0.356686
Average total loss: 0.852178
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.6504e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.482392
Average KL loss: 0.358195
Average total loss: 0.840587
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.5747e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.485085
Average KL loss: 0.359222
Average total loss: 0.844307
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.5148e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.478342
Average KL loss: 0.360037
Average total loss: 0.838379
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.7713e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.465030
Average KL loss: 0.361438
Average total loss: 0.826468
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(5.3888e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.478005
Average KL loss: 0.362025
Average total loss: 0.840030
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.4829e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.471253
Average KL loss: 0.363027
Average total loss: 0.834280
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.8054e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.465072
Average KL loss: 0.363902
Average total loss: 0.828974
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.6029e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.462672
Average KL loss: 0.363392
Average total loss: 0.826064
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.8293e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.468056
Average KL loss: 0.365609
Average total loss: 0.833665
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.4270e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.450857
Average KL loss: 0.364684
Average total loss: 0.815541
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.9893e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.449916
Average KL loss: 0.365240
Average total loss: 0.815156
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.7924e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.442667
Average KL loss: 0.365194
Average total loss: 0.807861
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(1.1098e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.446748
Average KL loss: 0.364828
Average total loss: 0.811576
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(6.3557e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.444481
Average KL loss: 0.365370
Average total loss: 0.809851
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.2976e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.437792
Average KL loss: 0.366874
Average total loss: 0.804666
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.2135e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.437108
Average KL loss: 0.366850
Average total loss: 0.803958
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.2377e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.439457
Average KL loss: 0.367136
Average total loss: 0.806593
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.3561e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.439577
Average KL loss: 0.367024
Average total loss: 0.806601
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-8.2974e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.434433
Average KL loss: 0.367012
Average total loss: 0.801445
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-8.0296e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.444380
Average KL loss: 0.367565
Average total loss: 0.811945
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(7.3443e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.431285
Average KL loss: 0.367810
Average total loss: 0.799095
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.5407e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.430732
Average KL loss: 0.367312
Average total loss: 0.798044
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.8412e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.435252
Average KL loss: 0.366949
Average total loss: 0.802201
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.9152e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.428959
Average KL loss: 0.366975
Average total loss: 0.795934
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.4301e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.434033
Average KL loss: 0.367459
Average total loss: 0.801492
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.2113e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.427129
Average KL loss: 0.367560
Average total loss: 0.794689
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(6.5636e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.432193
Average KL loss: 0.367471
Average total loss: 0.799664
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.6872e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.433460
Average KL loss: 0.367854
Average total loss: 0.801314
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.7095e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.425327
Average KL loss: 0.367616
Average total loss: 0.792943
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.5481e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.425581
Average KL loss: 0.367762
Average total loss: 0.793343
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.0391e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.428381
Average KL loss: 0.367939
Average total loss: 0.796320
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.6890e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.427947
Average KL loss: 0.368270
Average total loss: 0.796216
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.1235e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.422880
Average KL loss: 0.368542
Average total loss: 0.791422
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.2371e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.424870
Average KL loss: 0.368253
Average total loss: 0.793123
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.6100e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.422387
Average KL loss: 0.369431
Average total loss: 0.791818
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-9.4277e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.418830
Average KL loss: 0.369313
Average total loss: 0.788143
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.0887e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.414781
Average KL loss: 0.368207
Average total loss: 0.782988
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.0256e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.423603
Average KL loss: 0.368820
Average total loss: 0.792423
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.6780e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.416736
Average KL loss: 0.368768
Average total loss: 0.785503
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.7192e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.421550
Average KL loss: 0.369588
Average total loss: 0.791138
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.4058e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.415560
Average KL loss: 0.369608
Average total loss: 0.785168
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.7974e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.415512
Average KL loss: 0.369411
Average total loss: 0.784923
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(2.5242e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.413367
Average KL loss: 0.370024
Average total loss: 0.783391
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.6364e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.416485
Average KL loss: 0.369750
Average total loss: 0.786236
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.2183e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.415613
Average KL loss: 0.369777
Average total loss: 0.785390
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.1805e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.422441
Average KL loss: 0.370337
Average total loss: 0.792778
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.0161e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.414774
Average KL loss: 0.370505
Average total loss: 0.785279
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.2395e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.416306
Average KL loss: 0.370373
Average total loss: 0.786679
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.3202e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.410623
Average KL loss: 0.369107
Average total loss: 0.779730
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.0741e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.411361
Average KL loss: 0.366878
Average total loss: 0.778239
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.0047e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.416559
Average KL loss: 0.365259
Average total loss: 0.781818
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.0857e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.413404
Average KL loss: 0.363972
Average total loss: 0.777376
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.8328e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.409236
Average KL loss: 0.362932
Average total loss: 0.772167
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.3465e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.415935
Average KL loss: 0.361998
Average total loss: 0.777933
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(8.2216e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.413094
Average KL loss: 0.361159
Average total loss: 0.774253
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.1316e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.409961
Average KL loss: 0.360391
Average total loss: 0.770352
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4605e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.406060
Average KL loss: 0.359653
Average total loss: 0.765713
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.8157e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.415459
Average KL loss: 0.358928
Average total loss: 0.774387
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4513e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.411863
Average KL loss: 0.358406
Average total loss: 0.770269
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.7360e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.410910
Average KL loss: 0.357858
Average total loss: 0.768768
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.0331e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.413390
Average KL loss: 0.357429
Average total loss: 0.770819
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.5280e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.406736
Average KL loss: 0.356982
Average total loss: 0.763718
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.4399e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.409878
Average KL loss: 0.356573
Average total loss: 0.766451
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.7076e-11, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.409298
Average KL loss: 0.356179
Average total loss: 0.765478
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.9730e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.409500
Average KL loss: 0.355778
Average total loss: 0.765278
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.2870e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.416688
Average KL loss: 0.355365
Average total loss: 0.772053
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.3055e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.411407
Average KL loss: 0.355102
Average total loss: 0.766509
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.3060e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.411268
Average KL loss: 0.354771
Average total loss: 0.766039
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.6921e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.409512
Average KL loss: 0.354490
Average total loss: 0.764002
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.6017e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.410635
Average KL loss: 0.354184
Average total loss: 0.764818
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.4716e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.403656
Average KL loss: 0.353861
Average total loss: 0.757517
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(7.3945e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.413827
Average KL loss: 0.353603
Average total loss: 0.767429
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.7406e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.407376
Average KL loss: 0.353286
Average total loss: 0.760663
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.8620e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.413130
Average KL loss: 0.353015
Average total loss: 0.766145
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.4024e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.412524
Average KL loss: 0.352809
Average total loss: 0.765333
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.0857e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.410927
Average KL loss: 0.352592
Average total loss: 0.763518
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.0246e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.407445
Average KL loss: 0.352367
Average total loss: 0.759811
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.1084e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.406327
Average KL loss: 0.352217
Average total loss: 0.758544
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.6076e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.409912
Average KL loss: 0.352002
Average total loss: 0.761915
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.8406e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.413242
Average KL loss: 0.351858
Average total loss: 0.765101
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.1746e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.415977
Average KL loss: 0.351749
Average total loss: 0.767725
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.6023e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.413993
Average KL loss: 0.351674
Average total loss: 0.765667
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.1275e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.413879
Average KL loss: 0.351610
Average total loss: 0.765489
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.6783e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.412324
Average KL loss: 0.351564
Average total loss: 0.763887
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3908e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.411518
Average KL loss: 0.351525
Average total loss: 0.763043
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.5042e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.410463
Average KL loss: 0.351484
Average total loss: 0.761947
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.6210e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.412038
Average KL loss: 0.351441
Average total loss: 0.763479
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.1661e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.407295
Average KL loss: 0.351402
Average total loss: 0.758697
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.9618e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.408813
Average KL loss: 0.351366
Average total loss: 0.760179
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.4773e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.415142
Average KL loss: 0.351327
Average total loss: 0.766469
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.6389e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.406466
Average KL loss: 0.351288
Average total loss: 0.757754
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(8.9884e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.409367
Average KL loss: 0.351247
Average total loss: 0.760614
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.1979e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.406861
Average KL loss: 0.351209
Average total loss: 0.758071
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(6.5982e-11, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.410121
Average KL loss: 0.351181
Average total loss: 0.761302
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.3989e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.411000
Average KL loss: 0.351177
Average total loss: 0.762177
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.7708e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.405690
Average KL loss: 0.351174
Average total loss: 0.756864
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.9018e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.410588
Average KL loss: 0.351170
Average total loss: 0.761758
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.3862e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.409385
Average KL loss: 0.351165
Average total loss: 0.760550
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.5427e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.410118
Average KL loss: 0.351161
Average total loss: 0.761280
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.2053e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.407687
Average KL loss: 0.351158
Average total loss: 0.758845
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9535e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.405772
Average KL loss: 0.351154
Average total loss: 0.756925
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.5665e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.408768
Average KL loss: 0.351150
Average total loss: 0.759917
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.2371e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.408169
Average KL loss: 0.351145
Average total loss: 0.759314
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.6196e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.409757
Average KL loss: 0.351141
Average total loss: 0.760897
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.9642e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.405520
Average KL loss: 0.351137
Average total loss: 0.756657
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.0229e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.404994
Average KL loss: 0.351132
Average total loss: 0.756126
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9953e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.408476
Average KL loss: 0.351128
Average total loss: 0.759604
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3513e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.411259
Average KL loss: 0.351125
Average total loss: 0.762384
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4363e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.409818
Average KL loss: 0.351121
Average total loss: 0.760940
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9906e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.411275
Average KL loss: 0.351118
Average total loss: 0.762393
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.0029e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.407225
Average KL loss: 0.351115
Average total loss: 0.758340
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.8255e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.406387
Average KL loss: 0.351111
Average total loss: 0.757498
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.9098e-11, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.407259
Average KL loss: 0.351107
Average total loss: 0.758366
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9184e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.409115
Average KL loss: 0.351103
Average total loss: 0.760218
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9381e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.411683
Average KL loss: 0.351100
Average total loss: 0.762784
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.2621e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.410001
Average KL loss: 0.351097
Average total loss: 0.761097
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.4018e-09, device='cuda:0')
 Percentile value: 8.040932186759164e-08
Non-zero model percentage: 32.76801300048828%, Non-zero mask percentage: 32.76801300048828%

--- Pruning Level [5/24]: ---
conv1.weight         | nonzeros =    1049 /    1728             ( 60.71%) | total_pruned =     679 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
bn1.weight           | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
bn1.bias             | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   10540 /   36864             ( 28.59%) | total_pruned =   26324 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   16797 /   36864             ( 45.56%) | total_pruned =   20067 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   12974 /   36864             ( 35.19%) | total_pruned =   23890 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   13922 /   36864             ( 37.77%) | total_pruned =   22942 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   13612 /   73728             ( 18.46%) | total_pruned =   60116 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   25400 /  147456             ( 17.23%) | total_pruned =  122056 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2154 /    8192             ( 26.29%) | total_pruned =    6038 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   34804 /  147456             ( 23.60%) | total_pruned =  112652 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   41502 /  147456             ( 28.15%) | total_pruned =  105954 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   42193 /  294912             ( 14.31%) | total_pruned =  252719 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     161 /     256             ( 62.89%) | total_pruned =      95 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   86283 /  589824             ( 14.63%) | total_pruned =  503541 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     189 /     256             ( 73.83%) | total_pruned =      67 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     246 /     256             ( 96.09%) | total_pruned =      10 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6562 /   32768             ( 20.03%) | total_pruned =   26206 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     175 /     256             ( 68.36%) | total_pruned =      81 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   92287 /  589824             ( 15.65%) | total_pruned =  497537 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  116013 /  589824             ( 19.67%) | total_pruned =  473811 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     184 /     256             ( 71.88%) | total_pruned =      72 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     190 /     256             ( 74.22%) | total_pruned =      66 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  150929 / 1179648             ( 12.79%) | total_pruned = 1028719 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     331 /     512             ( 64.65%) | total_pruned =     181 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      70 /     512             ( 13.67%) | total_pruned =     442 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  491801 / 2359296             ( 20.85%) | total_pruned = 1867495 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     344 /     512             ( 67.19%) | total_pruned =     168 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     368 /     512             ( 71.88%) | total_pruned =     144 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     108 /     512             ( 21.09%) | total_pruned =     404 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   32929 /  131072             ( 25.12%) | total_pruned =   98143 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     358 /     512             ( 69.92%) | total_pruned =     154 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     337 /     512             ( 65.82%) | total_pruned =     175 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     105 /     512             ( 20.51%) | total_pruned =     407 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  951727 / 2359296             ( 40.34%) | total_pruned = 1407569 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     322 /     512             ( 62.89%) | total_pruned =     190 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     451 /     512             ( 88.09%) | total_pruned =      61 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1506485 / 2359296             ( 63.85%) | total_pruned =  852811 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     357 /     512             ( 69.73%) | total_pruned =     155 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     457 /     512             ( 89.26%) | total_pruned =      55 | shape = torch.Size([512])
linear.weight        | nonzeros =    4551 /    5120             ( 88.89%) | total_pruned =     569 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 3663058, pruned : 7515704, total: 11178762, Compression rate :       3.05x  ( 67.23% pruned)
Train Epoch: 56/100 Loss: 0.016493 Accuracy: 88.13 100.00 % Best test Accuracy: 88.33%
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.1711e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.630993
Average KL loss: 0.332381
Average total loss: 0.963374
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.3497e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.570244
Average KL loss: 0.338381
Average total loss: 0.908625
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0426e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.546127
Average KL loss: 0.344318
Average total loss: 0.890445
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.3860e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.530031
Average KL loss: 0.348915
Average total loss: 0.878946
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.9429e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.517751
Average KL loss: 0.351928
Average total loss: 0.869678
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-7.5434e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.503786
Average KL loss: 0.354135
Average total loss: 0.857920
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.7352e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.502048
Average KL loss: 0.356027
Average total loss: 0.858075
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-8.9545e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.496394
Average KL loss: 0.358637
Average total loss: 0.855030
tensor(0.0034, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.9168e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.483625
Average KL loss: 0.360137
Average total loss: 0.843762
tensor(0.0034, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.5312e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.481662
Average KL loss: 0.360918
Average total loss: 0.842580
tensor(0.0033, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.5006e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.477889
Average KL loss: 0.361103
Average total loss: 0.838992
tensor(0.0033, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.3086e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.479084
Average KL loss: 0.362387
Average total loss: 0.841472
tensor(0.0033, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.2886e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.470208
Average KL loss: 0.363334
Average total loss: 0.833542
tensor(0.0033, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.7042e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.468230
Average KL loss: 0.363301
Average total loss: 0.831531
tensor(0.0033, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.9714e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.472870
Average KL loss: 0.364249
Average total loss: 0.837119
tensor(0.0033, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.1573e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.470347
Average KL loss: 0.365309
Average total loss: 0.835656
tensor(0.0033, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.3035e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.461142
Average KL loss: 0.365541
Average total loss: 0.826682
tensor(0.0033, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.2358e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.463725
Average KL loss: 0.365597
Average total loss: 0.829322
tensor(0.0033, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.9542e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.454765
Average KL loss: 0.365810
Average total loss: 0.820575
tensor(0.0033, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.9019e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.449840
Average KL loss: 0.365853
Average total loss: 0.815693
tensor(0.0033, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-7.4982e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.454363
Average KL loss: 0.365940
Average total loss: 0.820303
tensor(0.0033, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.2780e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.460513
Average KL loss: 0.366213
Average total loss: 0.826726
tensor(0.0033, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.8586e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.454652
Average KL loss: 0.366930
Average total loss: 0.821581
tensor(0.0033, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(1.2031e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.458071
Average KL loss: 0.368720
Average total loss: 0.826791
tensor(0.0033, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.9099e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.449282
Average KL loss: 0.369159
Average total loss: 0.818441
tensor(0.0033, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.1625e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.450856
Average KL loss: 0.369089
Average total loss: 0.819945
tensor(0.0033, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.3454e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.450570
Average KL loss: 0.369028
Average total loss: 0.819598
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.1393e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.449697
Average KL loss: 0.369818
Average total loss: 0.819514
tensor(0.0033, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.7904e-12, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.451281
Average KL loss: 0.369857
Average total loss: 0.821138
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.6113e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.448316
Average KL loss: 0.369975
Average total loss: 0.818291
tensor(0.0034, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(8.1236e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.443902
Average KL loss: 0.370234
Average total loss: 0.814136
tensor(0.0033, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.7236e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.444148
Average KL loss: 0.369960
Average total loss: 0.814109
tensor(0.0033, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.4820e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.450545
Average KL loss: 0.369959
Average total loss: 0.820504
tensor(0.0034, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.6904e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.448169
Average KL loss: 0.370952
Average total loss: 0.819121
tensor(0.0034, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-6.9371e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.443863
Average KL loss: 0.371718
Average total loss: 0.815581
tensor(0.0034, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(8.0577e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.442216
Average KL loss: 0.370771
Average total loss: 0.812987
tensor(0.0034, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.6275e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.441079
Average KL loss: 0.371384
Average total loss: 0.812463
tensor(0.0034, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-8.8027e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.444992
Average KL loss: 0.371715
Average total loss: 0.816707
tensor(0.0034, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(2.5211e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.443809
Average KL loss: 0.371446
Average total loss: 0.815254
tensor(0.0034, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.8860e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.439112
Average KL loss: 0.371291
Average total loss: 0.810403
tensor(0.0034, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.0424e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.444401
Average KL loss: 0.371350
Average total loss: 0.815751
tensor(0.0034, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.6482e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.432773
Average KL loss: 0.371629
Average total loss: 0.804402
tensor(0.0034, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.7698e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.441699
Average KL loss: 0.371081
Average total loss: 0.812780
tensor(0.0034, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.1969e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.437161
Average KL loss: 0.371618
Average total loss: 0.808779
tensor(0.0034, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.5894e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.440941
Average KL loss: 0.371798
Average total loss: 0.812739
tensor(0.0034, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(1.2324e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.433243
Average KL loss: 0.371733
Average total loss: 0.804975
tensor(0.0034, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.2231e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.439764
Average KL loss: 0.371783
Average total loss: 0.811547
tensor(0.0034, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(1.1493e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.438636
Average KL loss: 0.372039
Average total loss: 0.810675
tensor(0.0034, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.4051e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.434566
Average KL loss: 0.372295
Average total loss: 0.806861
tensor(0.0034, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.5227e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.437032
Average KL loss: 0.372162
Average total loss: 0.809194
tensor(0.0034, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.9353e-11, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.431791
Average KL loss: 0.372525
Average total loss: 0.804316
tensor(0.0034, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(3.5945e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.434393
Average KL loss: 0.372609
Average total loss: 0.807003
tensor(0.0034, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(1.0424e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.435529
Average KL loss: 0.372554
Average total loss: 0.808084
tensor(0.0034, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(3.2717e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.433909
Average KL loss: 0.373336
Average total loss: 0.807245
tensor(0.0034, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(3.9248e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.432360
Average KL loss: 0.373384
Average total loss: 0.805743
tensor(0.0034, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(2.3535e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.436076
Average KL loss: 0.373313
Average total loss: 0.809389
tensor(0.0034, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.2639e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.432764
Average KL loss: 0.373860
Average total loss: 0.806624
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.8473e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.430676
Average KL loss: 0.373776
Average total loss: 0.804452
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.7098e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.431769
Average KL loss: 0.373681
Average total loss: 0.805450
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.8886e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.433225
Average KL loss: 0.373149
Average total loss: 0.806374
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.4227e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.431139
Average KL loss: 0.373389
Average total loss: 0.804528
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.7467e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.433656
Average KL loss: 0.373776
Average total loss: 0.807433
tensor(0.0034, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.6256e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.435178
Average KL loss: 0.373532
Average total loss: 0.808709
tensor(0.0034, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.1214e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.424201
Average KL loss: 0.372005
Average total loss: 0.796206
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.7749e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.430773
Average KL loss: 0.370842
Average total loss: 0.801615
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.2109e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.431042
Average KL loss: 0.369855
Average total loss: 0.800897
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.4362e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.431951
Average KL loss: 0.368964
Average total loss: 0.800915
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.8202e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.433885
Average KL loss: 0.368182
Average total loss: 0.802067
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.1214e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.429738
Average KL loss: 0.367484
Average total loss: 0.797221
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.8001e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.432066
Average KL loss: 0.366879
Average total loss: 0.798944
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.1406e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.428051
Average KL loss: 0.366300
Average total loss: 0.794352
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.9300e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.432131
Average KL loss: 0.365770
Average total loss: 0.797901
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.9203e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.433541
Average KL loss: 0.365320
Average total loss: 0.798861
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.5847e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.427853
Average KL loss: 0.364868
Average total loss: 0.792721
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.6989e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.426890
Average KL loss: 0.364427
Average total loss: 0.791317
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.8330e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.425824
Average KL loss: 0.364022
Average total loss: 0.789847
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.7469e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.426965
Average KL loss: 0.363547
Average total loss: 0.790511
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.7101e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.427144
Average KL loss: 0.363183
Average total loss: 0.790327
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.5636e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.426960
Average KL loss: 0.362816
Average total loss: 0.789776
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(7.7676e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.424281
Average KL loss: 0.362507
Average total loss: 0.786787
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.5334e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.430864
Average KL loss: 0.362168
Average total loss: 0.793032
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.2664e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.424797
Average KL loss: 0.361811
Average total loss: 0.786608
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.5390e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.431162
Average KL loss: 0.361523
Average total loss: 0.792685
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.4668e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.426479
Average KL loss: 0.361303
Average total loss: 0.787782
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.5556e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.428075
Average KL loss: 0.361044
Average total loss: 0.789119
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(6.9483e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.428507
Average KL loss: 0.360800
Average total loss: 0.789306
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.0408e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.430077
Average KL loss: 0.360547
Average total loss: 0.790624
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.2895e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.428278
Average KL loss: 0.360363
Average total loss: 0.788642
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.6158e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.428405
Average KL loss: 0.360158
Average total loss: 0.788562
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.1880e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.425471
Average KL loss: 0.359998
Average total loss: 0.785469
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.1067e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.429021
Average KL loss: 0.359754
Average total loss: 0.788774
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.3870e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.429596
Average KL loss: 0.359547
Average total loss: 0.789142
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.2858e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.432109
Average KL loss: 0.359439
Average total loss: 0.791547
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.9337e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.430036
Average KL loss: 0.359303
Average total loss: 0.789339
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(6.0309e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.427031
Average KL loss: 0.359125
Average total loss: 0.786156
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.2955e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.429226
Average KL loss: 0.358971
Average total loss: 0.788197
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(6.1200e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.426424
Average KL loss: 0.358865
Average total loss: 0.785288
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.9063e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.424628
Average KL loss: 0.358787
Average total loss: 0.783415
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.4136e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.426340
Average KL loss: 0.358675
Average total loss: 0.785015
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.3623e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.426437
Average KL loss: 0.358627
Average total loss: 0.785064
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.5840e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.424526
Average KL loss: 0.358505
Average total loss: 0.783031
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.6195e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.431213
Average KL loss: 0.358301
Average total loss: 0.789514
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.1268e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.432100
Average KL loss: 0.358168
Average total loss: 0.790268
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.5516e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.431919
Average KL loss: 0.358010
Average total loss: 0.789930
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.1470e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.425955
Average KL loss: 0.357909
Average total loss: 0.783864
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.7060e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.426265
Average KL loss: 0.357834
Average total loss: 0.784099
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.8288e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.429875
Average KL loss: 0.357722
Average total loss: 0.787597
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9941e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.426129
Average KL loss: 0.357554
Average total loss: 0.783683
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.6782e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.426359
Average KL loss: 0.357381
Average total loss: 0.783740
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.7960e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.423586
Average KL loss: 0.357324
Average total loss: 0.780910
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.1873e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.429364
Average KL loss: 0.357261
Average total loss: 0.786625
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.7520e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.423390
Average KL loss: 0.357196
Average total loss: 0.780587
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.3138e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.427227
Average KL loss: 0.357122
Average total loss: 0.784349
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.5001e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.432162
Average KL loss: 0.356975
Average total loss: 0.789137
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.6293e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.428239
Average KL loss: 0.356888
Average total loss: 0.785127
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.4022e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.425534
Average KL loss: 0.356794
Average total loss: 0.782328
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.3117e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.425718
Average KL loss: 0.356597
Average total loss: 0.782316
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.4720e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.422882
Average KL loss: 0.356428
Average total loss: 0.779310
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(4.9144e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.427341
Average KL loss: 0.356303
Average total loss: 0.783644
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.1539e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.430308
Average KL loss: 0.356310
Average total loss: 0.786618
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.6590e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.425612
Average KL loss: 0.356251
Average total loss: 0.781863
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.0317e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.431163
Average KL loss: 0.356165
Average total loss: 0.787328
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(8.7973e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.424778
Average KL loss: 0.356090
Average total loss: 0.780869
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(4.2174e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.427433
Average KL loss: 0.356022
Average total loss: 0.783455
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.7644e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.426088
Average KL loss: 0.355905
Average total loss: 0.781993
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.1822e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.431167
Average KL loss: 0.355873
Average total loss: 0.787040
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.5726e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.425912
Average KL loss: 0.355815
Average total loss: 0.781726
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.7297e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.427351
Average KL loss: 0.355684
Average total loss: 0.783035
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.4762e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.428251
Average KL loss: 0.355683
Average total loss: 0.783934
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.9325e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.425199
Average KL loss: 0.355649
Average total loss: 0.780848
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.5397e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.428417
Average KL loss: 0.355625
Average total loss: 0.784042
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.9888e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.428051
Average KL loss: 0.355594
Average total loss: 0.783645
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.1847e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.426200
Average KL loss: 0.355563
Average total loss: 0.781763
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.1863e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.425879
Average KL loss: 0.355541
Average total loss: 0.781420
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.5611e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.427044
Average KL loss: 0.355523
Average total loss: 0.782567
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.0059e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.426072
Average KL loss: 0.355495
Average total loss: 0.781568
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.7281e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.429347
Average KL loss: 0.355465
Average total loss: 0.784812
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.3241e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.426935
Average KL loss: 0.355443
Average total loss: 0.782378
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.7767e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.421785
Average KL loss: 0.355419
Average total loss: 0.777204
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.1313e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.430211
Average KL loss: 0.355393
Average total loss: 0.785604
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.7186e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.421209
Average KL loss: 0.355373
Average total loss: 0.776582
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(6.3702e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.429472
Average KL loss: 0.355352
Average total loss: 0.784825
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.1743e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.424649
Average KL loss: 0.355338
Average total loss: 0.779987
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.6270e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.431008
Average KL loss: 0.355319
Average total loss: 0.786326
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.8428e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.425461
Average KL loss: 0.355308
Average total loss: 0.780769
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4627e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.429523
Average KL loss: 0.355289
Average total loss: 0.784812
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(9.7496e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.425168
Average KL loss: 0.355271
Average total loss: 0.780439
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.0338e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.427367
Average KL loss: 0.355255
Average total loss: 0.782622
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(9.2315e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.431287
Average KL loss: 0.355237
Average total loss: 0.786525
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.3845e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.425167
Average KL loss: 0.355222
Average total loss: 0.780388
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.0179e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.428005
Average KL loss: 0.355207
Average total loss: 0.783212
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.8518e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.427751
Average KL loss: 0.355191
Average total loss: 0.782942
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.8191e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.429647
Average KL loss: 0.355181
Average total loss: 0.784828
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.8232e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.429474
Average KL loss: 0.355179
Average total loss: 0.784653
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.2331e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.425286
Average KL loss: 0.355177
Average total loss: 0.780463
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.2183e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.425996
Average KL loss: 0.355175
Average total loss: 0.781171
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.1730e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.428492
Average KL loss: 0.355173
Average total loss: 0.783665
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.9507e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.432454
Average KL loss: 0.355172
Average total loss: 0.787626
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.0341e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.427816
Average KL loss: 0.355170
Average total loss: 0.782986
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.3181e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.428102
Average KL loss: 0.355168
Average total loss: 0.783270
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(4.9847e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.432862
Average KL loss: 0.355166
Average total loss: 0.788028
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.5801e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.427403
Average KL loss: 0.355165
Average total loss: 0.782568
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.7083e-09, device='cuda:0')
 Percentile value: 7.98184913719524e-08
Non-zero model percentage: 26.214414596557617%, Non-zero mask percentage: 26.214414596557617%

--- Pruning Level [6/24]: ---
conv1.weight         | nonzeros =     848 /    1728             ( 49.07%) | total_pruned =     880 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
bn1.weight           | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
bn1.bias             | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    8399 /   36864             ( 22.78%) | total_pruned =   28465 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   13514 /   36864             ( 36.66%) | total_pruned =   23350 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   10374 /   36864             ( 28.14%) | total_pruned =   26490 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   11154 /   36864             ( 30.26%) | total_pruned =   25710 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   10510 /   73728             ( 14.26%) | total_pruned =   63218 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   19577 /  147456             ( 13.28%) | total_pruned =  127879 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1670 /    8192             ( 20.39%) | total_pruned =    6522 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   27006 /  147456             ( 18.31%) | total_pruned =  120450 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   32237 /  147456             ( 21.86%) | total_pruned =  115219 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   31954 /  294912             ( 10.84%) | total_pruned =  262958 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   64924 /  589824             ( 11.01%) | total_pruned =  524900 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     149 /     256             ( 58.20%) | total_pruned =     107 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    5069 /   32768             ( 15.47%) | total_pruned =   27699 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     152 /     256             ( 59.38%) | total_pruned =     104 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     196 /     256             ( 76.56%) | total_pruned =      60 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   67452 /  589824             ( 11.44%) | total_pruned =  522372 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     160 /     256             ( 62.50%) | total_pruned =      96 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   86000 /  589824             ( 14.58%) | total_pruned =  503824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     165 /     256             ( 64.45%) | total_pruned =      91 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  108291 / 1179648             (  9.18%) | total_pruned = 1071357 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     274 /     512             ( 53.52%) | total_pruned =     238 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     491 /     512             ( 95.90%) | total_pruned =      21 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      61 /     512             ( 11.91%) | total_pruned =     451 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  371563 / 2359296             ( 15.75%) | total_pruned = 1987733 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     288 /     512             ( 56.25%) | total_pruned =     224 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     343 /     512             ( 66.99%) | total_pruned =     169 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     105 /     512             ( 20.51%) | total_pruned =     407 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   25191 /  131072             ( 19.22%) | total_pruned =  105881 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     302 /     512             ( 58.98%) | total_pruned =     210 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     304 /     512             ( 59.38%) | total_pruned =     208 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     104 /     512             ( 20.31%) | total_pruned =     408 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  760110 / 2359296             ( 32.22%) | total_pruned = 1599186 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     283 /     512             ( 55.27%) | total_pruned =     229 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1262706 / 2359296             ( 53.52%) | total_pruned = 1096590 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     307 /     512             ( 59.96%) | total_pruned =     205 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     485 /     512             ( 94.73%) | total_pruned =      27 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     415 /     512             ( 81.05%) | total_pruned =      97 | shape = torch.Size([512])
linear.weight        | nonzeros =    4202 /    5120             ( 82.07%) | total_pruned =     918 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 2930447, pruned : 8248315, total: 11178762, Compression rate :       3.81x  ( 73.79% pruned)
Train Epoch: 61/100 Loss: 0.026736 Accuracy: 87.80 100.00 % Best test Accuracy: 87.90%
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9622e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.750648
Average KL loss: 0.334545
Average total loss: 1.085193
tensor(0.0034, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.5958e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.673145
Average KL loss: 0.336902
Average total loss: 1.010047
tensor(0.0033, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.3051e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.643142
Average KL loss: 0.342571
Average total loss: 0.985713
tensor(0.0032, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.7034e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.624138
Average KL loss: 0.347169
Average total loss: 0.971307
tensor(0.0032, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.3171e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.605661
Average KL loss: 0.350430
Average total loss: 0.956091
tensor(0.0032, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.7398e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.602434
Average KL loss: 0.352562
Average total loss: 0.954996
tensor(0.0032, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.0985e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.577291
Average KL loss: 0.355321
Average total loss: 0.932612
tensor(0.0032, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-5.1158e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.565905
Average KL loss: 0.357398
Average total loss: 0.923303
tensor(0.0032, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-5.4707e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.559907
Average KL loss: 0.359445
Average total loss: 0.919353
tensor(0.0032, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.2619e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.556514
Average KL loss: 0.361765
Average total loss: 0.918278
tensor(0.0032, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.0013e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.559554
Average KL loss: 0.363454
Average total loss: 0.923008
tensor(0.0032, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(4.0475e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.542852
Average KL loss: 0.365090
Average total loss: 0.907943
tensor(0.0032, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(5.0198e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.536723
Average KL loss: 0.365564
Average total loss: 0.902288
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.2447e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.534783
Average KL loss: 0.366326
Average total loss: 0.901109
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.6237e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.534934
Average KL loss: 0.367974
Average total loss: 0.902908
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.2258e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.528249
Average KL loss: 0.368836
Average total loss: 0.897085
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-7.7234e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.523067
Average KL loss: 0.369547
Average total loss: 0.892614
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.7682e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.525960
Average KL loss: 0.370073
Average total loss: 0.896033
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.1391e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.521968
Average KL loss: 0.370556
Average total loss: 0.892524
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.9537e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.520173
Average KL loss: 0.370926
Average total loss: 0.891099
tensor(0.0032, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.4367e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.517031
Average KL loss: 0.371680
Average total loss: 0.888711
tensor(0.0032, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(1.3605e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.514423
Average KL loss: 0.372317
Average total loss: 0.886739
tensor(0.0032, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.2287e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.508902
Average KL loss: 0.372698
Average total loss: 0.881600
tensor(0.0032, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.3545e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.503728
Average KL loss: 0.372865
Average total loss: 0.876593
tensor(0.0032, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(3.8069e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.511035
Average KL loss: 0.373499
Average total loss: 0.884534
tensor(0.0032, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.9395e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.503373
Average KL loss: 0.373595
Average total loss: 0.876968
tensor(0.0032, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.1612e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.508660
Average KL loss: 0.373565
Average total loss: 0.882225
tensor(0.0032, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(3.0830e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.495488
Average KL loss: 0.374273
Average total loss: 0.869761
tensor(0.0032, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.0847e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.496028
Average KL loss: 0.374116
Average total loss: 0.870144
tensor(0.0032, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-9.7529e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.489214
Average KL loss: 0.373701
Average total loss: 0.862914
tensor(0.0032, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.0044e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.494472
Average KL loss: 0.373870
Average total loss: 0.868342
tensor(0.0032, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.9432e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.498870
Average KL loss: 0.374931
Average total loss: 0.873801
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.2225e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.492277
Average KL loss: 0.375034
Average total loss: 0.867311
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.1006e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.495040
Average KL loss: 0.375136
Average total loss: 0.870176
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-9.7166e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.489885
Average KL loss: 0.375803
Average total loss: 0.865688
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.0249e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.488028
Average KL loss: 0.375662
Average total loss: 0.863690
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.0918e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.485076
Average KL loss: 0.375751
Average total loss: 0.860827
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.6190e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.493847
Average KL loss: 0.375924
Average total loss: 0.869771
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.1292e-11, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.492705
Average KL loss: 0.376753
Average total loss: 0.869459
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.7816e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.481931
Average KL loss: 0.377410
Average total loss: 0.859341
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.2682e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.478000
Average KL loss: 0.377130
Average total loss: 0.855130
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.1036e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.486491
Average KL loss: 0.376831
Average total loss: 0.863321
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(1.4938e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.478086
Average KL loss: 0.377185
Average total loss: 0.855271
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(3.3350e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.475873
Average KL loss: 0.377519
Average total loss: 0.853393
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(7.1479e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.480471
Average KL loss: 0.377263
Average total loss: 0.857734
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-9.0056e-11, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.476793
Average KL loss: 0.377194
Average total loss: 0.853987
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.4784e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.477510
Average KL loss: 0.377795
Average total loss: 0.855305
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.9223e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.470966
Average KL loss: 0.378126
Average total loss: 0.849092
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.3593e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.479386
Average KL loss: 0.378859
Average total loss: 0.858245
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.9070e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.471554
Average KL loss: 0.378986
Average total loss: 0.850540
tensor(0.0032, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.6567e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.478036
Average KL loss: 0.378897
Average total loss: 0.856933
tensor(0.0032, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.5880e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.470284
Average KL loss: 0.378727
Average total loss: 0.849011
tensor(0.0032, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.0461e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.475790
Average KL loss: 0.378683
Average total loss: 0.854473
tensor(0.0032, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.3157e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.472084
Average KL loss: 0.378926
Average total loss: 0.851010
tensor(0.0032, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(5.2887e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.472702
Average KL loss: 0.379016
Average total loss: 0.851718
tensor(0.0032, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.3731e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.472669
Average KL loss: 0.378639
Average total loss: 0.851308
tensor(0.0032, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.9012e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.469773
Average KL loss: 0.378668
Average total loss: 0.848440
tensor(0.0032, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.1224e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.468486
Average KL loss: 0.379368
Average total loss: 0.847854
tensor(0.0032, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.9209e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.465197
Average KL loss: 0.379577
Average total loss: 0.844774
tensor(0.0032, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(5.7895e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.475668
Average KL loss: 0.379781
Average total loss: 0.855448
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.1741e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.465184
Average KL loss: 0.379648
Average total loss: 0.844832
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-7.5740e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.465126
Average KL loss: 0.379991
Average total loss: 0.845117
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.3995e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.473211
Average KL loss: 0.380212
Average total loss: 0.853424
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.5820e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.468713
Average KL loss: 0.380828
Average total loss: 0.849541
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(1.9804e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.466952
Average KL loss: 0.381301
Average total loss: 0.848253
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.5794e-11, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.468035
Average KL loss: 0.381690
Average total loss: 0.849726
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.5156e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.464108
Average KL loss: 0.381744
Average total loss: 0.845851
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.5739e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.461652
Average KL loss: 0.381135
Average total loss: 0.842788
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.6196e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.460585
Average KL loss: 0.380835
Average total loss: 0.841421
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.2969e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.463703
Average KL loss: 0.381020
Average total loss: 0.844723
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.8814e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.468264
Average KL loss: 0.380739
Average total loss: 0.849003
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.2304e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.465244
Average KL loss: 0.381671
Average total loss: 0.846914
tensor(0.0033, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.7898e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.466971
Average KL loss: 0.382172
Average total loss: 0.849143
tensor(0.0033, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.0954e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.468105
Average KL loss: 0.382176
Average total loss: 0.850282
tensor(0.0033, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.9052e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.461030
Average KL loss: 0.382144
Average total loss: 0.843174
tensor(0.0033, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.3307e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.461394
Average KL loss: 0.381956
Average total loss: 0.843350
tensor(0.0033, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.3461e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.465133
Average KL loss: 0.382052
Average total loss: 0.847185
tensor(0.0033, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.4855e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.457109
Average KL loss: 0.382332
Average total loss: 0.839441
tensor(0.0033, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(9.7440e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.463090
Average KL loss: 0.382510
Average total loss: 0.845599
tensor(0.0033, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.3602e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.468727
Average KL loss: 0.382340
Average total loss: 0.851067
tensor(0.0033, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.6439e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.459252
Average KL loss: 0.382128
Average total loss: 0.841380
tensor(0.0033, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.5407e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.459194
Average KL loss: 0.381885
Average total loss: 0.841079
tensor(0.0033, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.7187e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.468419
Average KL loss: 0.382026
Average total loss: 0.850445
tensor(0.0033, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.5148e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.455922
Average KL loss: 0.382780
Average total loss: 0.838701
tensor(0.0033, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.2062e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.457449
Average KL loss: 0.382285
Average total loss: 0.839734
tensor(0.0033, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.6982e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.456297
Average KL loss: 0.382595
Average total loss: 0.838893
tensor(0.0033, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.8466e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.458489
Average KL loss: 0.382458
Average total loss: 0.840946
tensor(0.0033, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.6850e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.452391
Average KL loss: 0.382265
Average total loss: 0.834656
tensor(0.0033, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.2930e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.463927
Average KL loss: 0.382170
Average total loss: 0.846098
tensor(0.0033, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.1357e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.460474
Average KL loss: 0.382833
Average total loss: 0.843307
tensor(0.0033, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.2299e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.462096
Average KL loss: 0.382837
Average total loss: 0.844933
tensor(0.0033, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.0240e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.451783
Average KL loss: 0.382832
Average total loss: 0.834614
tensor(0.0033, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.7356e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.453696
Average KL loss: 0.382119
Average total loss: 0.835815
tensor(0.0033, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.7957e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.458790
Average KL loss: 0.382594
Average total loss: 0.841384
tensor(0.0033, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.8497e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.450433
Average KL loss: 0.382425
Average total loss: 0.832858
tensor(0.0033, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.6752e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.452360
Average KL loss: 0.382522
Average total loss: 0.834882
tensor(0.0033, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.4210e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.456627
Average KL loss: 0.383037
Average total loss: 0.839664
tensor(0.0033, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.8162e-11, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.457046
Average KL loss: 0.382657
Average total loss: 0.839703
tensor(0.0033, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.3413e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.456595
Average KL loss: 0.382621
Average total loss: 0.839216
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1809e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.457364
Average KL loss: 0.383061
Average total loss: 0.840425
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(6.9291e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.451664
Average KL loss: 0.383285
Average total loss: 0.834948
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.6704e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.457248
Average KL loss: 0.383574
Average total loss: 0.840822
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.1182e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.465076
Average KL loss: 0.383622
Average total loss: 0.848698
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.6288e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.452870
Average KL loss: 0.383997
Average total loss: 0.836867
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.4554e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.455946
Average KL loss: 0.383836
Average total loss: 0.839782
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.0471e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.454775
Average KL loss: 0.384283
Average total loss: 0.839059
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.7635e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.451099
Average KL loss: 0.383860
Average total loss: 0.834960
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.0866e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.450462
Average KL loss: 0.382753
Average total loss: 0.833215
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.0237e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.453390
Average KL loss: 0.381902
Average total loss: 0.835292
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.8469e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.457317
Average KL loss: 0.381200
Average total loss: 0.838517
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.4064e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.462509
Average KL loss: 0.380560
Average total loss: 0.843069
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.9024e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.453915
Average KL loss: 0.380010
Average total loss: 0.833926
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.1642e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.453331
Average KL loss: 0.379483
Average total loss: 0.832814
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.8437e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.453359
Average KL loss: 0.379030
Average total loss: 0.832389
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(6.2346e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.450169
Average KL loss: 0.378566
Average total loss: 0.828734
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.3592e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.453228
Average KL loss: 0.378128
Average total loss: 0.831356
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.6987e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.450624
Average KL loss: 0.377781
Average total loss: 0.828405
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.3836e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.448147
Average KL loss: 0.377417
Average total loss: 0.825565
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.5599e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.451012
Average KL loss: 0.377029
Average total loss: 0.828041
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.4387e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.451839
Average KL loss: 0.376616
Average total loss: 0.828456
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.9376e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.454856
Average KL loss: 0.376290
Average total loss: 0.831147
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(3.8960e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.451005
Average KL loss: 0.375994
Average total loss: 0.826999
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.8804e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.452609
Average KL loss: 0.375701
Average total loss: 0.828311
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.0226e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.451287
Average KL loss: 0.375403
Average total loss: 0.826689
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.8479e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.448492
Average KL loss: 0.375100
Average total loss: 0.823592
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.5882e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.450953
Average KL loss: 0.374814
Average total loss: 0.825767
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.6957e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.448807
Average KL loss: 0.374526
Average total loss: 0.823333
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.1936e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.450237
Average KL loss: 0.374295
Average total loss: 0.824532
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.5258e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.450591
Average KL loss: 0.374047
Average total loss: 0.824638
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.8723e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.447346
Average KL loss: 0.373810
Average total loss: 0.821156
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.0753e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.451357
Average KL loss: 0.373564
Average total loss: 0.824921
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.4893e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.462575
Average KL loss: 0.373399
Average total loss: 0.835975
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.3837e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.451015
Average KL loss: 0.373232
Average total loss: 0.824247
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.0532e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.453192
Average KL loss: 0.373015
Average total loss: 0.826206
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.8055e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.451781
Average KL loss: 0.372840
Average total loss: 0.824621
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.8065e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.449497
Average KL loss: 0.372678
Average total loss: 0.822175
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(8.9111e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.451346
Average KL loss: 0.372553
Average total loss: 0.823899
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.2088e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.450140
Average KL loss: 0.372408
Average total loss: 0.822548
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(6.0239e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.448168
Average KL loss: 0.372229
Average total loss: 0.820397
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.7770e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.453850
Average KL loss: 0.372065
Average total loss: 0.825915
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1314e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.454774
Average KL loss: 0.371893
Average total loss: 0.826667
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.1539e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.453943
Average KL loss: 0.371688
Average total loss: 0.825631
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.5992e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.452190
Average KL loss: 0.371526
Average total loss: 0.823716
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.2725e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.460450
Average KL loss: 0.371413
Average total loss: 0.831864
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.4340e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.448597
Average KL loss: 0.371297
Average total loss: 0.819894
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.5874e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.445465
Average KL loss: 0.371130
Average total loss: 0.816595
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.8013e-11, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.448060
Average KL loss: 0.370989
Average total loss: 0.819048
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.5376e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.450838
Average KL loss: 0.370846
Average total loss: 0.821685
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.0272e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.455249
Average KL loss: 0.370788
Average total loss: 0.826037
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.3026e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.457189
Average KL loss: 0.370698
Average total loss: 0.827887
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.1475e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.450379
Average KL loss: 0.370604
Average total loss: 0.820983
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.6376e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.453385
Average KL loss: 0.370532
Average total loss: 0.823916
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.3887e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.447976
Average KL loss: 0.370426
Average total loss: 0.818402
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.1138e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.456155
Average KL loss: 0.370316
Average total loss: 0.826471
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.5785e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.453079
Average KL loss: 0.370273
Average total loss: 0.823352
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.4769e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.455988
Average KL loss: 0.370151
Average total loss: 0.826139
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.9030e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.448684
Average KL loss: 0.370061
Average total loss: 0.818745
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.1961e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.450052
Average KL loss: 0.369994
Average total loss: 0.820046
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1723e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.451382
Average KL loss: 0.369968
Average total loss: 0.821350
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.9441e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.447480
Average KL loss: 0.369946
Average total loss: 0.817426
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.2595e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.446454
Average KL loss: 0.369925
Average total loss: 0.816379
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.4824e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.452760
Average KL loss: 0.369901
Average total loss: 0.822661
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(4.0891e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.448080
Average KL loss: 0.369879
Average total loss: 0.817959
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.8753e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.453503
Average KL loss: 0.369858
Average total loss: 0.823361
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.7513e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.450159
Average KL loss: 0.369836
Average total loss: 0.819995
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.7005e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.453682
Average KL loss: 0.369815
Average total loss: 0.823497
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(4.0911e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.451451
Average KL loss: 0.369802
Average total loss: 0.821253
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.1358e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.453318
Average KL loss: 0.369781
Average total loss: 0.823099
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.5302e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.459149
Average KL loss: 0.369761
Average total loss: 0.828910
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.6800e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.449828
Average KL loss: 0.369747
Average total loss: 0.819575
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.5577e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.451664
Average KL loss: 0.369729
Average total loss: 0.821393
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.6651e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.451637
Average KL loss: 0.369709
Average total loss: 0.821346
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.9959e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.451659
Average KL loss: 0.369694
Average total loss: 0.821352
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.8226e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.450987
Average KL loss: 0.369691
Average total loss: 0.820678
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(8.1283e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.451024
Average KL loss: 0.369690
Average total loss: 0.820714
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.4460e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.452931
Average KL loss: 0.369689
Average total loss: 0.822620
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.4011e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.447162
Average KL loss: 0.369687
Average total loss: 0.816849
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-9.8792e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.447486
Average KL loss: 0.369686
Average total loss: 0.817172
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.0961e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.447913
Average KL loss: 0.369684
Average total loss: 0.817597
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.2739e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.448728
Average KL loss: 0.369683
Average total loss: 0.818411
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1367e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.455824
Average KL loss: 0.369681
Average total loss: 0.825506
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.2390e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.450940
Average KL loss: 0.369679
Average total loss: 0.820619
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(4.5046e-09, device='cuda:0')
 Percentile value: 7.982733052358526e-08
Non-zero model percentage: 20.971534729003906%, Non-zero mask percentage: 20.971534729003906%

--- Pruning Level [7/24]: ---
conv1.weight         | nonzeros =     700 /    1728             ( 40.51%) | total_pruned =    1028 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.weight           | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
bn1.bias             | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    6857 /   36864             ( 18.60%) | total_pruned =   30007 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   10549 /   36864             ( 28.62%) | total_pruned =   26315 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    8029 /   36864             ( 21.78%) | total_pruned =   28835 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    8583 /   36864             ( 23.28%) | total_pruned =   28281 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    7918 /   73728             ( 10.74%) | total_pruned =   65810 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   14715 /  147456             (  9.98%) | total_pruned =  132741 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1293 /    8192             ( 15.78%) | total_pruned =    6899 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   20162 /  147456             ( 13.67%) | total_pruned =  127294 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   24160 /  147456             ( 16.38%) | total_pruned =  123296 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   23702 /  294912             (  8.04%) | total_pruned =  271210 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     103 /     256             ( 40.23%) | total_pruned =     153 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   47255 /  589824             (  8.01%) | total_pruned =  542569 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     238 /     256             ( 92.97%) | total_pruned =      18 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3802 /   32768             ( 11.60%) | total_pruned =   28966 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     122 /     256             ( 47.66%) | total_pruned =     134 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     181 /     256             ( 70.70%) | total_pruned =      75 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      34 /     256             ( 13.28%) | total_pruned =     222 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   48380 /  589824             (  8.20%) | total_pruned =  541444 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     134 /     256             ( 52.34%) | total_pruned =     122 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   63784 /  589824             ( 10.81%) | total_pruned =  526040 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     131 /     256             ( 51.17%) | total_pruned =     125 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   78627 / 1179648             (  6.67%) | total_pruned = 1101021 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     215 /     512             ( 41.99%) | total_pruned =     297 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     479 /     512             ( 93.55%) | total_pruned =      33 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      55 /     512             ( 10.74%) | total_pruned =     457 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  276561 / 2359296             ( 11.72%) | total_pruned = 2082735 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     224 /     512             ( 43.75%) | total_pruned =     288 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     305 /     512             ( 59.57%) | total_pruned =     207 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      98 /     512             ( 19.14%) | total_pruned =     414 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   18771 /  131072             ( 14.32%) | total_pruned =  112301 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     236 /     512             ( 46.09%) | total_pruned =     276 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     258 /     512             ( 50.39%) | total_pruned =     254 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      99 /     512             ( 19.34%) | total_pruned =     413 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  583575 / 2359296             ( 24.74%) | total_pruned = 1775721 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     231 /     512             ( 45.12%) | total_pruned =     281 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     344 /     512             ( 67.19%) | total_pruned =     168 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1086339 / 2359296             ( 46.05%) | total_pruned = 1272957 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     258 /     512             ( 50.39%) | total_pruned =     254 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     461 /     512             ( 90.04%) | total_pruned =      51 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     373 /     512             ( 72.85%) | total_pruned =     139 | shape = torch.Size([512])
linear.weight        | nonzeros =    3787 /    5120             ( 73.96%) | total_pruned =    1333 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 2344358, pruned : 8834404, total: 11178762, Compression rate :       4.77x  ( 79.03% pruned)
Train Epoch: 67/100 Loss: 0.019904 Accuracy: 87.00 100.00 % Best test Accuracy: 87.19%
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.7521e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.691258
Average KL loss: 0.347197
Average total loss: 1.038455
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.4714e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.631136
Average KL loss: 0.344269
Average total loss: 0.975405
tensor(0.0032, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.2960e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.598927
Average KL loss: 0.347849
Average total loss: 0.946776
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-3.5751e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.584509
Average KL loss: 0.350546
Average total loss: 0.935055
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.1905e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.572740
Average KL loss: 0.353498
Average total loss: 0.926238
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.9896e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.561882
Average KL loss: 0.355588
Average total loss: 0.917471
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.7210e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.555027
Average KL loss: 0.357434
Average total loss: 0.912461
tensor(0.0030, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.6161e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.557900
Average KL loss: 0.359525
Average total loss: 0.917425
tensor(0.0030, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.6303e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.545545
Average KL loss: 0.361489
Average total loss: 0.907034
tensor(0.0030, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-6.8953e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.530063
Average KL loss: 0.362780
Average total loss: 0.892843
tensor(0.0030, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.0931e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.531788
Average KL loss: 0.363604
Average total loss: 0.895392
tensor(0.0030, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.1860e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.521037
Average KL loss: 0.364720
Average total loss: 0.885757
tensor(0.0030, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.1352e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.528633
Average KL loss: 0.365903
Average total loss: 0.894536
tensor(0.0030, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.3195e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.515128
Average KL loss: 0.367013
Average total loss: 0.882141
tensor(0.0030, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(8.8735e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.512166
Average KL loss: 0.368118
Average total loss: 0.880284
tensor(0.0030, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.4201e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.512539
Average KL loss: 0.368798
Average total loss: 0.881337
tensor(0.0030, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.8688e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.510388
Average KL loss: 0.369163
Average total loss: 0.879552
tensor(0.0030, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.7998e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.517264
Average KL loss: 0.370174
Average total loss: 0.887438
tensor(0.0030, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.0906e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.509782
Average KL loss: 0.370917
Average total loss: 0.880700
tensor(0.0030, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.1329e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.498198
Average KL loss: 0.370988
Average total loss: 0.869186
tensor(0.0030, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.9845e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.500188
Average KL loss: 0.371640
Average total loss: 0.871828
tensor(0.0030, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-8.7067e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.503404
Average KL loss: 0.372132
Average total loss: 0.875536
tensor(0.0030, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.2058e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.494976
Average KL loss: 0.372716
Average total loss: 0.867691
tensor(0.0030, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.5029e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.495139
Average KL loss: 0.373020
Average total loss: 0.868158
tensor(0.0030, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.8562e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.501015
Average KL loss: 0.373649
Average total loss: 0.874664
tensor(0.0030, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(2.1149e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.489774
Average KL loss: 0.373621
Average total loss: 0.863395
tensor(0.0030, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.5806e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.492997
Average KL loss: 0.373829
Average total loss: 0.866826
tensor(0.0030, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.6350e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.496326
Average KL loss: 0.374280
Average total loss: 0.870606
tensor(0.0030, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.9406e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.497905
Average KL loss: 0.374538
Average total loss: 0.872443
tensor(0.0030, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.2834e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.486853
Average KL loss: 0.374810
Average total loss: 0.861662
tensor(0.0030, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.9227e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.495115
Average KL loss: 0.375204
Average total loss: 0.870319
tensor(0.0030, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.4961e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.483295
Average KL loss: 0.375321
Average total loss: 0.858616
tensor(0.0030, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.7117e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.486847
Average KL loss: 0.375977
Average total loss: 0.862824
tensor(0.0030, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.7961e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.484429
Average KL loss: 0.376460
Average total loss: 0.860889
tensor(0.0030, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.5671e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.487632
Average KL loss: 0.377254
Average total loss: 0.864887
tensor(0.0030, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(6.6864e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.497420
Average KL loss: 0.377160
Average total loss: 0.874580
tensor(0.0030, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.5888e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.483341
Average KL loss: 0.376999
Average total loss: 0.860339
tensor(0.0030, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.9830e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.481586
Average KL loss: 0.377475
Average total loss: 0.859061
tensor(0.0030, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(2.7079e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.477692
Average KL loss: 0.377966
Average total loss: 0.855658
tensor(0.0030, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(5.4625e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.481204
Average KL loss: 0.377718
Average total loss: 0.858922
tensor(0.0030, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.9681e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.481798
Average KL loss: 0.377839
Average total loss: 0.859637
tensor(0.0030, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.3027e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.475517
Average KL loss: 0.378276
Average total loss: 0.853794
tensor(0.0030, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(5.2371e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.477928
Average KL loss: 0.377919
Average total loss: 0.855847
tensor(0.0030, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.6886e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.476531
Average KL loss: 0.377927
Average total loss: 0.854459
tensor(0.0030, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-8.6326e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.485348
Average KL loss: 0.378195
Average total loss: 0.863543
tensor(0.0030, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-7.2042e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.481322
Average KL loss: 0.378492
Average total loss: 0.859814
tensor(0.0030, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(3.8805e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.475185
Average KL loss: 0.378601
Average total loss: 0.853786
tensor(0.0031, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.8483e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.474090
Average KL loss: 0.378749
Average total loss: 0.852839
tensor(0.0031, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-9.4751e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.473979
Average KL loss: 0.378678
Average total loss: 0.852657
tensor(0.0031, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(6.0465e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.472103
Average KL loss: 0.378514
Average total loss: 0.850617
tensor(0.0031, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.6486e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.475445
Average KL loss: 0.378762
Average total loss: 0.854206
tensor(0.0031, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.6352e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.471953
Average KL loss: 0.379233
Average total loss: 0.851186
tensor(0.0031, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(1.7979e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.477802
Average KL loss: 0.379459
Average total loss: 0.857261
tensor(0.0031, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.6638e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.474466
Average KL loss: 0.379375
Average total loss: 0.853841
tensor(0.0031, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.3071e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.470332
Average KL loss: 0.379503
Average total loss: 0.849834
tensor(0.0031, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.1862e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.466232
Average KL loss: 0.379922
Average total loss: 0.846154
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.1812e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.470265
Average KL loss: 0.379546
Average total loss: 0.849811
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.4143e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.475332
Average KL loss: 0.379870
Average total loss: 0.855202
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.7389e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.474119
Average KL loss: 0.380432
Average total loss: 0.854551
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.1856e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.475156
Average KL loss: 0.380222
Average total loss: 0.855378
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.9284e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.468217
Average KL loss: 0.380753
Average total loss: 0.848970
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.9878e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.466054
Average KL loss: 0.380806
Average total loss: 0.846860
tensor(0.0031, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.5116e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.469455
Average KL loss: 0.380778
Average total loss: 0.850233
tensor(0.0031, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.6905e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.468098
Average KL loss: 0.380587
Average total loss: 0.848685
tensor(0.0031, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-9.0547e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.470020
Average KL loss: 0.380811
Average total loss: 0.850830
tensor(0.0031, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-8.0676e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.464230
Average KL loss: 0.380730
Average total loss: 0.844961
tensor(0.0031, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-8.1229e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.465060
Average KL loss: 0.381034
Average total loss: 0.846094
tensor(0.0031, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.4794e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.470768
Average KL loss: 0.381086
Average total loss: 0.851855
tensor(0.0031, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(8.7450e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.469196
Average KL loss: 0.380963
Average total loss: 0.850159
tensor(0.0031, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.3031e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.474400
Average KL loss: 0.380695
Average total loss: 0.855095
tensor(0.0031, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.8369e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.462289
Average KL loss: 0.380780
Average total loss: 0.843069
tensor(0.0031, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.5148e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.467106
Average KL loss: 0.381016
Average total loss: 0.848122
tensor(0.0031, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.2057e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.462722
Average KL loss: 0.380973
Average total loss: 0.843695
tensor(0.0031, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.9305e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.463169
Average KL loss: 0.380890
Average total loss: 0.844059
tensor(0.0031, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.6338e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.464602
Average KL loss: 0.381068
Average total loss: 0.845670
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.9259e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.466745
Average KL loss: 0.381658
Average total loss: 0.848404
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.1539e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.464593
Average KL loss: 0.381829
Average total loss: 0.846422
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-9.9805e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.456763
Average KL loss: 0.381947
Average total loss: 0.838709
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.9754e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.468164
Average KL loss: 0.381782
Average total loss: 0.849946
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.3290e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.468272
Average KL loss: 0.381584
Average total loss: 0.849856
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(3.4825e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.464292
Average KL loss: 0.381872
Average total loss: 0.846164
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.3837e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.461953
Average KL loss: 0.382117
Average total loss: 0.844070
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.6773e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.464832
Average KL loss: 0.382257
Average total loss: 0.847089
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(6.1722e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.464385
Average KL loss: 0.382529
Average total loss: 0.846914
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.2519e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.462508
Average KL loss: 0.382514
Average total loss: 0.845022
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.1909e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.464246
Average KL loss: 0.382416
Average total loss: 0.846662
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.4509e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.467906
Average KL loss: 0.382636
Average total loss: 0.850542
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.6002e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.461743
Average KL loss: 0.382497
Average total loss: 0.844240
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.0536e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.462099
Average KL loss: 0.382268
Average total loss: 0.844367
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.4972e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.463405
Average KL loss: 0.381796
Average total loss: 0.845201
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.9646e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.458623
Average KL loss: 0.381141
Average total loss: 0.839764
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.1518e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.460737
Average KL loss: 0.380584
Average total loss: 0.841321
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.2149e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.464416
Average KL loss: 0.380110
Average total loss: 0.844527
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.8232e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.462349
Average KL loss: 0.379659
Average total loss: 0.842008
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.6154e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.463117
Average KL loss: 0.379258
Average total loss: 0.842375
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.8145e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.465556
Average KL loss: 0.378893
Average total loss: 0.844449
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.4320e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.459723
Average KL loss: 0.378571
Average total loss: 0.838294
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.6640e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.463232
Average KL loss: 0.378186
Average total loss: 0.841418
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.3000e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.466084
Average KL loss: 0.377861
Average total loss: 0.843945
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.3081e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.464682
Average KL loss: 0.377555
Average total loss: 0.842237
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.7123e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.463010
Average KL loss: 0.377314
Average total loss: 0.840324
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-6.6701e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.456565
Average KL loss: 0.377084
Average total loss: 0.833649
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.4339e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.460034
Average KL loss: 0.376845
Average total loss: 0.836879
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.6951e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.462501
Average KL loss: 0.376612
Average total loss: 0.839113
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.0961e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.462288
Average KL loss: 0.376400
Average total loss: 0.838688
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.3400e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.455600
Average KL loss: 0.376136
Average total loss: 0.831736
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.3757e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.458765
Average KL loss: 0.375919
Average total loss: 0.834684
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.0413e-11, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.464211
Average KL loss: 0.375745
Average total loss: 0.839956
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.9059e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.459443
Average KL loss: 0.375525
Average total loss: 0.834968
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.9965e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.459568
Average KL loss: 0.375318
Average total loss: 0.834886
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.3669e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.461799
Average KL loss: 0.375101
Average total loss: 0.836900
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.1914e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.463570
Average KL loss: 0.374913
Average total loss: 0.838483
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.2496e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.462767
Average KL loss: 0.374739
Average total loss: 0.837506
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.3730e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.461172
Average KL loss: 0.374573
Average total loss: 0.835745
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.8317e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.459319
Average KL loss: 0.374408
Average total loss: 0.833727
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.0840e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.459022
Average KL loss: 0.374270
Average total loss: 0.833293
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.3676e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.458100
Average KL loss: 0.374096
Average total loss: 0.832196
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.5720e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.461779
Average KL loss: 0.374007
Average total loss: 0.835786
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.7964e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.458175
Average KL loss: 0.373976
Average total loss: 0.832151
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.0693e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.460694
Average KL loss: 0.373953
Average total loss: 0.834647
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.7518e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.455063
Average KL loss: 0.373929
Average total loss: 0.828992
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.8459e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.455179
Average KL loss: 0.373902
Average total loss: 0.829081
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.6829e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.458405
Average KL loss: 0.373875
Average total loss: 0.832280
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.4913e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.462602
Average KL loss: 0.373850
Average total loss: 0.836452
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.3516e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.455514
Average KL loss: 0.373829
Average total loss: 0.829343
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.7616e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.461655
Average KL loss: 0.373809
Average total loss: 0.835465
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.3306e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.455462
Average KL loss: 0.373789
Average total loss: 0.829251
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.5690e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.460022
Average KL loss: 0.373772
Average total loss: 0.833794
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.4530e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.460897
Average KL loss: 0.373751
Average total loss: 0.834648
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.5616e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.453883
Average KL loss: 0.373726
Average total loss: 0.827609
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.4420e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.459239
Average KL loss: 0.373704
Average total loss: 0.832943
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.3705e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.456657
Average KL loss: 0.373676
Average total loss: 0.830333
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.8783e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.458833
Average KL loss: 0.373651
Average total loss: 0.832483
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.0505e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.462550
Average KL loss: 0.373631
Average total loss: 0.836181
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(6.4051e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.463886
Average KL loss: 0.373607
Average total loss: 0.837492
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.8577e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.455861
Average KL loss: 0.373587
Average total loss: 0.829448
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.1662e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.456943
Average KL loss: 0.373566
Average total loss: 0.830509
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(9.4458e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.457089
Average KL loss: 0.373548
Average total loss: 0.830637
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.2286e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.458384
Average KL loss: 0.373533
Average total loss: 0.831917
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.6440e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.464275
Average KL loss: 0.373515
Average total loss: 0.837790
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.8306e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.456751
Average KL loss: 0.373495
Average total loss: 0.830246
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.2538e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.463296
Average KL loss: 0.373484
Average total loss: 0.836779
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.9953e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.462012
Average KL loss: 0.373482
Average total loss: 0.835494
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.8688e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.460345
Average KL loss: 0.373480
Average total loss: 0.833825
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.1376e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.464007
Average KL loss: 0.373478
Average total loss: 0.837485
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(6.8556e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.459598
Average KL loss: 0.373477
Average total loss: 0.833075
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.1218e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.457562
Average KL loss: 0.373474
Average total loss: 0.831036
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.3052e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.459295
Average KL loss: 0.373472
Average total loss: 0.832767
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.7757e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.460283
Average KL loss: 0.373470
Average total loss: 0.833754
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.2518e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.459798
Average KL loss: 0.373468
Average total loss: 0.833266
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.9494e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.461990
Average KL loss: 0.373466
Average total loss: 0.835456
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.6945e-09, device='cuda:0')
 Percentile value: 7.981464733575194e-08
Non-zero model percentage: 16.777233123779297%, Non-zero mask percentage: 16.777233123779297%

--- Pruning Level [8/24]: ---
conv1.weight         | nonzeros =     321 /    1728             ( 18.58%) | total_pruned =    1407 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.weight           | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
bn1.bias             | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2933 /   36864             (  7.96%) | total_pruned =   33931 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4952 /   36864             ( 13.43%) | total_pruned =   31912 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3887 /   36864             ( 10.54%) | total_pruned =   32977 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4491 /   36864             ( 12.18%) | total_pruned =   32373 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4635 /   73728             (  6.29%) | total_pruned =   69093 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    8374 /  147456             (  5.68%) | total_pruned =  139082 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     736 /    8192             (  8.98%) | total_pruned =    7456 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   10365 /  147456             (  7.03%) | total_pruned =  137091 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   12318 /  147456             (  8.35%) | total_pruned =  135138 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   13719 /  294912             (  4.65%) | total_pruned =  281193 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   26951 /  589824             (  4.57%) | total_pruned =  562873 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      85 /     256             ( 33.20%) | total_pruned =     171 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     227 /     256             ( 88.67%) | total_pruned =      29 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2246 /   32768             (  6.85%) | total_pruned =   30522 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      90 /     256             ( 35.16%) | total_pruned =     166 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   26485 /  589824             (  4.49%) | total_pruned =  563339 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      96 /     256             ( 37.50%) | total_pruned =     160 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   43817 /  589824             (  7.43%) | total_pruned =  546007 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     108 /     256             ( 42.19%) | total_pruned =     148 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   61087 / 1179648             (  5.18%) | total_pruned = 1118561 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     160 /     512             ( 31.25%) | total_pruned =     352 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     462 /     512             ( 90.23%) | total_pruned =      50 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      49 /     512             (  9.57%) | total_pruned =     463 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  221787 / 2359296             (  9.40%) | total_pruned = 2137509 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     182 /     512             ( 35.55%) | total_pruned =     330 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     278 /     512             ( 54.30%) | total_pruned =     234 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      93 /     512             ( 18.16%) | total_pruned =     419 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   14983 /  131072             ( 11.43%) | total_pruned =  116089 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     180 /     512             ( 35.16%) | total_pruned =     332 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     219 /     512             ( 42.77%) | total_pruned =     293 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      95 /     512             ( 18.55%) | total_pruned =     417 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  485583 / 2359296             ( 20.58%) | total_pruned = 1873713 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     178 /     512             ( 34.77%) | total_pruned =     334 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     301 /     512             ( 58.79%) | total_pruned =     211 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  916831 / 2359296             ( 38.86%) | total_pruned = 1442465 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     202 /     512             ( 39.45%) | total_pruned =     310 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     421 /     512             ( 82.23%) | total_pruned =      91 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     322 /     512             ( 62.89%) | total_pruned =     190 | shape = torch.Size([512])
linear.weight        | nonzeros =    3304 /    5120             ( 64.53%) | total_pruned =    1816 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 1875487, pruned : 9303275, total: 11178762, Compression rate :       5.96x  ( 83.22% pruned)
Train Epoch: 71/100 Loss: 0.024885 Accuracy: 86.57 100.00 % Best test Accuracy: 86.94%
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.1253e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.783107
Average KL loss: 0.349932
Average total loss: 1.133039
tensor(0.0030, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.0520e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.715359
Average KL loss: 0.342863
Average total loss: 1.058222
tensor(0.0029, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.7688e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.691263
Average KL loss: 0.344463
Average total loss: 1.035726
tensor(0.0029, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.3824e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.664813
Average KL loss: 0.346824
Average total loss: 1.011637
tensor(0.0029, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-8.8442e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.652238
Average KL loss: 0.348647
Average total loss: 1.000885
tensor(0.0029, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.5592e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.632125
Average KL loss: 0.350593
Average total loss: 0.982718
tensor(0.0028, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.4716e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.615862
Average KL loss: 0.352389
Average total loss: 0.968252
tensor(0.0028, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.0560e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.602028
Average KL loss: 0.354430
Average total loss: 0.956457
tensor(0.0028, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.2125e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.600861
Average KL loss: 0.357083
Average total loss: 0.957944
tensor(0.0028, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.6821e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.587557
Average KL loss: 0.359471
Average total loss: 0.947028
tensor(0.0028, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.3714e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.584704
Average KL loss: 0.361482
Average total loss: 0.946186
tensor(0.0028, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.1190e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.571705
Average KL loss: 0.363515
Average total loss: 0.935220
tensor(0.0028, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.0736e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.569663
Average KL loss: 0.365291
Average total loss: 0.934953
tensor(0.0028, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.2186e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.563293
Average KL loss: 0.366404
Average total loss: 0.929697
tensor(0.0028, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.2204e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.561332
Average KL loss: 0.367253
Average total loss: 0.928585
tensor(0.0028, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(1.2027e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.549210
Average KL loss: 0.368481
Average total loss: 0.917691
tensor(0.0028, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.5565e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.557505
Average KL loss: 0.369426
Average total loss: 0.926931
tensor(0.0028, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-6.8144e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.544378
Average KL loss: 0.370570
Average total loss: 0.914948
tensor(0.0028, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(5.5547e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.538489
Average KL loss: 0.371731
Average total loss: 0.910220
tensor(0.0028, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.5183e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.535467
Average KL loss: 0.372487
Average total loss: 0.907954
tensor(0.0028, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-7.0731e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.541390
Average KL loss: 0.373514
Average total loss: 0.914904
tensor(0.0028, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.7322e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.534972
Average KL loss: 0.374355
Average total loss: 0.909327
tensor(0.0028, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.8618e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.531572
Average KL loss: 0.374969
Average total loss: 0.906542
tensor(0.0028, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(1.3118e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.523916
Average KL loss: 0.375473
Average total loss: 0.899389
tensor(0.0028, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(1.7308e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.529147
Average KL loss: 0.375773
Average total loss: 0.904920
tensor(0.0028, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.3367e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.526412
Average KL loss: 0.376585
Average total loss: 0.902997
tensor(0.0028, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-7.0392e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.526259
Average KL loss: 0.377228
Average total loss: 0.903487
tensor(0.0028, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.4691e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.523691
Average KL loss: 0.377534
Average total loss: 0.901225
tensor(0.0028, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.7167e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.525619
Average KL loss: 0.378110
Average total loss: 0.903729
tensor(0.0029, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.5009e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.513841
Average KL loss: 0.378499
Average total loss: 0.892340
tensor(0.0028, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.4176e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.520647
Average KL loss: 0.378753
Average total loss: 0.899400
tensor(0.0029, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.6533e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.525677
Average KL loss: 0.379276
Average total loss: 0.904952
tensor(0.0029, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.1457e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.518760
Average KL loss: 0.379589
Average total loss: 0.898349
tensor(0.0029, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.8406e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.516690
Average KL loss: 0.379755
Average total loss: 0.896445
tensor(0.0029, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.1596e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.508972
Average KL loss: 0.380356
Average total loss: 0.889328
tensor(0.0029, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.9923e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.515216
Average KL loss: 0.380956
Average total loss: 0.896173
tensor(0.0029, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-7.0642e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.508578
Average KL loss: 0.381627
Average total loss: 0.890205
tensor(0.0029, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(4.9862e-11, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.511027
Average KL loss: 0.381547
Average total loss: 0.892574
tensor(0.0029, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.1549e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.511044
Average KL loss: 0.381572
Average total loss: 0.892615
tensor(0.0029, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.2759e-11, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.510554
Average KL loss: 0.381894
Average total loss: 0.892448
tensor(0.0029, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-8.1148e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.507404
Average KL loss: 0.382360
Average total loss: 0.889765
tensor(0.0029, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-8.9666e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.507082
Average KL loss: 0.382786
Average total loss: 0.889869
tensor(0.0029, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.5163e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.501611
Average KL loss: 0.383269
Average total loss: 0.884880
tensor(0.0029, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.6461e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.513207
Average KL loss: 0.383547
Average total loss: 0.896754
tensor(0.0029, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.1199e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.505011
Average KL loss: 0.383705
Average total loss: 0.888717
tensor(0.0029, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.1830e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.504123
Average KL loss: 0.383862
Average total loss: 0.887985
tensor(0.0029, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.7947e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.504653
Average KL loss: 0.383954
Average total loss: 0.888607
tensor(0.0029, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-7.4531e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.498545
Average KL loss: 0.384581
Average total loss: 0.883125
tensor(0.0029, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.1066e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.511255
Average KL loss: 0.384979
Average total loss: 0.896234
tensor(0.0029, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.2054e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.504064
Average KL loss: 0.385379
Average total loss: 0.889443
tensor(0.0029, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.0130e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.498784
Average KL loss: 0.385553
Average total loss: 0.884337
tensor(0.0029, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.2085e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.501627
Average KL loss: 0.385574
Average total loss: 0.887201
tensor(0.0029, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(6.0778e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.493135
Average KL loss: 0.385823
Average total loss: 0.878958
tensor(0.0029, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.8020e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.490303
Average KL loss: 0.385681
Average total loss: 0.875984
tensor(0.0029, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-9.9839e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.502208
Average KL loss: 0.385914
Average total loss: 0.888123
tensor(0.0029, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(9.1237e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.500420
Average KL loss: 0.386446
Average total loss: 0.886866
tensor(0.0029, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.9554e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.502954
Average KL loss: 0.386767
Average total loss: 0.889721
tensor(0.0029, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.1491e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.491595
Average KL loss: 0.387165
Average total loss: 0.878760
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(4.7632e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.491498
Average KL loss: 0.387060
Average total loss: 0.878558
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.9390e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.494435
Average KL loss: 0.387342
Average total loss: 0.881777
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.9130e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.492410
Average KL loss: 0.387550
Average total loss: 0.879959
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.0866e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.489581
Average KL loss: 0.387801
Average total loss: 0.877382
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.9033e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.489654
Average KL loss: 0.388159
Average total loss: 0.877813
tensor(0.0029, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.4440e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.489717
Average KL loss: 0.388106
Average total loss: 0.877823
tensor(0.0029, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(7.5306e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.487476
Average KL loss: 0.388326
Average total loss: 0.875801
tensor(0.0029, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.4339e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.478892
Average KL loss: 0.388717
Average total loss: 0.867609
tensor(0.0029, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.1851e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.494308
Average KL loss: 0.388622
Average total loss: 0.882929
tensor(0.0029, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.3447e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.490582
Average KL loss: 0.389055
Average total loss: 0.879637
tensor(0.0029, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-8.7168e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.485514
Average KL loss: 0.389587
Average total loss: 0.875101
tensor(0.0029, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0389e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.482949
Average KL loss: 0.390020
Average total loss: 0.872969
tensor(0.0029, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.9360e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.492785
Average KL loss: 0.389659
Average total loss: 0.882444
tensor(0.0029, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.9802e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.485941
Average KL loss: 0.389749
Average total loss: 0.875690
tensor(0.0029, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.0755e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.489464
Average KL loss: 0.389574
Average total loss: 0.879037
tensor(0.0029, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.2441e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.487827
Average KL loss: 0.389490
Average total loss: 0.877318
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-8.1905e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.481496
Average KL loss: 0.389670
Average total loss: 0.871166
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.0165e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.491423
Average KL loss: 0.389464
Average total loss: 0.880887
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.1606e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.484497
Average KL loss: 0.389808
Average total loss: 0.874305
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.6805e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.487092
Average KL loss: 0.389497
Average total loss: 0.876589
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.5047e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.480694
Average KL loss: 0.389032
Average total loss: 0.869726
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-8.6568e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.484115
Average KL loss: 0.388653
Average total loss: 0.872768
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.5529e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.480779
Average KL loss: 0.388313
Average total loss: 0.869093
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(3.6137e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.482887
Average KL loss: 0.387984
Average total loss: 0.870870
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(7.5296e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.485745
Average KL loss: 0.387682
Average total loss: 0.873427
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.6165e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.482192
Average KL loss: 0.387392
Average total loss: 0.869583
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-9.1605e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.481743
Average KL loss: 0.387131
Average total loss: 0.868874
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(5.2329e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.482577
Average KL loss: 0.386859
Average total loss: 0.869435
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.8390e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.490219
Average KL loss: 0.386646
Average total loss: 0.876865
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-9.5379e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.479653
Average KL loss: 0.386433
Average total loss: 0.866086
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(6.6052e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.483143
Average KL loss: 0.386227
Average total loss: 0.869370
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.3125e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.482732
Average KL loss: 0.386026
Average total loss: 0.868758
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.2223e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.486878
Average KL loss: 0.385833
Average total loss: 0.872711
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.5577e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.476269
Average KL loss: 0.385670
Average total loss: 0.861939
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.4317e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.478861
Average KL loss: 0.385459
Average total loss: 0.864321
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-8.6935e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.483841
Average KL loss: 0.385282
Average total loss: 0.869123
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.0503e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.487757
Average KL loss: 0.385109
Average total loss: 0.872866
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.7402e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.479856
Average KL loss: 0.384955
Average total loss: 0.864811
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.9179e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.488131
Average KL loss: 0.384804
Average total loss: 0.872935
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.2395e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.484745
Average KL loss: 0.384665
Average total loss: 0.869410
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.7543e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.488827
Average KL loss: 0.384549
Average total loss: 0.873376
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-8.4259e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.483608
Average KL loss: 0.384462
Average total loss: 0.868070
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.1021e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.488151
Average KL loss: 0.384368
Average total loss: 0.872519
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.4068e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.485408
Average KL loss: 0.384292
Average total loss: 0.869700
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(7.0502e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.481702
Average KL loss: 0.384194
Average total loss: 0.865895
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.0509e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.486460
Average KL loss: 0.384153
Average total loss: 0.870613
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.7633e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.487280
Average KL loss: 0.384137
Average total loss: 0.871416
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.9724e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.477991
Average KL loss: 0.384119
Average total loss: 0.862110
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.6767e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.491997
Average KL loss: 0.384099
Average total loss: 0.876096
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.2297e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.477868
Average KL loss: 0.384088
Average total loss: 0.861956
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.1857e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.484995
Average KL loss: 0.384073
Average total loss: 0.869068
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.4136e-11, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.488243
Average KL loss: 0.384059
Average total loss: 0.872302
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.9646e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.486807
Average KL loss: 0.384047
Average total loss: 0.870854
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.6565e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.477501
Average KL loss: 0.384032
Average total loss: 0.861533
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(6.5510e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.481753
Average KL loss: 0.384014
Average total loss: 0.865767
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.8101e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.486884
Average KL loss: 0.383994
Average total loss: 0.870878
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(3.2796e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.479388
Average KL loss: 0.383974
Average total loss: 0.863362
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.4472e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.485109
Average KL loss: 0.383953
Average total loss: 0.869062
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.0253e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.482023
Average KL loss: 0.383938
Average total loss: 0.865961
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.8067e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.487806
Average KL loss: 0.383922
Average total loss: 0.871728
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.7548e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.484181
Average KL loss: 0.383908
Average total loss: 0.868089
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-9.3174e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.484840
Average KL loss: 0.383892
Average total loss: 0.868732
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.9435e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.479676
Average KL loss: 0.383876
Average total loss: 0.863552
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.4367e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.485133
Average KL loss: 0.383855
Average total loss: 0.868988
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.4761e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.482586
Average KL loss: 0.383841
Average total loss: 0.866426
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.6440e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.484163
Average KL loss: 0.383834
Average total loss: 0.867997
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.6019e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.485933
Average KL loss: 0.383832
Average total loss: 0.869765
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.0190e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.485618
Average KL loss: 0.383831
Average total loss: 0.869449
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.3918e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.478917
Average KL loss: 0.383829
Average total loss: 0.862746
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.9865e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.481712
Average KL loss: 0.383827
Average total loss: 0.865539
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.8855e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.481208
Average KL loss: 0.383825
Average total loss: 0.865033
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.3553e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.481617
Average KL loss: 0.383824
Average total loss: 0.865440
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(7.2962e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.492218
Average KL loss: 0.383822
Average total loss: 0.876040
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.9351e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.480685
Average KL loss: 0.383820
Average total loss: 0.864506
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.2565e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.487602
Average KL loss: 0.383819
Average total loss: 0.871421
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.8380e-11, device='cuda:0')
 Percentile value: 7.986406416193859e-08
Non-zero model percentage: 13.42179012298584%, Non-zero mask percentage: 13.42179012298584%

--- Pruning Level [9/24]: ---
conv1.weight         | nonzeros =     314 /    1728             ( 18.17%) | total_pruned =    1414 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.weight           | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
bn1.bias             | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2903 /   36864             (  7.87%) | total_pruned =   33961 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4900 /   36864             ( 13.29%) | total_pruned =   31964 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3824 /   36864             ( 10.37%) | total_pruned =   33040 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4401 /   36864             ( 11.94%) | total_pruned =   32463 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4314 /   73728             (  5.85%) | total_pruned =   69414 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    7716 /  147456             (  5.23%) | total_pruned =  139740 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     703 /    8192             (  8.58%) | total_pruned =    7489 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    9749 /  147456             (  6.61%) | total_pruned =  137707 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   11750 /  147456             (  7.97%) | total_pruned =  135706 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   12087 /  294912             (  4.10%) | total_pruned =  282825 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      66 /     256             ( 25.78%) | total_pruned =     190 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   24022 /  589824             (  4.07%) | total_pruned =  565802 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2026 /   32768             (  6.18%) | total_pruned =   30742 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      81 /     256             ( 31.64%) | total_pruned =     175 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     158 /     256             ( 61.72%) | total_pruned =      98 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   23696 /  589824             (  4.02%) | total_pruned =  566128 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      87 /     256             ( 33.98%) | total_pruned =     169 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   31417 /  589824             (  5.33%) | total_pruned =  558407 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      80 /     256             ( 31.25%) | total_pruned =     176 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     133 /     256             ( 51.95%) | total_pruned =     123 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   36878 / 1179648             (  3.13%) | total_pruned = 1142770 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     128 /     512             ( 25.00%) | total_pruned =     384 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     439 /     512             ( 85.74%) | total_pruned =      73 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      34 /     512             (  6.64%) | total_pruned =     478 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  134876 / 2359296             (  5.72%) | total_pruned = 2224420 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     123 /     512             ( 24.02%) | total_pruned =     389 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     250 /     512             ( 48.83%) | total_pruned =     262 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      88 /     512             ( 17.19%) | total_pruned =     424 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    9447 /  131072             (  7.21%) | total_pruned =  121625 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     108 /     512             ( 21.09%) | total_pruned =     404 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     181 /     512             ( 35.35%) | total_pruned =     331 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      87 /     512             ( 16.99%) | total_pruned =     425 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  302353 / 2359296             ( 12.82%) | total_pruned = 2056943 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     121 /     512             ( 23.63%) | total_pruned =     391 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     237 /     512             ( 46.29%) | total_pruned =     275 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  864917 / 2359296             ( 36.66%) | total_pruned = 1494379 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     188 /     512             ( 36.72%) | total_pruned =     324 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     419 /     512             ( 81.84%) | total_pruned =      93 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     290 /     512             ( 56.64%) | total_pruned =     222 | shape = torch.Size([512])
linear.weight        | nonzeros =    3019 /    5120             ( 58.96%) | total_pruned =    2101 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 1500390, pruned : 9678372, total: 11178762, Compression rate :       7.45x  ( 86.58% pruned)
Train Epoch: 59/100 Loss: 0.044861 Accuracy: 86.07 100.00 % Best test Accuracy: 86.24%
tensor(0.0029, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.2225e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.847598
Average KL loss: 0.361965
Average total loss: 1.209562
tensor(0.0029, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.8835e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.781894
Average KL loss: 0.353880
Average total loss: 1.135773
tensor(0.0028, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.7753e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.744041
Average KL loss: 0.353927
Average total loss: 1.097968
tensor(0.0028, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.9007e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.724126
Average KL loss: 0.355981
Average total loss: 1.080107
tensor(0.0028, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.2732e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.710195
Average KL loss: 0.358409
Average total loss: 1.068604
tensor(0.0027, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.3290e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.691947
Average KL loss: 0.360437
Average total loss: 1.052384
tensor(0.0027, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.5777e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.669004
Average KL loss: 0.362141
Average total loss: 1.031145
tensor(0.0027, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-5.2393e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.649904
Average KL loss: 0.363950
Average total loss: 1.013854
tensor(0.0027, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.6670e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.642809
Average KL loss: 0.365845
Average total loss: 1.008655
tensor(0.0027, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5590e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.637977
Average KL loss: 0.367717
Average total loss: 1.005694
tensor(0.0027, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.5557e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.612384
Average KL loss: 0.369042
Average total loss: 0.981426
tensor(0.0027, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.0089e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.612060
Average KL loss: 0.370308
Average total loss: 0.982368
tensor(0.0027, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.2927e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.617924
Average KL loss: 0.371694
Average total loss: 0.989618
tensor(0.0027, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.4303e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.592934
Average KL loss: 0.373032
Average total loss: 0.965967
tensor(0.0027, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.8135e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.594324
Average KL loss: 0.373854
Average total loss: 0.968178
tensor(0.0027, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.1366e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.592841
Average KL loss: 0.374773
Average total loss: 0.967614
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.7815e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.588745
Average KL loss: 0.375608
Average total loss: 0.964354
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.9698e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.580494
Average KL loss: 0.376486
Average total loss: 0.956979
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(5.5402e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.583383
Average KL loss: 0.377330
Average total loss: 0.960712
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.6116e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.579516
Average KL loss: 0.377841
Average total loss: 0.957357
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.5159e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.581661
Average KL loss: 0.378771
Average total loss: 0.960432
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.5449e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.569062
Average KL loss: 0.379555
Average total loss: 0.948616
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.5574e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.562615
Average KL loss: 0.380332
Average total loss: 0.942947
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-9.4178e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.560160
Average KL loss: 0.380159
Average total loss: 0.940319
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.5525e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.562380
Average KL loss: 0.380291
Average total loss: 0.942671
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(3.6175e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.566597
Average KL loss: 0.380665
Average total loss: 0.947262
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(3.2398e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.564346
Average KL loss: 0.381188
Average total loss: 0.945534
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.5616e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.549857
Average KL loss: 0.381264
Average total loss: 0.931120
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(6.1250e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.553518
Average KL loss: 0.381548
Average total loss: 0.935065
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.3647e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.549668
Average KL loss: 0.382059
Average total loss: 0.931727
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.2516e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.546389
Average KL loss: 0.382858
Average total loss: 0.929247
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.0708e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.545888
Average KL loss: 0.383099
Average total loss: 0.928987
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(2.6329e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.547444
Average KL loss: 0.383578
Average total loss: 0.931022
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.0605e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.547478
Average KL loss: 0.383834
Average total loss: 0.931312
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(1.6523e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.538218
Average KL loss: 0.383830
Average total loss: 0.922048
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.1621e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.551067
Average KL loss: 0.384012
Average total loss: 0.935079
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-9.3309e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.538139
Average KL loss: 0.384599
Average total loss: 0.922738
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.7894e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.534471
Average KL loss: 0.384991
Average total loss: 0.919462
tensor(0.0027, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.2795e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.532188
Average KL loss: 0.385221
Average total loss: 0.917409
tensor(0.0027, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.7538e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.542131
Average KL loss: 0.385966
Average total loss: 0.928096
tensor(0.0027, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.3915e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.534178
Average KL loss: 0.386063
Average total loss: 0.920241
tensor(0.0027, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.0588e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.536056
Average KL loss: 0.386230
Average total loss: 0.922286
tensor(0.0027, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.3207e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.534973
Average KL loss: 0.387070
Average total loss: 0.922043
tensor(0.0027, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.2487e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.531657
Average KL loss: 0.387125
Average total loss: 0.918782
tensor(0.0027, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-7.2539e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.536547
Average KL loss: 0.387229
Average total loss: 0.923776
tensor(0.0027, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.8707e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.523794
Average KL loss: 0.387452
Average total loss: 0.911247
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.3164e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.530218
Average KL loss: 0.387841
Average total loss: 0.918059
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.5272e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.526447
Average KL loss: 0.388092
Average total loss: 0.914540
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.0508e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.524004
Average KL loss: 0.388291
Average total loss: 0.912295
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(2.9013e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.520171
Average KL loss: 0.388282
Average total loss: 0.908453
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-6.8009e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.520264
Average KL loss: 0.388411
Average total loss: 0.908675
tensor(0.0027, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(1.8347e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.521134
Average KL loss: 0.388574
Average total loss: 0.909707
tensor(0.0027, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.5640e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.518395
Average KL loss: 0.388446
Average total loss: 0.906840
tensor(0.0027, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.0657e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.521668
Average KL loss: 0.388882
Average total loss: 0.910549
tensor(0.0028, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-7.4827e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.515855
Average KL loss: 0.389343
Average total loss: 0.905197
tensor(0.0028, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-9.7413e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.515945
Average KL loss: 0.389639
Average total loss: 0.905584
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.4990e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.522918
Average KL loss: 0.389795
Average total loss: 0.912713
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.2513e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.518727
Average KL loss: 0.390329
Average total loss: 0.909056
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.5126e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.516143
Average KL loss: 0.390371
Average total loss: 0.906515
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.6744e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.519415
Average KL loss: 0.391196
Average total loss: 0.910612
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.2199e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.521817
Average KL loss: 0.391205
Average total loss: 0.913023
tensor(0.0028, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.4878e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.523259
Average KL loss: 0.391610
Average total loss: 0.914869
tensor(0.0028, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(9.0413e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.510489
Average KL loss: 0.391836
Average total loss: 0.902326
tensor(0.0028, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.7646e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.516145
Average KL loss: 0.391772
Average total loss: 0.907917
tensor(0.0028, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.4375e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.512754
Average KL loss: 0.391951
Average total loss: 0.904705
tensor(0.0028, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.2569e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.519416
Average KL loss: 0.392477
Average total loss: 0.911893
tensor(0.0028, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.7002e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.507888
Average KL loss: 0.392579
Average total loss: 0.900466
tensor(0.0028, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.5858e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.510636
Average KL loss: 0.392393
Average total loss: 0.903029
tensor(0.0028, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.9330e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.511165
Average KL loss: 0.392964
Average total loss: 0.904128
tensor(0.0028, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.7590e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.507072
Average KL loss: 0.392840
Average total loss: 0.899912
tensor(0.0028, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.6880e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.511030
Average KL loss: 0.392947
Average total loss: 0.903977
tensor(0.0028, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.7177e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.509238
Average KL loss: 0.393139
Average total loss: 0.902377
tensor(0.0028, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.2297e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.507723
Average KL loss: 0.393579
Average total loss: 0.901303
tensor(0.0028, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(5.8073e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.502203
Average KL loss: 0.393652
Average total loss: 0.895855
tensor(0.0028, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.6818e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.502232
Average KL loss: 0.393673
Average total loss: 0.895905
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.7004e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.498352
Average KL loss: 0.393783
Average total loss: 0.892135
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.6714e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.512100
Average KL loss: 0.393531
Average total loss: 0.905631
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.4599e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.506155
Average KL loss: 0.393871
Average total loss: 0.900026
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.3992e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.503075
Average KL loss: 0.393963
Average total loss: 0.897038
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.3848e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.510356
Average KL loss: 0.394452
Average total loss: 0.904808
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-6.0482e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.507997
Average KL loss: 0.394763
Average total loss: 0.902761
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.8816e-11, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.507907
Average KL loss: 0.394996
Average total loss: 0.902903
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.5740e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.509737
Average KL loss: 0.395189
Average total loss: 0.904927
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.9081e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.501737
Average KL loss: 0.395441
Average total loss: 0.897178
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.7029e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.499397
Average KL loss: 0.395364
Average total loss: 0.894761
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-9.3209e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.500356
Average KL loss: 0.395269
Average total loss: 0.895625
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(7.5587e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.500374
Average KL loss: 0.395157
Average total loss: 0.895532
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.6668e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.501087
Average KL loss: 0.394949
Average total loss: 0.896036
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.0253e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.501363
Average KL loss: 0.394674
Average total loss: 0.896038
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.4580e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.500798
Average KL loss: 0.394411
Average total loss: 0.895209
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.3841e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.504628
Average KL loss: 0.394153
Average total loss: 0.898781
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.3504e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.494467
Average KL loss: 0.393967
Average total loss: 0.888434
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1429e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.504612
Average KL loss: 0.393793
Average total loss: 0.898404
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(7.6915e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.499291
Average KL loss: 0.393605
Average total loss: 0.892896
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.0131e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.502066
Average KL loss: 0.393451
Average total loss: 0.895518
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(6.1437e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.504623
Average KL loss: 0.393300
Average total loss: 0.897923
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.7390e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.499322
Average KL loss: 0.393144
Average total loss: 0.892466
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.5291e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.497788
Average KL loss: 0.392981
Average total loss: 0.890769
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(4.2428e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.493971
Average KL loss: 0.392833
Average total loss: 0.886804
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.3297e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.498623
Average KL loss: 0.392663
Average total loss: 0.891286
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.3839e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.495861
Average KL loss: 0.392521
Average total loss: 0.888382
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.3618e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.512600
Average KL loss: 0.392389
Average total loss: 0.904989
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.7483e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.494945
Average KL loss: 0.392273
Average total loss: 0.887218
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.9920e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.496997
Average KL loss: 0.392149
Average total loss: 0.889146
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.6137e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.505358
Average KL loss: 0.392056
Average total loss: 0.897414
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(4.0867e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.496801
Average KL loss: 0.391947
Average total loss: 0.888748
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.0521e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.502889
Average KL loss: 0.391851
Average total loss: 0.894740
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.9597e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.494480
Average KL loss: 0.391752
Average total loss: 0.886232
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.0225e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.503894
Average KL loss: 0.391654
Average total loss: 0.895548
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.0238e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.498623
Average KL loss: 0.391554
Average total loss: 0.890177
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.5202e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.500781
Average KL loss: 0.391467
Average total loss: 0.892247
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.4855e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.497680
Average KL loss: 0.391369
Average total loss: 0.889048
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.6391e-11, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.497250
Average KL loss: 0.391230
Average total loss: 0.888480
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.6571e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.500397
Average KL loss: 0.391122
Average total loss: 0.891519
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.9853e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.498150
Average KL loss: 0.391034
Average total loss: 0.889184
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.3408e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.499731
Average KL loss: 0.390932
Average total loss: 0.890662
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.3867e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.492900
Average KL loss: 0.390847
Average total loss: 0.883747
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.2381e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.499546
Average KL loss: 0.390725
Average total loss: 0.890271
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.4551e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.496513
Average KL loss: 0.390668
Average total loss: 0.887181
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.1900e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.507910
Average KL loss: 0.390575
Average total loss: 0.898485
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.5028e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.500749
Average KL loss: 0.390493
Average total loss: 0.891242
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.0988e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.499759
Average KL loss: 0.390407
Average total loss: 0.890167
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(4.9669e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.494425
Average KL loss: 0.390283
Average total loss: 0.884708
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.2050e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.500245
Average KL loss: 0.390191
Average total loss: 0.890436
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.0925e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.491697
Average KL loss: 0.390145
Average total loss: 0.881842
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.2069e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.498621
Average KL loss: 0.390092
Average total loss: 0.888713
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.7465e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.501360
Average KL loss: 0.390029
Average total loss: 0.891388
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.3916e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.499145
Average KL loss: 0.389966
Average total loss: 0.889111
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.1672e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.495344
Average KL loss: 0.389907
Average total loss: 0.885251
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.0308e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.497105
Average KL loss: 0.389833
Average total loss: 0.886939
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.3254e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.495997
Average KL loss: 0.389764
Average total loss: 0.885761
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.1554e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.508853
Average KL loss: 0.389665
Average total loss: 0.898518
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.2035e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.506705
Average KL loss: 0.389630
Average total loss: 0.896336
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.1092e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.501828
Average KL loss: 0.389568
Average total loss: 0.891395
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(7.2260e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.511970
Average KL loss: 0.389521
Average total loss: 0.901491
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.8670e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.495038
Average KL loss: 0.389483
Average total loss: 0.884521
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.0632e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.498186
Average KL loss: 0.389450
Average total loss: 0.887636
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.3259e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.500503
Average KL loss: 0.389445
Average total loss: 0.889948
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.7239e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.504976
Average KL loss: 0.389439
Average total loss: 0.894415
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.3681e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.495459
Average KL loss: 0.389430
Average total loss: 0.884890
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.6620e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.492159
Average KL loss: 0.389422
Average total loss: 0.881580
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.4003e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.503339
Average KL loss: 0.389408
Average total loss: 0.892747
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.1688e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.496097
Average KL loss: 0.389399
Average total loss: 0.885495
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-9.3204e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.493308
Average KL loss: 0.389390
Average total loss: 0.882697
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.2178e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.500416
Average KL loss: 0.389382
Average total loss: 0.889798
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.4532e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.496254
Average KL loss: 0.389375
Average total loss: 0.885629
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.8673e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.499717
Average KL loss: 0.389367
Average total loss: 0.889084
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.3981e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.494929
Average KL loss: 0.389360
Average total loss: 0.884289
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.8483e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.502726
Average KL loss: 0.389351
Average total loss: 0.892076
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.0918e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.496263
Average KL loss: 0.389338
Average total loss: 0.885601
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-9.1655e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.499842
Average KL loss: 0.389329
Average total loss: 0.889170
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.7101e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.505006
Average KL loss: 0.389322
Average total loss: 0.894328
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.0986e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.498561
Average KL loss: 0.389319
Average total loss: 0.887880
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.7954e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.498630
Average KL loss: 0.389318
Average total loss: 0.887948
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(4.1324e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.498573
Average KL loss: 0.389317
Average total loss: 0.887890
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.6922e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.500823
Average KL loss: 0.389317
Average total loss: 0.890140
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(9.9106e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.496354
Average KL loss: 0.389316
Average total loss: 0.885669
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.3628e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.495640
Average KL loss: 0.389315
Average total loss: 0.884955
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.5580e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.502005
Average KL loss: 0.389314
Average total loss: 0.891319
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.5397e-11, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.501873
Average KL loss: 0.389313
Average total loss: 0.891186
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.6064e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.500062
Average KL loss: 0.389312
Average total loss: 0.889375
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.8334e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.494179
Average KL loss: 0.389312
Average total loss: 0.883491
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1603e-09, device='cuda:0')
 Percentile value: 8.012311525362747e-08
Non-zero model percentage: 10.737431526184082%, Non-zero mask percentage: 10.737431526184082%

--- Pruning Level [10/24]: ---
conv1.weight         | nonzeros =     296 /    1728             ( 17.13%) | total_pruned =    1432 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.weight           | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
bn1.bias             | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2777 /   36864             (  7.53%) | total_pruned =   34087 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4496 /   36864             ( 12.20%) | total_pruned =   32368 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3557 /   36864             (  9.65%) | total_pruned =   33307 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3975 /   36864             ( 10.78%) | total_pruned =   32889 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3649 /   73728             (  4.95%) | total_pruned =   70079 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      34 /     128             ( 26.56%) | total_pruned =      94 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    6674 /  147456             (  4.53%) | total_pruned =  140782 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     607 /    8192             (  7.41%) | total_pruned =    7585 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8621 /  147456             (  5.85%) | total_pruned =  138835 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   10389 /  147456             (  7.05%) | total_pruned =  137067 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   10399 /  294912             (  3.53%) | total_pruned =  284513 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      60 /     256             ( 23.44%) | total_pruned =     196 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   21061 /  589824             (  3.57%) | total_pruned =  568763 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      62 /     256             ( 24.22%) | total_pruned =     194 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1769 /   32768             (  5.40%) | total_pruned =   30999 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     150 /     256             ( 58.59%) | total_pruned =     106 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   20246 /  589824             (  3.43%) | total_pruned =  569578 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   26386 /  589824             (  4.47%) | total_pruned =  563438 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      66 /     256             ( 25.78%) | total_pruned =     190 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     122 /     256             ( 47.66%) | total_pruned =     134 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   31140 / 1179648             (  2.64%) | total_pruned = 1148508 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     106 /     512             ( 20.70%) | total_pruned =     406 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     424 /     512             ( 82.81%) | total_pruned =      88 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  115943 / 2359296             (  4.91%) | total_pruned = 2243353 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      96 /     512             ( 18.75%) | total_pruned =     416 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     229 /     512             ( 44.73%) | total_pruned =     283 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      81 /     512             ( 15.82%) | total_pruned =     431 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    7915 /  131072             (  6.04%) | total_pruned =  123157 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      96 /     512             ( 18.75%) | total_pruned =     416 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     154 /     512             ( 30.08%) | total_pruned =     358 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      80 /     512             ( 15.62%) | total_pruned =     432 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  247550 / 2359296             ( 10.49%) | total_pruned = 2111746 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     112 /     512             ( 21.88%) | total_pruned =     400 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     209 /     512             ( 40.82%) | total_pruned =     303 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  665517 / 2359296             ( 28.21%) | total_pruned = 1693779 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     166 /     512             ( 32.42%) | total_pruned =     346 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     381 /     512             ( 74.41%) | total_pruned =     131 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     255 /     512             ( 49.80%) | total_pruned =     257 | shape = torch.Size([512])
linear.weight        | nonzeros =    2681 /    5120             ( 52.36%) | total_pruned =    2439 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 1200312, pruned : 9978450, total: 11178762, Compression rate :       9.31x  ( 89.26% pruned)
Train Epoch: 78/100 Loss: 0.046035 Accuracy: 84.91 99.98 % Best test Accuracy: 85.69%
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.9256e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.758150
Average KL loss: 0.371087
Average total loss: 1.129237
tensor(0.0028, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.7901e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.708938
Average KL loss: 0.364285
Average total loss: 1.073223
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.4451e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.688132
Average KL loss: 0.364817
Average total loss: 1.052949
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.1962e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.675002
Average KL loss: 0.366493
Average total loss: 1.041494
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.0748e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.662081
Average KL loss: 0.368754
Average total loss: 1.030835
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.1581e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.636237
Average KL loss: 0.370708
Average total loss: 1.006945
tensor(0.0027, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.2589e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.647099
Average KL loss: 0.372732
Average total loss: 1.019831
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.6979e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.621104
Average KL loss: 0.374788
Average total loss: 0.995892
tensor(0.0027, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.1811e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.615129
Average KL loss: 0.376771
Average total loss: 0.991901
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.6828e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.627702
Average KL loss: 0.378635
Average total loss: 1.006337
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.3257e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.597507
Average KL loss: 0.380263
Average total loss: 0.977771
tensor(0.0027, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.5171e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.596758
Average KL loss: 0.381535
Average total loss: 0.978293
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.0378e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.590164
Average KL loss: 0.382601
Average total loss: 0.972765
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.5578e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.590443
Average KL loss: 0.384146
Average total loss: 0.974589
tensor(0.0027, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.3075e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.590162
Average KL loss: 0.385485
Average total loss: 0.975647
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.2810e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.580322
Average KL loss: 0.386667
Average total loss: 0.966989
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.6163e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.573409
Average KL loss: 0.387780
Average total loss: 0.961188
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.6253e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.573485
Average KL loss: 0.388448
Average total loss: 0.961934
tensor(0.0027, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.6420e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.565973
Average KL loss: 0.389384
Average total loss: 0.955356
tensor(0.0027, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.9107e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.573930
Average KL loss: 0.390285
Average total loss: 0.964215
tensor(0.0027, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(1.7175e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.572706
Average KL loss: 0.391144
Average total loss: 0.963850
tensor(0.0027, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.4848e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.560053
Average KL loss: 0.391845
Average total loss: 0.951898
tensor(0.0027, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.8384e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.554807
Average KL loss: 0.392418
Average total loss: 0.947225
tensor(0.0027, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.3805e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.556128
Average KL loss: 0.392727
Average total loss: 0.948855
tensor(0.0027, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.4861e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.547555
Average KL loss: 0.393370
Average total loss: 0.940925
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-6.8696e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.549064
Average KL loss: 0.394254
Average total loss: 0.943319
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.2842e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.549773
Average KL loss: 0.394870
Average total loss: 0.944643
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-7.1065e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.551456
Average KL loss: 0.395213
Average total loss: 0.946669
tensor(0.0027, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.2962e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.543847
Average KL loss: 0.395468
Average total loss: 0.939315
tensor(0.0027, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(3.2042e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.553434
Average KL loss: 0.396085
Average total loss: 0.949519
tensor(0.0027, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-8.0096e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.550576
Average KL loss: 0.396471
Average total loss: 0.947047
tensor(0.0027, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.9381e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.535293
Average KL loss: 0.396931
Average total loss: 0.932224
tensor(0.0027, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.3687e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.551925
Average KL loss: 0.397195
Average total loss: 0.949120
tensor(0.0027, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(8.3377e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.540982
Average KL loss: 0.397505
Average total loss: 0.938487
tensor(0.0027, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.3508e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.542626
Average KL loss: 0.397972
Average total loss: 0.940598
tensor(0.0027, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.3531e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.538504
Average KL loss: 0.398402
Average total loss: 0.936906
tensor(0.0027, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9646e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.533664
Average KL loss: 0.398789
Average total loss: 0.932453
tensor(0.0027, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.0023e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.535042
Average KL loss: 0.398935
Average total loss: 0.933977
tensor(0.0027, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.0567e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.530168
Average KL loss: 0.399316
Average total loss: 0.929484
tensor(0.0027, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.1560e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.529975
Average KL loss: 0.399803
Average total loss: 0.929778
tensor(0.0027, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.6560e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.528403
Average KL loss: 0.400189
Average total loss: 0.928592
tensor(0.0027, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.6426e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.532995
Average KL loss: 0.400433
Average total loss: 0.933428
tensor(0.0027, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.8243e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.529728
Average KL loss: 0.400741
Average total loss: 0.930469
tensor(0.0027, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.6550e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.519875
Average KL loss: 0.400926
Average total loss: 0.920800
tensor(0.0027, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.3365e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.523981
Average KL loss: 0.401092
Average total loss: 0.925073
tensor(0.0027, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.2858e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.524006
Average KL loss: 0.401321
Average total loss: 0.925326
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.7245e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.522085
Average KL loss: 0.401593
Average total loss: 0.923678
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.5468e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.524163
Average KL loss: 0.401909
Average total loss: 0.926073
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.2933e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.515191
Average KL loss: 0.402319
Average total loss: 0.917510
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.2495e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.522159
Average KL loss: 0.402571
Average total loss: 0.924730
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.5508e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.520743
Average KL loss: 0.402889
Average total loss: 0.923632
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.4638e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.521607
Average KL loss: 0.403054
Average total loss: 0.924661
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.0236e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.518213
Average KL loss: 0.403286
Average total loss: 0.921499
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.3063e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.517725
Average KL loss: 0.403598
Average total loss: 0.921322
tensor(0.0028, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.0389e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.514990
Average KL loss: 0.403916
Average total loss: 0.918907
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.6234e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.516140
Average KL loss: 0.404340
Average total loss: 0.920481
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.2455e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.508561
Average KL loss: 0.404765
Average total loss: 0.913326
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.7179e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.513894
Average KL loss: 0.404848
Average total loss: 0.918742
tensor(0.0028, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.7990e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.519190
Average KL loss: 0.404533
Average total loss: 0.923723
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1510e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.511825
Average KL loss: 0.404470
Average total loss: 0.916295
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.6626e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.517122
Average KL loss: 0.404833
Average total loss: 0.921955
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.3989e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.509936
Average KL loss: 0.405185
Average total loss: 0.915121
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1240e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.512597
Average KL loss: 0.405481
Average total loss: 0.918078
tensor(0.0028, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1859e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.506248
Average KL loss: 0.405487
Average total loss: 0.911735
tensor(0.0028, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.4420e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.510147
Average KL loss: 0.405611
Average total loss: 0.915758
tensor(0.0028, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-9.6321e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.501342
Average KL loss: 0.405973
Average total loss: 0.907316
tensor(0.0028, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.0048e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.510016
Average KL loss: 0.406211
Average total loss: 0.916227
tensor(0.0028, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.6794e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.507145
Average KL loss: 0.406397
Average total loss: 0.913542
tensor(0.0028, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(3.1103e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.498657
Average KL loss: 0.406340
Average total loss: 0.904997
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.3739e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.509479
Average KL loss: 0.406377
Average total loss: 0.915855
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-8.9101e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.505616
Average KL loss: 0.406954
Average total loss: 0.912570
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.1755e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.508900
Average KL loss: 0.407242
Average total loss: 0.916142
tensor(0.0028, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.3368e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.515953
Average KL loss: 0.407399
Average total loss: 0.923352
tensor(0.0028, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.7799e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.509550
Average KL loss: 0.407675
Average total loss: 0.917225
tensor(0.0028, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.8482e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.505736
Average KL loss: 0.407863
Average total loss: 0.913599
tensor(0.0028, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.7417e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.511047
Average KL loss: 0.408191
Average total loss: 0.919238
tensor(0.0028, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.7659e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.501281
Average KL loss: 0.408517
Average total loss: 0.909799
tensor(0.0028, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-9.9422e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.508807
Average KL loss: 0.408394
Average total loss: 0.917200
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.5405e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.506648
Average KL loss: 0.408449
Average total loss: 0.915097
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.1730e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.503854
Average KL loss: 0.408565
Average total loss: 0.912420
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.4810e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.500524
Average KL loss: 0.408721
Average total loss: 0.909245
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.9147e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.505624
Average KL loss: 0.408521
Average total loss: 0.914145
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.0013e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.508800
Average KL loss: 0.408358
Average total loss: 0.917158
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.4778e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.498345
Average KL loss: 0.408212
Average total loss: 0.906558
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-9.1810e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.498672
Average KL loss: 0.408058
Average total loss: 0.906730
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.7006e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.495251
Average KL loss: 0.407907
Average total loss: 0.903157
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.6447e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.499687
Average KL loss: 0.407757
Average total loss: 0.907443
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.7140e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.501893
Average KL loss: 0.407610
Average total loss: 0.909503
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.0351e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.501711
Average KL loss: 0.407506
Average total loss: 0.909218
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(5.8184e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.504986
Average KL loss: 0.407381
Average total loss: 0.912367
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.9417e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.498340
Average KL loss: 0.407255
Average total loss: 0.905595
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.8993e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.501132
Average KL loss: 0.407115
Average total loss: 0.908247
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.1241e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.496931
Average KL loss: 0.407050
Average total loss: 0.903981
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.5627e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.500224
Average KL loss: 0.406966
Average total loss: 0.907191
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-7.1408e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.508229
Average KL loss: 0.406878
Average total loss: 0.915107
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.2633e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.499921
Average KL loss: 0.406808
Average total loss: 0.906729
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.0247e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.503133
Average KL loss: 0.406718
Average total loss: 0.909851
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-7.3706e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.495836
Average KL loss: 0.406645
Average total loss: 0.902481
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-9.8659e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.501556
Average KL loss: 0.406636
Average total loss: 0.908192
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.6164e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.495208
Average KL loss: 0.406627
Average total loss: 0.901835
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.4667e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.505826
Average KL loss: 0.406612
Average total loss: 0.912438
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.1523e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.497587
Average KL loss: 0.406601
Average total loss: 0.904188
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.9171e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.501461
Average KL loss: 0.406592
Average total loss: 0.908053
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.8619e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.500839
Average KL loss: 0.406588
Average total loss: 0.907427
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.6928e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.507239
Average KL loss: 0.406577
Average total loss: 0.913817
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.1437e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.500101
Average KL loss: 0.406566
Average total loss: 0.906667
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.2800e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.504549
Average KL loss: 0.406559
Average total loss: 0.911108
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.7962e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.498594
Average KL loss: 0.406551
Average total loss: 0.905145
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(4.6639e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.503095
Average KL loss: 0.406543
Average total loss: 0.909638
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.2736e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.497838
Average KL loss: 0.406530
Average total loss: 0.904369
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.6111e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.506700
Average KL loss: 0.406522
Average total loss: 0.913222
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.6752e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.502981
Average KL loss: 0.406517
Average total loss: 0.909498
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.0890e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.507077
Average KL loss: 0.406516
Average total loss: 0.913593
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.8019e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.497580
Average KL loss: 0.406515
Average total loss: 0.904095
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.1186e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.504940
Average KL loss: 0.406513
Average total loss: 0.911453
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.6517e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.512491
Average KL loss: 0.406513
Average total loss: 0.919003
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-9.1389e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.499836
Average KL loss: 0.406511
Average total loss: 0.906347
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.6794e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.496521
Average KL loss: 0.406510
Average total loss: 0.903031
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-7.3438e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.504034
Average KL loss: 0.406509
Average total loss: 0.910543
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.0390e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.507370
Average KL loss: 0.406508
Average total loss: 0.913879
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.2636e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.505649
Average KL loss: 0.406507
Average total loss: 0.912157
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.5352e-10, device='cuda:0')
 Percentile value: 8.025394038213562e-08
Non-zero model percentage: 8.589949607849121%, Non-zero mask percentage: 8.589949607849121%

--- Pruning Level [11/24]: ---
conv1.weight         | nonzeros =     287 /    1728             ( 16.61%) | total_pruned =    1441 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
bn1.weight           | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
bn1.bias             | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2710 /   36864             (  7.35%) | total_pruned =   34154 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4355 /   36864             ( 11.81%) | total_pruned =   32509 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3442 /   36864             (  9.34%) | total_pruned =   33422 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3769 /   36864             ( 10.22%) | total_pruned =   33095 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3216 /   73728             (  4.36%) | total_pruned =   70512 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    5976 /  147456             (  4.05%) | total_pruned =  141480 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     539 /    8192             (  6.58%) | total_pruned =    7653 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8086 /  147456             (  5.48%) | total_pruned =  139370 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    9822 /  147456             (  6.66%) | total_pruned =  137634 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    9342 /  294912             (  3.17%) | total_pruned =  285570 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   19031 /  589824             (  3.23%) | total_pruned =  570793 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      34 /     256             ( 13.28%) | total_pruned =     222 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1560 /   32768             (  4.76%) | total_pruned =   31208 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     141 /     256             ( 55.08%) | total_pruned =     115 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   18157 /  589824             (  3.08%) | total_pruned =  571667 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      49 /     256             ( 19.14%) | total_pruned =     207 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     195 /     256             ( 76.17%) | total_pruned =      61 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   23693 /  589824             (  4.02%) | total_pruned =  566131 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     117 /     256             ( 45.70%) | total_pruned =     139 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   27220 / 1179648             (  2.31%) | total_pruned = 1152428 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      60 /     512             ( 11.72%) | total_pruned =     452 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  103079 / 2359296             (  4.37%) | total_pruned = 2256217 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      69 /     512             ( 13.48%) | total_pruned =     443 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     206 /     512             ( 40.23%) | total_pruned =     306 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    6889 /  131072             (  5.26%) | total_pruned =  124183 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      74 /     512             ( 14.45%) | total_pruned =     438 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      65 /     512             ( 12.70%) | total_pruned =     447 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  226491 / 2359296             (  9.60%) | total_pruned = 2132805 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      89 /     512             ( 17.38%) | total_pruned =     423 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     174 /     512             ( 33.98%) | total_pruned =     338 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  476420 / 2359296             ( 20.19%) | total_pruned = 1882876 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     142 /     512             ( 27.73%) | total_pruned =     370 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     311 /     512             ( 60.74%) | total_pruned =     201 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     216 /     512             ( 42.19%) | total_pruned =     296 | shape = torch.Size([512])
linear.weight        | nonzeros =    2164 /    5120             ( 42.27%) | total_pruned =    2956 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 960250, pruned : 10218512, total: 11178762, Compression rate :      11.64x  ( 91.41% pruned)
Train Epoch: 99/100 Loss: 0.080701 Accuracy: 82.93 99.91 % Best test Accuracy: 85.03%
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.5642e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.842150
Average KL loss: 0.387402
Average total loss: 1.229552
tensor(0.0027, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.5144e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.799890
Average KL loss: 0.377825
Average total loss: 1.177716
tensor(0.0027, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.3629e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.756560
Average KL loss: 0.376487
Average total loss: 1.133047
tensor(0.0027, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.6297e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.740612
Average KL loss: 0.376668
Average total loss: 1.117280
tensor(0.0026, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.2397e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.725303
Average KL loss: 0.378152
Average total loss: 1.103455
tensor(0.0026, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.4311e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.699273
Average KL loss: 0.379575
Average total loss: 1.078848
tensor(0.0026, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.3314e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.695124
Average KL loss: 0.380854
Average total loss: 1.075978
tensor(0.0026, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.0460e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.685916
Average KL loss: 0.382657
Average total loss: 1.068573
tensor(0.0026, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.1775e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.673310
Average KL loss: 0.384876
Average total loss: 1.058187
tensor(0.0026, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-6.1374e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.652898
Average KL loss: 0.386652
Average total loss: 1.039550
tensor(0.0026, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.5610e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.657806
Average KL loss: 0.388058
Average total loss: 1.045864
tensor(0.0026, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.2972e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.647415
Average KL loss: 0.389451
Average total loss: 1.036867
tensor(0.0026, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.9333e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.643614
Average KL loss: 0.391008
Average total loss: 1.034621
tensor(0.0026, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.7419e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.640730
Average KL loss: 0.392633
Average total loss: 1.033362
tensor(0.0026, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.1937e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.632694
Average KL loss: 0.393881
Average total loss: 1.026575
tensor(0.0026, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-7.8007e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.619115
Average KL loss: 0.394955
Average total loss: 1.014069
tensor(0.0026, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.2832e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.625090
Average KL loss: 0.395870
Average total loss: 1.020960
tensor(0.0026, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.0682e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.619526
Average KL loss: 0.397141
Average total loss: 1.016667
tensor(0.0026, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-9.0720e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.604171
Average KL loss: 0.398247
Average total loss: 1.002419
tensor(0.0026, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-7.8181e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.603949
Average KL loss: 0.398952
Average total loss: 1.002900
tensor(0.0026, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.3914e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.612322
Average KL loss: 0.399572
Average total loss: 1.011894
tensor(0.0026, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-8.9438e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.606661
Average KL loss: 0.400504
Average total loss: 1.007165
tensor(0.0026, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.1136e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.597011
Average KL loss: 0.401377
Average total loss: 0.998388
tensor(0.0026, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.7177e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.594728
Average KL loss: 0.402151
Average total loss: 0.996878
tensor(0.0026, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.8755e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.601923
Average KL loss: 0.403045
Average total loss: 1.004967
tensor(0.0026, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.1915e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.595533
Average KL loss: 0.403806
Average total loss: 0.999339
tensor(0.0027, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.5650e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.589797
Average KL loss: 0.404387
Average total loss: 0.994184
tensor(0.0027, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.8464e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.580718
Average KL loss: 0.404705
Average total loss: 0.985422
tensor(0.0027, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.0285e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.585083
Average KL loss: 0.405084
Average total loss: 0.990167
tensor(0.0027, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.3210e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.584080
Average KL loss: 0.405944
Average total loss: 0.990024
tensor(0.0027, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0325e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.575723
Average KL loss: 0.406609
Average total loss: 0.982331
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.1065e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.576118
Average KL loss: 0.407025
Average total loss: 0.983143
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-9.7418e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.568519
Average KL loss: 0.407639
Average total loss: 0.976158
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.1094e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.574930
Average KL loss: 0.408135
Average total loss: 0.983065
tensor(0.0027, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.1216e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.578731
Average KL loss: 0.408844
Average total loss: 0.987576
tensor(0.0027, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.2926e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.580394
Average KL loss: 0.409560
Average total loss: 0.989954
tensor(0.0027, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.4351e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.561126
Average KL loss: 0.409829
Average total loss: 0.970955
tensor(0.0027, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.6755e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.561378
Average KL loss: 0.410250
Average total loss: 0.971628
tensor(0.0027, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.0190e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.559403
Average KL loss: 0.410514
Average total loss: 0.969917
tensor(0.0027, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.8926e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.557526
Average KL loss: 0.410967
Average total loss: 0.968493
tensor(0.0027, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.9012e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.561752
Average KL loss: 0.411247
Average total loss: 0.972999
tensor(0.0027, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.0161e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.555420
Average KL loss: 0.411656
Average total loss: 0.967077
tensor(0.0027, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.7782e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.552220
Average KL loss: 0.412470
Average total loss: 0.964690
tensor(0.0027, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.0697e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.555812
Average KL loss: 0.412947
Average total loss: 0.968760
tensor(0.0027, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.6383e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.554073
Average KL loss: 0.413556
Average total loss: 0.967630
tensor(0.0027, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.2710e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.554649
Average KL loss: 0.413976
Average total loss: 0.968624
tensor(0.0027, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.0620e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.545900
Average KL loss: 0.414490
Average total loss: 0.960390
tensor(0.0027, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.8938e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.556502
Average KL loss: 0.414924
Average total loss: 0.971426
tensor(0.0027, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.8963e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.542130
Average KL loss: 0.415276
Average total loss: 0.957407
tensor(0.0027, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.9082e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.544931
Average KL loss: 0.415600
Average total loss: 0.960531
tensor(0.0027, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.6050e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.552005
Average KL loss: 0.415767
Average total loss: 0.967771
tensor(0.0027, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.6341e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.542857
Average KL loss: 0.416227
Average total loss: 0.959084
tensor(0.0027, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.2297e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.545421
Average KL loss: 0.416573
Average total loss: 0.961993
tensor(0.0027, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.8155e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.545252
Average KL loss: 0.416912
Average total loss: 0.962164
tensor(0.0027, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.9781e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.546530
Average KL loss: 0.417497
Average total loss: 0.964027
tensor(0.0027, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.5988e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.533556
Average KL loss: 0.417982
Average total loss: 0.951539
tensor(0.0027, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-8.0118e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.538643
Average KL loss: 0.417984
Average total loss: 0.956627
tensor(0.0027, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.3101e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.534188
Average KL loss: 0.418208
Average total loss: 0.952397
tensor(0.0027, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.3279e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.536920
Average KL loss: 0.418722
Average total loss: 0.955642
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.3280e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.533800
Average KL loss: 0.419153
Average total loss: 0.952952
tensor(0.0028, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-7.4267e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.538047
Average KL loss: 0.419232
Average total loss: 0.957280
tensor(0.0028, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-4.5786e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.530691
Average KL loss: 0.419561
Average total loss: 0.950252
tensor(0.0028, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-8.9000e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.531007
Average KL loss: 0.420098
Average total loss: 0.951105
tensor(0.0028, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.4788e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.527853
Average KL loss: 0.420286
Average total loss: 0.948139
tensor(0.0028, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-6.2363e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.533476
Average KL loss: 0.420796
Average total loss: 0.954272
tensor(0.0028, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(1.9338e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.533856
Average KL loss: 0.420959
Average total loss: 0.954816
tensor(0.0028, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(2.6734e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.533388
Average KL loss: 0.421090
Average total loss: 0.954478
tensor(0.0028, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-5.9089e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.527503
Average KL loss: 0.421298
Average total loss: 0.948800
tensor(0.0028, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-5.9715e-11, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.538006
Average KL loss: 0.421594
Average total loss: 0.959601
tensor(0.0028, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.1303e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.524840
Average KL loss: 0.421992
Average total loss: 0.946831
tensor(0.0028, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.3770e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.527834
Average KL loss: 0.421819
Average total loss: 0.949653
tensor(0.0028, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-4.7204e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.527038
Average KL loss: 0.421893
Average total loss: 0.948931
tensor(0.0028, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-5.5651e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.526609
Average KL loss: 0.422148
Average total loss: 0.948757
tensor(0.0028, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-8.0882e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.523687
Average KL loss: 0.422438
Average total loss: 0.946125
tensor(0.0028, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-3.0592e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.514828
Average KL loss: 0.422945
Average total loss: 0.937773
tensor(0.0028, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.4461e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.527261
Average KL loss: 0.423019
Average total loss: 0.950280
tensor(0.0028, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-3.2732e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.530777
Average KL loss: 0.423355
Average total loss: 0.954132
tensor(0.0028, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.2340e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.532454
Average KL loss: 0.423862
Average total loss: 0.956316
tensor(0.0028, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.3900e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.526305
Average KL loss: 0.424258
Average total loss: 0.950563
tensor(0.0028, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-8.2076e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.520551
Average KL loss: 0.424618
Average total loss: 0.945169
tensor(0.0028, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-4.0588e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.518853
Average KL loss: 0.424809
Average total loss: 0.943662
tensor(0.0028, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-4.6905e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.526856
Average KL loss: 0.424865
Average total loss: 0.951720
tensor(0.0028, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.6785e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.519559
Average KL loss: 0.424785
Average total loss: 0.944344
tensor(0.0028, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(6.2193e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.524685
Average KL loss: 0.424804
Average total loss: 0.949490
tensor(0.0028, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(1.7368e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.522082
Average KL loss: 0.424946
Average total loss: 0.947028
tensor(0.0028, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-3.8549e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.511298
Average KL loss: 0.425232
Average total loss: 0.936531
tensor(0.0028, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(8.4813e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.519404
Average KL loss: 0.425443
Average total loss: 0.944847
tensor(0.0028, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.2864e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.520729
Average KL loss: 0.425804
Average total loss: 0.946534
tensor(0.0028, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(5.3699e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.517087
Average KL loss: 0.425959
Average total loss: 0.943046
tensor(0.0028, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.5855e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.518885
Average KL loss: 0.426032
Average total loss: 0.944917
tensor(0.0028, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(7.5465e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.513305
Average KL loss: 0.425962
Average total loss: 0.939266
tensor(0.0028, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(9.2852e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.511750
Average KL loss: 0.426144
Average total loss: 0.937894
tensor(0.0028, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-9.6084e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.513773
Average KL loss: 0.426368
Average total loss: 0.940141
tensor(0.0028, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(5.1743e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.526556
Average KL loss: 0.426531
Average total loss: 0.953086
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.8557e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.509922
Average KL loss: 0.426968
Average total loss: 0.936890
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-8.3006e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.512104
Average KL loss: 0.427116
Average total loss: 0.939220
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-8.7436e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.514307
Average KL loss: 0.427194
Average total loss: 0.941501
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-7.1178e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.514254
Average KL loss: 0.427301
Average total loss: 0.941555
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.2024e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.509391
Average KL loss: 0.427197
Average total loss: 0.936588
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.3994e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.505752
Average KL loss: 0.427092
Average total loss: 0.932844
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.9229e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.517139
Average KL loss: 0.426981
Average total loss: 0.944120
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.4024e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.516068
Average KL loss: 0.426905
Average total loss: 0.942974
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(8.3957e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.515384
Average KL loss: 0.426855
Average total loss: 0.942239
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.2426e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.519051
Average KL loss: 0.426800
Average total loss: 0.945851
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.0183e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.515510
Average KL loss: 0.426728
Average total loss: 0.942238
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.4178e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.514625
Average KL loss: 0.426672
Average total loss: 0.941297
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.9290e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.511877
Average KL loss: 0.426637
Average total loss: 0.938514
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.7784e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.513149
Average KL loss: 0.426588
Average total loss: 0.939736
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.6960e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.515963
Average KL loss: 0.426533
Average total loss: 0.942496
tensor(0.0028, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-8.6837e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.510220
Average KL loss: 0.426495
Average total loss: 0.936715
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.1494e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.512807
Average KL loss: 0.426472
Average total loss: 0.939279
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(4.5033e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.517411
Average KL loss: 0.426454
Average total loss: 0.943866
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.9809e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.515519
Average KL loss: 0.426450
Average total loss: 0.941969
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(9.4242e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.508597
Average KL loss: 0.426443
Average total loss: 0.935040
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.0337e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.514272
Average KL loss: 0.426433
Average total loss: 0.940704
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-9.1658e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.507919
Average KL loss: 0.426425
Average total loss: 0.934343
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.1488e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.513949
Average KL loss: 0.426422
Average total loss: 0.940371
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.8199e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.511625
Average KL loss: 0.426419
Average total loss: 0.938044
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.4417e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.514026
Average KL loss: 0.426412
Average total loss: 0.940439
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.0650e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.510848
Average KL loss: 0.426406
Average total loss: 0.937254
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.8111e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.516555
Average KL loss: 0.426399
Average total loss: 0.942955
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.9178e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.508928
Average KL loss: 0.426395
Average total loss: 0.935323
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-7.1621e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.511099
Average KL loss: 0.426391
Average total loss: 0.937490
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.6453e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.512157
Average KL loss: 0.426390
Average total loss: 0.938547
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.7697e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.513864
Average KL loss: 0.426390
Average total loss: 0.940254
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.2043e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.512716
Average KL loss: 0.426389
Average total loss: 0.939105
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.0784e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.523627
Average KL loss: 0.426388
Average total loss: 0.950016
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.5675e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.513127
Average KL loss: 0.426388
Average total loss: 0.939515
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.7466e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.503388
Average KL loss: 0.426387
Average total loss: 0.929775
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.1274e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.511054
Average KL loss: 0.426387
Average total loss: 0.937440
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-9.7462e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.514393
Average KL loss: 0.426386
Average total loss: 0.940779
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-5.3526e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.512109
Average KL loss: 0.426386
Average total loss: 0.938494
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.7783e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.515790
Average KL loss: 0.426385
Average total loss: 0.942175
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.2292e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.514054
Average KL loss: 0.426384
Average total loss: 0.940439
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.7053e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.505126
Average KL loss: 0.426383
Average total loss: 0.931509
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.8120e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.510518
Average KL loss: 0.426383
Average total loss: 0.936901
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.0185e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.507803
Average KL loss: 0.426382
Average total loss: 0.934185
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-7.8775e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.513059
Average KL loss: 0.426381
Average total loss: 0.939439
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(7.9608e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.511288
Average KL loss: 0.426380
Average total loss: 0.937668
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.3502e-09, device='cuda:0')
 Percentile value: 7.999278750503436e-08
Non-zero model percentage: 6.871959686279297%, Non-zero mask percentage: 6.871959686279297%

--- Pruning Level [12/24]: ---
conv1.weight         | nonzeros =     206 /    1728             ( 11.92%) | total_pruned =    1522 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
bn1.weight           | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
bn1.bias             | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1674 /   36864             (  4.54%) | total_pruned =   35190 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2614 /   36864             (  7.09%) | total_pruned =   34250 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2184 /   36864             (  5.92%) | total_pruned =   34680 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2322 /   36864             (  6.30%) | total_pruned =   34542 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1967 /   73728             (  2.67%) | total_pruned =   71761 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3815 /  147456             (  2.59%) | total_pruned =  143641 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     331 /    8192             (  4.04%) | total_pruned =    7861 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4922 /  147456             (  3.34%) | total_pruned =  142534 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    5947 /  147456             (  4.03%) | total_pruned =  141509 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    6261 /  294912             (  2.12%) | total_pruned =  288651 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     201 /     256             ( 78.52%) | total_pruned =      55 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   12996 /  589824             (  2.20%) | total_pruned =  576828 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1070 /   32768             (  3.27%) | total_pruned =   31698 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     126 /     256             ( 49.22%) | total_pruned =     130 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   11362 /  589824             (  1.93%) | total_pruned =  578462 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      39 /     256             ( 15.23%) | total_pruned =     217 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     185 /     256             ( 72.27%) | total_pruned =      71 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   12772 /  589824             (  2.17%) | total_pruned =  577052 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     107 /     256             ( 41.80%) | total_pruned =     149 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   16594 / 1179648             (  1.41%) | total_pruned = 1163054 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     364 /     512             ( 71.09%) | total_pruned =     148 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   55931 / 2359296             (  2.37%) | total_pruned = 2303365 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      37 /     512             (  7.23%) | total_pruned =     475 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     170 /     512             ( 33.20%) | total_pruned =     342 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      51 /     512             (  9.96%) | total_pruned =     461 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3433 /  131072             (  2.62%) | total_pruned =  127639 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      85 /     512             ( 16.60%) | total_pruned =     427 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      55 /     512             ( 10.74%) | total_pruned =     457 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  153062 / 2359296             (  6.49%) | total_pruned = 2206234 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      81 /     512             ( 15.82%) | total_pruned =     431 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     158 /     512             ( 30.86%) | total_pruned =     354 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  463418 / 2359296             ( 19.64%) | total_pruned = 1895878 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     128 /     512             ( 25.00%) | total_pruned =     384 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     285 /     512             ( 55.66%) | total_pruned =     227 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     194 /     512             ( 37.89%) | total_pruned =     318 | shape = torch.Size([512])
linear.weight        | nonzeros =    1930 /    5120             ( 37.70%) | total_pruned =    3190 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 768200, pruned : 10410562, total: 11178762, Compression rate :      14.55x  ( 93.13% pruned)
Train Epoch: 99/100 Loss: 0.227752 Accuracy: 77.29 96.06 % Best test Accuracy: 79.21%
tensor(0.0029, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-5.1253e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.682078
Average KL loss: 0.403612
Average total loss: 2.085690
tensor(0.0027, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.0279e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.518639
Average KL loss: 0.381842
Average total loss: 1.900481
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.3907e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.418539
Average KL loss: 0.369760
Average total loss: 1.788299
tensor(0.0024, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.3320e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.352443
Average KL loss: 0.360550
Average total loss: 1.712993
tensor(0.0023, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.7670e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.297263
Average KL loss: 0.352726
Average total loss: 1.649989
tensor(0.0023, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.3125e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.244031
Average KL loss: 0.346609
Average total loss: 1.590641
tensor(0.0022, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.0901e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.217214
Average KL loss: 0.342471
Average total loss: 1.559685
tensor(0.0022, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-3.2220e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.181957
Average KL loss: 0.340358
Average total loss: 1.522316
tensor(0.0022, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.1678e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.149647
Average KL loss: 0.339402
Average total loss: 1.489049
tensor(0.0022, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.9520e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.135977
Average KL loss: 0.338802
Average total loss: 1.474779
tensor(0.0022, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.0376e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.117753
Average KL loss: 0.338225
Average total loss: 1.455978
tensor(0.0021, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.7714e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.082217
Average KL loss: 0.337552
Average total loss: 1.419769
tensor(0.0021, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.2711e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.065841
Average KL loss: 0.336930
Average total loss: 1.402771
tensor(0.0021, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(8.5671e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.057444
Average KL loss: 0.336343
Average total loss: 1.393787
tensor(0.0021, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.4283e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.058191
Average KL loss: 0.335953
Average total loss: 1.394144
tensor(0.0021, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.3572e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.040266
Average KL loss: 0.335832
Average total loss: 1.376099
tensor(0.0021, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5370e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.025796
Average KL loss: 0.335604
Average total loss: 1.361400
tensor(0.0021, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.8297e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.000288
Average KL loss: 0.335296
Average total loss: 1.335583
tensor(0.0021, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.5567e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.012773
Average KL loss: 0.335179
Average total loss: 1.347952
tensor(0.0021, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.3950e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.979753
Average KL loss: 0.334894
Average total loss: 1.314647
tensor(0.0021, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.7824e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.968152
Average KL loss: 0.334664
Average total loss: 1.302817
tensor(0.0021, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.4321e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.966316
Average KL loss: 0.334368
Average total loss: 1.300684
tensor(0.0021, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.9618e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.968568
Average KL loss: 0.334378
Average total loss: 1.302946
tensor(0.0021, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.4092e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.948209
Average KL loss: 0.334277
Average total loss: 1.282486
tensor(0.0020, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.4236e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.942704
Average KL loss: 0.334060
Average total loss: 1.276764
tensor(0.0020, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.2908e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.930799
Average KL loss: 0.333819
Average total loss: 1.264618
tensor(0.0020, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.4117e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.925418
Average KL loss: 0.333708
Average total loss: 1.259125
tensor(0.0020, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.7396e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.914699
Average KL loss: 0.333481
Average total loss: 1.248180
tensor(0.0020, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0716e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.900720
Average KL loss: 0.333278
Average total loss: 1.233999
tensor(0.0020, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.0825e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.907045
Average KL loss: 0.333160
Average total loss: 1.240206
tensor(0.0020, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.6369e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.924693
Average KL loss: 0.333051
Average total loss: 1.257744
tensor(0.0020, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.2464e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.895640
Average KL loss: 0.333098
Average total loss: 1.228738
tensor(0.0020, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.7541e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.893051
Average KL loss: 0.333092
Average total loss: 1.226143
tensor(0.0020, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.3304e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.876751
Average KL loss: 0.332963
Average total loss: 1.209714
tensor(0.0020, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-6.2120e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.874166
Average KL loss: 0.332874
Average total loss: 1.207039
tensor(0.0020, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.5332e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.875510
Average KL loss: 0.333012
Average total loss: 1.208521
tensor(0.0020, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.5045e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.855991
Average KL loss: 0.333150
Average total loss: 1.189141
tensor(0.0020, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.3772e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.869092
Average KL loss: 0.333139
Average total loss: 1.202231
tensor(0.0020, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.3131e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.855338
Average KL loss: 0.333117
Average total loss: 1.188455
tensor(0.0020, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-7.9124e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.858594
Average KL loss: 0.333157
Average total loss: 1.191751
tensor(0.0020, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.9920e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.851974
Average KL loss: 0.333285
Average total loss: 1.185258
tensor(0.0020, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.0590e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.846876
Average KL loss: 0.333442
Average total loss: 1.180319
tensor(0.0020, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.6553e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.842213
Average KL loss: 0.333642
Average total loss: 1.175855
tensor(0.0020, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.0928e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.838524
Average KL loss: 0.333671
Average total loss: 1.172195
tensor(0.0020, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.1673e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.829127
Average KL loss: 0.333874
Average total loss: 1.163002
tensor(0.0020, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.6225e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.829828
Average KL loss: 0.334011
Average total loss: 1.163839
tensor(0.0020, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.7286e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.831271
Average KL loss: 0.334094
Average total loss: 1.165365
tensor(0.0020, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.2275e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.827390
Average KL loss: 0.334144
Average total loss: 1.161535
tensor(0.0020, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-8.5264e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.828517
Average KL loss: 0.334432
Average total loss: 1.162949
tensor(0.0020, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-8.7010e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.822578
Average KL loss: 0.334476
Average total loss: 1.157054
tensor(0.0020, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.3141e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.818491
Average KL loss: 0.334571
Average total loss: 1.153062
tensor(0.0020, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.0732e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.810278
Average KL loss: 0.335098
Average total loss: 1.145376
tensor(0.0020, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.3364e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.825624
Average KL loss: 0.335400
Average total loss: 1.161024
tensor(0.0020, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.7747e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.822749
Average KL loss: 0.335448
Average total loss: 1.158198
tensor(0.0020, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.2191e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.796955
Average KL loss: 0.335543
Average total loss: 1.132497
tensor(0.0020, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.6813e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.803366
Average KL loss: 0.335716
Average total loss: 1.139082
tensor(0.0020, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-8.2286e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.803486
Average KL loss: 0.335697
Average total loss: 1.139183
tensor(0.0020, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.9911e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.793579
Average KL loss: 0.335753
Average total loss: 1.129332
tensor(0.0020, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.9858e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.792974
Average KL loss: 0.336050
Average total loss: 1.129024
tensor(0.0020, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.1485e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.793499
Average KL loss: 0.336341
Average total loss: 1.129840
tensor(0.0021, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-6.5235e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.789551
Average KL loss: 0.336751
Average total loss: 1.126302
tensor(0.0021, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.3858e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.796370
Average KL loss: 0.336904
Average total loss: 1.133274
tensor(0.0021, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.3253e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.790219
Average KL loss: 0.336979
Average total loss: 1.127198
tensor(0.0021, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.5958e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.791376
Average KL loss: 0.337042
Average total loss: 1.128418
tensor(0.0021, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.6320e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.796031
Average KL loss: 0.337352
Average total loss: 1.133383
tensor(0.0021, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.1889e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.778261
Average KL loss: 0.337499
Average total loss: 1.115760
tensor(0.0021, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.6544e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.774953
Average KL loss: 0.337713
Average total loss: 1.112667
tensor(0.0021, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.8771e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.765946
Average KL loss: 0.338005
Average total loss: 1.103951
tensor(0.0021, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-7.8801e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.777797
Average KL loss: 0.338237
Average total loss: 1.116034
tensor(0.0021, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.3278e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.772860
Average KL loss: 0.338404
Average total loss: 1.111264
tensor(0.0021, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-8.6252e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.768210
Average KL loss: 0.338591
Average total loss: 1.106801
tensor(0.0021, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.5734e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.766976
Average KL loss: 0.338853
Average total loss: 1.105830
tensor(0.0021, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-6.4340e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.767136
Average KL loss: 0.339441
Average total loss: 1.106577
tensor(0.0021, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-8.1816e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.766221
Average KL loss: 0.339739
Average total loss: 1.105960
tensor(0.0021, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.1335e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.769176
Average KL loss: 0.339993
Average total loss: 1.109168
tensor(0.0021, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.0701e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.759514
Average KL loss: 0.340348
Average total loss: 1.099861
tensor(0.0021, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.4767e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.756610
Average KL loss: 0.340553
Average total loss: 1.097163
tensor(0.0021, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.8783e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.765940
Average KL loss: 0.340816
Average total loss: 1.106756
tensor(0.0021, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-7.5175e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.756820
Average KL loss: 0.341232
Average total loss: 1.098051
tensor(0.0021, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.6697e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.754942
Average KL loss: 0.341446
Average total loss: 1.096388
tensor(0.0021, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.8648e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.745982
Average KL loss: 0.341720
Average total loss: 1.087703
tensor(0.0021, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.1902e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.752273
Average KL loss: 0.341944
Average total loss: 1.094217
tensor(0.0021, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3191e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.750227
Average KL loss: 0.342095
Average total loss: 1.092321
tensor(0.0021, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.0229e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.739442
Average KL loss: 0.342331
Average total loss: 1.081773
tensor(0.0021, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.2169e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.745751
Average KL loss: 0.342558
Average total loss: 1.088309
tensor(0.0021, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.9036e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.750439
Average KL loss: 0.343035
Average total loss: 1.093474
tensor(0.0021, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.6416e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.742953
Average KL loss: 0.343453
Average total loss: 1.086406
tensor(0.0021, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.4430e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.745308
Average KL loss: 0.343863
Average total loss: 1.089171
tensor(0.0021, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.7200e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.751805
Average KL loss: 0.343963
Average total loss: 1.095767
tensor(0.0021, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.2617e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.742287
Average KL loss: 0.344262
Average total loss: 1.086549
tensor(0.0021, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.1010e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.737123
Average KL loss: 0.344479
Average total loss: 1.081601
tensor(0.0021, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.0384e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.756661
Average KL loss: 0.344560
Average total loss: 1.101221
tensor(0.0021, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.2755e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.736269
Average KL loss: 0.344892
Average total loss: 1.081161
tensor(0.0021, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.6758e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.742089
Average KL loss: 0.345280
Average total loss: 1.087368
tensor(0.0022, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.1388e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.742576
Average KL loss: 0.345571
Average total loss: 1.088148
tensor(0.0022, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.4927e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.732382
Average KL loss: 0.345781
Average total loss: 1.078163
tensor(0.0022, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.4139e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.724641
Average KL loss: 0.346143
Average total loss: 1.070784
tensor(0.0022, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.4187e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.736406
Average KL loss: 0.346140
Average total loss: 1.082546
tensor(0.0022, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.5931e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.726776
Average KL loss: 0.346291
Average total loss: 1.073067
tensor(0.0022, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.7119e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.725253
Average KL loss: 0.346487
Average total loss: 1.071740
tensor(0.0022, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.4886e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.726541
Average KL loss: 0.346732
Average total loss: 1.073273
tensor(0.0022, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-8.6892e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.725893
Average KL loss: 0.347206
Average total loss: 1.073099
tensor(0.0022, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.6285e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.731519
Average KL loss: 0.347581
Average total loss: 1.079100
tensor(0.0022, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2230e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.722707
Average KL loss: 0.347857
Average total loss: 1.070564
tensor(0.0022, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.0845e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.717809
Average KL loss: 0.348238
Average total loss: 1.066047
tensor(0.0022, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.6771e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.746673
Average KL loss: 0.348407
Average total loss: 1.095079
tensor(0.0022, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.8774e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.718681
Average KL loss: 0.348655
Average total loss: 1.067336
tensor(0.0022, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.1367e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.722487
Average KL loss: 0.349004
Average total loss: 1.071491
tensor(0.0022, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.6099e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.723738
Average KL loss: 0.349187
Average total loss: 1.072925
tensor(0.0022, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.1508e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.716779
Average KL loss: 0.349199
Average total loss: 1.065978
tensor(0.0022, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-7.3031e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.708735
Average KL loss: 0.349469
Average total loss: 1.058203
tensor(0.0022, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.3329e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.717409
Average KL loss: 0.349624
Average total loss: 1.067033
tensor(0.0022, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.8742e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.723000
Average KL loss: 0.349747
Average total loss: 1.072747
tensor(0.0022, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.6885e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.736556
Average KL loss: 0.350015
Average total loss: 1.086571
tensor(0.0022, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(8.3907e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.717786
Average KL loss: 0.350374
Average total loss: 1.068159
tensor(0.0022, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.6603e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.706724
Average KL loss: 0.350679
Average total loss: 1.057403
tensor(0.0022, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.3352e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.714590
Average KL loss: 0.350807
Average total loss: 1.065397
tensor(0.0022, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.4606e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.713078
Average KL loss: 0.350832
Average total loss: 1.063910
tensor(0.0022, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.8932e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.714891
Average KL loss: 0.350933
Average total loss: 1.065824
tensor(0.0022, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(7.7877e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.703355
Average KL loss: 0.351189
Average total loss: 1.054544
tensor(0.0022, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.2934e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.706954
Average KL loss: 0.351390
Average total loss: 1.058344
tensor(0.0022, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.0239e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.709616
Average KL loss: 0.351760
Average total loss: 1.061375
tensor(0.0022, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-7.2975e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.716027
Average KL loss: 0.351914
Average total loss: 1.067941
tensor(0.0022, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.0387e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.706475
Average KL loss: 0.352138
Average total loss: 1.058613
tensor(0.0022, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.4195e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.706047
Average KL loss: 0.352302
Average total loss: 1.058350
tensor(0.0022, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.0811e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.715235
Average KL loss: 0.352715
Average total loss: 1.067950
tensor(0.0023, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-4.2853e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.709027
Average KL loss: 0.352984
Average total loss: 1.062011
tensor(0.0023, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-8.4440e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.700680
Average KL loss: 0.353029
Average total loss: 1.053709
tensor(0.0023, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-7.8056e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.695784
Average KL loss: 0.353287
Average total loss: 1.049070
tensor(0.0023, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.0770e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.704512
Average KL loss: 0.353588
Average total loss: 1.058100
tensor(0.0023, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-9.1941e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.697726
Average KL loss: 0.353760
Average total loss: 1.051486
tensor(0.0023, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(7.1427e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.695434
Average KL loss: 0.354015
Average total loss: 1.049450
tensor(0.0023, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.6605e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.706379
Average KL loss: 0.354292
Average total loss: 1.060671
tensor(0.0023, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-8.2891e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.699670
Average KL loss: 0.354566
Average total loss: 1.054236
tensor(0.0023, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-6.3956e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.702496
Average KL loss: 0.354948
Average total loss: 1.057444
tensor(0.0023, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(1.7743e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.693924
Average KL loss: 0.354956
Average total loss: 1.048880
tensor(0.0023, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-4.5749e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.699001
Average KL loss: 0.355108
Average total loss: 1.054108
tensor(0.0023, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-9.3001e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.697906
Average KL loss: 0.355088
Average total loss: 1.052994
tensor(0.0023, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-6.6442e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.696984
Average KL loss: 0.355173
Average total loss: 1.052157
tensor(0.0023, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.0258e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.702529
Average KL loss: 0.355503
Average total loss: 1.058032
tensor(0.0023, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-7.9521e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.692678
Average KL loss: 0.355769
Average total loss: 1.048447
tensor(0.0023, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-8.0704e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.696435
Average KL loss: 0.356028
Average total loss: 1.052463
tensor(0.0023, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-5.3955e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.697251
Average KL loss: 0.356208
Average total loss: 1.053459
tensor(0.0023, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-8.8665e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.700926
Average KL loss: 0.356509
Average total loss: 1.057436
tensor(0.0023, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-5.7545e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.688927
Average KL loss: 0.356540
Average total loss: 1.045467
tensor(0.0023, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(2.7971e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.693168
Average KL loss: 0.356607
Average total loss: 1.049775
tensor(0.0023, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-8.6595e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.694523
Average KL loss: 0.357075
Average total loss: 1.051598
tensor(0.0023, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(2.3680e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.688168
Average KL loss: 0.357299
Average total loss: 1.045468
tensor(0.0023, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(1.5114e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.684154
Average KL loss: 0.357377
Average total loss: 1.041531
tensor(0.0023, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(1.3104e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.699756
Average KL loss: 0.357623
Average total loss: 1.057379
tensor(0.0023, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(3.4026e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.686431
Average KL loss: 0.357693
Average total loss: 1.044123
tensor(0.0023, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-4.4478e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.686981
Average KL loss: 0.357773
Average total loss: 1.044754
tensor(0.0023, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-3.4996e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.700083
Average KL loss: 0.357872
Average total loss: 1.057955
tensor(0.0023, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-7.7099e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.692683
Average KL loss: 0.358253
Average total loss: 1.050936
tensor(0.0023, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-2.3982e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.688465
Average KL loss: 0.358609
Average total loss: 1.047074
tensor(0.0023, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(6.4447e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.688094
Average KL loss: 0.358710
Average total loss: 1.046805
tensor(0.0023, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-3.4498e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.683118
Average KL loss: 0.358771
Average total loss: 1.041889
tensor(0.0023, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-5.2311e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.684975
Average KL loss: 0.359027
Average total loss: 1.044003
tensor(0.0023, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-7.0394e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.689754
Average KL loss: 0.359241
Average total loss: 1.048995
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.3140e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.683288
Average KL loss: 0.359453
Average total loss: 1.042741
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.4812e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.692987
Average KL loss: 0.359385
Average total loss: 1.052373
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-7.0050e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.683871
Average KL loss: 0.359295
Average total loss: 1.043166
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.6619e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.692776
Average KL loss: 0.359221
Average total loss: 1.051997
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.8882e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.685714
Average KL loss: 0.359153
Average total loss: 1.044867
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.6145e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.688680
Average KL loss: 0.359107
Average total loss: 1.047787
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.3206e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.681753
Average KL loss: 0.359063
Average total loss: 1.040817
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.6586e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.688653
Average KL loss: 0.359025
Average total loss: 1.047677
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-9.0978e-11, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.688847
Average KL loss: 0.358997
Average total loss: 1.047844
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-5.3057e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.688468
Average KL loss: 0.358955
Average total loss: 1.047423
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.1863e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.685100
Average KL loss: 0.358907
Average total loss: 1.044008
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.3670e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.684184
Average KL loss: 0.358862
Average total loss: 1.043046
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.7927e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.681299
Average KL loss: 0.358826
Average total loss: 1.040125
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.9811e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.684875
Average KL loss: 0.358771
Average total loss: 1.043645
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.7130e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.686620
Average KL loss: 0.358730
Average total loss: 1.045350
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.1960e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.688269
Average KL loss: 0.358718
Average total loss: 1.046987
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.1705e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.681995
Average KL loss: 0.358699
Average total loss: 1.040694
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.4795e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.686067
Average KL loss: 0.358675
Average total loss: 1.044742
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.3917e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.686620
Average KL loss: 0.358678
Average total loss: 1.045298
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.7321e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.702174
Average KL loss: 0.358650
Average total loss: 1.060824
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.7809e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.682560
Average KL loss: 0.358616
Average total loss: 1.041176
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.3614e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.675024
Average KL loss: 0.358595
Average total loss: 1.033619
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.5210e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.683068
Average KL loss: 0.358564
Average total loss: 1.041632
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.2913e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.690243
Average KL loss: 0.358555
Average total loss: 1.048798
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.4503e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.687919
Average KL loss: 0.358561
Average total loss: 1.046480
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.5029e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.706495
Average KL loss: 0.358540
Average total loss: 1.065035
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.4845e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.686779
Average KL loss: 0.358504
Average total loss: 1.045283
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.7245e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.677532
Average KL loss: 0.358474
Average total loss: 1.036006
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.9840e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.686535
Average KL loss: 0.358461
Average total loss: 1.044996
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.7054e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.689377
Average KL loss: 0.358477
Average total loss: 1.047853
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-9.8040e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.679866
Average KL loss: 0.358484
Average total loss: 1.038350
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.7797e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.686063
Average KL loss: 0.358463
Average total loss: 1.044526
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.2325e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.677897
Average KL loss: 0.358441
Average total loss: 1.036338
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.4266e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.680456
Average KL loss: 0.358422
Average total loss: 1.038878
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.7456e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.681637
Average KL loss: 0.358418
Average total loss: 1.040055
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(2.9957e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.678782
Average KL loss: 0.358415
Average total loss: 1.037197
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.8711e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.679932
Average KL loss: 0.358412
Average total loss: 1.038344
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.5404e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.684773
Average KL loss: 0.358410
Average total loss: 1.043182
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-7.2774e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.681114
Average KL loss: 0.358407
Average total loss: 1.039522
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.5505e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.689656
Average KL loss: 0.358404
Average total loss: 1.048061
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-7.4041e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.680758
Average KL loss: 0.358403
Average total loss: 1.039161
 Percentile value: 6.645869632393442e-08
Non-zero model percentage: 5.497567176818848%, Non-zero mask percentage: 5.497567176818848%

--- Pruning Level [13/24]: ---
conv1.weight         | nonzeros =     203 /    1728             ( 11.75%) | total_pruned =    1525 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
bn1.weight           | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
bn1.bias             | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1659 /   36864             (  4.50%) | total_pruned =   35205 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2584 /   36864             (  7.01%) | total_pruned =   34280 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2152 /   36864             (  5.84%) | total_pruned =   34712 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2251 /   36864             (  6.11%) | total_pruned =   34613 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1825 /   73728             (  2.48%) | total_pruned =   71903 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3526 /  147456             (  2.39%) | total_pruned =  143930 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     302 /    8192             (  3.69%) | total_pruned =    7890 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4693 /  147456             (  3.18%) | total_pruned =  142763 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    5725 /  147456             (  3.88%) | total_pruned =  141731 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    5678 /  294912             (  1.93%) | total_pruned =  289234 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     191 /     256             ( 74.61%) | total_pruned =      65 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   11678 /  589824             (  1.98%) | total_pruned =  578146 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     190 /     256             ( 74.22%) | total_pruned =      66 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     939 /   32768             (  2.87%) | total_pruned =   31829 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     113 /     256             ( 44.14%) | total_pruned =     143 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   10394 /  589824             (  1.76%) | total_pruned =  579430 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     169 /     256             ( 66.02%) | total_pruned =      87 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   12025 /  589824             (  2.04%) | total_pruned =  577799 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      97 /     256             ( 37.89%) | total_pruned =     159 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   14726 / 1179648             (  1.25%) | total_pruned = 1164922 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      25 /     512             (  4.88%) | total_pruned =     487 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     326 /     512             ( 63.67%) | total_pruned =     186 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   53059 / 2359296             (  2.25%) | total_pruned = 2306237 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     158 /     512             ( 30.86%) | total_pruned =     354 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      37 /     512             (  7.23%) | total_pruned =     475 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3237 /  131072             (  2.47%) | total_pruned =  127835 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      35 /     512             (  6.84%) | total_pruned =     477 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  101844 / 2359296             (  4.32%) | total_pruned = 2257452 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      48 /     512             (  9.38%) | total_pruned =     464 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     115 /     512             ( 22.46%) | total_pruned =     397 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  371600 / 2359296             ( 15.75%) | total_pruned = 1987696 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     122 /     512             ( 23.83%) | total_pruned =     390 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     243 /     512             ( 47.46%) | total_pruned =     269 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     166 /     512             ( 32.42%) | total_pruned =     346 | shape = torch.Size([512])
linear.weight        | nonzeros =    1547 /    5120             ( 30.21%) | total_pruned =    3573 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 614560, pruned : 10564202, total: 11178762, Compression rate :      18.19x  ( 94.50% pruned)
Train Epoch: 99/100 Loss: 0.404189 Accuracy: 74.53 85.91 % Best test Accuracy: 76.29%
tensor(0.0023, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.8476e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.665855
Average KL loss: 0.342665
Average total loss: 2.008520
tensor(0.0023, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.8238e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.556894
Average KL loss: 0.325855
Average total loss: 1.882748
tensor(0.0021, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.4314e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.479157
Average KL loss: 0.314801
Average total loss: 1.793958
tensor(0.0020, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.0397e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.396316
Average KL loss: 0.305299
Average total loss: 1.701615
tensor(0.0020, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.3055e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.361442
Average KL loss: 0.296898
Average total loss: 1.658340
tensor(0.0019, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.2909e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.318861
Average KL loss: 0.290084
Average total loss: 1.608945
tensor(0.0019, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.7038e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.289955
Average KL loss: 0.285189
Average total loss: 1.575144
tensor(0.0018, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-2.3257e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.264661
Average KL loss: 0.282561
Average total loss: 1.547222
tensor(0.0018, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.0163e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.240945
Average KL loss: 0.281483
Average total loss: 1.522428
tensor(0.0018, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.6530e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.235569
Average KL loss: 0.280649
Average total loss: 1.516218
tensor(0.0018, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.6644e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.186790
Average KL loss: 0.280032
Average total loss: 1.466823
tensor(0.0018, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.8724e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.172669
Average KL loss: 0.279449
Average total loss: 1.452118
tensor(0.0018, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.6884e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.158512
Average KL loss: 0.279176
Average total loss: 1.437688
tensor(0.0018, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.2124e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.148793
Average KL loss: 0.278770
Average total loss: 1.427563
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.4834e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.112072
Average KL loss: 0.278542
Average total loss: 1.390614
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.5683e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.099013
Average KL loss: 0.278428
Average total loss: 1.377440
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.4554e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.100252
Average KL loss: 0.278364
Average total loss: 1.378617
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.2513e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.073899
Average KL loss: 0.278142
Average total loss: 1.352041
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.8448e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.089835
Average KL loss: 0.277978
Average total loss: 1.367813
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.0884e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.064993
Average KL loss: 0.277976
Average total loss: 1.342969
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.4533e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.043112
Average KL loss: 0.277964
Average total loss: 1.321076
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.1071e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.041660
Average KL loss: 0.277977
Average total loss: 1.319637
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.3292e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.040411
Average KL loss: 0.278037
Average total loss: 1.318448
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.5047e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.026645
Average KL loss: 0.278260
Average total loss: 1.304905
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-9.5287e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.019471
Average KL loss: 0.278340
Average total loss: 1.297811
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.7261e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.997828
Average KL loss: 0.278494
Average total loss: 1.276321
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.6313e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.012573
Average KL loss: 0.278629
Average total loss: 1.291202
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-9.0107e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.983233
Average KL loss: 0.278700
Average total loss: 1.261933
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.2107e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.975354
Average KL loss: 0.278725
Average total loss: 1.254079
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.0817e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.974346
Average KL loss: 0.278698
Average total loss: 1.253044
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-9.2832e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.976811
Average KL loss: 0.278824
Average total loss: 1.255635
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.2304e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.956849
Average KL loss: 0.279204
Average total loss: 1.236053
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.0861e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.956918
Average KL loss: 0.279337
Average total loss: 1.236255
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.3696e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.957724
Average KL loss: 0.279455
Average total loss: 1.237180
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.1995e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.940525
Average KL loss: 0.279602
Average total loss: 1.220128
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-6.8347e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.941917
Average KL loss: 0.279715
Average total loss: 1.221632
tensor(0.0017, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.6189e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.940753
Average KL loss: 0.279783
Average total loss: 1.220535
tensor(0.0017, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.5816e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.942777
Average KL loss: 0.279983
Average total loss: 1.222760
tensor(0.0017, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.6423e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.937729
Average KL loss: 0.280176
Average total loss: 1.217905
tensor(0.0017, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.3077e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.937976
Average KL loss: 0.280411
Average total loss: 1.218386
tensor(0.0017, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-9.2937e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.924805
Average KL loss: 0.280449
Average total loss: 1.205254
tensor(0.0017, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.4055e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.915753
Average KL loss: 0.280655
Average total loss: 1.196409
tensor(0.0017, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.6424e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.918856
Average KL loss: 0.280860
Average total loss: 1.199717
tensor(0.0017, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.3749e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.908619
Average KL loss: 0.281154
Average total loss: 1.189774
tensor(0.0017, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.3396e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.910736
Average KL loss: 0.281542
Average total loss: 1.192278
tensor(0.0018, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-5.9662e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.896982
Average KL loss: 0.281916
Average total loss: 1.178898
tensor(0.0018, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-5.6818e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.886836
Average KL loss: 0.282039
Average total loss: 1.168875
tensor(0.0018, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.1567e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.901241
Average KL loss: 0.282151
Average total loss: 1.183392
tensor(0.0018, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.7444e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.889727
Average KL loss: 0.282504
Average total loss: 1.172231
tensor(0.0018, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.8068e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.900736
Average KL loss: 0.282882
Average total loss: 1.183618
tensor(0.0018, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.0943e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.914895
Average KL loss: 0.283072
Average total loss: 1.197966
tensor(0.0018, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.4357e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.885810
Average KL loss: 0.283417
Average total loss: 1.169226
tensor(0.0018, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.2745e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.880119
Average KL loss: 0.283707
Average total loss: 1.163826
tensor(0.0018, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.7324e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.875682
Average KL loss: 0.283863
Average total loss: 1.159545
tensor(0.0018, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.0499e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.878595
Average KL loss: 0.284240
Average total loss: 1.162835
tensor(0.0018, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.3173e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.872604
Average KL loss: 0.284334
Average total loss: 1.156939
tensor(0.0018, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.4167e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.879004
Average KL loss: 0.284531
Average total loss: 1.163535
tensor(0.0018, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.2746e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.863111
Average KL loss: 0.284703
Average total loss: 1.147814
tensor(0.0018, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.0502e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.855157
Average KL loss: 0.285062
Average total loss: 1.140220
tensor(0.0018, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.7621e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.871048
Average KL loss: 0.285306
Average total loss: 1.156354
tensor(0.0018, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.0454e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.850502
Average KL loss: 0.285777
Average total loss: 1.136279
tensor(0.0018, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.2560e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.852737
Average KL loss: 0.286178
Average total loss: 1.138915
tensor(0.0018, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.2903e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.848635
Average KL loss: 0.286571
Average total loss: 1.135206
tensor(0.0018, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.1791e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.857299
Average KL loss: 0.286889
Average total loss: 1.144187
tensor(0.0018, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.6927e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.839282
Average KL loss: 0.287414
Average total loss: 1.126696
tensor(0.0018, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-8.5267e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.851777
Average KL loss: 0.287786
Average total loss: 1.139562
tensor(0.0018, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.0122e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.847569
Average KL loss: 0.288094
Average total loss: 1.135663
tensor(0.0018, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-8.9116e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.847103
Average KL loss: 0.288354
Average total loss: 1.135456
tensor(0.0018, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.7167e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.848858
Average KL loss: 0.288697
Average total loss: 1.137555
tensor(0.0018, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.3011e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.829981
Average KL loss: 0.289102
Average total loss: 1.119083
tensor(0.0018, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.1216e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.839778
Average KL loss: 0.289733
Average total loss: 1.129511
tensor(0.0018, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.8135e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.836685
Average KL loss: 0.290155
Average total loss: 1.126840
tensor(0.0018, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-9.0033e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.835165
Average KL loss: 0.290480
Average total loss: 1.125645
tensor(0.0018, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.7425e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.826551
Average KL loss: 0.290869
Average total loss: 1.117419
tensor(0.0018, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.7888e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.845601
Average KL loss: 0.291270
Average total loss: 1.136871
tensor(0.0018, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.0888e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.828108
Average KL loss: 0.291638
Average total loss: 1.119747
tensor(0.0019, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.4437e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.818854
Average KL loss: 0.291855
Average total loss: 1.110709
tensor(0.0019, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-6.0486e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.815160
Average KL loss: 0.292112
Average total loss: 1.107271
tensor(0.0019, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(8.9730e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.819975
Average KL loss: 0.292312
Average total loss: 1.112287
tensor(0.0019, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.4574e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.818492
Average KL loss: 0.292462
Average total loss: 1.110954
tensor(0.0019, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.0152e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.817349
Average KL loss: 0.292890
Average total loss: 1.110239
tensor(0.0019, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.1386e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.818404
Average KL loss: 0.293198
Average total loss: 1.111601
tensor(0.0019, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.3462e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.816010
Average KL loss: 0.293698
Average total loss: 1.109709
tensor(0.0019, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.9792e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.813837
Average KL loss: 0.294137
Average total loss: 1.107974
tensor(0.0019, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.0334e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.823531
Average KL loss: 0.294417
Average total loss: 1.117948
tensor(0.0019, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.8463e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.807142
Average KL loss: 0.294916
Average total loss: 1.102058
tensor(0.0019, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.1974e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.806647
Average KL loss: 0.295448
Average total loss: 1.102094
tensor(0.0019, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-7.6063e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.802438
Average KL loss: 0.295659
Average total loss: 1.098097
tensor(0.0019, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.2013e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.804091
Average KL loss: 0.295869
Average total loss: 1.099960
tensor(0.0019, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-9.2381e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.805665
Average KL loss: 0.296191
Average total loss: 1.101855
tensor(0.0019, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-6.1133e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.797416
Average KL loss: 0.296548
Average total loss: 1.093963
tensor(0.0019, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.1555e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.803881
Average KL loss: 0.296823
Average total loss: 1.100703
tensor(0.0019, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.9799e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.797413
Average KL loss: 0.297119
Average total loss: 1.094531
tensor(0.0019, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.8184e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.795924
Average KL loss: 0.297461
Average total loss: 1.093384
tensor(0.0019, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.2217e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.793778
Average KL loss: 0.297917
Average total loss: 1.091694
tensor(0.0019, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.7039e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.799493
Average KL loss: 0.298411
Average total loss: 1.097904
tensor(0.0019, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.0387e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.787782
Average KL loss: 0.298917
Average total loss: 1.086698
tensor(0.0019, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.7340e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.800527
Average KL loss: 0.299254
Average total loss: 1.099782
tensor(0.0019, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(9.6758e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.791937
Average KL loss: 0.299668
Average total loss: 1.091605
tensor(0.0019, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.4606e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.791453
Average KL loss: 0.300219
Average total loss: 1.091672
tensor(0.0019, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.2456e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.787096
Average KL loss: 0.300615
Average total loss: 1.087710
tensor(0.0019, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.1205e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.780305
Average KL loss: 0.300905
Average total loss: 1.081210
tensor(0.0019, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.8214e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.781945
Average KL loss: 0.301262
Average total loss: 1.083207
tensor(0.0020, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.1532e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.776905
Average KL loss: 0.301568
Average total loss: 1.078473
tensor(0.0020, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.8968e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.786307
Average KL loss: 0.301941
Average total loss: 1.088248
tensor(0.0020, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.8702e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.784570
Average KL loss: 0.302350
Average total loss: 1.086920
tensor(0.0020, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.1311e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.772057
Average KL loss: 0.302809
Average total loss: 1.074867
tensor(0.0020, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.6337e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.782215
Average KL loss: 0.303129
Average total loss: 1.085345
tensor(0.0020, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.6817e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.786744
Average KL loss: 0.303542
Average total loss: 1.090286
tensor(0.0020, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-8.0750e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.771426
Average KL loss: 0.303920
Average total loss: 1.075346
tensor(0.0020, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.6157e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.776430
Average KL loss: 0.304376
Average total loss: 1.080806
tensor(0.0020, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.5396e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.775444
Average KL loss: 0.304706
Average total loss: 1.080150
tensor(0.0020, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.7596e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.772676
Average KL loss: 0.305020
Average total loss: 1.077696
tensor(0.0020, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.0456e-11, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.770603
Average KL loss: 0.305209
Average total loss: 1.075812
tensor(0.0020, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.9000e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.772799
Average KL loss: 0.305499
Average total loss: 1.078298
tensor(0.0020, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.9267e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.770522
Average KL loss: 0.305927
Average total loss: 1.076449
tensor(0.0020, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.6949e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.766288
Average KL loss: 0.306248
Average total loss: 1.072536
tensor(0.0020, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.9627e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.765055
Average KL loss: 0.306587
Average total loss: 1.071642
tensor(0.0020, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.8424e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.778503
Average KL loss: 0.306893
Average total loss: 1.085395
tensor(0.0020, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.2920e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.762270
Average KL loss: 0.307192
Average total loss: 1.069463
tensor(0.0020, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.9838e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.764606
Average KL loss: 0.307368
Average total loss: 1.071974
tensor(0.0020, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.3180e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.761035
Average KL loss: 0.307525
Average total loss: 1.068560
tensor(0.0020, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.8483e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.766899
Average KL loss: 0.307825
Average total loss: 1.074724
tensor(0.0020, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.5877e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.759111
Average KL loss: 0.308211
Average total loss: 1.067321
tensor(0.0020, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.1003e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.768264
Average KL loss: 0.308643
Average total loss: 1.076907
tensor(0.0020, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.1554e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.770558
Average KL loss: 0.308958
Average total loss: 1.079516
tensor(0.0020, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(6.6637e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.759473
Average KL loss: 0.309347
Average total loss: 1.068820
tensor(0.0020, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.0221e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.768178
Average KL loss: 0.309679
Average total loss: 1.077857
tensor(0.0020, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.7365e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.758838
Average KL loss: 0.309902
Average total loss: 1.068740
tensor(0.0020, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.1593e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.762024
Average KL loss: 0.310263
Average total loss: 1.072286
tensor(0.0021, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.9407e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.753221
Average KL loss: 0.310492
Average total loss: 1.063713
tensor(0.0021, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.1766e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.753300
Average KL loss: 0.310733
Average total loss: 1.064033
tensor(0.0021, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.4365e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.750532
Average KL loss: 0.311203
Average total loss: 1.061736
tensor(0.0021, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.0036e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.745929
Average KL loss: 0.311714
Average total loss: 1.057643
tensor(0.0021, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.6300e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.751262
Average KL loss: 0.311978
Average total loss: 1.063240
tensor(0.0021, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.1841e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.746475
Average KL loss: 0.312364
Average total loss: 1.058838
tensor(0.0021, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.7747e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.762016
Average KL loss: 0.312552
Average total loss: 1.074569
tensor(0.0021, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.6033e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.748694
Average KL loss: 0.312744
Average total loss: 1.061439
tensor(0.0021, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-3.1142e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.754393
Average KL loss: 0.312997
Average total loss: 1.067391
tensor(0.0021, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.2931e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.751528
Average KL loss: 0.313358
Average total loss: 1.064885
tensor(0.0021, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(4.2770e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.749422
Average KL loss: 0.313830
Average total loss: 1.063252
tensor(0.0021, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-2.2486e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.751472
Average KL loss: 0.314111
Average total loss: 1.065584
tensor(0.0021, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-2.8932e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.744257
Average KL loss: 0.314386
Average total loss: 1.058642
tensor(0.0021, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.0353e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.746088
Average KL loss: 0.314817
Average total loss: 1.060906
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.1892e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.745789
Average KL loss: 0.315198
Average total loss: 1.060986
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(4.8628e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.744250
Average KL loss: 0.315373
Average total loss: 1.059624
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(1.3228e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.747892
Average KL loss: 0.315346
Average total loss: 1.063238
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-5.4763e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.752237
Average KL loss: 0.315314
Average total loss: 1.067551
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(1.5602e-11, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.740414
Average KL loss: 0.315303
Average total loss: 1.055718
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-3.2014e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.741071
Average KL loss: 0.315291
Average total loss: 1.056362
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-6.3262e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.746508
Average KL loss: 0.315276
Average total loss: 1.061783
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.1999e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.750301
Average KL loss: 0.315281
Average total loss: 1.065582
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.9076e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.743156
Average KL loss: 0.315283
Average total loss: 1.058439
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-7.7092e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.750972
Average KL loss: 0.315262
Average total loss: 1.066234
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-7.9419e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.751573
Average KL loss: 0.315260
Average total loss: 1.066833
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(6.2043e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.744351
Average KL loss: 0.315250
Average total loss: 1.059602
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-7.5530e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.746164
Average KL loss: 0.315252
Average total loss: 1.061416
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(3.0284e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.741043
Average KL loss: 0.315246
Average total loss: 1.056289
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(5.4283e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.751012
Average KL loss: 0.315241
Average total loss: 1.066253
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(1.3317e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.745778
Average KL loss: 0.315242
Average total loss: 1.061019
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.3338e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.740236
Average KL loss: 0.315243
Average total loss: 1.055479
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.1627e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.750631
Average KL loss: 0.315243
Average total loss: 1.065874
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(1.9245e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.739449
Average KL loss: 0.315244
Average total loss: 1.054693
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.0398e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.750829
Average KL loss: 0.315242
Average total loss: 1.066071
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.3128e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.747882
Average KL loss: 0.315241
Average total loss: 1.063124
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.5750e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.748371
Average KL loss: 0.315240
Average total loss: 1.063611
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-6.1193e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.756611
Average KL loss: 0.315239
Average total loss: 1.071850
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.6878e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.740239
Average KL loss: 0.315240
Average total loss: 1.055480
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-3.5915e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.744996
Average KL loss: 0.315242
Average total loss: 1.060237
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-5.0961e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.742880
Average KL loss: 0.315242
Average total loss: 1.058122
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(8.5978e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.742773
Average KL loss: 0.315240
Average total loss: 1.058013
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-5.9743e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.741528
Average KL loss: 0.315239
Average total loss: 1.056767
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-5.6815e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.747425
Average KL loss: 0.315238
Average total loss: 1.062663
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-6.6187e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.746173
Average KL loss: 0.315238
Average total loss: 1.061411
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.1820e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.753756
Average KL loss: 0.315239
Average total loss: 1.068995
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-3.3901e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.749492
Average KL loss: 0.315239
Average total loss: 1.064731
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.0184e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.743172
Average KL loss: 0.315239
Average total loss: 1.058411
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(1.5317e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.737634
Average KL loss: 0.315239
Average total loss: 1.052874
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(1.2073e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.743452
Average KL loss: 0.315239
Average total loss: 1.058691
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-3.6813e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.752718
Average KL loss: 0.315239
Average total loss: 1.067958
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.7003e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.745634
Average KL loss: 0.315239
Average total loss: 1.060873
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-6.4504e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.744161
Average KL loss: 0.315239
Average total loss: 1.059401
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-5.2280e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.741205
Average KL loss: 0.315239
Average total loss: 1.056444
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.2328e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.743245
Average KL loss: 0.315239
Average total loss: 1.058484
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.2599e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.748598
Average KL loss: 0.315239
Average total loss: 1.063837
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-5.4591e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.739745
Average KL loss: 0.315239
Average total loss: 1.054984
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-5.1628e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.742479
Average KL loss: 0.315239
Average total loss: 1.057718
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-6.8291e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.744940
Average KL loss: 0.315239
Average total loss: 1.060179
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(1.2068e-10, device='cuda:0')
 Percentile value: 8.158714592809702e-08
Non-zero model percentage: 4.398054122924805%, Non-zero mask percentage: 4.398054122924805%

--- Pruning Level [14/24]: ---
conv1.weight         | nonzeros =      71 /    1728             (  4.11%) | total_pruned =    1657 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      26 /   36864             (  0.07%) | total_pruned =   36838 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      43 /   36864             (  0.12%) | total_pruned =   36821 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      90 /   36864             (  0.24%) | total_pruned =   36774 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     177 /   36864             (  0.48%) | total_pruned =   36687 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     364 /   73728             (  0.49%) | total_pruned =   73364 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     613 /  147456             (  0.42%) | total_pruned =  146843 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      42 /    8192             (  0.51%) | total_pruned =    8150 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     432 /  147456             (  0.29%) | total_pruned =  147024 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    5208 /  147456             (  3.53%) | total_pruned =  142248 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    5123 /  294912             (  1.74%) | total_pruned =  289789 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     175 /     256             ( 68.36%) | total_pruned =      81 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   10592 /  589824             (  1.80%) | total_pruned =  579232 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     172 /     256             ( 67.19%) | total_pruned =      84 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     800 /   32768             (  2.44%) | total_pruned =   31968 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      80 /     256             ( 31.25%) | total_pruned =     176 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    9593 /  589824             (  1.63%) | total_pruned =  580231 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     132 /     256             ( 51.56%) | total_pruned =     124 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   11446 /  589824             (  1.94%) | total_pruned =  578378 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      86 /     256             ( 33.59%) | total_pruned =     170 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   13204 / 1179648             (  1.12%) | total_pruned = 1166444 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     258 /     512             ( 50.39%) | total_pruned =     254 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   50824 / 2359296             (  2.15%) | total_pruned = 2308472 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     136 /     512             ( 26.56%) | total_pruned =     376 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3086 /  131072             (  2.35%) | total_pruned =  127986 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      35 /     512             (  6.84%) | total_pruned =     477 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      49 /     512             (  9.57%) | total_pruned =     463 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      35 /     512             (  6.84%) | total_pruned =     477 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   99415 / 2359296             (  4.21%) | total_pruned = 2259881 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     103 /     512             ( 20.12%) | total_pruned =     409 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  277304 / 2359296             ( 11.75%) | total_pruned = 2081992 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      54 /     512             ( 10.55%) | total_pruned =     458 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     165 /     512             ( 32.23%) | total_pruned =     347 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
linear.weight        | nonzeros =    1017 /    5120             ( 19.86%) | total_pruned =    4103 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 491648, pruned : 10687114, total: 11178762, Compression rate :      22.74x  ( 95.60% pruned)
Train Epoch: 99/100 Loss: 0.609957 Accuracy: 71.32 81.15 % Best test Accuracy: 72.19%
tensor(0.0021, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-3.2078e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.357169
Average KL loss: 0.304698
Average total loss: 1.661867
tensor(0.0020, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.2622e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.285844
Average KL loss: 0.294052
Average total loss: 1.579897
tensor(0.0019, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.4288e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.256895
Average KL loss: 0.286954
Average total loss: 1.543849
tensor(0.0018, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.7257e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.202934
Average KL loss: 0.280724
Average total loss: 1.483658
tensor(0.0018, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.8377e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.174328
Average KL loss: 0.275032
Average total loss: 1.449360
tensor(0.0018, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.3810e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.147120
Average KL loss: 0.270007
Average total loss: 1.417127
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.6618e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.139857
Average KL loss: 0.266101
Average total loss: 1.405958
tensor(0.0017, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.6836e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.128074
Average KL loss: 0.263924
Average total loss: 1.391998
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.2309e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.120396
Average KL loss: 0.262808
Average total loss: 1.383203
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.8988e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.078620
Average KL loss: 0.262147
Average total loss: 1.340767
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-8.6682e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.070631
Average KL loss: 0.261492
Average total loss: 1.332123
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.2359e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.065779
Average KL loss: 0.260863
Average total loss: 1.326641
tensor(0.0017, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.4045e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.058665
Average KL loss: 0.260355
Average total loss: 1.319020
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.1661e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.059362
Average KL loss: 0.259902
Average total loss: 1.319264
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.9029e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.048195
Average KL loss: 0.259442
Average total loss: 1.307637
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-8.8186e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.040081
Average KL loss: 0.259128
Average total loss: 1.299209
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.0324e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.026102
Average KL loss: 0.258772
Average total loss: 1.284874
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-6.6832e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.007972
Average KL loss: 0.258382
Average total loss: 1.266354
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.4086e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.014979
Average KL loss: 0.258015
Average total loss: 1.272994
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-7.9462e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.001609
Average KL loss: 0.257847
Average total loss: 1.259456
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-9.1114e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.003951
Average KL loss: 0.257436
Average total loss: 1.261387
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-8.4736e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.990646
Average KL loss: 0.257093
Average total loss: 1.247739
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-9.2810e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.984186
Average KL loss: 0.256756
Average total loss: 1.240942
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.7186e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.980696
Average KL loss: 0.256341
Average total loss: 1.237037
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.0534e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.979786
Average KL loss: 0.256072
Average total loss: 1.235858
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.6295e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.963010
Average KL loss: 0.255948
Average total loss: 1.218959
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.8044e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.966241
Average KL loss: 0.255852
Average total loss: 1.222092
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.3215e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.975168
Average KL loss: 0.255723
Average total loss: 1.230891
tensor(0.0016, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-6.9881e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.968307
Average KL loss: 0.255641
Average total loss: 1.223947
tensor(0.0016, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-4.3275e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.949852
Average KL loss: 0.255429
Average total loss: 1.205280
tensor(0.0016, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.2353e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.951075
Average KL loss: 0.255183
Average total loss: 1.206259
tensor(0.0016, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-8.5311e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.955072
Average KL loss: 0.255230
Average total loss: 1.210302
tensor(0.0016, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.2917e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.941054
Average KL loss: 0.255084
Average total loss: 1.196138
tensor(0.0016, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-5.7680e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.951123
Average KL loss: 0.255021
Average total loss: 1.206144
tensor(0.0016, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-4.5417e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.943513
Average KL loss: 0.255038
Average total loss: 1.198552
tensor(0.0016, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-9.0156e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.949723
Average KL loss: 0.255153
Average total loss: 1.204877
tensor(0.0016, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.1366e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.938476
Average KL loss: 0.255170
Average total loss: 1.193646
tensor(0.0016, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-8.1782e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.946860
Average KL loss: 0.255099
Average total loss: 1.201960
tensor(0.0016, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.9875e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.945794
Average KL loss: 0.255056
Average total loss: 1.200849
tensor(0.0016, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-6.4256e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.925543
Average KL loss: 0.255025
Average total loss: 1.180568
tensor(0.0016, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-7.8842e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.924034
Average KL loss: 0.255120
Average total loss: 1.179154
tensor(0.0016, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.0914e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.918034
Average KL loss: 0.255163
Average total loss: 1.173197
tensor(0.0016, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-5.0066e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.927166
Average KL loss: 0.255151
Average total loss: 1.182316
tensor(0.0016, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.4920e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.922537
Average KL loss: 0.255218
Average total loss: 1.177755
tensor(0.0016, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.5659e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.910561
Average KL loss: 0.255052
Average total loss: 1.165614
tensor(0.0016, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.3225e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.925942
Average KL loss: 0.255090
Average total loss: 1.181032
tensor(0.0016, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-6.4319e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.904046
Average KL loss: 0.255180
Average total loss: 1.159226
tensor(0.0016, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.0843e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.910048
Average KL loss: 0.255065
Average total loss: 1.165113
tensor(0.0016, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-5.2697e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.904817
Average KL loss: 0.255087
Average total loss: 1.159905
tensor(0.0016, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-7.5520e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.911073
Average KL loss: 0.255234
Average total loss: 1.166306
tensor(0.0016, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.9773e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.897357
Average KL loss: 0.255382
Average total loss: 1.152739
tensor(0.0016, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.8621e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.903965
Average KL loss: 0.255445
Average total loss: 1.159410
tensor(0.0016, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.7089e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.897270
Average KL loss: 0.255555
Average total loss: 1.152826
tensor(0.0016, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.5111e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.896779
Average KL loss: 0.255669
Average total loss: 1.152448
tensor(0.0016, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5291e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.890017
Average KL loss: 0.255932
Average total loss: 1.145950
tensor(0.0016, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.2138e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.878788
Average KL loss: 0.256029
Average total loss: 1.134817
tensor(0.0016, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.6829e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.905535
Average KL loss: 0.256041
Average total loss: 1.161576
tensor(0.0016, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.6863e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.885997
Average KL loss: 0.256244
Average total loss: 1.142241
tensor(0.0017, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.9885e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.884876
Average KL loss: 0.256434
Average total loss: 1.141310
tensor(0.0017, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.1155e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.891314
Average KL loss: 0.256514
Average total loss: 1.147828
tensor(0.0017, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-6.9680e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.887622
Average KL loss: 0.256746
Average total loss: 1.144368
tensor(0.0017, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.9925e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.891735
Average KL loss: 0.256913
Average total loss: 1.148649
tensor(0.0017, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.8920e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.878947
Average KL loss: 0.257147
Average total loss: 1.136094
tensor(0.0017, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.1416e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.876568
Average KL loss: 0.257379
Average total loss: 1.133946
tensor(0.0017, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.7433e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.878843
Average KL loss: 0.257576
Average total loss: 1.136419
tensor(0.0017, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.0660e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.868172
Average KL loss: 0.257834
Average total loss: 1.126006
tensor(0.0017, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.7308e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.873115
Average KL loss: 0.257997
Average total loss: 1.131112
tensor(0.0017, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.6933e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.885499
Average KL loss: 0.258166
Average total loss: 1.143665
tensor(0.0017, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.9914e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.872172
Average KL loss: 0.258521
Average total loss: 1.130693
tensor(0.0017, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.1585e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.870598
Average KL loss: 0.258730
Average total loss: 1.129328
tensor(0.0017, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.0497e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.869072
Average KL loss: 0.258891
Average total loss: 1.127963
tensor(0.0017, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.3499e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.869615
Average KL loss: 0.259084
Average total loss: 1.128699
tensor(0.0017, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.3534e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.869203
Average KL loss: 0.259284
Average total loss: 1.128487
tensor(0.0017, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.6830e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.874073
Average KL loss: 0.259453
Average total loss: 1.133526
tensor(0.0017, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.2112e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.861931
Average KL loss: 0.259680
Average total loss: 1.121611
tensor(0.0017, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.1453e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.863921
Average KL loss: 0.260100
Average total loss: 1.124021
tensor(0.0017, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.0467e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.856197
Average KL loss: 0.260292
Average total loss: 1.116489
tensor(0.0017, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.8813e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.860205
Average KL loss: 0.260638
Average total loss: 1.120843
tensor(0.0017, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.9526e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.856677
Average KL loss: 0.260968
Average total loss: 1.117645
tensor(0.0017, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.2093e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.854273
Average KL loss: 0.261213
Average total loss: 1.115485
tensor(0.0017, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.1429e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.851395
Average KL loss: 0.261374
Average total loss: 1.112769
tensor(0.0017, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.3724e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.848652
Average KL loss: 0.261681
Average total loss: 1.110333
tensor(0.0017, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.0420e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.854172
Average KL loss: 0.261852
Average total loss: 1.116024
tensor(0.0017, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-6.1840e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.851192
Average KL loss: 0.262087
Average total loss: 1.113279
tensor(0.0017, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-6.9817e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.865822
Average KL loss: 0.262259
Average total loss: 1.128081
tensor(0.0017, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.0545e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.855182
Average KL loss: 0.262400
Average total loss: 1.117583
tensor(0.0017, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.3341e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.856180
Average KL loss: 0.262628
Average total loss: 1.118808
tensor(0.0017, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.9309e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.850140
Average KL loss: 0.262920
Average total loss: 1.113059
tensor(0.0017, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.9289e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.849019
Average KL loss: 0.263093
Average total loss: 1.112112
tensor(0.0017, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.0229e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.845320
Average KL loss: 0.263348
Average total loss: 1.108668
tensor(0.0017, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.3488e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.857580
Average KL loss: 0.263624
Average total loss: 1.121204
tensor(0.0017, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.8092e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.846797
Average KL loss: 0.263926
Average total loss: 1.110724
tensor(0.0017, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.8472e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.843419
Average KL loss: 0.264112
Average total loss: 1.107530
tensor(0.0017, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(6.6255e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.840336
Average KL loss: 0.264512
Average total loss: 1.104848
tensor(0.0018, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.9226e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.844871
Average KL loss: 0.264705
Average total loss: 1.109577
tensor(0.0018, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.8804e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.849298
Average KL loss: 0.264812
Average total loss: 1.114110
tensor(0.0018, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.0205e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.834829
Average KL loss: 0.265088
Average total loss: 1.099917
tensor(0.0018, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(3.9586e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.837331
Average KL loss: 0.265266
Average total loss: 1.102597
tensor(0.0018, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.8180e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.844158
Average KL loss: 0.265514
Average total loss: 1.109673
tensor(0.0018, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(4.3912e-11, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.842800
Average KL loss: 0.265716
Average total loss: 1.108516
tensor(0.0018, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.0342e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.838941
Average KL loss: 0.265857
Average total loss: 1.104798
tensor(0.0018, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.4949e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.834015
Average KL loss: 0.266109
Average total loss: 1.100124
tensor(0.0018, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.5604e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.836171
Average KL loss: 0.266232
Average total loss: 1.102403
tensor(0.0018, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.6030e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.839380
Average KL loss: 0.266441
Average total loss: 1.105821
tensor(0.0018, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.0991e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.846269
Average KL loss: 0.266588
Average total loss: 1.112858
tensor(0.0018, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.0040e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.838495
Average KL loss: 0.266807
Average total loss: 1.105302
tensor(0.0018, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.0930e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.832754
Average KL loss: 0.266931
Average total loss: 1.099684
tensor(0.0018, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.5295e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.835667
Average KL loss: 0.267217
Average total loss: 1.102885
tensor(0.0018, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.8695e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.841915
Average KL loss: 0.267575
Average total loss: 1.109490
tensor(0.0018, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.8232e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.827467
Average KL loss: 0.267668
Average total loss: 1.095135
tensor(0.0018, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.3253e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.834427
Average KL loss: 0.267946
Average total loss: 1.102373
tensor(0.0018, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.6223e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.829172
Average KL loss: 0.268201
Average total loss: 1.097374
tensor(0.0018, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.5856e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.827036
Average KL loss: 0.268389
Average total loss: 1.095425
tensor(0.0018, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.4734e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.824436
Average KL loss: 0.268447
Average total loss: 1.092883
tensor(0.0018, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.5192e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.826146
Average KL loss: 0.268856
Average total loss: 1.095002
tensor(0.0018, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.3753e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.826901
Average KL loss: 0.269107
Average total loss: 1.096007
tensor(0.0018, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.4929e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.825638
Average KL loss: 0.269347
Average total loss: 1.094985
tensor(0.0018, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.0803e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.825540
Average KL loss: 0.269541
Average total loss: 1.095081
tensor(0.0018, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.3638e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.818022
Average KL loss: 0.269774
Average total loss: 1.087796
tensor(0.0018, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.0997e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.826688
Average KL loss: 0.269920
Average total loss: 1.096607
tensor(0.0018, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.8034e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.821936
Average KL loss: 0.270150
Average total loss: 1.092086
tensor(0.0018, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.7691e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.821828
Average KL loss: 0.270329
Average total loss: 1.092157
tensor(0.0018, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.7934e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.825199
Average KL loss: 0.270556
Average total loss: 1.095755
tensor(0.0018, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.7701e-11, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.829773
Average KL loss: 0.270634
Average total loss: 1.100407
tensor(0.0018, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.6391e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.832769
Average KL loss: 0.270816
Average total loss: 1.103585
tensor(0.0018, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.9610e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.823636
Average KL loss: 0.271027
Average total loss: 1.094663
tensor(0.0018, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.4087e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.825828
Average KL loss: 0.271264
Average total loss: 1.097091
tensor(0.0018, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.9341e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.829024
Average KL loss: 0.271449
Average total loss: 1.100473
tensor(0.0018, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.7120e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.823077
Average KL loss: 0.271557
Average total loss: 1.094634
tensor(0.0018, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.9384e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.818673
Average KL loss: 0.271725
Average total loss: 1.090398
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.5250e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.816690
Average KL loss: 0.271869
Average total loss: 1.088559
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.6874e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.813344
Average KL loss: 0.271857
Average total loss: 1.085201
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.3391e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.815480
Average KL loss: 0.271831
Average total loss: 1.087311
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.8169e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.818136
Average KL loss: 0.271805
Average total loss: 1.089941
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.9988e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.817490
Average KL loss: 0.271803
Average total loss: 1.089293
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.9036e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.820623
Average KL loss: 0.271809
Average total loss: 1.092432
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.7161e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.817628
Average KL loss: 0.271814
Average total loss: 1.089442
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.4220e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.817660
Average KL loss: 0.271821
Average total loss: 1.089481
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.8957e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.816347
Average KL loss: 0.271843
Average total loss: 1.088190
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.6526e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.817915
Average KL loss: 0.271860
Average total loss: 1.089774
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.1943e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.820271
Average KL loss: 0.271860
Average total loss: 1.092131
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.7163e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.824860
Average KL loss: 0.271876
Average total loss: 1.096736
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.3751e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.812807
Average KL loss: 0.271879
Average total loss: 1.084686
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.0382e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.817893
Average KL loss: 0.271886
Average total loss: 1.089779
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.8194e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.823197
Average KL loss: 0.271892
Average total loss: 1.095089
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.3582e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.821247
Average KL loss: 0.271899
Average total loss: 1.093146
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.0751e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.816427
Average KL loss: 0.271909
Average total loss: 1.088336
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.6757e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.814127
Average KL loss: 0.271915
Average total loss: 1.086042
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.9073e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.816578
Average KL loss: 0.271923
Average total loss: 1.088501
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.9313e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.822701
Average KL loss: 0.271928
Average total loss: 1.094628
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.9022e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.814930
Average KL loss: 0.271934
Average total loss: 1.086864
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.8131e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.824704
Average KL loss: 0.271948
Average total loss: 1.096652
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.5711e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.823710
Average KL loss: 0.271948
Average total loss: 1.095658
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.0229e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.819004
Average KL loss: 0.271952
Average total loss: 1.090956
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.3092e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.809945
Average KL loss: 0.271952
Average total loss: 1.081896
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.9547e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.818497
Average KL loss: 0.271951
Average total loss: 1.090448
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.0096e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.825399
Average KL loss: 0.271949
Average total loss: 1.097348
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.5410e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.824614
Average KL loss: 0.271948
Average total loss: 1.096563
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.1933e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.817310
Average KL loss: 0.271950
Average total loss: 1.089259
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-9.0150e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.820867
Average KL loss: 0.271950
Average total loss: 1.092817
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.8931e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.817512
Average KL loss: 0.271950
Average total loss: 1.089462
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.8982e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.818227
Average KL loss: 0.271950
Average total loss: 1.090177
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.4969e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.821341
Average KL loss: 0.271950
Average total loss: 1.093291
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.5630e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.816657
Average KL loss: 0.271950
Average total loss: 1.088607
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.3373e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.813891
Average KL loss: 0.271951
Average total loss: 1.085842
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.6806e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.820213
Average KL loss: 0.271952
Average total loss: 1.092165
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.4570e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.813016
Average KL loss: 0.271951
Average total loss: 1.084967
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.5961e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.818457
Average KL loss: 0.271951
Average total loss: 1.090409
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1067e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.809378
Average KL loss: 0.271951
Average total loss: 1.081329
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.6650e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.816220
Average KL loss: 0.271952
Average total loss: 1.088171
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.8284e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.816170
Average KL loss: 0.271952
Average total loss: 1.088122
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.0490e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.822880
Average KL loss: 0.271952
Average total loss: 1.094832
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.1389e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.815285
Average KL loss: 0.271951
Average total loss: 1.087236
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.8262e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.810690
Average KL loss: 0.271951
Average total loss: 1.082642
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.1890e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.815708
Average KL loss: 0.271952
Average total loss: 1.087659
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.3122e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.818638
Average KL loss: 0.271952
Average total loss: 1.090589
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.7269e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.817756
Average KL loss: 0.271951
Average total loss: 1.089708
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.0791e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.814048
Average KL loss: 0.271952
Average total loss: 1.085999
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.7226e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.814004
Average KL loss: 0.271952
Average total loss: 1.085955
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.6323e-09, device='cuda:0')
 Percentile value: 8.204791157595537e-08
Non-zero model percentage: 3.5184483528137207%, Non-zero mask percentage: 3.5184483528137207%

--- Pruning Level [15/24]: ---
conv1.weight         | nonzeros =      67 /    1728             (  3.88%) | total_pruned =    1661 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      16 /   36864             (  0.04%) | total_pruned =   36848 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      16 /   36864             (  0.04%) | total_pruned =   36848 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      55 /   36864             (  0.15%) | total_pruned =   36809 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      91 /   36864             (  0.25%) | total_pruned =   36773 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     198 /   73728             (  0.27%) | total_pruned =   73530 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     382 /  147456             (  0.26%) | total_pruned =  147074 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      31 /    8192             (  0.38%) | total_pruned =    8161 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     323 /  147456             (  0.22%) | total_pruned =  147133 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     292 /  147456             (  0.20%) | total_pruned =  147164 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     932 /  294912             (  0.32%) | total_pruned =  293980 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     147 /     256             ( 57.42%) | total_pruned =     109 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1254 /  589824             (  0.21%) | total_pruned =  588570 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     152 /     256             ( 59.38%) | total_pruned =     104 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     138 /   32768             (  0.42%) | total_pruned =   32630 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      58 /     256             ( 22.66%) | total_pruned =     198 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     708 /  589824             (  0.12%) | total_pruned =  589116 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      93 /     256             ( 36.33%) | total_pruned =     163 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     520 /  589824             (  0.09%) | total_pruned =  589304 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    1111 / 1179648             (  0.09%) | total_pruned = 1178537 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     177 /     512             ( 34.57%) | total_pruned =     335 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    7969 / 2359296             (  0.34%) | total_pruned = 2351327 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3051 /  131072             (  2.33%) | total_pruned =  128021 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      34 /     512             (  6.64%) | total_pruned =     478 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   98873 / 2359296             (  4.19%) | total_pruned = 2260423 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      95 /     512             ( 18.55%) | total_pruned =     417 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  274734 / 2359296             ( 11.64%) | total_pruned = 2084562 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      53 /     512             ( 10.35%) | total_pruned =     459 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     145 /     512             ( 28.32%) | total_pruned =     367 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      98 /     512             ( 19.14%) | total_pruned =     414 | shape = torch.Size([512])
linear.weight        | nonzeros =     864 /    5120             ( 16.88%) | total_pruned =    4256 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 393319, pruned : 10785443, total: 11178762, Compression rate :      28.42x  ( 96.48% pruned)
Train Epoch: 99/100 Loss: 0.915940 Accuracy: 68.46 75.45 % Best test Accuracy: 69.02%
tensor(0.0019, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.2996e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.295136
Average KL loss: 0.263451
Average total loss: 1.558587
tensor(0.0018, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.3236e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.244383
Average KL loss: 0.253977
Average total loss: 1.498360
tensor(0.0016, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.5110e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.230221
Average KL loss: 0.247039
Average total loss: 1.477260
tensor(0.0016, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.5612e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.216834
Average KL loss: 0.240596
Average total loss: 1.457430
tensor(0.0015, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.7158e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.181815
Average KL loss: 0.234664
Average total loss: 1.416479
tensor(0.0015, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.6069e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.179195
Average KL loss: 0.229566
Average total loss: 1.408761
tensor(0.0015, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.0788e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.160000
Average KL loss: 0.226018
Average total loss: 1.386018
tensor(0.0015, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.4209e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.155733
Average KL loss: 0.224246
Average total loss: 1.379979
tensor(0.0014, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-8.4091e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.155606
Average KL loss: 0.223566
Average total loss: 1.379172
tensor(0.0014, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.2738e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.139348
Average KL loss: 0.223214
Average total loss: 1.362561
tensor(0.0014, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.2706e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.131973
Average KL loss: 0.222881
Average total loss: 1.354854
tensor(0.0014, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-9.6980e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.119351
Average KL loss: 0.222562
Average total loss: 1.341914
tensor(0.0014, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.4590e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.092324
Average KL loss: 0.222166
Average total loss: 1.314491
tensor(0.0014, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.4426e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.094430
Average KL loss: 0.221929
Average total loss: 1.316360
tensor(0.0014, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.1955e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.079717
Average KL loss: 0.221722
Average total loss: 1.301440
tensor(0.0014, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.1014e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.077198
Average KL loss: 0.221601
Average total loss: 1.298799
tensor(0.0014, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.2332e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.070773
Average KL loss: 0.221365
Average total loss: 1.292139
tensor(0.0014, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.0619e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.059839
Average KL loss: 0.221174
Average total loss: 1.281013
tensor(0.0014, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.0633e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.071054
Average KL loss: 0.221263
Average total loss: 1.292317
tensor(0.0014, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.3142e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.054760
Average KL loss: 0.221354
Average total loss: 1.276114
tensor(0.0014, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-9.6365e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.036029
Average KL loss: 0.221271
Average total loss: 1.257300
tensor(0.0014, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-6.9376e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.046622
Average KL loss: 0.221167
Average total loss: 1.267789
tensor(0.0014, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(2.9751e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.066719
Average KL loss: 0.221108
Average total loss: 1.287827
tensor(0.0014, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-9.1845e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.063914
Average KL loss: 0.221048
Average total loss: 1.284961
tensor(0.0014, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-3.2440e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.040404
Average KL loss: 0.220856
Average total loss: 1.261260
tensor(0.0014, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-5.2368e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.025070
Average KL loss: 0.220731
Average total loss: 1.245801
tensor(0.0014, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-9.1963e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.013054
Average KL loss: 0.220755
Average total loss: 1.233810
tensor(0.0014, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-8.4778e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.016871
Average KL loss: 0.220749
Average total loss: 1.237620
tensor(0.0014, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-4.5447e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.027211
Average KL loss: 0.220752
Average total loss: 1.247963
tensor(0.0014, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.7409e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.016883
Average KL loss: 0.220765
Average total loss: 1.237647
tensor(0.0014, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.5481e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.999569
Average KL loss: 0.220890
Average total loss: 1.220458
tensor(0.0014, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-9.0374e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.014093
Average KL loss: 0.220885
Average total loss: 1.234978
tensor(0.0014, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.4817e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.002571
Average KL loss: 0.221086
Average total loss: 1.223657
tensor(0.0014, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.5086e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.005502
Average KL loss: 0.221152
Average total loss: 1.226653
tensor(0.0014, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.9893e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.002365
Average KL loss: 0.221249
Average total loss: 1.223614
tensor(0.0014, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-3.6494e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.993042
Average KL loss: 0.221309
Average total loss: 1.214351
tensor(0.0014, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.0249e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.984763
Average KL loss: 0.221415
Average total loss: 1.206178
tensor(0.0014, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-3.5545e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.988966
Average KL loss: 0.221471
Average total loss: 1.210438
tensor(0.0014, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-5.5080e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.988880
Average KL loss: 0.221782
Average total loss: 1.210662
tensor(0.0014, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-5.1326e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.978257
Average KL loss: 0.221982
Average total loss: 1.200239
tensor(0.0014, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-4.7640e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.984230
Average KL loss: 0.222034
Average total loss: 1.206265
tensor(0.0014, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.6334e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.972885
Average KL loss: 0.222130
Average total loss: 1.195016
tensor(0.0014, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.6213e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.980030
Average KL loss: 0.222245
Average total loss: 1.202275
tensor(0.0014, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-9.4417e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.978376
Average KL loss: 0.222324
Average total loss: 1.200700
tensor(0.0014, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-5.6527e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.979204
Average KL loss: 0.222373
Average total loss: 1.201577
tensor(0.0014, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-3.4303e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.984738
Average KL loss: 0.222448
Average total loss: 1.207186
tensor(0.0014, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.4406e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.965336
Average KL loss: 0.222619
Average total loss: 1.187956
tensor(0.0014, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-6.9590e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.968418
Average KL loss: 0.222795
Average total loss: 1.191213
tensor(0.0014, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-7.6858e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.971440
Average KL loss: 0.223023
Average total loss: 1.194463
tensor(0.0014, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-8.8878e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.974895
Average KL loss: 0.223165
Average total loss: 1.198060
tensor(0.0014, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(3.4941e-11, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.962367
Average KL loss: 0.223338
Average total loss: 1.185705
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.2745e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.953926
Average KL loss: 0.223431
Average total loss: 1.177357
tensor(0.0015, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-5.5700e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.951157
Average KL loss: 0.223587
Average total loss: 1.174744
tensor(0.0015, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-5.8244e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.951681
Average KL loss: 0.223870
Average total loss: 1.175551
tensor(0.0015, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-5.4686e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.943100
Average KL loss: 0.224062
Average total loss: 1.167161
tensor(0.0015, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-5.2206e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.963194
Average KL loss: 0.224218
Average total loss: 1.187412
tensor(0.0015, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-5.4507e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.954241
Average KL loss: 0.224450
Average total loss: 1.178691
tensor(0.0015, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.2297e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.967541
Average KL loss: 0.224654
Average total loss: 1.192195
tensor(0.0015, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.2860e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.945714
Average KL loss: 0.224805
Average total loss: 1.170519
tensor(0.0015, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.4972e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.947252
Average KL loss: 0.224999
Average total loss: 1.172251
tensor(0.0015, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-5.8311e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.945228
Average KL loss: 0.225185
Average total loss: 1.170412
tensor(0.0015, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-9.8705e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.947684
Average KL loss: 0.225405
Average total loss: 1.173089
tensor(0.0015, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-8.0070e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.953533
Average KL loss: 0.225535
Average total loss: 1.179068
tensor(0.0015, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.1490e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.943055
Average KL loss: 0.225644
Average total loss: 1.168698
tensor(0.0015, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.5746e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.940557
Average KL loss: 0.225830
Average total loss: 1.166387
tensor(0.0015, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-5.6009e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.945254
Average KL loss: 0.225976
Average total loss: 1.171230
tensor(0.0015, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.6611e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.933745
Average KL loss: 0.226099
Average total loss: 1.159844
tensor(0.0015, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-6.8553e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.965456
Average KL loss: 0.226165
Average total loss: 1.191621
tensor(0.0015, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.1751e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.945345
Average KL loss: 0.226346
Average total loss: 1.171691
tensor(0.0015, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.0311e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.940075
Average KL loss: 0.226602
Average total loss: 1.166677
tensor(0.0015, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-9.4232e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.940461
Average KL loss: 0.226808
Average total loss: 1.167270
tensor(0.0015, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.6898e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.929450
Average KL loss: 0.227074
Average total loss: 1.156524
tensor(0.0015, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-7.6233e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.927366
Average KL loss: 0.227357
Average total loss: 1.154722
tensor(0.0015, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.5708e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.921420
Average KL loss: 0.227493
Average total loss: 1.148913
tensor(0.0015, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-5.3344e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.942841
Average KL loss: 0.227610
Average total loss: 1.170450
tensor(0.0015, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.9685e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.947224
Average KL loss: 0.227768
Average total loss: 1.174992
tensor(0.0015, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.3483e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.926918
Average KL loss: 0.227881
Average total loss: 1.154798
tensor(0.0015, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.5390e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.921830
Average KL loss: 0.228067
Average total loss: 1.149897
tensor(0.0015, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.8878e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.943906
Average KL loss: 0.228280
Average total loss: 1.172186
tensor(0.0015, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.1777e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.926879
Average KL loss: 0.228424
Average total loss: 1.155304
tensor(0.0015, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.3627e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.917917
Average KL loss: 0.228680
Average total loss: 1.146597
tensor(0.0015, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.0300e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.932500
Average KL loss: 0.228912
Average total loss: 1.161412
tensor(0.0015, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.1736e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.910995
Average KL loss: 0.229226
Average total loss: 1.140221
tensor(0.0015, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-3.3732e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.925287
Average KL loss: 0.229456
Average total loss: 1.154743
tensor(0.0015, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.0820e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.931441
Average KL loss: 0.229632
Average total loss: 1.161074
tensor(0.0015, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.9985e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.912635
Average KL loss: 0.229777
Average total loss: 1.142411
tensor(0.0015, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.3810e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.920842
Average KL loss: 0.229902
Average total loss: 1.150744
tensor(0.0015, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.8077e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.933705
Average KL loss: 0.230142
Average total loss: 1.163847
tensor(0.0015, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.7040e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.916453
Average KL loss: 0.230264
Average total loss: 1.146717
tensor(0.0015, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.2920e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.914079
Average KL loss: 0.230435
Average total loss: 1.144513
tensor(0.0015, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.4739e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.921116
Average KL loss: 0.230630
Average total loss: 1.151746
tensor(0.0015, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.7100e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.914148
Average KL loss: 0.230821
Average total loss: 1.144968
tensor(0.0015, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.4604e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.919081
Average KL loss: 0.230918
Average total loss: 1.149999
tensor(0.0016, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.4274e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.909582
Average KL loss: 0.231147
Average total loss: 1.140729
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.4582e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.908795
Average KL loss: 0.231301
Average total loss: 1.140096
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(6.4533e-11, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.915334
Average KL loss: 0.231307
Average total loss: 1.146641
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.8967e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.923545
Average KL loss: 0.231306
Average total loss: 1.154852
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.9274e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.910053
Average KL loss: 0.231303
Average total loss: 1.141356
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.5162e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.906719
Average KL loss: 0.231299
Average total loss: 1.138018
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.4549e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.915919
Average KL loss: 0.231292
Average total loss: 1.147211
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.1051e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.919560
Average KL loss: 0.231291
Average total loss: 1.150850
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.1655e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.911529
Average KL loss: 0.231293
Average total loss: 1.142822
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.9342e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.901790
Average KL loss: 0.231301
Average total loss: 1.133091
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.3194e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.911221
Average KL loss: 0.231312
Average total loss: 1.142532
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.3747e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.907295
Average KL loss: 0.231317
Average total loss: 1.138612
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.6336e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.903857
Average KL loss: 0.231324
Average total loss: 1.135181
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.1870e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.932233
Average KL loss: 0.231324
Average total loss: 1.163556
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-9.0610e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.915082
Average KL loss: 0.231323
Average total loss: 1.146404
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.4983e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.902930
Average KL loss: 0.231327
Average total loss: 1.134256
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.3961e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.916899
Average KL loss: 0.231332
Average total loss: 1.148231
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-8.1449e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.919061
Average KL loss: 0.231338
Average total loss: 1.150400
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.0178e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.906423
Average KL loss: 0.231342
Average total loss: 1.137765
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.7496e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.914111
Average KL loss: 0.231339
Average total loss: 1.145451
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.5221e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.909197
Average KL loss: 0.231352
Average total loss: 1.140549
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.3097e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.912343
Average KL loss: 0.231356
Average total loss: 1.143700
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(1.9324e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.906945
Average KL loss: 0.231357
Average total loss: 1.138302
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.5496e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.909585
Average KL loss: 0.231358
Average total loss: 1.140943
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(4.6405e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.896499
Average KL loss: 0.231358
Average total loss: 1.127857
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.5755e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.908258
Average KL loss: 0.231359
Average total loss: 1.139617
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.8792e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.912823
Average KL loss: 0.231360
Average total loss: 1.144182
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.5673e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.907017
Average KL loss: 0.231361
Average total loss: 1.138378
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.4291e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.908525
Average KL loss: 0.231363
Average total loss: 1.139888
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.5748e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.903883
Average KL loss: 0.231364
Average total loss: 1.135247
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.0707e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.914991
Average KL loss: 0.231364
Average total loss: 1.146355
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.8055e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.905320
Average KL loss: 0.231364
Average total loss: 1.136684
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(1.0263e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.903563
Average KL loss: 0.231365
Average total loss: 1.134928
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.1813e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.907986
Average KL loss: 0.231365
Average total loss: 1.139352
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.9364e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.901831
Average KL loss: 0.231366
Average total loss: 1.133196
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.8693e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.911648
Average KL loss: 0.231366
Average total loss: 1.143013
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.1237e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.910141
Average KL loss: 0.231366
Average total loss: 1.141506
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.7011e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.913695
Average KL loss: 0.231366
Average total loss: 1.145061
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-9.7168e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.901891
Average KL loss: 0.231366
Average total loss: 1.133257
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.0479e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.908786
Average KL loss: 0.231366
Average total loss: 1.140153
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.1930e-11, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.903462
Average KL loss: 0.231366
Average total loss: 1.134828
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.3822e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.910344
Average KL loss: 0.231367
Average total loss: 1.141710
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.7432e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.918567
Average KL loss: 0.231367
Average total loss: 1.149934
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.9140e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.908195
Average KL loss: 0.231367
Average total loss: 1.139562
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.4895e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.909488
Average KL loss: 0.231367
Average total loss: 1.140855
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.4853e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.908023
Average KL loss: 0.231368
Average total loss: 1.139391
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.2599e-09, device='cuda:0')
 Percentile value: 8.018233188522572e-08
Non-zero model percentage: 2.8147659301757812%, Non-zero mask percentage: 2.8147659301757812%

--- Pruning Level [16/24]: ---
conv1.weight         | nonzeros =      66 /    1728             (  3.82%) | total_pruned =    1662 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      13 /   36864             (  0.04%) | total_pruned =   36851 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      14 /   36864             (  0.04%) | total_pruned =   36850 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      40 /   36864             (  0.11%) | total_pruned =   36824 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      60 /   36864             (  0.16%) | total_pruned =   36804 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     154 /   73728             (  0.21%) | total_pruned =   73574 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     329 /  147456             (  0.22%) | total_pruned =  147127 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      26 /    8192             (  0.32%) | total_pruned =    8166 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     276 /  147456             (  0.19%) | total_pruned =  147180 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     253 /  147456             (  0.17%) | total_pruned =  147203 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     768 /  294912             (  0.26%) | total_pruned =  294144 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     993 /  589824             (  0.17%) | total_pruned =  588831 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     104 /   32768             (  0.32%) | total_pruned =   32664 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     563 /  589824             (  0.10%) | total_pruned =  589261 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      80 /     256             ( 31.25%) | total_pruned =     176 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     409 /  589824             (  0.07%) | total_pruned =  589415 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      67 /     256             ( 26.17%) | total_pruned =     189 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     889 / 1179648             (  0.08%) | total_pruned = 1178759 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     162 /     512             ( 31.64%) | total_pruned =     350 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     825 / 2359296             (  0.03%) | total_pruned = 2358471 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      93 /     512             ( 18.16%) | total_pruned =     419 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      25 /     512             (  4.88%) | total_pruned =     487 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      69 /  131072             (  0.05%) | total_pruned =  131003 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   32800 / 2359296             (  1.39%) | total_pruned = 2326496 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      94 /     512             ( 18.36%) | total_pruned =     418 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  273731 / 2359296             ( 11.60%) | total_pruned = 2085565 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      53 /     512             ( 10.35%) | total_pruned =     459 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     143 /     512             ( 27.93%) | total_pruned =     369 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      94 /     512             ( 18.36%) | total_pruned =     418 | shape = torch.Size([512])
linear.weight        | nonzeros =     782 /    5120             ( 15.27%) | total_pruned =    4338 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 314656, pruned : 10864106, total: 11178762, Compression rate :      35.53x  ( 97.19% pruned)
Train Epoch: 99/100 Loss: 0.870363 Accuracy: 68.36 74.06 % Best test Accuracy: 68.59%
tensor(0.0016, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.2760e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.102856
Average KL loss: 0.225314
Average total loss: 1.328170
tensor(0.0015, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.4474e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.085073
Average KL loss: 0.219272
Average total loss: 1.304345
tensor(0.0014, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.0977e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.090508
Average KL loss: 0.215399
Average total loss: 1.305907
tensor(0.0014, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-7.9479e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.081468
Average KL loss: 0.212256
Average total loss: 1.293725
tensor(0.0013, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-7.2328e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.074550
Average KL loss: 0.209639
Average total loss: 1.284189
tensor(0.0013, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.2379e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.072665
Average KL loss: 0.207542
Average total loss: 1.280207
tensor(0.0013, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-4.6174e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.067667
Average KL loss: 0.206193
Average total loss: 1.273860
tensor(0.0013, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-7.5373e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.042431
Average KL loss: 0.205469
Average total loss: 1.247900
tensor(0.0013, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-7.7723e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.060472
Average KL loss: 0.205048
Average total loss: 1.265520
tensor(0.0013, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-8.5904e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.053910
Average KL loss: 0.204733
Average total loss: 1.258643
tensor(0.0013, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-5.9702e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.052008
Average KL loss: 0.204406
Average total loss: 1.256414
tensor(0.0013, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-5.1590e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.050142
Average KL loss: 0.204179
Average total loss: 1.254322
tensor(0.0013, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-5.3756e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.040618
Average KL loss: 0.203945
Average total loss: 1.244563
tensor(0.0013, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-4.2368e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.030727
Average KL loss: 0.203866
Average total loss: 1.234593
tensor(0.0013, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-5.5290e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.027399
Average KL loss: 0.203784
Average total loss: 1.231182
tensor(0.0013, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-4.7752e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.019889
Average KL loss: 0.203865
Average total loss: 1.223754
tensor(0.0013, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-5.5798e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.040556
Average KL loss: 0.203858
Average total loss: 1.244414
tensor(0.0013, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-5.2256e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.030031
Average KL loss: 0.203805
Average total loss: 1.233836
tensor(0.0013, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.0215e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.004028
Average KL loss: 0.203781
Average total loss: 1.207809
tensor(0.0013, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.4062e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.001958
Average KL loss: 0.203838
Average total loss: 1.205796
tensor(0.0013, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-9.4919e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.993773
Average KL loss: 0.203955
Average total loss: 1.197727
tensor(0.0013, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-9.5155e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.007446
Average KL loss: 0.203953
Average total loss: 1.211399
tensor(0.0013, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.0372e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.002125
Average KL loss: 0.203923
Average total loss: 1.206048
tensor(0.0013, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-9.6770e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.989690
Average KL loss: 0.204046
Average total loss: 1.193736
tensor(0.0013, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.5147e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.007604
Average KL loss: 0.204116
Average total loss: 1.211720
tensor(0.0013, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.8831e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.975726
Average KL loss: 0.204035
Average total loss: 1.179762
tensor(0.0013, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.2663e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.966274
Average KL loss: 0.204192
Average total loss: 1.170465
tensor(0.0013, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-6.3687e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.997978
Average KL loss: 0.204311
Average total loss: 1.202289
tensor(0.0013, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-7.9304e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.980882
Average KL loss: 0.204451
Average total loss: 1.185333
tensor(0.0013, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.3199e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.986684
Average KL loss: 0.204571
Average total loss: 1.191255
tensor(0.0013, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-3.8768e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.969632
Average KL loss: 0.204593
Average total loss: 1.174225
tensor(0.0013, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.1297e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.975158
Average KL loss: 0.204663
Average total loss: 1.179821
tensor(0.0013, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.5522e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.968163
Average KL loss: 0.204833
Average total loss: 1.172996
tensor(0.0013, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-8.4875e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.965545
Average KL loss: 0.205072
Average total loss: 1.170618
tensor(0.0013, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.1188e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.962460
Average KL loss: 0.205262
Average total loss: 1.167723
tensor(0.0013, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-5.0046e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.964843
Average KL loss: 0.205476
Average total loss: 1.170319
tensor(0.0013, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.5070e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.977230
Average KL loss: 0.205539
Average total loss: 1.182769
tensor(0.0013, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-5.2728e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.970967
Average KL loss: 0.205683
Average total loss: 1.176650
tensor(0.0013, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-5.7086e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.959028
Average KL loss: 0.205832
Average total loss: 1.164860
tensor(0.0013, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.0447e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.963467
Average KL loss: 0.206055
Average total loss: 1.169521
tensor(0.0013, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.9043e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.956874
Average KL loss: 0.206211
Average total loss: 1.163086
tensor(0.0013, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.8751e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.950448
Average KL loss: 0.206377
Average total loss: 1.156825
tensor(0.0013, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.8572e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.944701
Average KL loss: 0.206565
Average total loss: 1.151266
tensor(0.0013, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-9.2389e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.959347
Average KL loss: 0.206836
Average total loss: 1.166183
tensor(0.0013, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.8463e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.952284
Average KL loss: 0.206995
Average total loss: 1.159279
tensor(0.0013, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.7350e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.938088
Average KL loss: 0.207156
Average total loss: 1.145244
tensor(0.0014, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-3.1809e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.950985
Average KL loss: 0.207263
Average total loss: 1.158248
tensor(0.0014, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-4.7337e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.950967
Average KL loss: 0.207394
Average total loss: 1.158362
tensor(0.0014, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-8.0112e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.949534
Average KL loss: 0.207693
Average total loss: 1.157227
tensor(0.0014, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-2.3215e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.948321
Average KL loss: 0.207863
Average total loss: 1.156185
tensor(0.0014, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-6.4213e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.962851
Average KL loss: 0.207953
Average total loss: 1.170804
tensor(0.0014, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-3.1327e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.939345
Average KL loss: 0.208089
Average total loss: 1.147434
tensor(0.0014, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-3.6809e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.942962
Average KL loss: 0.208399
Average total loss: 1.151361
tensor(0.0014, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-7.2067e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.937730
Average KL loss: 0.208694
Average total loss: 1.146424
tensor(0.0014, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-5.9607e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.940943
Average KL loss: 0.208928
Average total loss: 1.149872
tensor(0.0014, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.4773e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.938999
Average KL loss: 0.209149
Average total loss: 1.148148
tensor(0.0014, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-2.2523e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.948842
Average KL loss: 0.209348
Average total loss: 1.158190
tensor(0.0014, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-9.4364e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.932789
Average KL loss: 0.209341
Average total loss: 1.142131
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-5.2648e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.928340
Average KL loss: 0.209346
Average total loss: 1.137686
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.8517e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.956487
Average KL loss: 0.209366
Average total loss: 1.165852
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.9231e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.933591
Average KL loss: 0.209374
Average total loss: 1.142964
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.8672e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.928171
Average KL loss: 0.209390
Average total loss: 1.137561
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.5621e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.934537
Average KL loss: 0.209405
Average total loss: 1.143942
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-5.0637e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.928848
Average KL loss: 0.209413
Average total loss: 1.138260
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.3753e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.931690
Average KL loss: 0.209417
Average total loss: 1.141107
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.1153e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.921642
Average KL loss: 0.209424
Average total loss: 1.131066
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.1469e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.935035
Average KL loss: 0.209431
Average total loss: 1.144466
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.6412e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.944246
Average KL loss: 0.209435
Average total loss: 1.153681
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.5317e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.933195
Average KL loss: 0.209449
Average total loss: 1.142643
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(8.0460e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.925783
Average KL loss: 0.209463
Average total loss: 1.135246
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-7.2215e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.924213
Average KL loss: 0.209485
Average total loss: 1.133698
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.8872e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.936258
Average KL loss: 0.209500
Average total loss: 1.145758
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.9405e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.936050
Average KL loss: 0.209512
Average total loss: 1.145562
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.0424e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.966523
Average KL loss: 0.209526
Average total loss: 1.176050
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.6250e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.928538
Average KL loss: 0.209542
Average total loss: 1.138079
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-6.6637e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.930362
Average KL loss: 0.209555
Average total loss: 1.139917
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.8487e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.925644
Average KL loss: 0.209570
Average total loss: 1.135214
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-8.2259e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.930504
Average KL loss: 0.209584
Average total loss: 1.140088
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(3.9553e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.933967
Average KL loss: 0.209585
Average total loss: 1.143553
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-7.2200e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.936826
Average KL loss: 0.209587
Average total loss: 1.146413
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.6296e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.929603
Average KL loss: 0.209589
Average total loss: 1.139191
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.6752e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.936397
Average KL loss: 0.209590
Average total loss: 1.145987
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.5039e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.924519
Average KL loss: 0.209592
Average total loss: 1.134111
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.3384e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.927282
Average KL loss: 0.209594
Average total loss: 1.136876
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.9903e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.922730
Average KL loss: 0.209595
Average total loss: 1.132325
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.5460e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.933867
Average KL loss: 0.209597
Average total loss: 1.143465
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.9618e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.922180
Average KL loss: 0.209599
Average total loss: 1.131780
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-7.5017e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.927847
Average KL loss: 0.209600
Average total loss: 1.137448
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.2238e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.923572
Average KL loss: 0.209601
Average total loss: 1.133173
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.4937e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.937195
Average KL loss: 0.209601
Average total loss: 1.146796
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.9502e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.929707
Average KL loss: 0.209601
Average total loss: 1.139308
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.8796e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.923623
Average KL loss: 0.209602
Average total loss: 1.133224
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-9.8753e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.933773
Average KL loss: 0.209602
Average total loss: 1.143375
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-7.6425e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.932779
Average KL loss: 0.209602
Average total loss: 1.142381
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-7.2316e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.939059
Average KL loss: 0.209602
Average total loss: 1.148661
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-5.4009e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.945105
Average KL loss: 0.209602
Average total loss: 1.154707
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.0902e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.934672
Average KL loss: 0.209603
Average total loss: 1.144275
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.4837e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.935629
Average KL loss: 0.209603
Average total loss: 1.145232
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.2760e-09, device='cuda:0')
 Percentile value: 8.041198640285074e-08
Non-zero model percentage: 2.251814603805542%, Non-zero mask percentage: 2.251814603805542%

--- Pruning Level [17/24]: ---
conv1.weight         | nonzeros =      65 /    1728             (  3.76%) | total_pruned =    1663 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      12 /   36864             (  0.03%) | total_pruned =   36852 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       8 /   36864             (  0.02%) | total_pruned =   36856 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      31 /   36864             (  0.08%) | total_pruned =   36833 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      53 /   36864             (  0.14%) | total_pruned =   36811 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     118 /   73728             (  0.16%) | total_pruned =   73610 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     267 /  147456             (  0.18%) | total_pruned =  147189 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      20 /    8192             (  0.24%) | total_pruned =    8172 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     242 /  147456             (  0.16%) | total_pruned =  147214 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     221 /  147456             (  0.15%) | total_pruned =  147235 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     618 /  294912             (  0.21%) | total_pruned =  294294 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     121 /     256             ( 47.27%) | total_pruned =     135 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     808 /  589824             (  0.14%) | total_pruned =  589016 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      80 /   32768             (  0.24%) | total_pruned =   32688 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      39 /     256             ( 15.23%) | total_pruned =     217 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     427 /  589824             (  0.07%) | total_pruned =  589397 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     327 /  589824             (  0.06%) | total_pruned =  589497 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      66 /     256             ( 25.78%) | total_pruned =     190 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     705 / 1179648             (  0.06%) | total_pruned = 1178943 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     152 /     512             ( 29.69%) | total_pruned =     360 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     670 / 2359296             (  0.03%) | total_pruned = 2358626 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      86 /     512             ( 16.80%) | total_pruned =     426 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      57 /  131072             (  0.04%) | total_pruned =  131015 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      23 /     512             (  4.49%) | total_pruned =     489 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     562 / 2359296             (  0.02%) | total_pruned = 2358734 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      65 /     512             ( 12.70%) | total_pruned =     447 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  244419 / 2359296             ( 10.36%) | total_pruned = 2114877 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     124 /     512             ( 24.22%) | total_pruned =     388 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      82 /     512             ( 16.02%) | total_pruned =     430 | shape = torch.Size([512])
linear.weight        | nonzeros =     710 /    5120             ( 13.87%) | total_pruned =    4410 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 251725, pruned : 10927037, total: 11178762, Compression rate :      44.41x  ( 97.75% pruned)
Train Epoch: 56/100 Loss: 1.210853 Accuracy: 63.54 66.18 % Best test Accuracy: 65.86%
tensor(0.0014, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-5.6536e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.283567
Average KL loss: 0.202987
Average total loss: 1.486554
tensor(0.0013, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-9.7826e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.307698
Average KL loss: 0.194251
Average total loss: 1.501950
tensor(0.0012, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-9.1469e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.297710
Average KL loss: 0.187147
Average total loss: 1.484857
tensor(0.0012, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.1428e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.273130
Average KL loss: 0.180652
Average total loss: 1.453781
tensor(0.0011, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.3504e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.294872
Average KL loss: 0.174294
Average total loss: 1.469166
tensor(0.0011, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.3414e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.275381
Average KL loss: 0.168619
Average total loss: 1.444000
tensor(0.0011, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.3948e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.267833
Average KL loss: 0.164725
Average total loss: 1.432558
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.4921e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.282653
Average KL loss: 0.162852
Average total loss: 1.445505
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.2291e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.237297
Average KL loss: 0.162122
Average total loss: 1.399418
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.2105e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.249721
Average KL loss: 0.161698
Average total loss: 1.411418
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.2583e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.231828
Average KL loss: 0.161333
Average total loss: 1.393161
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.5684e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.244753
Average KL loss: 0.161126
Average total loss: 1.405879
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.9035e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.220424
Average KL loss: 0.160980
Average total loss: 1.381404
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.6203e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.229066
Average KL loss: 0.160874
Average total loss: 1.389940
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.2031e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.215521
Average KL loss: 0.160729
Average total loss: 1.376250
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.4882e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.209282
Average KL loss: 0.160595
Average total loss: 1.369876
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.9970e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.198142
Average KL loss: 0.160571
Average total loss: 1.358713
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0068e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.178472
Average KL loss: 0.160620
Average total loss: 1.339092
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.4575e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.193951
Average KL loss: 0.160658
Average total loss: 1.354608
tensor(0.0010, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.1034e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.172491
Average KL loss: 0.160740
Average total loss: 1.333231
tensor(0.0010, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.7292e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.179100
Average KL loss: 0.160875
Average total loss: 1.339975
tensor(0.0010, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0210e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.169922
Average KL loss: 0.160998
Average total loss: 1.330920
tensor(0.0010, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.7626e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.163994
Average KL loss: 0.161119
Average total loss: 1.325113
tensor(0.0010, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.0965e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.155513
Average KL loss: 0.161189
Average total loss: 1.316702
tensor(0.0010, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.0184e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.177400
Average KL loss: 0.161309
Average total loss: 1.338710
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.2808e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.181068
Average KL loss: 0.161445
Average total loss: 1.342513
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-7.5311e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.151720
Average KL loss: 0.161519
Average total loss: 1.313239
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-7.5625e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.140542
Average KL loss: 0.161600
Average total loss: 1.302143
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-7.5964e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.141263
Average KL loss: 0.161794
Average total loss: 1.303056
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.1228e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.143088
Average KL loss: 0.161928
Average total loss: 1.305016
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.3182e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.151105
Average KL loss: 0.162117
Average total loss: 1.313223
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.6298e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.154850
Average KL loss: 0.162294
Average total loss: 1.317144
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.2185e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.129503
Average KL loss: 0.162446
Average total loss: 1.291949
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.4811e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.140028
Average KL loss: 0.162657
Average total loss: 1.302684
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.6982e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.135076
Average KL loss: 0.162835
Average total loss: 1.297911
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-9.3917e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.138382
Average KL loss: 0.162986
Average total loss: 1.301368
tensor(0.0011, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.6111e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.145626
Average KL loss: 0.163112
Average total loss: 1.308738
tensor(0.0011, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.3733e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.126588
Average KL loss: 0.163325
Average total loss: 1.289913
tensor(0.0011, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-8.9090e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.143251
Average KL loss: 0.163516
Average total loss: 1.306767
tensor(0.0011, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-6.7293e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.120224
Average KL loss: 0.163612
Average total loss: 1.283835
tensor(0.0011, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-4.3591e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.115553
Average KL loss: 0.163769
Average total loss: 1.279321
tensor(0.0011, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-4.6681e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.115209
Average KL loss: 0.163943
Average total loss: 1.279152
tensor(0.0011, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.0734e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.110589
Average KL loss: 0.164104
Average total loss: 1.274693
tensor(0.0011, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-4.5687e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.121075
Average KL loss: 0.164185
Average total loss: 1.285260
tensor(0.0011, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.3360e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.125923
Average KL loss: 0.164252
Average total loss: 1.290175
tensor(0.0011, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-6.1638e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.121892
Average KL loss: 0.164440
Average total loss: 1.286333
tensor(0.0011, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-3.8395e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.115377
Average KL loss: 0.164656
Average total loss: 1.280033
tensor(0.0011, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-5.2031e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.120782
Average KL loss: 0.164778
Average total loss: 1.285559
tensor(0.0011, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-3.6429e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.116598
Average KL loss: 0.164916
Average total loss: 1.281514
tensor(0.0011, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-4.6740e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.120862
Average KL loss: 0.165068
Average total loss: 1.285930
tensor(0.0011, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.8037e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.125448
Average KL loss: 0.165240
Average total loss: 1.290688
tensor(0.0011, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.3999e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.100999
Average KL loss: 0.165404
Average total loss: 1.266403
tensor(0.0011, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-6.0481e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.107206
Average KL loss: 0.165613
Average total loss: 1.272819
tensor(0.0011, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.2683e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.094776
Average KL loss: 0.165822
Average total loss: 1.260597
tensor(0.0011, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-4.0095e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.096160
Average KL loss: 0.165979
Average total loss: 1.262139
tensor(0.0011, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-5.6650e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.102000
Average KL loss: 0.166136
Average total loss: 1.268136
tensor(0.0011, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-9.9439e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.102969
Average KL loss: 0.166295
Average total loss: 1.269264
tensor(0.0011, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.3603e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.112673
Average KL loss: 0.166482
Average total loss: 1.279156
tensor(0.0011, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-9.1198e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.106464
Average KL loss: 0.166610
Average total loss: 1.273075
tensor(0.0011, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-6.8615e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.096571
Average KL loss: 0.166748
Average total loss: 1.263319
tensor(0.0011, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-4.6862e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.119455
Average KL loss: 0.166839
Average total loss: 1.286295
tensor(0.0011, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.3815e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.101384
Average KL loss: 0.166992
Average total loss: 1.268375
tensor(0.0011, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.6615e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.082269
Average KL loss: 0.167146
Average total loss: 1.249416
tensor(0.0011, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-7.7503e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.099948
Average KL loss: 0.167320
Average total loss: 1.267268
tensor(0.0011, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-4.1659e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.080876
Average KL loss: 0.167503
Average total loss: 1.248380
tensor(0.0011, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.7074e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.085075
Average KL loss: 0.167656
Average total loss: 1.252730
tensor(0.0011, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.2873e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.094634
Average KL loss: 0.167770
Average total loss: 1.262403
tensor(0.0011, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.6484e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.084478
Average KL loss: 0.167906
Average total loss: 1.252384
tensor(0.0011, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-6.8540e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.105512
Average KL loss: 0.168049
Average total loss: 1.273561
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-5.7046e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.083436
Average KL loss: 0.168203
Average total loss: 1.251639
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-3.0790e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.098917
Average KL loss: 0.168284
Average total loss: 1.267200
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-2.8048e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.089374
Average KL loss: 0.168451
Average total loss: 1.257825
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-9.1551e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.082577
Average KL loss: 0.168566
Average total loss: 1.251143
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-2.7828e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.093476
Average KL loss: 0.168626
Average total loss: 1.262102
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.0689e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.084749
Average KL loss: 0.168780
Average total loss: 1.253528
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.5629e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.099623
Average KL loss: 0.169003
Average total loss: 1.268626
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1603e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.079427
Average KL loss: 0.169072
Average total loss: 1.248499
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.6088e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.083484
Average KL loss: 0.169071
Average total loss: 1.252555
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.2136e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.077811
Average KL loss: 0.169075
Average total loss: 1.246887
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.5063e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.091790
Average KL loss: 0.169076
Average total loss: 1.260866
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.4819e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.075484
Average KL loss: 0.169081
Average total loss: 1.244564
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(3.5469e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.073926
Average KL loss: 0.169086
Average total loss: 1.243013
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.2928e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.080692
Average KL loss: 0.169092
Average total loss: 1.249784
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.2743e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.082282
Average KL loss: 0.169097
Average total loss: 1.251378
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.9880e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.089660
Average KL loss: 0.169103
Average total loss: 1.258763
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.6914e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.071915
Average KL loss: 0.169108
Average total loss: 1.241023
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.8015e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.083908
Average KL loss: 0.169113
Average total loss: 1.253021
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.8624e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.088447
Average KL loss: 0.169119
Average total loss: 1.257565
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.0881e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.082992
Average KL loss: 0.169127
Average total loss: 1.252118
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.2506e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.084684
Average KL loss: 0.169129
Average total loss: 1.253813
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.5385e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.080197
Average KL loss: 0.169137
Average total loss: 1.249334
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.5307e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.075593
Average KL loss: 0.169151
Average total loss: 1.244745
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.3403e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.077086
Average KL loss: 0.169166
Average total loss: 1.246252
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.7523e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.077157
Average KL loss: 0.169172
Average total loss: 1.246328
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.6731e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.090866
Average KL loss: 0.169181
Average total loss: 1.260047
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.8248e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.074004
Average KL loss: 0.169189
Average total loss: 1.243193
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.3946e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.076053
Average KL loss: 0.169197
Average total loss: 1.245250
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.6967e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.083831
Average KL loss: 0.169205
Average total loss: 1.253036
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.0199e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.078906
Average KL loss: 0.169206
Average total loss: 1.248113
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.3047e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.071909
Average KL loss: 0.169207
Average total loss: 1.241116
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.0521e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.072998
Average KL loss: 0.169208
Average total loss: 1.242206
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.9176e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.073428
Average KL loss: 0.169209
Average total loss: 1.242637
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.3618e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.082540
Average KL loss: 0.169210
Average total loss: 1.251749
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.8545e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.094229
Average KL loss: 0.169211
Average total loss: 1.263439
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0282e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.091016
Average KL loss: 0.169211
Average total loss: 1.260227
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.2014e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.072013
Average KL loss: 0.169212
Average total loss: 1.241226
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.5410e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.079724
Average KL loss: 0.169213
Average total loss: 1.248937
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.9843e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.077581
Average KL loss: 0.169213
Average total loss: 1.246795
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.0033e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.077098
Average KL loss: 0.169214
Average total loss: 1.246312
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.2118e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.078873
Average KL loss: 0.169214
Average total loss: 1.248087
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.3211e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.084628
Average KL loss: 0.169214
Average total loss: 1.253842
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.8461e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.084570
Average KL loss: 0.169214
Average total loss: 1.253785
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.7847e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.093061
Average KL loss: 0.169214
Average total loss: 1.262275
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.4013e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.076488
Average KL loss: 0.169214
Average total loss: 1.245703
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.4484e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.084239
Average KL loss: 0.169214
Average total loss: 1.253454
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.5547e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.084300
Average KL loss: 0.169214
Average total loss: 1.253515
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1171e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.096188
Average KL loss: 0.169215
Average total loss: 1.265403
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(2.1508e-11, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.076285
Average KL loss: 0.169215
Average total loss: 1.245499
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.3864e-09, device='cuda:0')
 Percentile value: 8.007035745549729e-08
Non-zero model percentage: 1.8014516830444336%, Non-zero mask percentage: 1.8014516830444336%

--- Pruning Level [18/24]: ---
conv1.weight         | nonzeros =      58 /    1728             (  3.36%) | total_pruned =    1670 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       8 /   36864             (  0.02%) | total_pruned =   36856 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       6 /   36864             (  0.02%) | total_pruned =   36858 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      22 /   36864             (  0.06%) | total_pruned =   36842 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      39 /   36864             (  0.11%) | total_pruned =   36825 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     112 /   73728             (  0.15%) | total_pruned =   73616 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     214 /  147456             (  0.15%) | total_pruned =  147242 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      18 /    8192             (  0.22%) | total_pruned =    8174 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     196 /  147456             (  0.13%) | total_pruned =  147260 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     186 /  147456             (  0.13%) | total_pruned =  147270 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     500 /  294912             (  0.17%) | total_pruned =  294412 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     113 /     256             ( 44.14%) | total_pruned =     143 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     678 /  589824             (  0.11%) | total_pruned =  589146 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      64 /   32768             (  0.20%) | total_pruned =   32704 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      32 /     256             ( 12.50%) | total_pruned =     224 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     363 /  589824             (  0.06%) | total_pruned =  589461 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      63 /     256             ( 24.61%) | total_pruned =     193 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     269 /  589824             (  0.05%) | total_pruned =  589555 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     579 / 1179648             (  0.05%) | total_pruned = 1179069 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     139 /     512             ( 27.15%) | total_pruned =     373 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     560 / 2359296             (  0.02%) | total_pruned = 2358736 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      82 /     512             ( 16.02%) | total_pruned =     430 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      48 /  131072             (  0.04%) | total_pruned =  131024 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     477 / 2359296             (  0.02%) | total_pruned = 2358819 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  195143 / 2359296             (  8.27%) | total_pruned = 2164153 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     110 /     512             ( 21.48%) | total_pruned =     402 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      77 /     512             ( 15.04%) | total_pruned =     435 | shape = torch.Size([512])
linear.weight        | nonzeros =     652 /    5120             ( 12.73%) | total_pruned =    4468 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 201380, pruned : 10977382, total: 11178762, Compression rate :      55.51x  ( 98.20% pruned)
Train Epoch: 92/100 Loss: 1.013329 Accuracy: 63.38 65.84 % Best test Accuracy: 63.61%
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.0808e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.165764
Average KL loss: 0.165452
Average total loss: 1.331216
tensor(0.0011, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-9.2873e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.176974
Average KL loss: 0.161392
Average total loss: 1.338366
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.9921e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.180639
Average KL loss: 0.158774
Average total loss: 1.339414
tensor(0.0010, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.3796e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.198205
Average KL loss: 0.156722
Average total loss: 1.354927
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.0654e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.200250
Average KL loss: 0.155021
Average total loss: 1.355271
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.3237e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.230921
Average KL loss: 0.153667
Average total loss: 1.384588
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.9462e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.184749
Average KL loss: 0.152890
Average total loss: 1.337639
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.2119e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.191791
Average KL loss: 0.152592
Average total loss: 1.344383
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.6965e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.209002
Average KL loss: 0.152489
Average total loss: 1.361491
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.4561e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.178551
Average KL loss: 0.152513
Average total loss: 1.331064
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.5897e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.171680
Average KL loss: 0.152610
Average total loss: 1.324290
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.9754e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.167565
Average KL loss: 0.152701
Average total loss: 1.320266
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.3308e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.153504
Average KL loss: 0.152813
Average total loss: 1.306317
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.6303e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.153681
Average KL loss: 0.152842
Average total loss: 1.306523
tensor(0.0010, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.5935e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.171006
Average KL loss: 0.152963
Average total loss: 1.323969
tensor(0.0010, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.4757e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.141689
Average KL loss: 0.152979
Average total loss: 1.294668
tensor(0.0010, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.0288e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.160940
Average KL loss: 0.153050
Average total loss: 1.313990
tensor(0.0010, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.8775e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.141084
Average KL loss: 0.153021
Average total loss: 1.294105
tensor(0.0010, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-9.0116e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.125206
Average KL loss: 0.153170
Average total loss: 1.278375
tensor(0.0010, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.1059e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.139895
Average KL loss: 0.153373
Average total loss: 1.293268
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-9.5767e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.124973
Average KL loss: 0.153522
Average total loss: 1.278495
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.2717e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.133687
Average KL loss: 0.153599
Average total loss: 1.287285
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.3883e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.131740
Average KL loss: 0.153720
Average total loss: 1.285460
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.7649e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.140017
Average KL loss: 0.153765
Average total loss: 1.293782
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-5.4603e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.124632
Average KL loss: 0.153863
Average total loss: 1.278495
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-5.2933e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.124887
Average KL loss: 0.154013
Average total loss: 1.278899
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.7744e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.116108
Average KL loss: 0.154184
Average total loss: 1.270292
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.2454e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.132714
Average KL loss: 0.154309
Average total loss: 1.287023
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.0801e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.130591
Average KL loss: 0.154374
Average total loss: 1.284965
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.8197e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.110154
Average KL loss: 0.154457
Average total loss: 1.264611
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-6.3476e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.114278
Average KL loss: 0.154619
Average total loss: 1.268897
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-7.7807e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.120077
Average KL loss: 0.154739
Average total loss: 1.274816
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-3.9165e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.112595
Average KL loss: 0.154822
Average total loss: 1.267417
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.5324e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.107852
Average KL loss: 0.154950
Average total loss: 1.262802
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.2265e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.108618
Average KL loss: 0.154985
Average total loss: 1.263603
tensor(0.0010, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-7.0711e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.129696
Average KL loss: 0.155042
Average total loss: 1.284738
tensor(0.0010, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-6.2138e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.104650
Average KL loss: 0.155119
Average total loss: 1.259769
tensor(0.0010, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.4097e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.110314
Average KL loss: 0.155285
Average total loss: 1.265599
tensor(0.0010, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.6601e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.134677
Average KL loss: 0.155483
Average total loss: 1.290160
tensor(0.0010, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-4.7363e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.104197
Average KL loss: 0.155602
Average total loss: 1.259799
tensor(0.0010, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.0930e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.105770
Average KL loss: 0.155730
Average total loss: 1.261500
tensor(0.0010, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-3.3685e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.106905
Average KL loss: 0.155921
Average total loss: 1.262827
tensor(0.0010, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-4.7738e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.090457
Average KL loss: 0.156043
Average total loss: 1.246500
tensor(0.0010, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-2.4763e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.098224
Average KL loss: 0.156140
Average total loss: 1.254363
tensor(0.0010, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-5.9167e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.089599
Average KL loss: 0.156225
Average total loss: 1.245823
tensor(0.0010, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.1550e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.096466
Average KL loss: 0.156347
Average total loss: 1.252813
tensor(0.0010, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-4.8287e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.094550
Average KL loss: 0.156471
Average total loss: 1.251022
tensor(0.0010, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-6.4695e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.100357
Average KL loss: 0.156585
Average total loss: 1.256942
tensor(0.0010, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.8335e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.098629
Average KL loss: 0.156726
Average total loss: 1.255355
tensor(0.0010, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(3.7512e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.088734
Average KL loss: 0.156851
Average total loss: 1.245585
tensor(0.0010, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-8.1211e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.104768
Average KL loss: 0.156977
Average total loss: 1.261745
tensor(0.0011, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.9482e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.087790
Average KL loss: 0.157140
Average total loss: 1.244930
tensor(0.0011, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.7028e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.088274
Average KL loss: 0.157303
Average total loss: 1.245577
tensor(0.0011, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.5255e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.085892
Average KL loss: 0.157396
Average total loss: 1.243288
tensor(0.0011, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-4.9651e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.074064
Average KL loss: 0.157516
Average total loss: 1.231580
tensor(0.0011, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-6.0560e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.085317
Average KL loss: 0.157669
Average total loss: 1.242986
tensor(0.0011, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.4754e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.080163
Average KL loss: 0.157820
Average total loss: 1.237983
tensor(0.0011, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-3.1651e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.077418
Average KL loss: 0.157977
Average total loss: 1.235395
tensor(0.0011, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.2131e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.080249
Average KL loss: 0.158145
Average total loss: 1.238395
tensor(0.0011, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.3364e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.075118
Average KL loss: 0.158262
Average total loss: 1.233380
tensor(0.0011, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.2102e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.076156
Average KL loss: 0.158435
Average total loss: 1.234591
tensor(0.0011, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.7798e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.067048
Average KL loss: 0.158531
Average total loss: 1.225579
tensor(0.0011, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.8118e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.073096
Average KL loss: 0.158657
Average total loss: 1.231752
tensor(0.0011, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-6.5572e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.080703
Average KL loss: 0.158848
Average total loss: 1.239552
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-4.5102e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.072264
Average KL loss: 0.158967
Average total loss: 1.231231
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.4801e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.076469
Average KL loss: 0.159070
Average total loss: 1.235538
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-4.9163e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.073112
Average KL loss: 0.159217
Average total loss: 1.232328
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-4.4918e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.069650
Average KL loss: 0.159333
Average total loss: 1.228983
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.3963e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.074635
Average KL loss: 0.159511
Average total loss: 1.234146
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.6858e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.069787
Average KL loss: 0.159649
Average total loss: 1.229436
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.4172e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.077046
Average KL loss: 0.159733
Average total loss: 1.236780
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1794e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.069776
Average KL loss: 0.159752
Average total loss: 1.229528
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1818e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.085559
Average KL loss: 0.159833
Average total loss: 1.245392
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.7969e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.067440
Average KL loss: 0.159866
Average total loss: 1.227306
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.4473e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.075039
Average KL loss: 0.159872
Average total loss: 1.234912
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.2783e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.078281
Average KL loss: 0.159880
Average total loss: 1.238161
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.9255e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.070543
Average KL loss: 0.159885
Average total loss: 1.230428
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.5723e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.073925
Average KL loss: 0.159888
Average total loss: 1.233813
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.3026e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.064585
Average KL loss: 0.159898
Average total loss: 1.224483
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.5266e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.081339
Average KL loss: 0.159912
Average total loss: 1.241250
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.9352e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.082347
Average KL loss: 0.159924
Average total loss: 1.242271
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.1018e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.079903
Average KL loss: 0.159930
Average total loss: 1.239833
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-9.6246e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.070130
Average KL loss: 0.159940
Average total loss: 1.230070
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(3.1069e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.071763
Average KL loss: 0.159949
Average total loss: 1.231712
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.8066e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.067857
Average KL loss: 0.159959
Average total loss: 1.227817
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.2431e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.070379
Average KL loss: 0.159968
Average total loss: 1.230346
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.1120e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.081720
Average KL loss: 0.159974
Average total loss: 1.241694
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.3495e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.074379
Average KL loss: 0.159983
Average total loss: 1.234362
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.3663e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.063217
Average KL loss: 0.159993
Average total loss: 1.223210
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.7192e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.076569
Average KL loss: 0.160002
Average total loss: 1.236572
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.4760e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.075083
Average KL loss: 0.160012
Average total loss: 1.235095
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.3633e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.078568
Average KL loss: 0.160018
Average total loss: 1.238586
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.7938e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.075011
Average KL loss: 0.160031
Average total loss: 1.235042
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.0668e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.094581
Average KL loss: 0.160036
Average total loss: 1.254617
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.3176e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.066956
Average KL loss: 0.160043
Average total loss: 1.226998
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.5007e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.074275
Average KL loss: 0.160053
Average total loss: 1.234327
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.3650e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.090838
Average KL loss: 0.160060
Average total loss: 1.250898
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.3399e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.071796
Average KL loss: 0.160070
Average total loss: 1.231865
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.8540e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.082854
Average KL loss: 0.160089
Average total loss: 1.242944
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.8170e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.070619
Average KL loss: 0.160108
Average total loss: 1.230727
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.6653e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.069468
Average KL loss: 0.160113
Average total loss: 1.229581
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(4.3382e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.062974
Average KL loss: 0.160114
Average total loss: 1.223088
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.6518e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.077633
Average KL loss: 0.160115
Average total loss: 1.237748
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.2290e-07, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.071472
Average KL loss: 0.160117
Average total loss: 1.231589
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.5536e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.070787
Average KL loss: 0.160118
Average total loss: 1.230904
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.4413e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.067855
Average KL loss: 0.160118
Average total loss: 1.227973
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.5482e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.068527
Average KL loss: 0.160119
Average total loss: 1.228646
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-9.8381e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.073415
Average KL loss: 0.160120
Average total loss: 1.233535
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.7155e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.068215
Average KL loss: 0.160121
Average total loss: 1.228336
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.2059e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.062441
Average KL loss: 0.160123
Average total loss: 1.222564
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.2296e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.064330
Average KL loss: 0.160124
Average total loss: 1.224454
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-6.6628e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.072262
Average KL loss: 0.160125
Average total loss: 1.232387
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.8139e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.076974
Average KL loss: 0.160126
Average total loss: 1.237099
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.2461e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.071071
Average KL loss: 0.160126
Average total loss: 1.231197
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.4102e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.065210
Average KL loss: 0.160128
Average total loss: 1.225337
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.6328e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.073721
Average KL loss: 0.160128
Average total loss: 1.233849
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.8351e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.076483
Average KL loss: 0.160129
Average total loss: 1.236612
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.2080e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.067773
Average KL loss: 0.160130
Average total loss: 1.227903
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.8404e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.090108
Average KL loss: 0.160131
Average total loss: 1.250239
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.4046e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.060910
Average KL loss: 0.160132
Average total loss: 1.221042
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.4144e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.063357
Average KL loss: 0.160134
Average total loss: 1.223492
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-6.5951e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.071523
Average KL loss: 0.160136
Average total loss: 1.231658
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.0706e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.068368
Average KL loss: 0.160137
Average total loss: 1.228505
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(5.2558e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.063008
Average KL loss: 0.160139
Average total loss: 1.223146
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-6.2430e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.074680
Average KL loss: 0.160140
Average total loss: 1.234820
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.3364e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.066497
Average KL loss: 0.160141
Average total loss: 1.226638
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.7813e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.058108
Average KL loss: 0.160141
Average total loss: 1.218249
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.0249e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.074100
Average KL loss: 0.160141
Average total loss: 1.234242
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.2858e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.072136
Average KL loss: 0.160142
Average total loss: 1.232278
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.9483e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.067708
Average KL loss: 0.160143
Average total loss: 1.227851
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.3066e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.068575
Average KL loss: 0.160145
Average total loss: 1.228720
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.2507e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.066867
Average KL loss: 0.160146
Average total loss: 1.227013
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.9787e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.064344
Average KL loss: 0.160147
Average total loss: 1.224491
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.6511e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.063402
Average KL loss: 0.160148
Average total loss: 1.223550
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(2.7294e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.070207
Average KL loss: 0.160149
Average total loss: 1.230356
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-8.8373e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.064385
Average KL loss: 0.160149
Average total loss: 1.224534
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.1811e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.069687
Average KL loss: 0.160151
Average total loss: 1.229838
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.4194e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.070336
Average KL loss: 0.160152
Average total loss: 1.230487
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.1288e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.086958
Average KL loss: 0.160152
Average total loss: 1.247110
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(3.2730e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.070839
Average KL loss: 0.160152
Average total loss: 1.230991
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.6038e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.079604
Average KL loss: 0.160153
Average total loss: 1.239757
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.3723e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.087172
Average KL loss: 0.160153
Average total loss: 1.247325
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.2819e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.071088
Average KL loss: 0.160153
Average total loss: 1.231241
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.7902e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.078222
Average KL loss: 0.160153
Average total loss: 1.238375
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.2257e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.074006
Average KL loss: 0.160153
Average total loss: 1.234159
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.6241e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.063267
Average KL loss: 0.160153
Average total loss: 1.223420
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(3.7417e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.068050
Average KL loss: 0.160153
Average total loss: 1.228203
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.0938e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.064050
Average KL loss: 0.160153
Average total loss: 1.224203
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.1501e-09, device='cuda:0')
 Percentile value: 8.086755798331069e-08
Non-zero model percentage: 1.4411613941192627%, Non-zero mask percentage: 1.4411613941192627%

--- Pruning Level [19/24]: ---
conv1.weight         | nonzeros =      55 /    1728             (  3.18%) | total_pruned =    1673 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       1 /   36864             (  0.00%) | total_pruned =   36863 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      14 /   36864             (  0.04%) | total_pruned =   36850 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      30 /   36864             (  0.08%) | total_pruned =   36834 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =      93 /   73728             (  0.13%) | total_pruned =   73635 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     132 /  147456             (  0.09%) | total_pruned =  147324 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      17 /    8192             (  0.21%) | total_pruned =    8175 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     154 /  147456             (  0.10%) | total_pruned =  147302 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     142 /  147456             (  0.10%) | total_pruned =  147314 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     356 /  294912             (  0.12%) | total_pruned =  294556 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      89 /     256             ( 34.77%) | total_pruned =     167 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     471 /  589824             (  0.08%) | total_pruned =  589353 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     108 /     256             ( 42.19%) | total_pruned =     148 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      45 /   32768             (  0.14%) | total_pruned =   32723 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     262 /  589824             (  0.04%) | total_pruned =  589562 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      56 /     256             ( 21.88%) | total_pruned =     200 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     208 /  589824             (  0.04%) | total_pruned =  589616 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     434 / 1179648             (  0.04%) | total_pruned = 1179214 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     119 /     512             ( 23.24%) | total_pruned =     393 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     441 / 2359296             (  0.02%) | total_pruned = 2358855 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      75 /     512             ( 14.65%) | total_pruned =     437 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      33 /  131072             (  0.03%) | total_pruned =  131039 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     375 / 2359296             (  0.02%) | total_pruned = 2358921 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      59 /     512             ( 11.52%) | total_pruned =     453 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  156237 / 2359296             (  6.62%) | total_pruned = 2203059 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      98 /     512             ( 19.14%) | total_pruned =     414 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      66 /     512             ( 12.89%) | total_pruned =     446 | shape = torch.Size([512])
linear.weight        | nonzeros =     592 /    5120             ( 11.56%) | total_pruned =    4528 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 161104, pruned : 11017658, total: 11178762, Compression rate :      69.39x  ( 98.56% pruned)
Train Epoch: 94/100 Loss: 1.062970 Accuracy: 63.07 64.87 % Best test Accuracy: 63.42%
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.6237e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.142432
Average KL loss: 0.157079
Average total loss: 1.299511
tensor(0.0011, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-2.2031e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.150420
Average KL loss: 0.153603
Average total loss: 1.304023
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.0823e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.167363
Average KL loss: 0.151243
Average total loss: 1.318605
tensor(0.0010, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.7266e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.163901
Average KL loss: 0.149329
Average total loss: 1.313230
tensor(0.0010, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.7322e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.189150
Average KL loss: 0.147780
Average total loss: 1.336929
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.5361e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.172491
Average KL loss: 0.146534
Average total loss: 1.319026
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.7441e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.165818
Average KL loss: 0.145854
Average total loss: 1.311671
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.7184e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.154016
Average KL loss: 0.145506
Average total loss: 1.299523
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-7.2366e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.189893
Average KL loss: 0.145369
Average total loss: 1.335262
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.9620e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.172295
Average KL loss: 0.145259
Average total loss: 1.317553
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.5951e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.143056
Average KL loss: 0.145289
Average total loss: 1.288345
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.0500e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.151154
Average KL loss: 0.145286
Average total loss: 1.296440
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.6072e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.129823
Average KL loss: 0.145384
Average total loss: 1.275207
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.3624e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.133866
Average KL loss: 0.145551
Average total loss: 1.279417
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.1690e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.147840
Average KL loss: 0.145647
Average total loss: 1.293487
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.3612e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.144058
Average KL loss: 0.145702
Average total loss: 1.289760
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.4648e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.126665
Average KL loss: 0.145765
Average total loss: 1.272430
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.2269e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.147947
Average KL loss: 0.145939
Average total loss: 1.293885
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.7850e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.137283
Average KL loss: 0.146012
Average total loss: 1.283295
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.1529e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.133565
Average KL loss: 0.146059
Average total loss: 1.279623
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.7917e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.128005
Average KL loss: 0.146130
Average total loss: 1.274136
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-6.0402e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.123736
Average KL loss: 0.146239
Average total loss: 1.269975
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-7.8771e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.127617
Average KL loss: 0.146430
Average total loss: 1.274047
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.0010e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.144905
Average KL loss: 0.146587
Average total loss: 1.291492
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.6656e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.117302
Average KL loss: 0.146633
Average total loss: 1.263936
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.4573e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.120640
Average KL loss: 0.146699
Average total loss: 1.267340
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.8103e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.142474
Average KL loss: 0.146884
Average total loss: 1.289358
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.5173e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.128024
Average KL loss: 0.146958
Average total loss: 1.274982
tensor(0.0010, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.5638e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.119431
Average KL loss: 0.147075
Average total loss: 1.266506
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.9192e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.111368
Average KL loss: 0.147304
Average total loss: 1.258672
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.3518e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.121749
Average KL loss: 0.147559
Average total loss: 1.269308
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.3068e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.116804
Average KL loss: 0.147753
Average total loss: 1.264557
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.3499e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.108929
Average KL loss: 0.147894
Average total loss: 1.256823
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(6.8195e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.105733
Average KL loss: 0.148051
Average total loss: 1.253784
tensor(0.0010, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.1710e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.111532
Average KL loss: 0.148235
Average total loss: 1.259767
tensor(0.0010, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.8453e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.106774
Average KL loss: 0.148366
Average total loss: 1.255140
tensor(0.0010, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-3.5404e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.114527
Average KL loss: 0.148536
Average total loss: 1.263063
tensor(0.0010, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.2165e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.101584
Average KL loss: 0.148732
Average total loss: 1.250316
tensor(0.0010, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.2741e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.110949
Average KL loss: 0.148826
Average total loss: 1.259774
tensor(0.0010, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-2.4503e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.094717
Average KL loss: 0.148977
Average total loss: 1.243694
tensor(0.0010, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.5595e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.113877
Average KL loss: 0.149121
Average total loss: 1.262999
tensor(0.0010, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-4.5602e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.112818
Average KL loss: 0.149251
Average total loss: 1.262069
tensor(0.0010, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-8.0884e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.099380
Average KL loss: 0.149417
Average total loss: 1.248798
tensor(0.0010, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(3.3035e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.110225
Average KL loss: 0.149489
Average total loss: 1.259714
tensor(0.0010, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-9.6368e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.122289
Average KL loss: 0.149640
Average total loss: 1.271929
tensor(0.0010, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.6883e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.117861
Average KL loss: 0.149739
Average total loss: 1.267601
tensor(0.0010, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-5.1741e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.095781
Average KL loss: 0.149870
Average total loss: 1.245650
tensor(0.0010, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(2.1472e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.098483
Average KL loss: 0.150006
Average total loss: 1.248488
tensor(0.0010, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.6336e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.101489
Average KL loss: 0.150097
Average total loss: 1.251587
tensor(0.0010, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-7.5886e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.098768
Average KL loss: 0.150198
Average total loss: 1.248967
tensor(0.0010, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.5375e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.092116
Average KL loss: 0.150329
Average total loss: 1.242445
tensor(0.0010, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.5561e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.089459
Average KL loss: 0.150495
Average total loss: 1.239954
tensor(0.0010, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.5013e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.100671
Average KL loss: 0.150614
Average total loss: 1.251285
tensor(0.0010, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-4.7444e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.107507
Average KL loss: 0.150758
Average total loss: 1.258264
tensor(0.0010, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-5.1015e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.114243
Average KL loss: 0.150821
Average total loss: 1.265064
tensor(0.0010, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-3.7355e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.090230
Average KL loss: 0.150879
Average total loss: 1.241109
tensor(0.0010, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-3.7361e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.113062
Average KL loss: 0.150999
Average total loss: 1.264061
tensor(0.0010, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-4.0789e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.081767
Average KL loss: 0.151031
Average total loss: 1.232798
tensor(0.0010, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-5.9267e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.098538
Average KL loss: 0.151111
Average total loss: 1.249650
tensor(0.0010, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.4868e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.093575
Average KL loss: 0.151229
Average total loss: 1.244803
tensor(0.0010, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-7.5258e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.110548
Average KL loss: 0.151324
Average total loss: 1.261871
tensor(0.0010, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.1359e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.085751
Average KL loss: 0.151385
Average total loss: 1.237136
tensor(0.0010, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.6606e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.090243
Average KL loss: 0.151490
Average total loss: 1.241733
tensor(0.0010, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.0507e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.089693
Average KL loss: 0.151593
Average total loss: 1.241285
tensor(0.0010, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.7353e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.103202
Average KL loss: 0.151734
Average total loss: 1.254936
tensor(0.0010, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(2.9658e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.080693
Average KL loss: 0.151818
Average total loss: 1.232511
tensor(0.0010, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(7.3242e-11, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.087282
Average KL loss: 0.151920
Average total loss: 1.239203
tensor(0.0010, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(1.5510e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.081698
Average KL loss: 0.152023
Average total loss: 1.233720
tensor(0.0010, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-9.8854e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.083149
Average KL loss: 0.152153
Average total loss: 1.235302
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-3.0282e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.082357
Average KL loss: 0.152240
Average total loss: 1.234597
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-7.9984e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.082624
Average KL loss: 0.152327
Average total loss: 1.234951
tensor(0.0011, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-2.8653e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.092902
Average KL loss: 0.152450
Average total loss: 1.245352
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.9493e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.086171
Average KL loss: 0.152626
Average total loss: 1.238797
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-9.3429e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.086107
Average KL loss: 0.152705
Average total loss: 1.238813
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.2510e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.082719
Average KL loss: 0.152821
Average total loss: 1.235540
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(6.7849e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.077213
Average KL loss: 0.152957
Average total loss: 1.230170
tensor(0.0011, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.5534e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.071070
Average KL loss: 0.153100
Average total loss: 1.224169
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.0405e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.085023
Average KL loss: 0.153209
Average total loss: 1.238232
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.1876e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.089455
Average KL loss: 0.153308
Average total loss: 1.242762
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.3434e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.078999
Average KL loss: 0.153416
Average total loss: 1.232415
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-7.4042e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.067251
Average KL loss: 0.153498
Average total loss: 1.220749
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.3579e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.073574
Average KL loss: 0.153579
Average total loss: 1.227153
tensor(0.0011, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.0575e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.085298
Average KL loss: 0.153662
Average total loss: 1.238960
tensor(0.0011, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.8986e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.088804
Average KL loss: 0.153731
Average total loss: 1.242535
tensor(0.0011, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.8469e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.070851
Average KL loss: 0.153860
Average total loss: 1.224711
tensor(0.0011, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(4.1293e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.096010
Average KL loss: 0.153900
Average total loss: 1.249909
tensor(0.0011, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.6766e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.075865
Average KL loss: 0.153933
Average total loss: 1.229798
tensor(0.0011, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-3.9859e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.070567
Average KL loss: 0.153993
Average total loss: 1.224560
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-5.2378e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.079871
Average KL loss: 0.154050
Average total loss: 1.233920
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.2801e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.071084
Average KL loss: 0.154175
Average total loss: 1.225259
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.1535e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.070893
Average KL loss: 0.154292
Average total loss: 1.225184
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-3.1948e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.078500
Average KL loss: 0.154397
Average total loss: 1.232896
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(6.9745e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.069935
Average KL loss: 0.154461
Average total loss: 1.224397
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-4.0039e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.064678
Average KL loss: 0.154466
Average total loss: 1.219145
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-3.2514e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.084468
Average KL loss: 0.154476
Average total loss: 1.238944
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.5612e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.073128
Average KL loss: 0.154485
Average total loss: 1.227612
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-3.9276e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.085551
Average KL loss: 0.154496
Average total loss: 1.240047
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-3.8004e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.071768
Average KL loss: 0.154504
Average total loss: 1.226272
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(5.4694e-11, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.069031
Average KL loss: 0.154511
Average total loss: 1.223541
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.6876e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.084616
Average KL loss: 0.154518
Average total loss: 1.239134
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(5.9777e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.071756
Average KL loss: 0.154522
Average total loss: 1.226278
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.4525e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.072754
Average KL loss: 0.154528
Average total loss: 1.227282
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.2017e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.070835
Average KL loss: 0.154528
Average total loss: 1.225363
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.6502e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.069419
Average KL loss: 0.154538
Average total loss: 1.223957
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-5.0215e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.071045
Average KL loss: 0.154545
Average total loss: 1.225590
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-4.6657e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.073974
Average KL loss: 0.154546
Average total loss: 1.228520
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.8782e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.070115
Average KL loss: 0.154547
Average total loss: 1.224662
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(1.0643e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.078524
Average KL loss: 0.154548
Average total loss: 1.233072
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.6985e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.082942
Average KL loss: 0.154549
Average total loss: 1.237491
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-4.2321e-11, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.080357
Average KL loss: 0.154550
Average total loss: 1.234907
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.3087e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.078393
Average KL loss: 0.154551
Average total loss: 1.232944
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.5913e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.091838
Average KL loss: 0.154552
Average total loss: 1.246389
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-5.7866e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.085561
Average KL loss: 0.154552
Average total loss: 1.240113
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.8912e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.078844
Average KL loss: 0.154553
Average total loss: 1.233397
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.9065e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.084285
Average KL loss: 0.154554
Average total loss: 1.238839
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-5.8726e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.071218
Average KL loss: 0.154554
Average total loss: 1.225773
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-8.7035e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.082448
Average KL loss: 0.154555
Average total loss: 1.237003
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(8.1836e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.070689
Average KL loss: 0.154555
Average total loss: 1.225244
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(7.7621e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.074420
Average KL loss: 0.154555
Average total loss: 1.228974
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.4292e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.067626
Average KL loss: 0.154555
Average total loss: 1.222181
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-5.4515e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.073863
Average KL loss: 0.154555
Average total loss: 1.228418
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-3.9550e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.071911
Average KL loss: 0.154555
Average total loss: 1.226466
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.9850e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.083696
Average KL loss: 0.154555
Average total loss: 1.238251
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.2327e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.076106
Average KL loss: 0.154555
Average total loss: 1.230661
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-6.7188e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.068347
Average KL loss: 0.154555
Average total loss: 1.222902
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(1.3799e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.076137
Average KL loss: 0.154555
Average total loss: 1.230692
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.2137e-09, device='cuda:0')
 Percentile value: 8.072006352222161e-08
Non-zero model percentage: 1.1529362201690674%, Non-zero mask percentage: 1.1529362201690674%

--- Pruning Level [20/24]: ---
conv1.weight         | nonzeros =      51 /    1728             (  2.95%) | total_pruned =    1677 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.bias             | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      13 /   36864             (  0.04%) | total_pruned =   36851 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      27 /   36864             (  0.07%) | total_pruned =   36837 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =      82 /   73728             (  0.11%) | total_pruned =   73646 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     113 /  147456             (  0.08%) | total_pruned =  147343 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      34 /     128             ( 26.56%) | total_pruned =      94 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      15 /    8192             (  0.18%) | total_pruned =    8177 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     135 /  147456             (  0.09%) | total_pruned =  147321 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     130 /  147456             (  0.09%) | total_pruned =  147326 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     301 /  294912             (  0.10%) | total_pruned =  294611 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     408 /  589824             (  0.07%) | total_pruned =  589416 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      38 /   32768             (  0.12%) | total_pruned =   32730 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     231 /  589824             (  0.04%) | total_pruned =  589593 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     187 /  589824             (  0.03%) | total_pruned =  589637 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      50 /     256             ( 19.53%) | total_pruned =     206 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     381 / 1179648             (  0.03%) | total_pruned = 1179267 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     110 /     512             ( 21.48%) | total_pruned =     402 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     398 / 2359296             (  0.02%) | total_pruned = 2358898 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      74 /     512             ( 14.45%) | total_pruned =     438 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      29 /  131072             (  0.02%) | total_pruned =  131043 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     333 / 2359296             (  0.01%) | total_pruned = 2358963 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      58 /     512             ( 11.33%) | total_pruned =     454 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  124487 / 2359296             (  5.28%) | total_pruned = 2234809 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      95 /     512             ( 18.55%) | total_pruned =     417 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
linear.weight        | nonzeros =     566 /    5120             ( 11.05%) | total_pruned =    4554 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 128884, pruned : 11049878, total: 11178762, Compression rate :      86.74x  ( 98.85% pruned)
Train Epoch: 56/100 Loss: 1.308314 Accuracy: 60.97 63.18 % Best test Accuracy: 62.42%
tensor(0.0011, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-9.7189e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.159844
Average KL loss: 0.151894
Average total loss: 1.311738
tensor(0.0011, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.6483e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.158879
Average KL loss: 0.148742
Average total loss: 1.307621
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-6.0443e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.181417
Average KL loss: 0.146497
Average total loss: 1.327914
tensor(0.0010, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-7.0415e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.180355
Average KL loss: 0.144626
Average total loss: 1.324981
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.0146e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.175632
Average KL loss: 0.143086
Average total loss: 1.318718
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0008e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.181592
Average KL loss: 0.141816
Average total loss: 1.323408
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.2251e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.187927
Average KL loss: 0.140872
Average total loss: 1.328799
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.8979e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.183430
Average KL loss: 0.140371
Average total loss: 1.323800
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.3973e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.171247
Average KL loss: 0.140207
Average total loss: 1.311455
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.7358e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.177729
Average KL loss: 0.140143
Average total loss: 1.317871
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-7.1829e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.180971
Average KL loss: 0.140078
Average total loss: 1.321049
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.4815e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.165494
Average KL loss: 0.140094
Average total loss: 1.305587
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.3262e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.158325
Average KL loss: 0.140189
Average total loss: 1.298514
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.0656e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.171069
Average KL loss: 0.140190
Average total loss: 1.311260
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.8826e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.151158
Average KL loss: 0.140211
Average total loss: 1.291369
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.8410e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.158672
Average KL loss: 0.140292
Average total loss: 1.298964
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.9373e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.164101
Average KL loss: 0.140369
Average total loss: 1.304470
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.0131e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.153949
Average KL loss: 0.140473
Average total loss: 1.294423
tensor(0.0009, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.7370e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.144248
Average KL loss: 0.140555
Average total loss: 1.284804
tensor(0.0009, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.1802e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.169696
Average KL loss: 0.140673
Average total loss: 1.310369
tensor(0.0009, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.0903e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.151680
Average KL loss: 0.140758
Average total loss: 1.292438
tensor(0.0009, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-9.8536e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.147642
Average KL loss: 0.140915
Average total loss: 1.288557
tensor(0.0009, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.2870e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.160548
Average KL loss: 0.141092
Average total loss: 1.301640
tensor(0.0009, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.1694e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.158007
Average KL loss: 0.141195
Average total loss: 1.299202
tensor(0.0009, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.5887e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.144930
Average KL loss: 0.141309
Average total loss: 1.286239
tensor(0.0009, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.7203e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.163335
Average KL loss: 0.141470
Average total loss: 1.304805
tensor(0.0009, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.8900e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.155438
Average KL loss: 0.141588
Average total loss: 1.297026
tensor(0.0009, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(1.1182e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.146451
Average KL loss: 0.141686
Average total loss: 1.288137
tensor(0.0009, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.4633e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.152667
Average KL loss: 0.141744
Average total loss: 1.294411
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-6.1263e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.149715
Average KL loss: 0.141833
Average total loss: 1.291548
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.1997e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.139173
Average KL loss: 0.141904
Average total loss: 1.281077
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-8.2866e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.135157
Average KL loss: 0.141915
Average total loss: 1.277072
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.5672e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.144276
Average KL loss: 0.141927
Average total loss: 1.286203
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.4838e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.137607
Average KL loss: 0.141939
Average total loss: 1.279546
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.9316e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.137165
Average KL loss: 0.141953
Average total loss: 1.279118
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.3439e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.134414
Average KL loss: 0.141964
Average total loss: 1.276378
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-5.4051e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.127058
Average KL loss: 0.141973
Average total loss: 1.269030
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.8676e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.145089
Average KL loss: 0.141984
Average total loss: 1.287073
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.2122e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.131071
Average KL loss: 0.141987
Average total loss: 1.273058
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-6.9315e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.125911
Average KL loss: 0.142000
Average total loss: 1.267910
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.5167e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.137697
Average KL loss: 0.142018
Average total loss: 1.279715
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-8.5281e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.149081
Average KL loss: 0.142029
Average total loss: 1.291110
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.2653e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.137897
Average KL loss: 0.142044
Average total loss: 1.279941
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.0448e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.143301
Average KL loss: 0.142057
Average total loss: 1.285358
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.1219e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.159505
Average KL loss: 0.142067
Average total loss: 1.301572
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-5.0542e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.145129
Average KL loss: 0.142071
Average total loss: 1.287200
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.1766e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.132716
Average KL loss: 0.142083
Average total loss: 1.274799
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-6.6249e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.144530
Average KL loss: 0.142099
Average total loss: 1.286629
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.8095e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.139793
Average KL loss: 0.142114
Average total loss: 1.281907
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.2830e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.139316
Average KL loss: 0.142123
Average total loss: 1.281439
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.3834e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.139059
Average KL loss: 0.142138
Average total loss: 1.281197
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-7.1375e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.132981
Average KL loss: 0.142145
Average total loss: 1.275126
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.7258e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.135812
Average KL loss: 0.142146
Average total loss: 1.277958
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(1.1815e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.141730
Average KL loss: 0.142148
Average total loss: 1.283877
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.9935e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.131643
Average KL loss: 0.142149
Average total loss: 1.273791
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.0860e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.147311
Average KL loss: 0.142150
Average total loss: 1.289461
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.9971e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.129181
Average KL loss: 0.142152
Average total loss: 1.271333
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-5.2996e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.135933
Average KL loss: 0.142153
Average total loss: 1.278086
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.5220e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.137290
Average KL loss: 0.142154
Average total loss: 1.279444
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.3860e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.132536
Average KL loss: 0.142156
Average total loss: 1.274692
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-5.6014e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.131398
Average KL loss: 0.142157
Average total loss: 1.273555
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.7815e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.136120
Average KL loss: 0.142159
Average total loss: 1.278279
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.5936e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.152373
Average KL loss: 0.142160
Average total loss: 1.294533
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-3.5783e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.142681
Average KL loss: 0.142160
Average total loss: 1.284841
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-5.3716e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.125653
Average KL loss: 0.142160
Average total loss: 1.267813
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-8.8958e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.131744
Average KL loss: 0.142160
Average total loss: 1.273904
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-3.5123e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.128772
Average KL loss: 0.142160
Average total loss: 1.270933
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.6457e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.129642
Average KL loss: 0.142160
Average total loss: 1.271803
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.5547e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.138913
Average KL loss: 0.142160
Average total loss: 1.281074
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-6.3214e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.143065
Average KL loss: 0.142161
Average total loss: 1.285226
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.8110e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.136653
Average KL loss: 0.142161
Average total loss: 1.278814
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.7857e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.131454
Average KL loss: 0.142161
Average total loss: 1.273615
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.0957e-09, device='cuda:0')
 Percentile value: 8.026263031979397e-08
Non-zero model percentage: 0.9223561882972717%, Non-zero mask percentage: 0.9223561882972717%

--- Pruning Level [21/24]: ---
conv1.weight         | nonzeros =      50 /    1728             (  2.89%) | total_pruned =    1678 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.bias             | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      11 /   36864             (  0.03%) | total_pruned =   36853 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      16 /   36864             (  0.04%) | total_pruned =   36848 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =      59 /   73728             (  0.08%) | total_pruned =   73669 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =      86 /  147456             (  0.06%) | total_pruned =  147370 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      11 /    8192             (  0.13%) | total_pruned =    8181 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     108 /  147456             (  0.07%) | total_pruned =  147348 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     121 /  147456             (  0.08%) | total_pruned =  147335 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     258 /  294912             (  0.09%) | total_pruned =  294654 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     326 /  589824             (  0.06%) | total_pruned =  589498 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      26 /   32768             (  0.08%) | total_pruned =   32742 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     187 /  589824             (  0.03%) | total_pruned =  589637 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     161 /  589824             (  0.03%) | total_pruned =  589663 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     328 / 1179648             (  0.03%) | total_pruned = 1179320 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      96 /     512             ( 18.75%) | total_pruned =     416 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     344 / 2359296             (  0.01%) | total_pruned = 2358952 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      67 /     512             ( 13.09%) | total_pruned =     445 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      23 /  131072             (  0.02%) | total_pruned =  131049 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     293 / 2359296             (  0.01%) | total_pruned = 2359003 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      55 /     512             ( 10.74%) | total_pruned =     457 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   99276 / 2359296             (  4.21%) | total_pruned = 2260020 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      94 /     512             ( 18.36%) | total_pruned =     418 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      61 /     512             ( 11.91%) | total_pruned =     451 | shape = torch.Size([512])
linear.weight        | nonzeros =     554 /    5120             ( 10.82%) | total_pruned =    4566 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 103108, pruned : 11075654, total: 11178762, Compression rate :     108.42x  ( 99.08% pruned)
Train Epoch: 99/100 Loss: 0.946748 Accuracy: 61.38 63.29 % Best test Accuracy: 61.66%
tensor(0.0010, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-5.6906e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.165901
Average KL loss: 0.139614
Average total loss: 1.305515
tensor(0.0009, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.0513e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.175842
Average KL loss: 0.136981
Average total loss: 1.312823
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-7.5559e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.189018
Average KL loss: 0.135561
Average total loss: 1.324579
tensor(0.0009, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-9.3252e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.214538
Average KL loss: 0.134529
Average total loss: 1.349067
tensor(0.0008, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-7.0432e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.222184
Average KL loss: 0.133772
Average total loss: 1.355956
tensor(0.0008, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.4305e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.186702
Average KL loss: 0.133223
Average total loss: 1.319925
tensor(0.0008, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.0124e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.193711
Average KL loss: 0.132970
Average total loss: 1.326680
tensor(0.0008, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-8.4739e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.197632
Average KL loss: 0.132966
Average total loss: 1.330599
tensor(0.0008, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.2743e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.187433
Average KL loss: 0.133103
Average total loss: 1.320536
tensor(0.0008, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.4783e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.192084
Average KL loss: 0.133269
Average total loss: 1.325353
tensor(0.0008, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.4154e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.182845
Average KL loss: 0.133440
Average total loss: 1.316285
tensor(0.0008, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.0954e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.194350
Average KL loss: 0.133611
Average total loss: 1.327961
tensor(0.0009, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.7568e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.174297
Average KL loss: 0.133701
Average total loss: 1.307998
tensor(0.0009, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.0818e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.193603
Average KL loss: 0.133717
Average total loss: 1.327320
tensor(0.0009, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.3514e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.174835
Average KL loss: 0.133732
Average total loss: 1.308567
tensor(0.0009, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.1115e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.179782
Average KL loss: 0.133748
Average total loss: 1.313529
tensor(0.0009, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.5503e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.171837
Average KL loss: 0.133763
Average total loss: 1.305600
tensor(0.0009, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-6.1089e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.166409
Average KL loss: 0.133790
Average total loss: 1.300198
tensor(0.0009, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.4982e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.159366
Average KL loss: 0.133818
Average total loss: 1.293184
tensor(0.0009, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.2710e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.183079
Average KL loss: 0.133842
Average total loss: 1.316922
tensor(0.0009, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.7401e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.178303
Average KL loss: 0.133868
Average total loss: 1.312170
tensor(0.0009, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.6798e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.164719
Average KL loss: 0.133889
Average total loss: 1.298607
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.6849e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.167982
Average KL loss: 0.133910
Average total loss: 1.301892
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.3865e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.177746
Average KL loss: 0.133932
Average total loss: 1.311678
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.8407e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.172212
Average KL loss: 0.133954
Average total loss: 1.306166
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2268e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.182375
Average KL loss: 0.133971
Average total loss: 1.316346
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.9236e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.167970
Average KL loss: 0.133992
Average total loss: 1.301961
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.0333e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.182602
Average KL loss: 0.134014
Average total loss: 1.316616
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-6.2821e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.179977
Average KL loss: 0.134031
Average total loss: 1.314008
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-8.5860e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.185373
Average KL loss: 0.134052
Average total loss: 1.319425
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.7791e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.169618
Average KL loss: 0.134064
Average total loss: 1.303683
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.9841e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.173665
Average KL loss: 0.134066
Average total loss: 1.307731
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.6309e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.168175
Average KL loss: 0.134068
Average total loss: 1.302242
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.4530e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.185098
Average KL loss: 0.134070
Average total loss: 1.319168
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.5273e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.188072
Average KL loss: 0.134072
Average total loss: 1.322145
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2047e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.163479
Average KL loss: 0.134075
Average total loss: 1.297554
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-7.9512e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.166372
Average KL loss: 0.134077
Average total loss: 1.300449
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.6748e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.179271
Average KL loss: 0.134079
Average total loss: 1.313350
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.3552e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.181136
Average KL loss: 0.134082
Average total loss: 1.315218
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.2922e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.159651
Average KL loss: 0.134084
Average total loss: 1.293735
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.0327e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.180228
Average KL loss: 0.134086
Average total loss: 1.314314
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.5857e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.171519
Average KL loss: 0.134088
Average total loss: 1.305607
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.9041e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.163584
Average KL loss: 0.134088
Average total loss: 1.297672
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.0262e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.164582
Average KL loss: 0.134088
Average total loss: 1.298671
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.1325e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.171201
Average KL loss: 0.134089
Average total loss: 1.305290
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.1278e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.166488
Average KL loss: 0.134089
Average total loss: 1.300577
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-7.9352e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.160317
Average KL loss: 0.134089
Average total loss: 1.294406
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.6424e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.179578
Average KL loss: 0.134089
Average total loss: 1.313668
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.9933e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.175412
Average KL loss: 0.134090
Average total loss: 1.309502
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.9512e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.164797
Average KL loss: 0.134090
Average total loss: 1.298887
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.3664e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.165793
Average KL loss: 0.134090
Average total loss: 1.299883
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.4093e-09, device='cuda:0')
 Percentile value: 8.071279467003478e-08
Non-zero model percentage: 0.7378903031349182%, Non-zero mask percentage: 0.7378903031349182%

--- Pruning Level [22/24]: ---
conv1.weight         | nonzeros =      48 /    1728             (  2.78%) | total_pruned =    1680 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.bias             | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      10 /   36864             (  0.03%) | total_pruned =   36854 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      15 /   36864             (  0.04%) | total_pruned =   36849 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =      52 /   73728             (  0.07%) | total_pruned =   73676 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =      83 /  147456             (  0.06%) | total_pruned =  147373 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      11 /    8192             (  0.13%) | total_pruned =    8181 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     100 /  147456             (  0.07%) | total_pruned =  147356 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     115 /  147456             (  0.08%) | total_pruned =  147341 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     239 /  294912             (  0.08%) | total_pruned =  294673 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      72 /     256             ( 28.12%) | total_pruned =     184 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     306 /  589824             (  0.05%) | total_pruned =  589518 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      78 /     256             ( 30.47%) | total_pruned =     178 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      21 /   32768             (  0.06%) | total_pruned =   32747 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     173 /  589824             (  0.03%) | total_pruned =  589651 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     151 /  589824             (  0.03%) | total_pruned =  589673 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     300 / 1179648             (  0.03%) | total_pruned = 1179348 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      90 /     512             ( 17.58%) | total_pruned =     422 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     303 / 2359296             (  0.01%) | total_pruned = 2358993 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      65 /     512             ( 12.70%) | total_pruned =     447 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      21 /  131072             (  0.02%) | total_pruned =  131051 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     265 / 2359296             (  0.01%) | total_pruned = 2359031 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      53 /     512             ( 10.35%) | total_pruned =     459 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   78916 / 2359296             (  3.34%) | total_pruned = 2280380 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      91 /     512             ( 17.77%) | total_pruned =     421 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      58 /     512             ( 11.33%) | total_pruned =     454 | shape = torch.Size([512])
linear.weight        | nonzeros =     526 /    5120             ( 10.27%) | total_pruned =    4594 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 82487, pruned : 11096275, total: 11178762, Compression rate :     135.52x  ( 99.26% pruned)
Train Epoch: 56/100 Loss: 1.038787 Accuracy: 60.09 61.79 % Best test Accuracy: 60.75%
tensor(0.0009, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-8.1720e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.236932
Average KL loss: 0.131407
Average total loss: 1.368339
tensor(0.0008, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.1079e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.251012
Average KL loss: 0.128464
Average total loss: 1.379476
tensor(0.0008, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-5.5579e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.247378
Average KL loss: 0.126668
Average total loss: 1.374045
tensor(0.0008, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.1309e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.245403
Average KL loss: 0.125331
Average total loss: 1.370734
tensor(0.0008, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-4.8685e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.248741
Average KL loss: 0.124273
Average total loss: 1.373014
tensor(0.0008, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-7.7223e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.235950
Average KL loss: 0.123625
Average total loss: 1.359575
tensor(0.0008, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-9.1206e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.220889
Average KL loss: 0.123349
Average total loss: 1.344238
tensor(0.0008, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-9.5488e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.250266
Average KL loss: 0.123299
Average total loss: 1.373565
tensor(0.0008, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.3151e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.230973
Average KL loss: 0.123332
Average total loss: 1.354305
tensor(0.0008, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-7.7808e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.228450
Average KL loss: 0.123452
Average total loss: 1.351902
tensor(0.0008, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2579e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.231090
Average KL loss: 0.123578
Average total loss: 1.354668
tensor(0.0008, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-4.1460e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.231906
Average KL loss: 0.123713
Average total loss: 1.355619
tensor(0.0008, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-5.9000e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.211090
Average KL loss: 0.123834
Average total loss: 1.334924
tensor(0.0008, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.6603e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.228220
Average KL loss: 0.123979
Average total loss: 1.352199
tensor(0.0008, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.9812e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.231169
Average KL loss: 0.124144
Average total loss: 1.355313
tensor(0.0008, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.5340e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.197659
Average KL loss: 0.124256
Average total loss: 1.321915
tensor(0.0008, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.7639e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.190467
Average KL loss: 0.124435
Average total loss: 1.314903
tensor(0.0008, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.6680e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.207971
Average KL loss: 0.124611
Average total loss: 1.332581
tensor(0.0008, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-4.7377e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.204789
Average KL loss: 0.124783
Average total loss: 1.329571
tensor(0.0008, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.6365e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.197664
Average KL loss: 0.124947
Average total loss: 1.322611
tensor(0.0008, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-3.3065e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.186541
Average KL loss: 0.125066
Average total loss: 1.311607
tensor(0.0008, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-3.2541e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.206747
Average KL loss: 0.125179
Average total loss: 1.331927
tensor(0.0008, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.4345e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.198002
Average KL loss: 0.125286
Average total loss: 1.323288
tensor(0.0008, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-4.2485e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.191717
Average KL loss: 0.125434
Average total loss: 1.317151
tensor(0.0008, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.2410e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.175845
Average KL loss: 0.125555
Average total loss: 1.301400
tensor(0.0008, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.2044e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.194312
Average KL loss: 0.125652
Average total loss: 1.319964
tensor(0.0008, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-4.5160e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.170986
Average KL loss: 0.125778
Average total loss: 1.296763
tensor(0.0008, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-4.8381e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.181900
Average KL loss: 0.125946
Average total loss: 1.307846
tensor(0.0008, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.4394e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.178028
Average KL loss: 0.126123
Average total loss: 1.304151
tensor(0.0008, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.1173e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.182113
Average KL loss: 0.126277
Average total loss: 1.308389
tensor(0.0008, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.5738e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.186880
Average KL loss: 0.126459
Average total loss: 1.313339
tensor(0.0008, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.9491e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.184764
Average KL loss: 0.126606
Average total loss: 1.311370
tensor(0.0008, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.7747e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.175080
Average KL loss: 0.126732
Average total loss: 1.301813
tensor(0.0008, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.1862e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.185455
Average KL loss: 0.126875
Average total loss: 1.312330
tensor(0.0008, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.5082e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.171573
Average KL loss: 0.127043
Average total loss: 1.298615
tensor(0.0008, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.8824e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.182335
Average KL loss: 0.127198
Average total loss: 1.309533
tensor(0.0008, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.1826e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.176769
Average KL loss: 0.127330
Average total loss: 1.304099
tensor(0.0008, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.7326e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.158658
Average KL loss: 0.127515
Average total loss: 1.286173
tensor(0.0008, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.2947e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.165752
Average KL loss: 0.127652
Average total loss: 1.293404
tensor(0.0008, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.9078e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.154714
Average KL loss: 0.127828
Average total loss: 1.282542
tensor(0.0008, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.9006e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.174572
Average KL loss: 0.127992
Average total loss: 1.302565
tensor(0.0008, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.4876e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.164600
Average KL loss: 0.128168
Average total loss: 1.292768
tensor(0.0008, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.2679e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.159976
Average KL loss: 0.128333
Average total loss: 1.288308
tensor(0.0008, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.0402e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.160503
Average KL loss: 0.128439
Average total loss: 1.288942
tensor(0.0008, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-6.3356e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.181152
Average KL loss: 0.128556
Average total loss: 1.309708
tensor(0.0008, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.4250e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.166674
Average KL loss: 0.128706
Average total loss: 1.295380
tensor(0.0008, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-6.5369e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.149950
Average KL loss: 0.128846
Average total loss: 1.278797
tensor(0.0008, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.1527e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.162908
Average KL loss: 0.129002
Average total loss: 1.291910
tensor(0.0008, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.3813e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.151160
Average KL loss: 0.129131
Average total loss: 1.280291
tensor(0.0008, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.0247e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.159727
Average KL loss: 0.129277
Average total loss: 1.289003
tensor(0.0009, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.3430e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.156805
Average KL loss: 0.129389
Average total loss: 1.286194
tensor(0.0009, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.0899e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.161757
Average KL loss: 0.129560
Average total loss: 1.291317
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-7.9747e-11, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.169899
Average KL loss: 0.129704
Average total loss: 1.299603
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.2459e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.143725
Average KL loss: 0.129831
Average total loss: 1.273556
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.8627e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.160370
Average KL loss: 0.129927
Average total loss: 1.290296
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.3096e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.152443
Average KL loss: 0.130027
Average total loss: 1.282469
tensor(0.0009, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.4494e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.155844
Average KL loss: 0.130095
Average total loss: 1.285939
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.6424e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.154183
Average KL loss: 0.130176
Average total loss: 1.284359
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.2351e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.144579
Average KL loss: 0.130253
Average total loss: 1.274832
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(4.8268e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.154181
Average KL loss: 0.130364
Average total loss: 1.284546
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.3748e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.157509
Average KL loss: 0.130471
Average total loss: 1.287980
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.8172e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.148870
Average KL loss: 0.130560
Average total loss: 1.279429
tensor(0.0009, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.9549e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.157928
Average KL loss: 0.130671
Average total loss: 1.288599
tensor(0.0009, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.2514e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.152265
Average KL loss: 0.130738
Average total loss: 1.283003
tensor(0.0009, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.5710e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.142398
Average KL loss: 0.130783
Average total loss: 1.273181
tensor(0.0009, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.3518e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.155563
Average KL loss: 0.130856
Average total loss: 1.286419
tensor(0.0009, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.8839e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.139520
Average KL loss: 0.130999
Average total loss: 1.270519
tensor(0.0009, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.3638e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.144374
Average KL loss: 0.131042
Average total loss: 1.275416
tensor(0.0009, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.0377e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.143250
Average KL loss: 0.131150
Average total loss: 1.274400
tensor(0.0009, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.1776e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.150443
Average KL loss: 0.131207
Average total loss: 1.281650
tensor(0.0009, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.8282e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.138759
Average KL loss: 0.131249
Average total loss: 1.270007
tensor(0.0009, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.0657e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.133205
Average KL loss: 0.131350
Average total loss: 1.264555
tensor(0.0009, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-5.1185e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.155054
Average KL loss: 0.131421
Average total loss: 1.286476
tensor(0.0009, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.5401e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.135839
Average KL loss: 0.131526
Average total loss: 1.267365
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.0424e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.139994
Average KL loss: 0.131627
Average total loss: 1.271621
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.6056e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.132810
Average KL loss: 0.131675
Average total loss: 1.264485
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(8.3942e-11, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.136189
Average KL loss: 0.131781
Average total loss: 1.267971
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.2467e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.145947
Average KL loss: 0.131901
Average total loss: 1.277848
tensor(0.0009, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-3.4519e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.144605
Average KL loss: 0.132024
Average total loss: 1.276630
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-7.4992e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.133387
Average KL loss: 0.132121
Average total loss: 1.265507
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.9800e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.142402
Average KL loss: 0.132183
Average total loss: 1.274585
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.0412e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.150317
Average KL loss: 0.132279
Average total loss: 1.282596
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.5717e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.135288
Average KL loss: 0.132345
Average total loss: 1.267632
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-3.7156e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.140670
Average KL loss: 0.132391
Average total loss: 1.273061
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.1584e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.138341
Average KL loss: 0.132397
Average total loss: 1.270738
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.3534e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.141083
Average KL loss: 0.132404
Average total loss: 1.273488
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-3.0810e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.137436
Average KL loss: 0.132413
Average total loss: 1.269849
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-9.7966e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.133026
Average KL loss: 0.132422
Average total loss: 1.265448
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.5879e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.148969
Average KL loss: 0.132429
Average total loss: 1.281398
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.3269e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.135430
Average KL loss: 0.132436
Average total loss: 1.267866
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.3783e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.135374
Average KL loss: 0.132439
Average total loss: 1.267813
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-7.8974e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.134927
Average KL loss: 0.132440
Average total loss: 1.267367
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-7.8413e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.136908
Average KL loss: 0.132447
Average total loss: 1.269355
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.7328e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.150937
Average KL loss: 0.132453
Average total loss: 1.283390
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.3821e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.146578
Average KL loss: 0.132458
Average total loss: 1.279036
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.1921e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.146618
Average KL loss: 0.132458
Average total loss: 1.279076
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(1.0246e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.129045
Average KL loss: 0.132458
Average total loss: 1.261504
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.9321e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.140446
Average KL loss: 0.132459
Average total loss: 1.272905
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.2118e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.134867
Average KL loss: 0.132459
Average total loss: 1.267326
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.3923e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.142848
Average KL loss: 0.132460
Average total loss: 1.275308
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.4834e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.152302
Average KL loss: 0.132460
Average total loss: 1.284762
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-9.3544e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.129156
Average KL loss: 0.132460
Average total loss: 1.261615
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-6.5309e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.135964
Average KL loss: 0.132460
Average total loss: 1.268424
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.7979e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.137728
Average KL loss: 0.132461
Average total loss: 1.270189
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.0660e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.142700
Average KL loss: 0.132461
Average total loss: 1.275161
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.3750e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.128013
Average KL loss: 0.132461
Average total loss: 1.260474
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.9039e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.140776
Average KL loss: 0.132462
Average total loss: 1.273237
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-8.6641e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.136340
Average KL loss: 0.132462
Average total loss: 1.268802
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.6893e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.141659
Average KL loss: 0.132463
Average total loss: 1.274121
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-6.8369e-11, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.141365
Average KL loss: 0.132464
Average total loss: 1.273829
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-3.9686e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.134759
Average KL loss: 0.132464
Average total loss: 1.267223
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(9.3419e-11, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.133868
Average KL loss: 0.132464
Average total loss: 1.266332
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.5686e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.139133
Average KL loss: 0.132465
Average total loss: 1.271598
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.2052e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.131888
Average KL loss: 0.132465
Average total loss: 1.264353
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-3.7356e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.137355
Average KL loss: 0.132466
Average total loss: 1.269821
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.9579e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.131908
Average KL loss: 0.132467
Average total loss: 1.264375
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-7.8146e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.145930
Average KL loss: 0.132468
Average total loss: 1.278398
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.8414e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.132162
Average KL loss: 0.132468
Average total loss: 1.264630
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.4861e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.136484
Average KL loss: 0.132468
Average total loss: 1.268952
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.1625e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.139116
Average KL loss: 0.132468
Average total loss: 1.271584
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.6517e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.130211
Average KL loss: 0.132468
Average total loss: 1.262679
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-6.0099e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.131186
Average KL loss: 0.132468
Average total loss: 1.263654
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.3002e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.135054
Average KL loss: 0.132468
Average total loss: 1.267522
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(2.7108e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.132231
Average KL loss: 0.132468
Average total loss: 1.264699
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.1480e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.145296
Average KL loss: 0.132468
Average total loss: 1.277765
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-4.8896e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.135901
Average KL loss: 0.132468
Average total loss: 1.268369
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-7.0069e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.150801
Average KL loss: 0.132468
Average total loss: 1.283270
tensor(0.0009, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.8379e-09, device='cuda:0')
 Percentile value: 7.982356464708573e-08
Non-zero model percentage: 0.5903157591819763%, Non-zero mask percentage: 0.5903157591819763%

--- Pruning Level [23/24]: ---
conv1.weight         | nonzeros =      48 /    1728             (  2.78%) | total_pruned =    1680 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.bias             | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      10 /   36864             (  0.03%) | total_pruned =   36854 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      15 /   36864             (  0.04%) | total_pruned =   36849 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =      47 /   73728             (  0.06%) | total_pruned =   73681 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =      80 /  147456             (  0.05%) | total_pruned =  147376 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      11 /    8192             (  0.13%) | total_pruned =    8181 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =      94 /  147456             (  0.06%) | total_pruned =  147362 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     111 /  147456             (  0.08%) | total_pruned =  147345 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     225 /  294912             (  0.08%) | total_pruned =  294687 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     287 /  589824             (  0.05%) | total_pruned =  589537 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      77 /     256             ( 30.08%) | total_pruned =     179 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      21 /   32768             (  0.06%) | total_pruned =   32747 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     157 /  589824             (  0.03%) | total_pruned =  589667 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     142 /  589824             (  0.02%) | total_pruned =  589682 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     283 / 1179648             (  0.02%) | total_pruned = 1179365 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      89 /     512             ( 17.38%) | total_pruned =     423 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     285 / 2359296             (  0.01%) | total_pruned = 2359011 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      65 /     512             ( 12.70%) | total_pruned =     447 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      21 /  131072             (  0.02%) | total_pruned =  131051 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     246 / 2359296             (  0.01%) | total_pruned = 2359050 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   62568 / 2359296             (  2.65%) | total_pruned = 2296728 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      91 /     512             ( 17.77%) | total_pruned =     421 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      57 /     512             ( 11.13%) | total_pruned =     455 | shape = torch.Size([512])
linear.weight        | nonzeros =     520 /    5120             ( 10.16%) | total_pruned =    4600 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 65990, pruned : 11112772, total: 11178762, Compression rate :     169.40x  ( 99.41% pruned)
Train Epoch: 56/100 Loss: 1.084905 Accuracy: 59.76 60.90 % Best test Accuracy: 59.98%
