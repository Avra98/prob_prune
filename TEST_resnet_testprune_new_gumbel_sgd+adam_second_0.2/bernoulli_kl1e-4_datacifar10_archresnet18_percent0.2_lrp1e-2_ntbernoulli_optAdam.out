Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/24]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/100 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-2.1415e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.807059
Average KL loss: 0.099185
Average total loss: 1.906244
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1158e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.536392
Average KL loss: 0.187266
Average total loss: 1.723659
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.5550e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.335482
Average KL loss: 0.203975
Average total loss: 1.539457
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.5427e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.212567
Average KL loss: 0.202521
Average total loss: 1.415087
tensor(0.0006, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.1285e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.129356
Average KL loss: 0.200126
Average total loss: 1.329483
tensor(0.0007, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-8.2994e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.053372
Average KL loss: 0.193159
Average total loss: 1.246531
tensor(0.0007, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-9.0651e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.990716
Average KL loss: 0.189515
Average total loss: 1.180231
tensor(0.0008, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-1.0346e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.936735
Average KL loss: 0.190883
Average total loss: 1.127618
tensor(0.0008, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-8.4514e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.867394
Average KL loss: 0.186818
Average total loss: 1.054212
tensor(0.0009, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-8.5210e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.837765
Average KL loss: 0.183669
Average total loss: 1.021434
tensor(0.0009, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.3236e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.803425
Average KL loss: 0.180601
Average total loss: 0.984025
tensor(0.0009, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.5203e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.762233
Average KL loss: 0.181105
Average total loss: 0.943337
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.8003e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.725372
Average KL loss: 0.180500
Average total loss: 0.905872
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.2455e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.705688
Average KL loss: 0.179686
Average total loss: 0.885374
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.0426e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.676358
Average KL loss: 0.178742
Average total loss: 0.855100
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.2488e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.640558
Average KL loss: 0.178544
Average total loss: 0.819103
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.3782e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.606625
Average KL loss: 0.174541
Average total loss: 0.781166
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.9983e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.600385
Average KL loss: 0.175483
Average total loss: 0.775868
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.0676e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.577382
Average KL loss: 0.176672
Average total loss: 0.754053
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-5.7464e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.558715
Average KL loss: 0.178658
Average total loss: 0.737373
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.1693e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.541920
Average KL loss: 0.177504
Average total loss: 0.719423
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.0752e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.518534
Average KL loss: 0.178593
Average total loss: 0.697127
tensor(0.0012, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.5057e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.506354
Average KL loss: 0.177409
Average total loss: 0.683763
tensor(0.0012, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-3.3033e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.494398
Average KL loss: 0.179375
Average total loss: 0.673773
tensor(0.0012, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-3.1493e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.476142
Average KL loss: 0.179700
Average total loss: 0.655842
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.1391e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.455866
Average KL loss: 0.178950
Average total loss: 0.634816
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.3682e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.450275
Average KL loss: 0.180364
Average total loss: 0.630638
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.0559e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.438472
Average KL loss: 0.181340
Average total loss: 0.619812
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.1282e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.428657
Average KL loss: 0.183476
Average total loss: 0.612133
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.1405e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.412652
Average KL loss: 0.184110
Average total loss: 0.596762
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.3505e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.411501
Average KL loss: 0.183051
Average total loss: 0.594552
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.9416e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.396269
Average KL loss: 0.185423
Average total loss: 0.581692
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.9326e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.382219
Average KL loss: 0.184027
Average total loss: 0.566246
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.2416e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.380810
Average KL loss: 0.185709
Average total loss: 0.566519
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.2523e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.380224
Average KL loss: 0.187513
Average total loss: 0.567737
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.7453e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.364830
Average KL loss: 0.188788
Average total loss: 0.553617
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.4571e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.365615
Average KL loss: 0.192358
Average total loss: 0.557973
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.9617e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.352055
Average KL loss: 0.192461
Average total loss: 0.544516
tensor(0.0014, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.2759e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.349910
Average KL loss: 0.194233
Average total loss: 0.544143
tensor(0.0014, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.6210e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.332771
Average KL loss: 0.191596
Average total loss: 0.524367
tensor(0.0014, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.2670e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.322691
Average KL loss: 0.190435
Average total loss: 0.513126
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.0044e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.316701
Average KL loss: 0.192265
Average total loss: 0.508967
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.1508e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.309037
Average KL loss: 0.191794
Average total loss: 0.500831
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.1331e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.320648
Average KL loss: 0.195304
Average total loss: 0.515952
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.6913e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.307518
Average KL loss: 0.197531
Average total loss: 0.505049
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-6.8348e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.297495
Average KL loss: 0.195246
Average total loss: 0.492741
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.9455e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.307040
Average KL loss: 0.197189
Average total loss: 0.504229
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.2557e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.292938
Average KL loss: 0.200869
Average total loss: 0.493807
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.5634e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.277423
Average KL loss: 0.199692
Average total loss: 0.477115
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.6869e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.284466
Average KL loss: 0.200903
Average total loss: 0.485369
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.2269e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.276868
Average KL loss: 0.201698
Average total loss: 0.478566
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.1950e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.269127
Average KL loss: 0.203121
Average total loss: 0.472248
tensor(0.0015, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.7374e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.268780
Average KL loss: 0.202764
Average total loss: 0.471545
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.6602e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.266839
Average KL loss: 0.203028
Average total loss: 0.469867
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-7.5060e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.262231
Average KL loss: 0.203778
Average total loss: 0.466009
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.3536e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.258842
Average KL loss: 0.204688
Average total loss: 0.463530
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.5026e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.253502
Average KL loss: 0.205340
Average total loss: 0.458842
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.9029e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.255296
Average KL loss: 0.208157
Average total loss: 0.463453
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.4473e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.247212
Average KL loss: 0.207342
Average total loss: 0.454555
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.4583e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.240889
Average KL loss: 0.208367
Average total loss: 0.449256
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.1806e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.237087
Average KL loss: 0.207449
Average total loss: 0.444536
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.7222e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.236286
Average KL loss: 0.207388
Average total loss: 0.443674
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.0600e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.240660
Average KL loss: 0.211750
Average total loss: 0.452409
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2634e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.232147
Average KL loss: 0.210598
Average total loss: 0.442745
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.0407e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.224523
Average KL loss: 0.209690
Average total loss: 0.434213
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-8.1484e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.235560
Average KL loss: 0.211457
Average total loss: 0.447017
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.2632e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.217586
Average KL loss: 0.212457
Average total loss: 0.430043
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2295e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.225713
Average KL loss: 0.213914
Average total loss: 0.439627
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.6760e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.229061
Average KL loss: 0.213877
Average total loss: 0.442938
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.1710e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.219295
Average KL loss: 0.215570
Average total loss: 0.434865
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.7053e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.221248
Average KL loss: 0.215788
Average total loss: 0.437036
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.6463e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.217305
Average KL loss: 0.216244
Average total loss: 0.433549
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.4341e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.210955
Average KL loss: 0.215536
Average total loss: 0.426492
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-7.9265e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.216271
Average KL loss: 0.218344
Average total loss: 0.434615
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(3.7528e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.202925
Average KL loss: 0.216895
Average total loss: 0.419820
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-7.0934e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.212403
Average KL loss: 0.218813
Average total loss: 0.431216
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.0850e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.210299
Average KL loss: 0.220755
Average total loss: 0.431053
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-4.6704e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.205627
Average KL loss: 0.219302
Average total loss: 0.424929
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-7.9027e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.202450
Average KL loss: 0.221513
Average total loss: 0.423963
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.3602e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.198652
Average KL loss: 0.219973
Average total loss: 0.418625
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-8.6931e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.195221
Average KL loss: 0.219281
Average total loss: 0.414501
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-4.8131e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.198325
Average KL loss: 0.219646
Average total loss: 0.417971
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-6.4182e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.192492
Average KL loss: 0.219272
Average total loss: 0.411764
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-5.9062e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.196327
Average KL loss: 0.220652
Average total loss: 0.416979
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.3770e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.190611
Average KL loss: 0.222206
Average total loss: 0.412817
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-8.9424e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.197929
Average KL loss: 0.223260
Average total loss: 0.421189
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.7825e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.188567
Average KL loss: 0.222689
Average total loss: 0.411255
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.3350e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.185629
Average KL loss: 0.222791
Average total loss: 0.408420
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.6804e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.183710
Average KL loss: 0.221060
Average total loss: 0.404769
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-9.8454e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.188986
Average KL loss: 0.224582
Average total loss: 0.413568
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.1714e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.187043
Average KL loss: 0.224000
Average total loss: 0.411043
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.0405e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.183116
Average KL loss: 0.225752
Average total loss: 0.408868
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(3.6225e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.187383
Average KL loss: 0.225236
Average total loss: 0.412619
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-5.0871e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.176161
Average KL loss: 0.225162
Average total loss: 0.401323
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(4.1458e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.185668
Average KL loss: 0.226110
Average total loss: 0.411777
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.1823e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.175576
Average KL loss: 0.227127
Average total loss: 0.402703
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-9.4672e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.176807
Average KL loss: 0.224252
Average total loss: 0.401058
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-8.5301e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.179821
Average KL loss: 0.227517
Average total loss: 0.407337
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.0387e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.171994
Average KL loss: 0.226376
Average total loss: 0.398370
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.1696e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.182151
Average KL loss: 0.227728
Average total loss: 0.409879
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.7677e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.168456
Average KL loss: 0.227924
Average total loss: 0.396380
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.8047e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.175817
Average KL loss: 0.225758
Average total loss: 0.401575
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.4577e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.171529
Average KL loss: 0.230236
Average total loss: 0.401765
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.2269e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.169237
Average KL loss: 0.227331
Average total loss: 0.396568
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.3344e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.169595
Average KL loss: 0.227030
Average total loss: 0.396625
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.8767e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.164188
Average KL loss: 0.227564
Average total loss: 0.391752
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.0248e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.168932
Average KL loss: 0.228591
Average total loss: 0.397523
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.6000e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.165910
Average KL loss: 0.229551
Average total loss: 0.395460
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-4.3244e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.164127
Average KL loss: 0.226335
Average total loss: 0.390462
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.8939e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.167070
Average KL loss: 0.227716
Average total loss: 0.394786
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.0560e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.170337
Average KL loss: 0.230945
Average total loss: 0.401282
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-6.6526e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.161741
Average KL loss: 0.229987
Average total loss: 0.391728
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-9.2412e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.163254
Average KL loss: 0.229954
Average total loss: 0.393207
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(2.0527e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.163210
Average KL loss: 0.230847
Average total loss: 0.394057
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-7.3006e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.158021
Average KL loss: 0.229052
Average total loss: 0.387073
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(1.1930e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.166417
Average KL loss: 0.229697
Average total loss: 0.396114
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.5153e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.165748
Average KL loss: 0.233115
Average total loss: 0.398863
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-4.6513e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.165887
Average KL loss: 0.233430
Average total loss: 0.399317
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(3.2160e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.157928
Average KL loss: 0.231227
Average total loss: 0.389155
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(6.8215e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.154485
Average KL loss: 0.229284
Average total loss: 0.383769
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-7.6395e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.155625
Average KL loss: 0.229152
Average total loss: 0.384777
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(2.5944e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.158604
Average KL loss: 0.229032
Average total loss: 0.387637
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.1190e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.157715
Average KL loss: 0.232058
Average total loss: 0.389772
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.8133e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.157833
Average KL loss: 0.231639
Average total loss: 0.389472
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.3500e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.153189
Average KL loss: 0.230401
Average total loss: 0.383589
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.6304e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.159175
Average KL loss: 0.235594
Average total loss: 0.394768
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(5.4253e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.157668
Average KL loss: 0.233618
Average total loss: 0.391286
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-9.6045e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.159794
Average KL loss: 0.234932
Average total loss: 0.394727
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.0774e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.160614
Average KL loss: 0.234984
Average total loss: 0.395598
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.1610e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.154253
Average KL loss: 0.233846
Average total loss: 0.388099
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-8.6472e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.157686
Average KL loss: 0.235569
Average total loss: 0.393255
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-4.8835e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.154858
Average KL loss: 0.232819
Average total loss: 0.387678
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.5621e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.149807
Average KL loss: 0.234041
Average total loss: 0.383848
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(8.9533e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.152601
Average KL loss: 0.233083
Average total loss: 0.385684
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.0672e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.154026
Average KL loss: 0.234128
Average total loss: 0.388154
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-4.7850e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.159618
Average KL loss: 0.238231
Average total loss: 0.397849
tensor(0.0016, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.8592e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.142910
Average KL loss: 0.227620
Average total loss: 0.370530
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(9.2778e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.151309
Average KL loss: 0.212144
Average total loss: 0.363453
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(2.4408e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.147320
Average KL loss: 0.204227
Average total loss: 0.351547
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(7.5886e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.148397
Average KL loss: 0.198986
Average total loss: 0.347383
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(7.3057e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.150280
Average KL loss: 0.195374
Average total loss: 0.345654
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(6.1297e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.155224
Average KL loss: 0.192704
Average total loss: 0.347928
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.8799e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.145883
Average KL loss: 0.190539
Average total loss: 0.336422
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.5059e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.145148
Average KL loss: 0.188691
Average total loss: 0.333838
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-9.6645e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.153055
Average KL loss: 0.187313
Average total loss: 0.340368
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.2114e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.148332
Average KL loss: 0.186243
Average total loss: 0.334576
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.1194e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.148167
Average KL loss: 0.185169
Average total loss: 0.333336
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-8.5450e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.148688
Average KL loss: 0.184380
Average total loss: 0.333068
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.9628e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.149513
Average KL loss: 0.183687
Average total loss: 0.333199
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-7.5904e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.146320
Average KL loss: 0.182995
Average total loss: 0.329316
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3732e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.151292
Average KL loss: 0.182332
Average total loss: 0.333624
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.7288e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.149852
Average KL loss: 0.181943
Average total loss: 0.331795
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.0082e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.148049
Average KL loss: 0.181506
Average total loss: 0.329555
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.1388e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.150221
Average KL loss: 0.181241
Average total loss: 0.331462
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.4935e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.149710
Average KL loss: 0.180978
Average total loss: 0.330688
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.9497e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.145694
Average KL loss: 0.180661
Average total loss: 0.326354
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.2410e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.148091
Average KL loss: 0.180261
Average total loss: 0.328352
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(7.6919e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.143940
Average KL loss: 0.179923
Average total loss: 0.323863
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.4525e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.149216
Average KL loss: 0.179591
Average total loss: 0.328807
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.1190e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.146853
Average KL loss: 0.179376
Average total loss: 0.326229
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.8073e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.146650
Average KL loss: 0.179159
Average total loss: 0.325809
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.4381e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.148533
Average KL loss: 0.179077
Average total loss: 0.327609
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(5.0903e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.150763
Average KL loss: 0.178985
Average total loss: 0.329748
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3397e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.144303
Average KL loss: 0.178709
Average total loss: 0.323012
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.6915e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.147804
Average KL loss: 0.178494
Average total loss: 0.326298
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-8.8366e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.147946
Average KL loss: 0.178427
Average total loss: 0.326374
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.1850e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.150105
Average KL loss: 0.178309
Average total loss: 0.328413
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.3981e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.149309
Average KL loss: 0.178257
Average total loss: 0.327566
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-6.0313e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.148691
Average KL loss: 0.178164
Average total loss: 0.326855
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.7121e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.150380
Average KL loss: 0.178037
Average total loss: 0.328417
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.7112e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.152333
Average KL loss: 0.178050
Average total loss: 0.330383
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.2672e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.151242
Average KL loss: 0.178058
Average total loss: 0.329300
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.1964e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.153341
Average KL loss: 0.178049
Average total loss: 0.331390
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(5.8018e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.150486
Average KL loss: 0.177973
Average total loss: 0.328459
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(4.8043e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.148168
Average KL loss: 0.177822
Average total loss: 0.325990
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.1695e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.148577
Average KL loss: 0.177577
Average total loss: 0.326154
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.5610e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.152439
Average KL loss: 0.177205
Average total loss: 0.329644
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.9239e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.148372
Average KL loss: 0.176907
Average total loss: 0.325279
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-6.5382e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.148874
Average KL loss: 0.176661
Average total loss: 0.325535
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.9526e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.144449
Average KL loss: 0.176428
Average total loss: 0.320877
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.8556e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.145889
Average KL loss: 0.176222
Average total loss: 0.322112
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.1828e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.150094
Average KL loss: 0.176039
Average total loss: 0.326133
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.3502e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.145606
Average KL loss: 0.175870
Average total loss: 0.321477
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.0667e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.147988
Average KL loss: 0.175722
Average total loss: 0.323710
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.3835e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.148484
Average KL loss: 0.175585
Average total loss: 0.324070
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.8706e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.146919
Average KL loss: 0.175458
Average total loss: 0.322377
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.5113e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.143155
Average KL loss: 0.175330
Average total loss: 0.318485
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.3377e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.144687
Average KL loss: 0.175210
Average total loss: 0.319897
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.6213e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.146123
Average KL loss: 0.175092
Average total loss: 0.321215
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3516e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.149649
Average KL loss: 0.174986
Average total loss: 0.324635
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(9.0040e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.142598
Average KL loss: 0.174888
Average total loss: 0.317485
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.1123e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.149470
Average KL loss: 0.174792
Average total loss: 0.324262
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.1113e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.144864
Average KL loss: 0.174701
Average total loss: 0.319565
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.3838e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.144288
Average KL loss: 0.174614
Average total loss: 0.318902
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-7.8579e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.151849
Average KL loss: 0.174537
Average total loss: 0.326386
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-7.7433e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.148325
Average KL loss: 0.174455
Average total loss: 0.322780
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(4.5472e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.147037
Average KL loss: 0.174380
Average total loss: 0.321418
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.7694e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.144989
Average KL loss: 0.174305
Average total loss: 0.319295
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.2202e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.150460
Average KL loss: 0.174233
Average total loss: 0.324694
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.5892e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.143727
Average KL loss: 0.174164
Average total loss: 0.317891
 Percentile value: -0.00032904290710575876
Non-zero model percentage: 80.0%, Non-zero mask percentage: 80.0%

--- Pruning Level [1/24]: ---
conv1.weight         | nonzeros =    1315 /    1728             ( 76.10%) | total_pruned =     413 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   21558 /   36864             ( 58.48%) | total_pruned =   15306 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   22046 /   36864             ( 59.80%) | total_pruned =   14818 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   22380 /   36864             ( 60.71%) | total_pruned =   14484 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   22016 /   36864             ( 59.72%) | total_pruned =   14848 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   44843 /   73728             ( 60.82%) | total_pruned =   28885 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   89627 /  147456             ( 60.78%) | total_pruned =   57829 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5440 /    8192             ( 66.41%) | total_pruned =    2752 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   94594 /  147456             ( 64.15%) | total_pruned =   52862 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   92215 /  147456             ( 62.54%) | total_pruned =   55241 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  182116 /  294912             ( 61.75%) | total_pruned =  112796 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     237 /     256             ( 92.58%) | total_pruned =      19 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  373227 /  589824             ( 63.28%) | total_pruned =  216597 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   20583 /   32768             ( 62.81%) | total_pruned =   12185 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  428488 /  589824             ( 72.65%) | total_pruned =  161336 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  421237 /  589824             ( 71.42%) | total_pruned =  168587 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     213 /     256             ( 83.20%) | total_pruned =      43 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  793442 / 1179648             ( 67.26%) | total_pruned =  386206 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     471 /     512             ( 91.99%) | total_pruned =      41 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1864952 / 2359296             ( 79.05%) | total_pruned =  494344 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     404 /     512             ( 78.91%) | total_pruned =     108 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   83297 /  131072             ( 63.55%) | total_pruned =   47775 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     406 /     512             ( 79.30%) | total_pruned =     106 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2099614 / 2359296             ( 88.99%) | total_pruned =  259682 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     417 /     512             ( 81.45%) | total_pruned =      95 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     412 /     512             ( 80.47%) | total_pruned =     100 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2242556 / 2359296             ( 95.05%) | total_pruned =  116740 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     141 /     512             ( 27.54%) | total_pruned =     371 | shape = torch.Size([512])
linear.weight        | nonzeros =    4337 /    5120             ( 84.71%) | total_pruned =     783 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       6 /      10             ( 60.00%) | total_pruned =       4 | shape = torch.Size([10])
alive: 8943010, pruned : 2235752, total: 11178762, Compression rate :       1.25x  ( 20.00% pruned)
Train Epoch: 36/100 Loss: 0.000032 Accuracy: 86.69 100.00 % Best test Accuracy: 87.04%
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.4290e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.240367
Average KL loss: 0.209477
Average total loss: 0.449844
tensor(0.0018, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.0299e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.230790
Average KL loss: 0.233529
Average total loss: 0.464318
tensor(0.0018, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.7015e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.224786
Average KL loss: 0.237873
Average total loss: 0.462660
tensor(0.0018, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.1505e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.215052
Average KL loss: 0.241375
Average total loss: 0.456427
tensor(0.0018, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(1.2557e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.204454
Average KL loss: 0.241086
Average total loss: 0.445541
tensor(0.0018, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(4.1661e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.204338
Average KL loss: 0.241889
Average total loss: 0.446227
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(2.2713e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.199869
Average KL loss: 0.244959
Average total loss: 0.444828
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-8.2281e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.199501
Average KL loss: 0.243930
Average total loss: 0.443431
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-6.3241e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.202352
Average KL loss: 0.246258
Average total loss: 0.448610
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-4.6258e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.194542
Average KL loss: 0.247019
Average total loss: 0.441561
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.8870e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.192984
Average KL loss: 0.246962
Average total loss: 0.439946
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.6084e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.196005
Average KL loss: 0.247840
Average total loss: 0.443845
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-4.8419e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.192433
Average KL loss: 0.249196
Average total loss: 0.441629
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-5.8988e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.191476
Average KL loss: 0.248686
Average total loss: 0.440162
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.6512e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.194050
Average KL loss: 0.250724
Average total loss: 0.444774
tensor(0.0019, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(4.3971e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.185694
Average KL loss: 0.251104
Average total loss: 0.436798
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.6761e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.191454
Average KL loss: 0.250825
Average total loss: 0.442279
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.9361e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.191876
Average KL loss: 0.251781
Average total loss: 0.443657
tensor(0.0019, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.3940e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.188084
Average KL loss: 0.252491
Average total loss: 0.440575
tensor(0.0019, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(3.4681e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.183196
Average KL loss: 0.251146
Average total loss: 0.434342
tensor(0.0019, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(7.0169e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.184542
Average KL loss: 0.250906
Average total loss: 0.435448
tensor(0.0019, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.9256e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.189104
Average KL loss: 0.252513
Average total loss: 0.441617
tensor(0.0018, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(2.0513e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.175310
Average KL loss: 0.252106
Average total loss: 0.427416
tensor(0.0018, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.5542e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.174941
Average KL loss: 0.248573
Average total loss: 0.423514
tensor(0.0018, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(1.0679e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.179087
Average KL loss: 0.251516
Average total loss: 0.430603
tensor(0.0018, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-9.8256e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.174099
Average KL loss: 0.250409
Average total loss: 0.424509
tensor(0.0018, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-6.0579e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.178446
Average KL loss: 0.253614
Average total loss: 0.432060
tensor(0.0018, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-4.5562e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.177428
Average KL loss: 0.252253
Average total loss: 0.429682
tensor(0.0018, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(2.1618e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.173462
Average KL loss: 0.253162
Average total loss: 0.426624
tensor(0.0019, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(4.4963e-11, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.176272
Average KL loss: 0.254308
Average total loss: 0.430580
tensor(0.0018, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(6.9343e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.166320
Average KL loss: 0.251191
Average total loss: 0.417512
tensor(0.0018, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-7.1684e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.171236
Average KL loss: 0.251657
Average total loss: 0.422893
tensor(0.0018, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-4.0738e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.180517
Average KL loss: 0.254808
Average total loss: 0.435325
tensor(0.0018, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(4.4410e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.172192
Average KL loss: 0.255612
Average total loss: 0.427805
tensor(0.0018, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.9656e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.176044
Average KL loss: 0.256226
Average total loss: 0.432270
tensor(0.0019, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.6353e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.172542
Average KL loss: 0.256787
Average total loss: 0.429328
tensor(0.0019, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.4733e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.170406
Average KL loss: 0.255861
Average total loss: 0.426268
tensor(0.0019, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(8.0882e-11, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.173307
Average KL loss: 0.256943
Average total loss: 0.430250
tensor(0.0019, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.2649e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.168575
Average KL loss: 0.256734
Average total loss: 0.425309
tensor(0.0019, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.4891e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.174021
Average KL loss: 0.255955
Average total loss: 0.429976
tensor(0.0019, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.7087e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.169692
Average KL loss: 0.257635
Average total loss: 0.427327
tensor(0.0018, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.7898e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.165226
Average KL loss: 0.256713
Average total loss: 0.421940
tensor(0.0018, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(6.1253e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.171360
Average KL loss: 0.248271
Average total loss: 0.419631
tensor(0.0018, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-6.1183e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.165863
Average KL loss: 0.234837
Average total loss: 0.400700
tensor(0.0018, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(3.1738e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.163140
Average KL loss: 0.226971
Average total loss: 0.390111
tensor(0.0018, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.3866e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.165691
Average KL loss: 0.221769
Average total loss: 0.387460
tensor(0.0018, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-4.7586e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.170026
Average KL loss: 0.217924
Average total loss: 0.387950
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-4.7872e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.162366
Average KL loss: 0.214933
Average total loss: 0.377299
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.3969e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.162478
Average KL loss: 0.212396
Average total loss: 0.374874
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(3.2842e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.165728
Average KL loss: 0.210419
Average total loss: 0.376147
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-4.3720e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.164387
Average KL loss: 0.208768
Average total loss: 0.373155
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.8298e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.160733
Average KL loss: 0.207356
Average total loss: 0.368089
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-5.7784e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.164395
Average KL loss: 0.206005
Average total loss: 0.370400
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(1.2755e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.167496
Average KL loss: 0.205004
Average total loss: 0.372500
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-3.1698e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.165813
Average KL loss: 0.204227
Average total loss: 0.370040
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.8891e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.160882
Average KL loss: 0.203427
Average total loss: 0.364310
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(1.1598e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.164874
Average KL loss: 0.202746
Average total loss: 0.367620
tensor(0.0018, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(1.0230e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.165127
Average KL loss: 0.202167
Average total loss: 0.367294
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-4.3083e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.167893
Average KL loss: 0.201621
Average total loss: 0.369514
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.8698e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.164782
Average KL loss: 0.201194
Average total loss: 0.365975
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-6.6508e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.171335
Average KL loss: 0.200859
Average total loss: 0.372194
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.5500e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.163125
Average KL loss: 0.200384
Average total loss: 0.363509
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.2815e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.162188
Average KL loss: 0.199926
Average total loss: 0.362115
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(3.7240e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.169422
Average KL loss: 0.199593
Average total loss: 0.369015
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-7.7317e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.166631
Average KL loss: 0.199236
Average total loss: 0.365867
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(4.2219e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.162452
Average KL loss: 0.199023
Average total loss: 0.361475
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.1471e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.161474
Average KL loss: 0.198509
Average total loss: 0.359983
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-9.0726e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.168664
Average KL loss: 0.198375
Average total loss: 0.367039
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(5.0699e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.162374
Average KL loss: 0.198200
Average total loss: 0.360574
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(2.9311e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.163127
Average KL loss: 0.197988
Average total loss: 0.361115
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.4268e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.168419
Average KL loss: 0.197880
Average total loss: 0.366299
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(2.5780e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.164372
Average KL loss: 0.197677
Average total loss: 0.362049
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.0372e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.165324
Average KL loss: 0.197516
Average total loss: 0.362840
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(6.8218e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.166469
Average KL loss: 0.197385
Average total loss: 0.363854
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(7.1751e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.166416
Average KL loss: 0.197368
Average total loss: 0.363784
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.0925e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.160970
Average KL loss: 0.197163
Average total loss: 0.358133
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.4109e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.167523
Average KL loss: 0.197008
Average total loss: 0.364532
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-4.2444e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.161087
Average KL loss: 0.196932
Average total loss: 0.358018
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.4555e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.164299
Average KL loss: 0.196739
Average total loss: 0.361038
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.0537e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.165115
Average KL loss: 0.196701
Average total loss: 0.361816
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.8338e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.166101
Average KL loss: 0.196623
Average total loss: 0.362725
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(5.6794e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.167465
Average KL loss: 0.196537
Average total loss: 0.364002
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-4.2173e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.158913
Average KL loss: 0.196424
Average total loss: 0.355338
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.1106e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.163153
Average KL loss: 0.196226
Average total loss: 0.359380
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-5.7315e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.169728
Average KL loss: 0.196174
Average total loss: 0.365902
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.8258e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.161799
Average KL loss: 0.196108
Average total loss: 0.357907
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(2.5740e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.163339
Average KL loss: 0.196033
Average total loss: 0.359371
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-5.7012e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.165178
Average KL loss: 0.195984
Average total loss: 0.361162
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.3148e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.166596
Average KL loss: 0.195911
Average total loss: 0.362507
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(4.6663e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.165545
Average KL loss: 0.195897
Average total loss: 0.361441
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.2556e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.166447
Average KL loss: 0.195895
Average total loss: 0.362342
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.9063e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.164531
Average KL loss: 0.195873
Average total loss: 0.360404
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.4224e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.164595
Average KL loss: 0.195755
Average total loss: 0.360349
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.4208e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.158764
Average KL loss: 0.195664
Average total loss: 0.354428
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.4452e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.163778
Average KL loss: 0.195554
Average total loss: 0.359332
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-5.3545e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.166582
Average KL loss: 0.195515
Average total loss: 0.362097
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.0679e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.163746
Average KL loss: 0.195471
Average total loss: 0.359217
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-8.9823e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.164473
Average KL loss: 0.195509
Average total loss: 0.359982
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.4992e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.166333
Average KL loss: 0.195401
Average total loss: 0.361734
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.5488e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.168676
Average KL loss: 0.195436
Average total loss: 0.364112
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(7.1450e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.165680
Average KL loss: 0.195364
Average total loss: 0.361045
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(5.2252e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.160626
Average KL loss: 0.195275
Average total loss: 0.355901
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.3544e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.164016
Average KL loss: 0.195181
Average total loss: 0.359197
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(2.1545e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.157169
Average KL loss: 0.195173
Average total loss: 0.352341
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(3.5473e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.160259
Average KL loss: 0.195065
Average total loss: 0.355324
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(6.9078e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.167041
Average KL loss: 0.195060
Average total loss: 0.362100
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.9865e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.165330
Average KL loss: 0.195179
Average total loss: 0.360509
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(3.8887e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.171714
Average KL loss: 0.195224
Average total loss: 0.366938
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.7189e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.158424
Average KL loss: 0.195231
Average total loss: 0.353655
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.0325e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.161441
Average KL loss: 0.195079
Average total loss: 0.356520
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(2.7797e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.160450
Average KL loss: 0.195028
Average total loss: 0.355478
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(5.6280e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.159192
Average KL loss: 0.194950
Average total loss: 0.354142
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.3500e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.160607
Average KL loss: 0.194838
Average total loss: 0.355445
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.1806e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.162226
Average KL loss: 0.194701
Average total loss: 0.356927
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.0248e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.166190
Average KL loss: 0.194778
Average total loss: 0.360968
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(5.5520e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.162746
Average KL loss: 0.194770
Average total loss: 0.357516
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(3.4820e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.164013
Average KL loss: 0.194462
Average total loss: 0.358474
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.1030e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.163842
Average KL loss: 0.194197
Average total loss: 0.358040
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.9199e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.160824
Average KL loss: 0.193967
Average total loss: 0.354791
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-5.5901e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.161554
Average KL loss: 0.193766
Average total loss: 0.355320
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.6715e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.165899
Average KL loss: 0.193578
Average total loss: 0.359476
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.3285e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.163199
Average KL loss: 0.193418
Average total loss: 0.356617
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-5.2784e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.164089
Average KL loss: 0.193273
Average total loss: 0.357362
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-4.4472e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.158608
Average KL loss: 0.193134
Average total loss: 0.351742
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(2.6472e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.168096
Average KL loss: 0.193006
Average total loss: 0.361102
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.3889e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.160461
Average KL loss: 0.192884
Average total loss: 0.353345
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-5.2474e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.165348
Average KL loss: 0.192764
Average total loss: 0.358112
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.4823e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.168176
Average KL loss: 0.192661
Average total loss: 0.360837
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.0115e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.160806
Average KL loss: 0.192566
Average total loss: 0.353372
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(3.6741e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.161608
Average KL loss: 0.192466
Average total loss: 0.354074
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(3.0643e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.166193
Average KL loss: 0.192373
Average total loss: 0.358566
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.0548e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.160646
Average KL loss: 0.192289
Average total loss: 0.352934
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(5.0582e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.161725
Average KL loss: 0.192202
Average total loss: 0.353927
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-8.7016e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.171994
Average KL loss: 0.192125
Average total loss: 0.364119
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(4.1823e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.159328
Average KL loss: 0.192051
Average total loss: 0.351378
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(2.5249e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.167199
Average KL loss: 0.191975
Average total loss: 0.359174
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-5.3913e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.163282
Average KL loss: 0.191906
Average total loss: 0.355188
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.3855e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.172448
Average KL loss: 0.191849
Average total loss: 0.364297
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.4516e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.162337
Average KL loss: 0.191795
Average total loss: 0.354132
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-4.4349e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.164091
Average KL loss: 0.191735
Average total loss: 0.355826
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-9.3534e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.157354
Average KL loss: 0.191677
Average total loss: 0.349031
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-8.6248e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.163006
Average KL loss: 0.191612
Average total loss: 0.354618
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(4.1530e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.164941
Average KL loss: 0.191555
Average total loss: 0.356496
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-9.2256e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.168466
Average KL loss: 0.191502
Average total loss: 0.359969
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-4.0518e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.159206
Average KL loss: 0.191452
Average total loss: 0.350658
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(2.4853e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.164824
Average KL loss: 0.191393
Average total loss: 0.356217
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-7.5238e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.161746
Average KL loss: 0.191334
Average total loss: 0.353080
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.4862e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.165307
Average KL loss: 0.191286
Average total loss: 0.356593
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.7101e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.161783
Average KL loss: 0.191240
Average total loss: 0.353023
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.9712e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.160790
Average KL loss: 0.191194
Average total loss: 0.351984
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-7.7638e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.164980
Average KL loss: 0.191151
Average total loss: 0.356131
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(2.2129e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.160218
Average KL loss: 0.191110
Average total loss: 0.351329
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-8.5275e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.167499
Average KL loss: 0.191083
Average total loss: 0.358582
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.1934e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.162565
Average KL loss: 0.191076
Average total loss: 0.353640
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-5.2402e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.159886
Average KL loss: 0.191069
Average total loss: 0.350955
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(4.4573e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.162546
Average KL loss: 0.191061
Average total loss: 0.353607
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(5.2105e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.162009
Average KL loss: 0.191053
Average total loss: 0.353062
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-4.1094e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.165429
Average KL loss: 0.191045
Average total loss: 0.356474
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(7.5916e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.161288
Average KL loss: 0.191038
Average total loss: 0.352326
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-4.2029e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.160808
Average KL loss: 0.191030
Average total loss: 0.351838
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-7.3069e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.162883
Average KL loss: 0.191023
Average total loss: 0.353905
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(8.6116e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.165458
Average KL loss: 0.191016
Average total loss: 0.356474
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(1.6636e-09, device='cuda:0')
 Percentile value: -0.00016613384359516194
Non-zero model percentage: 64.0%, Non-zero mask percentage: 64.0%

--- Pruning Level [2/24]: ---
conv1.weight         | nonzeros =    1124 /    1728             ( 65.05%) | total_pruned =     604 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   13368 /   36864             ( 36.26%) | total_pruned =   23496 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   13765 /   36864             ( 37.34%) | total_pruned =   23099 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   13964 /   36864             ( 37.88%) | total_pruned =   22900 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   13569 /   36864             ( 36.81%) | total_pruned =   23295 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   27526 /   73728             ( 37.33%) | total_pruned =   46202 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   54950 /  147456             ( 37.27%) | total_pruned =   92506 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3852 /    8192             ( 47.02%) | total_pruned =    4340 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   60041 /  147456             ( 40.72%) | total_pruned =   87415 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   57670 /  147456             ( 39.11%) | total_pruned =   89786 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  112932 /  294912             ( 38.29%) | total_pruned =  181980 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  233573 /  589824             ( 39.60%) | total_pruned =  356251 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   13708 /   32768             ( 41.83%) | total_pruned =   19060 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  311927 /  589824             ( 52.88%) | total_pruned =  277897 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     212 /     256             ( 82.81%) | total_pruned =      44 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  305104 /  589824             ( 51.73%) | total_pruned =  284720 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     169 /     256             ( 66.02%) | total_pruned =      87 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  516142 / 1179648             ( 43.75%) | total_pruned =  663506 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     414 /     512             ( 80.86%) | total_pruned =      98 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1390947 / 2359296             ( 58.96%) | total_pruned =  968349 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     368 /     512             ( 71.88%) | total_pruned =     144 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   53499 /  131072             ( 40.82%) | total_pruned =   77573 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     484 /     512             ( 94.53%) | total_pruned =      28 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     365 /     512             ( 71.29%) | total_pruned =     147 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1820894 / 2359296             ( 77.18%) | total_pruned =  538402 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     377 /     512             ( 73.63%) | total_pruned =     135 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2119484 / 2359296             ( 89.84%) | total_pruned =  239812 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      74 /     512             ( 14.45%) | total_pruned =     438 | shape = torch.Size([512])
linear.weight        | nonzeros =    3788 /    5120             ( 73.98%) | total_pruned =    1332 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 7154408, pruned : 4024354, total: 11178762, Compression rate :       1.56x  ( 36.00% pruned)
Train Epoch: 36/100 Loss: 0.000133 Accuracy: 87.08 100.00 % Best test Accuracy: 87.24%
tensor(0.0018, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.3916e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.295270
Average KL loss: 0.223739
Average total loss: 0.519009
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.8633e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.270715
Average KL loss: 0.250864
Average total loss: 0.521578
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-8.8524e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.253133
Average KL loss: 0.257386
Average total loss: 0.510519
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-5.0580e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.250040
Average KL loss: 0.260945
Average total loss: 0.510985
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0613e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.247744
Average KL loss: 0.263950
Average total loss: 0.511693
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.7796e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.244327
Average KL loss: 0.267143
Average total loss: 0.511471
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.8845e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.238940
Average KL loss: 0.266889
Average total loss: 0.505828
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.2982e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.234811
Average KL loss: 0.267339
Average total loss: 0.502150
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-4.2360e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.227386
Average KL loss: 0.267900
Average total loss: 0.495286
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.4340e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.227330
Average KL loss: 0.266981
Average total loss: 0.494311
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.1492e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.228525
Average KL loss: 0.269663
Average total loss: 0.498188
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.8987e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.228839
Average KL loss: 0.269922
Average total loss: 0.498762
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-8.7071e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.229178
Average KL loss: 0.272400
Average total loss: 0.501577
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.1246e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.224710
Average KL loss: 0.272922
Average total loss: 0.497632
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(3.5430e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.220399
Average KL loss: 0.271862
Average total loss: 0.492261
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.4477e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.234641
Average KL loss: 0.272730
Average total loss: 0.507371
tensor(0.0022, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-5.2193e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.220826
Average KL loss: 0.276983
Average total loss: 0.497809
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.5296e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.223477
Average KL loss: 0.275403
Average total loss: 0.498880
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(3.4545e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.221208
Average KL loss: 0.275803
Average total loss: 0.497010
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(2.4759e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.215959
Average KL loss: 0.274387
Average total loss: 0.490346
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-7.2695e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.216319
Average KL loss: 0.275116
Average total loss: 0.491435
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(5.7155e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.217038
Average KL loss: 0.276111
Average total loss: 0.493149
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-4.8487e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.217111
Average KL loss: 0.276627
Average total loss: 0.493737
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.0689e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.211983
Average KL loss: 0.278244
Average total loss: 0.490226
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.1029e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.215569
Average KL loss: 0.277762
Average total loss: 0.493331
tensor(0.0021, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.6472e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.214974
Average KL loss: 0.278282
Average total loss: 0.493256
tensor(0.0022, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.0414e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.202456
Average KL loss: 0.277438
Average total loss: 0.479894
tensor(0.0021, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.0154e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.209116
Average KL loss: 0.276849
Average total loss: 0.485965
tensor(0.0021, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(9.4301e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.200231
Average KL loss: 0.276383
Average total loss: 0.476614
tensor(0.0021, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(2.2263e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.210599
Average KL loss: 0.277259
Average total loss: 0.487858
tensor(0.0021, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-8.7439e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.213481
Average KL loss: 0.280209
Average total loss: 0.493691
tensor(0.0022, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-6.2743e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.209046
Average KL loss: 0.281117
Average total loss: 0.490163
tensor(0.0022, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-6.6006e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.203493
Average KL loss: 0.280388
Average total loss: 0.483881
tensor(0.0021, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.0132e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.203766
Average KL loss: 0.279898
Average total loss: 0.483664
tensor(0.0021, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.8480e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.200046
Average KL loss: 0.278469
Average total loss: 0.478515
tensor(0.0021, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.4270e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.205374
Average KL loss: 0.278393
Average total loss: 0.483766
tensor(0.0021, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.4901e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.201442
Average KL loss: 0.279867
Average total loss: 0.481309
tensor(0.0021, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.7066e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.206853
Average KL loss: 0.280039
Average total loss: 0.486892
tensor(0.0022, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(2.8152e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.202427
Average KL loss: 0.281329
Average total loss: 0.483756
tensor(0.0021, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(3.7766e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.203293
Average KL loss: 0.281007
Average total loss: 0.484301
tensor(0.0021, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.0360e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.206427
Average KL loss: 0.273926
Average total loss: 0.480353
tensor(0.0021, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.5673e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.199689
Average KL loss: 0.262474
Average total loss: 0.462162
tensor(0.0021, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(4.5875e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.196577
Average KL loss: 0.255254
Average total loss: 0.451831
tensor(0.0021, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.2197e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.200616
Average KL loss: 0.250129
Average total loss: 0.450745
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(4.9406e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.201247
Average KL loss: 0.246262
Average total loss: 0.447509
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(2.1017e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.200220
Average KL loss: 0.243182
Average total loss: 0.443401
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(5.4217e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.202113
Average KL loss: 0.240628
Average total loss: 0.442741
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.0666e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.201624
Average KL loss: 0.238523
Average total loss: 0.440147
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.4172e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.201308
Average KL loss: 0.236684
Average total loss: 0.437992
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.4204e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.200411
Average KL loss: 0.235131
Average total loss: 0.435541
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.2346e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.199891
Average KL loss: 0.233749
Average total loss: 0.433639
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-7.9652e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.196234
Average KL loss: 0.232532
Average total loss: 0.428766
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(1.7891e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.194786
Average KL loss: 0.231383
Average total loss: 0.426170
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(4.7599e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.202084
Average KL loss: 0.230432
Average total loss: 0.432516
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(4.5064e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.198088
Average KL loss: 0.229629
Average total loss: 0.427717
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-5.1485e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.194628
Average KL loss: 0.228781
Average total loss: 0.423408
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(3.7272e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.192402
Average KL loss: 0.227979
Average total loss: 0.420380
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-9.5145e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.199890
Average KL loss: 0.227358
Average total loss: 0.427249
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-7.3113e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.194260
Average KL loss: 0.226817
Average total loss: 0.421077
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(3.7194e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.199968
Average KL loss: 0.226230
Average total loss: 0.426199
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(6.9192e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.198039
Average KL loss: 0.225743
Average total loss: 0.423782
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(3.2279e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.197357
Average KL loss: 0.225245
Average total loss: 0.422603
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.4122e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.198254
Average KL loss: 0.224788
Average total loss: 0.423042
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.2842e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.196427
Average KL loss: 0.224485
Average total loss: 0.420912
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(1.2369e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.197508
Average KL loss: 0.224114
Average total loss: 0.421622
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-8.2557e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.206180
Average KL loss: 0.223816
Average total loss: 0.429996
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(3.9118e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.196337
Average KL loss: 0.223586
Average total loss: 0.419922
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-5.5250e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.202042
Average KL loss: 0.223215
Average total loss: 0.425257
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.3831e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.201085
Average KL loss: 0.223061
Average total loss: 0.424146
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.0340e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.204756
Average KL loss: 0.222885
Average total loss: 0.427641
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-6.4563e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.199568
Average KL loss: 0.222676
Average total loss: 0.422244
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(1.5389e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.200892
Average KL loss: 0.222458
Average total loss: 0.423350
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.2896e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.201486
Average KL loss: 0.222266
Average total loss: 0.423752
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(9.4966e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.194193
Average KL loss: 0.222063
Average total loss: 0.416255
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(1.1423e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.196895
Average KL loss: 0.221825
Average total loss: 0.418720
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.8104e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.196444
Average KL loss: 0.221611
Average total loss: 0.418055
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.4181e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.203270
Average KL loss: 0.221482
Average total loss: 0.424752
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(9.8658e-11, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.197886
Average KL loss: 0.221434
Average total loss: 0.419320
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.2518e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.198832
Average KL loss: 0.221254
Average total loss: 0.420085
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.9827e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.199928
Average KL loss: 0.221008
Average total loss: 0.420936
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-9.1051e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.197955
Average KL loss: 0.220902
Average total loss: 0.418856
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(9.2126e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.194580
Average KL loss: 0.220723
Average total loss: 0.415303
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-8.9488e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.197166
Average KL loss: 0.220578
Average total loss: 0.417744
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(5.6783e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.202479
Average KL loss: 0.220510
Average total loss: 0.422989
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(1.5456e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.195832
Average KL loss: 0.220465
Average total loss: 0.416297
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.1725e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.196877
Average KL loss: 0.220354
Average total loss: 0.417230
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.7880e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.197071
Average KL loss: 0.220231
Average total loss: 0.417302
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.0700e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.197416
Average KL loss: 0.220164
Average total loss: 0.417580
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-5.7382e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.198148
Average KL loss: 0.220074
Average total loss: 0.418221
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-5.3432e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.198812
Average KL loss: 0.219975
Average total loss: 0.418787
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.9749e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.200233
Average KL loss: 0.219815
Average total loss: 0.420048
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(4.6566e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.197291
Average KL loss: 0.219778
Average total loss: 0.417069
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-4.0364e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.198885
Average KL loss: 0.219725
Average total loss: 0.418610
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(5.9918e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.201026
Average KL loss: 0.219572
Average total loss: 0.420598
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.0263e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.204213
Average KL loss: 0.219340
Average total loss: 0.423553
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(8.4998e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.194115
Average KL loss: 0.219126
Average total loss: 0.413241
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(3.6977e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.196038
Average KL loss: 0.218927
Average total loss: 0.414964
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.2019e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.192308
Average KL loss: 0.218757
Average total loss: 0.411065
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-7.3751e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.196103
Average KL loss: 0.218598
Average total loss: 0.414701
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-4.0486e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.199599
Average KL loss: 0.218453
Average total loss: 0.418052
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(5.6782e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.196689
Average KL loss: 0.218318
Average total loss: 0.415007
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(3.1820e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.195951
Average KL loss: 0.218189
Average total loss: 0.414141
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.2126e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.197988
Average KL loss: 0.218071
Average total loss: 0.416059
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.8090e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.194747
Average KL loss: 0.217954
Average total loss: 0.412701
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.7425e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.190932
Average KL loss: 0.217841
Average total loss: 0.408773
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.0545e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.197415
Average KL loss: 0.217734
Average total loss: 0.415149
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(1.8280e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.191246
Average KL loss: 0.217640
Average total loss: 0.408886
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-4.4743e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.197583
Average KL loss: 0.217548
Average total loss: 0.415131
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-9.1846e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.193795
Average KL loss: 0.217456
Average total loss: 0.411251
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(3.1341e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.199406
Average KL loss: 0.217367
Average total loss: 0.416773
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.1296e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.195691
Average KL loss: 0.217283
Average total loss: 0.412974
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-7.3542e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.196714
Average KL loss: 0.217201
Average total loss: 0.413915
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(1.7915e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.195130
Average KL loss: 0.217119
Average total loss: 0.412249
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-3.3220e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.203148
Average KL loss: 0.217047
Average total loss: 0.420195
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(1.5796e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.203463
Average KL loss: 0.216980
Average total loss: 0.420443
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(6.7020e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.202047
Average KL loss: 0.216912
Average total loss: 0.418959
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(1.3327e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.198904
Average KL loss: 0.216874
Average total loss: 0.415779
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-7.2669e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.198352
Average KL loss: 0.216865
Average total loss: 0.415217
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.5877e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.198848
Average KL loss: 0.216856
Average total loss: 0.415704
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.8716e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.206830
Average KL loss: 0.216847
Average total loss: 0.423677
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-7.9137e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.195100
Average KL loss: 0.216839
Average total loss: 0.411939
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(3.7261e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.192575
Average KL loss: 0.216830
Average total loss: 0.409405
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(5.5577e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.203174
Average KL loss: 0.216821
Average total loss: 0.419994
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(7.1100e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.194862
Average KL loss: 0.216812
Average total loss: 0.411674
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(7.4514e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.193686
Average KL loss: 0.216803
Average total loss: 0.410489
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.8330e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.201187
Average KL loss: 0.216793
Average total loss: 0.417980
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-3.9562e-09, device='cuda:0')
 Percentile value: -0.00010632826597429816
Non-zero model percentage: 51.200008392333984%, Non-zero mask percentage: 51.200008392333984%

--- Pruning Level [3/24]: ---
conv1.weight         | nonzeros =     970 /    1728             ( 56.13%) | total_pruned =     758 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    8742 /   36864             ( 23.71%) | total_pruned =   28122 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    8977 /   36864             ( 24.35%) | total_pruned =   27887 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    8949 /   36864             ( 24.28%) | total_pruned =   27915 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    8664 /   36864             ( 23.50%) | total_pruned =   28200 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   17428 /   73728             ( 23.64%) | total_pruned =   56300 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   34300 /  147456             ( 23.26%) | total_pruned =  113156 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2852 /    8192             ( 34.81%) | total_pruned =    5340 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   38002 /  147456             ( 25.77%) | total_pruned =  109454 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   36642 /  147456             ( 24.85%) | total_pruned =  110814 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   70725 /  294912             ( 23.98%) | total_pruned =  224187 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     173 /     256             ( 67.58%) | total_pruned =      83 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  145908 /  589824             ( 24.74%) | total_pruned =  443916 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     194 /     256             ( 75.78%) | total_pruned =      62 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    9529 /   32768             ( 29.08%) | total_pruned =   23239 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  229852 /  589824             ( 38.97%) | total_pruned =  359972 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     212 /     256             ( 82.81%) | total_pruned =      44 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     167 /     256             ( 65.23%) | total_pruned =      89 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  223538 /  589824             ( 37.90%) | total_pruned =  366286 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     125 /     256             ( 48.83%) | total_pruned =     131 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  330802 / 1179648             ( 28.04%) | total_pruned =  848846 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     360 /     512             ( 70.31%) | total_pruned =     152 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  987415 / 2359296             ( 41.85%) | total_pruned = 1371881 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     346 /     512             ( 67.58%) | total_pruned =     166 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   35578 /  131072             ( 27.14%) | total_pruned =   95494 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     458 /     512             ( 89.45%) | total_pruned =      54 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     338 /     512             ( 66.02%) | total_pruned =     174 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1529891 / 2359296             ( 64.85%) | total_pruned =  829405 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     388 /     512             ( 75.78%) | total_pruned =     124 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     364 /     512             ( 71.09%) | total_pruned =     148 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1979393 / 2359296             ( 83.90%) | total_pruned =  379903 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      58 /     512             ( 11.33%) | total_pruned =     454 | shape = torch.Size([512])
linear.weight        | nonzeros =    3212 /    5120             ( 62.73%) | total_pruned =    1908 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 5723527, pruned : 5455235, total: 11178762, Compression rate :       1.95x  ( 48.80% pruned)
Train Epoch: 34/100 Loss: 0.000088 Accuracy: 87.06 100.00 % Best test Accuracy: 87.23%
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.5457e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.329234
Average KL loss: 0.240557
Average total loss: 0.569791
tensor(0.0023, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-9.0949e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.315548
Average KL loss: 0.265913
Average total loss: 0.581462
tensor(0.0024, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.3331e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.305814
Average KL loss: 0.276667
Average total loss: 0.582481
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.7384e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.295182
Average KL loss: 0.281077
Average total loss: 0.576258
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.8749e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.284506
Average KL loss: 0.282727
Average total loss: 0.567233
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-9.7005e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.293012
Average KL loss: 0.285359
Average total loss: 0.578372
tensor(0.0024, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.7758e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.280735
Average KL loss: 0.288013
Average total loss: 0.568748
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.0471e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.276663
Average KL loss: 0.288604
Average total loss: 0.565267
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(5.2352e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.280496
Average KL loss: 0.288643
Average total loss: 0.569139
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.8490e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.277159
Average KL loss: 0.290923
Average total loss: 0.568082
tensor(0.0024, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(1.3552e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.267983
Average KL loss: 0.291612
Average total loss: 0.559595
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.0651e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.274070
Average KL loss: 0.291892
Average total loss: 0.565962
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(4.3711e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.273871
Average KL loss: 0.294456
Average total loss: 0.568328
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(3.4660e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.265689
Average KL loss: 0.294300
Average total loss: 0.559989
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(1.5972e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.258853
Average KL loss: 0.294829
Average total loss: 0.553682
tensor(0.0024, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(2.7122e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.272343
Average KL loss: 0.295453
Average total loss: 0.567796
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.2745e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.263101
Average KL loss: 0.295201
Average total loss: 0.558302
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.5921e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.272825
Average KL loss: 0.297068
Average total loss: 0.569894
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(4.5123e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.267162
Average KL loss: 0.298271
Average total loss: 0.565433
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.1147e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.249628
Average KL loss: 0.297638
Average total loss: 0.547266
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.5825e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.262237
Average KL loss: 0.296125
Average total loss: 0.558362
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.1267e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.266173
Average KL loss: 0.299169
Average total loss: 0.565342
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(3.2813e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.262083
Average KL loss: 0.300124
Average total loss: 0.562207
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-7.5171e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.259272
Average KL loss: 0.301442
Average total loss: 0.560714
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0600e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.257315
Average KL loss: 0.299558
Average total loss: 0.556873
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(7.7248e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.253451
Average KL loss: 0.299833
Average total loss: 0.553285
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(1.9955e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.256173
Average KL loss: 0.300378
Average total loss: 0.556552
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(6.0190e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.251772
Average KL loss: 0.300269
Average total loss: 0.552040
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.7561e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.253793
Average KL loss: 0.299920
Average total loss: 0.553713
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0930e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.258022
Average KL loss: 0.301560
Average total loss: 0.559581
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(1.1082e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.243048
Average KL loss: 0.300230
Average total loss: 0.543279
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.4801e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.253040
Average KL loss: 0.299129
Average total loss: 0.552169
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.8647e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.250841
Average KL loss: 0.300148
Average total loss: 0.550989
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-9.1315e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.250694
Average KL loss: 0.301196
Average total loss: 0.551890
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.7867e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.248086
Average KL loss: 0.301497
Average total loss: 0.549584
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.2667e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.250339
Average KL loss: 0.302249
Average total loss: 0.552588
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.6100e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.245269
Average KL loss: 0.301837
Average total loss: 0.547106
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.0536e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.247843
Average KL loss: 0.301161
Average total loss: 0.549004
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(7.3004e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.251907
Average KL loss: 0.302785
Average total loss: 0.554692
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(6.1117e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.253380
Average KL loss: 0.305452
Average total loss: 0.558832
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(8.1442e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.249888
Average KL loss: 0.304383
Average total loss: 0.554270
tensor(0.0025, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.0654e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.243232
Average KL loss: 0.304769
Average total loss: 0.548001
tensor(0.0025, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(2.6341e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.246038
Average KL loss: 0.299200
Average total loss: 0.545238
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(9.0239e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.250945
Average KL loss: 0.289482
Average total loss: 0.540427
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(4.5487e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.240861
Average KL loss: 0.283193
Average total loss: 0.524054
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.8579e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.241627
Average KL loss: 0.278430
Average total loss: 0.520057
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.3612e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.240523
Average KL loss: 0.274614
Average total loss: 0.515137
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(2.2126e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.243537
Average KL loss: 0.271550
Average total loss: 0.515086
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.8328e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.251697
Average KL loss: 0.269010
Average total loss: 0.520707
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(8.9260e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.242073
Average KL loss: 0.266837
Average total loss: 0.508910
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0009e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.237988
Average KL loss: 0.264887
Average total loss: 0.502875
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.0315e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.235502
Average KL loss: 0.263078
Average total loss: 0.498580
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(2.0674e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.240003
Average KL loss: 0.261558
Average total loss: 0.501560
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(6.5708e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.245563
Average KL loss: 0.260264
Average total loss: 0.505827
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(8.3118e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.242121
Average KL loss: 0.259094
Average total loss: 0.501215
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(8.6960e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.247289
Average KL loss: 0.257995
Average total loss: 0.505284
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.2543e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.243021
Average KL loss: 0.257034
Average total loss: 0.500055
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(7.6323e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.244916
Average KL loss: 0.256113
Average total loss: 0.501029
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.0435e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.237690
Average KL loss: 0.255256
Average total loss: 0.492946
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(2.3531e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.237999
Average KL loss: 0.254490
Average total loss: 0.492489
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.6694e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.236332
Average KL loss: 0.253704
Average total loss: 0.490035
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.7480e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.244974
Average KL loss: 0.252996
Average total loss: 0.497970
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-9.5805e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.245276
Average KL loss: 0.252472
Average total loss: 0.497748
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.8945e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.235659
Average KL loss: 0.251961
Average total loss: 0.487620
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.5343e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.244165
Average KL loss: 0.251337
Average total loss: 0.495502
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.8134e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.238860
Average KL loss: 0.250937
Average total loss: 0.489797
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.1629e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.247809
Average KL loss: 0.250522
Average total loss: 0.498332
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(8.5648e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.238998
Average KL loss: 0.250123
Average total loss: 0.489121
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(4.8400e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.247250
Average KL loss: 0.249726
Average total loss: 0.496977
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.7238e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.248869
Average KL loss: 0.249439
Average total loss: 0.498308
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2464e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.244237
Average KL loss: 0.249113
Average total loss: 0.493350
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(4.8847e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.242191
Average KL loss: 0.248827
Average total loss: 0.491018
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-8.3244e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.244215
Average KL loss: 0.248452
Average total loss: 0.492667
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.2081e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.238946
Average KL loss: 0.248163
Average total loss: 0.487109
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(3.4741e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.242552
Average KL loss: 0.247900
Average total loss: 0.490452
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.1928e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.241442
Average KL loss: 0.247602
Average total loss: 0.489044
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.0301e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.246627
Average KL loss: 0.247360
Average total loss: 0.493987
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.0827e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.243235
Average KL loss: 0.247118
Average total loss: 0.490353
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.5925e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.238020
Average KL loss: 0.246868
Average total loss: 0.484888
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.8240e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.237721
Average KL loss: 0.246524
Average total loss: 0.484245
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.3746e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.240457
Average KL loss: 0.246343
Average total loss: 0.486800
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(4.6958e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.240396
Average KL loss: 0.246083
Average total loss: 0.486479
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-8.2897e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.238813
Average KL loss: 0.245850
Average total loss: 0.484662
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(2.0265e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.245516
Average KL loss: 0.245695
Average total loss: 0.491211
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.8103e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.236831
Average KL loss: 0.245498
Average total loss: 0.482328
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.4094e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.243077
Average KL loss: 0.245314
Average total loss: 0.488391
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.9192e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.249161
Average KL loss: 0.245234
Average total loss: 0.494396
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.6323e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.243860
Average KL loss: 0.245180
Average total loss: 0.489040
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.7445e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.237844
Average KL loss: 0.245013
Average total loss: 0.482856
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(7.7288e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.243552
Average KL loss: 0.244912
Average total loss: 0.488464
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(2.3560e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.238497
Average KL loss: 0.244794
Average total loss: 0.483292
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.9190e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.240200
Average KL loss: 0.244571
Average total loss: 0.484771
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-9.6075e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.237215
Average KL loss: 0.244398
Average total loss: 0.481613
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.1633e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.237048
Average KL loss: 0.244176
Average total loss: 0.481223
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(9.1491e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.247112
Average KL loss: 0.244051
Average total loss: 0.491163
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.3241e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.239195
Average KL loss: 0.244074
Average total loss: 0.483269
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.4464e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.245967
Average KL loss: 0.243920
Average total loss: 0.489887
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.2585e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.235864
Average KL loss: 0.243844
Average total loss: 0.479708
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.2368e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.248493
Average KL loss: 0.243854
Average total loss: 0.492347
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.4947e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.239440
Average KL loss: 0.243915
Average total loss: 0.483355
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.1742e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.238557
Average KL loss: 0.243767
Average total loss: 0.482324
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(4.0860e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.242217
Average KL loss: 0.243610
Average total loss: 0.485827
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(4.5080e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.239803
Average KL loss: 0.243572
Average total loss: 0.483375
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(5.6357e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.238874
Average KL loss: 0.243471
Average total loss: 0.482345
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.7521e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.237247
Average KL loss: 0.243410
Average total loss: 0.480657
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.3570e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.242966
Average KL loss: 0.243338
Average total loss: 0.486304
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(3.0314e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.243682
Average KL loss: 0.243309
Average total loss: 0.486991
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.4077e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.234680
Average KL loss: 0.243213
Average total loss: 0.477893
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.5662e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.237630
Average KL loss: 0.243075
Average total loss: 0.480705
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.7941e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.245273
Average KL loss: 0.243061
Average total loss: 0.488333
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.7961e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.237801
Average KL loss: 0.243128
Average total loss: 0.480929
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.3324e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.237948
Average KL loss: 0.243066
Average total loss: 0.481014
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.3096e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.240827
Average KL loss: 0.242964
Average total loss: 0.483791
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.1286e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.242130
Average KL loss: 0.242936
Average total loss: 0.485066
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.2114e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.238744
Average KL loss: 0.242912
Average total loss: 0.481657
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(3.8907e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.235658
Average KL loss: 0.242849
Average total loss: 0.478507
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.9533e-11, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.235910
Average KL loss: 0.242626
Average total loss: 0.478536
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.5641e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.239547
Average KL loss: 0.242607
Average total loss: 0.482154
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.9431e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.235271
Average KL loss: 0.242590
Average total loss: 0.477860
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(3.3063e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.240383
Average KL loss: 0.242486
Average total loss: 0.482869
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.0664e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.241475
Average KL loss: 0.242304
Average total loss: 0.483779
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.6694e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.239009
Average KL loss: 0.242140
Average total loss: 0.481149
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-8.0676e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.233974
Average KL loss: 0.241989
Average total loss: 0.475963
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2225e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.240138
Average KL loss: 0.241848
Average total loss: 0.481986
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.1123e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.236218
Average KL loss: 0.241729
Average total loss: 0.477947
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.0432e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.239167
Average KL loss: 0.241607
Average total loss: 0.480774
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.2790e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.236566
Average KL loss: 0.241495
Average total loss: 0.478061
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.1929e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.237213
Average KL loss: 0.241389
Average total loss: 0.478601
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.4185e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.243094
Average KL loss: 0.241283
Average total loss: 0.484377
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-8.0391e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.232376
Average KL loss: 0.241192
Average total loss: 0.473568
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.6526e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.236359
Average KL loss: 0.241101
Average total loss: 0.477459
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.0466e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.242284
Average KL loss: 0.241012
Average total loss: 0.483296
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.6830e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.237022
Average KL loss: 0.240936
Average total loss: 0.477959
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.6470e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.241894
Average KL loss: 0.240857
Average total loss: 0.482752
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(8.9262e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.240436
Average KL loss: 0.240786
Average total loss: 0.481222
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(6.6463e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.243423
Average KL loss: 0.240713
Average total loss: 0.484136
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.5319e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.234645
Average KL loss: 0.240637
Average total loss: 0.475282
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-8.2344e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.245117
Average KL loss: 0.240564
Average total loss: 0.485681
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.2119e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.238500
Average KL loss: 0.240494
Average total loss: 0.478994
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(9.7440e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.239734
Average KL loss: 0.240430
Average total loss: 0.480165
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(9.5314e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.237491
Average KL loss: 0.240370
Average total loss: 0.477860
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(4.7521e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.241510
Average KL loss: 0.240335
Average total loss: 0.481846
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.8687e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.240133
Average KL loss: 0.240327
Average total loss: 0.480460
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.4283e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.239795
Average KL loss: 0.240319
Average total loss: 0.480115
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.6872e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.230800
Average KL loss: 0.240311
Average total loss: 0.471111
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(4.5274e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.241660
Average KL loss: 0.240303
Average total loss: 0.481962
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.5668e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.238871
Average KL loss: 0.240294
Average total loss: 0.479166
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.1144e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.228203
Average KL loss: 0.240286
Average total loss: 0.468489
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(5.1215e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.232167
Average KL loss: 0.240277
Average total loss: 0.472443
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.5988e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.232061
Average KL loss: 0.240268
Average total loss: 0.472329
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(4.7231e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.236402
Average KL loss: 0.240260
Average total loss: 0.476662
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(4.4590e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.235706
Average KL loss: 0.240251
Average total loss: 0.475958
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.4222e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.238742
Average KL loss: 0.240243
Average total loss: 0.478985
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(2.9643e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.242756
Average KL loss: 0.240236
Average total loss: 0.482992
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.0013e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.238000
Average KL loss: 0.240228
Average total loss: 0.478228
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.5585e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.240832
Average KL loss: 0.240220
Average total loss: 0.481052
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-8.5917e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.234373
Average KL loss: 0.240213
Average total loss: 0.474585
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(6.2728e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.235010
Average KL loss: 0.240205
Average total loss: 0.475215
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(6.0873e-09, device='cuda:0')
 Percentile value: -1.0378417937317852e-05
Non-zero model percentage: 40.96000671386719%, Non-zero mask percentage: 40.96000671386719%

--- Pruning Level [4/24]: ---
conv1.weight         | nonzeros =     900 /    1728             ( 52.08%) | total_pruned =     828 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5911 /   36864             ( 16.03%) | total_pruned =   30953 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    6196 /   36864             ( 16.81%) | total_pruned =   30668 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    6022 /   36864             ( 16.34%) | total_pruned =   30842 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    5824 /   36864             ( 15.80%) | total_pruned =   31040 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   11611 /   73728             ( 15.75%) | total_pruned =   62117 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   22329 /  147456             ( 15.14%) | total_pruned =  125127 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2270 /    8192             ( 27.71%) | total_pruned =    5922 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   24491 /  147456             ( 16.61%) | total_pruned =  122965 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   23639 /  147456             ( 16.03%) | total_pruned =  123817 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   45454 /  294912             ( 15.41%) | total_pruned =  249458 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     140 /     256             ( 54.69%) | total_pruned =     116 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   92396 /  589824             ( 15.67%) | total_pruned =  497428 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     171 /     256             ( 66.80%) | total_pruned =      85 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    7105 /   32768             ( 21.68%) | total_pruned =   25663 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     174 /     256             ( 67.97%) | total_pruned =      82 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  173113 /  589824             ( 29.35%) | total_pruned =  416711 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     141 /     256             ( 55.08%) | total_pruned =     115 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  169150 /  589824             ( 28.68%) | total_pruned =  420674 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      92 /     256             ( 35.94%) | total_pruned =     164 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  211722 / 1179648             ( 17.95%) | total_pruned =  967926 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     320 /     512             ( 62.50%) | total_pruned =     192 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  671616 / 2359296             ( 28.47%) | total_pruned = 1687680 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     331 /     512             ( 64.65%) | total_pruned =     181 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   25171 /  131072             ( 19.20%) | total_pruned =  105901 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     435 /     512             ( 84.96%) | total_pruned =      77 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     330 /     512             ( 64.45%) | total_pruned =     182 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1253421 / 2359296             ( 53.13%) | total_pruned = 1105875 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     383 /     512             ( 74.80%) | total_pruned =     129 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     355 /     512             ( 69.34%) | total_pruned =     157 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1805978 / 2359296             ( 76.55%) | total_pruned =  553318 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      49 /     512             (  9.57%) | total_pruned =     463 | shape = torch.Size([512])
linear.weight        | nonzeros =    2694 /    5120             ( 52.62%) | total_pruned =    2426 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 4578822, pruned : 6599940, total: 11178762, Compression rate :       2.44x  ( 59.04% pruned)
Train Epoch: 32/100 Loss: 0.000054 Accuracy: 87.15 100.00 % Best test Accuracy: 87.23%
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.7032e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.387230
Average KL loss: 0.256488
Average total loss: 0.643718
tensor(0.0026, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.7833e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.377678
Average KL loss: 0.281823
Average total loss: 0.659501
tensor(0.0027, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.1219e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.360471
Average KL loss: 0.294734
Average total loss: 0.655206
tensor(0.0027, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.6946e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.353721
Average KL loss: 0.300115
Average total loss: 0.653837
tensor(0.0027, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.3266e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.350114
Average KL loss: 0.304876
Average total loss: 0.654990
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.7362e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.340807
Average KL loss: 0.310329
Average total loss: 0.651136
tensor(0.0028, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.9303e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.338938
Average KL loss: 0.312468
Average total loss: 0.651406
tensor(0.0028, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(5.3504e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.325413
Average KL loss: 0.311511
Average total loss: 0.636924
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(4.3826e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.319369
Average KL loss: 0.311913
Average total loss: 0.631282
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.8921e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.321908
Average KL loss: 0.312407
Average total loss: 0.634315
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(1.0819e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.321880
Average KL loss: 0.314602
Average total loss: 0.636483
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(1.7758e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.320366
Average KL loss: 0.314928
Average total loss: 0.635295
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-9.7273e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.327908
Average KL loss: 0.317827
Average total loss: 0.645735
tensor(0.0028, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.7825e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.309475
Average KL loss: 0.318134
Average total loss: 0.627609
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.9490e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.306565
Average KL loss: 0.317189
Average total loss: 0.623754
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.7316e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.321748
Average KL loss: 0.318828
Average total loss: 0.640577
tensor(0.0028, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.8082e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.319770
Average KL loss: 0.320865
Average total loss: 0.640635
tensor(0.0028, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-6.4628e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.311816
Average KL loss: 0.322037
Average total loss: 0.633853
tensor(0.0027, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(3.2347e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.309727
Average KL loss: 0.321868
Average total loss: 0.631594
tensor(0.0027, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(7.0803e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.310547
Average KL loss: 0.321390
Average total loss: 0.631937
tensor(0.0027, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.9936e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.301825
Average KL loss: 0.320652
Average total loss: 0.622476
tensor(0.0027, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.1537e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.301892
Average KL loss: 0.321241
Average total loss: 0.623133
tensor(0.0027, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(2.5170e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.306022
Average KL loss: 0.321057
Average total loss: 0.627080
tensor(0.0027, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-3.1939e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.301433
Average KL loss: 0.321104
Average total loss: 0.622537
tensor(0.0027, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.7454e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.313232
Average KL loss: 0.322380
Average total loss: 0.635613
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.6311e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.304635
Average KL loss: 0.323338
Average total loss: 0.627973
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(5.8004e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.300928
Average KL loss: 0.324861
Average total loss: 0.625789
tensor(0.0027, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(8.8687e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.293309
Average KL loss: 0.322913
Average total loss: 0.616222
tensor(0.0028, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(4.1178e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.297747
Average KL loss: 0.323278
Average total loss: 0.621025
tensor(0.0027, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-2.3657e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.305821
Average KL loss: 0.324984
Average total loss: 0.630805
tensor(0.0027, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-6.7000e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.287373
Average KL loss: 0.326219
Average total loss: 0.613592
tensor(0.0028, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(1.6570e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.301064
Average KL loss: 0.325602
Average total loss: 0.626666
tensor(0.0027, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-4.3154e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.305452
Average KL loss: 0.327364
Average total loss: 0.632816
tensor(0.0028, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-4.2516e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.299608
Average KL loss: 0.328727
Average total loss: 0.628334
tensor(0.0028, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(5.9800e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.305393
Average KL loss: 0.329375
Average total loss: 0.634768
tensor(0.0028, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-4.7986e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.298599
Average KL loss: 0.330548
Average total loss: 0.629148
tensor(0.0028, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(1.5074e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.298013
Average KL loss: 0.330089
Average total loss: 0.628102
tensor(0.0028, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(1.1927e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.297159
Average KL loss: 0.328361
Average total loss: 0.625520
tensor(0.0028, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(1.9346e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.301649
Average KL loss: 0.328949
Average total loss: 0.630598
tensor(0.0028, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(2.9860e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.293930
Average KL loss: 0.329248
Average total loss: 0.623178
tensor(0.0028, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-7.4972e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.297508
Average KL loss: 0.329726
Average total loss: 0.627234
tensor(0.0028, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(7.2332e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.292154
Average KL loss: 0.329663
Average total loss: 0.621816
tensor(0.0028, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-9.8832e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.288838
Average KL loss: 0.326402
Average total loss: 0.615240
tensor(0.0028, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(9.7610e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.290600
Average KL loss: 0.318425
Average total loss: 0.609025
tensor(0.0028, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.9599e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.292141
Average KL loss: 0.313005
Average total loss: 0.605146
tensor(0.0028, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(9.2581e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.290836
Average KL loss: 0.308818
Average total loss: 0.599654
tensor(0.0028, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(6.6052e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.293137
Average KL loss: 0.305490
Average total loss: 0.598627
tensor(0.0028, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(4.0514e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.283026
Average KL loss: 0.302650
Average total loss: 0.585675
tensor(0.0028, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(9.0680e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.284778
Average KL loss: 0.300102
Average total loss: 0.584879
tensor(0.0028, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-8.1892e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.287102
Average KL loss: 0.297983
Average total loss: 0.585084
tensor(0.0028, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(4.5576e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.288809
Average KL loss: 0.296085
Average total loss: 0.584895
tensor(0.0028, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(8.1183e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.291512
Average KL loss: 0.294446
Average total loss: 0.585958
tensor(0.0028, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(9.3803e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.282793
Average KL loss: 0.292965
Average total loss: 0.575758
tensor(0.0028, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(5.1931e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.295215
Average KL loss: 0.291574
Average total loss: 0.586789
tensor(0.0028, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-6.6329e-11, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.294314
Average KL loss: 0.290373
Average total loss: 0.584687
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.3549e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.286781
Average KL loss: 0.289301
Average total loss: 0.576082
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.3505e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.287905
Average KL loss: 0.288197
Average total loss: 0.576102
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(8.0787e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.286074
Average KL loss: 0.287199
Average total loss: 0.573273
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.7965e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.286567
Average KL loss: 0.286323
Average total loss: 0.572890
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(1.8758e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.291384
Average KL loss: 0.285479
Average total loss: 0.576863
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.1427e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.295585
Average KL loss: 0.284736
Average total loss: 0.580320
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(2.0256e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.296032
Average KL loss: 0.284066
Average total loss: 0.580098
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-6.4180e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.289872
Average KL loss: 0.283467
Average total loss: 0.573339
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.8097e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.286652
Average KL loss: 0.282855
Average total loss: 0.569508
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-8.5395e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.294225
Average KL loss: 0.282247
Average total loss: 0.576472
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-4.2913e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.298250
Average KL loss: 0.281736
Average total loss: 0.579987
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(5.4981e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.278646
Average KL loss: 0.281169
Average total loss: 0.559815
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.7708e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.291591
Average KL loss: 0.280544
Average total loss: 0.572135
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-7.8053e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.289602
Average KL loss: 0.280072
Average total loss: 0.569674
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(3.2859e-11, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.285409
Average KL loss: 0.279650
Average total loss: 0.565059
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(2.9097e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.294634
Average KL loss: 0.279206
Average total loss: 0.573840
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(2.6851e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.288796
Average KL loss: 0.278812
Average total loss: 0.567607
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.1946e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.285520
Average KL loss: 0.278414
Average total loss: 0.563934
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.8778e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.293172
Average KL loss: 0.277985
Average total loss: 0.571157
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-4.6486e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.284957
Average KL loss: 0.277756
Average total loss: 0.562713
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.5130e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.283545
Average KL loss: 0.277400
Average total loss: 0.560946
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.7937e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.294292
Average KL loss: 0.277152
Average total loss: 0.571444
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(1.7992e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.292915
Average KL loss: 0.276827
Average total loss: 0.569742
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.0977e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.285046
Average KL loss: 0.276641
Average total loss: 0.561687
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.9982e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.293742
Average KL loss: 0.276481
Average total loss: 0.570223
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.9287e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.285356
Average KL loss: 0.276327
Average total loss: 0.561683
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(3.4813e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.284634
Average KL loss: 0.276182
Average total loss: 0.560816
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.9974e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.291537
Average KL loss: 0.276053
Average total loss: 0.567590
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(8.0787e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.287326
Average KL loss: 0.275937
Average total loss: 0.563264
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(1.8546e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.290519
Average KL loss: 0.275818
Average total loss: 0.566337
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(1.8392e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.296425
Average KL loss: 0.275707
Average total loss: 0.572133
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(3.6998e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.285305
Average KL loss: 0.275603
Average total loss: 0.560907
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.0646e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.295414
Average KL loss: 0.275504
Average total loss: 0.570918
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-6.8196e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.297271
Average KL loss: 0.275404
Average total loss: 0.572675
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-3.5768e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.282902
Average KL loss: 0.275352
Average total loss: 0.558254
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.3059e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.293657
Average KL loss: 0.275340
Average total loss: 0.568997
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(2.3404e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.290809
Average KL loss: 0.275329
Average total loss: 0.566137
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(4.3569e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.292237
Average KL loss: 0.275317
Average total loss: 0.567554
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(2.1599e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.280594
Average KL loss: 0.275306
Average total loss: 0.555900
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.6203e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.282698
Average KL loss: 0.275294
Average total loss: 0.557993
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.1225e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.291824
Average KL loss: 0.275283
Average total loss: 0.567108
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(3.6375e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.285956
Average KL loss: 0.275272
Average total loss: 0.561228
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(3.4510e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.290136
Average KL loss: 0.275261
Average total loss: 0.565396
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.1592e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.288310
Average KL loss: 0.275250
Average total loss: 0.563560
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(1.1218e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.279318
Average KL loss: 0.275239
Average total loss: 0.554557
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-8.0569e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.286129
Average KL loss: 0.275227
Average total loss: 0.561356
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(5.2299e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.290021
Average KL loss: 0.275216
Average total loss: 0.565237
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-6.2292e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.293726
Average KL loss: 0.275206
Average total loss: 0.568931
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.0286e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.281964
Average KL loss: 0.275195
Average total loss: 0.557159
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.1614e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.292939
Average KL loss: 0.275183
Average total loss: 0.568123
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-7.1422e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.284859
Average KL loss: 0.275172
Average total loss: 0.560031
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(1.7602e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.280541
Average KL loss: 0.275161
Average total loss: 0.555702
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.3293e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.286065
Average KL loss: 0.275149
Average total loss: 0.561215
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-3.0062e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.281408
Average KL loss: 0.275138
Average total loss: 0.556547
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(9.7071e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.288750
Average KL loss: 0.275127
Average total loss: 0.563878
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-3.6558e-09, device='cuda:0')
 Percentile value: 7.962108838910353e-08
Non-zero model percentage: 32.76801300048828%, Non-zero mask percentage: 32.76801300048828%

--- Pruning Level [5/24]: ---
conv1.weight         | nonzeros =     836 /    1728             ( 48.38%) | total_pruned =     892 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    4102 /   36864             ( 11.13%) | total_pruned =   32762 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4534 /   36864             ( 12.30%) | total_pruned =   32330 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4258 /   36864             ( 11.55%) | total_pruned =   32606 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4130 /   36864             ( 11.20%) | total_pruned =   32734 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    8055 /   73728             ( 10.93%) | total_pruned =   65673 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   14913 /  147456             ( 10.11%) | total_pruned =  132543 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1880 /    8192             ( 22.95%) | total_pruned =    6312 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   16209 /  147456             ( 10.99%) | total_pruned =  131247 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   16033 /  147456             ( 10.87%) | total_pruned =  131423 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   30287 /  294912             ( 10.27%) | total_pruned =  264625 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     122 /     256             ( 47.66%) | total_pruned =     134 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   59509 /  589824             ( 10.09%) | total_pruned =  530315 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     146 /     256             ( 57.03%) | total_pruned =     110 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    5423 /   32768             ( 16.55%) | total_pruned =   27345 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     143 /     256             ( 55.86%) | total_pruned =     113 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  137152 /  589824             ( 23.25%) | total_pruned =  452672 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  134184 /  589824             ( 22.75%) | total_pruned =  455640 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      73 /     256             ( 28.52%) | total_pruned =     183 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  137629 / 1179648             ( 11.67%) | total_pruned = 1042019 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     275 /     512             ( 53.71%) | total_pruned =     237 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  447292 / 2359296             ( 18.96%) | total_pruned = 1912004 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     312 /     512             ( 60.94%) | total_pruned =     200 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   18873 /  131072             ( 14.40%) | total_pruned =  112199 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     417 /     512             ( 81.45%) | total_pruned =      95 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     311 /     512             ( 60.74%) | total_pruned =     201 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1017351 / 2359296             ( 43.12%) | total_pruned = 1341945 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     377 /     512             ( 73.63%) | total_pruned =     135 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     338 /     512             ( 66.02%) | total_pruned =     174 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1586803 / 2359296             ( 67.26%) | total_pruned =  772493 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     481 /     512             ( 93.95%) | total_pruned =      31 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      44 /     512             (  8.59%) | total_pruned =     468 | shape = torch.Size([512])
linear.weight        | nonzeros =    2148 /    5120             ( 41.95%) | total_pruned =    2972 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 3663058, pruned : 7515704, total: 11178762, Compression rate :       3.05x  ( 67.23% pruned)
Train Epoch: 30/100 Loss: 0.000126 Accuracy: 87.02 100.00 % Best test Accuracy: 87.59%
tensor(0.0028, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.5400e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.507909
Average KL loss: 0.281797
Average total loss: 0.789706
tensor(0.0030, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.5095e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.483634
Average KL loss: 0.307238
Average total loss: 0.790872
tensor(0.0031, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.7973e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.455580
Average KL loss: 0.320422
Average total loss: 0.776003
tensor(0.0031, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.7782e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.456337
Average KL loss: 0.328923
Average total loss: 0.785260
tensor(0.0031, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(6.7304e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.429035
Average KL loss: 0.332828
Average total loss: 0.761863
tensor(0.0031, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.0849e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.424231
Average KL loss: 0.336671
Average total loss: 0.760902
tensor(0.0031, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(4.2228e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.418736
Average KL loss: 0.339450
Average total loss: 0.758186
tensor(0.0031, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-7.9995e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.415359
Average KL loss: 0.342010
Average total loss: 0.757369
tensor(0.0031, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(1.9957e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.416517
Average KL loss: 0.343689
Average total loss: 0.760205
tensor(0.0031, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.0401e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.404890
Average KL loss: 0.346300
Average total loss: 0.751190
tensor(0.0031, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.5593e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.404225
Average KL loss: 0.346600
Average total loss: 0.750825
tensor(0.0031, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-7.8998e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.401807
Average KL loss: 0.347736
Average total loss: 0.749543
tensor(0.0031, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.4599e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.394148
Average KL loss: 0.349706
Average total loss: 0.743854
tensor(0.0031, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-9.1867e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.396214
Average KL loss: 0.348735
Average total loss: 0.744949
tensor(0.0031, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(3.1319e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.402174
Average KL loss: 0.349462
Average total loss: 0.751636
tensor(0.0031, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.1469e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.404982
Average KL loss: 0.352620
Average total loss: 0.757602
tensor(0.0031, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-7.8956e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.387465
Average KL loss: 0.352624
Average total loss: 0.740090
tensor(0.0031, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.1266e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.393003
Average KL loss: 0.353384
Average total loss: 0.746387
tensor(0.0031, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.4791e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.397452
Average KL loss: 0.354439
Average total loss: 0.751890
tensor(0.0031, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.3447e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.387363
Average KL loss: 0.355070
Average total loss: 0.742432
tensor(0.0031, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.5465e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.384628
Average KL loss: 0.357012
Average total loss: 0.741640
tensor(0.0031, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(5.7108e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.376426
Average KL loss: 0.355832
Average total loss: 0.732258
tensor(0.0031, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.9444e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.383527
Average KL loss: 0.355599
Average total loss: 0.739126
tensor(0.0031, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-9.4354e-11, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.392863
Average KL loss: 0.357615
Average total loss: 0.750477
tensor(0.0031, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(2.0933e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.389207
Average KL loss: 0.358891
Average total loss: 0.748098
tensor(0.0031, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(3.3681e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.395105
Average KL loss: 0.361079
Average total loss: 0.756184
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(3.0967e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.383985
Average KL loss: 0.361209
Average total loss: 0.745194
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(9.7792e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.382600
Average KL loss: 0.362010
Average total loss: 0.744610
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.7460e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.381663
Average KL loss: 0.361579
Average total loss: 0.743242
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(1.2296e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.377793
Average KL loss: 0.361023
Average total loss: 0.738817
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(6.4548e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.376168
Average KL loss: 0.361756
Average total loss: 0.737925
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.4767e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.373347
Average KL loss: 0.360882
Average total loss: 0.734229
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.4223e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.366146
Average KL loss: 0.360052
Average total loss: 0.726199
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.1364e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.365681
Average KL loss: 0.359826
Average total loss: 0.725507
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(1.1147e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.371217
Average KL loss: 0.359991
Average total loss: 0.731208
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-6.0473e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.374381
Average KL loss: 0.361604
Average total loss: 0.735985
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.9375e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.367085
Average KL loss: 0.361835
Average total loss: 0.728920
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(6.3861e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.370533
Average KL loss: 0.361590
Average total loss: 0.732124
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.2786e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.370977
Average KL loss: 0.363061
Average total loss: 0.734038
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(2.8031e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.368597
Average KL loss: 0.362631
Average total loss: 0.731229
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-3.4793e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.364889
Average KL loss: 0.362893
Average total loss: 0.727782
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-8.0434e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.372089
Average KL loss: 0.364065
Average total loss: 0.736154
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(6.2731e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.375358
Average KL loss: 0.364057
Average total loss: 0.739415
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(2.8034e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.362774
Average KL loss: 0.363827
Average total loss: 0.726601
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(6.0446e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.369378
Average KL loss: 0.365088
Average total loss: 0.734466
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.0407e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.375478
Average KL loss: 0.362311
Average total loss: 0.737789
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-3.3424e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.365475
Average KL loss: 0.356487
Average total loss: 0.721962
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.8892e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.360343
Average KL loss: 0.352134
Average total loss: 0.712477
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.0074e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.370118
Average KL loss: 0.348740
Average total loss: 0.718858
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(3.9623e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.360796
Average KL loss: 0.345886
Average total loss: 0.706682
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-6.7254e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.370615
Average KL loss: 0.343409
Average total loss: 0.714024
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.0725e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.370537
Average KL loss: 0.341337
Average total loss: 0.711874
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.8249e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.374071
Average KL loss: 0.339418
Average total loss: 0.713489
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.2605e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.363408
Average KL loss: 0.337696
Average total loss: 0.701104
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.9397e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.363101
Average KL loss: 0.336063
Average total loss: 0.699164
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.6313e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.365305
Average KL loss: 0.334641
Average total loss: 0.699946
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.1719e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.368447
Average KL loss: 0.333287
Average total loss: 0.701734
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-6.5071e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.361143
Average KL loss: 0.332065
Average total loss: 0.693208
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-6.1481e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.360914
Average KL loss: 0.330872
Average total loss: 0.691786
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-9.4438e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.364848
Average KL loss: 0.329797
Average total loss: 0.694645
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(8.6105e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.361554
Average KL loss: 0.328784
Average total loss: 0.690338
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(1.2168e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.358802
Average KL loss: 0.327928
Average total loss: 0.686730
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0579e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.359278
Average KL loss: 0.327015
Average total loss: 0.686293
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.3743e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.366286
Average KL loss: 0.326158
Average total loss: 0.692444
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-7.5644e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.363890
Average KL loss: 0.325412
Average total loss: 0.689302
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(2.5452e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.364129
Average KL loss: 0.324727
Average total loss: 0.688856
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-7.1318e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.369160
Average KL loss: 0.324026
Average total loss: 0.693187
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(4.1477e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.357511
Average KL loss: 0.323403
Average total loss: 0.680913
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(1.9769e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.357274
Average KL loss: 0.322694
Average total loss: 0.679968
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.1312e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.365619
Average KL loss: 0.322197
Average total loss: 0.687816
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(2.4897e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.358221
Average KL loss: 0.321631
Average total loss: 0.679852
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.9915e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.371301
Average KL loss: 0.321115
Average total loss: 0.692416
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.1334e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.359204
Average KL loss: 0.320668
Average total loss: 0.679872
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-8.1785e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.370670
Average KL loss: 0.320190
Average total loss: 0.690859
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.5272e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.369526
Average KL loss: 0.319790
Average total loss: 0.689317
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(1.8261e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.364067
Average KL loss: 0.319304
Average total loss: 0.683371
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(4.9924e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.363894
Average KL loss: 0.318900
Average total loss: 0.682794
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(1.1529e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.356247
Average KL loss: 0.318547
Average total loss: 0.674794
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(6.2103e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.359998
Average KL loss: 0.318095
Average total loss: 0.678094
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(3.0279e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.359020
Average KL loss: 0.317744
Average total loss: 0.676763
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-8.1905e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.370252
Average KL loss: 0.317374
Average total loss: 0.687626
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-8.4180e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.367437
Average KL loss: 0.317084
Average total loss: 0.684521
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-8.3150e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.361446
Average KL loss: 0.316780
Average total loss: 0.678226
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(1.5089e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.357256
Average KL loss: 0.316471
Average total loss: 0.673727
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0685e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.363125
Average KL loss: 0.316218
Average total loss: 0.679343
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(6.4199e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.365949
Average KL loss: 0.315943
Average total loss: 0.681893
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.9341e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.363128
Average KL loss: 0.315740
Average total loss: 0.678867
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.6522e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.358939
Average KL loss: 0.315411
Average total loss: 0.674349
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(5.4818e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.363129
Average KL loss: 0.315121
Average total loss: 0.678250
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.9112e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.363056
Average KL loss: 0.314895
Average total loss: 0.677951
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.5086e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.371814
Average KL loss: 0.314704
Average total loss: 0.686518
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0055e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.358042
Average KL loss: 0.314500
Average total loss: 0.672542
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(4.3782e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.361179
Average KL loss: 0.314281
Average total loss: 0.675460
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(1.4074e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.368343
Average KL loss: 0.314068
Average total loss: 0.682411
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(2.1592e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.366220
Average KL loss: 0.313867
Average total loss: 0.680087
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.8075e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.359979
Average KL loss: 0.313658
Average total loss: 0.673637
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(1.8683e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.352376
Average KL loss: 0.313488
Average total loss: 0.665865
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.6113e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.351381
Average KL loss: 0.313204
Average total loss: 0.664585
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.1667e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.366780
Average KL loss: 0.313012
Average total loss: 0.679793
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.7504e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.354042
Average KL loss: 0.312869
Average total loss: 0.666911
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-8.0954e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.356078
Average KL loss: 0.312665
Average total loss: 0.668743
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(5.0827e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.367157
Average KL loss: 0.312480
Average total loss: 0.679637
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-8.9000e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.355984
Average KL loss: 0.312299
Average total loss: 0.668283
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(7.7983e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.362186
Average KL loss: 0.312108
Average total loss: 0.674294
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(1.2027e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.361489
Average KL loss: 0.312034
Average total loss: 0.673523
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.7078e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.362737
Average KL loss: 0.311896
Average total loss: 0.674634
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.4189e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.362625
Average KL loss: 0.311756
Average total loss: 0.674381
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.1741e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.355556
Average KL loss: 0.311587
Average total loss: 0.667143
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(9.8031e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.357996
Average KL loss: 0.311423
Average total loss: 0.669419
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.5599e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.349687
Average KL loss: 0.311367
Average total loss: 0.661054
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.8469e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.362510
Average KL loss: 0.311252
Average total loss: 0.673762
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(4.8015e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.358093
Average KL loss: 0.311149
Average total loss: 0.669242
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(2.8177e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.358804
Average KL loss: 0.311056
Average total loss: 0.669860
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.1371e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.366958
Average KL loss: 0.310969
Average total loss: 0.677927
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(9.7980e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.364475
Average KL loss: 0.310894
Average total loss: 0.675369
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(6.8141e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.367401
Average KL loss: 0.310821
Average total loss: 0.678222
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(4.9822e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.364214
Average KL loss: 0.310747
Average total loss: 0.674961
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(6.0286e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.369624
Average KL loss: 0.310670
Average total loss: 0.680293
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(2.3020e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.364983
Average KL loss: 0.310605
Average total loss: 0.675588
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.6212e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.355752
Average KL loss: 0.310544
Average total loss: 0.666296
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.4207e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.354715
Average KL loss: 0.310482
Average total loss: 0.665197
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(9.7436e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.365701
Average KL loss: 0.310445
Average total loss: 0.676146
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.4064e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.358568
Average KL loss: 0.310438
Average total loss: 0.669006
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.2415e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.363504
Average KL loss: 0.310430
Average total loss: 0.673934
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.3770e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.357395
Average KL loss: 0.310423
Average total loss: 0.667818
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(7.1680e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.368166
Average KL loss: 0.310415
Average total loss: 0.678582
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(6.8956e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.352382
Average KL loss: 0.310408
Average total loss: 0.662790
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(3.3335e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.361042
Average KL loss: 0.310400
Average total loss: 0.671442
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(1.6346e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.360790
Average KL loss: 0.310393
Average total loss: 0.671183
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(3.6930e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.358914
Average KL loss: 0.310386
Average total loss: 0.669300
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(4.2588e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.360370
Average KL loss: 0.310379
Average total loss: 0.670749
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(8.5781e-10, device='cuda:0')
 Percentile value: 7.966732340491944e-08
Non-zero model percentage: 26.214414596557617%, Non-zero mask percentage: 26.214414596557617%

--- Pruning Level [6/24]: ---
conv1.weight         | nonzeros =     784 /    1728             ( 45.37%) | total_pruned =     944 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    3071 /   36864             (  8.33%) | total_pruned =   33793 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    3505 /   36864             (  9.51%) | total_pruned =   33359 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3258 /   36864             (  8.84%) | total_pruned =   33606 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3136 /   36864             (  8.51%) | total_pruned =   33728 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    6014 /   73728             (  8.16%) | total_pruned =   67714 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   10611 /  147456             (  7.20%) | total_pruned =  136845 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1612 /    8192             ( 19.68%) | total_pruned =    6580 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   11331 /  147456             (  7.68%) | total_pruned =  136125 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      34 /     128             ( 26.56%) | total_pruned =      94 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   11518 /  147456             (  7.81%) | total_pruned =  135938 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   21260 /  294912             (  7.21%) | total_pruned =  273652 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      99 /     256             ( 38.67%) | total_pruned =     157 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   39931 /  589824             (  6.77%) | total_pruned =  549893 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     116 /     256             ( 45.31%) | total_pruned =     140 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4346 /   32768             ( 13.26%) | total_pruned =   28422 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     114 /     256             ( 44.53%) | total_pruned =     142 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  114485 /  589824             ( 19.41%) | total_pruned =  475339 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      89 /     256             ( 34.77%) | total_pruned =     167 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  112207 /  589824             ( 19.02%) | total_pruned =  477617 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      44 /     256             ( 17.19%) | total_pruned =     212 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   92693 / 1179648             (  7.86%) | total_pruned = 1086955 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     237 /     512             ( 46.29%) | total_pruned =     275 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  298728 / 2359296             ( 12.66%) | total_pruned = 2060568 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     294 /     512             ( 57.42%) | total_pruned =     218 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   15213 /  131072             ( 11.61%) | total_pruned =  115859 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     394 /     512             ( 76.95%) | total_pruned =     118 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     293 /     512             ( 57.23%) | total_pruned =     219 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  838680 / 2359296             ( 35.55%) | total_pruned = 1520616 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     370 /     512             ( 72.27%) | total_pruned =     142 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     312 /     512             ( 60.94%) | total_pruned =     200 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1325268 / 2359296             ( 56.17%) | total_pruned = 1034028 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     422 /     512             ( 82.42%) | total_pruned =      90 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
linear.weight        | nonzeros =    1745 /    5120             ( 34.08%) | total_pruned =    3375 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 2930447, pruned : 8248315, total: 11178762, Compression rate :       3.81x  ( 73.79% pruned)
Train Epoch: 29/100 Loss: 0.000042 Accuracy: 86.82 100.00 % Best test Accuracy: 87.22%
tensor(0.0031, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.9900e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.562181
Average KL loss: 0.307505
Average total loss: 0.869686
tensor(0.0032, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.1504e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.547164
Average KL loss: 0.327147
Average total loss: 0.874311
tensor(0.0033, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.2997e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.536176
Average KL loss: 0.341729
Average total loss: 0.877905
tensor(0.0033, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-6.8222e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.502845
Average KL loss: 0.350534
Average total loss: 0.853379
tensor(0.0033, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.5437e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.523906
Average KL loss: 0.356462
Average total loss: 0.880369
tensor(0.0033, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-7.7146e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.487488
Average KL loss: 0.361961
Average total loss: 0.849449
tensor(0.0033, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-6.9784e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.497740
Average KL loss: 0.364111
Average total loss: 0.861851
tensor(0.0033, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.9837e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.489128
Average KL loss: 0.368494
Average total loss: 0.857621
tensor(0.0034, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.9425e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.491073
Average KL loss: 0.371720
Average total loss: 0.862793
tensor(0.0034, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.8943e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.473065
Average KL loss: 0.373404
Average total loss: 0.846469
tensor(0.0034, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.9852e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.477210
Average KL loss: 0.375252
Average total loss: 0.852462
tensor(0.0034, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(4.7883e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.483568
Average KL loss: 0.378165
Average total loss: 0.861733
tensor(0.0034, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-8.1651e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.462606
Average KL loss: 0.378749
Average total loss: 0.841355
tensor(0.0034, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(8.2356e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.470953
Average KL loss: 0.378476
Average total loss: 0.849429
tensor(0.0034, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-9.3364e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.461175
Average KL loss: 0.379083
Average total loss: 0.840258
tensor(0.0034, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-5.2032e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.459299
Average KL loss: 0.379582
Average total loss: 0.838882
tensor(0.0034, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.0808e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.465501
Average KL loss: 0.381405
Average total loss: 0.846906
tensor(0.0034, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.1986e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.463486
Average KL loss: 0.381987
Average total loss: 0.845473
tensor(0.0034, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(2.4126e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.464005
Average KL loss: 0.382064
Average total loss: 0.846069
tensor(0.0034, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.8610e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.464367
Average KL loss: 0.384035
Average total loss: 0.848402
tensor(0.0034, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.0951e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.464627
Average KL loss: 0.385652
Average total loss: 0.850279
tensor(0.0034, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.9688e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.454266
Average KL loss: 0.385978
Average total loss: 0.840244
tensor(0.0034, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(5.8946e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.451451
Average KL loss: 0.386857
Average total loss: 0.838307
tensor(0.0034, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(5.1686e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.455064
Average KL loss: 0.386809
Average total loss: 0.841873
tensor(0.0034, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-3.1336e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.457061
Average KL loss: 0.387556
Average total loss: 0.844617
tensor(0.0034, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.9290e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.441455
Average KL loss: 0.388937
Average total loss: 0.830392
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(2.8903e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.466875
Average KL loss: 0.388443
Average total loss: 0.855319
tensor(0.0033, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.3779e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.452605
Average KL loss: 0.389541
Average total loss: 0.842146
tensor(0.0034, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(7.2011e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.437193
Average KL loss: 0.390206
Average total loss: 0.827399
tensor(0.0034, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-3.7798e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.449691
Average KL loss: 0.388958
Average total loss: 0.838648
tensor(0.0033, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.0973e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.435706
Average KL loss: 0.389124
Average total loss: 0.824830
tensor(0.0033, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(1.8156e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.451691
Average KL loss: 0.389747
Average total loss: 0.841438
tensor(0.0033, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-4.2787e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.441784
Average KL loss: 0.390072
Average total loss: 0.831855
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(5.4966e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.444808
Average KL loss: 0.390548
Average total loss: 0.835356
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-4.8814e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.435010
Average KL loss: 0.390918
Average total loss: 0.825927
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.3024e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.427375
Average KL loss: 0.390626
Average total loss: 0.818001
tensor(0.0033, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-6.8271e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.448016
Average KL loss: 0.391528
Average total loss: 0.839544
tensor(0.0033, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-2.9629e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.444275
Average KL loss: 0.392202
Average total loss: 0.836477
tensor(0.0033, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-5.0027e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.453172
Average KL loss: 0.393377
Average total loss: 0.846550
tensor(0.0034, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(8.6696e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.437964
Average KL loss: 0.394064
Average total loss: 0.832028
tensor(0.0034, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.1598e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.444234
Average KL loss: 0.393518
Average total loss: 0.837751
tensor(0.0034, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.9023e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.433550
Average KL loss: 0.393896
Average total loss: 0.827446
tensor(0.0034, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-8.4789e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.440754
Average KL loss: 0.394552
Average total loss: 0.835306
tensor(0.0034, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-4.8586e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.435200
Average KL loss: 0.395358
Average total loss: 0.830558
tensor(0.0034, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(1.3228e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.429100
Average KL loss: 0.394077
Average total loss: 0.823177
tensor(0.0034, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-8.8307e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.441782
Average KL loss: 0.394870
Average total loss: 0.836651
tensor(0.0034, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.5803e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.433350
Average KL loss: 0.395578
Average total loss: 0.828928
tensor(0.0034, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-9.6657e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.433490
Average KL loss: 0.393349
Average total loss: 0.826840
tensor(0.0034, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(4.2116e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.429171
Average KL loss: 0.389181
Average total loss: 0.818352
tensor(0.0034, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-6.2349e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.439439
Average KL loss: 0.385988
Average total loss: 0.825427
tensor(0.0034, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.3768e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.420414
Average KL loss: 0.383295
Average total loss: 0.803709
tensor(0.0034, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.2591e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.430118
Average KL loss: 0.380925
Average total loss: 0.811043
tensor(0.0034, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(6.5308e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.427600
Average KL loss: 0.378873
Average total loss: 0.806473
tensor(0.0034, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.0642e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.433851
Average KL loss: 0.377024
Average total loss: 0.810875
tensor(0.0034, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-7.2580e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.422859
Average KL loss: 0.375382
Average total loss: 0.798241
tensor(0.0034, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.6943e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.411519
Average KL loss: 0.373798
Average total loss: 0.785316
tensor(0.0034, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-9.2588e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.423998
Average KL loss: 0.372273
Average total loss: 0.796271
tensor(0.0034, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.5249e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.433412
Average KL loss: 0.370965
Average total loss: 0.804377
tensor(0.0034, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(3.0547e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.438598
Average KL loss: 0.369884
Average total loss: 0.808482
tensor(0.0034, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(3.0604e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.429538
Average KL loss: 0.368819
Average total loss: 0.798356
tensor(0.0034, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.5622e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.431422
Average KL loss: 0.367782
Average total loss: 0.799203
tensor(0.0034, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.1922e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.446225
Average KL loss: 0.366855
Average total loss: 0.813080
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(5.5572e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.426247
Average KL loss: 0.365967
Average total loss: 0.792214
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.1154e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.435720
Average KL loss: 0.365115
Average total loss: 0.800835
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.7602e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.419257
Average KL loss: 0.364329
Average total loss: 0.783586
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(4.4812e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.435038
Average KL loss: 0.363434
Average total loss: 0.798472
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-4.7161e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.424234
Average KL loss: 0.362724
Average total loss: 0.786957
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.7050e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.424240
Average KL loss: 0.361970
Average total loss: 0.786210
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.8197e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.419785
Average KL loss: 0.361318
Average total loss: 0.781103
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(5.4400e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.427692
Average KL loss: 0.360656
Average total loss: 0.788347
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-7.0130e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.422434
Average KL loss: 0.360019
Average total loss: 0.782453
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.1759e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.414404
Average KL loss: 0.359389
Average total loss: 0.773794
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.5234e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.440890
Average KL loss: 0.358827
Average total loss: 0.799717
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-8.5349e-11, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.431600
Average KL loss: 0.358352
Average total loss: 0.789952
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(6.9311e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.435463
Average KL loss: 0.357827
Average total loss: 0.793290
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(3.8719e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.429387
Average KL loss: 0.357335
Average total loss: 0.786722
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.3404e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.418521
Average KL loss: 0.356886
Average total loss: 0.775407
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.2772e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.434329
Average KL loss: 0.356420
Average total loss: 0.790749
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-2.9332e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.428526
Average KL loss: 0.356087
Average total loss: 0.784613
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.8841e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.427813
Average KL loss: 0.355733
Average total loss: 0.783546
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(4.7760e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.431595
Average KL loss: 0.355351
Average total loss: 0.786946
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(4.8508e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.426341
Average KL loss: 0.354986
Average total loss: 0.781327
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.9611e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.422996
Average KL loss: 0.354584
Average total loss: 0.777580
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(8.2907e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.421357
Average KL loss: 0.354321
Average total loss: 0.775677
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.0369e-11, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.420193
Average KL loss: 0.354222
Average total loss: 0.774415
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(5.5922e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.417016
Average KL loss: 0.354126
Average total loss: 0.771142
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-7.3364e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.436188
Average KL loss: 0.354036
Average total loss: 0.790224
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.0338e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.427077
Average KL loss: 0.353949
Average total loss: 0.781026
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.2208e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.419736
Average KL loss: 0.353863
Average total loss: 0.773599
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(8.4297e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.426167
Average KL loss: 0.353782
Average total loss: 0.779949
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-4.9222e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.421575
Average KL loss: 0.353699
Average total loss: 0.775273
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(3.5180e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.425353
Average KL loss: 0.353614
Average total loss: 0.778968
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(4.7914e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.413331
Average KL loss: 0.353531
Average total loss: 0.766863
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(6.0718e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.422266
Average KL loss: 0.353452
Average total loss: 0.775718
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.2735e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.425129
Average KL loss: 0.353367
Average total loss: 0.778496
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-6.4512e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.434188
Average KL loss: 0.353294
Average total loss: 0.787482
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-8.3776e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.432782
Average KL loss: 0.353226
Average total loss: 0.786007
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.0489e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.438573
Average KL loss: 0.353158
Average total loss: 0.791731
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-9.7561e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.430124
Average KL loss: 0.353097
Average total loss: 0.783220
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(5.1013e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.408302
Average KL loss: 0.353024
Average total loss: 0.761325
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(4.4463e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.424297
Average KL loss: 0.352946
Average total loss: 0.777243
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(9.1057e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.422475
Average KL loss: 0.352877
Average total loss: 0.775352
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(4.9853e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.422481
Average KL loss: 0.352805
Average total loss: 0.775286
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.2325e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.433034
Average KL loss: 0.352741
Average total loss: 0.785775
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(5.1450e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.426185
Average KL loss: 0.352682
Average total loss: 0.778867
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(5.6456e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.428532
Average KL loss: 0.352620
Average total loss: 0.781153
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.4642e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.425277
Average KL loss: 0.352554
Average total loss: 0.777832
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(8.8569e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.436387
Average KL loss: 0.352492
Average total loss: 0.788879
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.6202e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.413398
Average KL loss: 0.352429
Average total loss: 0.765827
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-8.5073e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.423104
Average KL loss: 0.352364
Average total loss: 0.775468
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-7.6115e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.428353
Average KL loss: 0.352301
Average total loss: 0.780654
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(2.8968e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.419133
Average KL loss: 0.352268
Average total loss: 0.771401
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.3917e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.421028
Average KL loss: 0.352261
Average total loss: 0.773289
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(7.2405e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.423655
Average KL loss: 0.352253
Average total loss: 0.775908
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(2.1563e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.415478
Average KL loss: 0.352246
Average total loss: 0.767724
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-6.5271e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.421965
Average KL loss: 0.352239
Average total loss: 0.774204
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-7.5243e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.425809
Average KL loss: 0.352232
Average total loss: 0.778041
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.1860e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.431611
Average KL loss: 0.352225
Average total loss: 0.783836
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.2872e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.416936
Average KL loss: 0.352219
Average total loss: 0.769155
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-8.0302e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.433516
Average KL loss: 0.352212
Average total loss: 0.785728
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.0593e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.430916
Average KL loss: 0.352205
Average total loss: 0.783122
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-2.2737e-09, device='cuda:0')
 Percentile value: 8.017639174795477e-08
Non-zero model percentage: 20.971534729003906%, Non-zero mask percentage: 20.971534729003906%

--- Pruning Level [7/24]: ---
conv1.weight         | nonzeros =     734 /    1728             ( 42.48%) | total_pruned =     994 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2374 /   36864             (  6.44%) | total_pruned =   34490 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2796 /   36864             (  7.58%) | total_pruned =   34068 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2527 /   36864             (  6.85%) | total_pruned =   34337 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2459 /   36864             (  6.67%) | total_pruned =   34405 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4590 /   73728             (  6.23%) | total_pruned =   69138 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    7775 /  147456             (  5.27%) | total_pruned =  139681 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1416 /    8192             ( 17.29%) | total_pruned =    6776 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8434 /  147456             (  5.72%) | total_pruned =  139022 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    8769 /  147456             (  5.95%) | total_pruned =  138687 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   15438 /  294912             (  5.23%) | total_pruned =  279474 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      80 /     256             ( 31.25%) | total_pruned =     176 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   27593 /  589824             (  4.68%) | total_pruned =  562231 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      94 /     256             ( 36.72%) | total_pruned =     162 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3563 /   32768             ( 10.87%) | total_pruned =   29205 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      93 /     256             ( 36.33%) | total_pruned =     163 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  100619 /  589824             ( 17.06%) | total_pruned =  489205 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      73 /     256             ( 28.52%) | total_pruned =     183 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   98420 /  589824             ( 16.69%) | total_pruned =  491404 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      28 /     256             ( 10.94%) | total_pruned =     228 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   64478 / 1179648             (  5.47%) | total_pruned = 1115170 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     196 /     512             ( 38.28%) | total_pruned =     316 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  203832 / 2359296             (  8.64%) | total_pruned = 2155464 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     490 /     512             ( 95.70%) | total_pruned =      22 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     279 /     512             ( 54.49%) | total_pruned =     233 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   12756 /  131072             (  9.73%) | total_pruned =  118316 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     361 /     512             ( 70.51%) | total_pruned =     151 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     275 /     512             ( 53.71%) | total_pruned =     237 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  715133 / 2359296             ( 30.31%) | total_pruned = 1644163 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     362 /     512             ( 70.70%) | total_pruned =     150 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     287 /     512             ( 56.05%) | total_pruned =     225 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1048672 / 2359296             ( 44.45%) | total_pruned = 1310624 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     315 /     512             ( 61.52%) | total_pruned =     197 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
linear.weight        | nonzeros =    1337 /    5120             ( 26.11%) | total_pruned =    3783 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 2344358, pruned : 8834404, total: 11178762, Compression rate :       4.77x  ( 79.03% pruned)
Train Epoch: 28/100 Loss: 0.000106 Accuracy: 86.66 100.00 % Best test Accuracy: 87.13%
tensor(0.0034, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-7.7180e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.744432
Average KL loss: 0.342673
Average total loss: 1.087105
tensor(0.0036, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-6.6737e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.692255
Average KL loss: 0.360269
Average total loss: 1.052524
tensor(0.0036, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-3.2318e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.691122
Average KL loss: 0.375803
Average total loss: 1.066924
tensor(0.0037, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.6320e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.654826
Average KL loss: 0.388318
Average total loss: 1.043143
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.9713e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.626840
Average KL loss: 0.397151
Average total loss: 1.023991
tensor(0.0037, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-7.3693e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.628951
Average KL loss: 0.404004
Average total loss: 1.032955
tensor(0.0037, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.9333e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.626553
Average KL loss: 0.409678
Average total loss: 1.036231
tensor(0.0037, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.7025e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.609771
Average KL loss: 0.414461
Average total loss: 1.024232
tensor(0.0037, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-2.4641e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.624172
Average KL loss: 0.419240
Average total loss: 1.043412
tensor(0.0038, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.2744e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.585859
Average KL loss: 0.422855
Average total loss: 1.008714
tensor(0.0038, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.4697e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.587230
Average KL loss: 0.424966
Average total loss: 1.012196
tensor(0.0038, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(1.1651e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.584716
Average KL loss: 0.426884
Average total loss: 1.011600
tensor(0.0038, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.5667e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.572680
Average KL loss: 0.428049
Average total loss: 1.000729
tensor(0.0038, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.6535e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.572577
Average KL loss: 0.430191
Average total loss: 1.002768
tensor(0.0038, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.4041e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.573535
Average KL loss: 0.433002
Average total loss: 1.006537
tensor(0.0038, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(8.8516e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.577285
Average KL loss: 0.434118
Average total loss: 1.011403
tensor(0.0038, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.1920e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.577320
Average KL loss: 0.435875
Average total loss: 1.013196
tensor(0.0038, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(1.8817e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.558452
Average KL loss: 0.437326
Average total loss: 0.995778
tensor(0.0038, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(6.0045e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.575569
Average KL loss: 0.438821
Average total loss: 1.014390
tensor(0.0038, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.9489e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.555038
Average KL loss: 0.440281
Average total loss: 0.995318
tensor(0.0038, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(7.4833e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.560321
Average KL loss: 0.440879
Average total loss: 1.001199
tensor(0.0038, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.6739e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.549856
Average KL loss: 0.442042
Average total loss: 0.991898
tensor(0.0038, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.4149e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.549576
Average KL loss: 0.441433
Average total loss: 0.991008
tensor(0.0037, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5039e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.552973
Average KL loss: 0.441313
Average total loss: 0.994286
tensor(0.0037, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.0631e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.558501
Average KL loss: 0.442597
Average total loss: 1.001098
tensor(0.0037, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.1482e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.551721
Average KL loss: 0.444441
Average total loss: 0.996162
tensor(0.0038, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(1.6995e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.548852
Average KL loss: 0.445425
Average total loss: 0.994278
tensor(0.0038, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.1225e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.541439
Average KL loss: 0.445694
Average total loss: 0.987133
tensor(0.0037, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.1755e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.542610
Average KL loss: 0.446340
Average total loss: 0.988950
tensor(0.0038, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(1.2702e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.523378
Average KL loss: 0.446366
Average total loss: 0.969744
tensor(0.0037, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.0007e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.542636
Average KL loss: 0.445633
Average total loss: 0.988268
tensor(0.0038, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.5924e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.544717
Average KL loss: 0.446811
Average total loss: 0.991528
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.6183e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.542607
Average KL loss: 0.447345
Average total loss: 0.989953
tensor(0.0038, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.7033e-11, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.541833
Average KL loss: 0.448785
Average total loss: 0.990617
tensor(0.0038, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.0677e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.544978
Average KL loss: 0.449372
Average total loss: 0.994350
tensor(0.0038, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(5.2676e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.537807
Average KL loss: 0.450120
Average total loss: 0.987928
tensor(0.0038, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(8.8394e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.524759
Average KL loss: 0.450042
Average total loss: 0.974801
tensor(0.0038, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.5700e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.538143
Average KL loss: 0.449979
Average total loss: 0.988122
tensor(0.0038, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-9.2054e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.551369
Average KL loss: 0.451670
Average total loss: 1.003039
tensor(0.0038, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-9.3755e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.526166
Average KL loss: 0.451857
Average total loss: 0.978023
tensor(0.0038, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(1.2947e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.522021
Average KL loss: 0.450710
Average total loss: 0.972731
tensor(0.0038, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.5936e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.530034
Average KL loss: 0.450171
Average total loss: 0.980205
tensor(0.0038, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.5268e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.541574
Average KL loss: 0.447848
Average total loss: 0.989422
tensor(0.0038, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.6430e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.527414
Average KL loss: 0.445805
Average total loss: 0.973218
tensor(0.0038, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(8.6616e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.516230
Average KL loss: 0.443892
Average total loss: 0.960122
tensor(0.0038, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(9.7824e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.523916
Average KL loss: 0.442196
Average total loss: 0.966112
tensor(0.0038, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.9528e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.519680
Average KL loss: 0.440675
Average total loss: 0.960354
tensor(0.0038, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.3177e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.532126
Average KL loss: 0.439308
Average total loss: 0.971434
tensor(0.0038, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-9.7575e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.514956
Average KL loss: 0.438075
Average total loss: 0.953031
tensor(0.0038, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.8402e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.516502
Average KL loss: 0.436842
Average total loss: 0.953344
tensor(0.0038, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.5864e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.532882
Average KL loss: 0.435684
Average total loss: 0.968566
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.0117e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.523066
Average KL loss: 0.434625
Average total loss: 0.957691
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(3.3260e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.535453
Average KL loss: 0.433582
Average total loss: 0.969034
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.0722e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.520458
Average KL loss: 0.432619
Average total loss: 0.953077
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.2308e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.523837
Average KL loss: 0.431714
Average total loss: 0.955551
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.6690e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.529022
Average KL loss: 0.430834
Average total loss: 0.959856
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.1452e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.527522
Average KL loss: 0.430060
Average total loss: 0.957583
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.6887e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.521658
Average KL loss: 0.429320
Average total loss: 0.950978
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(1.8110e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.533263
Average KL loss: 0.428636
Average total loss: 0.961899
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(7.0790e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.521292
Average KL loss: 0.427972
Average total loss: 0.949264
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.1718e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.518270
Average KL loss: 0.427118
Average total loss: 0.945388
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(1.6652e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.517964
Average KL loss: 0.426383
Average total loss: 0.944347
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.0602e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.507154
Average KL loss: 0.425793
Average total loss: 0.932947
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(8.1821e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.536396
Average KL loss: 0.425141
Average total loss: 0.961537
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.1456e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.524961
Average KL loss: 0.424612
Average total loss: 0.949573
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.1623e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.517853
Average KL loss: 0.424040
Average total loss: 0.941893
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.0689e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.515411
Average KL loss: 0.423496
Average total loss: 0.938907
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.4921e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.510747
Average KL loss: 0.422897
Average total loss: 0.933643
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(3.5314e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.518615
Average KL loss: 0.422392
Average total loss: 0.941007
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(7.1484e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.506531
Average KL loss: 0.421778
Average total loss: 0.928310
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.4086e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.515566
Average KL loss: 0.421253
Average total loss: 0.936820
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.5762e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.520826
Average KL loss: 0.420773
Average total loss: 0.941600
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.1020e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.519488
Average KL loss: 0.420303
Average total loss: 0.939791
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(6.1704e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.522248
Average KL loss: 0.419843
Average total loss: 0.942091
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.4316e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.517766
Average KL loss: 0.419444
Average total loss: 0.937209
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.4296e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.513275
Average KL loss: 0.419044
Average total loss: 0.932319
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(8.2747e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.514588
Average KL loss: 0.418592
Average total loss: 0.933180
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(5.7024e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.527453
Average KL loss: 0.418125
Average total loss: 0.945578
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.2800e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.511217
Average KL loss: 0.417738
Average total loss: 0.928954
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.1343e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.522032
Average KL loss: 0.417369
Average total loss: 0.939401
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.9567e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.521426
Average KL loss: 0.417013
Average total loss: 0.938439
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(5.1678e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.523523
Average KL loss: 0.416827
Average total loss: 0.940350
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.0726e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.529215
Average KL loss: 0.416765
Average total loss: 0.945980
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.5597e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.518288
Average KL loss: 0.416703
Average total loss: 0.934992
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.3778e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.519665
Average KL loss: 0.416634
Average total loss: 0.936300
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.6689e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.519070
Average KL loss: 0.416574
Average total loss: 0.935644
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.4377e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.524706
Average KL loss: 0.416516
Average total loss: 0.941221
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.5544e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.510748
Average KL loss: 0.416456
Average total loss: 0.927204
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(5.0712e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.525428
Average KL loss: 0.416391
Average total loss: 0.941820
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.5385e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.515012
Average KL loss: 0.416329
Average total loss: 0.931342
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.2454e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.508780
Average KL loss: 0.416273
Average total loss: 0.925053
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.2339e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.516789
Average KL loss: 0.416209
Average total loss: 0.932998
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(6.7207e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.515448
Average KL loss: 0.416152
Average total loss: 0.931600
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.7858e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.507960
Average KL loss: 0.416095
Average total loss: 0.924055
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.7434e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.505585
Average KL loss: 0.416031
Average total loss: 0.921615
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.1796e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.527221
Average KL loss: 0.415973
Average total loss: 0.943194
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.9920e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.532358
Average KL loss: 0.415921
Average total loss: 0.948279
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.7516e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.509192
Average KL loss: 0.415865
Average total loss: 0.925057
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.2010e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.508226
Average KL loss: 0.415811
Average total loss: 0.924037
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(2.7744e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.534850
Average KL loss: 0.415763
Average total loss: 0.950613
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.4622e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.514180
Average KL loss: 0.415706
Average total loss: 0.929886
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.7917e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.512265
Average KL loss: 0.415646
Average total loss: 0.927911
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(2.9563e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.515289
Average KL loss: 0.415598
Average total loss: 0.930887
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.8710e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.524247
Average KL loss: 0.415546
Average total loss: 0.939792
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.1996e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.525492
Average KL loss: 0.415502
Average total loss: 0.940994
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(3.9683e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.514440
Average KL loss: 0.415452
Average total loss: 0.929892
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(6.6506e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.511969
Average KL loss: 0.415423
Average total loss: 0.927392
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.3377e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.512337
Average KL loss: 0.415417
Average total loss: 0.927754
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(5.7332e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.505585
Average KL loss: 0.415411
Average total loss: 0.920996
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.3995e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.524896
Average KL loss: 0.415404
Average total loss: 0.940300
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(4.9960e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.520256
Average KL loss: 0.415399
Average total loss: 0.935654
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(5.6011e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.507351
Average KL loss: 0.415393
Average total loss: 0.922744
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.5715e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.517702
Average KL loss: 0.415387
Average total loss: 0.933089
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.2145e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.519118
Average KL loss: 0.415382
Average total loss: 0.934500
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.3116e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.515786
Average KL loss: 0.415376
Average total loss: 0.931162
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(8.2582e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.505390
Average KL loss: 0.415368
Average total loss: 0.920759
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(8.4666e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.523458
Average KL loss: 0.415362
Average total loss: 0.938821
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.5348e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.514110
Average KL loss: 0.415358
Average total loss: 0.929467
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.4527e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.525501
Average KL loss: 0.415352
Average total loss: 0.940853
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.2306e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.517750
Average KL loss: 0.415347
Average total loss: 0.933097
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.8003e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.504703
Average KL loss: 0.415341
Average total loss: 0.920044
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(3.8077e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.515069
Average KL loss: 0.415335
Average total loss: 0.930404
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.1616e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.525350
Average KL loss: 0.415330
Average total loss: 0.940679
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.1310e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.523220
Average KL loss: 0.415324
Average total loss: 0.938544
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(9.0643e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.515541
Average KL loss: 0.415318
Average total loss: 0.930859
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(5.4948e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.514543
Average KL loss: 0.415313
Average total loss: 0.929856
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.5173e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.528961
Average KL loss: 0.415307
Average total loss: 0.944268
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.7583e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.525300
Average KL loss: 0.415301
Average total loss: 0.940602
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(7.0184e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.512599
Average KL loss: 0.415295
Average total loss: 0.927895
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(6.2338e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.515446
Average KL loss: 0.415289
Average total loss: 0.930735
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.7694e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.508093
Average KL loss: 0.415283
Average total loss: 0.923375
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.9947e-09, device='cuda:0')
 Percentile value: 8.075493695969271e-08
Non-zero model percentage: 16.777233123779297%, Non-zero mask percentage: 16.777233123779297%

--- Pruning Level [8/24]: ---
conv1.weight         | nonzeros =     701 /    1728             ( 40.57%) | total_pruned =    1027 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1912 /   36864             (  5.19%) | total_pruned =   34952 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2310 /   36864             (  6.27%) | total_pruned =   34554 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2046 /   36864             (  5.55%) | total_pruned =   34818 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2013 /   36864             (  5.46%) | total_pruned =   34851 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3677 /   73728             (  4.99%) | total_pruned =   70051 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    6049 /  147456             (  4.10%) | total_pruned =  141407 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1250 /    8192             ( 15.26%) | total_pruned =    6942 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    6235 /  147456             (  4.23%) | total_pruned =  141221 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    6566 /  147456             (  4.45%) | total_pruned =  140890 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   11740 /  294912             (  3.98%) | total_pruned =  283172 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      55 /     256             ( 21.48%) | total_pruned =     201 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   20118 /  589824             (  3.41%) | total_pruned =  569706 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      49 /     256             ( 19.14%) | total_pruned =     207 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2968 /   32768             (  9.06%) | total_pruned =   29800 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      39 /     256             ( 15.23%) | total_pruned =     217 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      79 /     256             ( 30.86%) | total_pruned =     177 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   79658 /  589824             ( 13.51%) | total_pruned =  510166 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     117 /     256             ( 45.70%) | total_pruned =     139 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     201 /     256             ( 78.52%) | total_pruned =      55 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      60 /     256             ( 23.44%) | total_pruned =     196 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   78194 /  589824             ( 13.26%) | total_pruned =  511630 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   46382 / 1179648             (  3.93%) | total_pruned = 1133266 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     224 /     512             ( 43.75%) | total_pruned =     288 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     163 /     512             ( 31.84%) | total_pruned =     349 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  140400 / 2359296             (  5.95%) | total_pruned = 2218896 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     226 /     512             ( 44.14%) | total_pruned =     286 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     250 /     512             ( 48.83%) | total_pruned =     262 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   10129 /  131072             (  7.73%) | total_pruned =  120943 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     185 /     512             ( 36.13%) | total_pruned =     327 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     329 /     512             ( 64.26%) | total_pruned =     183 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     250 /     512             ( 48.83%) | total_pruned =     262 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  556078 / 2359296             ( 23.57%) | total_pruned = 1803218 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     348 /     512             ( 67.97%) | total_pruned =     164 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     354 /     512             ( 69.14%) | total_pruned =     158 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     257 /     512             ( 50.20%) | total_pruned =     255 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  888658 / 2359296             ( 37.67%) | total_pruned = 1470638 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     322 /     512             ( 62.89%) | total_pruned =     190 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     230 /     512             ( 44.92%) | total_pruned =     282 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
linear.weight        | nonzeros =    1057 /    5120             ( 20.64%) | total_pruned =    4063 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 1875487, pruned : 9303275, total: 11178762, Compression rate :       5.96x  ( 83.22% pruned)
Train Epoch: 25/100 Loss: 0.000567 Accuracy: 86.36 100.00 % Best test Accuracy: 86.70%
tensor(0.0037, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.8394e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.867874
Average KL loss: 0.395564
Average total loss: 1.263438
tensor(0.0040, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-6.7135e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.872378
Average KL loss: 0.408071
Average total loss: 1.280449
tensor(0.0040, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.8289e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.802242
Average KL loss: 0.421782
Average total loss: 1.224024
tensor(0.0040, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-8.7042e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.813078
Average KL loss: 0.433815
Average total loss: 1.246894
tensor(0.0041, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.5861e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.755032
Average KL loss: 0.444376
Average total loss: 1.199408
tensor(0.0041, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(5.2610e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.758471
Average KL loss: 0.451020
Average total loss: 1.209490
tensor(0.0041, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.9791e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.755423
Average KL loss: 0.458733
Average total loss: 1.214157
tensor(0.0041, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.5688e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.745305
Average KL loss: 0.464961
Average total loss: 1.210267
tensor(0.0041, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.1219e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.714950
Average KL loss: 0.470649
Average total loss: 1.185599
tensor(0.0041, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.9197e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.711657
Average KL loss: 0.474801
Average total loss: 1.186458
tensor(0.0041, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.1599e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.709825
Average KL loss: 0.478522
Average total loss: 1.188348
tensor(0.0041, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(1.0956e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.696814
Average KL loss: 0.481559
Average total loss: 1.178373
tensor(0.0041, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.8073e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.702923
Average KL loss: 0.484665
Average total loss: 1.187588
tensor(0.0041, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.9195e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.669231
Average KL loss: 0.487403
Average total loss: 1.156634
tensor(0.0041, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.8255e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.698057
Average KL loss: 0.489335
Average total loss: 1.187392
tensor(0.0041, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.9444e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.683191
Average KL loss: 0.492222
Average total loss: 1.175413
tensor(0.0041, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(5.6024e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.673619
Average KL loss: 0.495108
Average total loss: 1.168727
tensor(0.0041, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.1945e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.695158
Average KL loss: 0.497217
Average total loss: 1.192375
tensor(0.0041, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.2486e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.673553
Average KL loss: 0.498814
Average total loss: 1.172367
tensor(0.0041, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.2685e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.673425
Average KL loss: 0.500036
Average total loss: 1.173461
tensor(0.0041, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.0561e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.651485
Average KL loss: 0.501984
Average total loss: 1.153469
tensor(0.0041, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.5432e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.647956
Average KL loss: 0.501554
Average total loss: 1.149510
tensor(0.0041, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(1.9190e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.651773
Average KL loss: 0.501426
Average total loss: 1.153199
tensor(0.0041, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(1.1551e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.655727
Average KL loss: 0.502993
Average total loss: 1.158720
tensor(0.0041, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.0018e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.640853
Average KL loss: 0.504101
Average total loss: 1.144954
tensor(0.0041, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.4133e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.637362
Average KL loss: 0.504906
Average total loss: 1.142268
tensor(0.0041, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-8.3299e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.635125
Average KL loss: 0.504927
Average total loss: 1.140052
tensor(0.0041, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.2471e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.646286
Average KL loss: 0.505076
Average total loss: 1.151362
tensor(0.0041, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(4.8019e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.637912
Average KL loss: 0.504854
Average total loss: 1.142766
tensor(0.0041, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.9055e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.640238
Average KL loss: 0.505888
Average total loss: 1.146126
tensor(0.0041, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.3921e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.642572
Average KL loss: 0.507068
Average total loss: 1.149640
tensor(0.0041, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.8612e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.633251
Average KL loss: 0.508120
Average total loss: 1.141371
tensor(0.0041, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.1126e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.634231
Average KL loss: 0.507746
Average total loss: 1.141977
tensor(0.0041, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.0301e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.609638
Average KL loss: 0.508242
Average total loss: 1.117880
tensor(0.0041, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.7655e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.630888
Average KL loss: 0.507240
Average total loss: 1.138128
tensor(0.0041, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-9.4840e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.609459
Average KL loss: 0.507437
Average total loss: 1.116896
tensor(0.0041, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.1713e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.626100
Average KL loss: 0.507990
Average total loss: 1.134090
tensor(0.0041, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.3438e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.622598
Average KL loss: 0.508384
Average total loss: 1.130982
tensor(0.0041, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(5.3842e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.618646
Average KL loss: 0.508518
Average total loss: 1.127164
tensor(0.0041, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(5.9490e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.627935
Average KL loss: 0.508984
Average total loss: 1.136918
tensor(0.0041, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(8.1410e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.623796
Average KL loss: 0.510199
Average total loss: 1.133995
tensor(0.0041, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.4956e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.619456
Average KL loss: 0.510754
Average total loss: 1.130210
tensor(0.0041, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.6036e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.634092
Average KL loss: 0.511904
Average total loss: 1.145996
tensor(0.0041, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.5768e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.623173
Average KL loss: 0.513265
Average total loss: 1.136438
tensor(0.0041, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.0046e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.602414
Average KL loss: 0.513188
Average total loss: 1.115602
tensor(0.0041, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.1018e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.615905
Average KL loss: 0.512878
Average total loss: 1.128784
tensor(0.0041, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.5769e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.605088
Average KL loss: 0.513276
Average total loss: 1.118364
tensor(0.0041, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(9.2307e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.609289
Average KL loss: 0.512880
Average total loss: 1.122169
tensor(0.0041, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.5819e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.609904
Average KL loss: 0.512327
Average total loss: 1.122230
tensor(0.0041, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(9.8544e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.603710
Average KL loss: 0.512834
Average total loss: 1.116543
tensor(0.0041, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.2047e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.603851
Average KL loss: 0.512801
Average total loss: 1.116651
tensor(0.0041, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(7.2719e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.594768
Average KL loss: 0.512113
Average total loss: 1.106881
tensor(0.0040, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.2304e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.603713
Average KL loss: 0.511702
Average total loss: 1.115415
tensor(0.0041, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.6597e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.600698
Average KL loss: 0.512505
Average total loss: 1.113203
tensor(0.0041, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.6201e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.601647
Average KL loss: 0.513012
Average total loss: 1.114660
tensor(0.0041, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.2635e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.584101
Average KL loss: 0.513072
Average total loss: 1.097173
tensor(0.0040, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.4425e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.596312
Average KL loss: 0.512142
Average total loss: 1.108454
tensor(0.0040, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.6439e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.604588
Average KL loss: 0.512581
Average total loss: 1.117168
tensor(0.0041, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.4694e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.601960
Average KL loss: 0.512506
Average total loss: 1.114466
tensor(0.0040, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(4.8395e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.599047
Average KL loss: 0.512656
Average total loss: 1.111702
tensor(0.0040, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.3663e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.591600
Average KL loss: 0.512255
Average total loss: 1.103855
tensor(0.0040, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.4255e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.596521
Average KL loss: 0.512119
Average total loss: 1.108640
tensor(0.0040, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.9152e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.612379
Average KL loss: 0.513053
Average total loss: 1.125432
tensor(0.0040, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.6967e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.606911
Average KL loss: 0.514373
Average total loss: 1.121284
tensor(0.0040, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(6.6171e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.590164
Average KL loss: 0.514032
Average total loss: 1.104195
tensor(0.0040, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.6954e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.593599
Average KL loss: 0.512955
Average total loss: 1.106553
tensor(0.0040, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(7.9257e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.583553
Average KL loss: 0.512822
Average total loss: 1.096374
tensor(0.0040, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(6.4348e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.589768
Average KL loss: 0.512581
Average total loss: 1.102349
tensor(0.0040, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.1525e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.582332
Average KL loss: 0.512351
Average total loss: 1.094683
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.0817e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.571738
Average KL loss: 0.511986
Average total loss: 1.083724
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.6744e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.604492
Average KL loss: 0.513041
Average total loss: 1.117532
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(6.2873e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.584115
Average KL loss: 0.513447
Average total loss: 1.097562
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(9.4701e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.585955
Average KL loss: 0.513358
Average total loss: 1.099313
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.7952e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.582915
Average KL loss: 0.513885
Average total loss: 1.096800
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.6743e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.585711
Average KL loss: 0.514609
Average total loss: 1.100320
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.3471e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.579573
Average KL loss: 0.514750
Average total loss: 1.094323
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.5414e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.582173
Average KL loss: 0.514188
Average total loss: 1.096361
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.5716e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.586226
Average KL loss: 0.514058
Average total loss: 1.100284
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.1860e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.593683
Average KL loss: 0.514780
Average total loss: 1.108464
tensor(0.0040, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(7.8983e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.572409
Average KL loss: 0.515185
Average total loss: 1.087594
tensor(0.0040, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(7.8110e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.578394
Average KL loss: 0.514507
Average total loss: 1.092900
tensor(0.0040, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.0945e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.578883
Average KL loss: 0.513504
Average total loss: 1.092387
tensor(0.0040, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.2810e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.579110
Average KL loss: 0.512043
Average total loss: 1.091154
tensor(0.0040, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.6900e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.569724
Average KL loss: 0.510702
Average total loss: 1.080426
tensor(0.0040, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.8114e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.566374
Average KL loss: 0.509428
Average total loss: 1.075802
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.1640e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.595548
Average KL loss: 0.508257
Average total loss: 1.103804
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(6.9551e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.577096
Average KL loss: 0.507265
Average total loss: 1.084361
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.1417e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.572041
Average KL loss: 0.506268
Average total loss: 1.078309
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.9252e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.574737
Average KL loss: 0.505348
Average total loss: 1.080085
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.2810e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.571681
Average KL loss: 0.504418
Average total loss: 1.076099
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(4.1602e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.589380
Average KL loss: 0.503550
Average total loss: 1.092930
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(5.7029e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.588176
Average KL loss: 0.502774
Average total loss: 1.090950
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.0457e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.573138
Average KL loss: 0.502034
Average total loss: 1.075172
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.1535e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.576678
Average KL loss: 0.501257
Average total loss: 1.077935
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-8.4981e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.571645
Average KL loss: 0.500507
Average total loss: 1.072153
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.7252e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.572010
Average KL loss: 0.499808
Average total loss: 1.071818
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.3522e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.573044
Average KL loss: 0.499097
Average total loss: 1.072141
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.8638e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.590150
Average KL loss: 0.498441
Average total loss: 1.088591
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.7632e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.570126
Average KL loss: 0.497769
Average total loss: 1.067895
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.5693e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.562582
Average KL loss: 0.497124
Average total loss: 1.059706
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(6.8090e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.577631
Average KL loss: 0.496491
Average total loss: 1.074122
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-9.4348e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.563971
Average KL loss: 0.495916
Average total loss: 1.059887
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.0813e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.568033
Average KL loss: 0.495281
Average total loss: 1.063314
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.2371e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.582751
Average KL loss: 0.494772
Average total loss: 1.077523
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.0330e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.580749
Average KL loss: 0.494308
Average total loss: 1.075057
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.7581e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.573792
Average KL loss: 0.493838
Average total loss: 1.067630
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(6.6440e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.567661
Average KL loss: 0.493364
Average total loss: 1.061024
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.5252e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.577162
Average KL loss: 0.492818
Average total loss: 1.069980
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.4473e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.573697
Average KL loss: 0.492326
Average total loss: 1.066023
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.5787e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.567758
Average KL loss: 0.491817
Average total loss: 1.059575
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.8381e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.567399
Average KL loss: 0.491338
Average total loss: 1.058737
tensor(0.0040, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.2558e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.583963
Average KL loss: 0.490813
Average total loss: 1.074776
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.0108e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.585459
Average KL loss: 0.490498
Average total loss: 1.075957
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(6.6781e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.582473
Average KL loss: 0.490211
Average total loss: 1.072684
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(3.3539e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.582723
Average KL loss: 0.489798
Average total loss: 1.072522
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.5509e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.567545
Average KL loss: 0.489341
Average total loss: 1.056886
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.7797e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.560105
Average KL loss: 0.488934
Average total loss: 1.049039
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.3842e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.577367
Average KL loss: 0.488525
Average total loss: 1.065892
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(6.0104e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.569270
Average KL loss: 0.488111
Average total loss: 1.057381
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.3101e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.565689
Average KL loss: 0.487671
Average total loss: 1.053360
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.0651e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.570724
Average KL loss: 0.487272
Average total loss: 1.057996
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.3442e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.572966
Average KL loss: 0.486946
Average total loss: 1.059911
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.0721e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.579406
Average KL loss: 0.486627
Average total loss: 1.066033
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.5466e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.579532
Average KL loss: 0.486265
Average total loss: 1.065797
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.4214e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.561904
Average KL loss: 0.485890
Average total loss: 1.047794
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.6624e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.567222
Average KL loss: 0.485473
Average total loss: 1.052695
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(5.6845e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.571789
Average KL loss: 0.485148
Average total loss: 1.056936
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.9219e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.573816
Average KL loss: 0.484863
Average total loss: 1.058679
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.8467e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.567877
Average KL loss: 0.484572
Average total loss: 1.052448
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.7355e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.577232
Average KL loss: 0.484320
Average total loss: 1.061552
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.7009e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.561333
Average KL loss: 0.484059
Average total loss: 1.045392
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(5.3858e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.566231
Average KL loss: 0.483694
Average total loss: 1.049925
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(5.3681e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.569306
Average KL loss: 0.483336
Average total loss: 1.052641
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.6069e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.565918
Average KL loss: 0.483058
Average total loss: 1.048976
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(5.6125e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.568548
Average KL loss: 0.482750
Average total loss: 1.051298
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.5798e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.571408
Average KL loss: 0.482462
Average total loss: 1.053870
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.3240e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.583042
Average KL loss: 0.482249
Average total loss: 1.065290
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(7.2132e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.575515
Average KL loss: 0.481991
Average total loss: 1.057507
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.9353e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.575167
Average KL loss: 0.481828
Average total loss: 1.056996
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.0363e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.572185
Average KL loss: 0.481602
Average total loss: 1.053787
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.8429e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.558083
Average KL loss: 0.481288
Average total loss: 1.039371
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.4813e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.570969
Average KL loss: 0.480958
Average total loss: 1.051926
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-8.7715e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.560111
Average KL loss: 0.480749
Average total loss: 1.040859
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(8.2213e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.569499
Average KL loss: 0.480494
Average total loss: 1.049993
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.6092e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.564370
Average KL loss: 0.480198
Average total loss: 1.044569
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.9468e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.565751
Average KL loss: 0.480004
Average total loss: 1.045755
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.1143e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.579232
Average KL loss: 0.479811
Average total loss: 1.059042
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.0034e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.565251
Average KL loss: 0.479686
Average total loss: 1.044937
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(9.2609e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.571651
Average KL loss: 0.479453
Average total loss: 1.051104
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.5336e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.566069
Average KL loss: 0.479172
Average total loss: 1.045241
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(5.3607e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.567267
Average KL loss: 0.478882
Average total loss: 1.046149
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.2979e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.569524
Average KL loss: 0.478728
Average total loss: 1.048252
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-8.4096e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.542437
Average KL loss: 0.478608
Average total loss: 1.021045
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(3.9302e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.578244
Average KL loss: 0.478575
Average total loss: 1.056820
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.5518e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.579922
Average KL loss: 0.478549
Average total loss: 1.058471
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.1283e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.576655
Average KL loss: 0.478518
Average total loss: 1.055173
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.8337e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.574290
Average KL loss: 0.478489
Average total loss: 1.052779
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-4.6561e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.571661
Average KL loss: 0.478461
Average total loss: 1.050122
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.1255e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.572401
Average KL loss: 0.478431
Average total loss: 1.050832
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.2129e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.566821
Average KL loss: 0.478398
Average total loss: 1.045219
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.6891e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.569348
Average KL loss: 0.478362
Average total loss: 1.047710
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(9.9800e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.555578
Average KL loss: 0.478333
Average total loss: 1.033911
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.9908e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.573677
Average KL loss: 0.478292
Average total loss: 1.051969
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.8866e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.568258
Average KL loss: 0.478260
Average total loss: 1.046519
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.6497e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.550924
Average KL loss: 0.478244
Average total loss: 1.029168
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.3320e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.583179
Average KL loss: 0.478240
Average total loss: 1.061419
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.1607e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.565090
Average KL loss: 0.478237
Average total loss: 1.043326
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.9174e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.564100
Average KL loss: 0.478233
Average total loss: 1.042333
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.6887e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.562086
Average KL loss: 0.478229
Average total loss: 1.040315
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(7.4206e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.568893
Average KL loss: 0.478225
Average total loss: 1.047117
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.1473e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.560888
Average KL loss: 0.478221
Average total loss: 1.039108
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.0132e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.577825
Average KL loss: 0.478217
Average total loss: 1.056042
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.7039e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.565110
Average KL loss: 0.478214
Average total loss: 1.043324
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.1754e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.576519
Average KL loss: 0.478211
Average total loss: 1.054729
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.6380e-09, device='cuda:0')
 Percentile value: 7.990693973169982e-08
Non-zero model percentage: 13.42179012298584%, Non-zero mask percentage: 13.42179012298584%

--- Pruning Level [9/24]: ---
conv1.weight         | nonzeros =     663 /    1728             ( 38.37%) | total_pruned =    1065 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1598 /   36864             (  4.33%) | total_pruned =   35266 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1963 /   36864             (  5.32%) | total_pruned =   34901 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1723 /   36864             (  4.67%) | total_pruned =   35141 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1705 /   36864             (  4.63%) | total_pruned =   35159 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3058 /   73728             (  4.15%) | total_pruned =   70670 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4816 /  147456             (  3.27%) | total_pruned =  142640 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1111 /    8192             ( 13.56%) | total_pruned =    7081 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4672 /  147456             (  3.17%) | total_pruned =  142784 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    4840 /  147456             (  3.28%) | total_pruned =  142616 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    9308 /  294912             (  3.16%) | total_pruned =  285604 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      54 /     256             ( 21.09%) | total_pruned =     202 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   15449 /  589824             (  2.62%) | total_pruned =  574375 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      67 /     256             ( 26.17%) | total_pruned =     189 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2513 /   32768             (  7.67%) | total_pruned =   30255 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      65 /     256             ( 25.39%) | total_pruned =     191 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   57410 /  589824             (  9.73%) | total_pruned =  532414 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     199 /     256             ( 77.73%) | total_pruned =      57 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   56235 /  589824             (  9.53%) | total_pruned =  533589 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     241 /     256             ( 94.14%) | total_pruned =      15 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   34071 / 1179648             (  2.89%) | total_pruned = 1145577 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     116 /     512             ( 22.66%) | total_pruned =     396 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     504 /     512             ( 98.44%) | total_pruned =       8 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     120 /     512             ( 23.44%) | total_pruned =     392 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   96317 / 2359296             (  4.08%) | total_pruned = 2262979 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     121 /     512             ( 23.63%) | total_pruned =     391 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     480 /     512             ( 93.75%) | total_pruned =      32 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     214 /     512             ( 41.80%) | total_pruned =     298 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    7669 /  131072             (  5.85%) | total_pruned =  123403 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     119 /     512             ( 23.24%) | total_pruned =     393 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     292 /     512             ( 57.03%) | total_pruned =     220 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     221 /     512             ( 43.16%) | total_pruned =     291 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  428116 / 2359296             ( 18.15%) | total_pruned = 1931180 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     266 /     512             ( 51.95%) | total_pruned =     246 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     340 /     512             ( 66.41%) | total_pruned =     172 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     223 /     512             ( 43.55%) | total_pruned =     289 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  760209 / 2359296             ( 32.22%) | total_pruned = 1599087 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     216 /     512             ( 42.19%) | total_pruned =     296 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     136 /     512             ( 26.56%) | total_pruned =     376 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
linear.weight        | nonzeros =     811 /    5120             ( 15.84%) | total_pruned =    4309 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 1500390, pruned : 9678372, total: 11178762, Compression rate :       7.45x  ( 86.58% pruned)
Train Epoch: 26/100 Loss: 0.000698 Accuracy: 86.35 100.00 % Best test Accuracy: 86.53%
tensor(0.0040, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.8508e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.013430
Average KL loss: 0.457003
Average total loss: 1.470433
tensor(0.0042, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.4556e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.969190
Average KL loss: 0.463705
Average total loss: 1.432895
tensor(0.0042, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4529e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.911489
Average KL loss: 0.475662
Average total loss: 1.387151
tensor(0.0043, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.4224e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.884697
Average KL loss: 0.486826
Average total loss: 1.371522
tensor(0.0043, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.9480e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.915455
Average KL loss: 0.497062
Average total loss: 1.412517
tensor(0.0043, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.0052e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.853831
Average KL loss: 0.506942
Average total loss: 1.360774
tensor(0.0043, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.1599e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.865136
Average KL loss: 0.514118
Average total loss: 1.379253
tensor(0.0043, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.0413e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.833255
Average KL loss: 0.521697
Average total loss: 1.354952
tensor(0.0044, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.3429e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.860253
Average KL loss: 0.529146
Average total loss: 1.389399
tensor(0.0044, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.3978e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.793267
Average KL loss: 0.535942
Average total loss: 1.329209
tensor(0.0044, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.4248e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.771003
Average KL loss: 0.540146
Average total loss: 1.311148
tensor(0.0044, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.2240e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.765991
Average KL loss: 0.543843
Average total loss: 1.309834
tensor(0.0044, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.4051e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.766227
Average KL loss: 0.547128
Average total loss: 1.313355
tensor(0.0044, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.3716e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.752598
Average KL loss: 0.550487
Average total loss: 1.303085
tensor(0.0044, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.9332e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.761049
Average KL loss: 0.553458
Average total loss: 1.314507
tensor(0.0044, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.0120e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.751779
Average KL loss: 0.556407
Average total loss: 1.308186
tensor(0.0044, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.1248e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.766342
Average KL loss: 0.559317
Average total loss: 1.325659
tensor(0.0044, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.2528e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.749495
Average KL loss: 0.562764
Average total loss: 1.312259
tensor(0.0044, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(2.8168e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.759978
Average KL loss: 0.565742
Average total loss: 1.325720
tensor(0.0044, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.1336e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.720052
Average KL loss: 0.568407
Average total loss: 1.288459
tensor(0.0044, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(6.0484e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.750619
Average KL loss: 0.570180
Average total loss: 1.320800
tensor(0.0044, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-6.6455e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.718588
Average KL loss: 0.572837
Average total loss: 1.291424
tensor(0.0044, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.7056e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.728975
Average KL loss: 0.574541
Average total loss: 1.303517
tensor(0.0044, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(2.5239e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.709571
Average KL loss: 0.576120
Average total loss: 1.285691
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.4725e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.707875
Average KL loss: 0.577236
Average total loss: 1.285111
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-7.1847e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.694653
Average KL loss: 0.577611
Average total loss: 1.272264
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(5.9307e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.701073
Average KL loss: 0.578827
Average total loss: 1.279900
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(2.2303e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.702317
Average KL loss: 0.579796
Average total loss: 1.282113
tensor(0.0044, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-3.6468e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.723449
Average KL loss: 0.581610
Average total loss: 1.305059
tensor(0.0045, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(7.7938e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.710163
Average KL loss: 0.583216
Average total loss: 1.293379
tensor(0.0045, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.1716e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.698158
Average KL loss: 0.583988
Average total loss: 1.282147
tensor(0.0044, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.6156e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.707886
Average KL loss: 0.584919
Average total loss: 1.292805
tensor(0.0045, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(6.8301e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.688102
Average KL loss: 0.585907
Average total loss: 1.274009
tensor(0.0045, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-4.6086e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.688404
Average KL loss: 0.586476
Average total loss: 1.274880
tensor(0.0045, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-8.8941e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.677213
Average KL loss: 0.587304
Average total loss: 1.264518
tensor(0.0045, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-4.5300e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.685307
Average KL loss: 0.587572
Average total loss: 1.272879
tensor(0.0045, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-5.9286e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.686466
Average KL loss: 0.587941
Average total loss: 1.274407
tensor(0.0045, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(2.9856e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.659793
Average KL loss: 0.588185
Average total loss: 1.247978
tensor(0.0045, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-4.0642e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.679430
Average KL loss: 0.588417
Average total loss: 1.267847
tensor(0.0045, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-8.7595e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.662205
Average KL loss: 0.589141
Average total loss: 1.251346
tensor(0.0045, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(6.2729e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.672182
Average KL loss: 0.589002
Average total loss: 1.261184
tensor(0.0044, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(5.9261e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.664647
Average KL loss: 0.590002
Average total loss: 1.254649
tensor(0.0044, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.2003e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.675309
Average KL loss: 0.590519
Average total loss: 1.265828
tensor(0.0044, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.0843e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.674021
Average KL loss: 0.591173
Average total loss: 1.265194
tensor(0.0044, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(6.3179e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.659411
Average KL loss: 0.591880
Average total loss: 1.251291
tensor(0.0044, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(7.8989e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.645545
Average KL loss: 0.591764
Average total loss: 1.237310
tensor(0.0044, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.4052e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.656951
Average KL loss: 0.591484
Average total loss: 1.248434
tensor(0.0044, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.5835e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.646090
Average KL loss: 0.591878
Average total loss: 1.237968
tensor(0.0044, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(9.6412e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.655987
Average KL loss: 0.592155
Average total loss: 1.248142
tensor(0.0044, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.3945e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.637079
Average KL loss: 0.591651
Average total loss: 1.228729
tensor(0.0044, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(9.9312e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.655429
Average KL loss: 0.590848
Average total loss: 1.246277
tensor(0.0044, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-7.0800e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.634311
Average KL loss: 0.590993
Average total loss: 1.225304
tensor(0.0044, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-5.3289e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.652021
Average KL loss: 0.590842
Average total loss: 1.242862
tensor(0.0044, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-9.7830e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.657555
Average KL loss: 0.591857
Average total loss: 1.249412
tensor(0.0044, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(1.8271e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.647603
Average KL loss: 0.591998
Average total loss: 1.239601
tensor(0.0044, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.8135e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.623782
Average KL loss: 0.592013
Average total loss: 1.215795
tensor(0.0044, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-2.8283e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.641215
Average KL loss: 0.591381
Average total loss: 1.232595
tensor(0.0044, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-9.4856e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.635639
Average KL loss: 0.591494
Average total loss: 1.227132
tensor(0.0044, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(7.9767e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.635809
Average KL loss: 0.591552
Average total loss: 1.227360
tensor(0.0044, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.0086e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.633681
Average KL loss: 0.592035
Average total loss: 1.225716
tensor(0.0044, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.2842e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.629080
Average KL loss: 0.592215
Average total loss: 1.221295
tensor(0.0044, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(2.7823e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.630544
Average KL loss: 0.591473
Average total loss: 1.222017
tensor(0.0044, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-9.7148e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.635395
Average KL loss: 0.591494
Average total loss: 1.226889
tensor(0.0044, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(2.8890e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.631393
Average KL loss: 0.591940
Average total loss: 1.223333
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(2.1177e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.633649
Average KL loss: 0.591550
Average total loss: 1.225199
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-9.0828e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.645430
Average KL loss: 0.592496
Average total loss: 1.237926
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(6.1483e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.648518
Average KL loss: 0.592962
Average total loss: 1.241480
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-9.7357e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.628130
Average KL loss: 0.592775
Average total loss: 1.220905
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(3.6000e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.602796
Average KL loss: 0.591796
Average total loss: 1.194591
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.4398e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.627637
Average KL loss: 0.590879
Average total loss: 1.218516
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(6.9439e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.625159
Average KL loss: 0.590119
Average total loss: 1.215278
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.6738e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.631873
Average KL loss: 0.589366
Average total loss: 1.221239
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-3.1791e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.615123
Average KL loss: 0.588582
Average total loss: 1.203705
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(2.2857e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.632503
Average KL loss: 0.587793
Average total loss: 1.220296
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.1330e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.628084
Average KL loss: 0.587154
Average total loss: 1.215238
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.0895e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.616726
Average KL loss: 0.586506
Average total loss: 1.203232
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-2.9208e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.633953
Average KL loss: 0.585829
Average total loss: 1.219782
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.5354e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.618277
Average KL loss: 0.585190
Average total loss: 1.203467
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-2.3819e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.632015
Average KL loss: 0.584584
Average total loss: 1.216600
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-9.2511e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.623790
Average KL loss: 0.584010
Average total loss: 1.207801
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.1182e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.633605
Average KL loss: 0.583670
Average total loss: 1.217275
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-5.2272e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.635333
Average KL loss: 0.583612
Average total loss: 1.218945
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-9.9399e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.622903
Average KL loss: 0.583552
Average total loss: 1.206455
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-8.7392e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.634677
Average KL loss: 0.583487
Average total loss: 1.218163
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(2.4074e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.620323
Average KL loss: 0.583427
Average total loss: 1.203750
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-3.5876e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.630752
Average KL loss: 0.583363
Average total loss: 1.214115
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(6.2028e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.618249
Average KL loss: 0.583293
Average total loss: 1.201542
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.0496e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.628488
Average KL loss: 0.583224
Average total loss: 1.211712
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(6.7275e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.613998
Average KL loss: 0.583162
Average total loss: 1.197160
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.7952e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.614556
Average KL loss: 0.583093
Average total loss: 1.197649
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(4.1757e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.636656
Average KL loss: 0.583028
Average total loss: 1.219684
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-3.2614e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.635495
Average KL loss: 0.582990
Average total loss: 1.218485
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.9444e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.621331
Average KL loss: 0.582983
Average total loss: 1.204314
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(9.5079e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.612577
Average KL loss: 0.582977
Average total loss: 1.195553
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.6416e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.654785
Average KL loss: 0.582969
Average total loss: 1.237755
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.1105e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.626832
Average KL loss: 0.582963
Average total loss: 1.209794
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.4667e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.621784
Average KL loss: 0.582956
Average total loss: 1.204740
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-3.8165e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.621065
Average KL loss: 0.582950
Average total loss: 1.204015
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-2.2377e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.630621
Average KL loss: 0.582943
Average total loss: 1.213564
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-8.0158e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.631391
Average KL loss: 0.582937
Average total loss: 1.214328
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.1047e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.616866
Average KL loss: 0.582930
Average total loss: 1.199797
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.0926e-08, device='cuda:0')
 Percentile value: 8.186071198679201e-08
Non-zero model percentage: 10.737431526184082%, Non-zero mask percentage: 10.737431526184082%

--- Pruning Level [10/24]: ---
conv1.weight         | nonzeros =     637 /    1728             ( 36.86%) | total_pruned =    1091 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1311 /   36864             (  3.56%) | total_pruned =   35553 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1659 /   36864             (  4.50%) | total_pruned =   35205 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1442 /   36864             (  3.91%) | total_pruned =   35422 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1461 /   36864             (  3.96%) | total_pruned =   35403 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2557 /   73728             (  3.47%) | total_pruned =   71171 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3890 /  147456             (  2.64%) | total_pruned =  143566 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     998 /    8192             ( 12.18%) | total_pruned =    7194 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3863 /  147456             (  2.62%) | total_pruned =  143593 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    4032 /  147456             (  2.73%) | total_pruned =  143424 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7405 /  294912             (  2.51%) | total_pruned =  287507 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   11708 /  589824             (  1.98%) | total_pruned =  578116 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      56 /     256             ( 21.88%) | total_pruned =     200 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2115 /   32768             (  6.45%) | total_pruned =   30653 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      57 /     256             ( 22.27%) | total_pruned =     199 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   53537 /  589824             (  9.08%) | total_pruned =  536287 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     199 /     256             ( 77.73%) | total_pruned =      57 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   52314 /  589824             (  8.87%) | total_pruned =  537510 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   26700 / 1179648             (  2.26%) | total_pruned = 1152948 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      60 /     512             ( 11.72%) | total_pruned =     452 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      94 /     512             ( 18.36%) | total_pruned =     418 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   76795 / 2359296             (  3.25%) | total_pruned = 2282501 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      62 /     512             ( 12.11%) | total_pruned =     450 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     473 /     512             ( 92.38%) | total_pruned =      39 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     181 /     512             ( 35.35%) | total_pruned =     331 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    6209 /  131072             (  4.74%) | total_pruned =  124863 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      92 /     512             ( 17.97%) | total_pruned =     420 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     275 /     512             ( 53.71%) | total_pruned =     237 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     174 /     512             ( 33.98%) | total_pruned =     338 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  364674 / 2359296             ( 15.46%) | total_pruned = 1994622 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     169 /     512             ( 33.01%) | total_pruned =     343 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     327 /     512             ( 63.87%) | total_pruned =     185 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     172 /     512             ( 33.59%) | total_pruned =     340 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  570953 / 2359296             ( 24.20%) | total_pruned = 1788343 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     136 /     512             ( 26.56%) | total_pruned =     376 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      90 /     512             ( 17.58%) | total_pruned =     422 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
linear.weight        | nonzeros =     656 /    5120             ( 12.81%) | total_pruned =    4464 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 1200312, pruned : 9978450, total: 11178762, Compression rate :       9.31x  ( 89.26% pruned)
Train Epoch: 24/100 Loss: 0.000503 Accuracy: 85.54 100.00 % Best test Accuracy: 86.03%
tensor(0.0044, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-3.1884e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.059374
Average KL loss: 0.551405
Average total loss: 1.610779
tensor(0.0047, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-5.9971e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.029553
Average KL loss: 0.548327
Average total loss: 1.577880
tensor(0.0047, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-3.2090e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.987908
Average KL loss: 0.556251
Average total loss: 1.544159
tensor(0.0047, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-7.3801e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.976743
Average KL loss: 0.564346
Average total loss: 1.541090
tensor(0.0047, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.7468e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.982500
Average KL loss: 0.572488
Average total loss: 1.554988
tensor(0.0047, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-3.6491e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.946386
Average KL loss: 0.580519
Average total loss: 1.526905
tensor(0.0047, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.7661e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.930219
Average KL loss: 0.587640
Average total loss: 1.517859
tensor(0.0047, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-5.3977e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.930269
Average KL loss: 0.593992
Average total loss: 1.524261
tensor(0.0047, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-4.5491e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.887374
Average KL loss: 0.599292
Average total loss: 1.486666
tensor(0.0048, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-5.6727e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.895038
Average KL loss: 0.604223
Average total loss: 1.499261
tensor(0.0048, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-6.1580e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.877959
Average KL loss: 0.608611
Average total loss: 1.486570
tensor(0.0048, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-5.6939e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.875948
Average KL loss: 0.613578
Average total loss: 1.489526
tensor(0.0048, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(1.5409e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.848600
Average KL loss: 0.617617
Average total loss: 1.466216
tensor(0.0048, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-3.9116e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.860726
Average KL loss: 0.621580
Average total loss: 1.482306
tensor(0.0048, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-2.5417e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.840523
Average KL loss: 0.625154
Average total loss: 1.465677
tensor(0.0048, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.2266e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.835361
Average KL loss: 0.628394
Average total loss: 1.463755
tensor(0.0048, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.9427e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.825858
Average KL loss: 0.631225
Average total loss: 1.457082
tensor(0.0048, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-5.6062e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.846859
Average KL loss: 0.634055
Average total loss: 1.480913
tensor(0.0048, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-9.7171e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.828163
Average KL loss: 0.637048
Average total loss: 1.465211
tensor(0.0048, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(6.1011e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.795857
Average KL loss: 0.639109
Average total loss: 1.434967
tensor(0.0048, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.3892e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.823170
Average KL loss: 0.641332
Average total loss: 1.464501
tensor(0.0048, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.9809e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.826298
Average KL loss: 0.643824
Average total loss: 1.470122
tensor(0.0048, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.3097e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.799496
Average KL loss: 0.646435
Average total loss: 1.445931
tensor(0.0048, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-5.4967e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.777106
Average KL loss: 0.647972
Average total loss: 1.425078
tensor(0.0048, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-3.6153e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.780694
Average KL loss: 0.649422
Average total loss: 1.430117
tensor(0.0048, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(6.8337e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.777042
Average KL loss: 0.650637
Average total loss: 1.427679
tensor(0.0048, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(4.7844e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.782002
Average KL loss: 0.651908
Average total loss: 1.433910
tensor(0.0048, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(3.4049e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.770571
Average KL loss: 0.653691
Average total loss: 1.424262
tensor(0.0048, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.2235e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.775122
Average KL loss: 0.655109
Average total loss: 1.430231
tensor(0.0048, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(3.4494e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.761403
Average KL loss: 0.656175
Average total loss: 1.417579
tensor(0.0048, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.3167e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.762511
Average KL loss: 0.657487
Average total loss: 1.419998
tensor(0.0048, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.2615e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.760700
Average KL loss: 0.658420
Average total loss: 1.419120
tensor(0.0048, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-3.6016e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.753302
Average KL loss: 0.659185
Average total loss: 1.412487
tensor(0.0048, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.8507e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.766691
Average KL loss: 0.660097
Average total loss: 1.426789
tensor(0.0048, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-3.5391e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.740096
Average KL loss: 0.661298
Average total loss: 1.401394
tensor(0.0048, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-5.8226e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.746811
Average KL loss: 0.662339
Average total loss: 1.409151
tensor(0.0048, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-7.3852e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.745200
Average KL loss: 0.663238
Average total loss: 1.408439
tensor(0.0048, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.7517e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.721675
Average KL loss: 0.663891
Average total loss: 1.385566
tensor(0.0048, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-2.2173e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.748499
Average KL loss: 0.664242
Average total loss: 1.412742
tensor(0.0048, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.1417e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.738774
Average KL loss: 0.665525
Average total loss: 1.404299
tensor(0.0048, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-3.5792e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.745857
Average KL loss: 0.666372
Average total loss: 1.412229
tensor(0.0048, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-2.6378e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.727496
Average KL loss: 0.667243
Average total loss: 1.394739
tensor(0.0048, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(8.8890e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.740161
Average KL loss: 0.667491
Average total loss: 1.407652
tensor(0.0048, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-3.7940e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.732248
Average KL loss: 0.668572
Average total loss: 1.400820
tensor(0.0048, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.6524e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.713897
Average KL loss: 0.669057
Average total loss: 1.382954
tensor(0.0048, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.3326e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.719877
Average KL loss: 0.669506
Average total loss: 1.389382
tensor(0.0048, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(3.2178e-12, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.727144
Average KL loss: 0.669897
Average total loss: 1.397041
tensor(0.0048, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-2.1058e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.702618
Average KL loss: 0.670756
Average total loss: 1.373375
tensor(0.0048, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.4643e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.715603
Average KL loss: 0.671097
Average total loss: 1.386700
tensor(0.0048, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.0187e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.729692
Average KL loss: 0.671849
Average total loss: 1.401541
tensor(0.0048, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.3285e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.713777
Average KL loss: 0.672780
Average total loss: 1.386556
tensor(0.0048, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(3.5994e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.715773
Average KL loss: 0.672814
Average total loss: 1.388587
tensor(0.0048, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(1.1568e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.706934
Average KL loss: 0.673210
Average total loss: 1.380144
tensor(0.0048, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.8032e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.702185
Average KL loss: 0.673640
Average total loss: 1.375824
tensor(0.0048, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(1.5134e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.713196
Average KL loss: 0.673656
Average total loss: 1.386852
tensor(0.0048, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(6.3026e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.711098
Average KL loss: 0.674387
Average total loss: 1.385485
tensor(0.0048, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-9.2316e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.710638
Average KL loss: 0.675415
Average total loss: 1.386053
tensor(0.0048, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-3.1620e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.707122
Average KL loss: 0.675698
Average total loss: 1.382820
tensor(0.0048, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.0118e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.690687
Average KL loss: 0.676277
Average total loss: 1.366963
tensor(0.0048, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.4790e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.694748
Average KL loss: 0.676198
Average total loss: 1.370946
tensor(0.0048, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-3.0957e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.708123
Average KL loss: 0.676327
Average total loss: 1.384450
tensor(0.0048, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-8.9763e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.700618
Average KL loss: 0.676804
Average total loss: 1.377423
tensor(0.0048, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.3544e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.689268
Average KL loss: 0.677526
Average total loss: 1.366794
tensor(0.0048, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.9114e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.680202
Average KL loss: 0.677458
Average total loss: 1.357660
tensor(0.0048, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(9.7296e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.697327
Average KL loss: 0.677757
Average total loss: 1.375084
tensor(0.0048, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.2534e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.693237
Average KL loss: 0.678181
Average total loss: 1.371418
tensor(0.0048, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.1899e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.690771
Average KL loss: 0.679340
Average total loss: 1.370111
tensor(0.0048, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.4859e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.693928
Average KL loss: 0.680042
Average total loss: 1.373970
tensor(0.0048, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.8403e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.695270
Average KL loss: 0.680805
Average total loss: 1.376076
tensor(0.0048, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.1019e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.681171
Average KL loss: 0.680831
Average total loss: 1.362002
tensor(0.0048, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(7.6891e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.698827
Average KL loss: 0.680607
Average total loss: 1.379434
tensor(0.0048, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.0111e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.692238
Average KL loss: 0.681087
Average total loss: 1.373325
tensor(0.0048, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.4896e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.680101
Average KL loss: 0.681678
Average total loss: 1.361779
tensor(0.0048, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.3237e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.675653
Average KL loss: 0.681541
Average total loss: 1.357194
tensor(0.0048, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(2.7989e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.663188
Average KL loss: 0.680793
Average total loss: 1.343981
tensor(0.0048, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.3577e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.698296
Average KL loss: 0.680990
Average total loss: 1.379286
tensor(0.0048, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.8736e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.667815
Average KL loss: 0.681234
Average total loss: 1.349049
tensor(0.0048, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-7.6701e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.697108
Average KL loss: 0.681405
Average total loss: 1.378512
tensor(0.0048, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.8034e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.659068
Average KL loss: 0.681885
Average total loss: 1.340952
tensor(0.0048, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.1269e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.669229
Average KL loss: 0.681767
Average total loss: 1.350995
tensor(0.0048, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.0295e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.668296
Average KL loss: 0.681506
Average total loss: 1.349802
tensor(0.0048, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-5.1587e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.674891
Average KL loss: 0.681420
Average total loss: 1.356311
tensor(0.0048, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(6.9335e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.676077
Average KL loss: 0.682014
Average total loss: 1.358090
tensor(0.0048, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(9.8568e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.665023
Average KL loss: 0.681954
Average total loss: 1.346977
tensor(0.0048, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.5027e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.676238
Average KL loss: 0.681938
Average total loss: 1.358175
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.6331e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.669724
Average KL loss: 0.682295
Average total loss: 1.352019
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-7.5009e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.664787
Average KL loss: 0.682828
Average total loss: 1.347615
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-5.3632e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.672770
Average KL loss: 0.683145
Average total loss: 1.355915
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.0095e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.689867
Average KL loss: 0.683613
Average total loss: 1.373480
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.8890e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.679637
Average KL loss: 0.684498
Average total loss: 1.364134
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.8746e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.663667
Average KL loss: 0.684411
Average total loss: 1.348078
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-9.4819e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.659135
Average KL loss: 0.683872
Average total loss: 1.343006
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.8162e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.662443
Average KL loss: 0.683314
Average total loss: 1.345757
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.9840e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.667129
Average KL loss: 0.682796
Average total loss: 1.349925
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.4942e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.654646
Average KL loss: 0.682300
Average total loss: 1.336946
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-6.4477e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.668404
Average KL loss: 0.681790
Average total loss: 1.350194
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(3.5638e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.660153
Average KL loss: 0.681325
Average total loss: 1.341478
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-7.0510e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.662584
Average KL loss: 0.680885
Average total loss: 1.343468
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.1290e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.672077
Average KL loss: 0.680454
Average total loss: 1.352531
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.2459e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.660206
Average KL loss: 0.680010
Average total loss: 1.340216
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-9.8962e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.677722
Average KL loss: 0.679593
Average total loss: 1.357315
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.0474e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.639686
Average KL loss: 0.679163
Average total loss: 1.318849
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.6290e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.662886
Average KL loss: 0.678725
Average total loss: 1.341611
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(3.9381e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.656167
Average KL loss: 0.678310
Average total loss: 1.334477
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-8.5961e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.652374
Average KL loss: 0.677925
Average total loss: 1.330299
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.5087e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.659029
Average KL loss: 0.677526
Average total loss: 1.336556
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.3259e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.647350
Average KL loss: 0.677170
Average total loss: 1.324520
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(9.1882e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.656730
Average KL loss: 0.676730
Average total loss: 1.333460
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(3.7771e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.666253
Average KL loss: 0.676341
Average total loss: 1.342595
tensor(0.0048, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.0113e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.658683
Average KL loss: 0.676020
Average total loss: 1.334702
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(8.9228e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.650623
Average KL loss: 0.675681
Average total loss: 1.326304
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.1082e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.653224
Average KL loss: 0.675274
Average total loss: 1.328498
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.4138e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.663562
Average KL loss: 0.674873
Average total loss: 1.338435
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-9.8368e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.658251
Average KL loss: 0.674681
Average total loss: 1.332932
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.8761e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.657570
Average KL loss: 0.674642
Average total loss: 1.332212
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.6144e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.648083
Average KL loss: 0.674598
Average total loss: 1.322681
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.6714e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.651985
Average KL loss: 0.674554
Average total loss: 1.326539
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.0922e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.665137
Average KL loss: 0.674511
Average total loss: 1.339648
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-8.0653e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.653115
Average KL loss: 0.674475
Average total loss: 1.327590
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.8813e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.663522
Average KL loss: 0.674435
Average total loss: 1.337957
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(9.6915e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.652093
Average KL loss: 0.674393
Average total loss: 1.326486
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-8.8299e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.651083
Average KL loss: 0.674349
Average total loss: 1.325432
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.0954e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.652756
Average KL loss: 0.674306
Average total loss: 1.327062
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(4.6687e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.655514
Average KL loss: 0.674269
Average total loss: 1.329782
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.7707e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.655409
Average KL loss: 0.674246
Average total loss: 1.329656
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(2.1796e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.656529
Average KL loss: 0.674242
Average total loss: 1.330772
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.4155e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.663519
Average KL loss: 0.674238
Average total loss: 1.337757
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.5751e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.659433
Average KL loss: 0.674234
Average total loss: 1.333667
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.1040e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.662575
Average KL loss: 0.674230
Average total loss: 1.336806
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.5972e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.669669
Average KL loss: 0.674227
Average total loss: 1.343895
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-6.4482e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.656263
Average KL loss: 0.674223
Average total loss: 1.330486
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.4320e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.668936
Average KL loss: 0.674219
Average total loss: 1.343154
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.2454e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.660582
Average KL loss: 0.674215
Average total loss: 1.334797
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.6336e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.657830
Average KL loss: 0.674211
Average total loss: 1.332041
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.1295e-08, device='cuda:0')
 Percentile value: 8.060081313487899e-08
Non-zero model percentage: 8.589949607849121%, Non-zero mask percentage: 8.589949607849121%

--- Pruning Level [11/24]: ---
conv1.weight         | nonzeros =     616 /    1728             ( 35.65%) | total_pruned =    1112 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1138 /   36864             (  3.09%) | total_pruned =   35726 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1451 /   36864             (  3.94%) | total_pruned =   35413 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1240 /   36864             (  3.36%) | total_pruned =   35624 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1258 /   36864             (  3.41%) | total_pruned =   35606 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2193 /   73728             (  2.97%) | total_pruned =   71535 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3233 /  147456             (  2.19%) | total_pruned =  144223 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     907 /    8192             ( 11.07%) | total_pruned =    7285 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3202 /  147456             (  2.17%) | total_pruned =  144254 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3306 /  147456             (  2.24%) | total_pruned =  144150 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    6063 /  294912             (  2.06%) | total_pruned =  288849 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      39 /     256             ( 15.23%) | total_pruned =     217 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    9279 /  589824             (  1.57%) | total_pruned =  580545 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1816 /   32768             (  5.54%) | total_pruned =   30952 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   45414 /  589824             (  7.70%) | total_pruned =  544410 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      33 /     256             ( 12.89%) | total_pruned =     223 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      28 /     256             ( 10.94%) | total_pruned =     228 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   44292 /  589824             (  7.51%) | total_pruned =  545532 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   21043 / 1179648             (  1.78%) | total_pruned = 1158605 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      37 /     512             (  7.23%) | total_pruned =     475 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      73 /     512             ( 14.26%) | total_pruned =     439 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   60469 / 2359296             (  2.56%) | total_pruned = 2298827 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      36 /     512             (  7.03%) | total_pruned =     476 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     470 /     512             ( 91.80%) | total_pruned =      42 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     145 /     512             ( 28.32%) | total_pruned =     367 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    5022 /  131072             (  3.83%) | total_pruned =  126050 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      71 /     512             ( 13.87%) | total_pruned =     441 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     259 /     512             ( 50.59%) | total_pruned =     253 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     147 /     512             ( 28.71%) | total_pruned =     365 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  298361 / 2359296             ( 12.65%) | total_pruned = 2060935 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     100 /     512             ( 19.53%) | total_pruned =     412 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     314 /     512             ( 61.33%) | total_pruned =     198 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     116 /     512             ( 22.66%) | total_pruned =     396 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  444477 / 2359296             ( 18.84%) | total_pruned = 1914819 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     101 /     512             ( 19.73%) | total_pruned =     411 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      77 /     512             ( 15.04%) | total_pruned =     435 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
linear.weight        | nonzeros =     545 /    5120             ( 10.64%) | total_pruned =    4575 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 960250, pruned : 10218512, total: 11178762, Compression rate :      11.64x  ( 91.41% pruned)
Train Epoch: 24/100 Loss: 0.001299 Accuracy: 85.25 100.00 % Best test Accuracy: 85.56%
tensor(0.0048, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-9.1420e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.058713
Average KL loss: 0.644335
Average total loss: 1.703048
tensor(0.0050, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-4.6100e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.048422
Average KL loss: 0.637723
Average total loss: 1.686145
tensor(0.0050, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.0003e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.030440
Average KL loss: 0.642816
Average total loss: 1.673256
tensor(0.0050, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.8562e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.990438
Average KL loss: 0.649290
Average total loss: 1.639727
tensor(0.0050, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.2600e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.978487
Average KL loss: 0.656010
Average total loss: 1.634498
tensor(0.0050, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-5.6940e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.934324
Average KL loss: 0.662501
Average total loss: 1.596825
tensor(0.0050, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-7.0862e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.929228
Average KL loss: 0.668048
Average total loss: 1.597276
tensor(0.0050, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-6.6673e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.916156
Average KL loss: 0.672926
Average total loss: 1.589082
tensor(0.0050, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.4324e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.921957
Average KL loss: 0.677541
Average total loss: 1.599498
tensor(0.0051, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.7328e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.895634
Average KL loss: 0.681941
Average total loss: 1.577575
tensor(0.0051, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-4.3302e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.887412
Average KL loss: 0.686394
Average total loss: 1.573806
tensor(0.0051, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-7.7760e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.915510
Average KL loss: 0.690870
Average total loss: 1.606380
tensor(0.0051, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-2.2456e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.879151
Average KL loss: 0.694946
Average total loss: 1.574097
tensor(0.0051, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-6.5586e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.888480
Average KL loss: 0.698410
Average total loss: 1.586889
tensor(0.0051, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-5.0370e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.867943
Average KL loss: 0.702347
Average total loss: 1.570289
tensor(0.0051, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.0983e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.852534
Average KL loss: 0.705121
Average total loss: 1.557655
tensor(0.0051, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.8774e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.858720
Average KL loss: 0.707854
Average total loss: 1.566574
tensor(0.0051, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.5942e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.859835
Average KL loss: 0.710716
Average total loss: 1.570551
tensor(0.0051, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.4247e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.846846
Average KL loss: 0.714017
Average total loss: 1.560864
tensor(0.0051, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-9.1238e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.835873
Average KL loss: 0.716764
Average total loss: 1.552636
tensor(0.0051, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-4.6221e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.817753
Average KL loss: 0.718856
Average total loss: 1.536608
tensor(0.0051, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(1.3099e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.828141
Average KL loss: 0.720716
Average total loss: 1.548857
tensor(0.0051, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-5.8985e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.800580
Average KL loss: 0.722710
Average total loss: 1.523290
tensor(0.0051, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-5.5711e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.816406
Average KL loss: 0.724635
Average total loss: 1.541041
tensor(0.0052, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.5219e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.791804
Average KL loss: 0.727002
Average total loss: 1.518806
tensor(0.0052, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.4389e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.794697
Average KL loss: 0.728487
Average total loss: 1.523184
tensor(0.0052, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-4.8709e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.806069
Average KL loss: 0.729802
Average total loss: 1.535871
tensor(0.0052, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.5124e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.807692
Average KL loss: 0.731483
Average total loss: 1.539175
tensor(0.0052, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.5334e-11, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.795085
Average KL loss: 0.733065
Average total loss: 1.528150
tensor(0.0052, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-8.5105e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.779334
Average KL loss: 0.734695
Average total loss: 1.514030
tensor(0.0052, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.5076e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.789546
Average KL loss: 0.735814
Average total loss: 1.525359
tensor(0.0052, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.1272e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.774207
Average KL loss: 0.737169
Average total loss: 1.511376
tensor(0.0052, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-4.2541e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.782253
Average KL loss: 0.738507
Average total loss: 1.520760
tensor(0.0052, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(5.7198e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.760498
Average KL loss: 0.740023
Average total loss: 1.500521
tensor(0.0052, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-6.9669e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.750593
Average KL loss: 0.740881
Average total loss: 1.491474
tensor(0.0052, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-4.1612e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.761212
Average KL loss: 0.742007
Average total loss: 1.503219
tensor(0.0052, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.5360e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.771203
Average KL loss: 0.743281
Average total loss: 1.514484
tensor(0.0052, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.0555e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.761401
Average KL loss: 0.744635
Average total loss: 1.506036
tensor(0.0052, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.3302e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.754190
Average KL loss: 0.745357
Average total loss: 1.499547
tensor(0.0052, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(3.0382e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.772639
Average KL loss: 0.746346
Average total loss: 1.518985
tensor(0.0052, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-2.6111e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.742371
Average KL loss: 0.747781
Average total loss: 1.490152
tensor(0.0052, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(6.3603e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.760555
Average KL loss: 0.748492
Average total loss: 1.509047
tensor(0.0052, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.9929e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.740376
Average KL loss: 0.749681
Average total loss: 1.490056
tensor(0.0052, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.9215e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.753530
Average KL loss: 0.751117
Average total loss: 1.504647
tensor(0.0052, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.0626e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.722621
Average KL loss: 0.751630
Average total loss: 1.474251
tensor(0.0052, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-6.3242e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.717157
Average KL loss: 0.751915
Average total loss: 1.469072
tensor(0.0052, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.6462e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.743297
Average KL loss: 0.752707
Average total loss: 1.496004
tensor(0.0052, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(9.9291e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.743654
Average KL loss: 0.753656
Average total loss: 1.497311
tensor(0.0052, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-6.5988e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.739723
Average KL loss: 0.754895
Average total loss: 1.494618
tensor(0.0052, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.5512e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.734287
Average KL loss: 0.755835
Average total loss: 1.490122
tensor(0.0052, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.6050e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.731017
Average KL loss: 0.756996
Average total loss: 1.488013
tensor(0.0052, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(3.0237e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.728778
Average KL loss: 0.758504
Average total loss: 1.487282
tensor(0.0052, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(1.0305e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.726568
Average KL loss: 0.759315
Average total loss: 1.485884
tensor(0.0052, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-9.0014e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.714057
Average KL loss: 0.759935
Average total loss: 1.473992
tensor(0.0052, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.5417e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.702141
Average KL loss: 0.760120
Average total loss: 1.462261
tensor(0.0052, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(4.8918e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.725487
Average KL loss: 0.760423
Average total loss: 1.485910
tensor(0.0052, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-5.2057e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.725382
Average KL loss: 0.761121
Average total loss: 1.486504
tensor(0.0052, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-5.3500e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.716741
Average KL loss: 0.761946
Average total loss: 1.478687
tensor(0.0052, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.4934e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.705301
Average KL loss: 0.762275
Average total loss: 1.467576
tensor(0.0052, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.4831e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.708432
Average KL loss: 0.762688
Average total loss: 1.471120
tensor(0.0052, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(1.3021e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.699649
Average KL loss: 0.763210
Average total loss: 1.462859
tensor(0.0052, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(6.0153e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.712442
Average KL loss: 0.763461
Average total loss: 1.475903
tensor(0.0052, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-3.4807e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.704836
Average KL loss: 0.763563
Average total loss: 1.468399
tensor(0.0052, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-3.0495e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.710128
Average KL loss: 0.764535
Average total loss: 1.474663
tensor(0.0052, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.5703e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.695559
Average KL loss: 0.765060
Average total loss: 1.460619
tensor(0.0052, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.0515e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.694904
Average KL loss: 0.765541
Average total loss: 1.460445
tensor(0.0052, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.8695e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.711968
Average KL loss: 0.765867
Average total loss: 1.477835
tensor(0.0052, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.1898e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.696988
Average KL loss: 0.766319
Average total loss: 1.463307
tensor(0.0052, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.6467e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.697760
Average KL loss: 0.766336
Average total loss: 1.464097
tensor(0.0052, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.0763e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.697660
Average KL loss: 0.766368
Average total loss: 1.464028
tensor(0.0052, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.4940e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.685416
Average KL loss: 0.766959
Average total loss: 1.452375
tensor(0.0052, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.1498e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.678597
Average KL loss: 0.766857
Average total loss: 1.445454
tensor(0.0053, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.6628e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.697819
Average KL loss: 0.767335
Average total loss: 1.465154
tensor(0.0053, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.8182e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.681671
Average KL loss: 0.767970
Average total loss: 1.449641
tensor(0.0053, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.4253e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.687452
Average KL loss: 0.768009
Average total loss: 1.455461
tensor(0.0053, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(6.4789e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.690447
Average KL loss: 0.768589
Average total loss: 1.459036
tensor(0.0053, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.8935e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.696603
Average KL loss: 0.768908
Average total loss: 1.465511
tensor(0.0053, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-8.1867e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.684695
Average KL loss: 0.769095
Average total loss: 1.453790
tensor(0.0053, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.1804e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.679120
Average KL loss: 0.769374
Average total loss: 1.448494
tensor(0.0053, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-7.6836e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.684270
Average KL loss: 0.769547
Average total loss: 1.453817
tensor(0.0053, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-7.8764e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.688854
Average KL loss: 0.770041
Average total loss: 1.458895
tensor(0.0053, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-8.6846e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.693355
Average KL loss: 0.770417
Average total loss: 1.463772
tensor(0.0053, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-3.0455e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.666946
Average KL loss: 0.771036
Average total loss: 1.437982
tensor(0.0053, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.0738e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.678389
Average KL loss: 0.770944
Average total loss: 1.449332
tensor(0.0053, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-4.7413e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.673674
Average KL loss: 0.771177
Average total loss: 1.444851
tensor(0.0053, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(4.4377e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.681423
Average KL loss: 0.771482
Average total loss: 1.452905
tensor(0.0053, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-7.5279e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.674691
Average KL loss: 0.771513
Average total loss: 1.446204
tensor(0.0053, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.3228e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.700385
Average KL loss: 0.772214
Average total loss: 1.472598
tensor(0.0053, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.6801e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.674315
Average KL loss: 0.773129
Average total loss: 1.447444
tensor(0.0053, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(2.4027e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.684441
Average KL loss: 0.773600
Average total loss: 1.458041
tensor(0.0053, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.0718e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.658885
Average KL loss: 0.773874
Average total loss: 1.432760
tensor(0.0053, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(1.7194e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.656876
Average KL loss: 0.773230
Average total loss: 1.430106
tensor(0.0053, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-7.8232e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.676091
Average KL loss: 0.773383
Average total loss: 1.449474
tensor(0.0053, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(1.5046e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.672811
Average KL loss: 0.774002
Average total loss: 1.446813
tensor(0.0053, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-4.6983e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.672841
Average KL loss: 0.774278
Average total loss: 1.447118
tensor(0.0053, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.1624e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.661302
Average KL loss: 0.774212
Average total loss: 1.435514
tensor(0.0053, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-6.7866e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.672506
Average KL loss: 0.773843
Average total loss: 1.446349
tensor(0.0053, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.4953e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.667393
Average KL loss: 0.774343
Average total loss: 1.441735
tensor(0.0053, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-8.4579e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.671193
Average KL loss: 0.774773
Average total loss: 1.445966
tensor(0.0053, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.0151e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.663158
Average KL loss: 0.774792
Average total loss: 1.437950
tensor(0.0053, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-9.9320e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.675168
Average KL loss: 0.775134
Average total loss: 1.450302
tensor(0.0053, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.5382e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.659250
Average KL loss: 0.775419
Average total loss: 1.434670
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.6669e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.659998
Average KL loss: 0.775861
Average total loss: 1.435859
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(4.4461e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.658665
Average KL loss: 0.775825
Average total loss: 1.434490
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(7.1768e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.663111
Average KL loss: 0.775449
Average total loss: 1.438560
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.1128e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.663632
Average KL loss: 0.775105
Average total loss: 1.438737
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.5023e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.652651
Average KL loss: 0.774756
Average total loss: 1.427407
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.7558e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.656244
Average KL loss: 0.774409
Average total loss: 1.430653
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.2712e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.653822
Average KL loss: 0.774043
Average total loss: 1.427865
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.7964e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.633465
Average KL loss: 0.773672
Average total loss: 1.407137
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-9.2085e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.656660
Average KL loss: 0.773351
Average total loss: 1.430010
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-8.4833e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.666449
Average KL loss: 0.773019
Average total loss: 1.439468
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.6926e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.657956
Average KL loss: 0.772749
Average total loss: 1.430705
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.5544e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.664927
Average KL loss: 0.772490
Average total loss: 1.437416
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-3.9496e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.663660
Average KL loss: 0.772282
Average total loss: 1.435942
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.9574e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.664759
Average KL loss: 0.772029
Average total loss: 1.436788
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.9640e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.658259
Average KL loss: 0.771772
Average total loss: 1.430031
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.9539e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.671415
Average KL loss: 0.771519
Average total loss: 1.442933
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.4731e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.656189
Average KL loss: 0.771219
Average total loss: 1.427408
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.2376e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.654490
Average KL loss: 0.770880
Average total loss: 1.425371
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.0152e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.655741
Average KL loss: 0.770612
Average total loss: 1.426353
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.0250e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.670646
Average KL loss: 0.770476
Average total loss: 1.441122
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.6432e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.664192
Average KL loss: 0.770446
Average total loss: 1.434638
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.1492e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.669571
Average KL loss: 0.770421
Average total loss: 1.439992
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(7.4859e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.661995
Average KL loss: 0.770397
Average total loss: 1.432391
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(4.2002e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.646052
Average KL loss: 0.770363
Average total loss: 1.416414
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-4.5197e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.647014
Average KL loss: 0.770331
Average total loss: 1.417346
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.5671e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.656180
Average KL loss: 0.770303
Average total loss: 1.426483
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.4485e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.679169
Average KL loss: 0.770279
Average total loss: 1.449448
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.1395e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.660957
Average KL loss: 0.770255
Average total loss: 1.431212
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-5.4465e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.656427
Average KL loss: 0.770228
Average total loss: 1.426654
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.3667e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.658864
Average KL loss: 0.770196
Average total loss: 1.429061
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-8.5404e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.647670
Average KL loss: 0.770178
Average total loss: 1.417847
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-6.1012e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.667790
Average KL loss: 0.770175
Average total loss: 1.437965
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(8.5965e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.661403
Average KL loss: 0.770172
Average total loss: 1.431576
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-7.6096e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.656642
Average KL loss: 0.770170
Average total loss: 1.426811
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.2105e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.659021
Average KL loss: 0.770167
Average total loss: 1.429188
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(7.3390e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.640981
Average KL loss: 0.770164
Average total loss: 1.411145
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(3.3248e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.650241
Average KL loss: 0.770161
Average total loss: 1.420401
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.0353e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.662837
Average KL loss: 0.770158
Average total loss: 1.432995
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(6.1254e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.649969
Average KL loss: 0.770155
Average total loss: 1.420123
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(1.2938e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.663279
Average KL loss: 0.770151
Average total loss: 1.433430
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(2.5998e-09, device='cuda:0')
 Percentile value: 7.989121542095745e-08
Non-zero model percentage: 6.871959686279297%, Non-zero mask percentage: 6.871959686279297%

--- Pruning Level [12/24]: ---
conv1.weight         | nonzeros =     598 /    1728             ( 34.61%) | total_pruned =    1130 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1025 /   36864             (  2.78%) | total_pruned =   35839 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1280 /   36864             (  3.47%) | total_pruned =   35584 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1066 /   36864             (  2.89%) | total_pruned =   35798 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1091 /   36864             (  2.96%) | total_pruned =   35773 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1909 /   73728             (  2.59%) | total_pruned =   71819 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2791 /  147456             (  1.89%) | total_pruned =  144665 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     829 /    8192             ( 10.12%) | total_pruned =    7363 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2460 /  147456             (  1.67%) | total_pruned =  144996 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2523 /  147456             (  1.71%) | total_pruned =  144933 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    5079 /  294912             (  1.72%) | total_pruned =  289833 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      33 /     256             ( 12.89%) | total_pruned =     223 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    7536 /  589824             (  1.28%) | total_pruned =  582288 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1585 /   32768             (  4.84%) | total_pruned =   31183 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   32212 /  589824             (  5.46%) | total_pruned =  557612 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     195 /     256             ( 76.17%) | total_pruned =      61 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   31286 /  589824             (  5.30%) | total_pruned =  558538 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   16011 / 1179648             (  1.36%) | total_pruned = 1163637 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      61 /     512             ( 11.91%) | total_pruned =     451 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   41588 / 2359296             (  1.76%) | total_pruned = 2317708 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     466 /     512             ( 91.02%) | total_pruned =      46 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     106 /     512             ( 20.70%) | total_pruned =     406 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3424 /  131072             (  2.61%) | total_pruned =  127648 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     244 /     512             ( 47.66%) | total_pruned =     268 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  196071 / 2359296             (  8.31%) | total_pruned = 2163225 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     303 /     512             ( 59.18%) | total_pruned =     209 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      76 /     512             ( 14.84%) | total_pruned =     436 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  412783 / 2359296             ( 17.50%) | total_pruned = 1946513 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     100 /     512             ( 19.53%) | total_pruned =     412 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      74 /     512             ( 14.45%) | total_pruned =     438 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
linear.weight        | nonzeros =     462 /    5120             (  9.02%) | total_pruned =    4658 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 768200, pruned : 10410562, total: 11178762, Compression rate :      14.55x  ( 93.13% pruned)
Train Epoch: 25/100 Loss: 0.004096 Accuracy: 84.77 100.00 % Best test Accuracy: 85.05%
tensor(0.0053, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-3.7726e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.965312
Average KL loss: 0.740129
Average total loss: 1.705441
tensor(0.0053, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-8.8254e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.948117
Average KL loss: 0.730515
Average total loss: 1.678632
tensor(0.0053, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-3.5161e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.929165
Average KL loss: 0.732797
Average total loss: 1.661962
tensor(0.0053, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.6778e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.955243
Average KL loss: 0.737347
Average total loss: 1.692590
tensor(0.0053, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-7.5758e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.904900
Average KL loss: 0.741776
Average total loss: 1.646676
tensor(0.0053, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.5220e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.906273
Average KL loss: 0.746082
Average total loss: 1.652355
tensor(0.0053, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.3111e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.901474
Average KL loss: 0.750747
Average total loss: 1.652222
tensor(0.0053, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-6.2382e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.869599
Average KL loss: 0.754998
Average total loss: 1.624597
tensor(0.0054, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.7983e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.870340
Average KL loss: 0.759058
Average total loss: 1.629398
tensor(0.0054, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.6723e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.883114
Average KL loss: 0.762648
Average total loss: 1.645761
tensor(0.0054, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-3.7724e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.877532
Average KL loss: 0.766720
Average total loss: 1.644252
tensor(0.0054, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.5338e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.853477
Average KL loss: 0.770642
Average total loss: 1.624119
tensor(0.0054, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-4.0642e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.837650
Average KL loss: 0.773969
Average total loss: 1.611619
tensor(0.0054, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-8.4059e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.831339
Average KL loss: 0.776819
Average total loss: 1.608158
tensor(0.0054, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.8200e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.808868
Average KL loss: 0.779187
Average total loss: 1.588056
tensor(0.0054, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-6.0336e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.806505
Average KL loss: 0.781381
Average total loss: 1.587886
tensor(0.0054, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.0397e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.815716
Average KL loss: 0.783768
Average total loss: 1.599484
tensor(0.0054, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.5981e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.805432
Average KL loss: 0.786959
Average total loss: 1.592391
tensor(0.0054, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.2916e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.798465
Average KL loss: 0.789496
Average total loss: 1.587961
tensor(0.0055, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.7290e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.802244
Average KL loss: 0.791815
Average total loss: 1.594059
tensor(0.0055, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.8965e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.803910
Average KL loss: 0.794204
Average total loss: 1.598114
tensor(0.0055, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.2674e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.794705
Average KL loss: 0.796460
Average total loss: 1.591166
tensor(0.0055, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(5.5685e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.803867
Average KL loss: 0.798726
Average total loss: 1.602593
tensor(0.0055, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.4369e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.770984
Average KL loss: 0.800776
Average total loss: 1.571760
tensor(0.0055, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.4090e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.780634
Average KL loss: 0.802172
Average total loss: 1.582806
tensor(0.0055, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.1238e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.773118
Average KL loss: 0.803819
Average total loss: 1.576937
tensor(0.0055, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-5.8282e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.767645
Average KL loss: 0.805221
Average total loss: 1.572867
tensor(0.0055, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.6945e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.756654
Average KL loss: 0.806540
Average total loss: 1.563193
tensor(0.0055, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.0780e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.733266
Average KL loss: 0.807735
Average total loss: 1.541001
tensor(0.0055, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-5.2994e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.742398
Average KL loss: 0.808995
Average total loss: 1.551393
tensor(0.0055, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(1.2417e-11, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.739761
Average KL loss: 0.810249
Average total loss: 1.550011
tensor(0.0055, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.5528e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.743215
Average KL loss: 0.811078
Average total loss: 1.554292
tensor(0.0055, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-7.2198e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.745858
Average KL loss: 0.812322
Average total loss: 1.558180
tensor(0.0055, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-7.4550e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.731004
Average KL loss: 0.813100
Average total loss: 1.544103
tensor(0.0055, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-2.1329e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.736565
Average KL loss: 0.813984
Average total loss: 1.550549
tensor(0.0055, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.2508e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.741130
Average KL loss: 0.814998
Average total loss: 1.556128
tensor(0.0055, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-3.8378e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.740273
Average KL loss: 0.816366
Average total loss: 1.556639
tensor(0.0055, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.5481e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.722752
Average KL loss: 0.817413
Average total loss: 1.540165
tensor(0.0055, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.4240e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.732065
Average KL loss: 0.818249
Average total loss: 1.550314
tensor(0.0055, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-2.1012e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.735527
Average KL loss: 0.819353
Average total loss: 1.554880
tensor(0.0055, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(4.6953e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.729612
Average KL loss: 0.820315
Average total loss: 1.549926
tensor(0.0056, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-7.4553e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.718387
Average KL loss: 0.821418
Average total loss: 1.539805
tensor(0.0056, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-5.5261e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.706016
Average KL loss: 0.822034
Average total loss: 1.528050
tensor(0.0056, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(1.6342e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.733217
Average KL loss: 0.823104
Average total loss: 1.556322
tensor(0.0056, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-2.1737e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.710328
Average KL loss: 0.824487
Average total loss: 1.534816
tensor(0.0056, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(1.0634e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.711774
Average KL loss: 0.825270
Average total loss: 1.537044
tensor(0.0056, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-1.1315e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.721178
Average KL loss: 0.826474
Average total loss: 1.547652
tensor(0.0056, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-2.1710e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.687924
Average KL loss: 0.827314
Average total loss: 1.515238
tensor(0.0056, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-2.7708e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.696573
Average KL loss: 0.827678
Average total loss: 1.524250
tensor(0.0056, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-2.3726e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.714065
Average KL loss: 0.828129
Average total loss: 1.542194
tensor(0.0056, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.2791e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.706652
Average KL loss: 0.828941
Average total loss: 1.535593
tensor(0.0056, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(4.0530e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.699095
Average KL loss: 0.829783
Average total loss: 1.528878
tensor(0.0056, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-3.1914e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.684369
Average KL loss: 0.830394
Average total loss: 1.514763
tensor(0.0056, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-1.5517e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.688963
Average KL loss: 0.830566
Average total loss: 1.519529
tensor(0.0056, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-1.0367e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.706914
Average KL loss: 0.831032
Average total loss: 1.537946
tensor(0.0056, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-5.9793e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.699818
Average KL loss: 0.831874
Average total loss: 1.531692
tensor(0.0056, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-1.1531e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.681977
Average KL loss: 0.832354
Average total loss: 1.514331
tensor(0.0056, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-1.7111e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.684382
Average KL loss: 0.832896
Average total loss: 1.517278
tensor(0.0056, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(6.5213e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.689911
Average KL loss: 0.833651
Average total loss: 1.523563
tensor(0.0056, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-1.3093e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.674594
Average KL loss: 0.834530
Average total loss: 1.509124
tensor(0.0056, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-8.1765e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.703404
Average KL loss: 0.835420
Average total loss: 1.538824
tensor(0.0056, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-1.0875e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.683447
Average KL loss: 0.836833
Average total loss: 1.520281
tensor(0.0056, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-1.3119e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.674269
Average KL loss: 0.837253
Average total loss: 1.511521
tensor(0.0056, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-2.0359e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.676510
Average KL loss: 0.837135
Average total loss: 1.513645
tensor(0.0056, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-8.5604e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.683242
Average KL loss: 0.837094
Average total loss: 1.520336
tensor(0.0056, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.6051e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.690661
Average KL loss: 0.837444
Average total loss: 1.528104
tensor(0.0056, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-2.8125e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.681559
Average KL loss: 0.838108
Average total loss: 1.519667
tensor(0.0056, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-1.7335e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.669034
Average KL loss: 0.838657
Average total loss: 1.507690
tensor(0.0056, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-3.4032e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.679917
Average KL loss: 0.839432
Average total loss: 1.519349
tensor(0.0056, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-1.4441e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.678382
Average KL loss: 0.839954
Average total loss: 1.518337
tensor(0.0056, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-5.6639e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.673845
Average KL loss: 0.840534
Average total loss: 1.514378
tensor(0.0056, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-8.5579e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.666490
Average KL loss: 0.840988
Average total loss: 1.507478
tensor(0.0056, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-4.4994e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.687381
Average KL loss: 0.841548
Average total loss: 1.528928
tensor(0.0057, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(1.0071e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.668067
Average KL loss: 0.841893
Average total loss: 1.509960
tensor(0.0057, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(3.1147e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.673689
Average KL loss: 0.842624
Average total loss: 1.516313
tensor(0.0057, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-1.1784e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.674306
Average KL loss: 0.843265
Average total loss: 1.517571
tensor(0.0057, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-4.0894e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.659031
Average KL loss: 0.843428
Average total loss: 1.502459
tensor(0.0057, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(1.4835e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.663579
Average KL loss: 0.843653
Average total loss: 1.507233
tensor(0.0057, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(9.1646e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.653171
Average KL loss: 0.843939
Average total loss: 1.497110
tensor(0.0057, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(7.7509e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.662064
Average KL loss: 0.844022
Average total loss: 1.506085
tensor(0.0057, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-1.0614e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.661806
Average KL loss: 0.843973
Average total loss: 1.505779
tensor(0.0057, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(3.4793e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.661578
Average KL loss: 0.843996
Average total loss: 1.505573
tensor(0.0057, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.3873e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.636561
Average KL loss: 0.844017
Average total loss: 1.480579
tensor(0.0057, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.0296e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.664540
Average KL loss: 0.844491
Average total loss: 1.509031
tensor(0.0057, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-4.7513e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.657475
Average KL loss: 0.844946
Average total loss: 1.502421
tensor(0.0057, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(2.7356e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.647989
Average KL loss: 0.845586
Average total loss: 1.493575
tensor(0.0057, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(1.6117e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.641262
Average KL loss: 0.845850
Average total loss: 1.487112
tensor(0.0057, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-4.6242e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.651957
Average KL loss: 0.846162
Average total loss: 1.498118
tensor(0.0057, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.1853e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.653618
Average KL loss: 0.846560
Average total loss: 1.500178
tensor(0.0057, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(5.0232e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.635826
Average KL loss: 0.846923
Average total loss: 1.482749
tensor(0.0057, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.5298e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.641703
Average KL loss: 0.846995
Average total loss: 1.488698
tensor(0.0057, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(3.1452e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.639634
Average KL loss: 0.846934
Average total loss: 1.486568
tensor(0.0057, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-5.5507e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.640447
Average KL loss: 0.846525
Average total loss: 1.486972
tensor(0.0057, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.1020e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.640247
Average KL loss: 0.846615
Average total loss: 1.486862
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.1433e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.647042
Average KL loss: 0.846906
Average total loss: 1.493948
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(1.6628e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.638872
Average KL loss: 0.846681
Average total loss: 1.485553
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.5788e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.631023
Average KL loss: 0.846457
Average total loss: 1.477480
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.3650e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.644743
Average KL loss: 0.846269
Average total loss: 1.491011
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(2.5667e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.643594
Average KL loss: 0.846067
Average total loss: 1.489660
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.4707e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.640260
Average KL loss: 0.845904
Average total loss: 1.486164
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.2987e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.640557
Average KL loss: 0.845705
Average total loss: 1.486262
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(2.0899e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.649899
Average KL loss: 0.845520
Average total loss: 1.495419
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-5.8170e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.633466
Average KL loss: 0.845360
Average total loss: 1.478826
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.8636e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.636553
Average KL loss: 0.845175
Average total loss: 1.481728
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-6.3715e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.630803
Average KL loss: 0.845006
Average total loss: 1.475808
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.5996e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.642675
Average KL loss: 0.844820
Average total loss: 1.487495
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-4.3913e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.646188
Average KL loss: 0.844654
Average total loss: 1.490843
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-4.1181e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.648199
Average KL loss: 0.844455
Average total loss: 1.492653
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.3202e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.635680
Average KL loss: 0.844316
Average total loss: 1.479996
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.1873e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.632078
Average KL loss: 0.844178
Average total loss: 1.476255
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-7.2463e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.637995
Average KL loss: 0.844028
Average total loss: 1.482023
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(6.2777e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.637300
Average KL loss: 0.843860
Average total loss: 1.481160
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(1.3783e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.617713
Average KL loss: 0.843673
Average total loss: 1.461386
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-6.4756e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.638736
Average KL loss: 0.843475
Average total loss: 1.482211
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.0937e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.638163
Average KL loss: 0.843355
Average total loss: 1.481518
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.0897e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.634036
Average KL loss: 0.843209
Average total loss: 1.477245
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.3295e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.629597
Average KL loss: 0.843016
Average total loss: 1.472613
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.6821e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.645673
Average KL loss: 0.842854
Average total loss: 1.488527
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.5045e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.632002
Average KL loss: 0.842717
Average total loss: 1.474719
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-5.1866e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.628483
Average KL loss: 0.842607
Average total loss: 1.471091
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.8721e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.643803
Average KL loss: 0.842448
Average total loss: 1.486251
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-6.8540e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.631788
Average KL loss: 0.842284
Average total loss: 1.474072
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-7.1879e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.633495
Average KL loss: 0.842156
Average total loss: 1.475651
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-8.9568e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.644630
Average KL loss: 0.842004
Average total loss: 1.486634
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.3370e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.642422
Average KL loss: 0.841941
Average total loss: 1.484363
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.3586e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.640950
Average KL loss: 0.841927
Average total loss: 1.482877
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.3868e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.642112
Average KL loss: 0.841916
Average total loss: 1.484027
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(4.6889e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.650652
Average KL loss: 0.841906
Average total loss: 1.492558
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.8182e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.645125
Average KL loss: 0.841890
Average total loss: 1.487015
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.1909e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.645998
Average KL loss: 0.841876
Average total loss: 1.487874
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.9922e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.642823
Average KL loss: 0.841862
Average total loss: 1.484685
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.1451e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.627740
Average KL loss: 0.841844
Average total loss: 1.469584
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(5.1171e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.626876
Average KL loss: 0.841826
Average total loss: 1.468702
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-9.0167e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.645401
Average KL loss: 0.841810
Average total loss: 1.487211
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(9.1979e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.622563
Average KL loss: 0.841793
Average total loss: 1.464355
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.1944e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.642572
Average KL loss: 0.841784
Average total loss: 1.484355
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.8095e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.633187
Average KL loss: 0.841782
Average total loss: 1.474969
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.2039e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.650570
Average KL loss: 0.841780
Average total loss: 1.492351
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(1.9141e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.641728
Average KL loss: 0.841779
Average total loss: 1.483506
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(4.1043e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.632037
Average KL loss: 0.841777
Average total loss: 1.473814
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(3.6303e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.643797
Average KL loss: 0.841776
Average total loss: 1.485572
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-6.0913e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.633919
Average KL loss: 0.841774
Average total loss: 1.475692
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.9185e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.632091
Average KL loss: 0.841772
Average total loss: 1.473862
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(3.6501e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.637411
Average KL loss: 0.841770
Average total loss: 1.479181
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.1361e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.641769
Average KL loss: 0.841768
Average total loss: 1.483537
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.2815e-08, device='cuda:0')
 Percentile value: 8.112678528959805e-08
Non-zero model percentage: 5.497567176818848%, Non-zero mask percentage: 5.497567176818848%

--- Pruning Level [13/24]: ---
conv1.weight         | nonzeros =     584 /    1728             ( 33.80%) | total_pruned =    1144 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     920 /   36864             (  2.50%) | total_pruned =   35944 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1165 /   36864             (  3.16%) | total_pruned =   35699 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     970 /   36864             (  2.63%) | total_pruned =   35894 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     990 /   36864             (  2.69%) | total_pruned =   35874 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1732 /   73728             (  2.35%) | total_pruned =   71996 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2460 /  147456             (  1.67%) | total_pruned =  144996 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     781 /    8192             (  9.53%) | total_pruned =    7411 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2188 /  147456             (  1.48%) | total_pruned =  145268 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2268 /  147456             (  1.54%) | total_pruned =  145188 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    4440 /  294912             (  1.51%) | total_pruned =  290472 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    6435 /  589824             (  1.09%) | total_pruned =  583389 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      31 /     256             ( 12.11%) | total_pruned =     225 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1382 /   32768             (  4.22%) | total_pruned =   31386 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      33 /     256             ( 12.89%) | total_pruned =     223 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   31427 /  589824             (  5.33%) | total_pruned =  558397 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     190 /     256             ( 74.22%) | total_pruned =      66 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   30401 /  589824             (  5.15%) | total_pruned =  559423 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     218 /     256             ( 85.16%) | total_pruned =      38 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   13915 / 1179648             (  1.18%) | total_pruned = 1165733 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     501 /     512             ( 97.85%) | total_pruned =      11 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      53 /     512             ( 10.35%) | total_pruned =     459 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   37316 / 2359296             (  1.58%) | total_pruned = 2321980 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     459 /     512             ( 89.65%) | total_pruned =      53 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      86 /     512             ( 16.80%) | total_pruned =     426 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2995 /  131072             (  2.29%) | total_pruned =  128077 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      37 /     512             (  7.23%) | total_pruned =     475 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     232 /     512             ( 45.31%) | total_pruned =     280 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      89 /     512             ( 17.38%) | total_pruned =     423 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  190504 / 2359296             (  8.07%) | total_pruned = 2168792 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      49 /     512             (  9.57%) | total_pruned =     463 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     292 /     512             ( 57.03%) | total_pruned =     220 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  276912 / 2359296             ( 11.74%) | total_pruned = 2082384 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      53 /     512             ( 10.35%) | total_pruned =     459 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
linear.weight        | nonzeros =     419 /    5120             (  8.18%) | total_pruned =    4701 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 614560, pruned : 10564202, total: 11178762, Compression rate :      18.19x  ( 94.50% pruned)
Train Epoch: 24/100 Loss: 0.003891 Accuracy: 84.41 100.00 % Best test Accuracy: 84.56%
tensor(0.0057, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.8268e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.859670
Average KL loss: 0.814412
Average total loss: 1.674082
tensor(0.0056, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.9299e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.910443
Average KL loss: 0.805011
Average total loss: 1.715454
tensor(0.0056, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-3.3033e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.883163
Average KL loss: 0.806717
Average total loss: 1.689880
tensor(0.0056, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-6.4192e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.882158
Average KL loss: 0.810082
Average total loss: 1.692241
tensor(0.0056, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.3151e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.844519
Average KL loss: 0.813736
Average total loss: 1.658256
tensor(0.0056, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.8977e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.875883
Average KL loss: 0.817677
Average total loss: 1.693560
tensor(0.0056, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.4785e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.845888
Average KL loss: 0.821382
Average total loss: 1.667270
tensor(0.0056, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.4437e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.847918
Average KL loss: 0.824699
Average total loss: 1.672616
tensor(0.0056, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-3.5358e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.815038
Average KL loss: 0.827997
Average total loss: 1.643035
tensor(0.0056, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-3.1943e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.817778
Average KL loss: 0.831169
Average total loss: 1.648947
tensor(0.0056, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-2.4765e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.810402
Average KL loss: 0.834101
Average total loss: 1.644503
tensor(0.0057, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-5.5656e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.791492
Average KL loss: 0.836948
Average total loss: 1.628440
tensor(0.0057, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-6.7314e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.800005
Average KL loss: 0.839404
Average total loss: 1.639410
tensor(0.0057, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-3.4489e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.768345
Average KL loss: 0.842072
Average total loss: 1.610417
tensor(0.0057, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-3.8575e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.772623
Average KL loss: 0.844234
Average total loss: 1.616857
tensor(0.0057, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-2.5987e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.765321
Average KL loss: 0.846349
Average total loss: 1.611670
tensor(0.0057, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-1.5528e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.771788
Average KL loss: 0.848164
Average total loss: 1.619952
tensor(0.0057, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-4.0241e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.774442
Average KL loss: 0.850450
Average total loss: 1.624892
tensor(0.0057, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(1.5939e-11, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.768756
Average KL loss: 0.852545
Average total loss: 1.621301
tensor(0.0057, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-3.1332e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.773229
Average KL loss: 0.854642
Average total loss: 1.627871
tensor(0.0057, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-9.8150e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.749762
Average KL loss: 0.856518
Average total loss: 1.606280
tensor(0.0057, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-2.0605e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.730944
Average KL loss: 0.858116
Average total loss: 1.589060
tensor(0.0057, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.1220e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.733437
Average KL loss: 0.859735
Average total loss: 1.593172
tensor(0.0058, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.4931e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.742268
Average KL loss: 0.861302
Average total loss: 1.603570
tensor(0.0058, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-1.4954e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.730943
Average KL loss: 0.863032
Average total loss: 1.593975
tensor(0.0058, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-8.4485e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.746567
Average KL loss: 0.864815
Average total loss: 1.611382
tensor(0.0058, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-2.2393e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.749888
Average KL loss: 0.866671
Average total loss: 1.616559
tensor(0.0058, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-8.1748e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.749287
Average KL loss: 0.868637
Average total loss: 1.617924
tensor(0.0058, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-1.7352e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.731518
Average KL loss: 0.870305
Average total loss: 1.601823
tensor(0.0058, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-3.3784e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.709780
Average KL loss: 0.871627
Average total loss: 1.581407
tensor(0.0058, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-2.2329e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.716023
Average KL loss: 0.872538
Average total loss: 1.588561
tensor(0.0058, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.6119e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.713083
Average KL loss: 0.873967
Average total loss: 1.587049
tensor(0.0058, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-2.5273e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.732220
Average KL loss: 0.875535
Average total loss: 1.607755
tensor(0.0058, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-1.1450e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.700357
Average KL loss: 0.876979
Average total loss: 1.577336
tensor(0.0058, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-7.0954e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.700813
Average KL loss: 0.877961
Average total loss: 1.578773
tensor(0.0058, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-6.5061e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.689369
Average KL loss: 0.878926
Average total loss: 1.568295
tensor(0.0058, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-2.6693e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.698221
Average KL loss: 0.879546
Average total loss: 1.577767
tensor(0.0058, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.8347e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.694468
Average KL loss: 0.880385
Average total loss: 1.574853
tensor(0.0059, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.3885e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.679157
Average KL loss: 0.881229
Average total loss: 1.560386
tensor(0.0059, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.2101e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.690622
Average KL loss: 0.882232
Average total loss: 1.572855
tensor(0.0059, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(1.2913e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.688647
Average KL loss: 0.883368
Average total loss: 1.572015
tensor(0.0059, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-2.0827e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.678732
Average KL loss: 0.883791
Average total loss: 1.562523
tensor(0.0059, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.6289e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.702443
Average KL loss: 0.884525
Average total loss: 1.586968
tensor(0.0059, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.5968e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.670062
Average KL loss: 0.885532
Average total loss: 1.555594
tensor(0.0059, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-1.2219e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.658497
Average KL loss: 0.885749
Average total loss: 1.544246
tensor(0.0059, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(2.3533e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.684360
Average KL loss: 0.886261
Average total loss: 1.570622
tensor(0.0059, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(3.0153e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.679240
Average KL loss: 0.886970
Average total loss: 1.566210
tensor(0.0059, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-1.0548e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.676567
Average KL loss: 0.888062
Average total loss: 1.564629
tensor(0.0059, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-2.7160e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.663180
Average KL loss: 0.888561
Average total loss: 1.551741
tensor(0.0059, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.4766e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.665287
Average KL loss: 0.889231
Average total loss: 1.554518
tensor(0.0059, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.0457e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.659481
Average KL loss: 0.890160
Average total loss: 1.549641
tensor(0.0059, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-1.0592e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.676031
Average KL loss: 0.891235
Average total loss: 1.567266
tensor(0.0059, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-1.3202e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.648193
Average KL loss: 0.891729
Average total loss: 1.539923
tensor(0.0059, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-6.5814e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.679610
Average KL loss: 0.892204
Average total loss: 1.571814
tensor(0.0059, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-1.9430e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.672152
Average KL loss: 0.892698
Average total loss: 1.564850
tensor(0.0059, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-3.2537e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.675646
Average KL loss: 0.893544
Average total loss: 1.569190
tensor(0.0059, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-6.3640e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.654734
Average KL loss: 0.893954
Average total loss: 1.548688
tensor(0.0059, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-1.8246e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.657463
Average KL loss: 0.894366
Average total loss: 1.551829
tensor(0.0059, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-1.2050e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.670564
Average KL loss: 0.895033
Average total loss: 1.565597
tensor(0.0059, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-2.6840e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.648477
Average KL loss: 0.895945
Average total loss: 1.544422
tensor(0.0059, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-1.1861e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.683890
Average KL loss: 0.896789
Average total loss: 1.580679
tensor(0.0059, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-3.8319e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.648918
Average KL loss: 0.897760
Average total loss: 1.546678
tensor(0.0060, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(6.4798e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.642981
Average KL loss: 0.898353
Average total loss: 1.541334
tensor(0.0060, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(1.4886e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.658262
Average KL loss: 0.898536
Average total loss: 1.556798
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-2.2604e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.657404
Average KL loss: 0.898850
Average total loss: 1.556253
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.6473e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.641887
Average KL loss: 0.898761
Average total loss: 1.540648
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.5826e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.642896
Average KL loss: 0.898654
Average total loss: 1.541550
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-9.9395e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.646826
Average KL loss: 0.898570
Average total loss: 1.545396
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.3153e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.646092
Average KL loss: 0.898461
Average total loss: 1.544553
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.9141e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.651615
Average KL loss: 0.898352
Average total loss: 1.549967
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(4.8314e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.635620
Average KL loss: 0.898255
Average total loss: 1.533875
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.1128e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.623993
Average KL loss: 0.898132
Average total loss: 1.522124
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-2.0085e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.635159
Average KL loss: 0.897999
Average total loss: 1.533158
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.3983e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.636058
Average KL loss: 0.897864
Average total loss: 1.533922
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(5.7582e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.634933
Average KL loss: 0.897711
Average total loss: 1.532644
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-3.3925e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.642714
Average KL loss: 0.897583
Average total loss: 1.540297
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.3489e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.641284
Average KL loss: 0.897517
Average total loss: 1.538801
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(4.1607e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.630934
Average KL loss: 0.897440
Average total loss: 1.528374
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(5.9922e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.631272
Average KL loss: 0.897354
Average total loss: 1.528626
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.5733e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.624415
Average KL loss: 0.897249
Average total loss: 1.521664
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-9.7833e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.635749
Average KL loss: 0.897162
Average total loss: 1.532911
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-2.7940e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.633498
Average KL loss: 0.897060
Average total loss: 1.530557
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-2.2898e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.618954
Average KL loss: 0.896970
Average total loss: 1.515924
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.7636e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.630441
Average KL loss: 0.896895
Average total loss: 1.527336
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.0229e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.627530
Average KL loss: 0.896830
Average total loss: 1.524361
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.9196e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.634555
Average KL loss: 0.896727
Average total loss: 1.531282
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(4.4594e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.651270
Average KL loss: 0.896636
Average total loss: 1.547906
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.6650e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.646041
Average KL loss: 0.896578
Average total loss: 1.542619
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-3.1313e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.652117
Average KL loss: 0.896526
Average total loss: 1.548644
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(4.1593e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.637764
Average KL loss: 0.896443
Average total loss: 1.534207
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(4.7675e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.654756
Average KL loss: 0.896387
Average total loss: 1.551144
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(1.3913e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.640057
Average KL loss: 0.896341
Average total loss: 1.536398
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-3.1584e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.645770
Average KL loss: 0.896285
Average total loss: 1.542055
tensor(0.0060, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(6.6589e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.622601
Average KL loss: 0.896238
Average total loss: 1.518839
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-3.7374e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.633612
Average KL loss: 0.896218
Average total loss: 1.529831
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.9398e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.646270
Average KL loss: 0.896211
Average total loss: 1.542481
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-4.4445e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.634676
Average KL loss: 0.896205
Average total loss: 1.530881
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-8.2142e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.631157
Average KL loss: 0.896195
Average total loss: 1.527352
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.8046e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.630257
Average KL loss: 0.896188
Average total loss: 1.526445
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.6805e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.665606
Average KL loss: 0.896178
Average total loss: 1.561784
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.0634e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.649491
Average KL loss: 0.896173
Average total loss: 1.545664
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.0479e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.630451
Average KL loss: 0.896167
Average total loss: 1.526618
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-3.3042e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.648469
Average KL loss: 0.896160
Average total loss: 1.544628
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-6.0788e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.638193
Average KL loss: 0.896152
Average total loss: 1.534345
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.0556e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.630886
Average KL loss: 0.896142
Average total loss: 1.527028
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-2.1991e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.653704
Average KL loss: 0.896134
Average total loss: 1.549838
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.4223e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.645922
Average KL loss: 0.896133
Average total loss: 1.542055
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.2127e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.632440
Average KL loss: 0.896133
Average total loss: 1.528573
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.0380e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.649857
Average KL loss: 0.896132
Average total loss: 1.545988
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-6.7001e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.656758
Average KL loss: 0.896131
Average total loss: 1.552889
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-2.6832e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.631552
Average KL loss: 0.896130
Average total loss: 1.527682
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.1233e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.641879
Average KL loss: 0.896129
Average total loss: 1.538008
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(5.8383e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.641195
Average KL loss: 0.896129
Average total loss: 1.537324
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.3743e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.638174
Average KL loss: 0.896128
Average total loss: 1.534302
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-5.0393e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.648032
Average KL loss: 0.896127
Average total loss: 1.544159
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-5.6461e-09, device='cuda:0')
 Percentile value: 7.970604087859101e-08
Non-zero model percentage: 4.398054122924805%, Non-zero mask percentage: 4.398054122924805%

--- Pruning Level [14/24]: ---
conv1.weight         | nonzeros =     572 /    1728             ( 33.10%) | total_pruned =    1156 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     861 /   36864             (  2.34%) | total_pruned =   36003 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1098 /   36864             (  2.98%) | total_pruned =   35766 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     872 /   36864             (  2.37%) | total_pruned =   35992 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     915 /   36864             (  2.48%) | total_pruned =   35949 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1597 /   73728             (  2.17%) | total_pruned =   72131 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2210 /  147456             (  1.50%) | total_pruned =  145246 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     742 /    8192             (  9.06%) | total_pruned =    7450 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1075 /  147456             (  0.73%) | total_pruned =  146381 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1014 /  147456             (  0.69%) | total_pruned =  146442 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    4011 /  294912             (  1.36%) | total_pruned =  290901 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    5663 /  589824             (  0.96%) | total_pruned =  584161 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      28 /     256             ( 10.94%) | total_pruned =     228 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1247 /   32768             (  3.81%) | total_pruned =   31521 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2042 /  589824             (  0.35%) | total_pruned =  587782 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1889 /  589824             (  0.32%) | total_pruned =  587935 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     212 /     256             ( 82.81%) | total_pruned =      44 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    8149 / 1179648             (  0.69%) | total_pruned = 1171499 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    9170 / 2359296             (  0.39%) | total_pruned = 2350126 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     453 /     512             ( 88.48%) | total_pruned =      59 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      75 /     512             ( 14.65%) | total_pruned =     437 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     760 /  131072             (  0.58%) | total_pruned =  130312 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     223 /     512             ( 43.55%) | total_pruned =     289 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      80 /     512             ( 15.62%) | total_pruned =     432 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  167129 / 2359296             (  7.08%) | total_pruned = 2192167 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     285 /     512             ( 55.66%) | total_pruned =     227 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      61 /     512             ( 11.91%) | total_pruned =     451 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  276071 / 2359296             ( 11.70%) | total_pruned = 2083225 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
linear.weight        | nonzeros =     400 /    5120             (  7.81%) | total_pruned =    4720 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 491648, pruned : 10687114, total: 11178762, Compression rate :      22.74x  ( 95.60% pruned)
Train Epoch: 23/100 Loss: 0.001660 Accuracy: 83.70 100.00 % Best test Accuracy: 84.09%
tensor(0.0060, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-4.4023e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.873558
Average KL loss: 0.871170
Average total loss: 1.744727
tensor(0.0058, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-2.0212e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.864193
Average KL loss: 0.863258
Average total loss: 1.727451
tensor(0.0058, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-4.6844e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.859269
Average KL loss: 0.864707
Average total loss: 1.723976
tensor(0.0058, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-6.4841e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.870321
Average KL loss: 0.867728
Average total loss: 1.738049
tensor(0.0058, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-3.6195e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.846765
Average KL loss: 0.871368
Average total loss: 1.718133
tensor(0.0058, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.6277e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.855854
Average KL loss: 0.874695
Average total loss: 1.730549
tensor(0.0058, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-2.7590e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.820416
Average KL loss: 0.878102
Average total loss: 1.698519
tensor(0.0058, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-5.7750e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.830743
Average KL loss: 0.881477
Average total loss: 1.712220
tensor(0.0058, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-4.3324e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.831197
Average KL loss: 0.884345
Average total loss: 1.715543
tensor(0.0058, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-3.8631e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.807157
Average KL loss: 0.887365
Average total loss: 1.694522
tensor(0.0059, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-5.8505e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.787848
Average KL loss: 0.890182
Average total loss: 1.678030
tensor(0.0059, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-3.6416e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.806275
Average KL loss: 0.892927
Average total loss: 1.699201
tensor(0.0059, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-4.2223e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.794048
Average KL loss: 0.895617
Average total loss: 1.689665
tensor(0.0059, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-1.6660e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.772199
Average KL loss: 0.898445
Average total loss: 1.670644
tensor(0.0059, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.4405e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.777308
Average KL loss: 0.900766
Average total loss: 1.678074
tensor(0.0059, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-6.6785e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.771038
Average KL loss: 0.903249
Average total loss: 1.674286
tensor(0.0059, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.9164e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.776903
Average KL loss: 0.905716
Average total loss: 1.682619
tensor(0.0059, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-4.5787e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.766992
Average KL loss: 0.908156
Average total loss: 1.675148
tensor(0.0060, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-3.4319e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.757202
Average KL loss: 0.910211
Average total loss: 1.667414
tensor(0.0060, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-9.6873e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.756371
Average KL loss: 0.912227
Average total loss: 1.668598
tensor(0.0060, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.2926e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.751834
Average KL loss: 0.914257
Average total loss: 1.666090
tensor(0.0060, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-1.2269e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.745166
Average KL loss: 0.915961
Average total loss: 1.661127
tensor(0.0060, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-2.7402e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.732326
Average KL loss: 0.917939
Average total loss: 1.650265
tensor(0.0060, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-1.4748e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.731356
Average KL loss: 0.919859
Average total loss: 1.651215
tensor(0.0060, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.9637e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.757475
Average KL loss: 0.921685
Average total loss: 1.679160
tensor(0.0060, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-5.7975e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.736693
Average KL loss: 0.923487
Average total loss: 1.660180
tensor(0.0060, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-2.9530e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.738273
Average KL loss: 0.925341
Average total loss: 1.663613
tensor(0.0060, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-1.2850e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.710047
Average KL loss: 0.927024
Average total loss: 1.637071
tensor(0.0060, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-1.5344e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.730040
Average KL loss: 0.928056
Average total loss: 1.658095
tensor(0.0061, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-3.0426e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.715423
Average KL loss: 0.929473
Average total loss: 1.644896
tensor(0.0061, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-1.2509e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.731412
Average KL loss: 0.931293
Average total loss: 1.662704
tensor(0.0061, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-1.1889e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.694135
Average KL loss: 0.932531
Average total loss: 1.626666
tensor(0.0061, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-1.3332e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.700149
Average KL loss: 0.933609
Average total loss: 1.633758
tensor(0.0061, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-2.6802e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.689225
Average KL loss: 0.934498
Average total loss: 1.623724
tensor(0.0061, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-1.5422e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.692694
Average KL loss: 0.935347
Average total loss: 1.628041
tensor(0.0061, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.5546e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.685617
Average KL loss: 0.936440
Average total loss: 1.622057
tensor(0.0061, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(5.5692e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.667820
Average KL loss: 0.937159
Average total loss: 1.604979
tensor(0.0061, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-4.3336e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.672656
Average KL loss: 0.938152
Average total loss: 1.610808
tensor(0.0061, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.3468e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.669566
Average KL loss: 0.939055
Average total loss: 1.608621
tensor(0.0061, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-7.2488e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.677359
Average KL loss: 0.939970
Average total loss: 1.617329
tensor(0.0061, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-1.0413e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.680240
Average KL loss: 0.941361
Average total loss: 1.621601
tensor(0.0061, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-2.0548e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.695234
Average KL loss: 0.942877
Average total loss: 1.638111
tensor(0.0061, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-2.0641e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.679719
Average KL loss: 0.944308
Average total loss: 1.624027
tensor(0.0062, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-7.9319e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.672285
Average KL loss: 0.945365
Average total loss: 1.617650
tensor(0.0062, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.6984e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.706303
Average KL loss: 0.946535
Average total loss: 1.652838
tensor(0.0062, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-2.8055e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.661682
Average KL loss: 0.947515
Average total loss: 1.609196
tensor(0.0062, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-7.2761e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.667828
Average KL loss: 0.948199
Average total loss: 1.616027
tensor(0.0062, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-9.6911e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.674639
Average KL loss: 0.949132
Average total loss: 1.623771
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.8714e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.673900
Average KL loss: 0.949311
Average total loss: 1.623211
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.5756e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.667491
Average KL loss: 0.949277
Average total loss: 1.616768
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.8630e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.661583
Average KL loss: 0.949235
Average total loss: 1.610818
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-3.2619e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.671712
Average KL loss: 0.949193
Average total loss: 1.620905
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-9.7581e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.660370
Average KL loss: 0.949133
Average total loss: 1.609502
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.0971e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.655063
Average KL loss: 0.949057
Average total loss: 1.604120
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.3532e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.634747
Average KL loss: 0.948966
Average total loss: 1.583713
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.3263e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.656944
Average KL loss: 0.948914
Average total loss: 1.605859
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.2521e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.658731
Average KL loss: 0.948916
Average total loss: 1.607646
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.8027e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.664487
Average KL loss: 0.948884
Average total loss: 1.613372
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.6985e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.669121
Average KL loss: 0.948875
Average total loss: 1.617996
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.3045e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.654963
Average KL loss: 0.948835
Average total loss: 1.603797
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-4.1355e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.656133
Average KL loss: 0.948770
Average total loss: 1.604903
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.9303e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.644603
Average KL loss: 0.948726
Average total loss: 1.593329
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.1761e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.650530
Average KL loss: 0.948651
Average total loss: 1.599181
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.2073e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.652953
Average KL loss: 0.948600
Average total loss: 1.601553
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.5998e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.655912
Average KL loss: 0.948571
Average total loss: 1.604482
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.6083e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.652262
Average KL loss: 0.948553
Average total loss: 1.600814
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.8931e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.660748
Average KL loss: 0.948544
Average total loss: 1.609292
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-8.8739e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.657308
Average KL loss: 0.948540
Average total loss: 1.605848
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.4758e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.661798
Average KL loss: 0.948538
Average total loss: 1.610335
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-3.1526e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.652918
Average KL loss: 0.948533
Average total loss: 1.601450
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.1081e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.638741
Average KL loss: 0.948527
Average total loss: 1.587268
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-6.9364e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.647178
Average KL loss: 0.948524
Average total loss: 1.595702
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.4171e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.656229
Average KL loss: 0.948520
Average total loss: 1.604748
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(9.1414e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.649997
Average KL loss: 0.948517
Average total loss: 1.598514
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-7.2574e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.662900
Average KL loss: 0.948512
Average total loss: 1.611412
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.2367e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.637099
Average KL loss: 0.948510
Average total loss: 1.585609
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-8.2528e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.664285
Average KL loss: 0.948503
Average total loss: 1.612788
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.3639e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.640318
Average KL loss: 0.948502
Average total loss: 1.588820
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-7.2345e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.672642
Average KL loss: 0.948502
Average total loss: 1.621144
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.0813e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.652570
Average KL loss: 0.948501
Average total loss: 1.601071
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-6.6619e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.635895
Average KL loss: 0.948501
Average total loss: 1.584396
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.4433e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.646216
Average KL loss: 0.948501
Average total loss: 1.594717
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(2.8291e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.621830
Average KL loss: 0.948500
Average total loss: 1.570330
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(1.0890e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.652731
Average KL loss: 0.948500
Average total loss: 1.601231
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-8.0507e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.671515
Average KL loss: 0.948500
Average total loss: 1.620014
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-3.0469e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.658229
Average KL loss: 0.948499
Average total loss: 1.606728
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.4577e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.652304
Average KL loss: 0.948499
Average total loss: 1.600803
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-4.3647e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.650417
Average KL loss: 0.948499
Average total loss: 1.598916
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.9528e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.657723
Average KL loss: 0.948499
Average total loss: 1.606221
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.0979e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.645423
Average KL loss: 0.948498
Average total loss: 1.593922
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.7003e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.669263
Average KL loss: 0.948498
Average total loss: 1.617761
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(5.3925e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.656125
Average KL loss: 0.948498
Average total loss: 1.604623
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.4271e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.647846
Average KL loss: 0.948498
Average total loss: 1.596343
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(7.5642e-09, device='cuda:0')
 Percentile value: 7.989838479716127e-08
Non-zero model percentage: 3.5184483528137207%, Non-zero mask percentage: 3.5184483528137207%

--- Pruning Level [15/24]: ---
conv1.weight         | nonzeros =     561 /    1728             ( 32.47%) | total_pruned =    1167 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     823 /   36864             (  2.23%) | total_pruned =   36041 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1057 /   36864             (  2.87%) | total_pruned =   35807 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     823 /   36864             (  2.23%) | total_pruned =   36041 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     871 /   36864             (  2.36%) | total_pruned =   35993 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1502 /   73728             (  2.04%) | total_pruned =   72226 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2064 /  147456             (  1.40%) | total_pruned =  145392 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     714 /    8192             (  8.72%) | total_pruned =    7478 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     977 /  147456             (  0.66%) | total_pruned =  146479 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     928 /  147456             (  0.63%) | total_pruned =  146528 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3676 /  294912             (  1.25%) | total_pruned =  291236 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    5107 /  589824             (  0.87%) | total_pruned =  584717 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1171 /   32768             (  3.57%) | total_pruned =   31597 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1760 /  589824             (  0.30%) | total_pruned =  588064 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     184 /     256             ( 71.88%) | total_pruned =      72 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1627 /  589824             (  0.28%) | total_pruned =  588197 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    7209 / 1179648             (  0.61%) | total_pruned = 1172439 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    7648 / 2359296             (  0.32%) | total_pruned = 2351648 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     449 /     512             ( 87.70%) | total_pruned =      63 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      69 /     512             ( 13.48%) | total_pruned =     443 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     675 /  131072             (  0.51%) | total_pruned =  130397 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     220 /     512             ( 42.97%) | total_pruned =     292 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      69 /     512             ( 13.48%) | total_pruned =     443 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   74457 / 2359296             (  3.16%) | total_pruned = 2284839 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     281 /     512             ( 54.88%) | total_pruned =     231 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      59 /     512             ( 11.52%) | total_pruned =     453 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  275166 / 2359296             ( 11.66%) | total_pruned = 2084130 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
linear.weight        | nonzeros =     395 /    5120             (  7.71%) | total_pruned =    4725 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 393319, pruned : 10785443, total: 11178762, Compression rate :      28.42x  ( 96.48% pruned)
Train Epoch: 23/100 Loss: 0.006420 Accuracy: 83.53 100.00 % Best test Accuracy: 83.77%
tensor(0.0062, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.4879e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.798398
Average KL loss: 0.922949
Average total loss: 1.721347
tensor(0.0060, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-3.4233e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.830463
Average KL loss: 0.914391
Average total loss: 1.744854
tensor(0.0060, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-3.1055e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.873649
Average KL loss: 0.914900
Average total loss: 1.788549
tensor(0.0060, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.6639e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.819417
Average KL loss: 0.916817
Average total loss: 1.736234
tensor(0.0060, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.6764e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.850595
Average KL loss: 0.919202
Average total loss: 1.769797
tensor(0.0060, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.3895e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.823086
Average KL loss: 0.921752
Average total loss: 1.744838
tensor(0.0060, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-4.4649e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.804265
Average KL loss: 0.924552
Average total loss: 1.728816
tensor(0.0060, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(2.7512e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.837469
Average KL loss: 0.927447
Average total loss: 1.764915
tensor(0.0060, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-2.3366e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.802627
Average KL loss: 0.930096
Average total loss: 1.732722
tensor(0.0060, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.1129e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.786895
Average KL loss: 0.932988
Average total loss: 1.719882
tensor(0.0060, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.3123e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.779801
Average KL loss: 0.935511
Average total loss: 1.715313
tensor(0.0060, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-3.1326e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.775410
Average KL loss: 0.937909
Average total loss: 1.713319
tensor(0.0061, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-3.6383e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.771548
Average KL loss: 0.940189
Average total loss: 1.711737
tensor(0.0061, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-3.3341e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.763441
Average KL loss: 0.942342
Average total loss: 1.705783
tensor(0.0061, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-2.9433e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.764666
Average KL loss: 0.944302
Average total loss: 1.708968
tensor(0.0061, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-1.8864e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.764989
Average KL loss: 0.946259
Average total loss: 1.711247
tensor(0.0061, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-1.2554e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.765050
Average KL loss: 0.948643
Average total loss: 1.713693
tensor(0.0061, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-3.4087e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.743170
Average KL loss: 0.950646
Average total loss: 1.693817
tensor(0.0061, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-3.5147e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.748906
Average KL loss: 0.952546
Average total loss: 1.701452
tensor(0.0061, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-2.1674e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.714027
Average KL loss: 0.954192
Average total loss: 1.668219
tensor(0.0061, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-1.7738e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.749301
Average KL loss: 0.955694
Average total loss: 1.704995
tensor(0.0061, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-3.0300e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.723538
Average KL loss: 0.957568
Average total loss: 1.681106
tensor(0.0062, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-2.5121e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.708598
Average KL loss: 0.959288
Average total loss: 1.667886
tensor(0.0062, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-3.7928e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.719772
Average KL loss: 0.960719
Average total loss: 1.680491
tensor(0.0062, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.1858e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.701677
Average KL loss: 0.962097
Average total loss: 1.663774
tensor(0.0062, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-8.4076e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.697667
Average KL loss: 0.963487
Average total loss: 1.661153
tensor(0.0062, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(1.0006e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.705500
Average KL loss: 0.964985
Average total loss: 1.670486
tensor(0.0062, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-1.6959e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.691972
Average KL loss: 0.966513
Average total loss: 1.658485
tensor(0.0062, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-3.0091e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.691969
Average KL loss: 0.967867
Average total loss: 1.659836
tensor(0.0062, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-2.2110e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.700885
Average KL loss: 0.969292
Average total loss: 1.670177
tensor(0.0062, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.6480e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.700107
Average KL loss: 0.970898
Average total loss: 1.671005
tensor(0.0062, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-1.5888e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.677347
Average KL loss: 0.972291
Average total loss: 1.649638
tensor(0.0062, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.3512e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.689161
Average KL loss: 0.973654
Average total loss: 1.662815
tensor(0.0063, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.6698e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.667408
Average KL loss: 0.974746
Average total loss: 1.642154
tensor(0.0063, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-9.7300e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.669841
Average KL loss: 0.975441
Average total loss: 1.645282
tensor(0.0063, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-9.1514e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.659392
Average KL loss: 0.976326
Average total loss: 1.635718
tensor(0.0063, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-1.1348e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.672431
Average KL loss: 0.977324
Average total loss: 1.649756
tensor(0.0063, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-2.4766e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.655714
Average KL loss: 0.978748
Average total loss: 1.634462
tensor(0.0063, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-2.6460e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.681660
Average KL loss: 0.979460
Average total loss: 1.661120
tensor(0.0063, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-6.0889e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.663972
Average KL loss: 0.980521
Average total loss: 1.644493
tensor(0.0063, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-3.6712e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.674576
Average KL loss: 0.981948
Average total loss: 1.656524
tensor(0.0063, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-1.1179e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.672904
Average KL loss: 0.983352
Average total loss: 1.656255
tensor(0.0063, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-1.8577e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.658709
Average KL loss: 0.984975
Average total loss: 1.643684
tensor(0.0063, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.4560e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.629699
Average KL loss: 0.985810
Average total loss: 1.615509
tensor(0.0063, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-2.4023e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.640722
Average KL loss: 0.986295
Average total loss: 1.627017
tensor(0.0063, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.6157e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.645340
Average KL loss: 0.987100
Average total loss: 1.632439
tensor(0.0064, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-7.1417e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.656367
Average KL loss: 0.987901
Average total loss: 1.644269
tensor(0.0064, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-3.9552e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.665805
Average KL loss: 0.988566
Average total loss: 1.654371
tensor(0.0064, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-5.9470e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.638511
Average KL loss: 0.989320
Average total loss: 1.627832
tensor(0.0064, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.8633e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.644918
Average KL loss: 0.990134
Average total loss: 1.635052
tensor(0.0064, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(1.1166e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.632890
Average KL loss: 0.991063
Average total loss: 1.623954
tensor(0.0064, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-7.0803e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.629799
Average KL loss: 0.991920
Average total loss: 1.621719
tensor(0.0064, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-1.3822e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.643854
Average KL loss: 0.992767
Average total loss: 1.636621
tensor(0.0064, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-1.1024e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.618217
Average KL loss: 0.993647
Average total loss: 1.611864
tensor(0.0064, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-1.8959e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.626020
Average KL loss: 0.994417
Average total loss: 1.620438
tensor(0.0064, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-3.3201e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.607438
Average KL loss: 0.995086
Average total loss: 1.602523
tensor(0.0064, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-9.6868e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.630046
Average KL loss: 0.995462
Average total loss: 1.625508
tensor(0.0064, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(3.5881e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.628074
Average KL loss: 0.996090
Average total loss: 1.624164
tensor(0.0064, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-2.2901e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.619193
Average KL loss: 0.996702
Average total loss: 1.615895
tensor(0.0064, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-2.6842e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.608963
Average KL loss: 0.997318
Average total loss: 1.606281
tensor(0.0064, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-2.2385e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.598444
Average KL loss: 0.997852
Average total loss: 1.596296
tensor(0.0064, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-2.0256e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.612901
Average KL loss: 0.998402
Average total loss: 1.611303
tensor(0.0064, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-1.8801e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.618764
Average KL loss: 0.999440
Average total loss: 1.618204
tensor(0.0065, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(1.5451e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.603086
Average KL loss: 1.000108
Average total loss: 1.603194
tensor(0.0065, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-1.0567e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.615187
Average KL loss: 1.000612
Average total loss: 1.615799
tensor(0.0065, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-2.5015e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.597486
Average KL loss: 1.001022
Average total loss: 1.598508
tensor(0.0065, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.4876e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.611873
Average KL loss: 1.001536
Average total loss: 1.613409
tensor(0.0065, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-2.4006e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.599452
Average KL loss: 1.002285
Average total loss: 1.601737
tensor(0.0065, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-2.0913e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.595807
Average KL loss: 1.002967
Average total loss: 1.598774
tensor(0.0065, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-3.8084e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.591737
Average KL loss: 1.003567
Average total loss: 1.595304
tensor(0.0065, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-2.0544e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.605241
Average KL loss: 1.004344
Average total loss: 1.609585
tensor(0.0065, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.6402e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.589533
Average KL loss: 1.004829
Average total loss: 1.594361
tensor(0.0065, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-7.7004e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.615189
Average KL loss: 1.005381
Average total loss: 1.620570
tensor(0.0065, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(1.3218e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.588724
Average KL loss: 1.006058
Average total loss: 1.594781
tensor(0.0065, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.5529e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.615430
Average KL loss: 1.006724
Average total loss: 1.622154
tensor(0.0065, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.7089e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.604307
Average KL loss: 1.007558
Average total loss: 1.611865
tensor(0.0065, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.6762e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.598634
Average KL loss: 1.008532
Average total loss: 1.607166
tensor(0.0065, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(4.9406e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.586863
Average KL loss: 1.009028
Average total loss: 1.595891
tensor(0.0065, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-2.4786e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.580137
Average KL loss: 1.009674
Average total loss: 1.589811
tensor(0.0065, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-6.9488e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.572420
Average KL loss: 1.009872
Average total loss: 1.582292
tensor(0.0065, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-1.4523e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.581908
Average KL loss: 1.010329
Average total loss: 1.592236
tensor(0.0066, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-8.9471e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.570412
Average KL loss: 1.010816
Average total loss: 1.581227
tensor(0.0066, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(1.6564e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.606806
Average KL loss: 1.010961
Average total loss: 1.617767
tensor(0.0066, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(2.8653e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.589076
Average KL loss: 1.011490
Average total loss: 1.600566
tensor(0.0066, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(6.1265e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.564067
Average KL loss: 1.011748
Average total loss: 1.575815
tensor(0.0066, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-2.1100e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.585175
Average KL loss: 1.012045
Average total loss: 1.597220
tensor(0.0066, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(1.3803e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.568817
Average KL loss: 1.012187
Average total loss: 1.581004
tensor(0.0066, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(1.2143e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.575189
Average KL loss: 1.012348
Average total loss: 1.587537
tensor(0.0066, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(8.1060e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.583377
Average KL loss: 1.012874
Average total loss: 1.596251
tensor(0.0066, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-1.1909e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.557079
Average KL loss: 1.013198
Average total loss: 1.570276
tensor(0.0066, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(5.7911e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.573534
Average KL loss: 1.013452
Average total loss: 1.586986
tensor(0.0066, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-5.9844e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.574901
Average KL loss: 1.013946
Average total loss: 1.588847
tensor(0.0066, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-2.6892e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.549894
Average KL loss: 1.014357
Average total loss: 1.564252
tensor(0.0066, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-1.6311e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.570234
Average KL loss: 1.014898
Average total loss: 1.585132
tensor(0.0066, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-1.4683e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.567368
Average KL loss: 1.015137
Average total loss: 1.582505
tensor(0.0066, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-5.1808e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.552904
Average KL loss: 1.015352
Average total loss: 1.568256
tensor(0.0066, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-4.9207e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.560094
Average KL loss: 1.015541
Average total loss: 1.575635
tensor(0.0066, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-1.2809e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.559424
Average KL loss: 1.016288
Average total loss: 1.575712
tensor(0.0066, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(5.4828e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.564299
Average KL loss: 1.016724
Average total loss: 1.581023
tensor(0.0066, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-9.7761e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.561407
Average KL loss: 1.017274
Average total loss: 1.578681
tensor(0.0066, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-2.5079e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.552038
Average KL loss: 1.017715
Average total loss: 1.569753
tensor(0.0066, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-1.0606e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.556481
Average KL loss: 1.017668
Average total loss: 1.574149
tensor(0.0067, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-1.2723e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.557713
Average KL loss: 1.018038
Average total loss: 1.575750
tensor(0.0067, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-2.0655e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.552099
Average KL loss: 1.018195
Average total loss: 1.570295
tensor(0.0067, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-1.8875e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.566847
Average KL loss: 1.018320
Average total loss: 1.585167
tensor(0.0067, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-9.8498e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.572037
Average KL loss: 1.018297
Average total loss: 1.590333
tensor(0.0067, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-2.0683e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.546796
Average KL loss: 1.018216
Average total loss: 1.565013
tensor(0.0067, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-2.7523e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.569786
Average KL loss: 1.018130
Average total loss: 1.587916
tensor(0.0067, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-5.0191e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.558867
Average KL loss: 1.018109
Average total loss: 1.576976
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(6.4035e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.567838
Average KL loss: 1.018052
Average total loss: 1.585890
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.5928e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.550664
Average KL loss: 1.018014
Average total loss: 1.568677
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(8.1612e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.543993
Average KL loss: 1.017990
Average total loss: 1.561984
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(8.4240e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.536452
Average KL loss: 1.017938
Average total loss: 1.554390
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-3.2945e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.550935
Average KL loss: 1.017881
Average total loss: 1.568816
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-8.3795e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.547383
Average KL loss: 1.017812
Average total loss: 1.565195
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.9079e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.528853
Average KL loss: 1.017761
Average total loss: 1.546613
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-6.6198e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.546934
Average KL loss: 1.017709
Average total loss: 1.564643
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-3.0896e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.547184
Average KL loss: 1.017656
Average total loss: 1.564840
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.2528e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.550324
Average KL loss: 1.017604
Average total loss: 1.567929
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-3.5852e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.561309
Average KL loss: 1.017574
Average total loss: 1.578883
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(2.8100e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.559987
Average KL loss: 1.017545
Average total loss: 1.577532
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.4730e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.549134
Average KL loss: 1.017484
Average total loss: 1.566618
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(9.3828e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.553782
Average KL loss: 1.017456
Average total loss: 1.571238
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-8.2357e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.552712
Average KL loss: 1.017407
Average total loss: 1.570120
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-7.0176e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.569122
Average KL loss: 1.017358
Average total loss: 1.586480
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(2.3465e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.569045
Average KL loss: 1.017353
Average total loss: 1.586398
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-2.5774e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.548858
Average KL loss: 1.017352
Average total loss: 1.566210
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(3.5447e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.541295
Average KL loss: 1.017319
Average total loss: 1.558615
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-3.0740e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.562803
Average KL loss: 1.017311
Average total loss: 1.580114
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(8.4478e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.539165
Average KL loss: 1.017305
Average total loss: 1.556470
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-4.7673e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.525967
Average KL loss: 1.017299
Average total loss: 1.543266
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(5.8795e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.541370
Average KL loss: 1.017289
Average total loss: 1.558659
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.7912e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.550212
Average KL loss: 1.017280
Average total loss: 1.567492
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.2261e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.542869
Average KL loss: 1.017275
Average total loss: 1.560144
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-2.9895e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.552641
Average KL loss: 1.017266
Average total loss: 1.569907
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-2.9018e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.549507
Average KL loss: 1.017257
Average total loss: 1.566764
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-9.5797e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.554606
Average KL loss: 1.017251
Average total loss: 1.571857
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-5.0342e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.548239
Average KL loss: 1.017244
Average total loss: 1.565483
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.7264e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.552186
Average KL loss: 1.017238
Average total loss: 1.569424
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.3034e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.541815
Average KL loss: 1.017232
Average total loss: 1.559047
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-6.3113e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.539846
Average KL loss: 1.017224
Average total loss: 1.557070
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-6.3755e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.562171
Average KL loss: 1.017215
Average total loss: 1.579386
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-5.3676e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.546831
Average KL loss: 1.017212
Average total loss: 1.564043
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-6.1592e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.578098
Average KL loss: 1.017212
Average total loss: 1.595310
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.5382e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.554395
Average KL loss: 1.017211
Average total loss: 1.571606
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-6.9838e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.549264
Average KL loss: 1.017211
Average total loss: 1.566475
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(5.0517e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.551997
Average KL loss: 1.017210
Average total loss: 1.569206
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.0634e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.552942
Average KL loss: 1.017209
Average total loss: 1.570151
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.5580e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.550901
Average KL loss: 1.017209
Average total loss: 1.568110
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(8.4214e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.549691
Average KL loss: 1.017208
Average total loss: 1.566899
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.6970e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.544850
Average KL loss: 1.017207
Average total loss: 1.562058
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(3.3856e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.545844
Average KL loss: 1.017207
Average total loss: 1.563051
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.6966e-08, device='cuda:0')
 Percentile value: 7.970204052298868e-08
Non-zero model percentage: 2.8147659301757812%, Non-zero mask percentage: 2.8147659301757812%

--- Pruning Level [16/24]: ---
conv1.weight         | nonzeros =     549 /    1728             ( 31.77%) | total_pruned =    1179 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     792 /   36864             (  2.15%) | total_pruned =   36072 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1016 /   36864             (  2.76%) | total_pruned =   35848 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     791 /   36864             (  2.15%) | total_pruned =   36073 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     835 /   36864             (  2.27%) | total_pruned =   36029 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1435 /   73728             (  1.95%) | total_pruned =   72293 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1944 /  147456             (  1.32%) | total_pruned =  145512 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     689 /    8192             (  8.41%) | total_pruned =    7503 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     898 /  147456             (  0.61%) | total_pruned =  146558 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     861 /  147456             (  0.58%) | total_pruned =  146595 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3419 /  294912             (  1.16%) | total_pruned =  291493 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    4714 /  589824             (  0.80%) | total_pruned =  585110 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1123 /   32768             (  3.43%) | total_pruned =   31645 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1558 /  589824             (  0.26%) | total_pruned =  588266 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     183 /     256             ( 71.48%) | total_pruned =      73 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1448 /  589824             (  0.25%) | total_pruned =  588376 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    6510 / 1179648             (  0.55%) | total_pruned = 1173138 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      35 /     512             (  6.84%) | total_pruned =     477 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    6616 / 2359296             (  0.28%) | total_pruned = 2352680 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     446 /     512             ( 87.11%) | total_pruned =      66 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      63 /     512             ( 12.30%) | total_pruned =     449 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     615 /  131072             (  0.47%) | total_pruned =  130457 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     213 /     512             ( 41.60%) | total_pruned =     299 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      59 /     512             ( 11.52%) | total_pruned =     453 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3810 / 2359296             (  0.16%) | total_pruned = 2355486 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     272 /     512             ( 53.12%) | total_pruned =     240 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  270688 / 2359296             ( 11.47%) | total_pruned = 2088608 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
linear.weight        | nonzeros =     385 /    5120             (  7.52%) | total_pruned =    4735 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 314656, pruned : 10864106, total: 11178762, Compression rate :      35.53x  ( 97.19% pruned)
Train Epoch: 23/100 Loss: 0.023757 Accuracy: 83.33 99.97 % Best test Accuracy: 83.51%
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-2.2579e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.730169
Average KL loss: 0.992932
Average total loss: 1.723101
tensor(0.0064, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-4.7876e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.731959
Average KL loss: 0.983590
Average total loss: 1.715549
tensor(0.0064, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-2.8872e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.754433
Average KL loss: 0.982713
Average total loss: 1.737145
tensor(0.0063, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-1.9039e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.762365
Average KL loss: 0.984306
Average total loss: 1.746672
tensor(0.0063, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-2.1546e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.728151
Average KL loss: 0.986460
Average total loss: 1.714611
tensor(0.0063, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-4.2545e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.732960
Average KL loss: 0.989009
Average total loss: 1.721970
tensor(0.0063, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-2.1105e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.728407
Average KL loss: 0.991522
Average total loss: 1.719929
tensor(0.0064, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.7492e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.701322
Average KL loss: 0.994003
Average total loss: 1.695325
tensor(0.0064, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-2.0478e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.720792
Average KL loss: 0.996198
Average total loss: 1.716990
tensor(0.0064, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-2.8356e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.699893
Average KL loss: 0.998536
Average total loss: 1.698428
tensor(0.0064, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-2.9612e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.741334
Average KL loss: 1.001048
Average total loss: 1.742382
tensor(0.0064, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-2.6643e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.689144
Average KL loss: 1.003183
Average total loss: 1.692327
tensor(0.0064, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-2.5342e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.684493
Average KL loss: 1.005197
Average total loss: 1.689691
tensor(0.0064, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-2.0866e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.679594
Average KL loss: 1.007169
Average total loss: 1.686763
tensor(0.0064, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-7.0871e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.677676
Average KL loss: 1.009270
Average total loss: 1.686945
tensor(0.0065, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-1.9649e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.678140
Average KL loss: 1.011030
Average total loss: 1.689170
tensor(0.0065, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-1.5010e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.667779
Average KL loss: 1.012861
Average total loss: 1.680641
tensor(0.0065, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-5.3257e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.682501
Average KL loss: 1.014563
Average total loss: 1.697064
tensor(0.0065, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-2.8783e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.650608
Average KL loss: 1.015931
Average total loss: 1.666539
tensor(0.0065, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-3.6875e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.656225
Average KL loss: 1.017492
Average total loss: 1.673716
tensor(0.0065, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-4.9642e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.649714
Average KL loss: 1.018938
Average total loss: 1.668653
tensor(0.0065, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-1.3030e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.655211
Average KL loss: 1.020024
Average total loss: 1.675234
tensor(0.0065, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-4.2300e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.634337
Average KL loss: 1.021595
Average total loss: 1.655931
tensor(0.0065, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-2.9309e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.634419
Average KL loss: 1.022968
Average total loss: 1.657387
tensor(0.0065, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-4.7673e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.631991
Average KL loss: 1.024132
Average total loss: 1.656123
tensor(0.0066, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.0632e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.645274
Average KL loss: 1.025356
Average total loss: 1.670630
tensor(0.0066, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.2611e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.609075
Average KL loss: 1.026308
Average total loss: 1.635383
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.4695e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.620186
Average KL loss: 1.027072
Average total loss: 1.647258
tensor(0.0066, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-1.3977e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.619945
Average KL loss: 1.028354
Average total loss: 1.648299
tensor(0.0066, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-2.0330e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.623243
Average KL loss: 1.029464
Average total loss: 1.652707
tensor(0.0066, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-2.7620e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.608174
Average KL loss: 1.030829
Average total loss: 1.639002
tensor(0.0066, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-5.1953e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.602210
Average KL loss: 1.031877
Average total loss: 1.634087
tensor(0.0066, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-4.0062e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.608501
Average KL loss: 1.032810
Average total loss: 1.641311
tensor(0.0066, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-2.8690e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.605629
Average KL loss: 1.033711
Average total loss: 1.639340
tensor(0.0066, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(9.4935e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.604957
Average KL loss: 1.034895
Average total loss: 1.639851
tensor(0.0066, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-4.7821e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.597081
Average KL loss: 1.036167
Average total loss: 1.633248
tensor(0.0066, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-5.3974e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.600088
Average KL loss: 1.037235
Average total loss: 1.637323
tensor(0.0067, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-2.0320e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.618841
Average KL loss: 1.038056
Average total loss: 1.656897
tensor(0.0067, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-6.5162e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.583038
Average KL loss: 1.039047
Average total loss: 1.622086
tensor(0.0067, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-3.5026e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.596074
Average KL loss: 1.039999
Average total loss: 1.636073
tensor(0.0067, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-5.3997e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.568088
Average KL loss: 1.040677
Average total loss: 1.608765
tensor(0.0067, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-1.0849e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.580638
Average KL loss: 1.041238
Average total loss: 1.621876
tensor(0.0067, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-1.5658e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.577189
Average KL loss: 1.041701
Average total loss: 1.618890
tensor(0.0067, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-4.7646e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.576640
Average KL loss: 1.042376
Average total loss: 1.619017
tensor(0.0067, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-7.2894e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.578211
Average KL loss: 1.042915
Average total loss: 1.621126
tensor(0.0067, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-9.0008e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.572594
Average KL loss: 1.043568
Average total loss: 1.616161
tensor(0.0067, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-2.2788e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.561853
Average KL loss: 1.044397
Average total loss: 1.606251
tensor(0.0067, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-1.3111e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.587774
Average KL loss: 1.044956
Average total loss: 1.632730
tensor(0.0067, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-1.3134e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.565732
Average KL loss: 1.045758
Average total loss: 1.611490
tensor(0.0067, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(5.2391e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.567360
Average KL loss: 1.046519
Average total loss: 1.613879
tensor(0.0067, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-2.8990e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.565835
Average KL loss: 1.047443
Average total loss: 1.613278
tensor(0.0067, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-5.0905e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.571123
Average KL loss: 1.047922
Average total loss: 1.619045
tensor(0.0067, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-1.5015e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.560082
Average KL loss: 1.048486
Average total loss: 1.608568
tensor(0.0068, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-1.1481e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.580472
Average KL loss: 1.049319
Average total loss: 1.629790
tensor(0.0068, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.2230e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.559443
Average KL loss: 1.049781
Average total loss: 1.609224
tensor(0.0068, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-1.5023e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.571959
Average KL loss: 1.050582
Average total loss: 1.622541
tensor(0.0068, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-2.5260e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.550582
Average KL loss: 1.051175
Average total loss: 1.601757
tensor(0.0068, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-3.0364e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.558524
Average KL loss: 1.051594
Average total loss: 1.610117
tensor(0.0068, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-2.3048e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.556818
Average KL loss: 1.052055
Average total loss: 1.608873
tensor(0.0068, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.8241e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.533176
Average KL loss: 1.052446
Average total loss: 1.585622
tensor(0.0068, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.0986e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.531046
Average KL loss: 1.053033
Average total loss: 1.584080
tensor(0.0068, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(4.8770e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.544722
Average KL loss: 1.053361
Average total loss: 1.598083
tensor(0.0068, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-3.0319e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.540548
Average KL loss: 1.053886
Average total loss: 1.594434
tensor(0.0068, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-3.3756e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.560812
Average KL loss: 1.054298
Average total loss: 1.615110
tensor(0.0068, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(9.9677e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.542647
Average KL loss: 1.055001
Average total loss: 1.597648
tensor(0.0068, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-8.0579e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.540948
Average KL loss: 1.055407
Average total loss: 1.596355
tensor(0.0068, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(2.7922e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.546105
Average KL loss: 1.055923
Average total loss: 1.602028
tensor(0.0068, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(1.8828e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.540873
Average KL loss: 1.056428
Average total loss: 1.597301
tensor(0.0068, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-1.7134e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.553789
Average KL loss: 1.057221
Average total loss: 1.611009
tensor(0.0068, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.4831e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.536412
Average KL loss: 1.057926
Average total loss: 1.594338
tensor(0.0069, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.1122e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.546156
Average KL loss: 1.058473
Average total loss: 1.604629
tensor(0.0069, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(3.1359e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.528408
Average KL loss: 1.059115
Average total loss: 1.587523
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-5.2716e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.542678
Average KL loss: 1.059330
Average total loss: 1.602008
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(4.1702e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.536100
Average KL loss: 1.059282
Average total loss: 1.595381
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.2611e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.519875
Average KL loss: 1.059260
Average total loss: 1.579135
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-6.3627e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.515518
Average KL loss: 1.059239
Average total loss: 1.574758
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.6220e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.525307
Average KL loss: 1.059214
Average total loss: 1.584521
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.5863e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.539534
Average KL loss: 1.059193
Average total loss: 1.598727
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-4.4881e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.528584
Average KL loss: 1.059142
Average total loss: 1.587726
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-2.5307e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.543383
Average KL loss: 1.059136
Average total loss: 1.602519
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.9498e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.526561
Average KL loss: 1.059125
Average total loss: 1.585686
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.7887e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.527590
Average KL loss: 1.059111
Average total loss: 1.586701
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.3924e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.533694
Average KL loss: 1.059102
Average total loss: 1.592796
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(9.2151e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.524051
Average KL loss: 1.059059
Average total loss: 1.583111
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.8900e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.537397
Average KL loss: 1.059013
Average total loss: 1.596410
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.3249e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.522342
Average KL loss: 1.058989
Average total loss: 1.581331
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-6.7717e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.534293
Average KL loss: 1.058978
Average total loss: 1.593271
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(5.2214e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.532896
Average KL loss: 1.058966
Average total loss: 1.591862
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(4.6607e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.524785
Average KL loss: 1.058964
Average total loss: 1.583749
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-2.8395e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.541684
Average KL loss: 1.058961
Average total loss: 1.600644
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-3.2956e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.518605
Average KL loss: 1.058958
Average total loss: 1.577562
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(5.1453e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.545984
Average KL loss: 1.058954
Average total loss: 1.604938
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.1453e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.540663
Average KL loss: 1.058952
Average total loss: 1.599615
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-8.1678e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.524698
Average KL loss: 1.058952
Average total loss: 1.583650
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(2.0872e-11, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.534003
Average KL loss: 1.058953
Average total loss: 1.592956
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.3620e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.529941
Average KL loss: 1.058952
Average total loss: 1.588893
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-3.7093e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.512758
Average KL loss: 1.058950
Average total loss: 1.571708
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-3.4918e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.536314
Average KL loss: 1.058950
Average total loss: 1.595264
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.5648e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.503275
Average KL loss: 1.058949
Average total loss: 1.562224
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.9362e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.522421
Average KL loss: 1.058945
Average total loss: 1.581366
tensor(0.0069, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.8836e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.524065
Average KL loss: 1.058945
Average total loss: 1.583010
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.3884e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.520951
Average KL loss: 1.058943
Average total loss: 1.579893
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-2.8985e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.539994
Average KL loss: 1.058940
Average total loss: 1.598934
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.2817e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.522147
Average KL loss: 1.058935
Average total loss: 1.581082
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-4.4200e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.528464
Average KL loss: 1.058934
Average total loss: 1.587399
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(4.5432e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.535025
Average KL loss: 1.058932
Average total loss: 1.593957
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-2.7212e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.524710
Average KL loss: 1.058926
Average total loss: 1.583636
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.1797e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.520603
Average KL loss: 1.058922
Average total loss: 1.579525
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(5.8894e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.513846
Average KL loss: 1.058917
Average total loss: 1.572763
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(5.4201e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.540468
Average KL loss: 1.058913
Average total loss: 1.599381
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.7321e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.520524
Average KL loss: 1.058913
Average total loss: 1.579437
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-7.2402e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.536627
Average KL loss: 1.058913
Average total loss: 1.595540
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-8.0352e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.505830
Average KL loss: 1.058913
Average total loss: 1.564743
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-5.9854e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.530999
Average KL loss: 1.058913
Average total loss: 1.589912
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-5.4680e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.523565
Average KL loss: 1.058913
Average total loss: 1.582477
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(2.8959e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.516354
Average KL loss: 1.058912
Average total loss: 1.575266
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-7.8846e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.521280
Average KL loss: 1.058912
Average total loss: 1.580192
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-2.8428e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.506780
Average KL loss: 1.058911
Average total loss: 1.565691
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-2.7690e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.524657
Average KL loss: 1.058911
Average total loss: 1.583568
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-4.3233e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.526360
Average KL loss: 1.058910
Average total loss: 1.585270
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.0468e-08, device='cuda:0')
 Percentile value: 7.97189301238177e-08
Non-zero model percentage: 2.251814603805542%, Non-zero mask percentage: 2.251814603805542%

--- Pruning Level [17/24]: ---
conv1.weight         | nonzeros =     538 /    1728             ( 31.13%) | total_pruned =    1190 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     756 /   36864             (  2.05%) | total_pruned =   36108 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     973 /   36864             (  2.64%) | total_pruned =   35891 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     753 /   36864             (  2.04%) | total_pruned =   36111 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     799 /   36864             (  2.17%) | total_pruned =   36065 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1371 /   73728             (  1.86%) | total_pruned =   72357 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1856 /  147456             (  1.26%) | total_pruned =  145600 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     670 /    8192             (  8.18%) | total_pruned =    7522 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     848 /  147456             (  0.58%) | total_pruned =  146608 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     806 /  147456             (  0.55%) | total_pruned =  146650 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3243 /  294912             (  1.10%) | total_pruned =  291669 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    4394 /  589824             (  0.74%) | total_pruned =  585430 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1076 /   32768             (  3.28%) | total_pruned =   31692 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1426 /  589824             (  0.24%) | total_pruned =  588398 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     178 /     256             ( 69.53%) | total_pruned =      78 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1329 /  589824             (  0.23%) | total_pruned =  588495 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    5945 / 1179648             (  0.50%) | total_pruned = 1173703 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    5909 / 2359296             (  0.25%) | total_pruned = 2353387 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     442 /     512             ( 86.33%) | total_pruned =      70 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      61 /     512             ( 11.91%) | total_pruned =     451 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     556 /  131072             (  0.42%) | total_pruned =  130516 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      50 /     512             (  9.77%) | total_pruned =     462 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3382 / 2359296             (  0.14%) | total_pruned = 2355914 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     269 /     512             ( 52.54%) | total_pruned =     243 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  210804 / 2359296             (  8.94%) | total_pruned = 2148492 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
linear.weight        | nonzeros =     381 /    5120             (  7.44%) | total_pruned =    4739 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 251725, pruned : 10927037, total: 11178762, Compression rate :      44.41x  ( 97.75% pruned)
Train Epoch: 22/100 Loss: 0.000894 Accuracy: 83.12 100.00 % Best test Accuracy: 83.27%
tensor(0.0069, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-2.3073e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.617559
Average KL loss: 1.034749
Average total loss: 1.652308
tensor(0.0066, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-1.4872e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.666116
Average KL loss: 1.023891
Average total loss: 1.690007
tensor(0.0065, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-3.3177e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.702270
Average KL loss: 1.022728
Average total loss: 1.724997
tensor(0.0065, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-1.8661e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.697298
Average KL loss: 1.023951
Average total loss: 1.721249
tensor(0.0065, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-1.7288e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.705450
Average KL loss: 1.025488
Average total loss: 1.730938
tensor(0.0065, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-3.6841e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.724379
Average KL loss: 1.027510
Average total loss: 1.751889
tensor(0.0065, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.6800e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.684076
Average KL loss: 1.029757
Average total loss: 1.713833
tensor(0.0065, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-4.0882e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.679736
Average KL loss: 1.031960
Average total loss: 1.711695
tensor(0.0065, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-3.2749e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.668719
Average KL loss: 1.033860
Average total loss: 1.702578
tensor(0.0065, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-3.5548e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.631479
Average KL loss: 1.035711
Average total loss: 1.667191
tensor(0.0066, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-2.8027e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.651267
Average KL loss: 1.037631
Average total loss: 1.688898
tensor(0.0066, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-3.7611e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.630451
Average KL loss: 1.039346
Average total loss: 1.669796
tensor(0.0066, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-2.8108e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.667257
Average KL loss: 1.040220
Average total loss: 1.707478
tensor(0.0066, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.6789e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.651840
Average KL loss: 1.040354
Average total loss: 1.692194
tensor(0.0066, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(4.1749e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.641622
Average KL loss: 1.040492
Average total loss: 1.682114
tensor(0.0066, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-2.8765e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.627722
Average KL loss: 1.040648
Average total loss: 1.668370
tensor(0.0066, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-2.4117e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.657867
Average KL loss: 1.040803
Average total loss: 1.698670
tensor(0.0066, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-2.4708e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.653649
Average KL loss: 1.040935
Average total loss: 1.694584
tensor(0.0066, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.1116e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.663934
Average KL loss: 1.041079
Average total loss: 1.705013
tensor(0.0066, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.1305e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.642441
Average KL loss: 1.041233
Average total loss: 1.683674
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.4598e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.645359
Average KL loss: 1.041408
Average total loss: 1.686768
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.7807e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.634439
Average KL loss: 1.041565
Average total loss: 1.676004
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.0293e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.629379
Average KL loss: 1.041691
Average total loss: 1.671070
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.4792e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.626626
Average KL loss: 1.041775
Average total loss: 1.668401
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.1637e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.644998
Average KL loss: 1.041785
Average total loss: 1.686783
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-3.5149e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.659241
Average KL loss: 1.041800
Average total loss: 1.701041
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-3.6159e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.639536
Average KL loss: 1.041816
Average total loss: 1.681352
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-3.2989e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.614133
Average KL loss: 1.041828
Average total loss: 1.655962
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.3337e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.636380
Average KL loss: 1.041838
Average total loss: 1.678218
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-6.0701e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.608725
Average KL loss: 1.041850
Average total loss: 1.650575
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.8819e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.650159
Average KL loss: 1.041864
Average total loss: 1.692023
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.3215e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.633076
Average KL loss: 1.041876
Average total loss: 1.674952
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.5557e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.644324
Average KL loss: 1.041888
Average total loss: 1.686212
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-8.2143e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.622185
Average KL loss: 1.041899
Average total loss: 1.664084
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.5893e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.639199
Average KL loss: 1.041914
Average total loss: 1.681112
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.5527e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.646068
Average KL loss: 1.041928
Average total loss: 1.687996
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.4060e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.640538
Average KL loss: 1.041942
Average total loss: 1.682480
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.7270e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.650924
Average KL loss: 1.041961
Average total loss: 1.692885
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-3.8404e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.630477
Average KL loss: 1.041977
Average total loss: 1.672454
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.6600e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.633325
Average KL loss: 1.041992
Average total loss: 1.675317
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.8854e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.619641
Average KL loss: 1.042006
Average total loss: 1.661647
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.7108e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.636444
Average KL loss: 1.042013
Average total loss: 1.678457
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.1326e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.639070
Average KL loss: 1.042015
Average total loss: 1.681085
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.4526e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.645001
Average KL loss: 1.042016
Average total loss: 1.687017
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.7087e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.644595
Average KL loss: 1.042017
Average total loss: 1.686612
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-5.3263e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.655169
Average KL loss: 1.042019
Average total loss: 1.697188
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.3469e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.646117
Average KL loss: 1.042020
Average total loss: 1.688137
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.7017e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.601259
Average KL loss: 1.042021
Average total loss: 1.643280
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.4907e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.686068
Average KL loss: 1.042022
Average total loss: 1.728090
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.1455e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.628426
Average KL loss: 1.042024
Average total loss: 1.670450
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-3.1012e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.634610
Average KL loss: 1.042025
Average total loss: 1.676635
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.3730e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.652315
Average KL loss: 1.042026
Average total loss: 1.694341
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-5.2005e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.629328
Average KL loss: 1.042027
Average total loss: 1.671355
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.5452e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.626886
Average KL loss: 1.042028
Average total loss: 1.668914
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.9572e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.624007
Average KL loss: 1.042029
Average total loss: 1.666036
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(4.2901e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.636329
Average KL loss: 1.042031
Average total loss: 1.678360
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-6.4196e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.634938
Average KL loss: 1.042032
Average total loss: 1.676970
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.5838e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.651973
Average KL loss: 1.042033
Average total loss: 1.694007
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.3438e-08, device='cuda:0')
 Percentile value: 8.185603661559071e-08
Non-zero model percentage: 1.8014516830444336%, Non-zero mask percentage: 1.8014516830444336%

--- Pruning Level [18/24]: ---
conv1.weight         | nonzeros =     532 /    1728             ( 30.79%) | total_pruned =    1196 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     743 /   36864             (  2.02%) | total_pruned =   36121 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     952 /   36864             (  2.58%) | total_pruned =   35912 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     730 /   36864             (  1.98%) | total_pruned =   36134 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     787 /   36864             (  2.13%) | total_pruned =   36077 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1343 /   73728             (  1.82%) | total_pruned =   72385 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1789 /  147456             (  1.21%) | total_pruned =  145667 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     653 /    8192             (  7.97%) | total_pruned =    7539 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     806 /  147456             (  0.55%) | total_pruned =  146650 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     775 /  147456             (  0.53%) | total_pruned =  146681 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3133 /  294912             (  1.06%) | total_pruned =  291779 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    4203 /  589824             (  0.71%) | total_pruned =  585621 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1054 /   32768             (  3.22%) | total_pruned =   31714 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1339 /  589824             (  0.23%) | total_pruned =  588485 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     175 /     256             ( 68.36%) | total_pruned =      81 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1213 /  589824             (  0.21%) | total_pruned =  588611 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     195 /     256             ( 76.17%) | total_pruned =      61 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    5637 / 1179648             (  0.48%) | total_pruned = 1174011 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     496 /     512             ( 96.88%) | total_pruned =      16 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    5403 / 2359296             (  0.23%) | total_pruned = 2353893 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     441 /     512             ( 86.13%) | total_pruned =      71 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      58 /     512             ( 11.33%) | total_pruned =     454 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     512 /  131072             (  0.39%) | total_pruned =  130560 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     199 /     512             ( 38.87%) | total_pruned =     313 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      49 /     512             (  9.57%) | total_pruned =     463 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2968 / 2359296             (  0.13%) | total_pruned = 2356328 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     268 /     512             ( 52.34%) | total_pruned =     244 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  162547 / 2359296             (  6.89%) | total_pruned = 2196749 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
linear.weight        | nonzeros =     379 /    5120             (  7.40%) | total_pruned =    4741 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 201380, pruned : 10977382, total: 11178762, Compression rate :      55.51x  ( 98.20% pruned)
Train Epoch: 21/100 Loss: 0.001377 Accuracy: 82.89 99.98 % Best test Accuracy: 83.18%
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-5.4174e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.777992
Average KL loss: 1.019250
Average total loss: 1.797242
tensor(0.0064, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-3.2630e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.803931
Average KL loss: 1.010838
Average total loss: 1.814769
tensor(0.0063, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-4.4501e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.809750
Average KL loss: 1.011191
Average total loss: 1.820942
tensor(0.0063, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-3.9844e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.790610
Average KL loss: 1.013246
Average total loss: 1.803856
tensor(0.0063, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-5.4764e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.818211
Average KL loss: 1.016052
Average total loss: 1.834263
tensor(0.0063, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-3.4755e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.779653
Average KL loss: 1.018884
Average total loss: 1.798537
tensor(0.0063, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-4.5398e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.778244
Average KL loss: 1.021673
Average total loss: 1.799917
tensor(0.0064, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-3.8717e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.739601
Average KL loss: 1.024694
Average total loss: 1.764295
tensor(0.0064, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-6.4496e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.769333
Average KL loss: 1.027461
Average total loss: 1.796793
tensor(0.0064, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-5.9899e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.763878
Average KL loss: 1.030182
Average total loss: 1.794060
tensor(0.0064, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(5.8655e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.739928
Average KL loss: 1.032593
Average total loss: 1.772521
tensor(0.0064, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-5.3681e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.734363
Average KL loss: 1.034607
Average total loss: 1.768969
tensor(0.0064, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-4.2484e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.753301
Average KL loss: 1.037022
Average total loss: 1.790323
tensor(0.0064, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-4.9238e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.755376
Average KL loss: 1.039401
Average total loss: 1.794777
tensor(0.0065, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-4.4342e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.696521
Average KL loss: 1.041849
Average total loss: 1.738370
tensor(0.0065, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-2.0980e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.696698
Average KL loss: 1.043989
Average total loss: 1.740686
tensor(0.0065, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-4.4505e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.747269
Average KL loss: 1.046418
Average total loss: 1.793687
tensor(0.0065, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-5.5069e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.728729
Average KL loss: 1.048578
Average total loss: 1.777308
tensor(0.0065, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-5.0710e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.721411
Average KL loss: 1.050538
Average total loss: 1.771948
tensor(0.0065, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-1.1731e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.693229
Average KL loss: 1.052595
Average total loss: 1.745824
tensor(0.0066, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-2.9968e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.686143
Average KL loss: 1.054624
Average total loss: 1.740768
tensor(0.0066, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-1.3630e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.686441
Average KL loss: 1.056452
Average total loss: 1.742893
tensor(0.0066, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-4.1653e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.708650
Average KL loss: 1.058265
Average total loss: 1.766914
tensor(0.0066, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-2.1676e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.661637
Average KL loss: 1.060272
Average total loss: 1.721908
tensor(0.0066, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-5.0700e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.642837
Average KL loss: 1.061876
Average total loss: 1.704713
tensor(0.0066, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.0730e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.668525
Average KL loss: 1.063478
Average total loss: 1.732003
tensor(0.0066, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-3.1141e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.653838
Average KL loss: 1.065165
Average total loss: 1.719003
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.9313e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.660210
Average KL loss: 1.067014
Average total loss: 1.727224
tensor(0.0067, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-3.6958e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.642353
Average KL loss: 1.068452
Average total loss: 1.710805
tensor(0.0067, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-2.6233e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.657960
Average KL loss: 1.069942
Average total loss: 1.727902
tensor(0.0067, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-4.8094e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.626164
Average KL loss: 1.071394
Average total loss: 1.697559
tensor(0.0067, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(7.2865e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.617403
Average KL loss: 1.072416
Average total loss: 1.689819
tensor(0.0067, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-3.3654e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.632658
Average KL loss: 1.073625
Average total loss: 1.706283
tensor(0.0067, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-6.7913e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.623565
Average KL loss: 1.075101
Average total loss: 1.698666
tensor(0.0067, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(2.8579e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.621711
Average KL loss: 1.076522
Average total loss: 1.698233
tensor(0.0067, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-1.9066e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.608138
Average KL loss: 1.077788
Average total loss: 1.685927
tensor(0.0067, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-2.3739e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.626066
Average KL loss: 1.078986
Average total loss: 1.705052
tensor(0.0068, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-1.9310e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.604688
Average KL loss: 1.080461
Average total loss: 1.685149
tensor(0.0068, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-1.2764e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.595325
Average KL loss: 1.081665
Average total loss: 1.676989
tensor(0.0068, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-2.1545e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.601796
Average KL loss: 1.083047
Average total loss: 1.684844
tensor(0.0068, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-3.9923e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.603778
Average KL loss: 1.084437
Average total loss: 1.688215
tensor(0.0068, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-3.9136e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.602352
Average KL loss: 1.085631
Average total loss: 1.687983
tensor(0.0068, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-2.6431e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.596667
Average KL loss: 1.086856
Average total loss: 1.683523
tensor(0.0068, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-1.6013e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.580441
Average KL loss: 1.087859
Average total loss: 1.668300
tensor(0.0068, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-1.7584e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.592736
Average KL loss: 1.088858
Average total loss: 1.681594
tensor(0.0068, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-3.2739e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.574071
Average KL loss: 1.089725
Average total loss: 1.663797
tensor(0.0068, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-2.6762e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.559985
Average KL loss: 1.090607
Average total loss: 1.650592
tensor(0.0068, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-1.1390e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.593176
Average KL loss: 1.091309
Average total loss: 1.684485
tensor(0.0069, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-8.1283e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.565956
Average KL loss: 1.092235
Average total loss: 1.658191
tensor(0.0069, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-3.5951e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.565752
Average KL loss: 1.093249
Average total loss: 1.659000
tensor(0.0069, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-3.5022e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.568530
Average KL loss: 1.094121
Average total loss: 1.662652
tensor(0.0069, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-3.5061e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.585846
Average KL loss: 1.095324
Average total loss: 1.681170
tensor(0.0069, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.3553e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.560333
Average KL loss: 1.096431
Average total loss: 1.656763
tensor(0.0069, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.6267e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.570537
Average KL loss: 1.097138
Average total loss: 1.667675
tensor(0.0069, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-1.0373e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.571136
Average KL loss: 1.098138
Average total loss: 1.669274
tensor(0.0069, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.6819e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.563926
Average KL loss: 1.098936
Average total loss: 1.662862
tensor(0.0069, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.5611e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.548442
Average KL loss: 1.099649
Average total loss: 1.648091
tensor(0.0069, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-2.4489e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.544056
Average KL loss: 1.100408
Average total loss: 1.644464
tensor(0.0069, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(1.9550e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.551277
Average KL loss: 1.101281
Average total loss: 1.652558
tensor(0.0069, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-1.8135e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.521859
Average KL loss: 1.102033
Average total loss: 1.623892
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(1.5962e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.525894
Average KL loss: 1.102347
Average total loss: 1.628242
tensor(0.0070, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-1.3707e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.537629
Average KL loss: 1.103102
Average total loss: 1.640731
tensor(0.0070, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-7.0008e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.528492
Average KL loss: 1.103798
Average total loss: 1.632290
tensor(0.0070, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-2.0637e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.528034
Average KL loss: 1.104215
Average total loss: 1.632249
tensor(0.0070, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-9.7209e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.524284
Average KL loss: 1.104875
Average total loss: 1.629158
tensor(0.0070, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-2.1042e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.540647
Average KL loss: 1.105486
Average total loss: 1.646133
tensor(0.0070, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-6.1762e-11, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.524680
Average KL loss: 1.106081
Average total loss: 1.630761
tensor(0.0070, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-1.0217e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.525270
Average KL loss: 1.106508
Average total loss: 1.631778
tensor(0.0070, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-1.0164e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.518941
Average KL loss: 1.106880
Average total loss: 1.625820
tensor(0.0070, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-8.0515e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.513987
Average KL loss: 1.107272
Average total loss: 1.621259
tensor(0.0070, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-8.0588e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.526741
Average KL loss: 1.107760
Average total loss: 1.634500
tensor(0.0070, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-1.5392e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.526773
Average KL loss: 1.108408
Average total loss: 1.635181
tensor(0.0070, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-2.8802e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.516469
Average KL loss: 1.109352
Average total loss: 1.625821
tensor(0.0070, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-1.2534e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.496817
Average KL loss: 1.109831
Average total loss: 1.606648
tensor(0.0070, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-9.5964e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.504070
Average KL loss: 1.110262
Average total loss: 1.614332
tensor(0.0071, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-1.2598e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.525369
Average KL loss: 1.110838
Average total loss: 1.636206
tensor(0.0071, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(4.8344e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.512402
Average KL loss: 1.111646
Average total loss: 1.624047
tensor(0.0071, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-7.1090e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.514183
Average KL loss: 1.112430
Average total loss: 1.626613
tensor(0.0071, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-6.1118e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.494640
Average KL loss: 1.113136
Average total loss: 1.607776
tensor(0.0071, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-5.7579e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.520717
Average KL loss: 1.113501
Average total loss: 1.634218
tensor(0.0071, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-2.6238e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.496173
Average KL loss: 1.114034
Average total loss: 1.610206
tensor(0.0071, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-2.5758e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.509594
Average KL loss: 1.114668
Average total loss: 1.624262
tensor(0.0071, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-2.9633e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.495596
Average KL loss: 1.115225
Average total loss: 1.610822
tensor(0.0071, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-1.4209e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.479346
Average KL loss: 1.115767
Average total loss: 1.595113
tensor(0.0071, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-2.6325e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.491391
Average KL loss: 1.116133
Average total loss: 1.607524
tensor(0.0071, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-2.2323e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.491985
Average KL loss: 1.116613
Average total loss: 1.608598
tensor(0.0071, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(1.1519e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.484882
Average KL loss: 1.117170
Average total loss: 1.602052
tensor(0.0071, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-7.1371e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.482750
Average KL loss: 1.117763
Average total loss: 1.600513
tensor(0.0071, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.3712e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.499010
Average KL loss: 1.118509
Average total loss: 1.617519
tensor(0.0072, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.3665e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.477627
Average KL loss: 1.118962
Average total loss: 1.596589
tensor(0.0072, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.1111e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.498313
Average KL loss: 1.119558
Average total loss: 1.617871
tensor(0.0072, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-1.1981e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.475043
Average KL loss: 1.119971
Average total loss: 1.595013
tensor(0.0072, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-1.2348e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.465058
Average KL loss: 1.120537
Average total loss: 1.585595
tensor(0.0072, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-1.0797e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.473404
Average KL loss: 1.120914
Average total loss: 1.594318
tensor(0.0072, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-4.4675e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.453121
Average KL loss: 1.121011
Average total loss: 1.574131
tensor(0.0072, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-5.8442e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.489955
Average KL loss: 1.121465
Average total loss: 1.611420
tensor(0.0072, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.6930e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.475990
Average KL loss: 1.121813
Average total loss: 1.597803
tensor(0.0072, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.3099e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.467682
Average KL loss: 1.121925
Average total loss: 1.589607
tensor(0.0072, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-1.1989e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.465043
Average KL loss: 1.122263
Average total loss: 1.587306
tensor(0.0072, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-1.0849e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.468587
Average KL loss: 1.122774
Average total loss: 1.591361
tensor(0.0072, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.3721e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.483475
Average KL loss: 1.123463
Average total loss: 1.606938
tensor(0.0072, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.9523e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.465507
Average KL loss: 1.123716
Average total loss: 1.589224
tensor(0.0072, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-4.5030e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.466791
Average KL loss: 1.124106
Average total loss: 1.590897
tensor(0.0072, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-1.3624e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.461499
Average KL loss: 1.124666
Average total loss: 1.586165
tensor(0.0072, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-1.8958e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.457271
Average KL loss: 1.125248
Average total loss: 1.582519
tensor(0.0072, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-2.9113e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.442464
Average KL loss: 1.125783
Average total loss: 1.568246
tensor(0.0072, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-1.3833e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.476532
Average KL loss: 1.126014
Average total loss: 1.602546
tensor(0.0073, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(2.1495e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.449851
Average KL loss: 1.126155
Average total loss: 1.576005
tensor(0.0073, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-5.7668e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.460671
Average KL loss: 1.126039
Average total loss: 1.586710
tensor(0.0073, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-4.3998e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.469772
Average KL loss: 1.126276
Average total loss: 1.596048
tensor(0.0073, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-4.9507e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.458895
Average KL loss: 1.126900
Average total loss: 1.585795
tensor(0.0073, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-3.2850e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.457579
Average KL loss: 1.127613
Average total loss: 1.585192
tensor(0.0073, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(3.9373e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.450330
Average KL loss: 1.127945
Average total loss: 1.578275
tensor(0.0073, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-4.9834e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.447286
Average KL loss: 1.127978
Average total loss: 1.575264
tensor(0.0073, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-1.2020e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.473961
Average KL loss: 1.128277
Average total loss: 1.602238
tensor(0.0073, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-1.1115e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.454682
Average KL loss: 1.128470
Average total loss: 1.583151
tensor(0.0073, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-1.0732e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.464362
Average KL loss: 1.128926
Average total loss: 1.593288
tensor(0.0073, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(2.1832e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.440682
Average KL loss: 1.129200
Average total loss: 1.569882
tensor(0.0073, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(4.9267e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.453172
Average KL loss: 1.129184
Average total loss: 1.582356
tensor(0.0073, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(3.0461e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.464083
Average KL loss: 1.129198
Average total loss: 1.593281
tensor(0.0073, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-1.1910e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.453289
Average KL loss: 1.129208
Average total loss: 1.582498
tensor(0.0073, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-1.4460e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.463194
Average KL loss: 1.129208
Average total loss: 1.592402
tensor(0.0073, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-1.8372e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.447917
Average KL loss: 1.129172
Average total loss: 1.577089
tensor(0.0073, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-1.8757e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.454348
Average KL loss: 1.129172
Average total loss: 1.583520
tensor(0.0073, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-2.9848e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.444913
Average KL loss: 1.129178
Average total loss: 1.574091
tensor(0.0073, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(9.2692e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.451562
Average KL loss: 1.129173
Average total loss: 1.580735
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-2.5312e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.450361
Average KL loss: 1.129183
Average total loss: 1.579544
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-5.0885e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.466475
Average KL loss: 1.129182
Average total loss: 1.595658
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-2.9187e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.438733
Average KL loss: 1.129188
Average total loss: 1.567921
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.8733e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.451598
Average KL loss: 1.129186
Average total loss: 1.580784
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-2.4563e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.446350
Average KL loss: 1.129184
Average total loss: 1.575534
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(3.4723e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.436877
Average KL loss: 1.129182
Average total loss: 1.566059
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.4763e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.448220
Average KL loss: 1.129177
Average total loss: 1.577397
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(1.3811e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.450875
Average KL loss: 1.129175
Average total loss: 1.580051
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-7.7015e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.445849
Average KL loss: 1.129175
Average total loss: 1.575024
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-6.4495e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.459225
Average KL loss: 1.129173
Average total loss: 1.588398
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.1281e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.438409
Average KL loss: 1.129170
Average total loss: 1.567579
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.1882e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.461543
Average KL loss: 1.129170
Average total loss: 1.590712
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-8.8473e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.438149
Average KL loss: 1.129172
Average total loss: 1.567321
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(3.2431e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.438558
Average KL loss: 1.129171
Average total loss: 1.567729
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(1.8216e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.458767
Average KL loss: 1.129169
Average total loss: 1.587936
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-2.5088e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.460984
Average KL loss: 1.129169
Average total loss: 1.590153
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.2049e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.465821
Average KL loss: 1.129170
Average total loss: 1.594991
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.4683e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.449114
Average KL loss: 1.129168
Average total loss: 1.578282
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(4.8764e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.452017
Average KL loss: 1.129168
Average total loss: 1.581185
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.5797e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.437005
Average KL loss: 1.129168
Average total loss: 1.566173
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.6619e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.442026
Average KL loss: 1.129168
Average total loss: 1.571194
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-2.5944e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.448491
Average KL loss: 1.129168
Average total loss: 1.577659
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-9.5310e-11, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.453208
Average KL loss: 1.129168
Average total loss: 1.582376
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-2.7179e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.421054
Average KL loss: 1.129168
Average total loss: 1.550222
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.0748e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.446988
Average KL loss: 1.129168
Average total loss: 1.576156
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.2269e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.453624
Average KL loss: 1.129167
Average total loss: 1.582791
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.6725e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.451252
Average KL loss: 1.129167
Average total loss: 1.580419
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(1.2591e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.435565
Average KL loss: 1.129167
Average total loss: 1.564732
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-4.8224e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.431100
Average KL loss: 1.129167
Average total loss: 1.560267
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(9.1780e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.431706
Average KL loss: 1.129166
Average total loss: 1.560872
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.7316e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.448873
Average KL loss: 1.129166
Average total loss: 1.578039
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.0837e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.452037
Average KL loss: 1.129165
Average total loss: 1.581202
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-3.9008e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.437598
Average KL loss: 1.129165
Average total loss: 1.566763
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-9.8960e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.447143
Average KL loss: 1.129165
Average total loss: 1.576309
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-3.5221e-08, device='cuda:0')
 Percentile value: 7.998484363724856e-08
Non-zero model percentage: 1.4411613941192627%, Non-zero mask percentage: 1.4411613941192627%

--- Pruning Level [19/24]: ---
conv1.weight         | nonzeros =     524 /    1728             ( 30.32%) | total_pruned =    1204 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     715 /   36864             (  1.94%) | total_pruned =   36149 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     926 /   36864             (  2.51%) | total_pruned =   35938 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     702 /   36864             (  1.90%) | total_pruned =   36162 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     762 /   36864             (  2.07%) | total_pruned =   36102 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1303 /   73728             (  1.77%) | total_pruned =   72425 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1728 /  147456             (  1.17%) | total_pruned =  145728 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     642 /    8192             (  7.84%) | total_pruned =    7550 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     769 /  147456             (  0.52%) | total_pruned =  146687 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     736 /  147456             (  0.50%) | total_pruned =  146720 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3010 /  294912             (  1.02%) | total_pruned =  291902 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    3985 /  589824             (  0.68%) | total_pruned =  585839 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1016 /   32768             (  3.10%) | total_pruned =   31752 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1220 /  589824             (  0.21%) | total_pruned =  588604 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     170 /     256             ( 66.41%) | total_pruned =      86 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1070 /  589824             (  0.18%) | total_pruned =  588754 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     194 /     256             ( 75.78%) | total_pruned =      62 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    5259 / 1179648             (  0.45%) | total_pruned = 1174389 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    4859 / 2359296             (  0.21%) | total_pruned = 2354437 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     435 /     512             ( 84.96%) | total_pruned =      77 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     444 /  131072             (  0.34%) | total_pruned =  130628 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     187 /     512             ( 36.52%) | total_pruned =     325 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      43 /     512             (  8.40%) | total_pruned =     469 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2444 / 2359296             (  0.10%) | total_pruned = 2356852 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     262 /     512             ( 51.17%) | total_pruned =     250 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  124813 / 2359296             (  5.29%) | total_pruned = 2234483 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
linear.weight        | nonzeros =     367 /    5120             (  7.17%) | total_pruned =    4753 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 161104, pruned : 11017658, total: 11178762, Compression rate :      69.39x  ( 98.56% pruned)
Train Epoch: 22/100 Loss: 0.001144 Accuracy: 82.40 100.00 % Best test Accuracy: 82.99%
tensor(0.0073, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-1.6600e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.519512
Average KL loss: 1.105350
Average total loss: 1.624862
tensor(0.0070, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-1.5658e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.567850
Average KL loss: 1.093177
Average total loss: 1.661027
tensor(0.0069, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-2.4276e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.574844
Average KL loss: 1.090796
Average total loss: 1.665640
tensor(0.0069, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-2.5345e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.579609
Average KL loss: 1.090907
Average total loss: 1.670515
tensor(0.0069, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-3.4459e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.619770
Average KL loss: 1.092207
Average total loss: 1.711976
tensor(0.0069, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-3.9563e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.575079
Average KL loss: 1.093795
Average total loss: 1.668874
tensor(0.0069, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.8580e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.572977
Average KL loss: 1.095552
Average total loss: 1.668529
tensor(0.0069, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-5.5417e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.591880
Average KL loss: 1.097387
Average total loss: 1.689267
tensor(0.0069, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-1.8058e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.586017
Average KL loss: 1.099445
Average total loss: 1.685462
tensor(0.0069, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.2384e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.563980
Average KL loss: 1.100953
Average total loss: 1.664934
tensor(0.0069, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-2.0984e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.570162
Average KL loss: 1.102452
Average total loss: 1.672614
tensor(0.0069, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-2.3005e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.582723
Average KL loss: 1.104188
Average total loss: 1.686911
tensor(0.0069, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.9297e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.599773
Average KL loss: 1.104991
Average total loss: 1.704764
tensor(0.0069, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.3737e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.586961
Average KL loss: 1.105136
Average total loss: 1.692098
tensor(0.0069, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-3.5374e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.572107
Average KL loss: 1.105275
Average total loss: 1.677382
tensor(0.0069, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.2370e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.563207
Average KL loss: 1.105432
Average total loss: 1.668639
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.3544e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.547896
Average KL loss: 1.105563
Average total loss: 1.653458
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-4.6597e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.557127
Average KL loss: 1.105691
Average total loss: 1.662818
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.0307e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.571136
Average KL loss: 1.105824
Average total loss: 1.676960
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-3.6292e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.572176
Average KL loss: 1.105977
Average total loss: 1.678153
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-3.2873e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.564888
Average KL loss: 1.106101
Average total loss: 1.670989
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.1635e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.559600
Average KL loss: 1.106239
Average total loss: 1.665839
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-6.1632e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.563281
Average KL loss: 1.106373
Average total loss: 1.669654
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.7650e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.549852
Average KL loss: 1.106453
Average total loss: 1.656305
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.0579e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.593632
Average KL loss: 1.106467
Average total loss: 1.700098
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-4.1586e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.553253
Average KL loss: 1.106479
Average total loss: 1.659731
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(1.9127e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.589050
Average KL loss: 1.106492
Average total loss: 1.695542
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.2962e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.552526
Average KL loss: 1.106507
Average total loss: 1.659033
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.1768e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.581021
Average KL loss: 1.106520
Average total loss: 1.687541
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-4.9676e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.583298
Average KL loss: 1.106536
Average total loss: 1.689834
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.8323e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.564971
Average KL loss: 1.106550
Average total loss: 1.671521
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.2654e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.556783
Average KL loss: 1.106564
Average total loss: 1.663347
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.7117e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.564145
Average KL loss: 1.106579
Average total loss: 1.670724
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-1.0928e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.595061
Average KL loss: 1.106593
Average total loss: 1.701654
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-3.8233e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.570851
Average KL loss: 1.106600
Average total loss: 1.677451
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-3.3427e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.598610
Average KL loss: 1.106602
Average total loss: 1.705212
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-4.7995e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.583148
Average KL loss: 1.106604
Average total loss: 1.689751
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-3.4252e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.580764
Average KL loss: 1.106605
Average total loss: 1.687369
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-1.3573e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.561058
Average KL loss: 1.106607
Average total loss: 1.667664
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.8477e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.565947
Average KL loss: 1.106608
Average total loss: 1.672556
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-1.9992e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.559982
Average KL loss: 1.106609
Average total loss: 1.666591
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-1.9836e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.563112
Average KL loss: 1.106611
Average total loss: 1.669723
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-1.8736e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.559059
Average KL loss: 1.106612
Average total loss: 1.665671
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-6.5520e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.544514
Average KL loss: 1.106614
Average total loss: 1.651127
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-1.0164e-08, device='cuda:0')
 Percentile value: 7.985809702404367e-08
Non-zero model percentage: 1.1529362201690674%, Non-zero mask percentage: 1.1529362201690674%

--- Pruning Level [20/24]: ---
conv1.weight         | nonzeros =     522 /    1728             ( 30.21%) | total_pruned =    1206 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     710 /   36864             (  1.93%) | total_pruned =   36154 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     910 /   36864             (  2.47%) | total_pruned =   35954 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     688 /   36864             (  1.87%) | total_pruned =   36176 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     752 /   36864             (  2.04%) | total_pruned =   36112 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1291 /   73728             (  1.75%) | total_pruned =   72437 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1694 /  147456             (  1.15%) | total_pruned =  145762 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     632 /    8192             (  7.71%) | total_pruned =    7560 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     756 /  147456             (  0.51%) | total_pruned =  146700 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     716 /  147456             (  0.49%) | total_pruned =  146740 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2944 /  294912             (  1.00%) | total_pruned =  291968 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    3853 /  589824             (  0.65%) | total_pruned =  585971 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1001 /   32768             (  3.05%) | total_pruned =   31767 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1192 /  589824             (  0.20%) | total_pruned =  588632 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     170 /     256             ( 66.41%) | total_pruned =      86 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1034 /  589824             (  0.18%) | total_pruned =  588790 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     194 /     256             ( 75.78%) | total_pruned =      62 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    5071 / 1179648             (  0.43%) | total_pruned = 1174577 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     494 /     512             ( 96.48%) | total_pruned =      18 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    4661 / 2359296             (  0.20%) | total_pruned = 2354635 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     433 /     512             ( 84.57%) | total_pruned =      79 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     431 /  131072             (  0.33%) | total_pruned =  130641 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     184 /     512             ( 35.94%) | total_pruned =     328 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2340 / 2359296             (  0.10%) | total_pruned = 2356956 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     258 /     512             ( 50.39%) | total_pruned =     254 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   93533 / 2359296             (  3.96%) | total_pruned = 2265763 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
linear.weight        | nonzeros =     361 /    5120             (  7.05%) | total_pruned =    4759 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 128884, pruned : 11049878, total: 11178762, Compression rate :      86.74x  ( 98.85% pruned)
Train Epoch: 21/100 Loss: 0.001578 Accuracy: 82.59 100.00 % Best test Accuracy: 82.72%
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-1.7666e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.679306
Average KL loss: 1.083533
Average total loss: 1.762839
tensor(0.0067, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-4.5016e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.673337
Average KL loss: 1.073850
Average total loss: 1.747187
tensor(0.0066, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-3.8242e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.697103
Average KL loss: 1.073277
Average total loss: 1.770381
tensor(0.0066, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.9241e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.689403
Average KL loss: 1.074659
Average total loss: 1.764062
tensor(0.0066, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-4.3876e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.700974
Average KL loss: 1.076818
Average total loss: 1.777792
tensor(0.0066, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-3.6579e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.701408
Average KL loss: 1.079214
Average total loss: 1.780622
tensor(0.0066, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.7082e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.677651
Average KL loss: 1.081866
Average total loss: 1.759517
tensor(0.0067, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-1.8153e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.679115
Average KL loss: 1.084324
Average total loss: 1.763439
tensor(0.0067, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-3.3189e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.668498
Average KL loss: 1.086707
Average total loss: 1.755205
tensor(0.0067, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-3.5961e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.668234
Average KL loss: 1.089244
Average total loss: 1.757478
tensor(0.0067, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-4.7780e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.680618
Average KL loss: 1.091591
Average total loss: 1.772209
tensor(0.0067, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-2.2528e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.641823
Average KL loss: 1.094084
Average total loss: 1.735906
tensor(0.0067, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-2.2154e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.632215
Average KL loss: 1.096155
Average total loss: 1.728370
tensor(0.0068, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-1.0091e-07, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.621755
Average KL loss: 1.098359
Average total loss: 1.720114
tensor(0.0068, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-3.3878e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.625859
Average KL loss: 1.100310
Average total loss: 1.726170
tensor(0.0068, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-2.7187e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.632929
Average KL loss: 1.102124
Average total loss: 1.735053
tensor(0.0068, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-1.1199e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.593960
Average KL loss: 1.103889
Average total loss: 1.697849
tensor(0.0068, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-2.0151e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.597218
Average KL loss: 1.105280
Average total loss: 1.702498
tensor(0.0068, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-1.9109e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.610306
Average KL loss: 1.106763
Average total loss: 1.717069
tensor(0.0068, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-1.8581e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.621674
Average KL loss: 1.108347
Average total loss: 1.730021
tensor(0.0069, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-1.5798e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.570448
Average KL loss: 1.109869
Average total loss: 1.680317
tensor(0.0069, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-3.1356e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.607411
Average KL loss: 1.111505
Average total loss: 1.718916
tensor(0.0069, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-2.8226e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.581071
Average KL loss: 1.113140
Average total loss: 1.694211
tensor(0.0069, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-4.2077e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.581151
Average KL loss: 1.114343
Average total loss: 1.695494
tensor(0.0069, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-8.1136e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.560560
Average KL loss: 1.115892
Average total loss: 1.676452
tensor(0.0069, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-3.6673e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.567432
Average KL loss: 1.117472
Average total loss: 1.684904
tensor(0.0069, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-2.7884e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.552384
Average KL loss: 1.118576
Average total loss: 1.670961
tensor(0.0069, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-7.8137e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.582664
Average KL loss: 1.119573
Average total loss: 1.702237
tensor(0.0069, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-2.9617e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.558379
Average KL loss: 1.120672
Average total loss: 1.679050
tensor(0.0070, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.7821e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.565417
Average KL loss: 1.121940
Average total loss: 1.687357
tensor(0.0070, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-2.4471e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.544036
Average KL loss: 1.123112
Average total loss: 1.667148
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.7881e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.525942
Average KL loss: 1.124328
Average total loss: 1.650270
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-2.3467e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.528821
Average KL loss: 1.125205
Average total loss: 1.654026
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-1.7136e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.535683
Average KL loss: 1.126266
Average total loss: 1.661950
tensor(0.0070, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.0004e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.530362
Average KL loss: 1.127124
Average total loss: 1.657485
tensor(0.0070, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-4.1165e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.520472
Average KL loss: 1.127872
Average total loss: 1.648344
tensor(0.0070, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(9.3802e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.543408
Average KL loss: 1.128560
Average total loss: 1.671969
tensor(0.0070, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-1.2667e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.530682
Average KL loss: 1.129769
Average total loss: 1.660451
tensor(0.0071, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-2.5041e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.558754
Average KL loss: 1.130850
Average total loss: 1.689604
tensor(0.0071, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-1.4117e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.529422
Average KL loss: 1.132042
Average total loss: 1.661463
tensor(0.0071, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-1.6163e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.523970
Average KL loss: 1.132851
Average total loss: 1.656821
tensor(0.0071, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(3.8176e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.536883
Average KL loss: 1.133779
Average total loss: 1.670663
tensor(0.0071, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-1.4760e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.529714
Average KL loss: 1.134970
Average total loss: 1.664684
tensor(0.0071, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-1.4141e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.522474
Average KL loss: 1.136114
Average total loss: 1.658588
tensor(0.0071, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-3.2402e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.514257
Average KL loss: 1.137028
Average total loss: 1.651285
tensor(0.0071, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-2.2785e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.514694
Average KL loss: 1.137897
Average total loss: 1.652591
tensor(0.0071, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-3.5570e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.491028
Average KL loss: 1.139034
Average total loss: 1.630061
tensor(0.0071, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.6064e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.499504
Average KL loss: 1.139728
Average total loss: 1.639232
tensor(0.0071, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-2.7393e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.465661
Average KL loss: 1.140539
Average total loss: 1.606200
tensor(0.0072, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-1.7978e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.488448
Average KL loss: 1.141154
Average total loss: 1.629601
tensor(0.0072, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-1.8982e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.498111
Average KL loss: 1.141846
Average total loss: 1.639957
tensor(0.0072, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-3.4840e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.507397
Average KL loss: 1.142796
Average total loss: 1.650193
tensor(0.0072, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-2.1773e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.491971
Average KL loss: 1.143925
Average total loss: 1.635896
tensor(0.0072, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-2.7492e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.466974
Average KL loss: 1.144553
Average total loss: 1.611527
tensor(0.0072, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-2.0378e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.467370
Average KL loss: 1.145101
Average total loss: 1.612470
tensor(0.0072, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.3707e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.480928
Average KL loss: 1.145651
Average total loss: 1.626578
tensor(0.0072, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-2.8790e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.478372
Average KL loss: 1.146494
Average total loss: 1.624866
tensor(0.0072, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-6.2994e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.488171
Average KL loss: 1.147144
Average total loss: 1.635315
tensor(0.0072, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-1.4649e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.472634
Average KL loss: 1.147903
Average total loss: 1.620537
tensor(0.0072, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-8.9873e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.461218
Average KL loss: 1.148534
Average total loss: 1.609752
tensor(0.0072, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-3.4292e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.479921
Average KL loss: 1.148868
Average total loss: 1.628789
tensor(0.0072, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-4.5922e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.461565
Average KL loss: 1.148872
Average total loss: 1.610436
tensor(0.0072, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-2.0826e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.458429
Average KL loss: 1.148878
Average total loss: 1.607306
tensor(0.0072, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-9.5694e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.455118
Average KL loss: 1.148872
Average total loss: 1.603990
tensor(0.0072, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.3992e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.468716
Average KL loss: 1.148887
Average total loss: 1.617604
tensor(0.0072, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-2.6299e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.449550
Average KL loss: 1.148923
Average total loss: 1.598473
tensor(0.0072, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-6.7386e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.475423
Average KL loss: 1.148937
Average total loss: 1.624360
tensor(0.0073, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.2383e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.487297
Average KL loss: 1.148963
Average total loss: 1.636260
tensor(0.0073, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(1.2894e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.470199
Average KL loss: 1.149004
Average total loss: 1.619203
tensor(0.0073, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-8.3622e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.482588
Average KL loss: 1.149056
Average total loss: 1.631644
tensor(0.0073, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.4652e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.471375
Average KL loss: 1.149105
Average total loss: 1.620480
tensor(0.0073, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-2.5656e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.457321
Average KL loss: 1.149146
Average total loss: 1.606466
tensor(0.0073, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.9960e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.451686
Average KL loss: 1.149173
Average total loss: 1.600859
tensor(0.0073, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-9.4738e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.460456
Average KL loss: 1.149209
Average total loss: 1.609665
tensor(0.0073, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.2639e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.446985
Average KL loss: 1.149221
Average total loss: 1.596206
tensor(0.0073, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.4713e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.451482
Average KL loss: 1.149209
Average total loss: 1.600691
tensor(0.0073, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-2.3037e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.480925
Average KL loss: 1.149227
Average total loss: 1.630152
tensor(0.0073, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.7586e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.433662
Average KL loss: 1.149248
Average total loss: 1.582911
tensor(0.0073, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.7036e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.445267
Average KL loss: 1.149248
Average total loss: 1.594515
tensor(0.0073, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(2.7299e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.450365
Average KL loss: 1.149258
Average total loss: 1.599623
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-7.8868e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.479318
Average KL loss: 1.149285
Average total loss: 1.628603
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(8.1409e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.461283
Average KL loss: 1.149321
Average total loss: 1.610605
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.3746e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.455416
Average KL loss: 1.149341
Average total loss: 1.604757
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(7.0971e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.453592
Average KL loss: 1.149385
Average total loss: 1.602977
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-4.2079e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.462492
Average KL loss: 1.149431
Average total loss: 1.611923
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.7885e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.443309
Average KL loss: 1.149434
Average total loss: 1.592743
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(6.3099e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.464134
Average KL loss: 1.149457
Average total loss: 1.613591
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-2.9311e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.449021
Average KL loss: 1.149498
Average total loss: 1.598520
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(2.6578e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.449585
Average KL loss: 1.149518
Average total loss: 1.599102
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-3.8410e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.466328
Average KL loss: 1.149541
Average total loss: 1.615869
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.4536e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.491058
Average KL loss: 1.149548
Average total loss: 1.640606
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.5025e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.460272
Average KL loss: 1.149553
Average total loss: 1.609825
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(1.4466e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.449703
Average KL loss: 1.149555
Average total loss: 1.599258
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-2.4946e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.444147
Average KL loss: 1.149558
Average total loss: 1.593704
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.5612e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.482620
Average KL loss: 1.149559
Average total loss: 1.632179
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-5.1771e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.462296
Average KL loss: 1.149562
Average total loss: 1.611858
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-2.7534e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.458444
Average KL loss: 1.149567
Average total loss: 1.608011
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-4.2101e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.471460
Average KL loss: 1.149573
Average total loss: 1.621032
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-7.6088e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.460329
Average KL loss: 1.149575
Average total loss: 1.609904
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-2.0259e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.461324
Average KL loss: 1.149578
Average total loss: 1.610902
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-2.2136e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.477962
Average KL loss: 1.149580
Average total loss: 1.627542
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.6602e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.438875
Average KL loss: 1.149581
Average total loss: 1.588456
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.5096e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.465686
Average KL loss: 1.149581
Average total loss: 1.615268
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-5.0032e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.440648
Average KL loss: 1.149582
Average total loss: 1.590229
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.0725e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.460576
Average KL loss: 1.149582
Average total loss: 1.610158
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-4.1894e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.477738
Average KL loss: 1.149582
Average total loss: 1.627320
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-6.6732e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.465185
Average KL loss: 1.149583
Average total loss: 1.614768
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-3.0448e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.464714
Average KL loss: 1.149584
Average total loss: 1.614298
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-2.7693e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.468282
Average KL loss: 1.149584
Average total loss: 1.617866
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.3987e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.452816
Average KL loss: 1.149584
Average total loss: 1.602401
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-5.0850e-08, device='cuda:0')
 Percentile value: 8.03403850113682e-08
Non-zero model percentage: 0.9223561882972717%, Non-zero mask percentage: 0.9223561882972717%

--- Pruning Level [21/24]: ---
conv1.weight         | nonzeros =     522 /    1728             ( 30.21%) | total_pruned =    1206 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     702 /   36864             (  1.90%) | total_pruned =   36162 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     888 /   36864             (  2.41%) | total_pruned =   35976 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     683 /   36864             (  1.85%) | total_pruned =   36181 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     740 /   36864             (  2.01%) | total_pruned =   36124 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1279 /   73728             (  1.73%) | total_pruned =   72449 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1659 /  147456             (  1.13%) | total_pruned =  145797 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     627 /    8192             (  7.65%) | total_pruned =    7565 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     740 /  147456             (  0.50%) | total_pruned =  146716 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     687 /  147456             (  0.47%) | total_pruned =  146769 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2881 /  294912             (  0.98%) | total_pruned =  292031 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    3742 /  589824             (  0.63%) | total_pruned =  586082 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     980 /   32768             (  2.99%) | total_pruned =   31788 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1138 /  589824             (  0.19%) | total_pruned =  588686 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     169 /     256             ( 66.02%) | total_pruned =      87 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     974 /  589824             (  0.17%) | total_pruned =  588850 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     192 /     256             ( 75.00%) | total_pruned =      64 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    4856 / 1179648             (  0.41%) | total_pruned = 1174792 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     492 /     512             ( 96.09%) | total_pruned =      20 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    4414 / 2359296             (  0.19%) | total_pruned = 2354882 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     428 /     512             ( 83.59%) | total_pruned =      84 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     402 /  131072             (  0.31%) | total_pruned =  130670 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     182 /     512             ( 35.55%) | total_pruned =     330 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      38 /     512             (  7.42%) | total_pruned =     474 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2133 / 2359296             (  0.09%) | total_pruned = 2357163 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     252 /     512             ( 49.22%) | total_pruned =     260 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   68942 / 2359296             (  2.92%) | total_pruned = 2290354 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
linear.weight        | nonzeros =     358 /    5120             (  6.99%) | total_pruned =    4762 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 103108, pruned : 11075654, total: 11178762, Compression rate :     108.42x  ( 99.08% pruned)
Train Epoch: 21/100 Loss: 0.008482 Accuracy: 82.41 99.98 % Best test Accuracy: 82.54%
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-2.3667e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.582721
Average KL loss: 1.125906
Average total loss: 1.708628
tensor(0.0070, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-2.0756e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.637411
Average KL loss: 1.114390
Average total loss: 1.751801
tensor(0.0069, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-2.1344e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.634659
Average KL loss: 1.113243
Average total loss: 1.747902
tensor(0.0069, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-4.6630e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.618981
Average KL loss: 1.113981
Average total loss: 1.732963
tensor(0.0069, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-3.5413e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.641292
Average KL loss: 1.115161
Average total loss: 1.756453
tensor(0.0069, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-2.5017e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.637944
Average KL loss: 1.116744
Average total loss: 1.754688
tensor(0.0069, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-5.4506e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.634211
Average KL loss: 1.118918
Average total loss: 1.753129
tensor(0.0069, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-2.5009e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.637036
Average KL loss: 1.120955
Average total loss: 1.757991
tensor(0.0069, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-2.6408e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.624575
Average KL loss: 1.123003
Average total loss: 1.747578
tensor(0.0069, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-2.9549e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.607368
Average KL loss: 1.125119
Average total loss: 1.732488
tensor(0.0069, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.4183e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.583846
Average KL loss: 1.126728
Average total loss: 1.710574
tensor(0.0070, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-2.8449e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.580711
Average KL loss: 1.128255
Average total loss: 1.708966
tensor(0.0070, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.3521e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.607956
Average KL loss: 1.128969
Average total loss: 1.736925
tensor(0.0070, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-5.9592e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.602079
Average KL loss: 1.129146
Average total loss: 1.731225
tensor(0.0070, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-2.8791e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.583360
Average KL loss: 1.129286
Average total loss: 1.712646
tensor(0.0070, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-3.7869e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.571089
Average KL loss: 1.129417
Average total loss: 1.700506
tensor(0.0070, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-2.5254e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.596580
Average KL loss: 1.129571
Average total loss: 1.726151
tensor(0.0070, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-5.6250e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.592627
Average KL loss: 1.129712
Average total loss: 1.722339
tensor(0.0070, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-5.5550e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.583210
Average KL loss: 1.129823
Average total loss: 1.713032
tensor(0.0070, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-2.8979e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.575136
Average KL loss: 1.129947
Average total loss: 1.705083
tensor(0.0070, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.7546e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.586593
Average KL loss: 1.130063
Average total loss: 1.716656
tensor(0.0070, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.5949e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.591094
Average KL loss: 1.130208
Average total loss: 1.721302
tensor(0.0070, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-3.1522e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.601626
Average KL loss: 1.130408
Average total loss: 1.732033
tensor(0.0070, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.8615e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.584450
Average KL loss: 1.130605
Average total loss: 1.715055
tensor(0.0070, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-3.4506e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.584996
Average KL loss: 1.130760
Average total loss: 1.715756
tensor(0.0070, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-2.2678e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.558776
Average KL loss: 1.130894
Average total loss: 1.689670
tensor(0.0070, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-6.6319e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.584054
Average KL loss: 1.131002
Average total loss: 1.715056
tensor(0.0070, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-2.8596e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.549597
Average KL loss: 1.131112
Average total loss: 1.680709
tensor(0.0070, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.6163e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.595376
Average KL loss: 1.131256
Average total loss: 1.726631
tensor(0.0070, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-3.2934e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.609392
Average KL loss: 1.131416
Average total loss: 1.740808
tensor(0.0070, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-3.7609e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.585367
Average KL loss: 1.131587
Average total loss: 1.716954
tensor(0.0070, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-4.8979e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.576991
Average KL loss: 1.131723
Average total loss: 1.708714
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-6.3887e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.558422
Average KL loss: 1.131864
Average total loss: 1.690286
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.5616e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.570566
Average KL loss: 1.132007
Average total loss: 1.702572
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.6568e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.560764
Average KL loss: 1.132161
Average total loss: 1.692925
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.3896e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.584869
Average KL loss: 1.132285
Average total loss: 1.717154
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.0647e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.598215
Average KL loss: 1.132421
Average total loss: 1.730635
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-2.3191e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.605158
Average KL loss: 1.132597
Average total loss: 1.737755
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.2220e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.607461
Average KL loss: 1.132744
Average total loss: 1.740206
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.5313e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.585239
Average KL loss: 1.132831
Average total loss: 1.718070
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-4.2446e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.562746
Average KL loss: 1.132847
Average total loss: 1.695593
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.2601e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.569850
Average KL loss: 1.132864
Average total loss: 1.702713
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.3707e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.595532
Average KL loss: 1.132878
Average total loss: 1.728409
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-2.0261e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.570829
Average KL loss: 1.132889
Average total loss: 1.703718
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.6522e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.573308
Average KL loss: 1.132902
Average total loss: 1.706210
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.0174e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.584289
Average KL loss: 1.132915
Average total loss: 1.717204
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.7928e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.563263
Average KL loss: 1.132926
Average total loss: 1.696189
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-4.4869e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.602904
Average KL loss: 1.132939
Average total loss: 1.735843
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-2.2289e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.562163
Average KL loss: 1.132955
Average total loss: 1.695119
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-2.0312e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.584104
Average KL loss: 1.132971
Average total loss: 1.717075
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-2.8453e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.592435
Average KL loss: 1.132979
Average total loss: 1.725414
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.8602e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.550251
Average KL loss: 1.132981
Average total loss: 1.683232
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.2899e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.587479
Average KL loss: 1.132982
Average total loss: 1.720461
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.7947e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.582191
Average KL loss: 1.132984
Average total loss: 1.715175
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-2.3628e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.579906
Average KL loss: 1.132985
Average total loss: 1.712891
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.4811e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.592270
Average KL loss: 1.132987
Average total loss: 1.725257
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-2.3283e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.569923
Average KL loss: 1.132988
Average total loss: 1.702911
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-2.2298e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.567905
Average KL loss: 1.132989
Average total loss: 1.700894
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.8928e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.574307
Average KL loss: 1.132991
Average total loss: 1.707298
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.6528e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.561129
Average KL loss: 1.132992
Average total loss: 1.694120
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.6375e-08, device='cuda:0')
 Percentile value: 7.989550709908144e-08
Non-zero model percentage: 0.7378903031349182%, Non-zero mask percentage: 0.7378903031349182%

--- Pruning Level [22/24]: ---
conv1.weight         | nonzeros =     521 /    1728             ( 30.15%) | total_pruned =    1207 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     690 /   36864             (  1.87%) | total_pruned =   36174 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     882 /   36864             (  2.39%) | total_pruned =   35982 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     674 /   36864             (  1.83%) | total_pruned =   36190 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     725 /   36864             (  1.97%) | total_pruned =   36139 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1267 /   73728             (  1.72%) | total_pruned =   72461 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1637 /  147456             (  1.11%) | total_pruned =  145819 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     623 /    8192             (  7.60%) | total_pruned =    7569 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     726 /  147456             (  0.49%) | total_pruned =  146730 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     676 /  147456             (  0.46%) | total_pruned =  146780 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2826 /  294912             (  0.96%) | total_pruned =  292086 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    3669 /  589824             (  0.62%) | total_pruned =  586155 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     968 /   32768             (  2.95%) | total_pruned =   31800 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     224 /     256             ( 87.50%) | total_pruned =      32 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1102 /  589824             (  0.19%) | total_pruned =  588722 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     167 /     256             ( 65.23%) | total_pruned =      89 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     949 /  589824             (  0.16%) | total_pruned =  588875 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     192 /     256             ( 75.00%) | total_pruned =      64 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    4741 / 1179648             (  0.40%) | total_pruned = 1174907 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     492 /     512             ( 96.09%) | total_pruned =      20 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      31 /     512             (  6.05%) | total_pruned =     481 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    4260 / 2359296             (  0.18%) | total_pruned = 2355036 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     425 /     512             ( 83.01%) | total_pruned =      87 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     396 /  131072             (  0.30%) | total_pruned =  130676 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     174 /     512             ( 33.98%) | total_pruned =     338 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      34 /     512             (  6.64%) | total_pruned =     478 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2073 / 2359296             (  0.09%) | total_pruned = 2357223 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     249 /     512             ( 48.63%) | total_pruned =     263 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   48994 / 2359296             (  2.08%) | total_pruned = 2310302 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
linear.weight        | nonzeros =     355 /    5120             (  6.93%) | total_pruned =    4765 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 82487, pruned : 11096275, total: 11178762, Compression rate :     135.52x  ( 99.26% pruned)
Train Epoch: 21/100 Loss: 0.002061 Accuracy: 82.70 100.00 % Best test Accuracy: 82.77%
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.0784e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.657670
Average KL loss: 1.109703
Average total loss: 1.767373
tensor(0.0067, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-4.6964e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.697960
Average KL loss: 1.100218
Average total loss: 1.798177
tensor(0.0067, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-3.7796e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.736462
Average KL loss: 1.099877
Average total loss: 1.836340
tensor(0.0067, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-4.5448e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.709188
Average KL loss: 1.101686
Average total loss: 1.810874
tensor(0.0067, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-4.4259e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.659094
Average KL loss: 1.103855
Average total loss: 1.762949
tensor(0.0067, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-3.3323e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.692222
Average KL loss: 1.106067
Average total loss: 1.798290
tensor(0.0067, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-1.2486e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.680236
Average KL loss: 1.108704
Average total loss: 1.788940
tensor(0.0067, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-4.1250e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.707474
Average KL loss: 1.111134
Average total loss: 1.818608
tensor(0.0068, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-6.3980e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.671904
Average KL loss: 1.113375
Average total loss: 1.785279
tensor(0.0068, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-4.4170e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.696110
Average KL loss: 1.115434
Average total loss: 1.811544
tensor(0.0068, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-2.1243e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.688319
Average KL loss: 1.118272
Average total loss: 1.806591
tensor(0.0068, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-3.7132e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.648171
Average KL loss: 1.120558
Average total loss: 1.768729
tensor(0.0068, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-4.2023e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.634389
Average KL loss: 1.122868
Average total loss: 1.757257
tensor(0.0068, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-4.9981e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.649995
Average KL loss: 1.124683
Average total loss: 1.774678
tensor(0.0069, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-3.6794e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.620969
Average KL loss: 1.126801
Average total loss: 1.747770
tensor(0.0069, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-4.7317e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.593028
Average KL loss: 1.128693
Average total loss: 1.721721
tensor(0.0069, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-4.0429e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.600768
Average KL loss: 1.130481
Average total loss: 1.731249
tensor(0.0069, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-3.4758e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.574566
Average KL loss: 1.132094
Average total loss: 1.706660
tensor(0.0069, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-7.5063e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.586108
Average KL loss: 1.133471
Average total loss: 1.719579
tensor(0.0069, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-3.5100e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.598528
Average KL loss: 1.134905
Average total loss: 1.733432
tensor(0.0069, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-9.2715e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.583013
Average KL loss: 1.136155
Average total loss: 1.719168
tensor(0.0069, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-4.2670e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.570665
Average KL loss: 1.137718
Average total loss: 1.708383
tensor(0.0070, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-5.4723e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.554532
Average KL loss: 1.138910
Average total loss: 1.693442
tensor(0.0070, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-3.1733e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.555107
Average KL loss: 1.140187
Average total loss: 1.695294
tensor(0.0070, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-3.7380e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.578401
Average KL loss: 1.141568
Average total loss: 1.719969
tensor(0.0070, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-3.1803e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.587527
Average KL loss: 1.142693
Average total loss: 1.730220
tensor(0.0070, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-3.3965e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.537675
Average KL loss: 1.143994
Average total loss: 1.681668
tensor(0.0070, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.8086e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.549309
Average KL loss: 1.145616
Average total loss: 1.694925
tensor(0.0070, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.2769e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.541645
Average KL loss: 1.147228
Average total loss: 1.688873
tensor(0.0070, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.8598e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.516256
Average KL loss: 1.148187
Average total loss: 1.664443
tensor(0.0071, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-2.8292e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.513071
Average KL loss: 1.149089
Average total loss: 1.662159
tensor(0.0071, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-3.4665e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.535790
Average KL loss: 1.150284
Average total loss: 1.686075
tensor(0.0071, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-2.7588e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.516480
Average KL loss: 1.151456
Average total loss: 1.667935
tensor(0.0071, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-3.1142e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.495524
Average KL loss: 1.152607
Average total loss: 1.648131
tensor(0.0071, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-2.9599e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.518370
Average KL loss: 1.153316
Average total loss: 1.671686
tensor(0.0071, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-5.8666e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.500529
Average KL loss: 1.154570
Average total loss: 1.655100
tensor(0.0071, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-4.2987e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.526224
Average KL loss: 1.155771
Average total loss: 1.681995
tensor(0.0071, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-1.9010e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.492916
Average KL loss: 1.156998
Average total loss: 1.649913
tensor(0.0071, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-3.3357e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.526394
Average KL loss: 1.157904
Average total loss: 1.684298
tensor(0.0072, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-1.9935e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.508074
Average KL loss: 1.158791
Average total loss: 1.666865
tensor(0.0072, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(1.0087e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.500948
Average KL loss: 1.159513
Average total loss: 1.660462
tensor(0.0072, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-1.4848e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.500304
Average KL loss: 1.160531
Average total loss: 1.660836
tensor(0.0072, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(6.2532e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.485440
Average KL loss: 1.161490
Average total loss: 1.646930
tensor(0.0072, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(7.0349e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.501084
Average KL loss: 1.162242
Average total loss: 1.663325
tensor(0.0072, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-1.5172e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.474728
Average KL loss: 1.162714
Average total loss: 1.637442
tensor(0.0072, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-3.1964e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.482990
Average KL loss: 1.163422
Average total loss: 1.646412
tensor(0.0072, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-1.3357e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.484572
Average KL loss: 1.164015
Average total loss: 1.648587
tensor(0.0072, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-1.7942e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.495338
Average KL loss: 1.164748
Average total loss: 1.660086
tensor(0.0072, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.2779e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.458497
Average KL loss: 1.165522
Average total loss: 1.624019
tensor(0.0072, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-1.4763e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.487147
Average KL loss: 1.166152
Average total loss: 1.653299
tensor(0.0072, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-5.5465e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.463982
Average KL loss: 1.166928
Average total loss: 1.630910
tensor(0.0073, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-6.7038e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.451871
Average KL loss: 1.167707
Average total loss: 1.619578
tensor(0.0073, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-1.5278e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.444185
Average KL loss: 1.168239
Average total loss: 1.612424
tensor(0.0073, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-3.0543e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.490220
Average KL loss: 1.168784
Average total loss: 1.659004
tensor(0.0073, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-2.0608e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.481176
Average KL loss: 1.169842
Average total loss: 1.651019
tensor(0.0073, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.4376e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.451937
Average KL loss: 1.170274
Average total loss: 1.622211
tensor(0.0073, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.2221e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.447358
Average KL loss: 1.170871
Average total loss: 1.618229
tensor(0.0073, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-1.7842e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.469090
Average KL loss: 1.171384
Average total loss: 1.640475
tensor(0.0073, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.2139e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.443499
Average KL loss: 1.171768
Average total loss: 1.615267
tensor(0.0073, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.5748e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.468478
Average KL loss: 1.172434
Average total loss: 1.640912
tensor(0.0073, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.7350e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.468073
Average KL loss: 1.172838
Average total loss: 1.640911
tensor(0.0073, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-1.9151e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.428085
Average KL loss: 1.173359
Average total loss: 1.601444
tensor(0.0073, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-5.7011e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.453596
Average KL loss: 1.173785
Average total loss: 1.627381
tensor(0.0074, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-7.5992e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.469370
Average KL loss: 1.174379
Average total loss: 1.643750
tensor(0.0074, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-2.3102e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.421949
Average KL loss: 1.175225
Average total loss: 1.597174
tensor(0.0074, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(2.2016e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.451582
Average KL loss: 1.175859
Average total loss: 1.627441
tensor(0.0074, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(1.1135e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.445235
Average KL loss: 1.176259
Average total loss: 1.621493
tensor(0.0074, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-1.6719e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.446499
Average KL loss: 1.177047
Average total loss: 1.623545
tensor(0.0074, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-1.7218e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.411569
Average KL loss: 1.177833
Average total loss: 1.589402
tensor(0.0074, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-1.4497e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.426593
Average KL loss: 1.178359
Average total loss: 1.604952
tensor(0.0074, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-1.1303e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.431350
Average KL loss: 1.178754
Average total loss: 1.610105
tensor(0.0074, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-1.9891e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.421511
Average KL loss: 1.179248
Average total loss: 1.600759
tensor(0.0074, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-7.2099e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.415596
Average KL loss: 1.179499
Average total loss: 1.595095
tensor(0.0074, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-6.2279e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.410242
Average KL loss: 1.179638
Average total loss: 1.589879
tensor(0.0074, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-2.3292e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.425510
Average KL loss: 1.179925
Average total loss: 1.605435
tensor(0.0074, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-2.4977e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.416357
Average KL loss: 1.180657
Average total loss: 1.597014
tensor(0.0075, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(1.5475e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.414947
Average KL loss: 1.181234
Average total loss: 1.596181
tensor(0.0075, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-3.5808e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.404814
Average KL loss: 1.181682
Average total loss: 1.586496
tensor(0.0075, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-8.9972e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.428780
Average KL loss: 1.182095
Average total loss: 1.610874
tensor(0.0075, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-2.4078e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.423005
Average KL loss: 1.182396
Average total loss: 1.605400
tensor(0.0075, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-1.3552e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.404172
Average KL loss: 1.182812
Average total loss: 1.586985
tensor(0.0075, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-1.4779e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.395950
Average KL loss: 1.183019
Average total loss: 1.578969
tensor(0.0075, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-9.3907e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.405705
Average KL loss: 1.182977
Average total loss: 1.588682
tensor(0.0075, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-1.7782e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.408318
Average KL loss: 1.183322
Average total loss: 1.591639
tensor(0.0075, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.2071e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.393931
Average KL loss: 1.183760
Average total loss: 1.577691
tensor(0.0075, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-9.2382e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.392231
Average KL loss: 1.183839
Average total loss: 1.576070
tensor(0.0075, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-5.2220e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.409142
Average KL loss: 1.183886
Average total loss: 1.593028
tensor(0.0075, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-1.6540e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.411396
Average KL loss: 1.184482
Average total loss: 1.595877
tensor(0.0075, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-1.1839e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.401110
Average KL loss: 1.184811
Average total loss: 1.585921
tensor(0.0075, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-9.4287e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.393923
Average KL loss: 1.185040
Average total loss: 1.578962
tensor(0.0075, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-6.6422e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.399413
Average KL loss: 1.185643
Average total loss: 1.585056
tensor(0.0075, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-1.3586e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.416486
Average KL loss: 1.186217
Average total loss: 1.602703
tensor(0.0076, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-1.3809e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.416638
Average KL loss: 1.186640
Average total loss: 1.603278
tensor(0.0076, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-3.0007e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.388697
Average KL loss: 1.186934
Average total loss: 1.575630
tensor(0.0076, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-1.6992e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.375967
Average KL loss: 1.187177
Average total loss: 1.563143
tensor(0.0076, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-6.8682e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.382810
Average KL loss: 1.187328
Average total loss: 1.570138
tensor(0.0076, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-1.6276e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.393649
Average KL loss: 1.187458
Average total loss: 1.581108
tensor(0.0076, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-9.4080e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.414190
Average KL loss: 1.187815
Average total loss: 1.602005
tensor(0.0076, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-1.6014e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.400407
Average KL loss: 1.188347
Average total loss: 1.588754
tensor(0.0076, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-9.6213e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.374899
Average KL loss: 1.188488
Average total loss: 1.563387
tensor(0.0076, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-3.1980e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.401701
Average KL loss: 1.188876
Average total loss: 1.590576
tensor(0.0076, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-5.3827e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.377921
Average KL loss: 1.189296
Average total loss: 1.567217
tensor(0.0076, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-2.7120e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.386274
Average KL loss: 1.189779
Average total loss: 1.576053
tensor(0.0076, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-1.5437e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.376949
Average KL loss: 1.189873
Average total loss: 1.566821
tensor(0.0076, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(1.8033e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.381474
Average KL loss: 1.190214
Average total loss: 1.571688
tensor(0.0076, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.6783e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.377424
Average KL loss: 1.190558
Average total loss: 1.567982
tensor(0.0076, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.9030e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.393439
Average KL loss: 1.190724
Average total loss: 1.584163
tensor(0.0076, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.2779e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.372728
Average KL loss: 1.190753
Average total loss: 1.563481
tensor(0.0076, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-1.6820e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.375753
Average KL loss: 1.190745
Average total loss: 1.566498
tensor(0.0076, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(5.8658e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.377472
Average KL loss: 1.190710
Average total loss: 1.568183
tensor(0.0076, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-9.4535e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.382363
Average KL loss: 1.190703
Average total loss: 1.573066
tensor(0.0076, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.0484e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.368341
Average KL loss: 1.190688
Average total loss: 1.559029
tensor(0.0076, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-3.0049e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.370429
Average KL loss: 1.190705
Average total loss: 1.561134
tensor(0.0076, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.4327e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.383070
Average KL loss: 1.190718
Average total loss: 1.573787
tensor(0.0076, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.3975e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.357377
Average KL loss: 1.190712
Average total loss: 1.548089
tensor(0.0076, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-3.5358e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.371204
Average KL loss: 1.190696
Average total loss: 1.561900
tensor(0.0076, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.6779e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.375704
Average KL loss: 1.190697
Average total loss: 1.566401
tensor(0.0076, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-3.0965e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.397623
Average KL loss: 1.190716
Average total loss: 1.588339
tensor(0.0076, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.5070e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.366575
Average KL loss: 1.190747
Average total loss: 1.557322
tensor(0.0076, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-3.9981e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.374714
Average KL loss: 1.190756
Average total loss: 1.565470
tensor(0.0076, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(1.6034e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.365141
Average KL loss: 1.190763
Average total loss: 1.555903
tensor(0.0076, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.6829e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.365149
Average KL loss: 1.190768
Average total loss: 1.555917
tensor(0.0076, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-2.7002e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.367608
Average KL loss: 1.190751
Average total loss: 1.558359
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.2324e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.360096
Average KL loss: 1.190756
Average total loss: 1.550852
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-2.5834e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.365059
Average KL loss: 1.190741
Average total loss: 1.555800
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.2319e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.364264
Average KL loss: 1.190742
Average total loss: 1.555006
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.0690e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.377799
Average KL loss: 1.190751
Average total loss: 1.568550
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-7.9873e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.373907
Average KL loss: 1.190749
Average total loss: 1.564656
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-3.0123e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.363324
Average KL loss: 1.190751
Average total loss: 1.554075
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.2803e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.365190
Average KL loss: 1.190752
Average total loss: 1.555943
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.6221e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.375491
Average KL loss: 1.190752
Average total loss: 1.566244
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.2224e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.369396
Average KL loss: 1.190751
Average total loss: 1.560146
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.9569e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.372270
Average KL loss: 1.190746
Average total loss: 1.563016
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-4.3510e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.388279
Average KL loss: 1.190746
Average total loss: 1.579026
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.5077e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.383805
Average KL loss: 1.190748
Average total loss: 1.574553
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-2.5123e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.368932
Average KL loss: 1.190750
Average total loss: 1.559682
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.1921e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.365744
Average KL loss: 1.190751
Average total loss: 1.556495
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-5.5310e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.379859
Average KL loss: 1.190750
Average total loss: 1.570609
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(9.9555e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.375006
Average KL loss: 1.190750
Average total loss: 1.565757
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.3293e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.369949
Average KL loss: 1.190751
Average total loss: 1.560699
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-2.2726e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.387049
Average KL loss: 1.190751
Average total loss: 1.577799
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(3.7700e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.373638
Average KL loss: 1.190751
Average total loss: 1.564389
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.6112e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.373725
Average KL loss: 1.190751
Average total loss: 1.564476
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.2450e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.365023
Average KL loss: 1.190752
Average total loss: 1.555775
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-6.0316e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.375752
Average KL loss: 1.190752
Average total loss: 1.566504
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(1.7733e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.360925
Average KL loss: 1.190752
Average total loss: 1.551677
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-8.4129e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.373095
Average KL loss: 1.190752
Average total loss: 1.563848
tensor(0.0077, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-1.0482e-08, device='cuda:0')
 Percentile value: 7.960574777143847e-08
Non-zero model percentage: 0.5903157591819763%, Non-zero mask percentage: 0.5903157591819763%

--- Pruning Level [23/24]: ---
conv1.weight         | nonzeros =     517 /    1728             ( 29.92%) | total_pruned =    1211 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     681 /   36864             (  1.85%) | total_pruned =   36183 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     867 /   36864             (  2.35%) | total_pruned =   35997 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     661 /   36864             (  1.79%) | total_pruned =   36203 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     715 /   36864             (  1.94%) | total_pruned =   36149 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1246 /   73728             (  1.69%) | total_pruned =   72482 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1609 /  147456             (  1.09%) | total_pruned =  145847 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     615 /    8192             (  7.51%) | total_pruned =    7577 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     711 /  147456             (  0.48%) | total_pruned =  146745 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     667 /  147456             (  0.45%) | total_pruned =  146789 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2766 /  294912             (  0.94%) | total_pruned =  292146 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    3575 /  589824             (  0.61%) | total_pruned =  586249 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     949 /   32768             (  2.90%) | total_pruned =   31819 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1070 /  589824             (  0.18%) | total_pruned =  588754 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     166 /     256             ( 64.84%) | total_pruned =      90 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     916 /  589824             (  0.16%) | total_pruned =  588908 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     192 /     256             ( 75.00%) | total_pruned =      64 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    4589 / 1179648             (  0.39%) | total_pruned = 1175059 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     490 /     512             ( 95.70%) | total_pruned =      22 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    4109 / 2359296             (  0.17%) | total_pruned = 2355187 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     424 /     512             ( 82.81%) | total_pruned =      88 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     387 /  131072             (  0.30%) | total_pruned =  130685 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     172 /     512             ( 33.59%) | total_pruned =     340 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2000 / 2359296             (  0.08%) | total_pruned = 2357296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     248 /     512             ( 48.44%) | total_pruned =     264 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   33267 / 2359296             (  1.41%) | total_pruned = 2326029 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
linear.weight        | nonzeros =     351 /    5120             (  6.86%) | total_pruned =    4769 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 65990, pruned : 11112772, total: 11178762, Compression rate :     169.40x  ( 99.41% pruned)
Train Epoch: 21/100 Loss: 0.004558 Accuracy: 82.43 100.00 % Best test Accuracy: 82.67%
