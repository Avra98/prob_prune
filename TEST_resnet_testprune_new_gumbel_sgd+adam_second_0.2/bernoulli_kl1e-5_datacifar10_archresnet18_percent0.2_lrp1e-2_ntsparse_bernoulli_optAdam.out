Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/24]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/100 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(2.2858e-06, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.842214
Average KL loss: 51.205980
Average total loss: 53.048193
tensor(-0.3263, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(2.3036e-06, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.539445
Average KL loss: 43.283579
Average total loss: 44.823023
tensor(-0.6075, device='cuda:0') tensor(0.0950, device='cuda:0') tensor(2.0862e-06, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.328707
Average KL loss: 36.797161
Average total loss: 38.125868
tensor(-0.8654, device='cuda:0') tensor(0.1945, device='cuda:0') tensor(1.8518e-06, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.195685
Average KL loss: 31.636416
Average total loss: 32.832100
tensor(-1.0985, device='cuda:0') tensor(0.3052, device='cuda:0') tensor(1.6975e-06, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.113441
Average KL loss: 27.604928
Average total loss: 28.718368
tensor(-1.3075, device='cuda:0') tensor(0.4152, device='cuda:0') tensor(1.5482e-06, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.041288
Average KL loss: 24.434859
Average total loss: 25.476146
tensor(-1.4953, device='cuda:0') tensor(0.5183, device='cuda:0') tensor(1.3772e-06, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.983985
Average KL loss: 21.899403
Average total loss: 22.883387
tensor(-1.6647, device='cuda:0') tensor(0.6125, device='cuda:0') tensor(1.2520e-06, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.935748
Average KL loss: 19.833767
Average total loss: 20.769514
tensor(-1.8184, device='cuda:0') tensor(0.6975, device='cuda:0') tensor(1.1509e-06, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.874812
Average KL loss: 18.122524
Average total loss: 18.997336
tensor(-1.9588, device='cuda:0') tensor(0.7737, device='cuda:0') tensor(1.0574e-06, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.853488
Average KL loss: 16.678564
Average total loss: 17.532052
tensor(-2.0880, device='cuda:0') tensor(0.8419, device='cuda:0') tensor(1.0042e-06, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.826411
Average KL loss: 15.443607
Average total loss: 16.270018
tensor(-2.2074, device='cuda:0') tensor(0.9032, device='cuda:0') tensor(9.2353e-07, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.795674
Average KL loss: 14.375667
Average total loss: 15.171340
tensor(-2.3183, device='cuda:0') tensor(0.9585, device='cuda:0') tensor(8.4631e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.756798
Average KL loss: 13.443233
Average total loss: 14.200031
tensor(-2.4218, device='cuda:0') tensor(1.0085, device='cuda:0') tensor(8.0595e-07, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.757134
Average KL loss: 12.620784
Average total loss: 13.377918
tensor(-2.5188, device='cuda:0') tensor(1.0540, device='cuda:0') tensor(7.5902e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.732274
Average KL loss: 11.889878
Average total loss: 12.622151
tensor(-2.6100, device='cuda:0') tensor(1.0955, device='cuda:0') tensor(7.3302e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.706229
Average KL loss: 11.236757
Average total loss: 11.942986
tensor(-2.6961, device='cuda:0') tensor(1.1337, device='cuda:0') tensor(6.8779e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.678526
Average KL loss: 10.648519
Average total loss: 11.327044
tensor(-2.7776, device='cuda:0') tensor(1.1687, device='cuda:0') tensor(6.4534e-07, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.682383
Average KL loss: 10.116205
Average total loss: 10.798589
tensor(-2.8549, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(6.1790e-07, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.667043
Average KL loss: 9.633089
Average total loss: 10.300132
tensor(-2.9285, device='cuda:0') tensor(1.2319, device='cuda:0') tensor(5.7920e-07, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.656584
Average KL loss: 9.192422
Average total loss: 9.849005
tensor(-2.9987, device='cuda:0') tensor(1.2604, device='cuda:0') tensor(5.6006e-07, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.645927
Average KL loss: 8.788566
Average total loss: 9.434493
tensor(-3.0657, device='cuda:0') tensor(1.2872, device='cuda:0') tensor(5.2622e-07, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.628530
Average KL loss: 8.417790
Average total loss: 9.046320
tensor(-3.1298, device='cuda:0') tensor(1.3126, device='cuda:0') tensor(4.9079e-07, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.619190
Average KL loss: 8.076343
Average total loss: 8.695533
tensor(-3.1913, device='cuda:0') tensor(1.3366, device='cuda:0') tensor(5.0753e-07, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.616374
Average KL loss: 7.760306
Average total loss: 8.376679
tensor(-3.2504, device='cuda:0') tensor(1.3594, device='cuda:0') tensor(4.8043e-07, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.604985
Average KL loss: 7.467135
Average total loss: 8.072120
tensor(-3.3072, device='cuda:0') tensor(1.3813, device='cuda:0') tensor(4.6585e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.593856
Average KL loss: 7.194880
Average total loss: 7.788736
tensor(-3.3620, device='cuda:0') tensor(1.4022, device='cuda:0') tensor(4.4420e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.589742
Average KL loss: 6.940971
Average total loss: 7.530713
tensor(-3.4149, device='cuda:0') tensor(1.4224, device='cuda:0') tensor(4.2884e-07, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.585291
Average KL loss: 6.703803
Average total loss: 7.289094
tensor(-3.4659, device='cuda:0') tensor(1.4419, device='cuda:0') tensor(4.0310e-07, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.581726
Average KL loss: 6.482873
Average total loss: 7.064598
tensor(-3.5152, device='cuda:0') tensor(1.4610, device='cuda:0') tensor(4.1135e-07, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.572865
Average KL loss: 6.275629
Average total loss: 6.848494
tensor(-3.5630, device='cuda:0') tensor(1.4794, device='cuda:0') tensor(3.8294e-07, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.576111
Average KL loss: 6.080650
Average total loss: 6.656761
tensor(-3.6093, device='cuda:0') tensor(1.4972, device='cuda:0') tensor(3.7036e-07, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.559167
Average KL loss: 5.897320
Average total loss: 6.456487
tensor(-3.6543, device='cuda:0') tensor(1.5146, device='cuda:0') tensor(3.5365e-07, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.556533
Average KL loss: 5.724549
Average total loss: 6.281082
tensor(-3.6979, device='cuda:0') tensor(1.5316, device='cuda:0') tensor(3.5672e-07, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.552031
Average KL loss: 5.561272
Average total loss: 6.113302
tensor(-3.7404, device='cuda:0') tensor(1.5481, device='cuda:0') tensor(3.4287e-07, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.555476
Average KL loss: 5.406817
Average total loss: 5.962293
tensor(-3.7817, device='cuda:0') tensor(1.5643, device='cuda:0') tensor(3.3613e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.550190
Average KL loss: 5.260993
Average total loss: 5.811182
tensor(-3.8219, device='cuda:0') tensor(1.5805, device='cuda:0') tensor(3.1190e-07, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.549583
Average KL loss: 5.122980
Average total loss: 5.672563
tensor(-3.8611, device='cuda:0') tensor(1.5963, device='cuda:0') tensor(3.0091e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.545864
Average KL loss: 4.992138
Average total loss: 5.538002
tensor(-3.8993, device='cuda:0') tensor(1.6120, device='cuda:0') tensor(3.0265e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.544505
Average KL loss: 4.867985
Average total loss: 5.412490
tensor(-3.9365, device='cuda:0') tensor(1.6275, device='cuda:0') tensor(2.9679e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.531598
Average KL loss: 4.749891
Average total loss: 5.281488
tensor(-3.9729, device='cuda:0') tensor(1.6426, device='cuda:0') tensor(3.0232e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.524677
Average KL loss: 4.636990
Average total loss: 5.161666
tensor(-4.0085, device='cuda:0') tensor(1.6575, device='cuda:0') tensor(2.8441e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.522023
Average KL loss: 4.529288
Average total loss: 5.051311
tensor(-4.0433, device='cuda:0') tensor(1.6722, device='cuda:0') tensor(2.8483e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.521305
Average KL loss: 4.426519
Average total loss: 4.947824
tensor(-4.0773, device='cuda:0') tensor(1.6870, device='cuda:0') tensor(2.7090e-07, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.536584
Average KL loss: 4.329073
Average total loss: 4.865657
tensor(-4.1106, device='cuda:0') tensor(1.7017, device='cuda:0') tensor(2.6280e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.521662
Average KL loss: 4.236020
Average total loss: 4.757682
tensor(-4.1433, device='cuda:0') tensor(1.7163, device='cuda:0') tensor(2.6730e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.519539
Average KL loss: 4.146740
Average total loss: 4.666279
tensor(-4.1752, device='cuda:0') tensor(1.7307, device='cuda:0') tensor(2.4931e-07, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.534664
Average KL loss: 4.061456
Average total loss: 4.596120
tensor(-4.2065, device='cuda:0') tensor(1.7452, device='cuda:0') tensor(2.4164e-07, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.521344
Average KL loss: 3.979865
Average total loss: 4.501209
tensor(-4.2372, device='cuda:0') tensor(1.7597, device='cuda:0') tensor(2.5577e-07, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.510377
Average KL loss: 3.901862
Average total loss: 4.412239
tensor(-4.2673, device='cuda:0') tensor(1.7740, device='cuda:0') tensor(2.2066e-07, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.513646
Average KL loss: 3.826668
Average total loss: 4.340314
tensor(-4.2970, device='cuda:0') tensor(1.7881, device='cuda:0') tensor(2.2143e-07, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.514702
Average KL loss: 3.754366
Average total loss: 4.269069
tensor(-4.3260, device='cuda:0') tensor(1.8023, device='cuda:0') tensor(2.1656e-07, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.507663
Average KL loss: 3.685278
Average total loss: 4.192941
tensor(-4.3546, device='cuda:0') tensor(1.8164, device='cuda:0') tensor(2.1863e-07, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.514687
Average KL loss: 3.618614
Average total loss: 4.133301
tensor(-4.3826, device='cuda:0') tensor(1.8305, device='cuda:0') tensor(2.1488e-07, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.511667
Average KL loss: 3.554920
Average total loss: 4.066587
tensor(-4.4101, device='cuda:0') tensor(1.8448, device='cuda:0') tensor(2.1300e-07, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.498976
Average KL loss: 3.493183
Average total loss: 3.992159
tensor(-4.4373, device='cuda:0') tensor(1.8586, device='cuda:0') tensor(2.0968e-07, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.505660
Average KL loss: 3.433297
Average total loss: 3.938957
tensor(-4.4640, device='cuda:0') tensor(1.8724, device='cuda:0') tensor(1.9194e-07, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.507553
Average KL loss: 3.375632
Average total loss: 3.883184
tensor(-4.4903, device='cuda:0') tensor(1.8862, device='cuda:0') tensor(1.9000e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.504094
Average KL loss: 3.320220
Average total loss: 3.824314
tensor(-4.5163, device='cuda:0') tensor(1.9001, device='cuda:0') tensor(1.9408e-07, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.502175
Average KL loss: 3.266663
Average total loss: 3.768838
tensor(-4.5418, device='cuda:0') tensor(1.9139, device='cuda:0') tensor(2.0107e-07, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.500447
Average KL loss: 3.214900
Average total loss: 3.715346
tensor(-4.5670, device='cuda:0') tensor(1.9277, device='cuda:0') tensor(1.8367e-07, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.487795
Average KL loss: 3.165048
Average total loss: 3.652843
tensor(-4.5918, device='cuda:0') tensor(1.9416, device='cuda:0') tensor(1.8234e-07, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.490343
Average KL loss: 3.116778
Average total loss: 3.607121
tensor(-4.6162, device='cuda:0') tensor(1.9553, device='cuda:0') tensor(1.8423e-07, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.498563
Average KL loss: 3.070068
Average total loss: 3.568632
tensor(-4.6403, device='cuda:0') tensor(1.9693, device='cuda:0') tensor(1.7992e-07, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.493252
Average KL loss: 3.024785
Average total loss: 3.518036
tensor(-4.6642, device='cuda:0') tensor(1.9829, device='cuda:0') tensor(1.8341e-07, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.487083
Average KL loss: 2.980680
Average total loss: 3.467763
tensor(-4.6877, device='cuda:0') tensor(1.9965, device='cuda:0') tensor(1.6692e-07, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.492769
Average KL loss: 2.938040
Average total loss: 3.430809
tensor(-4.7109, device='cuda:0') tensor(2.0102, device='cuda:0') tensor(1.6593e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.490921
Average KL loss: 2.896723
Average total loss: 3.387644
tensor(-4.7338, device='cuda:0') tensor(2.0239, device='cuda:0') tensor(1.5149e-07, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.494679
Average KL loss: 2.856781
Average total loss: 3.351460
tensor(-4.7565, device='cuda:0') tensor(2.0377, device='cuda:0') tensor(1.6813e-07, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.492806
Average KL loss: 2.817994
Average total loss: 3.310800
tensor(-4.7789, device='cuda:0') tensor(2.0514, device='cuda:0') tensor(1.5543e-07, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.491064
Average KL loss: 2.780354
Average total loss: 3.271418
tensor(-4.8010, device='cuda:0') tensor(2.0652, device='cuda:0') tensor(1.6071e-07, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.491181
Average KL loss: 2.744007
Average total loss: 3.235188
tensor(-4.8228, device='cuda:0') tensor(2.0790, device='cuda:0') tensor(1.4201e-07, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.488938
Average KL loss: 2.708530
Average total loss: 3.197467
tensor(-4.8444, device='cuda:0') tensor(2.0928, device='cuda:0') tensor(1.3768e-07, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.491107
Average KL loss: 2.674094
Average total loss: 3.165202
tensor(-4.8658, device='cuda:0') tensor(2.1066, device='cuda:0') tensor(1.6251e-07, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.486348
Average KL loss: 2.640636
Average total loss: 3.126984
tensor(-4.8869, device='cuda:0') tensor(2.1204, device='cuda:0') tensor(1.4952e-07, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.482604
Average KL loss: 2.608030
Average total loss: 3.090634
tensor(-4.9078, device='cuda:0') tensor(2.1342, device='cuda:0') tensor(1.4731e-07, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.482443
Average KL loss: 2.576319
Average total loss: 3.058762
tensor(-4.9284, device='cuda:0') tensor(2.1480, device='cuda:0') tensor(1.3978e-07, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.483632
Average KL loss: 2.545459
Average total loss: 3.029091
tensor(-4.9489, device='cuda:0') tensor(2.1617, device='cuda:0') tensor(1.2753e-07, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.484485
Average KL loss: 2.515388
Average total loss: 2.999873
tensor(-4.9691, device='cuda:0') tensor(2.1755, device='cuda:0') tensor(1.4583e-07, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.485255
Average KL loss: 2.486402
Average total loss: 2.971657
tensor(-4.9891, device='cuda:0') tensor(2.1895, device='cuda:0') tensor(1.3792e-07, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.471576
Average KL loss: 2.458076
Average total loss: 2.929653
tensor(-5.0089, device='cuda:0') tensor(2.2033, device='cuda:0') tensor(1.3015e-07, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.475109
Average KL loss: 2.430230
Average total loss: 2.905339
tensor(-5.0286, device='cuda:0') tensor(2.2172, device='cuda:0') tensor(1.4438e-07, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.476049
Average KL loss: 2.403008
Average total loss: 2.879056
tensor(-5.0480, device='cuda:0') tensor(2.2309, device='cuda:0') tensor(1.3079e-07, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.475509
Average KL loss: 2.376513
Average total loss: 2.852022
tensor(-5.0673, device='cuda:0') tensor(2.2447, device='cuda:0') tensor(1.3166e-07, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.479487
Average KL loss: 2.350591
Average total loss: 2.830078
tensor(-5.0865, device='cuda:0') tensor(2.2585, device='cuda:0') tensor(1.2825e-07, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.481842
Average KL loss: 2.325544
Average total loss: 2.807386
tensor(-5.1054, device='cuda:0') tensor(2.2726, device='cuda:0') tensor(1.4395e-07, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.474544
Average KL loss: 2.301071
Average total loss: 2.775615
tensor(-5.1242, device='cuda:0') tensor(2.2865, device='cuda:0') tensor(1.2670e-07, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.475302
Average KL loss: 2.277022
Average total loss: 2.752324
tensor(-5.1428, device='cuda:0') tensor(2.3003, device='cuda:0') tensor(1.2291e-07, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.478173
Average KL loss: 2.253570
Average total loss: 2.731742
tensor(-5.1612, device='cuda:0') tensor(2.3142, device='cuda:0') tensor(1.2534e-07, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.474599
Average KL loss: 2.230634
Average total loss: 2.705233
tensor(-5.1795, device='cuda:0') tensor(2.3281, device='cuda:0') tensor(1.3062e-07, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.472311
Average KL loss: 2.208195
Average total loss: 2.680506
tensor(-5.1976, device='cuda:0') tensor(2.3421, device='cuda:0') tensor(1.1532e-07, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.474693
Average KL loss: 2.186444
Average total loss: 2.661137
tensor(-5.2156, device='cuda:0') tensor(2.3562, device='cuda:0') tensor(1.1428e-07, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.470633
Average KL loss: 2.165189
Average total loss: 2.635823
tensor(-5.2335, device='cuda:0') tensor(2.3702, device='cuda:0') tensor(1.1286e-07, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.468099
Average KL loss: 2.144102
Average total loss: 2.612201
tensor(-5.2512, device='cuda:0') tensor(2.3841, device='cuda:0') tensor(1.0846e-07, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.468303
Average KL loss: 2.123573
Average total loss: 2.591877
tensor(-5.2687, device='cuda:0') tensor(2.3981, device='cuda:0') tensor(1.1339e-07, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.471813
Average KL loss: 2.103516
Average total loss: 2.575329
tensor(-5.2862, device='cuda:0') tensor(2.4122, device='cuda:0') tensor(1.1694e-07, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.472561
Average KL loss: 2.084057
Average total loss: 2.556618
tensor(-5.3035, device='cuda:0') tensor(2.4263, device='cuda:0') tensor(1.1651e-07, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.471955
Average KL loss: 2.064852
Average total loss: 2.536807
tensor(-5.3207, device='cuda:0') tensor(2.4404, device='cuda:0') tensor(1.1378e-07, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.469138
Average KL loss: 2.046223
Average total loss: 2.515361
tensor(-5.3378, device='cuda:0') tensor(2.4546, device='cuda:0') tensor(1.1637e-07, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.465387
Average KL loss: 2.027854
Average total loss: 2.493241
tensor(-5.3547, device='cuda:0') tensor(2.4688, device='cuda:0') tensor(1.1477e-07, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.465038
Average KL loss: 2.009871
Average total loss: 2.474910
tensor(-5.3715, device='cuda:0') tensor(2.4829, device='cuda:0') tensor(1.0636e-07, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.465685
Average KL loss: 1.992220
Average total loss: 2.457905
tensor(-5.3882, device='cuda:0') tensor(2.4971, device='cuda:0') tensor(1.0462e-07, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.468923
Average KL loss: 1.974948
Average total loss: 2.443871
tensor(-5.4048, device='cuda:0') tensor(2.5114, device='cuda:0') tensor(1.0224e-07, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.463956
Average KL loss: 1.958164
Average total loss: 2.422121
tensor(-5.4213, device='cuda:0') tensor(2.5257, device='cuda:0') tensor(1.0493e-07, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.463122
Average KL loss: 1.941444
Average total loss: 2.404566
tensor(-5.4377, device='cuda:0') tensor(2.5398, device='cuda:0') tensor(1.0277e-07, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.459215
Average KL loss: 1.925087
Average total loss: 2.384302
tensor(-5.4540, device='cuda:0') tensor(2.5541, device='cuda:0') tensor(1.0298e-07, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.442619
Average KL loss: 1.908870
Average total loss: 2.351489
tensor(-5.4702, device='cuda:0') tensor(2.5680, device='cuda:0') tensor(9.6574e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.465471
Average KL loss: 1.892843
Average total loss: 2.358313
tensor(-5.4863, device='cuda:0') tensor(2.5823, device='cuda:0') tensor(9.5756e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.458515
Average KL loss: 1.877469
Average total loss: 2.335984
tensor(-5.5022, device='cuda:0') tensor(2.5967, device='cuda:0') tensor(9.4216e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.446775
Average KL loss: 1.862239
Average total loss: 2.309014
tensor(-5.5182, device='cuda:0') tensor(2.6109, device='cuda:0') tensor(9.4383e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.458059
Average KL loss: 1.847184
Average total loss: 2.305243
tensor(-5.5340, device='cuda:0') tensor(2.6251, device='cuda:0') tensor(9.5232e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.466265
Average KL loss: 1.832542
Average total loss: 2.298808
tensor(-5.5497, device='cuda:0') tensor(2.6395, device='cuda:0') tensor(9.9198e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.444903
Average KL loss: 1.818084
Average total loss: 2.262987
tensor(-5.5654, device='cuda:0') tensor(2.6538, device='cuda:0') tensor(8.9611e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.450223
Average KL loss: 1.803718
Average total loss: 2.253940
tensor(-5.5809, device='cuda:0') tensor(2.6681, device='cuda:0') tensor(9.6014e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.454013
Average KL loss: 1.789800
Average total loss: 2.243813
tensor(-5.5964, device='cuda:0') tensor(2.6825, device='cuda:0') tensor(9.7146e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.456398
Average KL loss: 1.776120
Average total loss: 2.232517
tensor(-5.6118, device='cuda:0') tensor(2.6969, device='cuda:0') tensor(9.2893e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.454218
Average KL loss: 1.762788
Average total loss: 2.217006
tensor(-5.6271, device='cuda:0') tensor(2.7114, device='cuda:0') tensor(8.8015e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.462865
Average KL loss: 1.749761
Average total loss: 2.212626
tensor(-5.6424, device='cuda:0') tensor(2.7260, device='cuda:0') tensor(9.4739e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.451861
Average KL loss: 1.736863
Average total loss: 2.188724
tensor(-5.6575, device='cuda:0') tensor(2.7405, device='cuda:0') tensor(8.8386e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.449553
Average KL loss: 1.723978
Average total loss: 2.173531
tensor(-5.6726, device='cuda:0') tensor(2.7549, device='cuda:0') tensor(9.2654e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.447552
Average KL loss: 1.711339
Average total loss: 2.158891
tensor(-5.6876, device='cuda:0') tensor(2.7693, device='cuda:0') tensor(8.8543e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.452308
Average KL loss: 1.698924
Average total loss: 2.151231
tensor(-5.7025, device='cuda:0') tensor(2.7838, device='cuda:0') tensor(8.8323e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.446000
Average KL loss: 1.686673
Average total loss: 2.132673
tensor(-5.7174, device='cuda:0') tensor(2.7983, device='cuda:0') tensor(7.0316e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.448399
Average KL loss: 1.674671
Average total loss: 2.123070
tensor(-5.7322, device='cuda:0') tensor(2.8129, device='cuda:0') tensor(8.2577e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.444125
Average KL loss: 1.662855
Average total loss: 2.106980
tensor(-5.7469, device='cuda:0') tensor(2.8274, device='cuda:0') tensor(8.5501e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.439580
Average KL loss: 1.651109
Average total loss: 2.090689
tensor(-5.7615, device='cuda:0') tensor(2.8419, device='cuda:0') tensor(8.7612e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.450935
Average KL loss: 1.639508
Average total loss: 2.090443
tensor(-5.7761, device='cuda:0') tensor(2.8566, device='cuda:0') tensor(9.2686e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.444557
Average KL loss: 1.628356
Average total loss: 2.072913
tensor(-5.7906, device='cuda:0') tensor(2.8713, device='cuda:0') tensor(7.9586e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.447671
Average KL loss: 1.617285
Average total loss: 2.064956
tensor(-5.8051, device='cuda:0') tensor(2.8860, device='cuda:0') tensor(9.1277e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.439084
Average KL loss: 1.606427
Average total loss: 2.045511
tensor(-5.8195, device='cuda:0') tensor(2.9006, device='cuda:0') tensor(8.6817e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.438613
Average KL loss: 1.595452
Average total loss: 2.034064
tensor(-5.8338, device='cuda:0') tensor(2.9151, device='cuda:0') tensor(7.5140e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.444171
Average KL loss: 1.584826
Average total loss: 2.028997
tensor(-5.8481, device='cuda:0') tensor(2.9300, device='cuda:0') tensor(6.4193e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.438284
Average KL loss: 1.574346
Average total loss: 2.012630
tensor(-5.8623, device='cuda:0') tensor(2.9446, device='cuda:0') tensor(7.8627e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.438658
Average KL loss: 1.564104
Average total loss: 2.002762
tensor(-5.8764, device='cuda:0') tensor(2.9594, device='cuda:0') tensor(7.0150e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.438160
Average KL loss: 1.554040
Average total loss: 1.992200
tensor(-5.8905, device='cuda:0') tensor(2.9742, device='cuda:0') tensor(7.9039e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.441449
Average KL loss: 1.543979
Average total loss: 1.985428
tensor(-5.9046, device='cuda:0') tensor(2.9890, device='cuda:0') tensor(7.8630e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.441399
Average KL loss: 1.534135
Average total loss: 1.975534
tensor(-5.9186, device='cuda:0') tensor(3.0039, device='cuda:0') tensor(8.3640e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.427006
Average KL loss: 1.524415
Average total loss: 1.951421
tensor(-5.9325, device='cuda:0') tensor(3.0185, device='cuda:0') tensor(7.4105e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.437143
Average KL loss: 1.514679
Average total loss: 1.951821
tensor(-5.9464, device='cuda:0') tensor(3.0334, device='cuda:0') tensor(7.6033e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.431741
Average KL loss: 1.505414
Average total loss: 1.937155
tensor(-5.9602, device='cuda:0') tensor(3.0484, device='cuda:0') tensor(7.8190e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.437519
Average KL loss: 1.496163
Average total loss: 1.933682
tensor(-5.9740, device='cuda:0') tensor(3.0634, device='cuda:0') tensor(7.7272e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.437155
Average KL loss: 1.487114
Average total loss: 1.924269
tensor(-5.9877, device='cuda:0') tensor(3.0785, device='cuda:0') tensor(6.7683e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.433321
Average KL loss: 1.478233
Average total loss: 1.911554
tensor(-6.0013, device='cuda:0') tensor(3.0935, device='cuda:0') tensor(7.4660e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.431575
Average KL loss: 1.469277
Average total loss: 1.900853
tensor(-6.0150, device='cuda:0') tensor(3.1084, device='cuda:0') tensor(7.1062e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.433957
Average KL loss: 1.460463
Average total loss: 1.894421
tensor(-6.0285, device='cuda:0') tensor(3.1235, device='cuda:0') tensor(7.4544e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.436878
Average KL loss: 1.451790
Average total loss: 1.888668
tensor(-6.0420, device='cuda:0') tensor(3.1386, device='cuda:0') tensor(7.2201e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.432951
Average KL loss: 1.443429
Average total loss: 1.876381
tensor(-6.0555, device='cuda:0') tensor(3.1538, device='cuda:0') tensor(7.3998e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.434673
Average KL loss: 1.435009
Average total loss: 1.869682
tensor(-6.0689, device='cuda:0') tensor(3.1689, device='cuda:0') tensor(7.1224e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.429562
Average KL loss: 1.426744
Average total loss: 1.856305
tensor(-6.0823, device='cuda:0') tensor(3.1840, device='cuda:0') tensor(7.4976e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.429825
Average KL loss: 1.418622
Average total loss: 1.848447
tensor(-6.0956, device='cuda:0') tensor(3.1992, device='cuda:0') tensor(6.6171e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.428428
Average KL loss: 1.410479
Average total loss: 1.838907
tensor(-6.1089, device='cuda:0') tensor(3.2143, device='cuda:0') tensor(6.6892e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.431636
Average KL loss: 1.402513
Average total loss: 1.834149
tensor(-6.1221, device='cuda:0') tensor(3.2295, device='cuda:0') tensor(6.7829e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.428615
Average KL loss: 1.394653
Average total loss: 1.823268
tensor(-6.1353, device='cuda:0') tensor(3.2446, device='cuda:0') tensor(6.5519e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.429541
Average KL loss: 1.386973
Average total loss: 1.816514
tensor(-6.1484, device='cuda:0') tensor(3.2600, device='cuda:0') tensor(6.0865e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.434732
Average KL loss: 1.379475
Average total loss: 1.814207
tensor(-6.1615, device='cuda:0') tensor(3.2753, device='cuda:0') tensor(6.1608e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.421468
Average KL loss: 1.372003
Average total loss: 1.793472
tensor(-6.1745, device='cuda:0') tensor(3.2906, device='cuda:0') tensor(6.0175e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.424112
Average KL loss: 1.364456
Average total loss: 1.788568
tensor(-6.1875, device='cuda:0') tensor(3.3058, device='cuda:0') tensor(6.8825e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.429464
Average KL loss: 1.357107
Average total loss: 1.786571
tensor(-6.2005, device='cuda:0') tensor(3.3211, device='cuda:0') tensor(5.8403e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.422614
Average KL loss: 1.349824
Average total loss: 1.772438
tensor(-6.2134, device='cuda:0') tensor(3.3364, device='cuda:0') tensor(6.5213e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.423723
Average KL loss: 1.342688
Average total loss: 1.766410
tensor(-6.2263, device='cuda:0') tensor(3.3517, device='cuda:0') tensor(7.0336e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.423852
Average KL loss: 1.335656
Average total loss: 1.759508
tensor(-6.2391, device='cuda:0') tensor(3.3670, device='cuda:0') tensor(6.6554e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.423059
Average KL loss: 1.328625
Average total loss: 1.751684
tensor(-6.2519, device='cuda:0') tensor(3.3824, device='cuda:0') tensor(6.5692e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.419431
Average KL loss: 1.321625
Average total loss: 1.741056
tensor(-6.2647, device='cuda:0') tensor(3.3977, device='cuda:0') tensor(6.1913e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.421778
Average KL loss: 1.314806
Average total loss: 1.736584
tensor(-6.2774, device='cuda:0') tensor(3.4131, device='cuda:0') tensor(5.5575e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.421768
Average KL loss: 1.308051
Average total loss: 1.729819
tensor(-6.2901, device='cuda:0') tensor(3.4284, device='cuda:0') tensor(6.4232e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.423576
Average KL loss: 1.301317
Average total loss: 1.724892
tensor(-6.3027, device='cuda:0') tensor(3.4438, device='cuda:0') tensor(5.3302e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.418693
Average KL loss: 1.294683
Average total loss: 1.713376
tensor(-6.3153, device='cuda:0') tensor(3.4591, device='cuda:0') tensor(6.8156e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.415929
Average KL loss: 1.288071
Average total loss: 1.704000
tensor(-6.3279, device='cuda:0') tensor(3.4744, device='cuda:0') tensor(6.1179e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.417302
Average KL loss: 1.281555
Average total loss: 1.698857
tensor(-6.3404, device='cuda:0') tensor(3.4897, device='cuda:0') tensor(7.2587e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.418535
Average KL loss: 1.275069
Average total loss: 1.693605
tensor(-6.3529, device='cuda:0') tensor(3.5051, device='cuda:0') tensor(6.0368e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.410300
Average KL loss: 1.268721
Average total loss: 1.679021
tensor(-6.3654, device='cuda:0') tensor(3.5203, device='cuda:0') tensor(6.2437e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.424532
Average KL loss: 1.262372
Average total loss: 1.686904
tensor(-6.3779, device='cuda:0') tensor(3.5358, device='cuda:0') tensor(6.1727e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.412060
Average KL loss: 1.256291
Average total loss: 1.668352
tensor(-6.3903, device='cuda:0') tensor(3.5512, device='cuda:0') tensor(6.2370e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.417192
Average KL loss: 1.250202
Average total loss: 1.667394
tensor(-6.4026, device='cuda:0') tensor(3.5666, device='cuda:0') tensor(5.8171e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.413626
Average KL loss: 1.244288
Average total loss: 1.657915
tensor(-6.4150, device='cuda:0') tensor(3.5821, device='cuda:0') tensor(5.7366e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.417897
Average KL loss: 1.238357
Average total loss: 1.656253
tensor(-6.4272, device='cuda:0') tensor(3.5975, device='cuda:0') tensor(5.6383e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.415333
Average KL loss: 1.232405
Average total loss: 1.647738
tensor(-6.4395, device='cuda:0') tensor(3.6130, device='cuda:0') tensor(4.6799e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.408220
Average KL loss: 1.226627
Average total loss: 1.634846
tensor(-6.4517, device='cuda:0') tensor(3.6285, device='cuda:0') tensor(6.1062e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.410511
Average KL loss: 1.220827
Average total loss: 1.631338
tensor(-6.4639, device='cuda:0') tensor(3.6438, device='cuda:0') tensor(6.4015e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.408300
Average KL loss: 1.215074
Average total loss: 1.623374
tensor(-6.4761, device='cuda:0') tensor(3.6592, device='cuda:0') tensor(4.9350e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.410301
Average KL loss: 1.209339
Average total loss: 1.619640
tensor(-6.4882, device='cuda:0') tensor(3.6744, device='cuda:0') tensor(5.7480e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.402803
Average KL loss: 1.203742
Average total loss: 1.606545
tensor(-6.5003, device='cuda:0') tensor(3.6899, device='cuda:0') tensor(5.5435e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.414716
Average KL loss: 1.198352
Average total loss: 1.613068
tensor(-6.5124, device='cuda:0') tensor(3.7054, device='cuda:0') tensor(5.3487e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.402951
Average KL loss: 1.192902
Average total loss: 1.595853
tensor(-6.5244, device='cuda:0') tensor(3.7207, device='cuda:0') tensor(5.8015e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.405851
Average KL loss: 1.187428
Average total loss: 1.593279
tensor(-6.5364, device='cuda:0') tensor(3.7360, device='cuda:0') tensor(5.0210e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.412808
Average KL loss: 1.182042
Average total loss: 1.594850
tensor(-6.5484, device='cuda:0') tensor(3.7514, device='cuda:0') tensor(4.1565e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.411997
Average KL loss: 1.176697
Average total loss: 1.588694
tensor(-6.5604, device='cuda:0') tensor(3.7667, device='cuda:0') tensor(4.9017e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.399024
Average KL loss: 1.171468
Average total loss: 1.570492
tensor(-6.5723, device='cuda:0') tensor(3.7820, device='cuda:0') tensor(6.0434e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.404094
Average KL loss: 1.166225
Average total loss: 1.570319
tensor(-6.5842, device='cuda:0') tensor(3.7973, device='cuda:0') tensor(6.0415e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.403723
Average KL loss: 1.161062
Average total loss: 1.564785
tensor(-6.5960, device='cuda:0') tensor(3.8125, device='cuda:0') tensor(4.9899e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.407377
Average KL loss: 1.155941
Average total loss: 1.563317
tensor(-6.6079, device='cuda:0') tensor(3.8279, device='cuda:0') tensor(4.7984e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.397062
Average KL loss: 1.150946
Average total loss: 1.548008
tensor(-6.6196, device='cuda:0') tensor(3.8431, device='cuda:0') tensor(5.0047e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.407399
Average KL loss: 1.145871
Average total loss: 1.553270
tensor(-6.6314, device='cuda:0') tensor(3.8584, device='cuda:0') tensor(5.2612e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.399513
Average KL loss: 1.140891
Average total loss: 1.540404
tensor(-6.6431, device='cuda:0') tensor(3.8736, device='cuda:0') tensor(3.9395e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.395851
Average KL loss: 1.136023
Average total loss: 1.531874
tensor(-6.6548, device='cuda:0') tensor(3.8890, device='cuda:0') tensor(3.9196e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.394635
Average KL loss: 1.131256
Average total loss: 1.525891
tensor(-6.6665, device='cuda:0') tensor(3.9042, device='cuda:0') tensor(4.2344e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.398895
Average KL loss: 1.126391
Average total loss: 1.525286
tensor(-6.6782, device='cuda:0') tensor(3.9195, device='cuda:0') tensor(5.4317e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.397468
Average KL loss: 1.121593
Average total loss: 1.519060
tensor(-6.6898, device='cuda:0') tensor(3.9346, device='cuda:0') tensor(5.0857e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.400240
Average KL loss: 1.116772
Average total loss: 1.517012
tensor(-6.7014, device='cuda:0') tensor(3.9497, device='cuda:0') tensor(5.0760e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.393764
Average KL loss: 1.112041
Average total loss: 1.505805
tensor(-6.7130, device='cuda:0') tensor(3.9647, device='cuda:0') tensor(4.9230e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.397167
Average KL loss: 1.107373
Average total loss: 1.504540
 Percentile value: -7.640959548950195
Non-zero model percentage: 80.0%, Non-zero mask percentage: 80.0%

--- Pruning Level [1/24]: ---
conv1.weight         | nonzeros =    1726 /    1728             ( 99.88%) | total_pruned =       2 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   35963 /   36864             ( 97.56%) | total_pruned =     901 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36007 /   36864             ( 97.68%) | total_pruned =     857 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   35814 /   36864             ( 97.15%) | total_pruned =    1050 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   35738 /   36864             ( 96.95%) | total_pruned =    1126 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   71123 /   73728             ( 96.47%) | total_pruned =    2605 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  140593 /  147456             ( 95.35%) | total_pruned =    6863 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8131 /    8192             ( 99.26%) | total_pruned =      61 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  138523 /  147456             ( 93.94%) | total_pruned =    8933 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  138501 /  147456             ( 93.93%) | total_pruned =    8955 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  277561 /  294912             ( 94.12%) | total_pruned =   17351 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  546069 /  589824             ( 92.58%) | total_pruned =   43755 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32018 /   32768             ( 97.71%) | total_pruned =     750 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  520274 /  589824             ( 88.21%) | total_pruned =   69550 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  517181 /  589824             ( 87.68%) | total_pruned =   72643 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1054132 / 1179648             ( 89.36%) | total_pruned =  125516 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1965047 / 2359296             ( 83.29%) | total_pruned =  394249 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  122762 /  131072             ( 93.66%) | total_pruned =    8310 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1636623 / 2359296             ( 69.37%) | total_pruned =  722673 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1614509 / 2359296             ( 68.43%) | total_pruned =  744787 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5109 /    5120             ( 99.79%) | total_pruned =      11 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 8943010, pruned : 2235752, total: 11178762, Compression rate :       1.25x  ( 20.00% pruned)
Train Epoch: 30/100 Loss: 0.000007 Accuracy: 87.45 100.00 % Best test Accuracy: 87.45%
tensor(-6.7245, device='cuda:0') tensor(3.9798, device='cuda:0') tensor(5.5612e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.425824
Average KL loss: 1.040012
Average total loss: 1.465836
tensor(-6.9014, device='cuda:0') tensor(3.7568, device='cuda:0') tensor(4.2637e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.430058
Average KL loss: 0.986168
Average total loss: 1.416225
tensor(-7.0191, device='cuda:0') tensor(3.7199, device='cuda:0') tensor(2.5592e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.432435
Average KL loss: 0.963210
Average total loss: 1.395645
tensor(-7.1103, device='cuda:0') tensor(3.7340, device='cuda:0') tensor(3.5135e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.425302
Average KL loss: 0.948996
Average total loss: 1.374299
tensor(-7.1859, device='cuda:0') tensor(3.7690, device='cuda:0') tensor(3.5136e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.429336
Average KL loss: 0.938709
Average total loss: 1.368045
tensor(-7.2510, device='cuda:0') tensor(3.8139, device='cuda:0') tensor(4.5988e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.426139
Average KL loss: 0.930702
Average total loss: 1.356841
tensor(-7.3085, device='cuda:0') tensor(3.8635, device='cuda:0') tensor(3.7764e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.418922
Average KL loss: 0.924018
Average total loss: 1.342940
tensor(-7.3602, device='cuda:0') tensor(3.9153, device='cuda:0') tensor(3.5142e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.418890
Average KL loss: 0.918212
Average total loss: 1.337102
tensor(-7.4072, device='cuda:0') tensor(3.9677, device='cuda:0') tensor(3.2408e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.421903
Average KL loss: 0.913127
Average total loss: 1.335030
tensor(-7.4505, device='cuda:0') tensor(4.0201, device='cuda:0') tensor(3.3716e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.417757
Average KL loss: 0.908449
Average total loss: 1.326206
tensor(-7.4907, device='cuda:0') tensor(4.0718, device='cuda:0') tensor(3.1919e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.411244
Average KL loss: 0.904116
Average total loss: 1.315360
tensor(-7.5282, device='cuda:0') tensor(4.1226, device='cuda:0') tensor(3.0149e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.411584
Average KL loss: 0.900106
Average total loss: 1.311690
tensor(-7.5635, device='cuda:0') tensor(4.1723, device='cuda:0') tensor(3.6689e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.401985
Average KL loss: 0.896283
Average total loss: 1.298268
tensor(-7.5968, device='cuda:0') tensor(4.2208, device='cuda:0') tensor(3.3875e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.406782
Average KL loss: 0.892569
Average total loss: 1.299352
tensor(-7.6284, device='cuda:0') tensor(4.2680, device='cuda:0') tensor(3.3243e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.411866
Average KL loss: 0.889054
Average total loss: 1.300920
tensor(-7.6584, device='cuda:0') tensor(4.3141, device='cuda:0') tensor(3.3824e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.404787
Average KL loss: 0.885766
Average total loss: 1.290553
tensor(-7.6871, device='cuda:0') tensor(4.3589, device='cuda:0') tensor(2.1890e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.406171
Average KL loss: 0.882533
Average total loss: 1.288704
tensor(-7.7146, device='cuda:0') tensor(4.4026, device='cuda:0') tensor(3.3210e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.406539
Average KL loss: 0.879438
Average total loss: 1.285977
tensor(-7.7409, device='cuda:0') tensor(4.4451, device='cuda:0') tensor(3.4945e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.401260
Average KL loss: 0.876374
Average total loss: 1.277634
tensor(-7.7662, device='cuda:0') tensor(4.4864, device='cuda:0') tensor(3.3094e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.402642
Average KL loss: 0.873425
Average total loss: 1.276068
tensor(-7.7906, device='cuda:0') tensor(4.5268, device='cuda:0') tensor(2.8654e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.402119
Average KL loss: 0.870592
Average total loss: 1.272711
tensor(-7.8142, device='cuda:0') tensor(4.5660, device='cuda:0') tensor(2.9421e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.395340
Average KL loss: 0.867614
Average total loss: 1.262954
tensor(-7.8370, device='cuda:0') tensor(4.6041, device='cuda:0') tensor(2.2324e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.399634
Average KL loss: 0.864725
Average total loss: 1.264359
tensor(-7.8590, device='cuda:0') tensor(4.6412, device='cuda:0') tensor(2.9417e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.396651
Average KL loss: 0.861921
Average total loss: 1.258572
tensor(-7.8804, device='cuda:0') tensor(4.6774, device='cuda:0') tensor(2.7013e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.398638
Average KL loss: 0.859179
Average total loss: 1.257816
tensor(-7.9012, device='cuda:0') tensor(4.7127, device='cuda:0') tensor(2.7746e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.394141
Average KL loss: 0.856519
Average total loss: 1.250661
tensor(-7.9214, device='cuda:0') tensor(4.7473, device='cuda:0') tensor(3.0265e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.389178
Average KL loss: 0.853884
Average total loss: 1.243062
tensor(-7.9411, device='cuda:0') tensor(4.7807, device='cuda:0') tensor(2.8196e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.389966
Average KL loss: 0.851219
Average total loss: 1.241185
tensor(-7.9602, device='cuda:0') tensor(4.8135, device='cuda:0') tensor(2.8559e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.386324
Average KL loss: 0.848688
Average total loss: 1.235011
tensor(-7.9789, device='cuda:0') tensor(4.8454, device='cuda:0') tensor(3.0014e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.394774
Average KL loss: 0.846105
Average total loss: 1.240879
tensor(-7.9972, device='cuda:0') tensor(4.8766, device='cuda:0') tensor(2.6750e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.389018
Average KL loss: 0.843620
Average total loss: 1.232638
tensor(-8.0150, device='cuda:0') tensor(4.9071, device='cuda:0') tensor(3.5962e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.386112
Average KL loss: 0.841131
Average total loss: 1.227242
tensor(-8.0324, device='cuda:0') tensor(4.9368, device='cuda:0') tensor(3.9373e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.389816
Average KL loss: 0.838651
Average total loss: 1.228467
tensor(-8.0494, device='cuda:0') tensor(4.9660, device='cuda:0') tensor(3.1537e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.384277
Average KL loss: 0.836303
Average total loss: 1.220580
tensor(-8.0661, device='cuda:0') tensor(4.9944, device='cuda:0') tensor(2.6624e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.383929
Average KL loss: 0.833833
Average total loss: 1.217762
tensor(-8.0825, device='cuda:0') tensor(5.0221, device='cuda:0') tensor(2.1285e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.390624
Average KL loss: 0.831395
Average total loss: 1.222019
tensor(-8.0985, device='cuda:0') tensor(5.0492, device='cuda:0') tensor(3.5478e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.387991
Average KL loss: 0.829052
Average total loss: 1.217043
tensor(-8.1142, device='cuda:0') tensor(5.0759, device='cuda:0') tensor(3.3219e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.392318
Average KL loss: 0.826854
Average total loss: 1.219171
tensor(-8.1297, device='cuda:0') tensor(5.1020, device='cuda:0') tensor(2.2344e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.383855
Average KL loss: 0.824647
Average total loss: 1.208502
tensor(-8.1448, device='cuda:0') tensor(5.1276, device='cuda:0') tensor(2.4359e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.385143
Average KL loss: 0.822462
Average total loss: 1.207605
tensor(-8.1597, device='cuda:0') tensor(5.1526, device='cuda:0') tensor(1.8527e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.380777
Average KL loss: 0.820270
Average total loss: 1.201047
tensor(-8.1743, device='cuda:0') tensor(5.1771, device='cuda:0') tensor(2.5038e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.378831
Average KL loss: 0.818013
Average total loss: 1.196843
tensor(-8.1887, device='cuda:0') tensor(5.2010, device='cuda:0') tensor(2.2220e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.386171
Average KL loss: 0.815756
Average total loss: 1.201927
tensor(-8.2028, device='cuda:0') tensor(5.2246, device='cuda:0') tensor(3.0772e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.377702
Average KL loss: 0.813594
Average total loss: 1.191295
tensor(-8.2168, device='cuda:0') tensor(5.2475, device='cuda:0') tensor(2.9083e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.383497
Average KL loss: 0.811425
Average total loss: 1.194922
tensor(-8.2305, device='cuda:0') tensor(5.2702, device='cuda:0') tensor(2.4722e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.383151
Average KL loss: 0.809341
Average total loss: 1.192492
tensor(-8.2440, device='cuda:0') tensor(5.2924, device='cuda:0') tensor(2.1094e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.371688
Average KL loss: 0.807197
Average total loss: 1.178885
tensor(-8.2573, device='cuda:0') tensor(5.3139, device='cuda:0') tensor(2.7187e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.382262
Average KL loss: 0.805061
Average total loss: 1.187323
tensor(-8.2705, device='cuda:0') tensor(5.3352, device='cuda:0') tensor(2.5665e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.377704
Average KL loss: 0.803065
Average total loss: 1.180768
tensor(-8.2834, device='cuda:0') tensor(5.3560, device='cuda:0') tensor(2.8307e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.376722
Average KL loss: 0.801023
Average total loss: 1.177744
tensor(-8.2962, device='cuda:0') tensor(5.3764, device='cuda:0') tensor(2.9575e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.374349
Average KL loss: 0.798959
Average total loss: 1.173308
tensor(-8.3088, device='cuda:0') tensor(5.3965, device='cuda:0') tensor(2.3666e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.377528
Average KL loss: 0.796957
Average total loss: 1.174484
tensor(-8.3212, device='cuda:0') tensor(5.4162, device='cuda:0') tensor(2.3489e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.376472
Average KL loss: 0.794930
Average total loss: 1.171402
tensor(-8.3335, device='cuda:0') tensor(5.4355, device='cuda:0') tensor(2.5993e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.364999
Average KL loss: 0.792954
Average total loss: 1.157952
tensor(-8.3456, device='cuda:0') tensor(5.4545, device='cuda:0') tensor(2.1936e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.374921
Average KL loss: 0.790970
Average total loss: 1.165891
tensor(-8.3576, device='cuda:0') tensor(5.4731, device='cuda:0') tensor(2.8307e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.371499
Average KL loss: 0.788933
Average total loss: 1.160432
tensor(-8.3695, device='cuda:0') tensor(5.4913, device='cuda:0') tensor(3.5186e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.368051
Average KL loss: 0.786901
Average total loss: 1.154952
tensor(-8.3812, device='cuda:0') tensor(5.5092, device='cuda:0') tensor(2.6586e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.368667
Average KL loss: 0.784916
Average total loss: 1.153583
tensor(-8.3927, device='cuda:0') tensor(5.5268, device='cuda:0') tensor(2.1305e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.367995
Average KL loss: 0.782974
Average total loss: 1.150970
tensor(-8.4042, device='cuda:0') tensor(5.5440, device='cuda:0') tensor(2.9732e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.364421
Average KL loss: 0.781003
Average total loss: 1.145424
tensor(-8.4155, device='cuda:0') tensor(5.5610, device='cuda:0') tensor(2.5100e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.367515
Average KL loss: 0.779063
Average total loss: 1.146577
tensor(-8.4267, device='cuda:0') tensor(5.5776, device='cuda:0') tensor(2.4950e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.365762
Average KL loss: 0.777164
Average total loss: 1.142926
tensor(-8.4378, device='cuda:0') tensor(5.5941, device='cuda:0') tensor(2.9135e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.366702
Average KL loss: 0.775273
Average total loss: 1.141975
tensor(-8.4487, device='cuda:0') tensor(5.6103, device='cuda:0') tensor(2.6389e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.360304
Average KL loss: 0.773380
Average total loss: 1.133684
tensor(-8.4596, device='cuda:0') tensor(5.6261, device='cuda:0') tensor(2.0650e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.361560
Average KL loss: 0.771512
Average total loss: 1.133072
tensor(-8.4703, device='cuda:0') tensor(5.6416, device='cuda:0') tensor(2.2884e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.362037
Average KL loss: 0.769626
Average total loss: 1.131664
tensor(-8.4810, device='cuda:0') tensor(5.6568, device='cuda:0') tensor(2.9337e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.362059
Average KL loss: 0.767797
Average total loss: 1.129856
tensor(-8.4915, device='cuda:0') tensor(5.6719, device='cuda:0') tensor(2.2910e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.357227
Average KL loss: 0.765941
Average total loss: 1.123168
tensor(-8.5020, device='cuda:0') tensor(5.6865, device='cuda:0') tensor(2.6749e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.356783
Average KL loss: 0.764046
Average total loss: 1.120828
tensor(-8.5123, device='cuda:0') tensor(5.7010, device='cuda:0') tensor(2.3034e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.358830
Average KL loss: 0.762213
Average total loss: 1.121043
tensor(-8.5226, device='cuda:0') tensor(5.7151, device='cuda:0') tensor(2.7192e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.359986
Average KL loss: 0.760458
Average total loss: 1.120444
tensor(-8.5328, device='cuda:0') tensor(5.7292, device='cuda:0') tensor(2.3678e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.356904
Average KL loss: 0.758701
Average total loss: 1.115606
tensor(-8.5429, device='cuda:0') tensor(5.7429, device='cuda:0') tensor(3.0211e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.360903
Average KL loss: 0.756865
Average total loss: 1.117767
tensor(-8.5529, device='cuda:0') tensor(5.7563, device='cuda:0') tensor(2.8710e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.361367
Average KL loss: 0.755073
Average total loss: 1.116441
tensor(-8.5628, device='cuda:0') tensor(5.7696, device='cuda:0') tensor(2.8338e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.357179
Average KL loss: 0.753329
Average total loss: 1.110509
tensor(-8.5726, device='cuda:0') tensor(5.7826, device='cuda:0') tensor(3.0545e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.355731
Average KL loss: 0.751548
Average total loss: 1.107279
tensor(-8.5824, device='cuda:0') tensor(5.7955, device='cuda:0') tensor(1.9951e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.354470
Average KL loss: 0.749806
Average total loss: 1.104276
tensor(-8.5921, device='cuda:0') tensor(5.8080, device='cuda:0') tensor(2.7656e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.352123
Average KL loss: 0.748074
Average total loss: 1.100197
tensor(-8.6017, device='cuda:0') tensor(5.8206, device='cuda:0') tensor(1.7499e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.350166
Average KL loss: 0.746420
Average total loss: 1.096585
tensor(-8.6112, device='cuda:0') tensor(5.8329, device='cuda:0') tensor(2.1551e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.351091
Average KL loss: 0.744699
Average total loss: 1.095791
tensor(-8.6206, device='cuda:0') tensor(5.8449, device='cuda:0') tensor(1.9464e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.346695
Average KL loss: 0.742955
Average total loss: 1.089650
tensor(-8.6301, device='cuda:0') tensor(5.8566, device='cuda:0') tensor(2.3778e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.350585
Average KL loss: 0.741171
Average total loss: 1.091756
tensor(-8.6394, device='cuda:0') tensor(5.8682, device='cuda:0') tensor(2.2712e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.350196
Average KL loss: 0.739485
Average total loss: 1.089681
tensor(-8.6486, device='cuda:0') tensor(5.8797, device='cuda:0') tensor(2.8367e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.351062
Average KL loss: 0.737783
Average total loss: 1.088844
tensor(-8.6578, device='cuda:0') tensor(5.8909, device='cuda:0') tensor(1.1203e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.351034
Average KL loss: 0.736125
Average total loss: 1.087159
tensor(-8.6669, device='cuda:0') tensor(5.9020, device='cuda:0') tensor(2.6770e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.352094
Average KL loss: 0.734500
Average total loss: 1.086593
tensor(-8.6760, device='cuda:0') tensor(5.9131, device='cuda:0') tensor(3.0560e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.352473
Average KL loss: 0.732921
Average total loss: 1.085393
tensor(-8.6850, device='cuda:0') tensor(5.9239, device='cuda:0') tensor(2.1351e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.346554
Average KL loss: 0.731367
Average total loss: 1.077921
tensor(-8.6939, device='cuda:0') tensor(5.9346, device='cuda:0') tensor(2.2751e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.346157
Average KL loss: 0.729796
Average total loss: 1.075953
tensor(-8.7028, device='cuda:0') tensor(5.9450, device='cuda:0') tensor(2.4366e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.345100
Average KL loss: 0.728203
Average total loss: 1.073303
tensor(-8.7116, device='cuda:0') tensor(5.9551, device='cuda:0') tensor(2.2154e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.346508
Average KL loss: 0.726626
Average total loss: 1.073134
tensor(-8.7204, device='cuda:0') tensor(5.9651, device='cuda:0') tensor(2.4489e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.347218
Average KL loss: 0.724980
Average total loss: 1.072198
tensor(-8.7291, device='cuda:0') tensor(5.9750, device='cuda:0') tensor(2.8609e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.345219
Average KL loss: 0.723418
Average total loss: 1.068637
tensor(-8.7377, device='cuda:0') tensor(5.9848, device='cuda:0') tensor(2.0362e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.340980
Average KL loss: 0.721864
Average total loss: 1.062844
tensor(-8.7463, device='cuda:0') tensor(5.9942, device='cuda:0') tensor(2.2433e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.347134
Average KL loss: 0.720296
Average total loss: 1.067429
tensor(-8.7549, device='cuda:0') tensor(6.0037, device='cuda:0') tensor(1.7366e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.342498
Average KL loss: 0.718818
Average total loss: 1.061315
tensor(-8.7634, device='cuda:0') tensor(6.0131, device='cuda:0') tensor(2.1835e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.343168
Average KL loss: 0.717303
Average total loss: 1.060471
tensor(-8.7719, device='cuda:0') tensor(6.0223, device='cuda:0') tensor(2.1882e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.336591
Average KL loss: 0.715823
Average total loss: 1.052415
tensor(-8.7803, device='cuda:0') tensor(6.0312, device='cuda:0') tensor(2.4016e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.337859
Average KL loss: 0.714286
Average total loss: 1.052145
tensor(-8.7886, device='cuda:0') tensor(6.0400, device='cuda:0') tensor(2.3764e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.340079
Average KL loss: 0.712672
Average total loss: 1.052751
tensor(-8.7970, device='cuda:0') tensor(6.0485, device='cuda:0') tensor(1.9606e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.338559
Average KL loss: 0.711174
Average total loss: 1.049733
tensor(-8.8052, device='cuda:0') tensor(6.0571, device='cuda:0') tensor(2.3096e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.335343
Average KL loss: 0.709628
Average total loss: 1.044972
tensor(-8.8135, device='cuda:0') tensor(6.0653, device='cuda:0') tensor(2.0830e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.333966
Average KL loss: 0.708080
Average total loss: 1.042046
tensor(-8.8216, device='cuda:0') tensor(6.0736, device='cuda:0') tensor(2.5929e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.337532
Average KL loss: 0.706571
Average total loss: 1.044103
tensor(-8.8298, device='cuda:0') tensor(6.0817, device='cuda:0') tensor(2.4631e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.336468
Average KL loss: 0.705127
Average total loss: 1.041595
tensor(-8.8379, device='cuda:0') tensor(6.0898, device='cuda:0') tensor(2.5941e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.337491
Average KL loss: 0.703666
Average total loss: 1.041157
tensor(-8.8460, device='cuda:0') tensor(6.0976, device='cuda:0') tensor(1.2322e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.334858
Average KL loss: 0.702218
Average total loss: 1.037076
tensor(-8.8540, device='cuda:0') tensor(6.1052, device='cuda:0') tensor(2.0305e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.334745
Average KL loss: 0.700694
Average total loss: 1.035440
tensor(-8.8620, device='cuda:0') tensor(6.1127, device='cuda:0') tensor(2.0404e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.331825
Average KL loss: 0.699280
Average total loss: 1.031105
tensor(-8.8699, device='cuda:0') tensor(6.1203, device='cuda:0') tensor(2.2507e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.334246
Average KL loss: 0.697853
Average total loss: 1.032099
tensor(-8.8778, device='cuda:0') tensor(6.1277, device='cuda:0') tensor(1.9461e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.332857
Average KL loss: 0.696419
Average total loss: 1.029275
tensor(-8.8857, device='cuda:0') tensor(6.1349, device='cuda:0') tensor(2.6562e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.333945
Average KL loss: 0.694972
Average total loss: 1.028917
tensor(-8.8935, device='cuda:0') tensor(6.1419, device='cuda:0') tensor(1.6593e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.337057
Average KL loss: 0.693587
Average total loss: 1.030643
tensor(-8.9013, device='cuda:0') tensor(6.1490, device='cuda:0') tensor(2.4688e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.332145
Average KL loss: 0.692299
Average total loss: 1.024444
tensor(-8.9090, device='cuda:0') tensor(6.1560, device='cuda:0') tensor(2.5592e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.328086
Average KL loss: 0.690928
Average total loss: 1.019015
tensor(-8.9168, device='cuda:0') tensor(6.1627, device='cuda:0') tensor(1.9472e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.326862
Average KL loss: 0.689526
Average total loss: 1.016387
tensor(-8.9245, device='cuda:0') tensor(6.1693, device='cuda:0') tensor(1.7540e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.326254
Average KL loss: 0.688153
Average total loss: 1.014407
tensor(-8.9321, device='cuda:0') tensor(6.1759, device='cuda:0') tensor(2.3877e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.331609
Average KL loss: 0.686783
Average total loss: 1.018392
tensor(-8.9397, device='cuda:0') tensor(6.1824, device='cuda:0') tensor(2.1912e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.328133
Average KL loss: 0.685435
Average total loss: 1.013567
tensor(-8.9473, device='cuda:0') tensor(6.1887, device='cuda:0') tensor(2.3628e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.327060
Average KL loss: 0.684088
Average total loss: 1.011148
tensor(-8.9549, device='cuda:0') tensor(6.1948, device='cuda:0') tensor(2.7835e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.329036
Average KL loss: 0.682757
Average total loss: 1.011793
tensor(-8.9624, device='cuda:0') tensor(6.2010, device='cuda:0') tensor(2.2740e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.322133
Average KL loss: 0.681407
Average total loss: 1.003540
tensor(-8.9699, device='cuda:0') tensor(6.2069, device='cuda:0') tensor(1.9976e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.323638
Average KL loss: 0.679977
Average total loss: 1.003615
tensor(-8.9774, device='cuda:0') tensor(6.2127, device='cuda:0') tensor(2.2073e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.329469
Average KL loss: 0.678590
Average total loss: 1.008058
tensor(-8.9848, device='cuda:0') tensor(6.2185, device='cuda:0') tensor(2.6121e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.320645
Average KL loss: 0.677302
Average total loss: 0.997947
tensor(-8.9922, device='cuda:0') tensor(6.2242, device='cuda:0') tensor(1.7137e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.321599
Average KL loss: 0.675975
Average total loss: 0.997574
tensor(-8.9996, device='cuda:0') tensor(6.2298, device='cuda:0') tensor(1.7250e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.325013
Average KL loss: 0.674598
Average total loss: 0.999611
tensor(-9.0069, device='cuda:0') tensor(6.2351, device='cuda:0') tensor(2.0406e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.321610
Average KL loss: 0.673273
Average total loss: 0.994882
tensor(-9.0142, device='cuda:0') tensor(6.2405, device='cuda:0') tensor(1.2431e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.324850
Average KL loss: 0.671975
Average total loss: 0.996824
tensor(-9.0215, device='cuda:0') tensor(6.2459, device='cuda:0') tensor(2.3104e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.321527
Average KL loss: 0.670718
Average total loss: 0.992245
tensor(-9.0288, device='cuda:0') tensor(6.2513, device='cuda:0') tensor(1.2054e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.320544
Average KL loss: 0.669480
Average total loss: 0.990024
tensor(-9.0360, device='cuda:0') tensor(6.2564, device='cuda:0') tensor(2.4822e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.317154
Average KL loss: 0.668149
Average total loss: 0.985303
tensor(-9.0432, device='cuda:0') tensor(6.2614, device='cuda:0') tensor(2.3018e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.317547
Average KL loss: 0.666806
Average total loss: 0.984352
tensor(-9.0504, device='cuda:0') tensor(6.2662, device='cuda:0') tensor(1.8141e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.318883
Average KL loss: 0.665499
Average total loss: 0.984383
tensor(-9.0575, device='cuda:0') tensor(6.2710, device='cuda:0') tensor(2.0358e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.319022
Average KL loss: 0.664236
Average total loss: 0.983258
tensor(-9.0647, device='cuda:0') tensor(6.2757, device='cuda:0') tensor(2.3544e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.318159
Average KL loss: 0.662942
Average total loss: 0.981100
tensor(-9.0718, device='cuda:0') tensor(6.2804, device='cuda:0') tensor(2.1961e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.314272
Average KL loss: 0.661656
Average total loss: 0.975928
tensor(-9.0789, device='cuda:0') tensor(6.2848, device='cuda:0') tensor(1.9715e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.310918
Average KL loss: 0.660339
Average total loss: 0.971257
tensor(-9.0859, device='cuda:0') tensor(6.2892, device='cuda:0') tensor(1.6851e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.312335
Average KL loss: 0.659053
Average total loss: 0.971388
tensor(-9.0930, device='cuda:0') tensor(6.2935, device='cuda:0') tensor(1.8805e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.314293
Average KL loss: 0.657818
Average total loss: 0.972110
tensor(-9.1000, device='cuda:0') tensor(6.2979, device='cuda:0') tensor(2.0868e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.313404
Average KL loss: 0.656611
Average total loss: 0.970016
tensor(-9.1070, device='cuda:0') tensor(6.3021, device='cuda:0') tensor(1.3709e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.312502
Average KL loss: 0.655409
Average total loss: 0.967911
tensor(-9.1139, device='cuda:0') tensor(6.3063, device='cuda:0') tensor(1.8934e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.311403
Average KL loss: 0.654196
Average total loss: 0.965600
tensor(-9.1209, device='cuda:0') tensor(6.3104, device='cuda:0') tensor(1.6893e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.308903
Average KL loss: 0.652997
Average total loss: 0.961900
tensor(-9.1278, device='cuda:0') tensor(6.3145, device='cuda:0') tensor(1.7763e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.313677
Average KL loss: 0.651809
Average total loss: 0.965487
tensor(-9.1347, device='cuda:0') tensor(6.3183, device='cuda:0') tensor(1.2720e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.311158
Average KL loss: 0.650658
Average total loss: 0.961816
tensor(-9.1416, device='cuda:0') tensor(6.3221, device='cuda:0') tensor(1.9432e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.303849
Average KL loss: 0.649395
Average total loss: 0.953244
tensor(-9.1484, device='cuda:0') tensor(6.3258, device='cuda:0') tensor(1.4420e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.311981
Average KL loss: 0.648269
Average total loss: 0.960250
tensor(-9.1552, device='cuda:0') tensor(6.3297, device='cuda:0') tensor(1.9429e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.310782
Average KL loss: 0.647114
Average total loss: 0.957896
tensor(-9.1620, device='cuda:0') tensor(6.3333, device='cuda:0') tensor(2.0852e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.305272
Average KL loss: 0.645988
Average total loss: 0.951259
tensor(-9.1688, device='cuda:0') tensor(6.3368, device='cuda:0') tensor(2.0676e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.314504
Average KL loss: 0.644797
Average total loss: 0.959301
tensor(-9.1756, device='cuda:0') tensor(6.3402, device='cuda:0') tensor(2.1844e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.305913
Average KL loss: 0.643662
Average total loss: 0.949575
tensor(-9.1824, device='cuda:0') tensor(6.3436, device='cuda:0') tensor(2.4309e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.308819
Average KL loss: 0.642459
Average total loss: 0.951278
tensor(-9.1891, device='cuda:0') tensor(6.3468, device='cuda:0') tensor(1.4128e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.305362
Average KL loss: 0.641275
Average total loss: 0.946637
tensor(-9.1958, device='cuda:0') tensor(6.3500, device='cuda:0') tensor(1.9083e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.307376
Average KL loss: 0.640144
Average total loss: 0.947521
tensor(-9.2025, device='cuda:0') tensor(6.3532, device='cuda:0') tensor(1.7273e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.303054
Average KL loss: 0.639004
Average total loss: 0.942058
tensor(-9.2092, device='cuda:0') tensor(6.3563, device='cuda:0') tensor(1.7095e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.303710
Average KL loss: 0.637859
Average total loss: 0.941569
tensor(-9.2158, device='cuda:0') tensor(6.3592, device='cuda:0') tensor(2.3809e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.301332
Average KL loss: 0.636707
Average total loss: 0.938039
tensor(-9.2225, device='cuda:0') tensor(6.3622, device='cuda:0') tensor(1.9679e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.303455
Average KL loss: 0.635589
Average total loss: 0.939045
tensor(-9.2291, device='cuda:0') tensor(6.3650, device='cuda:0') tensor(1.4175e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.307580
Average KL loss: 0.634449
Average total loss: 0.942028
tensor(-9.2357, device='cuda:0') tensor(6.3678, device='cuda:0') tensor(1.9576e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.297493
Average KL loss: 0.633399
Average total loss: 0.930892
tensor(-9.2423, device='cuda:0') tensor(6.3705, device='cuda:0') tensor(1.7319e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.301923
Average KL loss: 0.632248
Average total loss: 0.934172
tensor(-9.2489, device='cuda:0') tensor(6.3731, device='cuda:0') tensor(1.4078e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.303704
Average KL loss: 0.631078
Average total loss: 0.934781
tensor(-9.2554, device='cuda:0') tensor(6.3756, device='cuda:0') tensor(1.3984e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.301790
Average KL loss: 0.629926
Average total loss: 0.931717
tensor(-9.2619, device='cuda:0') tensor(6.3781, device='cuda:0') tensor(1.9603e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.303263
Average KL loss: 0.628787
Average total loss: 0.932050
tensor(-9.2685, device='cuda:0') tensor(6.3805, device='cuda:0') tensor(1.3475e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.299572
Average KL loss: 0.627696
Average total loss: 0.927268
tensor(-9.2749, device='cuda:0') tensor(6.3830, device='cuda:0') tensor(1.7292e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.297984
Average KL loss: 0.626619
Average total loss: 0.924603
tensor(-9.2814, device='cuda:0') tensor(6.3854, device='cuda:0') tensor(1.7412e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.298415
Average KL loss: 0.625559
Average total loss: 0.923974
tensor(-9.2878, device='cuda:0') tensor(6.3879, device='cuda:0') tensor(1.6818e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.293901
Average KL loss: 0.624503
Average total loss: 0.918404
tensor(-9.2943, device='cuda:0') tensor(6.3902, device='cuda:0') tensor(1.6488e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.296822
Average KL loss: 0.623457
Average total loss: 0.920279
tensor(-9.3007, device='cuda:0') tensor(6.3924, device='cuda:0') tensor(1.6231e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.294401
Average KL loss: 0.622402
Average total loss: 0.916803
tensor(-9.3071, device='cuda:0') tensor(6.3946, device='cuda:0') tensor(1.3599e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.291113
Average KL loss: 0.621349
Average total loss: 0.912462
tensor(-9.3135, device='cuda:0') tensor(6.3966, device='cuda:0') tensor(2.1657e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.294852
Average KL loss: 0.620299
Average total loss: 0.915151
tensor(-9.3199, device='cuda:0') tensor(6.3987, device='cuda:0') tensor(7.7818e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.291385
Average KL loss: 0.619258
Average total loss: 0.910644
tensor(-9.3262, device='cuda:0') tensor(6.4007, device='cuda:0') tensor(1.7456e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.296797
Average KL loss: 0.618188
Average total loss: 0.914984
tensor(-9.3326, device='cuda:0') tensor(6.4025, device='cuda:0') tensor(1.6770e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.295733
Average KL loss: 0.617196
Average total loss: 0.912930
tensor(-9.3389, device='cuda:0') tensor(6.4044, device='cuda:0') tensor(1.1828e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.296350
Average KL loss: 0.616197
Average total loss: 0.912548
tensor(-9.3452, device='cuda:0') tensor(6.4062, device='cuda:0') tensor(1.7691e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.292630
Average KL loss: 0.615152
Average total loss: 0.907782
tensor(-9.3515, device='cuda:0') tensor(6.4078, device='cuda:0') tensor(1.2666e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.292940
Average KL loss: 0.614072
Average total loss: 0.907012
tensor(-9.3578, device='cuda:0') tensor(6.4094, device='cuda:0') tensor(1.7193e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.288729
Average KL loss: 0.613092
Average total loss: 0.901821
tensor(-9.3641, device='cuda:0') tensor(6.4109, device='cuda:0') tensor(1.8298e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.291541
Average KL loss: 0.612075
Average total loss: 0.903616
tensor(-9.3703, device='cuda:0') tensor(6.4125, device='cuda:0') tensor(1.6466e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.288944
Average KL loss: 0.611090
Average total loss: 0.900034
tensor(-9.3766, device='cuda:0') tensor(6.4139, device='cuda:0') tensor(1.3949e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.286263
Average KL loss: 0.610074
Average total loss: 0.896337
tensor(-9.3828, device='cuda:0') tensor(6.4154, device='cuda:0') tensor(1.5237e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.286407
Average KL loss: 0.609051
Average total loss: 0.895458
tensor(-9.3890, device='cuda:0') tensor(6.4169, device='cuda:0') tensor(1.7877e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.282924
Average KL loss: 0.608086
Average total loss: 0.891010
tensor(-9.3952, device='cuda:0') tensor(6.4182, device='cuda:0') tensor(1.2740e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.287125
Average KL loss: 0.607110
Average total loss: 0.894236
tensor(-9.4014, device='cuda:0') tensor(6.4196, device='cuda:0') tensor(1.5562e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.285419
Average KL loss: 0.606073
Average total loss: 0.891493
tensor(-9.4076, device='cuda:0') tensor(6.4208, device='cuda:0') tensor(1.9157e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.286109
Average KL loss: 0.605082
Average total loss: 0.891191
tensor(-9.4137, device='cuda:0') tensor(6.4220, device='cuda:0') tensor(1.9159e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.287608
Average KL loss: 0.604110
Average total loss: 0.891718
tensor(-9.4199, device='cuda:0') tensor(6.4231, device='cuda:0') tensor(1.7487e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.287374
Average KL loss: 0.603137
Average total loss: 0.890511
tensor(-9.4260, device='cuda:0') tensor(6.4241, device='cuda:0') tensor(1.1339e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.281194
Average KL loss: 0.602110
Average total loss: 0.883305
tensor(-9.4321, device='cuda:0') tensor(6.4250, device='cuda:0') tensor(1.9814e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.287954
Average KL loss: 0.601122
Average total loss: 0.889076
tensor(-9.4382, device='cuda:0') tensor(6.4260, device='cuda:0') tensor(1.6402e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.283837
Average KL loss: 0.600137
Average total loss: 0.883974
tensor(-9.4443, device='cuda:0') tensor(6.4268, device='cuda:0') tensor(1.2242e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.285878
Average KL loss: 0.599183
Average total loss: 0.885061
tensor(-9.4504, device='cuda:0') tensor(6.4277, device='cuda:0') tensor(1.9159e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.284732
Average KL loss: 0.598213
Average total loss: 0.882945
tensor(-9.4565, device='cuda:0') tensor(6.4285, device='cuda:0') tensor(1.3370e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.282605
Average KL loss: 0.597294
Average total loss: 0.879899
tensor(-9.4625, device='cuda:0') tensor(6.4292, device='cuda:0') tensor(1.7151e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.285776
Average KL loss: 0.596358
Average total loss: 0.882134
tensor(-9.4685, device='cuda:0') tensor(6.4301, device='cuda:0') tensor(1.5871e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.278562
Average KL loss: 0.595398
Average total loss: 0.873960
tensor(-9.4746, device='cuda:0') tensor(6.4308, device='cuda:0') tensor(1.8876e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.286662
Average KL loss: 0.594454
Average total loss: 0.881116
tensor(-9.4806, device='cuda:0') tensor(6.4315, device='cuda:0') tensor(1.8126e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.280881
Average KL loss: 0.593509
Average total loss: 0.874390
 Percentile value: -10.928498268127441
Non-zero model percentage: 64.0%, Non-zero mask percentage: 64.0%

--- Pruning Level [2/24]: ---
conv1.weight         | nonzeros =    1721 /    1728             ( 99.59%) | total_pruned =       7 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   34895 /   36864             ( 94.66%) | total_pruned =    1969 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   35087 /   36864             ( 95.18%) | total_pruned =    1777 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   34629 /   36864             ( 93.94%) | total_pruned =    2235 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   34445 /   36864             ( 93.44%) | total_pruned =    2419 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   68671 /   73728             ( 93.14%) | total_pruned =    5057 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  134464 /  147456             ( 91.19%) | total_pruned =   12992 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8051 /    8192             ( 98.28%) | total_pruned =     141 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  130459 /  147456             ( 88.47%) | total_pruned =   16997 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  130515 /  147456             ( 88.51%) | total_pruned =   16941 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  262829 /  294912             ( 89.12%) | total_pruned =   32083 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  509931 /  589824             ( 86.45%) | total_pruned =   79893 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   31267 /   32768             ( 95.42%) | total_pruned =    1501 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  447311 /  589824             ( 75.84%) | total_pruned =  142513 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  441138 /  589824             ( 74.79%) | total_pruned =  148686 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  930386 / 1179648             ( 78.87%) | total_pruned =  249262 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1591048 / 2359296             ( 67.44%) | total_pruned =  768248 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  113039 /  131072             ( 86.24%) | total_pruned =   18033 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1100405 / 2359296             ( 46.64%) | total_pruned = 1258891 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     491 /     512             ( 95.90%) | total_pruned =      21 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1099430 / 2359296             ( 46.60%) | total_pruned = 1259866 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5102 /    5120             ( 99.65%) | total_pruned =      18 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 7154408, pruned : 4024354, total: 11178762, Compression rate :       1.56x  ( 36.00% pruned)
Train Epoch: 29/100 Loss: 0.000122 Accuracy: 86.52 100.00 % Best test Accuracy: 86.99%
tensor(-9.4866, device='cuda:0') tensor(6.4321, device='cuda:0') tensor(1.4574e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.310048
Average KL loss: 0.572253
Average total loss: 0.882300
tensor(-9.5583, device='cuda:0') tensor(6.0163, device='cuda:0') tensor(1.4945e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.307387
Average KL loss: 0.555599
Average total loss: 0.862986
tensor(-9.6075, device='cuda:0') tensor(5.7925, device='cuda:0') tensor(4.0584e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.302986
Average KL loss: 0.548608
Average total loss: 0.851594
tensor(-9.6463, device='cuda:0') tensor(5.6418, device='cuda:0') tensor(1.0605e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.303108
Average KL loss: 0.544421
Average total loss: 0.847529
tensor(-9.6791, device='cuda:0') tensor(5.5306, device='cuda:0') tensor(1.2726e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.305557
Average KL loss: 0.541534
Average total loss: 0.847091
tensor(-9.7077, device='cuda:0') tensor(5.4440, device='cuda:0') tensor(1.2863e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.300350
Average KL loss: 0.539279
Average total loss: 0.839629
tensor(-9.7332, device='cuda:0') tensor(5.3743, device='cuda:0') tensor(1.1623e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.305177
Average KL loss: 0.537542
Average total loss: 0.842719
tensor(-9.7564, device='cuda:0') tensor(5.3168, device='cuda:0') tensor(1.0126e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.296952
Average KL loss: 0.536021
Average total loss: 0.832972
tensor(-9.7778, device='cuda:0') tensor(5.2684, device='cuda:0') tensor(1.3072e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.293065
Average KL loss: 0.534672
Average total loss: 0.827737
tensor(-9.7977, device='cuda:0') tensor(5.2269, device='cuda:0') tensor(1.4309e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.296030
Average KL loss: 0.533463
Average total loss: 0.829493
tensor(-9.8163, device='cuda:0') tensor(5.1910, device='cuda:0') tensor(7.9771e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.293723
Average KL loss: 0.532392
Average total loss: 0.826115
tensor(-9.8339, device='cuda:0') tensor(5.1597, device='cuda:0') tensor(8.8661e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.293357
Average KL loss: 0.531433
Average total loss: 0.824790
tensor(-9.8506, device='cuda:0') tensor(5.1323, device='cuda:0') tensor(1.0422e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.295484
Average KL loss: 0.530552
Average total loss: 0.826036
tensor(-9.8664, device='cuda:0') tensor(5.1081, device='cuda:0') tensor(6.7380e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.287990
Average KL loss: 0.529727
Average total loss: 0.817717
tensor(-9.8815, device='cuda:0') tensor(5.0865, device='cuda:0') tensor(9.4896e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.285989
Average KL loss: 0.528918
Average total loss: 0.814907
tensor(-9.8960, device='cuda:0') tensor(5.0673, device='cuda:0') tensor(1.4018e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.289382
Average KL loss: 0.528156
Average total loss: 0.817537
tensor(-9.9100, device='cuda:0') tensor(5.0500, device='cuda:0') tensor(1.1004e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.286910
Average KL loss: 0.527391
Average total loss: 0.814301
tensor(-9.9234, device='cuda:0') tensor(5.0342, device='cuda:0') tensor(1.0019e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.289413
Average KL loss: 0.526679
Average total loss: 0.816092
tensor(-9.9364, device='cuda:0') tensor(5.0200, device='cuda:0') tensor(7.8965e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.285717
Average KL loss: 0.525986
Average total loss: 0.811702
tensor(-9.9490, device='cuda:0') tensor(5.0072, device='cuda:0') tensor(1.0876e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.280576
Average KL loss: 0.525286
Average total loss: 0.805862
tensor(-9.9611, device='cuda:0') tensor(4.9955, device='cuda:0') tensor(1.2958e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.283230
Average KL loss: 0.524631
Average total loss: 0.807860
tensor(-9.9730, device='cuda:0') tensor(4.9849, device='cuda:0') tensor(1.1337e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.287085
Average KL loss: 0.524015
Average total loss: 0.811100
tensor(-9.9845, device='cuda:0') tensor(4.9752, device='cuda:0') tensor(9.5263e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.285765
Average KL loss: 0.523393
Average total loss: 0.809158
tensor(-9.9957, device='cuda:0') tensor(4.9663, device='cuda:0') tensor(1.2264e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.277144
Average KL loss: 0.522796
Average total loss: 0.799940
tensor(-10.0066, device='cuda:0') tensor(4.9581, device='cuda:0') tensor(1.1776e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.277692
Average KL loss: 0.522134
Average total loss: 0.799826
tensor(-10.0173, device='cuda:0') tensor(4.9506, device='cuda:0') tensor(1.0832e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.280005
Average KL loss: 0.521509
Average total loss: 0.801514
tensor(-10.0277, device='cuda:0') tensor(4.9436, device='cuda:0') tensor(8.7268e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.275069
Average KL loss: 0.520892
Average total loss: 0.795961
tensor(-10.0379, device='cuda:0') tensor(4.9371, device='cuda:0') tensor(8.7624e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.280950
Average KL loss: 0.520267
Average total loss: 0.801217
tensor(-10.0479, device='cuda:0') tensor(4.9312, device='cuda:0') tensor(1.0522e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.279585
Average KL loss: 0.519693
Average total loss: 0.799278
tensor(-10.0577, device='cuda:0') tensor(4.9258, device='cuda:0') tensor(7.0744e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.277079
Average KL loss: 0.519087
Average total loss: 0.796166
tensor(-10.0673, device='cuda:0') tensor(4.9208, device='cuda:0') tensor(8.5712e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.272857
Average KL loss: 0.518488
Average total loss: 0.791345
tensor(-10.0767, device='cuda:0') tensor(4.9160, device='cuda:0') tensor(9.8683e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.279867
Average KL loss: 0.517880
Average total loss: 0.797747
tensor(-10.0860, device='cuda:0') tensor(4.9117, device='cuda:0') tensor(9.1796e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.273535
Average KL loss: 0.517286
Average total loss: 0.790821
tensor(-10.0951, device='cuda:0') tensor(4.9077, device='cuda:0') tensor(1.2428e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.276368
Average KL loss: 0.516704
Average total loss: 0.793071
tensor(-10.1040, device='cuda:0') tensor(4.9040, device='cuda:0') tensor(1.2359e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.272596
Average KL loss: 0.516119
Average total loss: 0.788715
tensor(-10.1128, device='cuda:0') tensor(4.9005, device='cuda:0') tensor(9.0809e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.272910
Average KL loss: 0.515495
Average total loss: 0.788405
tensor(-10.1214, device='cuda:0') tensor(4.8972, device='cuda:0') tensor(6.9223e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.271612
Average KL loss: 0.514922
Average total loss: 0.786533
tensor(-10.1299, device='cuda:0') tensor(4.8943, device='cuda:0') tensor(9.9701e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.273123
Average KL loss: 0.514432
Average total loss: 0.787554
tensor(-10.1383, device='cuda:0') tensor(4.8917, device='cuda:0') tensor(7.0997e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.271843
Average KL loss: 0.513934
Average total loss: 0.785777
tensor(-10.1466, device='cuda:0') tensor(4.8893, device='cuda:0') tensor(1.1564e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.270513
Average KL loss: 0.513423
Average total loss: 0.783936
tensor(-10.1547, device='cuda:0') tensor(4.8870, device='cuda:0') tensor(1.4525e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.267096
Average KL loss: 0.512935
Average total loss: 0.780031
tensor(-10.1628, device='cuda:0') tensor(4.8848, device='cuda:0') tensor(1.1752e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.271724
Average KL loss: 0.512380
Average total loss: 0.784104
tensor(-10.1707, device='cuda:0') tensor(4.8829, device='cuda:0') tensor(1.0831e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.263861
Average KL loss: 0.511880
Average total loss: 0.775741
tensor(-10.1785, device='cuda:0') tensor(4.8810, device='cuda:0') tensor(5.1643e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.266503
Average KL loss: 0.511345
Average total loss: 0.777848
tensor(-10.1862, device='cuda:0') tensor(4.8793, device='cuda:0') tensor(1.0801e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.269209
Average KL loss: 0.510831
Average total loss: 0.780040
tensor(-10.1938, device='cuda:0') tensor(4.8777, device='cuda:0') tensor(6.4760e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.262286
Average KL loss: 0.510344
Average total loss: 0.772629
tensor(-10.2014, device='cuda:0') tensor(4.8762, device='cuda:0') tensor(5.8940e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.265919
Average KL loss: 0.509800
Average total loss: 0.775719
tensor(-10.2088, device='cuda:0') tensor(4.8747, device='cuda:0') tensor(1.0428e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.264244
Average KL loss: 0.509254
Average total loss: 0.773498
tensor(-10.2162, device='cuda:0') tensor(4.8733, device='cuda:0') tensor(1.0520e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.262391
Average KL loss: 0.508699
Average total loss: 0.771090
tensor(-10.2235, device='cuda:0') tensor(4.8722, device='cuda:0') tensor(1.1255e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.263766
Average KL loss: 0.508181
Average total loss: 0.771947
tensor(-10.2307, device='cuda:0') tensor(4.8710, device='cuda:0') tensor(8.2865e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.261950
Average KL loss: 0.507647
Average total loss: 0.769597
tensor(-10.2378, device='cuda:0') tensor(4.8700, device='cuda:0') tensor(1.1579e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.263508
Average KL loss: 0.507105
Average total loss: 0.770612
tensor(-10.2449, device='cuda:0') tensor(4.8690, device='cuda:0') tensor(7.6045e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.259982
Average KL loss: 0.506600
Average total loss: 0.766583
tensor(-10.2518, device='cuda:0') tensor(4.8681, device='cuda:0') tensor(1.1643e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.263027
Average KL loss: 0.506063
Average total loss: 0.769090
tensor(-10.2587, device='cuda:0') tensor(4.8674, device='cuda:0') tensor(1.0074e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.260953
Average KL loss: 0.505560
Average total loss: 0.766513
tensor(-10.2656, device='cuda:0') tensor(4.8667, device='cuda:0') tensor(6.4622e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.258404
Average KL loss: 0.505069
Average total loss: 0.763472
tensor(-10.2723, device='cuda:0') tensor(4.8660, device='cuda:0') tensor(9.8015e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.257191
Average KL loss: 0.504582
Average total loss: 0.761772
tensor(-10.2790, device='cuda:0') tensor(4.8653, device='cuda:0') tensor(1.1177e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.255737
Average KL loss: 0.504081
Average total loss: 0.759818
tensor(-10.2857, device='cuda:0') tensor(4.8647, device='cuda:0') tensor(8.1862e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.251568
Average KL loss: 0.503559
Average total loss: 0.755127
tensor(-10.2923, device='cuda:0') tensor(4.8642, device='cuda:0') tensor(6.4493e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.261699
Average KL loss: 0.503108
Average total loss: 0.764807
tensor(-10.2988, device='cuda:0') tensor(4.8638, device='cuda:0') tensor(5.9331e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.258965
Average KL loss: 0.502634
Average total loss: 0.761599
tensor(-10.3052, device='cuda:0') tensor(4.8634, device='cuda:0') tensor(9.2069e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.254815
Average KL loss: 0.502188
Average total loss: 0.757003
tensor(-10.3117, device='cuda:0') tensor(4.8629, device='cuda:0') tensor(7.1193e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.258426
Average KL loss: 0.501741
Average total loss: 0.760167
tensor(-10.3180, device='cuda:0') tensor(4.8625, device='cuda:0') tensor(1.2426e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.258215
Average KL loss: 0.501248
Average total loss: 0.759463
tensor(-10.3243, device='cuda:0') tensor(4.8621, device='cuda:0') tensor(9.0108e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.254231
Average KL loss: 0.500779
Average total loss: 0.755009
tensor(-10.3306, device='cuda:0') tensor(4.8617, device='cuda:0') tensor(1.2418e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.254832
Average KL loss: 0.500306
Average total loss: 0.755137
tensor(-10.3368, device='cuda:0') tensor(4.8615, device='cuda:0') tensor(1.0103e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.254922
Average KL loss: 0.499862
Average total loss: 0.754783
tensor(-10.3429, device='cuda:0') tensor(4.8612, device='cuda:0') tensor(6.5787e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.251831
Average KL loss: 0.499378
Average total loss: 0.751209
tensor(-10.3491, device='cuda:0') tensor(4.8610, device='cuda:0') tensor(7.7146e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.250987
Average KL loss: 0.498915
Average total loss: 0.749902
tensor(-10.3551, device='cuda:0') tensor(4.8607, device='cuda:0') tensor(1.0063e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.255383
Average KL loss: 0.498431
Average total loss: 0.753814
tensor(-10.3611, device='cuda:0') tensor(4.8604, device='cuda:0') tensor(7.6464e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.251788
Average KL loss: 0.497963
Average total loss: 0.749751
tensor(-10.3671, device='cuda:0') tensor(4.8602, device='cuda:0') tensor(8.1998e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.248786
Average KL loss: 0.497507
Average total loss: 0.746293
tensor(-10.3730, device='cuda:0') tensor(4.8601, device='cuda:0') tensor(1.1272e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.252635
Average KL loss: 0.497033
Average total loss: 0.749668
tensor(-10.3789, device='cuda:0') tensor(4.8598, device='cuda:0') tensor(8.7916e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.249186
Average KL loss: 0.496540
Average total loss: 0.745726
tensor(-10.3848, device='cuda:0') tensor(4.8596, device='cuda:0') tensor(9.0500e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.245326
Average KL loss: 0.496030
Average total loss: 0.741356
tensor(-10.3906, device='cuda:0') tensor(4.8592, device='cuda:0') tensor(7.6715e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.250059
Average KL loss: 0.495568
Average total loss: 0.745627
tensor(-10.3964, device='cuda:0') tensor(4.8591, device='cuda:0') tensor(9.1686e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.254937
Average KL loss: 0.495098
Average total loss: 0.750035
tensor(-10.4021, device='cuda:0') tensor(4.8588, device='cuda:0') tensor(6.6731e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.246149
Average KL loss: 0.494613
Average total loss: 0.740762
tensor(-10.4078, device='cuda:0') tensor(4.8587, device='cuda:0') tensor(5.1234e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.251674
Average KL loss: 0.494155
Average total loss: 0.745829
tensor(-10.4134, device='cuda:0') tensor(4.8584, device='cuda:0') tensor(6.8437e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.241957
Average KL loss: 0.493647
Average total loss: 0.735604
tensor(-10.4191, device='cuda:0') tensor(4.8582, device='cuda:0') tensor(1.0790e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.247781
Average KL loss: 0.493135
Average total loss: 0.740916
tensor(-10.4247, device='cuda:0') tensor(4.8580, device='cuda:0') tensor(7.5185e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.245044
Average KL loss: 0.492675
Average total loss: 0.737719
tensor(-10.4302, device='cuda:0') tensor(4.8578, device='cuda:0') tensor(1.1025e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.242956
Average KL loss: 0.492219
Average total loss: 0.735175
tensor(-10.4357, device='cuda:0') tensor(4.8576, device='cuda:0') tensor(1.0941e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.243938
Average KL loss: 0.491746
Average total loss: 0.735684
tensor(-10.4412, device='cuda:0') tensor(4.8573, device='cuda:0') tensor(1.0543e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.244135
Average KL loss: 0.491278
Average total loss: 0.735412
tensor(-10.4467, device='cuda:0') tensor(4.8571, device='cuda:0') tensor(8.5408e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.243319
Average KL loss: 0.490820
Average total loss: 0.734139
tensor(-10.4521, device='cuda:0') tensor(4.8569, device='cuda:0') tensor(1.0227e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.240778
Average KL loss: 0.490366
Average total loss: 0.731144
tensor(-10.4575, device='cuda:0') tensor(4.8567, device='cuda:0') tensor(8.3996e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.240359
Average KL loss: 0.489932
Average total loss: 0.730291
tensor(-10.4628, device='cuda:0') tensor(4.8565, device='cuda:0') tensor(6.4835e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.243938
Average KL loss: 0.489456
Average total loss: 0.733394
tensor(-10.4682, device='cuda:0') tensor(4.8562, device='cuda:0') tensor(1.3885e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.243379
Average KL loss: 0.489002
Average total loss: 0.732381
tensor(-10.4735, device='cuda:0') tensor(4.8560, device='cuda:0') tensor(8.0712e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.241775
Average KL loss: 0.488617
Average total loss: 0.730392
tensor(-10.4788, device='cuda:0') tensor(4.8558, device='cuda:0') tensor(8.7217e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.239031
Average KL loss: 0.488171
Average total loss: 0.727202
tensor(-10.4840, device='cuda:0') tensor(4.8554, device='cuda:0') tensor(8.2118e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.240428
Average KL loss: 0.487741
Average total loss: 0.728170
tensor(-10.4892, device='cuda:0') tensor(4.8552, device='cuda:0') tensor(8.3145e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.237622
Average KL loss: 0.487315
Average total loss: 0.724937
tensor(-10.4944, device='cuda:0') tensor(4.8549, device='cuda:0') tensor(1.0189e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.240004
Average KL loss: 0.486866
Average total loss: 0.726870
tensor(-10.4996, device='cuda:0') tensor(4.8546, device='cuda:0') tensor(6.5059e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.237924
Average KL loss: 0.486426
Average total loss: 0.724350
tensor(-10.5047, device='cuda:0') tensor(4.8543, device='cuda:0') tensor(1.0487e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.236405
Average KL loss: 0.485969
Average total loss: 0.722374
tensor(-10.5099, device='cuda:0') tensor(4.8539, device='cuda:0') tensor(1.1178e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.234991
Average KL loss: 0.485523
Average total loss: 0.720513
tensor(-10.5150, device='cuda:0') tensor(4.8535, device='cuda:0') tensor(9.2747e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.239045
Average KL loss: 0.485062
Average total loss: 0.724107
tensor(-10.5200, device='cuda:0') tensor(4.8531, device='cuda:0') tensor(1.0401e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.236307
Average KL loss: 0.484633
Average total loss: 0.720940
tensor(-10.5251, device='cuda:0') tensor(4.8529, device='cuda:0') tensor(5.6460e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.236533
Average KL loss: 0.484199
Average total loss: 0.720732
tensor(-10.5301, device='cuda:0') tensor(4.8525, device='cuda:0') tensor(9.3781e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.232230
Average KL loss: 0.483763
Average total loss: 0.715993
tensor(-10.5351, device='cuda:0') tensor(4.8522, device='cuda:0') tensor(8.5906e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.235602
Average KL loss: 0.483337
Average total loss: 0.718939
tensor(-10.5400, device='cuda:0') tensor(4.8520, device='cuda:0') tensor(8.6280e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.235257
Average KL loss: 0.482908
Average total loss: 0.718165
tensor(-10.5450, device='cuda:0') tensor(4.8516, device='cuda:0') tensor(8.3898e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.234857
Average KL loss: 0.482459
Average total loss: 0.717317
tensor(-10.5499, device='cuda:0') tensor(4.8512, device='cuda:0') tensor(7.7188e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.228824
Average KL loss: 0.482027
Average total loss: 0.710851
tensor(-10.5548, device='cuda:0') tensor(4.8507, device='cuda:0') tensor(6.5635e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.233295
Average KL loss: 0.481599
Average total loss: 0.714893
tensor(-10.5597, device='cuda:0') tensor(4.8504, device='cuda:0') tensor(7.7333e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.235904
Average KL loss: 0.481174
Average total loss: 0.717078
tensor(-10.5645, device='cuda:0') tensor(4.8500, device='cuda:0') tensor(8.1818e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.231815
Average KL loss: 0.480746
Average total loss: 0.712561
tensor(-10.5694, device='cuda:0') tensor(4.8496, device='cuda:0') tensor(8.0406e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.230016
Average KL loss: 0.480322
Average total loss: 0.710339
tensor(-10.5742, device='cuda:0') tensor(4.8491, device='cuda:0') tensor(7.7293e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.230628
Average KL loss: 0.479889
Average total loss: 0.710518
tensor(-10.5790, device='cuda:0') tensor(4.8487, device='cuda:0') tensor(6.1805e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.228945
Average KL loss: 0.479510
Average total loss: 0.708454
tensor(-10.5837, device='cuda:0') tensor(4.8483, device='cuda:0') tensor(6.7368e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.230396
Average KL loss: 0.479117
Average total loss: 0.709512
tensor(-10.5885, device='cuda:0') tensor(4.8478, device='cuda:0') tensor(5.0486e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.228489
Average KL loss: 0.478702
Average total loss: 0.707191
tensor(-10.5932, device='cuda:0') tensor(4.8472, device='cuda:0') tensor(8.8340e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.229919
Average KL loss: 0.478263
Average total loss: 0.708182
tensor(-10.5980, device='cuda:0') tensor(4.8466, device='cuda:0') tensor(5.8296e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.229121
Average KL loss: 0.477862
Average total loss: 0.706983
tensor(-10.6027, device='cuda:0') tensor(4.8461, device='cuda:0') tensor(7.4653e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.229579
Average KL loss: 0.477460
Average total loss: 0.707039
tensor(-10.6073, device='cuda:0') tensor(4.8456, device='cuda:0') tensor(7.0810e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.225978
Average KL loss: 0.477076
Average total loss: 0.703053
tensor(-10.6120, device='cuda:0') tensor(4.8450, device='cuda:0') tensor(8.0713e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.226868
Average KL loss: 0.476627
Average total loss: 0.703495
tensor(-10.6166, device='cuda:0') tensor(4.8444, device='cuda:0') tensor(5.9965e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.227216
Average KL loss: 0.476210
Average total loss: 0.703426
tensor(-10.6213, device='cuda:0') tensor(4.8439, device='cuda:0') tensor(6.2775e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.224976
Average KL loss: 0.475827
Average total loss: 0.700803
tensor(-10.6259, device='cuda:0') tensor(4.8433, device='cuda:0') tensor(5.6746e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.226044
Average KL loss: 0.475423
Average total loss: 0.701468
tensor(-10.6305, device='cuda:0') tensor(4.8426, device='cuda:0') tensor(6.1878e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.227805
Average KL loss: 0.474993
Average total loss: 0.702797
tensor(-10.6350, device='cuda:0') tensor(4.8419, device='cuda:0') tensor(7.6445e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.222886
Average KL loss: 0.474581
Average total loss: 0.697468
tensor(-10.6396, device='cuda:0') tensor(4.8412, device='cuda:0') tensor(8.4279e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.222554
Average KL loss: 0.474186
Average total loss: 0.696740
tensor(-10.6442, device='cuda:0') tensor(4.8406, device='cuda:0') tensor(9.3239e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.221858
Average KL loss: 0.473798
Average total loss: 0.695655
tensor(-10.6487, device='cuda:0') tensor(4.8399, device='cuda:0') tensor(1.2185e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.221630
Average KL loss: 0.473387
Average total loss: 0.695017
tensor(-10.6532, device='cuda:0') tensor(4.8391, device='cuda:0') tensor(6.5303e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.221532
Average KL loss: 0.472974
Average total loss: 0.694506
tensor(-10.6577, device='cuda:0') tensor(4.8383, device='cuda:0') tensor(6.5334e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.222880
Average KL loss: 0.472580
Average total loss: 0.695460
tensor(-10.6622, device='cuda:0') tensor(4.8377, device='cuda:0') tensor(4.1225e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.223970
Average KL loss: 0.472169
Average total loss: 0.696139
tensor(-10.6666, device='cuda:0') tensor(4.8368, device='cuda:0') tensor(6.7396e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.222499
Average KL loss: 0.471783
Average total loss: 0.694282
tensor(-10.6711, device='cuda:0') tensor(4.8361, device='cuda:0') tensor(7.0765e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.221086
Average KL loss: 0.471417
Average total loss: 0.692503
tensor(-10.6755, device='cuda:0') tensor(4.8353, device='cuda:0') tensor(7.9733e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.218790
Average KL loss: 0.471011
Average total loss: 0.689800
tensor(-10.6799, device='cuda:0') tensor(4.8344, device='cuda:0') tensor(8.9268e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.220109
Average KL loss: 0.470605
Average total loss: 0.690714
tensor(-10.6844, device='cuda:0') tensor(4.8335, device='cuda:0') tensor(1.1188e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.218892
Average KL loss: 0.470205
Average total loss: 0.689097
tensor(-10.6887, device='cuda:0') tensor(4.8325, device='cuda:0') tensor(4.7778e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.218086
Average KL loss: 0.469815
Average total loss: 0.687901
tensor(-10.6931, device='cuda:0') tensor(4.8317, device='cuda:0') tensor(9.6535e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.216505
Average KL loss: 0.469422
Average total loss: 0.685928
tensor(-10.6975, device='cuda:0') tensor(4.8308, device='cuda:0') tensor(7.3876e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.219289
Average KL loss: 0.469034
Average total loss: 0.688323
tensor(-10.7018, device='cuda:0') tensor(4.8300, device='cuda:0') tensor(7.0861e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.216997
Average KL loss: 0.468703
Average total loss: 0.685699
tensor(-10.7062, device='cuda:0') tensor(4.8292, device='cuda:0') tensor(1.3427e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.214022
Average KL loss: 0.468346
Average total loss: 0.682368
tensor(-10.7105, device='cuda:0') tensor(4.8283, device='cuda:0') tensor(6.8031e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.216693
Average KL loss: 0.467947
Average total loss: 0.684640
tensor(-10.7148, device='cuda:0') tensor(4.8273, device='cuda:0') tensor(7.3617e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.217636
Average KL loss: 0.467577
Average total loss: 0.685214
tensor(-10.7191, device='cuda:0') tensor(4.8263, device='cuda:0') tensor(1.0722e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.216303
Average KL loss: 0.467206
Average total loss: 0.683508
tensor(-10.7233, device='cuda:0') tensor(4.8253, device='cuda:0') tensor(6.7233e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.216457
Average KL loss: 0.466830
Average total loss: 0.683287
tensor(-10.7276, device='cuda:0') tensor(4.8244, device='cuda:0') tensor(9.3304e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.219242
Average KL loss: 0.466418
Average total loss: 0.685660
tensor(-10.7319, device='cuda:0') tensor(4.8233, device='cuda:0') tensor(7.5846e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.211123
Average KL loss: 0.466004
Average total loss: 0.677126
tensor(-10.7361, device='cuda:0') tensor(4.8223, device='cuda:0') tensor(7.5838e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.213696
Average KL loss: 0.465613
Average total loss: 0.679309
tensor(-10.7403, device='cuda:0') tensor(4.8214, device='cuda:0') tensor(8.3246e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.215740
Average KL loss: 0.465250
Average total loss: 0.680990
tensor(-10.7445, device='cuda:0') tensor(4.8203, device='cuda:0') tensor(8.7781e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.215809
Average KL loss: 0.464867
Average total loss: 0.680676
tensor(-10.7488, device='cuda:0') tensor(4.8192, device='cuda:0') tensor(8.8835e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.213601
Average KL loss: 0.464441
Average total loss: 0.678042
tensor(-10.7529, device='cuda:0') tensor(4.8181, device='cuda:0') tensor(8.5950e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.212014
Average KL loss: 0.464044
Average total loss: 0.676057
tensor(-10.7571, device='cuda:0') tensor(4.8170, device='cuda:0') tensor(7.2385e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.209747
Average KL loss: 0.463683
Average total loss: 0.673430
tensor(-10.7613, device='cuda:0') tensor(4.8159, device='cuda:0') tensor(9.0337e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.210449
Average KL loss: 0.463333
Average total loss: 0.673783
tensor(-10.7654, device='cuda:0') tensor(4.8148, device='cuda:0') tensor(8.8269e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.210995
Average KL loss: 0.462955
Average total loss: 0.673950
tensor(-10.7696, device='cuda:0') tensor(4.8136, device='cuda:0') tensor(5.2876e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.208358
Average KL loss: 0.462576
Average total loss: 0.670934
tensor(-10.7737, device='cuda:0') tensor(4.8125, device='cuda:0') tensor(3.7089e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.209377
Average KL loss: 0.462179
Average total loss: 0.671556
tensor(-10.7778, device='cuda:0') tensor(4.8112, device='cuda:0') tensor(7.3490e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.210458
Average KL loss: 0.461840
Average total loss: 0.672299
tensor(-10.7819, device='cuda:0') tensor(4.8101, device='cuda:0') tensor(4.2129e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.206192
Average KL loss: 0.461489
Average total loss: 0.667681
tensor(-10.7860, device='cuda:0') tensor(4.8089, device='cuda:0') tensor(9.2201e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.209391
Average KL loss: 0.461111
Average total loss: 0.670502
tensor(-10.7901, device='cuda:0') tensor(4.8077, device='cuda:0') tensor(1.8093e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.210797
Average KL loss: 0.460795
Average total loss: 0.671592
tensor(-10.7942, device='cuda:0') tensor(4.8065, device='cuda:0') tensor(5.4565e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.210015
Average KL loss: 0.460458
Average total loss: 0.670473
tensor(-10.7983, device='cuda:0') tensor(4.8052, device='cuda:0') tensor(1.0933e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.204632
Average KL loss: 0.460091
Average total loss: 0.664722
tensor(-10.8023, device='cuda:0') tensor(4.8039, device='cuda:0') tensor(8.1223e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.206606
Average KL loss: 0.459718
Average total loss: 0.666324
tensor(-10.8064, device='cuda:0') tensor(4.8026, device='cuda:0') tensor(7.5869e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.207129
Average KL loss: 0.459377
Average total loss: 0.666506
tensor(-10.8104, device='cuda:0') tensor(4.8013, device='cuda:0') tensor(9.1358e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.205283
Average KL loss: 0.459013
Average total loss: 0.664295
tensor(-10.8144, device='cuda:0') tensor(4.7999, device='cuda:0') tensor(1.0182e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.202579
Average KL loss: 0.458645
Average total loss: 0.661224
tensor(-10.8185, device='cuda:0') tensor(4.7984, device='cuda:0') tensor(8.4943e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.207633
Average KL loss: 0.458282
Average total loss: 0.665915
tensor(-10.8225, device='cuda:0') tensor(4.7970, device='cuda:0') tensor(8.4115e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.203811
Average KL loss: 0.457945
Average total loss: 0.661757
tensor(-10.8265, device='cuda:0') tensor(4.7957, device='cuda:0') tensor(1.2086e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.204086
Average KL loss: 0.457588
Average total loss: 0.661675
tensor(-10.8304, device='cuda:0') tensor(4.7942, device='cuda:0') tensor(4.5175e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.202607
Average KL loss: 0.457286
Average total loss: 0.659893
tensor(-10.8344, device='cuda:0') tensor(4.7929, device='cuda:0') tensor(8.8884e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.203860
Average KL loss: 0.456924
Average total loss: 0.660784
tensor(-10.8384, device='cuda:0') tensor(4.7915, device='cuda:0') tensor(7.6634e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.202183
Average KL loss: 0.456558
Average total loss: 0.658741
tensor(-10.8423, device='cuda:0') tensor(4.7900, device='cuda:0') tensor(2.8848e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.202506
Average KL loss: 0.456205
Average total loss: 0.658710
tensor(-10.8463, device='cuda:0') tensor(4.7885, device='cuda:0') tensor(8.8937e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.202585
Average KL loss: 0.455875
Average total loss: 0.658460
tensor(-10.8502, device='cuda:0') tensor(4.7871, device='cuda:0') tensor(8.5716e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.200937
Average KL loss: 0.455549
Average total loss: 0.656486
tensor(-10.8542, device='cuda:0') tensor(4.7855, device='cuda:0') tensor(8.6874e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.202052
Average KL loss: 0.455196
Average total loss: 0.657249
tensor(-10.8581, device='cuda:0') tensor(4.7840, device='cuda:0') tensor(7.3473e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.204825
Average KL loss: 0.454861
Average total loss: 0.659686
tensor(-10.8620, device='cuda:0') tensor(4.7824, device='cuda:0') tensor(9.1757e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.197286
Average KL loss: 0.454542
Average total loss: 0.651828
tensor(-10.8659, device='cuda:0') tensor(4.7810, device='cuda:0') tensor(9.1688e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.198906
Average KL loss: 0.454233
Average total loss: 0.653139
tensor(-10.8698, device='cuda:0') tensor(4.7794, device='cuda:0') tensor(5.2994e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.200949
Average KL loss: 0.453935
Average total loss: 0.654884
tensor(-10.8737, device='cuda:0') tensor(4.7780, device='cuda:0') tensor(9.3690e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.199419
Average KL loss: 0.453572
Average total loss: 0.652991
tensor(-10.8775, device='cuda:0') tensor(4.7763, device='cuda:0') tensor(5.6543e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.202005
Average KL loss: 0.453229
Average total loss: 0.655234
tensor(-10.8814, device='cuda:0') tensor(4.7747, device='cuda:0') tensor(6.2977e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.197091
Average KL loss: 0.452889
Average total loss: 0.649980
tensor(-10.8853, device='cuda:0') tensor(4.7730, device='cuda:0') tensor(7.6085e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.198190
Average KL loss: 0.452528
Average total loss: 0.650718
tensor(-10.8891, device='cuda:0') tensor(4.7713, device='cuda:0') tensor(3.9260e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.198190
Average KL loss: 0.452202
Average total loss: 0.650392
tensor(-10.8929, device='cuda:0') tensor(4.7698, device='cuda:0') tensor(8.6690e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.195701
Average KL loss: 0.451885
Average total loss: 0.647585
tensor(-10.8968, device='cuda:0') tensor(4.7681, device='cuda:0') tensor(5.4526e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.196568
Average KL loss: 0.451559
Average total loss: 0.648127
tensor(-10.9006, device='cuda:0') tensor(4.7665, device='cuda:0') tensor(7.8922e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.196418
Average KL loss: 0.451219
Average total loss: 0.647637
tensor(-10.9044, device='cuda:0') tensor(4.7649, device='cuda:0') tensor(7.1266e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.195746
Average KL loss: 0.450873
Average total loss: 0.646619
tensor(-10.9082, device='cuda:0') tensor(4.7630, device='cuda:0') tensor(5.9508e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.196670
Average KL loss: 0.450534
Average total loss: 0.647204
tensor(-10.9120, device='cuda:0') tensor(4.7612, device='cuda:0') tensor(7.7154e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.197419
Average KL loss: 0.450201
Average total loss: 0.647620
tensor(-10.9158, device='cuda:0') tensor(4.7594, device='cuda:0') tensor(7.1317e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.194322
Average KL loss: 0.449869
Average total loss: 0.644191
tensor(-10.9196, device='cuda:0') tensor(4.7577, device='cuda:0') tensor(5.7837e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.195472
Average KL loss: 0.449549
Average total loss: 0.645021
tensor(-10.9234, device='cuda:0') tensor(4.7561, device='cuda:0') tensor(7.3778e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.188841
Average KL loss: 0.449231
Average total loss: 0.638072
tensor(-10.9271, device='cuda:0') tensor(4.7543, device='cuda:0') tensor(6.8384e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.194018
Average KL loss: 0.448898
Average total loss: 0.642916
tensor(-10.9309, device='cuda:0') tensor(4.7525, device='cuda:0') tensor(8.0454e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.193608
Average KL loss: 0.448557
Average total loss: 0.642166
tensor(-10.9346, device='cuda:0') tensor(4.7507, device='cuda:0') tensor(5.3544e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.191677
Average KL loss: 0.448237
Average total loss: 0.639914
tensor(-10.9384, device='cuda:0') tensor(4.7489, device='cuda:0') tensor(8.2580e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.190974
Average KL loss: 0.447951
Average total loss: 0.638924
tensor(-10.9421, device='cuda:0') tensor(4.7471, device='cuda:0') tensor(5.0105e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.189628
Average KL loss: 0.447668
Average total loss: 0.637296
tensor(-10.9459, device='cuda:0') tensor(4.7453, device='cuda:0') tensor(8.7886e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.190799
Average KL loss: 0.447332
Average total loss: 0.638131
 Percentile value: -11.621021270751953
Non-zero model percentage: 51.200008392333984%, Non-zero mask percentage: 51.200008392333984%

--- Pruning Level [3/24]: ---
conv1.weight         | nonzeros =    1716 /    1728             ( 99.31%) | total_pruned =      12 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   32741 /   36864             ( 88.82%) | total_pruned =    4123 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   33055 /   36864             ( 89.67%) | total_pruned =    3809 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   32325 /   36864             ( 87.69%) | total_pruned =    4539 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   32148 /   36864             ( 87.21%) | total_pruned =    4716 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   64145 /   73728             ( 87.00%) | total_pruned =    9583 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  124019 /  147456             ( 84.11%) | total_pruned =   23437 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7821 /    8192             ( 95.47%) | total_pruned =     371 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  117252 /  147456             ( 79.52%) | total_pruned =   30204 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  117442 /  147456             ( 79.65%) | total_pruned =   30014 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  238729 /  294912             ( 80.95%) | total_pruned =   56183 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  454162 /  589824             ( 77.00%) | total_pruned =  135662 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   29632 /   32768             ( 90.43%) | total_pruned =    3136 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  365613 /  589824             ( 61.99%) | total_pruned =  224211 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     246 /     256             ( 96.09%) | total_pruned =      10 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  360524 /  589824             ( 61.12%) | total_pruned =  229300 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  773710 / 1179648             ( 65.59%) | total_pruned =  405938 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1230237 / 2359296             ( 52.14%) | total_pruned = 1129059 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   95952 /  131072             ( 73.21%) | total_pruned =   35120 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  787065 / 2359296             ( 33.36%) | total_pruned = 1572231 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     483 /     512             ( 94.34%) | total_pruned =      29 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     364 /     512             ( 71.09%) | total_pruned =     148 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  810753 / 2359296             ( 34.36%) | total_pruned = 1548543 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5078 /    5120             ( 99.18%) | total_pruned =      42 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 5723527, pruned : 5455235, total: 11178762, Compression rate :       1.95x  ( 48.80% pruned)
Train Epoch: 27/100 Loss: 0.001902 Accuracy: 86.77 100.00 % Best test Accuracy: 86.89%
tensor(-10.9496, device='cuda:0') tensor(4.7434, device='cuda:0') tensor(6.5195e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.226393
Average KL loss: 0.438754
Average total loss: 0.665147
tensor(-10.9812, device='cuda:0') tensor(4.4868, device='cuda:0') tensor(6.2765e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.223277
Average KL loss: 0.432279
Average total loss: 0.655556
tensor(-11.0032, device='cuda:0') tensor(4.3421, device='cuda:0') tensor(7.3218e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.218375
Average KL loss: 0.429585
Average total loss: 0.647960
tensor(-11.0209, device='cuda:0') tensor(4.2409, device='cuda:0') tensor(4.2509e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.217949
Average KL loss: 0.428026
Average total loss: 0.645974
tensor(-11.0360, device='cuda:0') tensor(4.1634, device='cuda:0') tensor(9.4477e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.219668
Average KL loss: 0.426976
Average total loss: 0.646643
tensor(-11.0494, device='cuda:0') tensor(4.1012, device='cuda:0') tensor(1.6516e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.213101
Average KL loss: 0.426157
Average total loss: 0.639258
tensor(-11.0615, device='cuda:0') tensor(4.0494, device='cuda:0') tensor(6.4949e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.213588
Average KL loss: 0.425497
Average total loss: 0.639085
tensor(-11.0727, device='cuda:0') tensor(4.0052, device='cuda:0') tensor(2.8952e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.213952
Average KL loss: 0.424953
Average total loss: 0.638905
tensor(-11.0831, device='cuda:0') tensor(3.9669, device='cuda:0') tensor(1.6297e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.212453
Average KL loss: 0.424485
Average total loss: 0.636938
tensor(-11.0929, device='cuda:0') tensor(3.9331, device='cuda:0') tensor(2.8467e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.214222
Average KL loss: 0.424084
Average total loss: 0.638306
tensor(-11.1021, device='cuda:0') tensor(3.9032, device='cuda:0') tensor(5.1574e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.206496
Average KL loss: 0.423731
Average total loss: 0.630227
tensor(-11.1109, device='cuda:0') tensor(3.8763, device='cuda:0') tensor(6.0497e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.206127
Average KL loss: 0.423379
Average total loss: 0.629506
tensor(-11.1192, device='cuda:0') tensor(3.8520, device='cuda:0') tensor(7.0853e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.204877
Average KL loss: 0.423073
Average total loss: 0.627950
tensor(-11.1273, device='cuda:0') tensor(3.8299, device='cuda:0') tensor(1.9261e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.205435
Average KL loss: 0.422790
Average total loss: 0.628225
tensor(-11.1350, device='cuda:0') tensor(3.8096, device='cuda:0') tensor(3.8395e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.207787
Average KL loss: 0.422492
Average total loss: 0.630280
tensor(-11.1425, device='cuda:0') tensor(3.7909, device='cuda:0') tensor(4.6293e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.203211
Average KL loss: 0.422223
Average total loss: 0.625434
tensor(-11.1498, device='cuda:0') tensor(3.7736, device='cuda:0') tensor(3.6207e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.204056
Average KL loss: 0.421955
Average total loss: 0.626011
tensor(-11.1568, device='cuda:0') tensor(3.7576, device='cuda:0') tensor(5.8840e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.202117
Average KL loss: 0.421694
Average total loss: 0.623810
tensor(-11.1636, device='cuda:0') tensor(3.7426, device='cuda:0') tensor(2.8560e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.203877
Average KL loss: 0.421453
Average total loss: 0.625330
tensor(-11.1703, device='cuda:0') tensor(3.7287, device='cuda:0') tensor(6.9840e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.202061
Average KL loss: 0.421222
Average total loss: 0.623283
tensor(-11.1768, device='cuda:0') tensor(3.7155, device='cuda:0') tensor(4.0125e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.202044
Average KL loss: 0.420979
Average total loss: 0.623023
tensor(-11.1831, device='cuda:0') tensor(3.7033, device='cuda:0') tensor(2.9905e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.201502
Average KL loss: 0.420753
Average total loss: 0.622256
tensor(-11.1893, device='cuda:0') tensor(3.6916, device='cuda:0') tensor(8.3323e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.200018
Average KL loss: 0.420533
Average total loss: 0.620551
tensor(-11.1954, device='cuda:0') tensor(3.6806, device='cuda:0') tensor(2.5307e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.198380
Average KL loss: 0.420302
Average total loss: 0.618682
tensor(-11.2014, device='cuda:0') tensor(3.6703, device='cuda:0') tensor(1.9580e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.199485
Average KL loss: 0.420100
Average total loss: 0.619586
tensor(-11.2072, device='cuda:0') tensor(3.6605, device='cuda:0') tensor(6.0643e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.197573
Average KL loss: 0.419895
Average total loss: 0.617468
tensor(-11.2129, device='cuda:0') tensor(3.6512, device='cuda:0') tensor(5.7093e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.198692
Average KL loss: 0.419696
Average total loss: 0.618389
tensor(-11.2186, device='cuda:0') tensor(3.6423, device='cuda:0') tensor(2.9021e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.198575
Average KL loss: 0.419499
Average total loss: 0.618074
tensor(-11.2241, device='cuda:0') tensor(3.6339, device='cuda:0') tensor(3.7562e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.198801
Average KL loss: 0.419306
Average total loss: 0.618107
tensor(-11.2296, device='cuda:0') tensor(3.6258, device='cuda:0') tensor(3.0979e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.194952
Average KL loss: 0.419095
Average total loss: 0.614046
tensor(-11.2349, device='cuda:0') tensor(3.6180, device='cuda:0') tensor(2.4814e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.192854
Average KL loss: 0.418884
Average total loss: 0.611738
tensor(-11.2402, device='cuda:0') tensor(3.6107, device='cuda:0') tensor(5.2360e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.194291
Average KL loss: 0.418714
Average total loss: 0.613005
tensor(-11.2455, device='cuda:0') tensor(3.6037, device='cuda:0') tensor(3.8794e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.192017
Average KL loss: 0.418555
Average total loss: 0.610572
tensor(-11.2506, device='cuda:0') tensor(3.5970, device='cuda:0') tensor(5.2512e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.194486
Average KL loss: 0.418371
Average total loss: 0.612857
tensor(-11.2557, device='cuda:0') tensor(3.5904, device='cuda:0') tensor(4.7802e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.189974
Average KL loss: 0.418177
Average total loss: 0.608152
tensor(-11.2607, device='cuda:0') tensor(3.5842, device='cuda:0') tensor(3.5948e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.192697
Average KL loss: 0.417999
Average total loss: 0.610695
tensor(-11.2656, device='cuda:0') tensor(3.5782, device='cuda:0') tensor(3.8938e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.194195
Average KL loss: 0.417823
Average total loss: 0.612018
tensor(-11.2705, device='cuda:0') tensor(3.5725, device='cuda:0') tensor(5.8602e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.187941
Average KL loss: 0.417641
Average total loss: 0.605582
tensor(-11.2753, device='cuda:0') tensor(3.5670, device='cuda:0') tensor(5.4836e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.190891
Average KL loss: 0.417467
Average total loss: 0.608358
tensor(-11.2801, device='cuda:0') tensor(3.5616, device='cuda:0') tensor(3.5115e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.189563
Average KL loss: 0.417298
Average total loss: 0.606862
tensor(-11.2848, device='cuda:0') tensor(3.5565, device='cuda:0') tensor(4.4739e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.188572
Average KL loss: 0.417136
Average total loss: 0.605708
tensor(-11.2895, device='cuda:0') tensor(3.5515, device='cuda:0') tensor(4.2280e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.188590
Average KL loss: 0.416967
Average total loss: 0.605558
tensor(-11.2941, device='cuda:0') tensor(3.5468, device='cuda:0') tensor(5.8769e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.187683
Average KL loss: 0.416795
Average total loss: 0.604477
tensor(-11.2987, device='cuda:0') tensor(3.5422, device='cuda:0') tensor(2.4104e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.189526
Average KL loss: 0.416632
Average total loss: 0.606159
tensor(-11.3032, device='cuda:0') tensor(3.5377, device='cuda:0') tensor(5.5153e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.186369
Average KL loss: 0.416467
Average total loss: 0.602836
tensor(-11.3077, device='cuda:0') tensor(3.5334, device='cuda:0') tensor(1.2159e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.189075
Average KL loss: 0.416337
Average total loss: 0.605413
tensor(-11.3121, device='cuda:0') tensor(3.5293, device='cuda:0') tensor(2.0976e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.184560
Average KL loss: 0.416184
Average total loss: 0.600744
tensor(-11.3166, device='cuda:0') tensor(3.5252, device='cuda:0') tensor(4.1344e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.187702
Average KL loss: 0.416005
Average total loss: 0.603707
tensor(-11.3209, device='cuda:0') tensor(3.5211, device='cuda:0') tensor(5.0318e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.182041
Average KL loss: 0.415811
Average total loss: 0.597853
tensor(-11.3252, device='cuda:0') tensor(3.5171, device='cuda:0') tensor(6.9836e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.184167
Average KL loss: 0.415603
Average total loss: 0.599770
tensor(-11.3295, device='cuda:0') tensor(3.5134, device='cuda:0') tensor(3.0531e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.180305
Average KL loss: 0.415446
Average total loss: 0.595751
tensor(-11.3338, device='cuda:0') tensor(3.5097, device='cuda:0') tensor(3.8423e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.180826
Average KL loss: 0.415261
Average total loss: 0.596087
tensor(-11.3380, device='cuda:0') tensor(3.5062, device='cuda:0') tensor(5.9987e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.184818
Average KL loss: 0.415093
Average total loss: 0.599910
tensor(-11.3422, device='cuda:0') tensor(3.5028, device='cuda:0') tensor(3.5706e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.181683
Average KL loss: 0.414937
Average total loss: 0.596620
tensor(-11.3463, device='cuda:0') tensor(3.4994, device='cuda:0') tensor(1.1640e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.182238
Average KL loss: 0.414804
Average total loss: 0.597042
tensor(-11.3505, device='cuda:0') tensor(3.4962, device='cuda:0') tensor(4.9000e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.182477
Average KL loss: 0.414638
Average total loss: 0.597115
tensor(-11.3546, device='cuda:0') tensor(3.4929, device='cuda:0') tensor(2.9527e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.179250
Average KL loss: 0.414454
Average total loss: 0.593704
tensor(-11.3586, device='cuda:0') tensor(3.4897, device='cuda:0') tensor(1.4390e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.180020
Average KL loss: 0.414280
Average total loss: 0.594301
tensor(-11.3626, device='cuda:0') tensor(3.4867, device='cuda:0') tensor(3.7429e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.182107
Average KL loss: 0.414117
Average total loss: 0.596224
tensor(-11.3666, device='cuda:0') tensor(3.4837, device='cuda:0') tensor(4.1493e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.178631
Average KL loss: 0.413968
Average total loss: 0.592599
tensor(-11.3706, device='cuda:0') tensor(3.4810, device='cuda:0') tensor(2.8657e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.178807
Average KL loss: 0.413793
Average total loss: 0.592600
tensor(-11.3746, device='cuda:0') tensor(3.4781, device='cuda:0') tensor(4.9384e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.179094
Average KL loss: 0.413609
Average total loss: 0.592703
tensor(-11.3785, device='cuda:0') tensor(3.4752, device='cuda:0') tensor(5.7285e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.181426
Average KL loss: 0.413458
Average total loss: 0.594884
tensor(-11.3824, device='cuda:0') tensor(3.4726, device='cuda:0') tensor(8.8574e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.178831
Average KL loss: 0.413264
Average total loss: 0.592094
tensor(-11.3862, device='cuda:0') tensor(3.4698, device='cuda:0') tensor(6.6589e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.176088
Average KL loss: 0.413079
Average total loss: 0.589167
tensor(-11.3901, device='cuda:0') tensor(3.4671, device='cuda:0') tensor(4.3181e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.175533
Average KL loss: 0.412913
Average total loss: 0.588445
tensor(-11.3939, device='cuda:0') tensor(3.4646, device='cuda:0') tensor(3.1696e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.176801
Average KL loss: 0.412738
Average total loss: 0.589539
tensor(-11.3977, device='cuda:0') tensor(3.4621, device='cuda:0') tensor(1.9108e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.176171
Average KL loss: 0.412563
Average total loss: 0.588734
tensor(-11.4015, device='cuda:0') tensor(3.4596, device='cuda:0') tensor(4.5444e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.175945
Average KL loss: 0.412415
Average total loss: 0.588360
tensor(-11.4052, device='cuda:0') tensor(3.4572, device='cuda:0') tensor(2.7454e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.174509
Average KL loss: 0.412261
Average total loss: 0.586770
tensor(-11.4090, device='cuda:0') tensor(3.4548, device='cuda:0') tensor(4.8401e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.173847
Average KL loss: 0.412080
Average total loss: 0.585926
tensor(-11.4127, device='cuda:0') tensor(3.4525, device='cuda:0') tensor(1.9804e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.172859
Average KL loss: 0.411925
Average total loss: 0.584784
tensor(-11.4163, device='cuda:0') tensor(3.4501, device='cuda:0') tensor(4.6562e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.175889
Average KL loss: 0.411770
Average total loss: 0.587660
tensor(-11.4200, device='cuda:0') tensor(3.4478, device='cuda:0') tensor(4.3801e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.174986
Average KL loss: 0.411608
Average total loss: 0.586595
tensor(-11.4237, device='cuda:0') tensor(3.4456, device='cuda:0') tensor(3.5661e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.171099
Average KL loss: 0.411432
Average total loss: 0.582531
tensor(-11.4273, device='cuda:0') tensor(3.4434, device='cuda:0') tensor(3.6428e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.171308
Average KL loss: 0.411227
Average total loss: 0.582535
tensor(-11.4309, device='cuda:0') tensor(3.4411, device='cuda:0') tensor(7.8797e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.173369
Average KL loss: 0.411041
Average total loss: 0.584410
tensor(-11.4345, device='cuda:0') tensor(3.4390, device='cuda:0') tensor(5.3484e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.173562
Average KL loss: 0.410877
Average total loss: 0.584440
tensor(-11.4381, device='cuda:0') tensor(3.4370, device='cuda:0') tensor(1.4972e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.172201
Average KL loss: 0.410749
Average total loss: 0.582950
tensor(-11.4416, device='cuda:0') tensor(3.4350, device='cuda:0') tensor(3.6125e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.172512
Average KL loss: 0.410613
Average total loss: 0.583125
tensor(-11.4451, device='cuda:0') tensor(3.4330, device='cuda:0') tensor(6.9660e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.170115
Average KL loss: 0.410470
Average total loss: 0.580585
tensor(-11.4486, device='cuda:0') tensor(3.4310, device='cuda:0') tensor(3.4031e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.170546
Average KL loss: 0.410286
Average total loss: 0.580832
tensor(-11.4521, device='cuda:0') tensor(3.4290, device='cuda:0') tensor(2.4675e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.171861
Average KL loss: 0.410109
Average total loss: 0.581970
tensor(-11.4556, device='cuda:0') tensor(3.4271, device='cuda:0') tensor(7.2441e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.172095
Average KL loss: 0.409933
Average total loss: 0.582029
tensor(-11.4591, device='cuda:0') tensor(3.4252, device='cuda:0') tensor(3.6172e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.167753
Average KL loss: 0.409781
Average total loss: 0.577534
tensor(-11.4625, device='cuda:0') tensor(3.4233, device='cuda:0') tensor(5.8491e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.167520
Average KL loss: 0.409609
Average total loss: 0.577129
tensor(-11.4660, device='cuda:0') tensor(3.4213, device='cuda:0') tensor(2.4128e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.169828
Average KL loss: 0.409444
Average total loss: 0.579271
tensor(-11.4694, device='cuda:0') tensor(3.4195, device='cuda:0') tensor(5.6095e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.172577
Average KL loss: 0.409285
Average total loss: 0.581863
tensor(-11.4728, device='cuda:0') tensor(3.4177, device='cuda:0') tensor(2.7442e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.168759
Average KL loss: 0.409131
Average total loss: 0.577890
tensor(-11.4762, device='cuda:0') tensor(3.4160, device='cuda:0') tensor(4.1061e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.167235
Average KL loss: 0.408988
Average total loss: 0.576223
tensor(-11.4796, device='cuda:0') tensor(3.4141, device='cuda:0') tensor(3.4445e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.166629
Average KL loss: 0.408819
Average total loss: 0.575448
tensor(-11.4829, device='cuda:0') tensor(3.4124, device='cuda:0') tensor(2.1596e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.164931
Average KL loss: 0.408686
Average total loss: 0.573616
tensor(-11.4863, device='cuda:0') tensor(3.4107, device='cuda:0') tensor(4.1256e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.163220
Average KL loss: 0.408528
Average total loss: 0.571748
tensor(-11.4896, device='cuda:0') tensor(3.4089, device='cuda:0') tensor(3.3619e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.168130
Average KL loss: 0.408358
Average total loss: 0.576488
tensor(-11.4929, device='cuda:0') tensor(3.4071, device='cuda:0') tensor(4.3082e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.164342
Average KL loss: 0.408210
Average total loss: 0.572553
tensor(-11.4962, device='cuda:0') tensor(3.4055, device='cuda:0') tensor(5.8466e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.163967
Average KL loss: 0.408046
Average total loss: 0.572012
tensor(-11.4995, device='cuda:0') tensor(3.4038, device='cuda:0') tensor(4.7761e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.166368
Average KL loss: 0.407894
Average total loss: 0.574262
tensor(-11.5028, device='cuda:0') tensor(3.4021, device='cuda:0') tensor(7.9691e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.166819
Average KL loss: 0.407757
Average total loss: 0.574576
tensor(-11.5060, device='cuda:0') tensor(3.4004, device='cuda:0') tensor(2.2951e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.164170
Average KL loss: 0.407614
Average total loss: 0.571784
tensor(-11.5093, device='cuda:0') tensor(3.3988, device='cuda:0') tensor(2.9828e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.162267
Average KL loss: 0.407474
Average total loss: 0.569741
tensor(-11.5125, device='cuda:0') tensor(3.3972, device='cuda:0') tensor(5.5873e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.160067
Average KL loss: 0.407318
Average total loss: 0.567385
tensor(-11.5157, device='cuda:0') tensor(3.3955, device='cuda:0') tensor(4.5265e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.161619
Average KL loss: 0.407173
Average total loss: 0.568792
tensor(-11.5189, device='cuda:0') tensor(3.3939, device='cuda:0') tensor(3.6774e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.162397
Average KL loss: 0.406989
Average total loss: 0.569387
tensor(-11.5221, device='cuda:0') tensor(3.3922, device='cuda:0') tensor(1.7145e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.165629
Average KL loss: 0.406813
Average total loss: 0.572442
tensor(-11.5253, device='cuda:0') tensor(3.3906, device='cuda:0') tensor(9.7977e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.162887
Average KL loss: 0.406651
Average total loss: 0.569538
tensor(-11.5285, device='cuda:0') tensor(3.3890, device='cuda:0') tensor(2.6480e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.160345
Average KL loss: 0.406501
Average total loss: 0.566845
tensor(-11.5317, device='cuda:0') tensor(3.3875, device='cuda:0') tensor(3.5375e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.162614
Average KL loss: 0.406364
Average total loss: 0.568978
tensor(-11.5348, device='cuda:0') tensor(3.3859, device='cuda:0') tensor(5.2394e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.160379
Average KL loss: 0.406226
Average total loss: 0.566604
tensor(-11.5380, device='cuda:0') tensor(3.3843, device='cuda:0') tensor(3.2731e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.160476
Average KL loss: 0.406088
Average total loss: 0.566564
tensor(-11.5411, device='cuda:0') tensor(3.3828, device='cuda:0') tensor(3.5754e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.160865
Average KL loss: 0.405946
Average total loss: 0.566811
tensor(-11.5442, device='cuda:0') tensor(3.3812, device='cuda:0') tensor(1.9191e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.159346
Average KL loss: 0.405785
Average total loss: 0.565131
tensor(-11.5473, device='cuda:0') tensor(3.3797, device='cuda:0') tensor(6.0260e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.158059
Average KL loss: 0.405626
Average total loss: 0.563686
tensor(-11.5504, device='cuda:0') tensor(3.3781, device='cuda:0') tensor(4.2917e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.162390
Average KL loss: 0.405457
Average total loss: 0.567847
tensor(-11.5535, device='cuda:0') tensor(3.3767, device='cuda:0') tensor(3.0195e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.157272
Average KL loss: 0.405301
Average total loss: 0.562573
tensor(-11.5566, device='cuda:0') tensor(3.3752, device='cuda:0') tensor(5.4267e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.158553
Average KL loss: 0.405123
Average total loss: 0.563676
tensor(-11.5596, device='cuda:0') tensor(3.3738, device='cuda:0') tensor(1.9144e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.157122
Average KL loss: 0.404992
Average total loss: 0.562113
tensor(-11.5627, device='cuda:0') tensor(3.3723, device='cuda:0') tensor(1.9844e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.155723
Average KL loss: 0.404858
Average total loss: 0.560582
tensor(-11.5657, device='cuda:0') tensor(3.3709, device='cuda:0') tensor(1.8058e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.157457
Average KL loss: 0.404691
Average total loss: 0.562148
tensor(-11.5688, device='cuda:0') tensor(3.3693, device='cuda:0') tensor(4.4592e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.157547
Average KL loss: 0.404539
Average total loss: 0.562087
tensor(-11.5718, device='cuda:0') tensor(3.3678, device='cuda:0') tensor(3.9318e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.155587
Average KL loss: 0.404371
Average total loss: 0.559958
tensor(-11.5748, device='cuda:0') tensor(3.3664, device='cuda:0') tensor(4.5510e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.154770
Average KL loss: 0.404224
Average total loss: 0.558995
tensor(-11.5778, device='cuda:0') tensor(3.3649, device='cuda:0') tensor(2.6007e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.154991
Average KL loss: 0.404082
Average total loss: 0.559073
tensor(-11.5808, device='cuda:0') tensor(3.3636, device='cuda:0') tensor(1.2983e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.155240
Average KL loss: 0.403939
Average total loss: 0.559179
tensor(-11.5838, device='cuda:0') tensor(3.3620, device='cuda:0') tensor(9.3321e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.152968
Average KL loss: 0.403760
Average total loss: 0.556729
tensor(-11.5868, device='cuda:0') tensor(3.3605, device='cuda:0') tensor(4.2168e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.155990
Average KL loss: 0.403623
Average total loss: 0.559613
tensor(-11.5897, device='cuda:0') tensor(3.3591, device='cuda:0') tensor(3.5459e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.152741
Average KL loss: 0.403479
Average total loss: 0.556220
tensor(-11.5927, device='cuda:0') tensor(3.3577, device='cuda:0') tensor(6.1363e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.151914
Average KL loss: 0.403318
Average total loss: 0.555232
tensor(-11.5956, device='cuda:0') tensor(3.3563, device='cuda:0') tensor(1.2235e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.152221
Average KL loss: 0.403185
Average total loss: 0.555406
tensor(-11.5986, device='cuda:0') tensor(3.3548, device='cuda:0') tensor(3.0449e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.150746
Average KL loss: 0.403037
Average total loss: 0.553783
tensor(-11.6015, device='cuda:0') tensor(3.3534, device='cuda:0') tensor(5.5255e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.154805
Average KL loss: 0.402867
Average total loss: 0.557672
tensor(-11.6045, device='cuda:0') tensor(3.3520, device='cuda:0') tensor(3.1158e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.151621
Average KL loss: 0.402696
Average total loss: 0.554316
tensor(-11.6074, device='cuda:0') tensor(3.3505, device='cuda:0') tensor(6.7881e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.151542
Average KL loss: 0.402560
Average total loss: 0.554102
tensor(-11.6103, device='cuda:0') tensor(3.3491, device='cuda:0') tensor(3.1184e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.149415
Average KL loss: 0.402425
Average total loss: 0.551839
tensor(-11.6132, device='cuda:0') tensor(3.3477, device='cuda:0') tensor(5.5074e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.153190
Average KL loss: 0.402292
Average total loss: 0.555482
tensor(-11.6161, device='cuda:0') tensor(3.3463, device='cuda:0') tensor(2.7485e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.148594
Average KL loss: 0.402180
Average total loss: 0.550774
tensor(-11.6189, device='cuda:0') tensor(3.3449, device='cuda:0') tensor(2.9538e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.149998
Average KL loss: 0.401996
Average total loss: 0.551994
tensor(-11.6218, device='cuda:0') tensor(3.3434, device='cuda:0') tensor(4.8263e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.148882
Average KL loss: 0.401826
Average total loss: 0.550708
tensor(-11.6247, device='cuda:0') tensor(3.3420, device='cuda:0') tensor(4.3472e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.149119
Average KL loss: 0.401666
Average total loss: 0.550785
tensor(-11.6275, device='cuda:0') tensor(3.3406, device='cuda:0') tensor(1.3902e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.147542
Average KL loss: 0.401536
Average total loss: 0.549077
tensor(-11.6304, device='cuda:0') tensor(3.3393, device='cuda:0') tensor(2.9041e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.152058
Average KL loss: 0.401404
Average total loss: 0.553462
tensor(-11.6332, device='cuda:0') tensor(3.3379, device='cuda:0') tensor(3.9772e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.149955
Average KL loss: 0.401237
Average total loss: 0.551192
tensor(-11.6361, device='cuda:0') tensor(3.3364, device='cuda:0') tensor(3.1383e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.150962
Average KL loss: 0.401079
Average total loss: 0.552041
tensor(-11.6389, device='cuda:0') tensor(3.3350, device='cuda:0') tensor(1.5489e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.148297
Average KL loss: 0.400931
Average total loss: 0.549228
tensor(-11.6417, device='cuda:0') tensor(3.3336, device='cuda:0') tensor(2.7790e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.149252
Average KL loss: 0.400789
Average total loss: 0.550042
tensor(-11.6445, device='cuda:0') tensor(3.3322, device='cuda:0') tensor(3.4721e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.147702
Average KL loss: 0.400643
Average total loss: 0.548345
tensor(-11.6473, device='cuda:0') tensor(3.3308, device='cuda:0') tensor(4.5361e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.151582
Average KL loss: 0.400507
Average total loss: 0.552089
tensor(-11.6501, device='cuda:0') tensor(3.3294, device='cuda:0') tensor(1.9656e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.146227
Average KL loss: 0.400380
Average total loss: 0.546607
tensor(-11.6529, device='cuda:0') tensor(3.3280, device='cuda:0') tensor(5.9191e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.145361
Average KL loss: 0.400266
Average total loss: 0.545627
tensor(-11.6557, device='cuda:0') tensor(3.3267, device='cuda:0') tensor(2.5541e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.146037
Average KL loss: 0.400120
Average total loss: 0.546157
tensor(-11.6585, device='cuda:0') tensor(3.3254, device='cuda:0') tensor(3.3193e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.143844
Average KL loss: 0.399974
Average total loss: 0.543818
tensor(-11.6612, device='cuda:0') tensor(3.3240, device='cuda:0') tensor(3.1320e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.146955
Average KL loss: 0.399824
Average total loss: 0.546779
tensor(-11.6640, device='cuda:0') tensor(3.3227, device='cuda:0') tensor(3.8345e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.143057
Average KL loss: 0.399670
Average total loss: 0.542727
tensor(-11.6668, device='cuda:0') tensor(3.3213, device='cuda:0') tensor(3.8152e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.144925
Average KL loss: 0.399509
Average total loss: 0.544433
tensor(-11.6695, device='cuda:0') tensor(3.3199, device='cuda:0') tensor(2.6174e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.143004
Average KL loss: 0.399370
Average total loss: 0.542374
tensor(-11.6722, device='cuda:0') tensor(3.3185, device='cuda:0') tensor(2.5371e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.143105
Average KL loss: 0.399233
Average total loss: 0.542338
tensor(-11.6750, device='cuda:0') tensor(3.3170, device='cuda:0') tensor(2.5032e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.144030
Average KL loss: 0.399085
Average total loss: 0.543116
tensor(-11.6777, device='cuda:0') tensor(3.3156, device='cuda:0') tensor(4.3478e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.143250
Average KL loss: 0.398942
Average total loss: 0.542192
tensor(-11.6804, device='cuda:0') tensor(3.3141, device='cuda:0') tensor(2.8204e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.142911
Average KL loss: 0.398787
Average total loss: 0.541699
tensor(-11.6832, device='cuda:0') tensor(3.3128, device='cuda:0') tensor(4.0291e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.143242
Average KL loss: 0.398639
Average total loss: 0.541881
tensor(-11.6859, device='cuda:0') tensor(3.3114, device='cuda:0') tensor(3.0056e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.140888
Average KL loss: 0.398504
Average total loss: 0.539392
tensor(-11.6886, device='cuda:0') tensor(3.3100, device='cuda:0') tensor(6.1151e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.141715
Average KL loss: 0.398383
Average total loss: 0.540098
tensor(-11.6913, device='cuda:0') tensor(3.3087, device='cuda:0') tensor(4.8571e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.140307
Average KL loss: 0.398221
Average total loss: 0.538528
tensor(-11.6940, device='cuda:0') tensor(3.3073, device='cuda:0') tensor(2.9865e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.144095
Average KL loss: 0.398101
Average total loss: 0.542196
tensor(-11.6967, device='cuda:0') tensor(3.3058, device='cuda:0') tensor(2.4330e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.141355
Average KL loss: 0.397990
Average total loss: 0.539345
tensor(-11.6993, device='cuda:0') tensor(3.3044, device='cuda:0') tensor(4.4824e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.139240
Average KL loss: 0.397854
Average total loss: 0.537094
tensor(-11.7020, device='cuda:0') tensor(3.3030, device='cuda:0') tensor(3.5777e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.141827
Average KL loss: 0.397711
Average total loss: 0.539538
tensor(-11.7047, device='cuda:0') tensor(3.3016, device='cuda:0') tensor(4.0415e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.139103
Average KL loss: 0.397580
Average total loss: 0.536684
tensor(-11.7073, device='cuda:0') tensor(3.3002, device='cuda:0') tensor(5.3442e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.142468
Average KL loss: 0.397458
Average total loss: 0.539926
tensor(-11.7100, device='cuda:0') tensor(3.2988, device='cuda:0') tensor(-2.5896e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.141850
Average KL loss: 0.397323
Average total loss: 0.539172
tensor(-11.7126, device='cuda:0') tensor(3.2974, device='cuda:0') tensor(3.6373e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.141722
Average KL loss: 0.397187
Average total loss: 0.538909
tensor(-11.7153, device='cuda:0') tensor(3.2960, device='cuda:0') tensor(2.4011e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.140169
Average KL loss: 0.397074
Average total loss: 0.537243
tensor(-11.7179, device='cuda:0') tensor(3.2946, device='cuda:0') tensor(5.4927e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.137022
Average KL loss: 0.396934
Average total loss: 0.533956
tensor(-11.7206, device='cuda:0') tensor(3.2931, device='cuda:0') tensor(2.0970e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.137833
Average KL loss: 0.396776
Average total loss: 0.534609
tensor(-11.7232, device='cuda:0') tensor(3.2916, device='cuda:0') tensor(4.4282e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.140294
Average KL loss: 0.396649
Average total loss: 0.536943
tensor(-11.7258, device='cuda:0') tensor(3.2902, device='cuda:0') tensor(6.0551e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.138525
Average KL loss: 0.396523
Average total loss: 0.535048
tensor(-11.7284, device='cuda:0') tensor(3.2888, device='cuda:0') tensor(2.0268e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.139119
Average KL loss: 0.396369
Average total loss: 0.535488
tensor(-11.7310, device='cuda:0') tensor(3.2873, device='cuda:0') tensor(4.1358e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.138528
Average KL loss: 0.396203
Average total loss: 0.534732
tensor(-11.7336, device='cuda:0') tensor(3.2859, device='cuda:0') tensor(2.6876e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.138965
Average KL loss: 0.396068
Average total loss: 0.535032
tensor(-11.7362, device='cuda:0') tensor(3.2845, device='cuda:0') tensor(3.1321e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.137383
Average KL loss: 0.395938
Average total loss: 0.533321
tensor(-11.7388, device='cuda:0') tensor(3.2831, device='cuda:0') tensor(3.9975e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.135371
Average KL loss: 0.395801
Average total loss: 0.531172
tensor(-11.7414, device='cuda:0') tensor(3.2816, device='cuda:0') tensor(2.0732e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.136938
Average KL loss: 0.395647
Average total loss: 0.532585
tensor(-11.7440, device='cuda:0') tensor(3.2803, device='cuda:0') tensor(2.7125e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.136524
Average KL loss: 0.395507
Average total loss: 0.532031
tensor(-11.7466, device='cuda:0') tensor(3.2789, device='cuda:0') tensor(-3.0610e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.135176
Average KL loss: 0.395387
Average total loss: 0.530563
tensor(-11.7491, device='cuda:0') tensor(3.2775, device='cuda:0') tensor(1.8856e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.135795
Average KL loss: 0.395250
Average total loss: 0.531046
tensor(-11.7517, device='cuda:0') tensor(3.2761, device='cuda:0') tensor(6.2382e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.136970
Average KL loss: 0.395153
Average total loss: 0.532124
tensor(-11.7543, device='cuda:0') tensor(3.2747, device='cuda:0') tensor(5.7225e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.135815
Average KL loss: 0.395026
Average total loss: 0.530842
tensor(-11.7568, device='cuda:0') tensor(3.2733, device='cuda:0') tensor(3.6881e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.132869
Average KL loss: 0.394866
Average total loss: 0.527735
tensor(-11.7594, device='cuda:0') tensor(3.2717, device='cuda:0') tensor(4.5931e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.136383
Average KL loss: 0.394708
Average total loss: 0.531091
tensor(-11.7619, device='cuda:0') tensor(3.2702, device='cuda:0') tensor(3.0941e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.132646
Average KL loss: 0.394571
Average total loss: 0.527217
tensor(-11.7645, device='cuda:0') tensor(3.2688, device='cuda:0') tensor(3.3505e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.132717
Average KL loss: 0.394438
Average total loss: 0.527154
tensor(-11.7670, device='cuda:0') tensor(3.2674, device='cuda:0') tensor(1.5000e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.131233
Average KL loss: 0.394293
Average total loss: 0.525527
tensor(-11.7695, device='cuda:0') tensor(3.2658, device='cuda:0') tensor(2.1637e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.135180
Average KL loss: 0.394145
Average total loss: 0.529325
tensor(-11.7721, device='cuda:0') tensor(3.2644, device='cuda:0') tensor(3.8833e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.134130
Average KL loss: 0.394006
Average total loss: 0.528136
tensor(-11.7746, device='cuda:0') tensor(3.2630, device='cuda:0') tensor(2.3007e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.131599
Average KL loss: 0.393875
Average total loss: 0.525474
tensor(-11.7771, device='cuda:0') tensor(3.2616, device='cuda:0') tensor(4.3108e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.133702
Average KL loss: 0.393749
Average total loss: 0.527451
tensor(-11.7796, device='cuda:0') tensor(3.2600, device='cuda:0') tensor(2.0514e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.129216
Average KL loss: 0.393611
Average total loss: 0.522827
tensor(-11.7821, device='cuda:0') tensor(3.2586, device='cuda:0') tensor(4.5150e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.133916
Average KL loss: 0.393470
Average total loss: 0.527386
tensor(-11.7846, device='cuda:0') tensor(3.2572, device='cuda:0') tensor(3.6697e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.131233
Average KL loss: 0.393354
Average total loss: 0.524586
tensor(-11.7871, device='cuda:0') tensor(3.2558, device='cuda:0') tensor(3.6623e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.134536
Average KL loss: 0.393247
Average total loss: 0.527783
tensor(-11.7896, device='cuda:0') tensor(3.2543, device='cuda:0') tensor(1.9734e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.134775
Average KL loss: 0.393103
Average total loss: 0.527878
 Percentile value: -12.155950546264648
Non-zero model percentage: 40.96000671386719%, Non-zero mask percentage: 40.96000671386719%

--- Pruning Level [4/24]: ---
conv1.weight         | nonzeros =    1706 /    1728             ( 98.73%) | total_pruned =      22 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   30410 /   36864             ( 82.49%) | total_pruned =    6454 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   30934 /   36864             ( 83.91%) | total_pruned =    5930 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   30004 /   36864             ( 81.39%) | total_pruned =    6860 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   29629 /   36864             ( 80.37%) | total_pruned =    7235 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   59458 /   73728             ( 80.65%) | total_pruned =   14270 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  113049 /  147456             ( 76.67%) | total_pruned =   34407 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7544 /    8192             ( 92.09%) | total_pruned =     648 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  104781 /  147456             ( 71.06%) | total_pruned =   42675 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  105082 /  147456             ( 71.26%) | total_pruned =   42374 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  214386 /  294912             ( 72.69%) | total_pruned =   80526 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  399450 /  589824             ( 67.72%) | total_pruned =  190374 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   27974 /   32768             ( 85.37%) | total_pruned =    4794 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  301567 /  589824             ( 51.13%) | total_pruned =  288257 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     237 /     256             ( 92.58%) | total_pruned =      19 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  298582 /  589824             ( 50.62%) | total_pruned =  291242 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  638095 / 1179648             ( 54.09%) | total_pruned =  541553 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  938527 / 2359296             ( 39.78%) | total_pruned = 1420769 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   83378 /  131072             ( 63.61%) | total_pruned =   47694 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  558834 / 2359296             ( 23.69%) | total_pruned = 1800462 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     466 /     512             ( 91.02%) | total_pruned =      46 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     328 /     512             ( 64.06%) | total_pruned =     184 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  591051 / 2359296             ( 25.05%) | total_pruned = 1768245 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
linear.weight        | nonzeros =    5049 /    5120             ( 98.61%) | total_pruned =      71 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       9 /      10             ( 90.00%) | total_pruned =       1 | shape = torch.Size([10])
alive: 4578822, pruned : 6599940, total: 11178762, Compression rate :       2.44x  ( 59.04% pruned)
Train Epoch: 22/100 Loss: 0.000004 Accuracy: 86.88 100.00 % Best test Accuracy: 86.90%
tensor(-11.7921, device='cuda:0') tensor(3.2528, device='cuda:0') tensor(3.4987e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.171056
Average KL loss: 0.389157
Average total loss: 0.560213
tensor(-11.8074, device='cuda:0') tensor(3.1079, device='cuda:0') tensor(-1.9198e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.167755
Average KL loss: 0.386294
Average total loss: 0.554048
tensor(-11.8182, device='cuda:0') tensor(3.0264, device='cuda:0') tensor(2.2053e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.164353
Average KL loss: 0.385145
Average total loss: 0.549499
tensor(-11.8270, device='cuda:0') tensor(2.9693, device='cuda:0') tensor(5.4478e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.157398
Average KL loss: 0.384488
Average total loss: 0.541886
tensor(-11.8347, device='cuda:0') tensor(2.9257, device='cuda:0') tensor(-4.2157e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.158510
Average KL loss: 0.384039
Average total loss: 0.542550
tensor(-11.8415, device='cuda:0') tensor(2.8905, device='cuda:0') tensor(1.6542e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.159849
Average KL loss: 0.383713
Average total loss: 0.543562
tensor(-11.8478, device='cuda:0') tensor(2.8612, device='cuda:0') tensor(3.8785e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.155452
Average KL loss: 0.383483
Average total loss: 0.538936
tensor(-11.8536, device='cuda:0') tensor(2.8362, device='cuda:0') tensor(1.3121e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.155763
Average KL loss: 0.383267
Average total loss: 0.539031
tensor(-11.8591, device='cuda:0') tensor(2.8142, device='cuda:0') tensor(3.0712e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.155481
Average KL loss: 0.383056
Average total loss: 0.538537
tensor(-11.8644, device='cuda:0') tensor(2.7947, device='cuda:0') tensor(-3.7076e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.155472
Average KL loss: 0.382904
Average total loss: 0.538376
tensor(-11.8693, device='cuda:0') tensor(2.7774, device='cuda:0') tensor(2.4607e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.152355
Average KL loss: 0.382792
Average total loss: 0.535147
tensor(-11.8741, device='cuda:0') tensor(2.7617, device='cuda:0') tensor(1.5996e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.155268
Average KL loss: 0.382680
Average total loss: 0.537948
tensor(-11.8787, device='cuda:0') tensor(2.7474, device='cuda:0') tensor(1.0928e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.150531
Average KL loss: 0.382579
Average total loss: 0.533109
tensor(-11.8832, device='cuda:0') tensor(2.7343, device='cuda:0') tensor(-4.1687e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.150492
Average KL loss: 0.382482
Average total loss: 0.532975
tensor(-11.8875, device='cuda:0') tensor(2.7223, device='cuda:0') tensor(1.9142e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.148260
Average KL loss: 0.382388
Average total loss: 0.530648
tensor(-11.8917, device='cuda:0') tensor(2.7110, device='cuda:0') tensor(1.1267e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.152204
Average KL loss: 0.382288
Average total loss: 0.534492
tensor(-11.8958, device='cuda:0') tensor(2.7006, device='cuda:0') tensor(2.5682e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.150192
Average KL loss: 0.382219
Average total loss: 0.532410
tensor(-11.8997, device='cuda:0') tensor(2.6910, device='cuda:0') tensor(-4.1530e-11, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.146131
Average KL loss: 0.382144
Average total loss: 0.528275
tensor(-11.9036, device='cuda:0') tensor(2.6819, device='cuda:0') tensor(2.1457e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.145649
Average KL loss: 0.382060
Average total loss: 0.527709
tensor(-11.9075, device='cuda:0') tensor(2.6733, device='cuda:0') tensor(1.3455e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.144343
Average KL loss: 0.381978
Average total loss: 0.526321
tensor(-11.9112, device='cuda:0') tensor(2.6652, device='cuda:0') tensor(1.5040e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.146324
Average KL loss: 0.381900
Average total loss: 0.528223
tensor(-11.9149, device='cuda:0') tensor(2.6575, device='cuda:0') tensor(2.4264e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.144718
Average KL loss: 0.381826
Average total loss: 0.526544
tensor(-11.9185, device='cuda:0') tensor(2.6503, device='cuda:0') tensor(1.3128e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.144384
Average KL loss: 0.381753
Average total loss: 0.526136
tensor(-11.9221, device='cuda:0') tensor(2.6435, device='cuda:0') tensor(1.8278e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.141696
Average KL loss: 0.381664
Average total loss: 0.523360
tensor(-11.9256, device='cuda:0') tensor(2.6369, device='cuda:0') tensor(1.3702e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.142198
Average KL loss: 0.381578
Average total loss: 0.523776
tensor(-11.9290, device='cuda:0') tensor(2.6305, device='cuda:0') tensor(1.6241e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.146211
Average KL loss: 0.381492
Average total loss: 0.527703
tensor(-11.9325, device='cuda:0') tensor(2.6246, device='cuda:0') tensor(1.3052e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.140264
Average KL loss: 0.381427
Average total loss: 0.521692
tensor(-11.9358, device='cuda:0') tensor(2.6189, device='cuda:0') tensor(2.1096e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.142863
Average KL loss: 0.381368
Average total loss: 0.524230
tensor(-11.9391, device='cuda:0') tensor(2.6135, device='cuda:0') tensor(1.7963e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.142355
Average KL loss: 0.381293
Average total loss: 0.523648
tensor(-11.9424, device='cuda:0') tensor(2.6082, device='cuda:0') tensor(1.8889e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.142642
Average KL loss: 0.381221
Average total loss: 0.523863
tensor(-11.9456, device='cuda:0') tensor(2.6032, device='cuda:0') tensor(1.2007e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.140457
Average KL loss: 0.381170
Average total loss: 0.521627
tensor(-11.9488, device='cuda:0') tensor(2.5986, device='cuda:0') tensor(2.5208e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.139940
Average KL loss: 0.381133
Average total loss: 0.521073
tensor(-11.9520, device='cuda:0') tensor(2.5941, device='cuda:0') tensor(2.3168e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.138264
Average KL loss: 0.381064
Average total loss: 0.519327
tensor(-11.9551, device='cuda:0') tensor(2.5896, device='cuda:0') tensor(2.7944e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.139461
Average KL loss: 0.380977
Average total loss: 0.520438
tensor(-11.9582, device='cuda:0') tensor(2.5853, device='cuda:0') tensor(2.3047e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.137557
Average KL loss: 0.380900
Average total loss: 0.518457
tensor(-11.9613, device='cuda:0') tensor(2.5812, device='cuda:0') tensor(2.8281e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.139460
Average KL loss: 0.380830
Average total loss: 0.520290
tensor(-11.9643, device='cuda:0') tensor(2.5772, device='cuda:0') tensor(1.9781e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.140109
Average KL loss: 0.380786
Average total loss: 0.520895
tensor(-11.9674, device='cuda:0') tensor(2.5734, device='cuda:0') tensor(2.2558e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.137125
Average KL loss: 0.380738
Average total loss: 0.517863
tensor(-11.9703, device='cuda:0') tensor(2.5696, device='cuda:0') tensor(2.2220e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.135912
Average KL loss: 0.380676
Average total loss: 0.516589
tensor(-11.9733, device='cuda:0') tensor(2.5660, device='cuda:0') tensor(1.7692e-11, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.135625
Average KL loss: 0.380609
Average total loss: 0.516233
tensor(-11.9762, device='cuda:0') tensor(2.5625, device='cuda:0') tensor(4.4107e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.138607
Average KL loss: 0.380528
Average total loss: 0.519135
tensor(-11.9792, device='cuda:0') tensor(2.5590, device='cuda:0') tensor(-3.0369e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.133586
Average KL loss: 0.380475
Average total loss: 0.514062
tensor(-11.9820, device='cuda:0') tensor(2.5557, device='cuda:0') tensor(1.9158e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.133316
Average KL loss: 0.380407
Average total loss: 0.513723
tensor(-11.9849, device='cuda:0') tensor(2.5525, device='cuda:0') tensor(2.8827e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.135539
Average KL loss: 0.380336
Average total loss: 0.515875
tensor(-11.9878, device='cuda:0') tensor(2.5493, device='cuda:0') tensor(3.9672e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.132368
Average KL loss: 0.380256
Average total loss: 0.512624
tensor(-11.9906, device='cuda:0') tensor(2.5462, device='cuda:0') tensor(2.4992e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.131897
Average KL loss: 0.380187
Average total loss: 0.512084
tensor(-11.9934, device='cuda:0') tensor(2.5433, device='cuda:0') tensor(3.3739e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.132608
Average KL loss: 0.380128
Average total loss: 0.512736
tensor(-11.9962, device='cuda:0') tensor(2.5404, device='cuda:0') tensor(8.1188e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.132195
Average KL loss: 0.380055
Average total loss: 0.512250
tensor(-11.9990, device='cuda:0') tensor(2.5376, device='cuda:0') tensor(3.7358e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.129831
Average KL loss: 0.379974
Average total loss: 0.509805
tensor(-12.0017, device='cuda:0') tensor(2.5347, device='cuda:0') tensor(1.5214e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.134446
Average KL loss: 0.379893
Average total loss: 0.514339
tensor(-12.0044, device='cuda:0') tensor(2.5321, device='cuda:0') tensor(1.3437e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.134243
Average KL loss: 0.379822
Average total loss: 0.514065
tensor(-12.0072, device='cuda:0') tensor(2.5295, device='cuda:0') tensor(1.3572e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.133757
Average KL loss: 0.379742
Average total loss: 0.513499
tensor(-12.0099, device='cuda:0') tensor(2.5269, device='cuda:0') tensor(4.2283e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.130517
Average KL loss: 0.379687
Average total loss: 0.510204
tensor(-12.0125, device='cuda:0') tensor(2.5245, device='cuda:0') tensor(4.4303e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.132847
Average KL loss: 0.379624
Average total loss: 0.512471
tensor(-12.0152, device='cuda:0') tensor(2.5220, device='cuda:0') tensor(9.0597e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.130445
Average KL loss: 0.379542
Average total loss: 0.509987
tensor(-12.0179, device='cuda:0') tensor(2.5197, device='cuda:0') tensor(2.9358e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.128984
Average KL loss: 0.379477
Average total loss: 0.508461
tensor(-12.0205, device='cuda:0') tensor(2.5174, device='cuda:0') tensor(3.3591e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.130003
Average KL loss: 0.379398
Average total loss: 0.509401
tensor(-12.0231, device='cuda:0') tensor(2.5151, device='cuda:0') tensor(4.0726e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.130507
Average KL loss: 0.379351
Average total loss: 0.509859
tensor(-12.0257, device='cuda:0') tensor(2.5129, device='cuda:0') tensor(-2.2316e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.129413
Average KL loss: 0.379317
Average total loss: 0.508731
tensor(-12.0283, device='cuda:0') tensor(2.5108, device='cuda:0') tensor(-6.7039e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.129019
Average KL loss: 0.379255
Average total loss: 0.508274
tensor(-12.0309, device='cuda:0') tensor(2.5087, device='cuda:0') tensor(1.1978e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.126846
Average KL loss: 0.379191
Average total loss: 0.506037
tensor(-12.0334, device='cuda:0') tensor(2.5067, device='cuda:0') tensor(-4.4527e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.127577
Average KL loss: 0.379129
Average total loss: 0.506706
tensor(-12.0360, device='cuda:0') tensor(2.5047, device='cuda:0') tensor(-3.1630e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.126984
Average KL loss: 0.379073
Average total loss: 0.506058
tensor(-12.0385, device='cuda:0') tensor(2.5028, device='cuda:0') tensor(3.0382e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.127023
Average KL loss: 0.379008
Average total loss: 0.506031
tensor(-12.0411, device='cuda:0') tensor(2.5007, device='cuda:0') tensor(2.7058e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.125739
Average KL loss: 0.378951
Average total loss: 0.504690
tensor(-12.0436, device='cuda:0') tensor(2.4989, device='cuda:0') tensor(2.8831e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.128462
Average KL loss: 0.378899
Average total loss: 0.507360
tensor(-12.0461, device='cuda:0') tensor(2.4970, device='cuda:0') tensor(1.9354e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.127914
Average KL loss: 0.378847
Average total loss: 0.506761
tensor(-12.0486, device='cuda:0') tensor(2.4951, device='cuda:0') tensor(4.0943e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.126565
Average KL loss: 0.378796
Average total loss: 0.505361
tensor(-12.0511, device='cuda:0') tensor(2.4933, device='cuda:0') tensor(8.3020e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.124517
Average KL loss: 0.378744
Average total loss: 0.503261
tensor(-12.0535, device='cuda:0') tensor(2.4915, device='cuda:0') tensor(-4.2652e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.124685
Average KL loss: 0.378679
Average total loss: 0.503364
tensor(-12.0560, device='cuda:0') tensor(2.4898, device='cuda:0') tensor(2.4875e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.125419
Average KL loss: 0.378615
Average total loss: 0.504034
tensor(-12.0584, device='cuda:0') tensor(2.4880, device='cuda:0') tensor(2.1611e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.123187
Average KL loss: 0.378547
Average total loss: 0.501734
tensor(-12.0609, device='cuda:0') tensor(2.4863, device='cuda:0') tensor(-1.3174e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.126125
Average KL loss: 0.378473
Average total loss: 0.504598
tensor(-12.0633, device='cuda:0') tensor(2.4845, device='cuda:0') tensor(3.0361e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.123238
Average KL loss: 0.378405
Average total loss: 0.501644
tensor(-12.0657, device='cuda:0') tensor(2.4830, device='cuda:0') tensor(1.6734e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.124972
Average KL loss: 0.378346
Average total loss: 0.503318
tensor(-12.0681, device='cuda:0') tensor(2.4814, device='cuda:0') tensor(2.1625e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.123864
Average KL loss: 0.378287
Average total loss: 0.502151
tensor(-12.0705, device='cuda:0') tensor(2.4798, device='cuda:0') tensor(-6.6743e-12, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.122484
Average KL loss: 0.378189
Average total loss: 0.500673
tensor(-12.0729, device='cuda:0') tensor(2.4782, device='cuda:0') tensor(-1.4519e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.122950
Average KL loss: 0.378116
Average total loss: 0.501065
tensor(-12.0753, device='cuda:0') tensor(2.4767, device='cuda:0') tensor(2.9761e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.123871
Average KL loss: 0.378045
Average total loss: 0.501915
tensor(-12.0777, device='cuda:0') tensor(2.4751, device='cuda:0') tensor(3.1518e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.121146
Average KL loss: 0.377978
Average total loss: 0.499124
tensor(-12.0800, device='cuda:0') tensor(2.4736, device='cuda:0') tensor(1.0551e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.121403
Average KL loss: 0.377908
Average total loss: 0.499311
tensor(-12.0824, device='cuda:0') tensor(2.4721, device='cuda:0') tensor(1.2029e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.120506
Average KL loss: 0.377839
Average total loss: 0.498345
tensor(-12.0847, device='cuda:0') tensor(2.4707, device='cuda:0') tensor(4.6646e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.122954
Average KL loss: 0.377776
Average total loss: 0.500729
tensor(-12.0871, device='cuda:0') tensor(2.4692, device='cuda:0') tensor(4.0842e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.122316
Average KL loss: 0.377708
Average total loss: 0.500024
tensor(-12.0894, device='cuda:0') tensor(2.4679, device='cuda:0') tensor(3.8390e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.118105
Average KL loss: 0.377652
Average total loss: 0.495756
tensor(-12.0917, device='cuda:0') tensor(2.4664, device='cuda:0') tensor(-3.4582e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.119726
Average KL loss: 0.377583
Average total loss: 0.497309
tensor(-12.0940, device='cuda:0') tensor(2.4650, device='cuda:0') tensor(5.0451e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.121019
Average KL loss: 0.377521
Average total loss: 0.498540
tensor(-12.0963, device='cuda:0') tensor(2.4636, device='cuda:0') tensor(2.0474e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.119608
Average KL loss: 0.377459
Average total loss: 0.497067
tensor(-12.0986, device='cuda:0') tensor(2.4623, device='cuda:0') tensor(2.3062e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.119135
Average KL loss: 0.377387
Average total loss: 0.496522
tensor(-12.1009, device='cuda:0') tensor(2.4609, device='cuda:0') tensor(1.5178e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.120647
Average KL loss: 0.377298
Average total loss: 0.497944
tensor(-12.1032, device='cuda:0') tensor(2.4596, device='cuda:0') tensor(-1.8228e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.117835
Average KL loss: 0.377229
Average total loss: 0.495064
tensor(-12.1054, device='cuda:0') tensor(2.4582, device='cuda:0') tensor(1.7115e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.117608
Average KL loss: 0.377155
Average total loss: 0.494763
tensor(-12.1077, device='cuda:0') tensor(2.4569, device='cuda:0') tensor(1.8052e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.118369
Average KL loss: 0.377085
Average total loss: 0.495454
tensor(-12.1100, device='cuda:0') tensor(2.4556, device='cuda:0') tensor(1.0051e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.120473
Average KL loss: 0.377043
Average total loss: 0.497516
tensor(-12.1122, device='cuda:0') tensor(2.4543, device='cuda:0') tensor(1.2058e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.117928
Average KL loss: 0.376998
Average total loss: 0.494926
tensor(-12.1145, device='cuda:0') tensor(2.4530, device='cuda:0') tensor(1.2728e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.119048
Average KL loss: 0.376930
Average total loss: 0.495977
tensor(-12.1167, device='cuda:0') tensor(2.4518, device='cuda:0') tensor(2.5184e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.118223
Average KL loss: 0.376846
Average total loss: 0.495068
tensor(-12.1189, device='cuda:0') tensor(2.4505, device='cuda:0') tensor(1.4902e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.116700
Average KL loss: 0.376780
Average total loss: 0.493480
tensor(-12.1211, device='cuda:0') tensor(2.4493, device='cuda:0') tensor(1.2380e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.118544
Average KL loss: 0.376711
Average total loss: 0.495255
tensor(-12.1234, device='cuda:0') tensor(2.4481, device='cuda:0') tensor(9.9023e-11, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.117769
Average KL loss: 0.376647
Average total loss: 0.494416
tensor(-12.1256, device='cuda:0') tensor(2.4469, device='cuda:0') tensor(1.3300e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.115810
Average KL loss: 0.376573
Average total loss: 0.492382
tensor(-12.1278, device='cuda:0') tensor(2.4456, device='cuda:0') tensor(1.8772e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.115899
Average KL loss: 0.376495
Average total loss: 0.492394
tensor(-12.1300, device='cuda:0') tensor(2.4445, device='cuda:0') tensor(9.7934e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.114108
Average KL loss: 0.376451
Average total loss: 0.490559
tensor(-12.1321, device='cuda:0') tensor(2.4434, device='cuda:0') tensor(7.1234e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.114317
Average KL loss: 0.376388
Average total loss: 0.490705
tensor(-12.1343, device='cuda:0') tensor(2.4422, device='cuda:0') tensor(-6.9325e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.115909
Average KL loss: 0.376311
Average total loss: 0.492221
tensor(-12.1365, device='cuda:0') tensor(2.4410, device='cuda:0') tensor(2.4105e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.115914
Average KL loss: 0.376249
Average total loss: 0.492163
tensor(-12.1387, device='cuda:0') tensor(2.4399, device='cuda:0') tensor(1.0698e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.115233
Average KL loss: 0.376192
Average total loss: 0.491425
tensor(-12.1408, device='cuda:0') tensor(2.4388, device='cuda:0') tensor(1.3484e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.115001
Average KL loss: 0.376122
Average total loss: 0.491123
tensor(-12.1430, device='cuda:0') tensor(2.4377, device='cuda:0') tensor(3.8915e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.114079
Average KL loss: 0.376055
Average total loss: 0.490134
tensor(-12.1451, device='cuda:0') tensor(2.4366, device='cuda:0') tensor(1.8288e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.113046
Average KL loss: 0.375993
Average total loss: 0.489039
tensor(-12.1473, device='cuda:0') tensor(2.4356, device='cuda:0') tensor(2.8094e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.112090
Average KL loss: 0.375918
Average total loss: 0.488008
tensor(-12.1494, device='cuda:0') tensor(2.4344, device='cuda:0') tensor(7.3120e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.114232
Average KL loss: 0.375852
Average total loss: 0.490083
tensor(-12.1515, device='cuda:0') tensor(2.4333, device='cuda:0') tensor(1.6226e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.112103
Average KL loss: 0.375811
Average total loss: 0.487913
tensor(-12.1536, device='cuda:0') tensor(2.4324, device='cuda:0') tensor(9.7609e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.113146
Average KL loss: 0.375766
Average total loss: 0.488912
tensor(-12.1558, device='cuda:0') tensor(2.4314, device='cuda:0') tensor(1.6203e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.112570
Average KL loss: 0.375716
Average total loss: 0.488286
tensor(-12.1579, device='cuda:0') tensor(2.4304, device='cuda:0') tensor(1.5130e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.112569
Average KL loss: 0.375660
Average total loss: 0.488229
tensor(-12.1600, device='cuda:0') tensor(2.4294, device='cuda:0') tensor(4.6046e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.114305
Average KL loss: 0.375612
Average total loss: 0.489917
tensor(-12.1621, device='cuda:0') tensor(2.4284, device='cuda:0') tensor(2.5956e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.112056
Average KL loss: 0.375545
Average total loss: 0.487601
tensor(-12.1642, device='cuda:0') tensor(2.4273, device='cuda:0') tensor(2.4266e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.109942
Average KL loss: 0.375470
Average total loss: 0.485411
tensor(-12.1663, device='cuda:0') tensor(2.4263, device='cuda:0') tensor(1.8852e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.111630
Average KL loss: 0.375395
Average total loss: 0.487025
tensor(-12.1683, device='cuda:0') tensor(2.4253, device='cuda:0') tensor(1.7510e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.111289
Average KL loss: 0.375331
Average total loss: 0.486620
tensor(-12.1704, device='cuda:0') tensor(2.4243, device='cuda:0') tensor(1.2599e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.111649
Average KL loss: 0.375244
Average total loss: 0.486892
tensor(-12.1725, device='cuda:0') tensor(2.4232, device='cuda:0') tensor(1.6018e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.109823
Average KL loss: 0.375174
Average total loss: 0.484997
tensor(-12.1746, device='cuda:0') tensor(2.4223, device='cuda:0') tensor(1.8151e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.112484
Average KL loss: 0.375132
Average total loss: 0.487617
tensor(-12.1766, device='cuda:0') tensor(2.4213, device='cuda:0') tensor(2.1552e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.109457
Average KL loss: 0.375075
Average total loss: 0.484532
tensor(-12.1787, device='cuda:0') tensor(2.4203, device='cuda:0') tensor(1.1034e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.111353
Average KL loss: 0.375002
Average total loss: 0.486355
tensor(-12.1808, device='cuda:0') tensor(2.4193, device='cuda:0') tensor(1.7582e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.108813
Average KL loss: 0.374912
Average total loss: 0.483725
tensor(-12.1828, device='cuda:0') tensor(2.4182, device='cuda:0') tensor(1.7258e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.108548
Average KL loss: 0.374836
Average total loss: 0.483384
tensor(-12.1849, device='cuda:0') tensor(2.4173, device='cuda:0') tensor(1.4324e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.108506
Average KL loss: 0.374786
Average total loss: 0.483293
tensor(-12.1869, device='cuda:0') tensor(2.4163, device='cuda:0') tensor(1.4359e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.109772
Average KL loss: 0.374744
Average total loss: 0.484516
tensor(-12.1889, device='cuda:0') tensor(2.4154, device='cuda:0') tensor(1.0208e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.109989
Average KL loss: 0.374696
Average total loss: 0.484685
tensor(-12.1910, device='cuda:0') tensor(2.4144, device='cuda:0') tensor(3.6481e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.109316
Average KL loss: 0.374630
Average total loss: 0.483945
tensor(-12.1930, device='cuda:0') tensor(2.4134, device='cuda:0') tensor(8.9829e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.107561
Average KL loss: 0.374576
Average total loss: 0.482137
tensor(-12.1950, device='cuda:0') tensor(2.4125, device='cuda:0') tensor(4.6300e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.110795
Average KL loss: 0.374523
Average total loss: 0.485318
tensor(-12.1970, device='cuda:0') tensor(2.4117, device='cuda:0') tensor(1.0073e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.110767
Average KL loss: 0.374468
Average total loss: 0.485235
tensor(-12.1990, device='cuda:0') tensor(2.4108, device='cuda:0') tensor(6.9540e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.107771
Average KL loss: 0.374431
Average total loss: 0.482202
tensor(-12.2010, device='cuda:0') tensor(2.4099, device='cuda:0') tensor(3.7650e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.105858
Average KL loss: 0.374379
Average total loss: 0.480237
tensor(-12.2030, device='cuda:0') tensor(2.4091, device='cuda:0') tensor(-8.3246e-11, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.107458
Average KL loss: 0.374326
Average total loss: 0.481784
tensor(-12.2050, device='cuda:0') tensor(2.4082, device='cuda:0') tensor(2.5522e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.107326
Average KL loss: 0.374271
Average total loss: 0.481597
tensor(-12.2070, device='cuda:0') tensor(2.4073, device='cuda:0') tensor(4.6151e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.105009
Average KL loss: 0.374208
Average total loss: 0.479217
tensor(-12.2090, device='cuda:0') tensor(2.4064, device='cuda:0') tensor(3.7279e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.106200
Average KL loss: 0.374156
Average total loss: 0.480356
tensor(-12.2110, device='cuda:0') tensor(2.4055, device='cuda:0') tensor(1.4668e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.103135
Average KL loss: 0.374095
Average total loss: 0.477230
tensor(-12.2130, device='cuda:0') tensor(2.4046, device='cuda:0') tensor(2.4944e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.105696
Average KL loss: 0.374031
Average total loss: 0.479727
tensor(-12.2150, device='cuda:0') tensor(2.4037, device='cuda:0') tensor(1.1538e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.105431
Average KL loss: 0.373966
Average total loss: 0.479397
tensor(-12.2169, device='cuda:0') tensor(2.4027, device='cuda:0') tensor(-3.8502e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.105727
Average KL loss: 0.373908
Average total loss: 0.479635
tensor(-12.2189, device='cuda:0') tensor(2.4019, device='cuda:0') tensor(2.9280e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.106086
Average KL loss: 0.373849
Average total loss: 0.479935
tensor(-12.2209, device='cuda:0') tensor(2.4009, device='cuda:0') tensor(1.4329e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.105190
Average KL loss: 0.373789
Average total loss: 0.478979
tensor(-12.2228, device='cuda:0') tensor(2.4000, device='cuda:0') tensor(1.2029e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.105330
Average KL loss: 0.373725
Average total loss: 0.479055
tensor(-12.2248, device='cuda:0') tensor(2.3991, device='cuda:0') tensor(1.3416e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.106740
Average KL loss: 0.373662
Average total loss: 0.480402
tensor(-12.2268, device='cuda:0') tensor(2.3982, device='cuda:0') tensor(3.4934e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.106249
Average KL loss: 0.373574
Average total loss: 0.479823
tensor(-12.2287, device='cuda:0') tensor(2.3973, device='cuda:0') tensor(1.5760e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.103633
Average KL loss: 0.373495
Average total loss: 0.477128
tensor(-12.2306, device='cuda:0') tensor(2.3963, device='cuda:0') tensor(1.4722e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.104677
Average KL loss: 0.373449
Average total loss: 0.478126
tensor(-12.2326, device='cuda:0') tensor(2.3955, device='cuda:0') tensor(-3.2379e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.102388
Average KL loss: 0.373399
Average total loss: 0.475787
tensor(-12.2345, device='cuda:0') tensor(2.3946, device='cuda:0') tensor(7.1404e-11, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.104423
Average KL loss: 0.373327
Average total loss: 0.477749
tensor(-12.2364, device='cuda:0') tensor(2.3937, device='cuda:0') tensor(2.5835e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.104039
Average KL loss: 0.373266
Average total loss: 0.477305
tensor(-12.2384, device='cuda:0') tensor(2.3929, device='cuda:0') tensor(1.4959e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.103302
Average KL loss: 0.373190
Average total loss: 0.476492
tensor(-12.2403, device='cuda:0') tensor(2.3920, device='cuda:0') tensor(7.5323e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.101325
Average KL loss: 0.373133
Average total loss: 0.474458
tensor(-12.2422, device='cuda:0') tensor(2.3912, device='cuda:0') tensor(1.0962e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.102599
Average KL loss: 0.373092
Average total loss: 0.475692
tensor(-12.2441, device='cuda:0') tensor(2.3903, device='cuda:0') tensor(1.3709e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.102185
Average KL loss: 0.373040
Average total loss: 0.475226
tensor(-12.2461, device='cuda:0') tensor(2.3894, device='cuda:0') tensor(2.2540e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.100456
Average KL loss: 0.372978
Average total loss: 0.473433
tensor(-12.2480, device='cuda:0') tensor(2.3886, device='cuda:0') tensor(-1.0572e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.100588
Average KL loss: 0.372912
Average total loss: 0.473500
tensor(-12.2499, device='cuda:0') tensor(2.3877, device='cuda:0') tensor(2.6493e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.102635
Average KL loss: 0.372849
Average total loss: 0.475483
tensor(-12.2518, device='cuda:0') tensor(2.3869, device='cuda:0') tensor(6.4854e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.101597
Average KL loss: 0.372780
Average total loss: 0.474377
tensor(-12.2537, device='cuda:0') tensor(2.3860, device='cuda:0') tensor(8.4997e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.102136
Average KL loss: 0.372725
Average total loss: 0.474861
tensor(-12.2556, device='cuda:0') tensor(2.3851, device='cuda:0') tensor(1.5812e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.100358
Average KL loss: 0.372668
Average total loss: 0.473027
tensor(-12.2575, device='cuda:0') tensor(2.3842, device='cuda:0') tensor(9.9796e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.099783
Average KL loss: 0.372622
Average total loss: 0.472405
tensor(-12.2593, device='cuda:0') tensor(2.3834, device='cuda:0') tensor(1.8404e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.102196
Average KL loss: 0.372564
Average total loss: 0.474760
tensor(-12.2612, device='cuda:0') tensor(2.3825, device='cuda:0') tensor(1.1407e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.099816
Average KL loss: 0.372501
Average total loss: 0.472318
tensor(-12.2631, device='cuda:0') tensor(2.3816, device='cuda:0') tensor(1.3073e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.099218
Average KL loss: 0.372428
Average total loss: 0.471646
tensor(-12.2650, device='cuda:0') tensor(2.3807, device='cuda:0') tensor(7.3288e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.101094
Average KL loss: 0.372363
Average total loss: 0.473457
tensor(-12.2669, device='cuda:0') tensor(2.3798, device='cuda:0') tensor(1.5664e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.100340
Average KL loss: 0.372281
Average total loss: 0.472622
tensor(-12.2688, device='cuda:0') tensor(2.3789, device='cuda:0') tensor(1.5484e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.100238
Average KL loss: 0.372204
Average total loss: 0.472442
tensor(-12.2706, device='cuda:0') tensor(2.3780, device='cuda:0') tensor(2.7693e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.098614
Average KL loss: 0.372147
Average total loss: 0.470762
tensor(-12.2725, device='cuda:0') tensor(2.3771, device='cuda:0') tensor(2.0916e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.101230
Average KL loss: 0.372092
Average total loss: 0.473322
tensor(-12.2744, device='cuda:0') tensor(2.3762, device='cuda:0') tensor(1.1645e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.098690
Average KL loss: 0.372046
Average total loss: 0.470736
tensor(-12.2762, device='cuda:0') tensor(2.3753, device='cuda:0') tensor(1.2912e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.099587
Average KL loss: 0.371994
Average total loss: 0.471581
tensor(-12.2781, device='cuda:0') tensor(2.3745, device='cuda:0') tensor(5.2268e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.099563
Average KL loss: 0.371942
Average total loss: 0.471505
tensor(-12.2799, device='cuda:0') tensor(2.3736, device='cuda:0') tensor(2.4362e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.096004
Average KL loss: 0.371903
Average total loss: 0.467907
tensor(-12.2818, device='cuda:0') tensor(2.3728, device='cuda:0') tensor(9.5075e-11, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.098927
Average KL loss: 0.371854
Average total loss: 0.470781
tensor(-12.2836, device='cuda:0') tensor(2.3719, device='cuda:0') tensor(2.2707e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.097066
Average KL loss: 0.371799
Average total loss: 0.468865
tensor(-12.2855, device='cuda:0') tensor(2.3711, device='cuda:0') tensor(1.4403e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.098103
Average KL loss: 0.371735
Average total loss: 0.469838
tensor(-12.2873, device='cuda:0') tensor(2.3702, device='cuda:0') tensor(8.2779e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.097547
Average KL loss: 0.371675
Average total loss: 0.469222
tensor(-12.2891, device='cuda:0') tensor(2.3694, device='cuda:0') tensor(1.9925e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.098036
Average KL loss: 0.371592
Average total loss: 0.469627
tensor(-12.2910, device='cuda:0') tensor(2.3685, device='cuda:0') tensor(5.0681e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.096203
Average KL loss: 0.371522
Average total loss: 0.467725
tensor(-12.2928, device='cuda:0') tensor(2.3676, device='cuda:0') tensor(-9.6557e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.097780
Average KL loss: 0.371481
Average total loss: 0.469261
tensor(-12.2946, device='cuda:0') tensor(2.3668, device='cuda:0') tensor(2.2470e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.095570
Average KL loss: 0.371440
Average total loss: 0.467010
tensor(-12.2965, device='cuda:0') tensor(2.3660, device='cuda:0') tensor(2.7752e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.094455
Average KL loss: 0.371377
Average total loss: 0.465832
tensor(-12.2983, device='cuda:0') tensor(2.3651, device='cuda:0') tensor(1.1795e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.095481
Average KL loss: 0.371303
Average total loss: 0.466784
tensor(-12.3001, device='cuda:0') tensor(2.3642, device='cuda:0') tensor(6.9887e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.098611
Average KL loss: 0.371256
Average total loss: 0.469867
tensor(-12.3019, device='cuda:0') tensor(2.3633, device='cuda:0') tensor(6.3080e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.095667
Average KL loss: 0.371188
Average total loss: 0.466855
tensor(-12.3037, device='cuda:0') tensor(2.3625, device='cuda:0') tensor(1.7073e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.095316
Average KL loss: 0.371117
Average total loss: 0.466433
tensor(-12.3055, device='cuda:0') tensor(2.3617, device='cuda:0') tensor(2.9202e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.095662
Average KL loss: 0.371060
Average total loss: 0.466722
tensor(-12.3073, device='cuda:0') tensor(2.3609, device='cuda:0') tensor(-4.2255e-11, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.093939
Average KL loss: 0.370984
Average total loss: 0.464923
tensor(-12.3091, device='cuda:0') tensor(2.3600, device='cuda:0') tensor(8.2627e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.095527
Average KL loss: 0.370923
Average total loss: 0.466450
tensor(-12.3109, device='cuda:0') tensor(2.3592, device='cuda:0') tensor(1.8642e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.096197
Average KL loss: 0.370858
Average total loss: 0.467055
tensor(-12.3127, device='cuda:0') tensor(2.3583, device='cuda:0') tensor(7.5065e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.094815
Average KL loss: 0.370801
Average total loss: 0.465616
tensor(-12.3145, device='cuda:0') tensor(2.3575, device='cuda:0') tensor(8.4589e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.095063
Average KL loss: 0.370757
Average total loss: 0.465820
tensor(-12.3163, device='cuda:0') tensor(2.3567, device='cuda:0') tensor(2.9763e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.097302
Average KL loss: 0.370705
Average total loss: 0.468007
tensor(-12.3181, device='cuda:0') tensor(2.3560, device='cuda:0') tensor(1.5343e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.093732
Average KL loss: 0.370655
Average total loss: 0.464387
tensor(-12.3199, device='cuda:0') tensor(2.3552, device='cuda:0') tensor(8.2594e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.093049
Average KL loss: 0.370607
Average total loss: 0.463656
 Percentile value: -12.470901489257812
Non-zero model percentage: 32.76801300048828%, Non-zero mask percentage: 32.76801300048828%

--- Pruning Level [5/24]: ---
conv1.weight         | nonzeros =    1691 /    1728             ( 97.86%) | total_pruned =      37 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   28419 /   36864             ( 77.09%) | total_pruned =    8445 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   29023 /   36864             ( 78.73%) | total_pruned =    7841 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   27734 /   36864             ( 75.23%) | total_pruned =    9130 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   27310 /   36864             ( 74.08%) | total_pruned =    9554 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   55196 /   73728             ( 74.86%) | total_pruned =   18532 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  103818 /  147456             ( 70.41%) | total_pruned =   43638 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7287 /    8192             ( 88.95%) | total_pruned =     905 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   93641 /  147456             ( 63.50%) | total_pruned =   53815 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   94325 /  147456             ( 63.97%) | total_pruned =   53131 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  194362 /  294912             ( 65.91%) | total_pruned =  100550 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  354787 /  589824             ( 60.15%) | total_pruned =  235037 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   26349 /   32768             ( 80.41%) | total_pruned =    6419 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  244935 /  589824             ( 41.53%) | total_pruned =  344889 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     224 /     256             ( 87.50%) | total_pruned =      32 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  242684 /  589824             ( 41.15%) | total_pruned =  347140 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  515235 / 1179648             ( 43.68%) | total_pruned =  664413 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     483 /     512             ( 94.34%) | total_pruned =      29 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  703235 / 2359296             ( 29.81%) | total_pruned = 1656061 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   71546 /  131072             ( 54.59%) | total_pruned =   59526 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  395079 / 2359296             ( 16.75%) | total_pruned = 1964217 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     414 /     512             ( 80.86%) | total_pruned =      98 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     269 /     512             ( 52.54%) | total_pruned =     243 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  432222 / 2359296             ( 18.32%) | total_pruned = 1927074 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
linear.weight        | nonzeros =    5006 /    5120             ( 97.77%) | total_pruned =     114 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       9 /      10             ( 90.00%) | total_pruned =       1 | shape = torch.Size([10])
alive: 3663058, pruned : 7515704, total: 11178762, Compression rate :       3.05x  ( 67.23% pruned)
Train Epoch: 22/100 Loss: 0.000243 Accuracy: 86.66 100.00 % Best test Accuracy: 86.83%
tensor(-12.3217, device='cuda:0') tensor(2.3543, device='cuda:0') tensor(2.2796e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.136572
Average KL loss: 0.368580
Average total loss: 0.505153
tensor(-12.3299, device='cuda:0') tensor(2.2680, device='cuda:0') tensor(1.6976e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.133738
Average KL loss: 0.367127
Average total loss: 0.500866
tensor(-12.3358, device='cuda:0') tensor(2.2197, device='cuda:0') tensor(1.1037e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.131438
Average KL loss: 0.366559
Average total loss: 0.497996
tensor(-12.3407, device='cuda:0') tensor(2.1865, device='cuda:0') tensor(2.0087e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.130882
Average KL loss: 0.366237
Average total loss: 0.497119
tensor(-12.3450, device='cuda:0') tensor(2.1614, device='cuda:0') tensor(4.4075e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.127443
Average KL loss: 0.366022
Average total loss: 0.493465
tensor(-12.3490, device='cuda:0') tensor(2.1414, device='cuda:0') tensor(2.4967e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.127807
Average KL loss: 0.365866
Average total loss: 0.493674
tensor(-12.3526, device='cuda:0') tensor(2.1249, device='cuda:0') tensor(8.0692e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.125130
Average KL loss: 0.365739
Average total loss: 0.490869
tensor(-12.3560, device='cuda:0') tensor(2.1108, device='cuda:0') tensor(-5.3668e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.123942
Average KL loss: 0.365631
Average total loss: 0.489573
tensor(-12.3593, device='cuda:0') tensor(2.0985, device='cuda:0') tensor(-1.7941e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.125793
Average KL loss: 0.365563
Average total loss: 0.491356
tensor(-12.3624, device='cuda:0') tensor(2.0878, device='cuda:0') tensor(-4.0757e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.123418
Average KL loss: 0.365512
Average total loss: 0.488930
tensor(-12.3654, device='cuda:0') tensor(2.0782, device='cuda:0') tensor(1.1282e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.125609
Average KL loss: 0.365454
Average total loss: 0.491063
tensor(-12.3683, device='cuda:0') tensor(2.0697, device='cuda:0') tensor(1.0918e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.121791
Average KL loss: 0.365419
Average total loss: 0.487210
tensor(-12.3711, device='cuda:0') tensor(2.0619, device='cuda:0') tensor(-2.7715e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.120040
Average KL loss: 0.365387
Average total loss: 0.485427
tensor(-12.3738, device='cuda:0') tensor(2.0547, device='cuda:0') tensor(3.4530e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.121082
Average KL loss: 0.365346
Average total loss: 0.486428
tensor(-12.3765, device='cuda:0') tensor(2.0480, device='cuda:0') tensor(-1.5791e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.122082
Average KL loss: 0.365309
Average total loss: 0.487391
tensor(-12.3791, device='cuda:0') tensor(2.0418, device='cuda:0') tensor(-8.7507e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.119619
Average KL loss: 0.365291
Average total loss: 0.484910
tensor(-12.3816, device='cuda:0') tensor(2.0360, device='cuda:0') tensor(3.3056e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.118749
Average KL loss: 0.365271
Average total loss: 0.484020
tensor(-12.3842, device='cuda:0') tensor(2.0306, device='cuda:0') tensor(-2.4130e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.116032
Average KL loss: 0.365239
Average total loss: 0.481271
tensor(-12.3866, device='cuda:0') tensor(2.0255, device='cuda:0') tensor(-4.6579e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.117018
Average KL loss: 0.365211
Average total loss: 0.482229
tensor(-12.3891, device='cuda:0') tensor(2.0208, device='cuda:0') tensor(1.0743e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.117119
Average KL loss: 0.365186
Average total loss: 0.482305
tensor(-12.3915, device='cuda:0') tensor(2.0164, device='cuda:0') tensor(-2.6937e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.118101
Average KL loss: 0.365154
Average total loss: 0.483255
tensor(-12.3938, device='cuda:0') tensor(2.0121, device='cuda:0') tensor(3.5313e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.114298
Average KL loss: 0.365122
Average total loss: 0.479420
tensor(-12.3961, device='cuda:0') tensor(2.0080, device='cuda:0') tensor(6.9768e-11, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.117197
Average KL loss: 0.365080
Average total loss: 0.482277
tensor(-12.3984, device='cuda:0') tensor(2.0042, device='cuda:0') tensor(-1.7104e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.115721
Average KL loss: 0.365055
Average total loss: 0.480776
tensor(-12.4007, device='cuda:0') tensor(2.0006, device='cuda:0') tensor(2.1545e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.114619
Average KL loss: 0.365032
Average total loss: 0.479651
tensor(-12.4030, device='cuda:0') tensor(1.9971, device='cuda:0') tensor(9.9353e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.113147
Average KL loss: 0.365020
Average total loss: 0.478167
tensor(-12.4052, device='cuda:0') tensor(1.9938, device='cuda:0') tensor(-8.4568e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.113162
Average KL loss: 0.365001
Average total loss: 0.478163
tensor(-12.4074, device='cuda:0') tensor(1.9906, device='cuda:0') tensor(7.5822e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.112248
Average KL loss: 0.364988
Average total loss: 0.477236
tensor(-12.4096, device='cuda:0') tensor(1.9876, device='cuda:0') tensor(1.2627e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.108609
Average KL loss: 0.364958
Average total loss: 0.473568
tensor(-12.4117, device='cuda:0') tensor(1.9846, device='cuda:0') tensor(-8.1712e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.111085
Average KL loss: 0.364922
Average total loss: 0.476007
tensor(-12.4139, device='cuda:0') tensor(1.9818, device='cuda:0') tensor(-1.4897e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.110977
Average KL loss: 0.364913
Average total loss: 0.475890
tensor(-12.4160, device='cuda:0') tensor(1.9792, device='cuda:0') tensor(3.4588e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.108610
Average KL loss: 0.364902
Average total loss: 0.473513
tensor(-12.4181, device='cuda:0') tensor(1.9766, device='cuda:0') tensor(-1.4032e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.113132
Average KL loss: 0.364878
Average total loss: 0.478010
tensor(-12.4202, device='cuda:0') tensor(1.9741, device='cuda:0') tensor(3.5601e-11, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.110792
Average KL loss: 0.364861
Average total loss: 0.475653
tensor(-12.4223, device='cuda:0') tensor(1.9717, device='cuda:0') tensor(3.0895e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.109472
Average KL loss: 0.364852
Average total loss: 0.474324
tensor(-12.4244, device='cuda:0') tensor(1.9694, device='cuda:0') tensor(4.3979e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.109928
Average KL loss: 0.364831
Average total loss: 0.474759
tensor(-12.4264, device='cuda:0') tensor(1.9671, device='cuda:0') tensor(2.1451e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.108980
Average KL loss: 0.364805
Average total loss: 0.473785
tensor(-12.4284, device='cuda:0') tensor(1.9649, device='cuda:0') tensor(-2.4926e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.109018
Average KL loss: 0.364766
Average total loss: 0.473784
tensor(-12.4305, device='cuda:0') tensor(1.9628, device='cuda:0') tensor(1.7334e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.109964
Average KL loss: 0.364746
Average total loss: 0.474711
tensor(-12.4325, device='cuda:0') tensor(1.9608, device='cuda:0') tensor(8.0406e-11, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.108118
Average KL loss: 0.364725
Average total loss: 0.472843
tensor(-12.4345, device='cuda:0') tensor(1.9587, device='cuda:0') tensor(3.5809e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.109024
Average KL loss: 0.364719
Average total loss: 0.473743
tensor(-12.4364, device='cuda:0') tensor(1.9569, device='cuda:0') tensor(1.7490e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.105406
Average KL loss: 0.364701
Average total loss: 0.470107
tensor(-12.4384, device='cuda:0') tensor(1.9550, device='cuda:0') tensor(8.0413e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.108427
Average KL loss: 0.364682
Average total loss: 0.473109
tensor(-12.4404, device='cuda:0') tensor(1.9532, device='cuda:0') tensor(-3.4725e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.103887
Average KL loss: 0.364667
Average total loss: 0.468554
tensor(-12.4423, device='cuda:0') tensor(1.9514, device='cuda:0') tensor(-1.7232e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.104888
Average KL loss: 0.364643
Average total loss: 0.469531
tensor(-12.4443, device='cuda:0') tensor(1.9497, device='cuda:0') tensor(-1.3880e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.107548
Average KL loss: 0.364611
Average total loss: 0.472159
tensor(-12.4462, device='cuda:0') tensor(1.9480, device='cuda:0') tensor(-1.8092e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.105110
Average KL loss: 0.364590
Average total loss: 0.469700
tensor(-12.4481, device='cuda:0') tensor(1.9464, device='cuda:0') tensor(1.1740e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.105157
Average KL loss: 0.364557
Average total loss: 0.469714
tensor(-12.4500, device='cuda:0') tensor(1.9448, device='cuda:0') tensor(-1.1714e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.104834
Average KL loss: 0.364538
Average total loss: 0.469371
tensor(-12.4519, device='cuda:0') tensor(1.9433, device='cuda:0') tensor(4.6306e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.103936
Average KL loss: 0.364512
Average total loss: 0.468449
tensor(-12.4538, device='cuda:0') tensor(1.9418, device='cuda:0') tensor(1.0701e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.104444
Average KL loss: 0.364480
Average total loss: 0.468924
tensor(-12.4557, device='cuda:0') tensor(1.9403, device='cuda:0') tensor(8.6718e-11, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.103806
Average KL loss: 0.364461
Average total loss: 0.468267
tensor(-12.4576, device='cuda:0') tensor(1.9389, device='cuda:0') tensor(-4.9626e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.103273
Average KL loss: 0.364423
Average total loss: 0.467696
tensor(-12.4594, device='cuda:0') tensor(1.9374, device='cuda:0') tensor(2.0969e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.103738
Average KL loss: 0.364379
Average total loss: 0.468117
tensor(-12.4613, device='cuda:0') tensor(1.9360, device='cuda:0') tensor(1.0207e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.103058
Average KL loss: 0.364360
Average total loss: 0.467418
tensor(-12.4631, device='cuda:0') tensor(1.9347, device='cuda:0') tensor(8.3489e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.103103
Average KL loss: 0.364338
Average total loss: 0.467441
tensor(-12.4650, device='cuda:0') tensor(1.9334, device='cuda:0') tensor(-2.0550e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.103116
Average KL loss: 0.364309
Average total loss: 0.467426
tensor(-12.4668, device='cuda:0') tensor(1.9322, device='cuda:0') tensor(5.0825e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.102869
Average KL loss: 0.364299
Average total loss: 0.467168
tensor(-12.4686, device='cuda:0') tensor(1.9309, device='cuda:0') tensor(-1.4737e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.102984
Average KL loss: 0.364282
Average total loss: 0.467265
tensor(-12.4704, device='cuda:0') tensor(1.9297, device='cuda:0') tensor(8.2725e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.099771
Average KL loss: 0.364242
Average total loss: 0.464012
tensor(-12.4722, device='cuda:0') tensor(1.9285, device='cuda:0') tensor(-2.7663e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.100491
Average KL loss: 0.364209
Average total loss: 0.464700
tensor(-12.4740, device='cuda:0') tensor(1.9274, device='cuda:0') tensor(1.3232e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.101635
Average KL loss: 0.364189
Average total loss: 0.465824
tensor(-12.4758, device='cuda:0') tensor(1.9262, device='cuda:0') tensor(2.9736e-11, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.097726
Average KL loss: 0.364162
Average total loss: 0.461889
tensor(-12.4776, device='cuda:0') tensor(1.9251, device='cuda:0') tensor(4.9371e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.104232
Average KL loss: 0.364153
Average total loss: 0.468385
tensor(-12.4794, device='cuda:0') tensor(1.9240, device='cuda:0') tensor(-1.6239e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.099061
Average KL loss: 0.364138
Average total loss: 0.463198
tensor(-12.4812, device='cuda:0') tensor(1.9229, device='cuda:0') tensor(1.2462e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.098495
Average KL loss: 0.364121
Average total loss: 0.462617
tensor(-12.4829, device='cuda:0') tensor(1.9219, device='cuda:0') tensor(5.6959e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.099369
Average KL loss: 0.364097
Average total loss: 0.463465
tensor(-12.4847, device='cuda:0') tensor(1.9208, device='cuda:0') tensor(9.7280e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.099486
Average KL loss: 0.364064
Average total loss: 0.463550
tensor(-12.4865, device='cuda:0') tensor(1.9199, device='cuda:0') tensor(9.9927e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.100658
Average KL loss: 0.364030
Average total loss: 0.464687
tensor(-12.4882, device='cuda:0') tensor(1.9189, device='cuda:0') tensor(4.6740e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.098755
Average KL loss: 0.363987
Average total loss: 0.462742
tensor(-12.4900, device='cuda:0') tensor(1.9179, device='cuda:0') tensor(4.7617e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.097872
Average KL loss: 0.363964
Average total loss: 0.461836
tensor(-12.4917, device='cuda:0') tensor(1.9169, device='cuda:0') tensor(-4.8929e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.097260
Average KL loss: 0.363950
Average total loss: 0.461210
tensor(-12.4934, device='cuda:0') tensor(1.9160, device='cuda:0') tensor(-9.5255e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.100598
Average KL loss: 0.363930
Average total loss: 0.464528
tensor(-12.4952, device='cuda:0') tensor(1.9150, device='cuda:0') tensor(-4.0382e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.096911
Average KL loss: 0.363913
Average total loss: 0.460824
tensor(-12.4969, device='cuda:0') tensor(1.9141, device='cuda:0') tensor(6.0755e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.096129
Average KL loss: 0.363870
Average total loss: 0.460000
tensor(-12.4986, device='cuda:0') tensor(1.9132, device='cuda:0') tensor(-8.1917e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.096846
Average KL loss: 0.363851
Average total loss: 0.460697
tensor(-12.5003, device='cuda:0') tensor(1.9123, device='cuda:0') tensor(9.4492e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.098217
Average KL loss: 0.363818
Average total loss: 0.462036
tensor(-12.5020, device='cuda:0') tensor(1.9115, device='cuda:0') tensor(-8.5573e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.095368
Average KL loss: 0.363777
Average total loss: 0.459146
tensor(-12.5037, device='cuda:0') tensor(1.9106, device='cuda:0') tensor(4.5492e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.097618
Average KL loss: 0.363739
Average total loss: 0.461358
tensor(-12.5054, device='cuda:0') tensor(1.9097, device='cuda:0') tensor(-3.2721e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.096486
Average KL loss: 0.363716
Average total loss: 0.460202
tensor(-12.5071, device='cuda:0') tensor(1.9089, device='cuda:0') tensor(1.8110e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.095305
Average KL loss: 0.363698
Average total loss: 0.459003
tensor(-12.5088, device='cuda:0') tensor(1.9081, device='cuda:0') tensor(9.6928e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.094013
Average KL loss: 0.363662
Average total loss: 0.457675
tensor(-12.5105, device='cuda:0') tensor(1.9072, device='cuda:0') tensor(1.0742e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.095828
Average KL loss: 0.363623
Average total loss: 0.459451
tensor(-12.5122, device='cuda:0') tensor(1.9064, device='cuda:0') tensor(4.4694e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.094831
Average KL loss: 0.363597
Average total loss: 0.458428
tensor(-12.5138, device='cuda:0') tensor(1.9057, device='cuda:0') tensor(7.3219e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.093659
Average KL loss: 0.363570
Average total loss: 0.457229
tensor(-12.5155, device='cuda:0') tensor(1.9049, device='cuda:0') tensor(5.7552e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.094819
Average KL loss: 0.363520
Average total loss: 0.458339
tensor(-12.5172, device='cuda:0') tensor(1.9041, device='cuda:0') tensor(-6.2549e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.094935
Average KL loss: 0.363477
Average total loss: 0.458412
tensor(-12.5188, device='cuda:0') tensor(1.9034, device='cuda:0') tensor(6.1008e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.094762
Average KL loss: 0.363453
Average total loss: 0.458215
tensor(-12.5205, device='cuda:0') tensor(1.9026, device='cuda:0') tensor(2.6076e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.095207
Average KL loss: 0.363412
Average total loss: 0.458619
tensor(-12.5221, device='cuda:0') tensor(1.9019, device='cuda:0') tensor(-1.1893e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.095779
Average KL loss: 0.363369
Average total loss: 0.459148
tensor(-12.5238, device='cuda:0') tensor(1.9012, device='cuda:0') tensor(4.1168e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.094231
Average KL loss: 0.363328
Average total loss: 0.457559
tensor(-12.5254, device='cuda:0') tensor(1.9005, device='cuda:0') tensor(-9.1972e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.094531
Average KL loss: 0.363297
Average total loss: 0.457828
tensor(-12.5271, device='cuda:0') tensor(1.8998, device='cuda:0') tensor(4.8667e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.093965
Average KL loss: 0.363269
Average total loss: 0.457234
tensor(-12.5287, device='cuda:0') tensor(1.8992, device='cuda:0') tensor(-4.5894e-11, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.092129
Average KL loss: 0.363242
Average total loss: 0.455371
tensor(-12.5303, device='cuda:0') tensor(1.8984, device='cuda:0') tensor(-4.3697e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.092345
Average KL loss: 0.363211
Average total loss: 0.455556
tensor(-12.5320, device='cuda:0') tensor(1.8977, device='cuda:0') tensor(1.6992e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.092945
Average KL loss: 0.363170
Average total loss: 0.456115
tensor(-12.5336, device='cuda:0') tensor(1.8970, device='cuda:0') tensor(7.6204e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.092111
Average KL loss: 0.363137
Average total loss: 0.455248
tensor(-12.5352, device='cuda:0') tensor(1.8963, device='cuda:0') tensor(5.1447e-11, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.090388
Average KL loss: 0.363115
Average total loss: 0.453503
tensor(-12.5368, device='cuda:0') tensor(1.8957, device='cuda:0') tensor(1.9088e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.091208
Average KL loss: 0.363086
Average total loss: 0.454294
tensor(-12.5384, device='cuda:0') tensor(1.8951, device='cuda:0') tensor(1.7682e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.091624
Average KL loss: 0.363056
Average total loss: 0.454680
tensor(-12.5400, device='cuda:0') tensor(1.8945, device='cuda:0') tensor(4.4794e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.090464
Average KL loss: 0.363026
Average total loss: 0.453490
tensor(-12.5416, device='cuda:0') tensor(1.8938, device='cuda:0') tensor(1.3330e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.090463
Average KL loss: 0.362997
Average total loss: 0.453460
tensor(-12.5432, device='cuda:0') tensor(1.8931, device='cuda:0') tensor(-8.1491e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.090832
Average KL loss: 0.362979
Average total loss: 0.453812
tensor(-12.5448, device='cuda:0') tensor(1.8926, device='cuda:0') tensor(1.2843e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.090662
Average KL loss: 0.362950
Average total loss: 0.453613
tensor(-12.5464, device='cuda:0') tensor(1.8920, device='cuda:0') tensor(7.7749e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.091144
Average KL loss: 0.362924
Average total loss: 0.454068
tensor(-12.5480, device='cuda:0') tensor(1.8914, device='cuda:0') tensor(-9.5652e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.092379
Average KL loss: 0.362897
Average total loss: 0.455276
tensor(-12.5496, device='cuda:0') tensor(1.8908, device='cuda:0') tensor(1.2075e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.092516
Average KL loss: 0.362874
Average total loss: 0.455390
tensor(-12.5511, device='cuda:0') tensor(1.8902, device='cuda:0') tensor(-1.5217e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.091314
Average KL loss: 0.362858
Average total loss: 0.454171
tensor(-12.5527, device='cuda:0') tensor(1.8896, device='cuda:0') tensor(5.4087e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.089750
Average KL loss: 0.362830
Average total loss: 0.452580
tensor(-12.5543, device='cuda:0') tensor(1.8891, device='cuda:0') tensor(1.0680e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.092786
Average KL loss: 0.362790
Average total loss: 0.455576
tensor(-12.5559, device='cuda:0') tensor(1.8885, device='cuda:0') tensor(6.1600e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.088911
Average KL loss: 0.362748
Average total loss: 0.451659
tensor(-12.5574, device='cuda:0') tensor(1.8880, device='cuda:0') tensor(9.0703e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.089496
Average KL loss: 0.362709
Average total loss: 0.452206
tensor(-12.5590, device='cuda:0') tensor(1.8875, device='cuda:0') tensor(7.4140e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.087988
Average KL loss: 0.362685
Average total loss: 0.450673
tensor(-12.5605, device='cuda:0') tensor(1.8870, device='cuda:0') tensor(1.0761e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.089039
Average KL loss: 0.362656
Average total loss: 0.451695
tensor(-12.5621, device='cuda:0') tensor(1.8864, device='cuda:0') tensor(5.8035e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.088775
Average KL loss: 0.362621
Average total loss: 0.451397
tensor(-12.5636, device='cuda:0') tensor(1.8858, device='cuda:0') tensor(-6.2911e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.088440
Average KL loss: 0.362579
Average total loss: 0.451020
tensor(-12.5652, device='cuda:0') tensor(1.8853, device='cuda:0') tensor(2.6176e-11, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.088738
Average KL loss: 0.362547
Average total loss: 0.451286
tensor(-12.5667, device='cuda:0') tensor(1.8848, device='cuda:0') tensor(9.8450e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.088883
Average KL loss: 0.362513
Average total loss: 0.451396
tensor(-12.5683, device='cuda:0') tensor(1.8842, device='cuda:0') tensor(-2.7429e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.086688
Average KL loss: 0.362474
Average total loss: 0.449162
tensor(-12.5698, device='cuda:0') tensor(1.8837, device='cuda:0') tensor(1.0277e-11, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.088605
Average KL loss: 0.362447
Average total loss: 0.451053
tensor(-12.5714, device='cuda:0') tensor(1.8832, device='cuda:0') tensor(-7.4206e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.087480
Average KL loss: 0.362424
Average total loss: 0.449904
tensor(-12.5729, device='cuda:0') tensor(1.8827, device='cuda:0') tensor(-7.2114e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.086891
Average KL loss: 0.362396
Average total loss: 0.449287
tensor(-12.5744, device='cuda:0') tensor(1.8823, device='cuda:0') tensor(-1.7457e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.087576
Average KL loss: 0.362375
Average total loss: 0.449950
tensor(-12.5759, device='cuda:0') tensor(1.8818, device='cuda:0') tensor(-1.3750e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.087779
Average KL loss: 0.362350
Average total loss: 0.450129
tensor(-12.5775, device='cuda:0') tensor(1.8814, device='cuda:0') tensor(-1.3808e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.085366
Average KL loss: 0.362320
Average total loss: 0.447686
tensor(-12.5790, device='cuda:0') tensor(1.8809, device='cuda:0') tensor(8.4563e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.088707
Average KL loss: 0.362285
Average total loss: 0.450992
tensor(-12.5805, device='cuda:0') tensor(1.8804, device='cuda:0') tensor(-2.0481e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.086635
Average KL loss: 0.362255
Average total loss: 0.448890
tensor(-12.5820, device='cuda:0') tensor(1.8799, device='cuda:0') tensor(9.8330e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.085365
Average KL loss: 0.362214
Average total loss: 0.447579
tensor(-12.5835, device='cuda:0') tensor(1.8795, device='cuda:0') tensor(-6.1230e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.086615
Average KL loss: 0.362193
Average total loss: 0.448808
tensor(-12.5850, device='cuda:0') tensor(1.8789, device='cuda:0') tensor(-5.0452e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.085852
Average KL loss: 0.362155
Average total loss: 0.448007
tensor(-12.5866, device='cuda:0') tensor(1.8785, device='cuda:0') tensor(-2.7132e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.086029
Average KL loss: 0.362108
Average total loss: 0.448137
tensor(-12.5881, device='cuda:0') tensor(1.8780, device='cuda:0') tensor(-5.3556e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.085912
Average KL loss: 0.362075
Average total loss: 0.447987
tensor(-12.5896, device='cuda:0') tensor(1.8776, device='cuda:0') tensor(-6.3794e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.085751
Average KL loss: 0.362051
Average total loss: 0.447801
tensor(-12.5911, device='cuda:0') tensor(1.8772, device='cuda:0') tensor(5.1776e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.084777
Average KL loss: 0.362008
Average total loss: 0.446785
tensor(-12.5926, device='cuda:0') tensor(1.8766, device='cuda:0') tensor(-1.0235e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.084575
Average KL loss: 0.361973
Average total loss: 0.446548
tensor(-12.5940, device='cuda:0') tensor(1.8762, device='cuda:0') tensor(2.7592e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.084767
Average KL loss: 0.361937
Average total loss: 0.446705
tensor(-12.5955, device='cuda:0') tensor(1.8757, device='cuda:0') tensor(1.3452e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.085362
Average KL loss: 0.361908
Average total loss: 0.447270
tensor(-12.5970, device='cuda:0') tensor(1.8752, device='cuda:0') tensor(2.7353e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.084962
Average KL loss: 0.361883
Average total loss: 0.446845
tensor(-12.5985, device='cuda:0') tensor(1.8747, device='cuda:0') tensor(-6.7058e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.086431
Average KL loss: 0.361872
Average total loss: 0.448303
tensor(-12.6000, device='cuda:0') tensor(1.8743, device='cuda:0') tensor(5.4047e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.084215
Average KL loss: 0.361851
Average total loss: 0.446065
tensor(-12.6015, device='cuda:0') tensor(1.8739, device='cuda:0') tensor(-2.6523e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.083840
Average KL loss: 0.361829
Average total loss: 0.445669
tensor(-12.6029, device='cuda:0') tensor(1.8735, device='cuda:0') tensor(1.1199e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.084438
Average KL loss: 0.361799
Average total loss: 0.446237
tensor(-12.6044, device='cuda:0') tensor(1.8731, device='cuda:0') tensor(9.9675e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.084510
Average KL loss: 0.361763
Average total loss: 0.446273
tensor(-12.6059, device='cuda:0') tensor(1.8726, device='cuda:0') tensor(4.2575e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.081470
Average KL loss: 0.361724
Average total loss: 0.443194
tensor(-12.6074, device='cuda:0') tensor(1.8722, device='cuda:0') tensor(-6.2023e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.081335
Average KL loss: 0.361691
Average total loss: 0.443026
tensor(-12.6088, device='cuda:0') tensor(1.8717, device='cuda:0') tensor(5.6891e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.082462
Average KL loss: 0.361657
Average total loss: 0.444119
tensor(-12.6103, device='cuda:0') tensor(1.8713, device='cuda:0') tensor(5.5563e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.083018
Average KL loss: 0.361627
Average total loss: 0.444645
tensor(-12.6117, device='cuda:0') tensor(1.8709, device='cuda:0') tensor(1.0247e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.082793
Average KL loss: 0.361598
Average total loss: 0.444390
tensor(-12.6132, device='cuda:0') tensor(1.8705, device='cuda:0') tensor(1.2406e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.081601
Average KL loss: 0.361558
Average total loss: 0.443159
tensor(-12.6147, device='cuda:0') tensor(1.8701, device='cuda:0') tensor(7.6211e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.083697
Average KL loss: 0.361509
Average total loss: 0.445206
tensor(-12.6161, device='cuda:0') tensor(1.8697, device='cuda:0') tensor(4.0691e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.083298
Average KL loss: 0.361479
Average total loss: 0.444777
tensor(-12.6176, device='cuda:0') tensor(1.8693, device='cuda:0') tensor(4.2587e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.081189
Average KL loss: 0.361455
Average total loss: 0.442643
tensor(-12.6190, device='cuda:0') tensor(1.8689, device='cuda:0') tensor(2.0518e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.082949
Average KL loss: 0.361418
Average total loss: 0.444366
tensor(-12.6205, device='cuda:0') tensor(1.8684, device='cuda:0') tensor(-1.0189e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.083208
Average KL loss: 0.361385
Average total loss: 0.444593
tensor(-12.6219, device='cuda:0') tensor(1.8680, device='cuda:0') tensor(2.5469e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.084093
Average KL loss: 0.361355
Average total loss: 0.445448
tensor(-12.6234, device='cuda:0') tensor(1.8676, device='cuda:0') tensor(7.6945e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.082371
Average KL loss: 0.361317
Average total loss: 0.443689
tensor(-12.6248, device='cuda:0') tensor(1.8672, device='cuda:0') tensor(-9.4996e-11, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.080564
Average KL loss: 0.361287
Average total loss: 0.441850
tensor(-12.6262, device='cuda:0') tensor(1.8668, device='cuda:0') tensor(-5.2545e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.082541
Average KL loss: 0.361256
Average total loss: 0.443797
tensor(-12.6277, device='cuda:0') tensor(1.8664, device='cuda:0') tensor(9.1144e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.080548
Average KL loss: 0.361214
Average total loss: 0.441762
tensor(-12.6291, device='cuda:0') tensor(1.8659, device='cuda:0') tensor(5.8876e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.080297
Average KL loss: 0.361179
Average total loss: 0.441475
tensor(-12.6305, device='cuda:0') tensor(1.8655, device='cuda:0') tensor(1.0034e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.081677
Average KL loss: 0.361136
Average total loss: 0.442813
tensor(-12.6320, device='cuda:0') tensor(1.8650, device='cuda:0') tensor(6.4128e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.080203
Average KL loss: 0.361112
Average total loss: 0.441314
tensor(-12.6334, device='cuda:0') tensor(1.8647, device='cuda:0') tensor(5.7604e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.082188
Average KL loss: 0.361083
Average total loss: 0.443271
tensor(-12.6348, device='cuda:0') tensor(1.8643, device='cuda:0') tensor(-9.4080e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.080843
Average KL loss: 0.361040
Average total loss: 0.441883
tensor(-12.6363, device='cuda:0') tensor(1.8639, device='cuda:0') tensor(1.1701e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.079750
Average KL loss: 0.360997
Average total loss: 0.440747
tensor(-12.6377, device='cuda:0') tensor(1.8635, device='cuda:0') tensor(8.0465e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.080570
Average KL loss: 0.360962
Average total loss: 0.441532
tensor(-12.6391, device='cuda:0') tensor(1.8631, device='cuda:0') tensor(5.5996e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.078441
Average KL loss: 0.360930
Average total loss: 0.439370
tensor(-12.6405, device='cuda:0') tensor(1.8627, device='cuda:0') tensor(-1.8623e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.080664
Average KL loss: 0.360903
Average total loss: 0.441567
tensor(-12.6419, device='cuda:0') tensor(1.8624, device='cuda:0') tensor(5.0581e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.080059
Average KL loss: 0.360886
Average total loss: 0.440945
tensor(-12.6433, device='cuda:0') tensor(1.8621, device='cuda:0') tensor(7.6148e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.079827
Average KL loss: 0.360863
Average total loss: 0.440690
tensor(-12.6448, device='cuda:0') tensor(1.8617, device='cuda:0') tensor(5.0553e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.079485
Average KL loss: 0.360843
Average total loss: 0.440328
tensor(-12.6462, device='cuda:0') tensor(1.8613, device='cuda:0') tensor(8.5911e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.080427
Average KL loss: 0.360819
Average total loss: 0.441246
tensor(-12.6476, device='cuda:0') tensor(1.8609, device='cuda:0') tensor(6.9674e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.078837
Average KL loss: 0.360793
Average total loss: 0.439630
tensor(-12.6490, device='cuda:0') tensor(1.8605, device='cuda:0') tensor(-2.1802e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.079253
Average KL loss: 0.360776
Average total loss: 0.440029
tensor(-12.6504, device='cuda:0') tensor(1.8602, device='cuda:0') tensor(8.9934e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.077623
Average KL loss: 0.360751
Average total loss: 0.438374
tensor(-12.6518, device='cuda:0') tensor(1.8598, device='cuda:0') tensor(-5.4031e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.079548
Average KL loss: 0.360711
Average total loss: 0.440259
tensor(-12.6532, device='cuda:0') tensor(1.8593, device='cuda:0') tensor(1.4664e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.078008
Average KL loss: 0.360681
Average total loss: 0.438689
tensor(-12.6546, device='cuda:0') tensor(1.8589, device='cuda:0') tensor(5.1235e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.078210
Average KL loss: 0.360655
Average total loss: 0.438865
tensor(-12.6560, device='cuda:0') tensor(1.8584, device='cuda:0') tensor(-1.1808e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.079233
Average KL loss: 0.360628
Average total loss: 0.439861
tensor(-12.6574, device='cuda:0') tensor(1.8580, device='cuda:0') tensor(-4.8146e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.078231
Average KL loss: 0.360593
Average total loss: 0.438823
tensor(-12.6588, device='cuda:0') tensor(1.8576, device='cuda:0') tensor(-4.2170e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.078365
Average KL loss: 0.360572
Average total loss: 0.438937
tensor(-12.6601, device='cuda:0') tensor(1.8573, device='cuda:0') tensor(8.9521e-11, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.079030
Average KL loss: 0.360537
Average total loss: 0.439566
tensor(-12.6615, device='cuda:0') tensor(1.8569, device='cuda:0') tensor(-8.4032e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.076864
Average KL loss: 0.360512
Average total loss: 0.437377
tensor(-12.6629, device='cuda:0') tensor(1.8566, device='cuda:0') tensor(7.7386e-11, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.078315
Average KL loss: 0.360488
Average total loss: 0.438803
tensor(-12.6643, device='cuda:0') tensor(1.8562, device='cuda:0') tensor(-8.5607e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.077120
Average KL loss: 0.360460
Average total loss: 0.437581
tensor(-12.6657, device='cuda:0') tensor(1.8559, device='cuda:0') tensor(-1.9249e-11, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.078362
Average KL loss: 0.360427
Average total loss: 0.438788
tensor(-12.6670, device='cuda:0') tensor(1.8555, device='cuda:0') tensor(6.5751e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.075651
Average KL loss: 0.360392
Average total loss: 0.436043
tensor(-12.6684, device='cuda:0') tensor(1.8551, device='cuda:0') tensor(9.8467e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.077706
Average KL loss: 0.360368
Average total loss: 0.438074
tensor(-12.6698, device='cuda:0') tensor(1.8548, device='cuda:0') tensor(6.1694e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.077773
Average KL loss: 0.360349
Average total loss: 0.438123
tensor(-12.6712, device='cuda:0') tensor(1.8544, device='cuda:0') tensor(-3.9750e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.076892
Average KL loss: 0.360325
Average total loss: 0.437217
tensor(-12.6725, device='cuda:0') tensor(1.8541, device='cuda:0') tensor(-3.2660e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.077054
Average KL loss: 0.360307
Average total loss: 0.437361
tensor(-12.6739, device='cuda:0') tensor(1.8537, device='cuda:0') tensor(7.3812e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.075883
Average KL loss: 0.360262
Average total loss: 0.436144
tensor(-12.6753, device='cuda:0') tensor(1.8534, device='cuda:0') tensor(1.3791e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.076995
Average KL loss: 0.360240
Average total loss: 0.437235
tensor(-12.6766, device='cuda:0') tensor(1.8530, device='cuda:0') tensor(-1.1384e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.075981
Average KL loss: 0.360222
Average total loss: 0.436203
tensor(-12.6780, device='cuda:0') tensor(1.8526, device='cuda:0') tensor(8.0040e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.075704
Average KL loss: 0.360190
Average total loss: 0.435894
tensor(-12.6794, device='cuda:0') tensor(1.8522, device='cuda:0') tensor(5.4042e-11, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.074765
Average KL loss: 0.360155
Average total loss: 0.434920
tensor(-12.6807, device='cuda:0') tensor(1.8518, device='cuda:0') tensor(4.8472e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.076171
Average KL loss: 0.360128
Average total loss: 0.436300
tensor(-12.6821, device='cuda:0') tensor(1.8514, device='cuda:0') tensor(-6.4507e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.075805
Average KL loss: 0.360083
Average total loss: 0.435888
tensor(-12.6834, device='cuda:0') tensor(1.8511, device='cuda:0') tensor(-1.1843e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.074617
Average KL loss: 0.360048
Average total loss: 0.434665
tensor(-12.6848, device='cuda:0') tensor(1.8507, device='cuda:0') tensor(8.4708e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.077558
Average KL loss: 0.360007
Average total loss: 0.437565
 Percentile value: -12.669968605041504
Non-zero model percentage: 26.214414596557617%, Non-zero mask percentage: 26.214414596557617%

--- Pruning Level [6/24]: ---
conv1.weight         | nonzeros =    1671 /    1728             ( 96.70%) | total_pruned =      57 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   26082 /   36864             ( 70.75%) | total_pruned =   10782 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   26599 /   36864             ( 72.15%) | total_pruned =   10265 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   24917 /   36864             ( 67.59%) | total_pruned =   11947 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   24479 /   36864             ( 66.40%) | total_pruned =   12385 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   50263 /   73728             ( 68.17%) | total_pruned =   23465 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   93519 /  147456             ( 63.42%) | total_pruned =   53937 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    6877 /    8192             ( 83.95%) | total_pruned =    1315 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   81479 /  147456             ( 55.26%) | total_pruned =   65977 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   82554 /  147456             ( 55.99%) | total_pruned =   64902 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  171953 /  294912             ( 58.31%) | total_pruned =  122959 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  307039 /  589824             ( 52.06%) | total_pruned =  282785 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   24147 /   32768             ( 73.69%) | total_pruned =    8621 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  194646 /  589824             ( 33.00%) | total_pruned =  395178 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     196 /     256             ( 76.56%) | total_pruned =      60 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  194144 /  589824             ( 32.92%) | total_pruned =  395680 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  406487 / 1179648             ( 34.46%) | total_pruned =  773161 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     491 /     512             ( 95.90%) | total_pruned =      21 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     428 /     512             ( 83.59%) | total_pruned =      84 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  527788 / 2359296             ( 22.37%) | total_pruned = 1831508 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   56772 /  131072             ( 43.31%) | total_pruned =   74300 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  289265 / 2359296             ( 12.26%) | total_pruned = 2070031 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     351 /     512             ( 68.55%) | total_pruned =     161 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     224 /     512             ( 43.75%) | total_pruned =     288 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  325912 / 2359296             ( 13.81%) | total_pruned = 2033384 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
linear.weight        | nonzeros =    4936 /    5120             ( 96.41%) | total_pruned =     184 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       9 /      10             ( 90.00%) | total_pruned =       1 | shape = torch.Size([10])
alive: 2930447, pruned : 8248315, total: 11178762, Compression rate :       3.81x  ( 73.79% pruned)
Train Epoch: 23/100 Loss: 0.000014 Accuracy: 86.63 100.00 % Best test Accuracy: 86.63%
tensor(-12.6861, device='cuda:0') tensor(1.8504, device='cuda:0') tensor(5.6557e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.137121
Average KL loss: 0.358841
Average total loss: 0.495962
tensor(-12.6910, device='cuda:0') tensor(1.7945, device='cuda:0') tensor(-1.5200e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.132335
Average KL loss: 0.358017
Average total loss: 0.490352
tensor(-12.6945, device='cuda:0') tensor(1.7634, device='cuda:0') tensor(9.3587e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.130789
Average KL loss: 0.357676
Average total loss: 0.488464
tensor(-12.6975, device='cuda:0') tensor(1.7423, device='cuda:0') tensor(4.4242e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.127274
Average KL loss: 0.357470
Average total loss: 0.484744
tensor(-12.7002, device='cuda:0') tensor(1.7268, device='cuda:0') tensor(7.0975e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.128137
Average KL loss: 0.357329
Average total loss: 0.485466
tensor(-12.7027, device='cuda:0') tensor(1.7148, device='cuda:0') tensor(-4.8930e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.124676
Average KL loss: 0.357228
Average total loss: 0.481904
tensor(-12.7050, device='cuda:0') tensor(1.7051, device='cuda:0') tensor(-5.1231e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.120809
Average KL loss: 0.357147
Average total loss: 0.477957
tensor(-12.7072, device='cuda:0') tensor(1.6970, device='cuda:0') tensor(-3.2668e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.122802
Average KL loss: 0.357078
Average total loss: 0.479880
tensor(-12.7093, device='cuda:0') tensor(1.6901, device='cuda:0') tensor(-1.1499e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.119653
Average KL loss: 0.357038
Average total loss: 0.476691
tensor(-12.7113, device='cuda:0') tensor(1.6841, device='cuda:0') tensor(-1.1212e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.118567
Average KL loss: 0.357013
Average total loss: 0.475581
tensor(-12.7132, device='cuda:0') tensor(1.6790, device='cuda:0') tensor(-1.0651e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.118975
Average KL loss: 0.356983
Average total loss: 0.475958
tensor(-12.7152, device='cuda:0') tensor(1.6743, device='cuda:0') tensor(-1.3164e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.118351
Average KL loss: 0.356952
Average total loss: 0.475303
tensor(-12.7170, device='cuda:0') tensor(1.6700, device='cuda:0') tensor(1.7774e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.115269
Average KL loss: 0.356932
Average total loss: 0.472201
tensor(-12.7189, device='cuda:0') tensor(1.6662, device='cuda:0') tensor(-1.1411e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.114517
Average KL loss: 0.356913
Average total loss: 0.471429
tensor(-12.7207, device='cuda:0') tensor(1.6626, device='cuda:0') tensor(4.0761e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.115372
Average KL loss: 0.356893
Average total loss: 0.472265
tensor(-12.7224, device='cuda:0') tensor(1.6593, device='cuda:0') tensor(4.4040e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.114461
Average KL loss: 0.356886
Average total loss: 0.471348
tensor(-12.7242, device='cuda:0') tensor(1.6562, device='cuda:0') tensor(-1.1056e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.113954
Average KL loss: 0.356869
Average total loss: 0.470823
tensor(-12.7259, device='cuda:0') tensor(1.6534, device='cuda:0') tensor(1.0523e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.113144
Average KL loss: 0.356848
Average total loss: 0.469992
tensor(-12.7276, device='cuda:0') tensor(1.6508, device='cuda:0') tensor(-2.8409e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.111627
Average KL loss: 0.356837
Average total loss: 0.468464
tensor(-12.7293, device='cuda:0') tensor(1.6483, device='cuda:0') tensor(-4.5440e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.109747
Average KL loss: 0.356827
Average total loss: 0.466574
tensor(-12.7309, device='cuda:0') tensor(1.6459, device='cuda:0') tensor(-1.7370e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.111102
Average KL loss: 0.356813
Average total loss: 0.467914
tensor(-12.7326, device='cuda:0') tensor(1.6436, device='cuda:0') tensor(-1.7259e-11, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.108847
Average KL loss: 0.356800
Average total loss: 0.465647
tensor(-12.7342, device='cuda:0') tensor(1.6415, device='cuda:0') tensor(-1.4257e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.109607
Average KL loss: 0.356794
Average total loss: 0.466402
tensor(-12.7358, device='cuda:0') tensor(1.6396, device='cuda:0') tensor(-6.8362e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.107665
Average KL loss: 0.356791
Average total loss: 0.464456
tensor(-12.7374, device='cuda:0') tensor(1.6377, device='cuda:0') tensor(-7.6640e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.107312
Average KL loss: 0.356786
Average total loss: 0.464098
tensor(-12.7390, device='cuda:0') tensor(1.6359, device='cuda:0') tensor(-1.7379e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.106652
Average KL loss: 0.356790
Average total loss: 0.463442
tensor(-12.7406, device='cuda:0') tensor(1.6342, device='cuda:0') tensor(-1.4347e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.107707
Average KL loss: 0.356783
Average total loss: 0.464490
tensor(-12.7421, device='cuda:0') tensor(1.6326, device='cuda:0') tensor(-2.3279e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.107454
Average KL loss: 0.356773
Average total loss: 0.464226
tensor(-12.7437, device='cuda:0') tensor(1.6311, device='cuda:0') tensor(-5.7229e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.105539
Average KL loss: 0.356764
Average total loss: 0.462303
tensor(-12.7452, device='cuda:0') tensor(1.6296, device='cuda:0') tensor(-1.4192e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.105800
Average KL loss: 0.356762
Average total loss: 0.462562
tensor(-12.7467, device='cuda:0') tensor(1.6282, device='cuda:0') tensor(-1.4334e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.107225
Average KL loss: 0.356741
Average total loss: 0.463966
tensor(-12.7483, device='cuda:0') tensor(1.6268, device='cuda:0') tensor(4.8408e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.106112
Average KL loss: 0.356722
Average total loss: 0.462834
tensor(-12.7498, device='cuda:0') tensor(1.6255, device='cuda:0') tensor(9.6613e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.104986
Average KL loss: 0.356720
Average total loss: 0.461706
tensor(-12.7513, device='cuda:0') tensor(1.6243, device='cuda:0') tensor(-5.8945e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.105352
Average KL loss: 0.356725
Average total loss: 0.462076
tensor(-12.7528, device='cuda:0') tensor(1.6231, device='cuda:0') tensor(-1.9128e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.104119
Average KL loss: 0.356725
Average total loss: 0.460844
tensor(-12.7542, device='cuda:0') tensor(1.6219, device='cuda:0') tensor(1.9944e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.100420
Average KL loss: 0.356723
Average total loss: 0.457143
tensor(-12.7557, device='cuda:0') tensor(1.6208, device='cuda:0') tensor(1.3962e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.102900
Average KL loss: 0.356733
Average total loss: 0.459633
tensor(-12.7572, device='cuda:0') tensor(1.6198, device='cuda:0') tensor(1.4298e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.101630
Average KL loss: 0.356732
Average total loss: 0.458362
tensor(-12.7587, device='cuda:0') tensor(1.6187, device='cuda:0') tensor(-3.3400e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.105250
Average KL loss: 0.356719
Average total loss: 0.461969
tensor(-12.7601, device='cuda:0') tensor(1.6177, device='cuda:0') tensor(1.9499e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.101377
Average KL loss: 0.356711
Average total loss: 0.458089
tensor(-12.7616, device='cuda:0') tensor(1.6167, device='cuda:0') tensor(1.7254e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.101727
Average KL loss: 0.356703
Average total loss: 0.458430
tensor(-12.7630, device='cuda:0') tensor(1.6158, device='cuda:0') tensor(-1.4437e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.099179
Average KL loss: 0.356714
Average total loss: 0.455893
tensor(-12.7644, device='cuda:0') tensor(1.6149, device='cuda:0') tensor(-5.7255e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.101996
Average KL loss: 0.356714
Average total loss: 0.458710
tensor(-12.7659, device='cuda:0') tensor(1.6140, device='cuda:0') tensor(4.1303e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.101885
Average KL loss: 0.356722
Average total loss: 0.458607
tensor(-12.7673, device='cuda:0') tensor(1.6131, device='cuda:0') tensor(-8.3665e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.100135
Average KL loss: 0.356724
Average total loss: 0.456859
tensor(-12.7687, device='cuda:0') tensor(1.6124, device='cuda:0') tensor(-4.3417e-11, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.098725
Average KL loss: 0.356725
Average total loss: 0.455450
tensor(-12.7701, device='cuda:0') tensor(1.6115, device='cuda:0') tensor(3.9677e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.100920
Average KL loss: 0.356719
Average total loss: 0.457639
tensor(-12.7715, device='cuda:0') tensor(1.6107, device='cuda:0') tensor(-1.1506e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.097883
Average KL loss: 0.356706
Average total loss: 0.454588
tensor(-12.7729, device='cuda:0') tensor(1.6100, device='cuda:0') tensor(-2.7351e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.098428
Average KL loss: 0.356696
Average total loss: 0.455124
tensor(-12.7743, device='cuda:0') tensor(1.6093, device='cuda:0') tensor(1.0173e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.097558
Average KL loss: 0.356675
Average total loss: 0.454233
tensor(-12.7757, device='cuda:0') tensor(1.6086, device='cuda:0') tensor(-5.4892e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.096080
Average KL loss: 0.356654
Average total loss: 0.452734
tensor(-12.7771, device='cuda:0') tensor(1.6079, device='cuda:0') tensor(-1.6812e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.097858
Average KL loss: 0.356633
Average total loss: 0.454491
tensor(-12.7785, device='cuda:0') tensor(1.6071, device='cuda:0') tensor(-4.1828e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.095988
Average KL loss: 0.356620
Average total loss: 0.452608
tensor(-12.7799, device='cuda:0') tensor(1.6065, device='cuda:0') tensor(7.3162e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.096366
Average KL loss: 0.356601
Average total loss: 0.452967
tensor(-12.7813, device='cuda:0') tensor(1.6058, device='cuda:0') tensor(5.5648e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.096645
Average KL loss: 0.356601
Average total loss: 0.453246
tensor(-12.7826, device='cuda:0') tensor(1.6052, device='cuda:0') tensor(-1.4183e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.095702
Average KL loss: 0.356594
Average total loss: 0.452295
tensor(-12.7840, device='cuda:0') tensor(1.6046, device='cuda:0') tensor(1.6157e-11, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.094838
Average KL loss: 0.356584
Average total loss: 0.451422
tensor(-12.7854, device='cuda:0') tensor(1.6040, device='cuda:0') tensor(-1.0100e-11, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.095890
Average KL loss: 0.356571
Average total loss: 0.452460
tensor(-12.7867, device='cuda:0') tensor(1.6034, device='cuda:0') tensor(2.7004e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.095602
Average KL loss: 0.356568
Average total loss: 0.452169
tensor(-12.7881, device='cuda:0') tensor(1.6029, device='cuda:0') tensor(-1.0695e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.094020
Average KL loss: 0.356562
Average total loss: 0.450582
tensor(-12.7894, device='cuda:0') tensor(1.6024, device='cuda:0') tensor(-1.5256e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.093523
Average KL loss: 0.356557
Average total loss: 0.450079
tensor(-12.7908, device='cuda:0') tensor(1.6019, device='cuda:0') tensor(-9.4754e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.095307
Average KL loss: 0.356557
Average total loss: 0.451864
tensor(-12.7921, device='cuda:0') tensor(1.6014, device='cuda:0') tensor(7.5414e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.093028
Average KL loss: 0.356548
Average total loss: 0.449576
tensor(-12.7935, device='cuda:0') tensor(1.6009, device='cuda:0') tensor(6.1228e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.092737
Average KL loss: 0.356522
Average total loss: 0.449259
tensor(-12.7948, device='cuda:0') tensor(1.6004, device='cuda:0') tensor(8.9449e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.093592
Average KL loss: 0.356512
Average total loss: 0.450104
tensor(-12.7961, device='cuda:0') tensor(1.5999, device='cuda:0') tensor(5.6822e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.091995
Average KL loss: 0.356515
Average total loss: 0.448510
tensor(-12.7975, device='cuda:0') tensor(1.5995, device='cuda:0') tensor(7.1375e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.092803
Average KL loss: 0.356506
Average total loss: 0.449308
tensor(-12.7988, device='cuda:0') tensor(1.5990, device='cuda:0') tensor(-1.9024e-11, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.094180
Average KL loss: 0.356494
Average total loss: 0.450674
tensor(-12.8001, device='cuda:0') tensor(1.5985, device='cuda:0') tensor(-2.2706e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.094202
Average KL loss: 0.356490
Average total loss: 0.450692
tensor(-12.8014, device='cuda:0') tensor(1.5982, device='cuda:0') tensor(1.0946e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.090460
Average KL loss: 0.356486
Average total loss: 0.446946
tensor(-12.8027, device='cuda:0') tensor(1.5977, device='cuda:0') tensor(-1.1230e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.093000
Average KL loss: 0.356465
Average total loss: 0.449466
tensor(-12.8041, device='cuda:0') tensor(1.5972, device='cuda:0') tensor(4.7558e-11, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.091394
Average KL loss: 0.356442
Average total loss: 0.447835
tensor(-12.8054, device='cuda:0') tensor(1.5969, device='cuda:0') tensor(-9.3512e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.090616
Average KL loss: 0.356435
Average total loss: 0.447051
tensor(-12.8067, device='cuda:0') tensor(1.5965, device='cuda:0') tensor(-8.4092e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.091515
Average KL loss: 0.356437
Average total loss: 0.447952
tensor(-12.8080, device='cuda:0') tensor(1.5961, device='cuda:0') tensor(1.6163e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.091456
Average KL loss: 0.356442
Average total loss: 0.447899
tensor(-12.8093, device='cuda:0') tensor(1.5958, device='cuda:0') tensor(3.3511e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.090669
Average KL loss: 0.356433
Average total loss: 0.447103
tensor(-12.8106, device='cuda:0') tensor(1.5954, device='cuda:0') tensor(-1.8042e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.088137
Average KL loss: 0.356427
Average total loss: 0.444564
tensor(-12.8118, device='cuda:0') tensor(1.5951, device='cuda:0') tensor(2.0687e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.088682
Average KL loss: 0.356415
Average total loss: 0.445096
tensor(-12.8131, device='cuda:0') tensor(1.5947, device='cuda:0') tensor(-1.1469e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.089485
Average KL loss: 0.356398
Average total loss: 0.445883
tensor(-12.8144, device='cuda:0') tensor(1.5944, device='cuda:0') tensor(-2.0915e-11, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.089093
Average KL loss: 0.356383
Average total loss: 0.445476
tensor(-12.8157, device='cuda:0') tensor(1.5940, device='cuda:0') tensor(-1.4480e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.088710
Average KL loss: 0.356372
Average total loss: 0.445082
tensor(-12.8170, device='cuda:0') tensor(1.5938, device='cuda:0') tensor(-7.0455e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.090102
Average KL loss: 0.356360
Average total loss: 0.446462
tensor(-12.8183, device='cuda:0') tensor(1.5934, device='cuda:0') tensor(-4.2902e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.089598
Average KL loss: 0.356340
Average total loss: 0.445938
tensor(-12.8195, device='cuda:0') tensor(1.5931, device='cuda:0') tensor(3.8754e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.088041
Average KL loss: 0.356324
Average total loss: 0.444365
tensor(-12.8208, device='cuda:0') tensor(1.5928, device='cuda:0') tensor(-1.7102e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.087612
Average KL loss: 0.356312
Average total loss: 0.443924
tensor(-12.8221, device='cuda:0') tensor(1.5924, device='cuda:0') tensor(7.8041e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.088553
Average KL loss: 0.356294
Average total loss: 0.444847
tensor(-12.8233, device='cuda:0') tensor(1.5922, device='cuda:0') tensor(-6.8608e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.087977
Average KL loss: 0.356283
Average total loss: 0.444260
tensor(-12.8246, device='cuda:0') tensor(1.5919, device='cuda:0') tensor(-1.4698e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.086637
Average KL loss: 0.356268
Average total loss: 0.442905
tensor(-12.8259, device='cuda:0') tensor(1.5916, device='cuda:0') tensor(1.8229e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.089376
Average KL loss: 0.356263
Average total loss: 0.445639
tensor(-12.8271, device='cuda:0') tensor(1.5914, device='cuda:0') tensor(5.9806e-11, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.087665
Average KL loss: 0.356272
Average total loss: 0.443938
tensor(-12.8284, device='cuda:0') tensor(1.5911, device='cuda:0') tensor(1.0013e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.086399
Average KL loss: 0.356264
Average total loss: 0.442662
tensor(-12.8296, device='cuda:0') tensor(1.5910, device='cuda:0') tensor(-7.2513e-11, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.088693
Average KL loss: 0.356247
Average total loss: 0.444940
tensor(-12.8309, device='cuda:0') tensor(1.5908, device='cuda:0') tensor(1.2611e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.086995
Average KL loss: 0.356229
Average total loss: 0.443224
tensor(-12.8321, device='cuda:0') tensor(1.5905, device='cuda:0') tensor(-2.3071e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.085598
Average KL loss: 0.356208
Average total loss: 0.441806
tensor(-12.8333, device='cuda:0') tensor(1.5904, device='cuda:0') tensor(-4.6542e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.086587
Average KL loss: 0.356200
Average total loss: 0.442786
tensor(-12.8346, device='cuda:0') tensor(1.5901, device='cuda:0') tensor(-5.0088e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.086002
Average KL loss: 0.356190
Average total loss: 0.442192
tensor(-12.8358, device='cuda:0') tensor(1.5899, device='cuda:0') tensor(-4.5276e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.086751
Average KL loss: 0.356174
Average total loss: 0.442925
tensor(-12.8371, device='cuda:0') tensor(1.5897, device='cuda:0') tensor(-2.3731e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.085709
Average KL loss: 0.356162
Average total loss: 0.441871
tensor(-12.8383, device='cuda:0') tensor(1.5894, device='cuda:0') tensor(-1.1068e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.084281
Average KL loss: 0.356146
Average total loss: 0.440428
tensor(-12.8395, device='cuda:0') tensor(1.5892, device='cuda:0') tensor(-1.6862e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.085748
Average KL loss: 0.356127
Average total loss: 0.441875
tensor(-12.8408, device='cuda:0') tensor(1.5889, device='cuda:0') tensor(-1.5068e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.084896
Average KL loss: 0.356121
Average total loss: 0.441018
tensor(-12.8420, device='cuda:0') tensor(1.5887, device='cuda:0') tensor(-1.6356e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.083482
Average KL loss: 0.356108
Average total loss: 0.439590
tensor(-12.8432, device='cuda:0') tensor(1.5886, device='cuda:0') tensor(-1.6274e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.084939
Average KL loss: 0.356103
Average total loss: 0.441041
tensor(-12.8445, device='cuda:0') tensor(1.5883, device='cuda:0') tensor(-7.4985e-12, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.085047
Average KL loss: 0.356081
Average total loss: 0.441127
tensor(-12.8457, device='cuda:0') tensor(1.5882, device='cuda:0') tensor(-4.6852e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.083508
Average KL loss: 0.356069
Average total loss: 0.439577
tensor(-12.8469, device='cuda:0') tensor(1.5880, device='cuda:0') tensor(-8.6544e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.084079
Average KL loss: 0.356062
Average total loss: 0.440141
tensor(-12.8481, device='cuda:0') tensor(1.5878, device='cuda:0') tensor(-3.0074e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.083268
Average KL loss: 0.356048
Average total loss: 0.439316
tensor(-12.8493, device='cuda:0') tensor(1.5876, device='cuda:0') tensor(6.9595e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.081907
Average KL loss: 0.356028
Average total loss: 0.437935
tensor(-12.8505, device='cuda:0') tensor(1.5874, device='cuda:0') tensor(2.4177e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.084488
Average KL loss: 0.356014
Average total loss: 0.440501
tensor(-12.8518, device='cuda:0') tensor(1.5873, device='cuda:0') tensor(-1.7916e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.085113
Average KL loss: 0.355995
Average total loss: 0.441107
tensor(-12.8530, device='cuda:0') tensor(1.5871, device='cuda:0') tensor(-6.3819e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.083217
Average KL loss: 0.355982
Average total loss: 0.439199
tensor(-12.8542, device='cuda:0') tensor(1.5870, device='cuda:0') tensor(2.1906e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.082189
Average KL loss: 0.355957
Average total loss: 0.438146
tensor(-12.8554, device='cuda:0') tensor(1.5868, device='cuda:0') tensor(-9.8714e-12, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.082725
Average KL loss: 0.355934
Average total loss: 0.438659
tensor(-12.8566, device='cuda:0') tensor(1.5866, device='cuda:0') tensor(8.6257e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.082547
Average KL loss: 0.355911
Average total loss: 0.438458
tensor(-12.8578, device='cuda:0') tensor(1.5864, device='cuda:0') tensor(-7.8654e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.080601
Average KL loss: 0.355889
Average total loss: 0.436490
tensor(-12.8590, device='cuda:0') tensor(1.5863, device='cuda:0') tensor(-1.3688e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.082214
Average KL loss: 0.355874
Average total loss: 0.438088
tensor(-12.8602, device='cuda:0') tensor(1.5861, device='cuda:0') tensor(-4.1804e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.082085
Average KL loss: 0.355851
Average total loss: 0.437936
tensor(-12.8614, device='cuda:0') tensor(1.5860, device='cuda:0') tensor(-1.0653e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.083358
Average KL loss: 0.355833
Average total loss: 0.439191
tensor(-12.8626, device='cuda:0') tensor(1.5858, device='cuda:0') tensor(-1.5441e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.083433
Average KL loss: 0.355818
Average total loss: 0.439251
tensor(-12.8638, device='cuda:0') tensor(1.5857, device='cuda:0') tensor(6.1294e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.080967
Average KL loss: 0.355799
Average total loss: 0.436766
tensor(-12.8650, device='cuda:0') tensor(1.5854, device='cuda:0') tensor(-9.0294e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.081845
Average KL loss: 0.355786
Average total loss: 0.437631
tensor(-12.8661, device='cuda:0') tensor(1.5853, device='cuda:0') tensor(-6.1334e-11, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.080770
Average KL loss: 0.355771
Average total loss: 0.436541
tensor(-12.8673, device='cuda:0') tensor(1.5852, device='cuda:0') tensor(-4.9515e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.081371
Average KL loss: 0.355759
Average total loss: 0.437130
tensor(-12.8685, device='cuda:0') tensor(1.5851, device='cuda:0') tensor(-1.5078e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.082080
Average KL loss: 0.355747
Average total loss: 0.437827
tensor(-12.8697, device='cuda:0') tensor(1.5849, device='cuda:0') tensor(-3.1289e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.081500
Average KL loss: 0.355729
Average total loss: 0.437229
tensor(-12.8709, device='cuda:0') tensor(1.5848, device='cuda:0') tensor(-3.6166e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.080308
Average KL loss: 0.355696
Average total loss: 0.436005
tensor(-12.8721, device='cuda:0') tensor(1.5847, device='cuda:0') tensor(-3.0582e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.081167
Average KL loss: 0.355670
Average total loss: 0.436837
tensor(-12.8732, device='cuda:0') tensor(1.5845, device='cuda:0') tensor(-1.0128e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.079418
Average KL loss: 0.355653
Average total loss: 0.435071
tensor(-12.8744, device='cuda:0') tensor(1.5844, device='cuda:0') tensor(1.6260e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.078983
Average KL loss: 0.355631
Average total loss: 0.434614
tensor(-12.8756, device='cuda:0') tensor(1.5843, device='cuda:0') tensor(-2.0378e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.080044
Average KL loss: 0.355628
Average total loss: 0.435672
tensor(-12.8768, device='cuda:0') tensor(1.5842, device='cuda:0') tensor(-5.7736e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.079613
Average KL loss: 0.355607
Average total loss: 0.435220
tensor(-12.8779, device='cuda:0') tensor(1.5840, device='cuda:0') tensor(9.1830e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.079120
Average KL loss: 0.355578
Average total loss: 0.434698
tensor(-12.8791, device='cuda:0') tensor(1.5839, device='cuda:0') tensor(-7.1143e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.078297
Average KL loss: 0.355552
Average total loss: 0.433848
tensor(-12.8803, device='cuda:0') tensor(1.5838, device='cuda:0') tensor(1.6156e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.078349
Average KL loss: 0.355524
Average total loss: 0.433873
tensor(-12.8814, device='cuda:0') tensor(1.5837, device='cuda:0') tensor(4.2423e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.080047
Average KL loss: 0.355498
Average total loss: 0.435545
tensor(-12.8826, device='cuda:0') tensor(1.5836, device='cuda:0') tensor(1.7502e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.078686
Average KL loss: 0.355479
Average total loss: 0.434165
tensor(-12.8838, device='cuda:0') tensor(1.5835, device='cuda:0') tensor(-3.4838e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.077704
Average KL loss: 0.355474
Average total loss: 0.433178
tensor(-12.8849, device='cuda:0') tensor(1.5834, device='cuda:0') tensor(7.0277e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.078842
Average KL loss: 0.355468
Average total loss: 0.434310
tensor(-12.8861, device='cuda:0') tensor(1.5833, device='cuda:0') tensor(6.7323e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.079199
Average KL loss: 0.355456
Average total loss: 0.434655
tensor(-12.8872, device='cuda:0') tensor(1.5832, device='cuda:0') tensor(6.0332e-11, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.077625
Average KL loss: 0.355448
Average total loss: 0.433073
tensor(-12.8884, device='cuda:0') tensor(1.5831, device='cuda:0') tensor(-8.8574e-11, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.078084
Average KL loss: 0.355426
Average total loss: 0.433509
tensor(-12.8896, device='cuda:0') tensor(1.5829, device='cuda:0') tensor(-1.1320e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.077279
Average KL loss: 0.355403
Average total loss: 0.432681
tensor(-12.8907, device='cuda:0') tensor(1.5829, device='cuda:0') tensor(-1.0493e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.076775
Average KL loss: 0.355387
Average total loss: 0.432162
tensor(-12.8918, device='cuda:0') tensor(1.5828, device='cuda:0') tensor(-1.0473e-11, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.076393
Average KL loss: 0.355373
Average total loss: 0.431766
tensor(-12.8930, device='cuda:0') tensor(1.5827, device='cuda:0') tensor(2.0904e-12, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.077059
Average KL loss: 0.355357
Average total loss: 0.432416
tensor(-12.8941, device='cuda:0') tensor(1.5826, device='cuda:0') tensor(8.4817e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.077696
Average KL loss: 0.355336
Average total loss: 0.433032
tensor(-12.8953, device='cuda:0') tensor(1.5825, device='cuda:0') tensor(-1.3525e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.077696
Average KL loss: 0.355322
Average total loss: 0.433018
tensor(-12.8964, device='cuda:0') tensor(1.5825, device='cuda:0') tensor(-5.3601e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.076205
Average KL loss: 0.355304
Average total loss: 0.431509
tensor(-12.8976, device='cuda:0') tensor(1.5824, device='cuda:0') tensor(-1.0825e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.076457
Average KL loss: 0.355287
Average total loss: 0.431744
tensor(-12.8987, device='cuda:0') tensor(1.5823, device='cuda:0') tensor(1.1050e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.076438
Average KL loss: 0.355263
Average total loss: 0.431701
tensor(-12.8999, device='cuda:0') tensor(1.5821, device='cuda:0') tensor(8.0150e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.075972
Average KL loss: 0.355238
Average total loss: 0.431209
tensor(-12.9010, device='cuda:0') tensor(1.5820, device='cuda:0') tensor(-7.1971e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.076710
Average KL loss: 0.355228
Average total loss: 0.431938
tensor(-12.9021, device='cuda:0') tensor(1.5819, device='cuda:0') tensor(-2.3821e-11, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.075640
Average KL loss: 0.355221
Average total loss: 0.430862
tensor(-12.9033, device='cuda:0') tensor(1.5818, device='cuda:0') tensor(1.5408e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.074451
Average KL loss: 0.355196
Average total loss: 0.429647
tensor(-12.9044, device='cuda:0') tensor(1.5817, device='cuda:0') tensor(-9.7377e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.075656
Average KL loss: 0.355184
Average total loss: 0.430840
tensor(-12.9055, device='cuda:0') tensor(1.5816, device='cuda:0') tensor(-2.6612e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.076937
Average KL loss: 0.355173
Average total loss: 0.432110
tensor(-12.9066, device='cuda:0') tensor(1.5815, device='cuda:0') tensor(-1.5262e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.076321
Average KL loss: 0.355156
Average total loss: 0.431477
tensor(-12.9078, device='cuda:0') tensor(1.5814, device='cuda:0') tensor(3.8980e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.075125
Average KL loss: 0.355149
Average total loss: 0.430274
tensor(-12.9089, device='cuda:0') tensor(1.5814, device='cuda:0') tensor(-1.4200e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.073504
Average KL loss: 0.355135
Average total loss: 0.428639
tensor(-12.9100, device='cuda:0') tensor(1.5813, device='cuda:0') tensor(-1.1158e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.076094
Average KL loss: 0.355115
Average total loss: 0.431209
tensor(-12.9112, device='cuda:0') tensor(1.5812, device='cuda:0') tensor(-4.3943e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.076043
Average KL loss: 0.355085
Average total loss: 0.431128
tensor(-12.9123, device='cuda:0') tensor(1.5811, device='cuda:0') tensor(5.5130e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.074443
Average KL loss: 0.355072
Average total loss: 0.429515
tensor(-12.9134, device='cuda:0') tensor(1.5810, device='cuda:0') tensor(-1.7049e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.075455
Average KL loss: 0.355059
Average total loss: 0.430515
tensor(-12.9145, device='cuda:0') tensor(1.5809, device='cuda:0') tensor(-1.5723e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.075766
Average KL loss: 0.355055
Average total loss: 0.430821
tensor(-12.9156, device='cuda:0') tensor(1.5809, device='cuda:0') tensor(1.3063e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.075169
Average KL loss: 0.355044
Average total loss: 0.430212
tensor(-12.9167, device='cuda:0') tensor(1.5809, device='cuda:0') tensor(-4.0013e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.075853
Average KL loss: 0.355039
Average total loss: 0.430892
tensor(-12.9179, device='cuda:0') tensor(1.5809, device='cuda:0') tensor(-4.0574e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.075189
Average KL loss: 0.355020
Average total loss: 0.430209
tensor(-12.9190, device='cuda:0') tensor(1.5808, device='cuda:0') tensor(5.8251e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.074689
Average KL loss: 0.355006
Average total loss: 0.429694
tensor(-12.9201, device='cuda:0') tensor(1.5808, device='cuda:0') tensor(4.0601e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.073200
Average KL loss: 0.354978
Average total loss: 0.428177
tensor(-12.9212, device='cuda:0') tensor(1.5806, device='cuda:0') tensor(8.5673e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.073090
Average KL loss: 0.354951
Average total loss: 0.428040
tensor(-12.9223, device='cuda:0') tensor(1.5805, device='cuda:0') tensor(5.4320e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.074156
Average KL loss: 0.354930
Average total loss: 0.429086
tensor(-12.9234, device='cuda:0') tensor(1.5805, device='cuda:0') tensor(-1.7164e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.074298
Average KL loss: 0.354916
Average total loss: 0.429215
tensor(-12.9245, device='cuda:0') tensor(1.5804, device='cuda:0') tensor(-5.8502e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.073028
Average KL loss: 0.354903
Average total loss: 0.427931
tensor(-12.9256, device='cuda:0') tensor(1.5803, device='cuda:0') tensor(6.7196e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.074596
Average KL loss: 0.354884
Average total loss: 0.429480
tensor(-12.9267, device='cuda:0') tensor(1.5803, device='cuda:0') tensor(4.9970e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.074260
Average KL loss: 0.354868
Average total loss: 0.429128
tensor(-12.9278, device='cuda:0') tensor(1.5802, device='cuda:0') tensor(-7.9271e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.073742
Average KL loss: 0.354864
Average total loss: 0.428606
tensor(-12.9289, device='cuda:0') tensor(1.5801, device='cuda:0') tensor(1.6666e-11, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.072442
Average KL loss: 0.354846
Average total loss: 0.427288
tensor(-12.9300, device='cuda:0') tensor(1.5801, device='cuda:0') tensor(3.2919e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.073001
Average KL loss: 0.354825
Average total loss: 0.427826
tensor(-12.9311, device='cuda:0') tensor(1.5800, device='cuda:0') tensor(5.7295e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.072481
Average KL loss: 0.354801
Average total loss: 0.427282
tensor(-12.9322, device='cuda:0') tensor(1.5799, device='cuda:0') tensor(1.8612e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.071846
Average KL loss: 0.354777
Average total loss: 0.426623
tensor(-12.9333, device='cuda:0') tensor(1.5798, device='cuda:0') tensor(1.6238e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.073446
Average KL loss: 0.354757
Average total loss: 0.428203
tensor(-12.9344, device='cuda:0') tensor(1.5798, device='cuda:0') tensor(7.9556e-11, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.072646
Average KL loss: 0.354755
Average total loss: 0.427400
tensor(-12.9355, device='cuda:0') tensor(1.5797, device='cuda:0') tensor(1.5594e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.073125
Average KL loss: 0.354742
Average total loss: 0.427867
tensor(-12.9366, device='cuda:0') tensor(1.5796, device='cuda:0') tensor(1.5933e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.072172
Average KL loss: 0.354715
Average total loss: 0.426887
tensor(-12.9377, device='cuda:0') tensor(1.5796, device='cuda:0') tensor(-6.3114e-11, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.073083
Average KL loss: 0.354698
Average total loss: 0.427781
tensor(-12.9388, device='cuda:0') tensor(1.5795, device='cuda:0') tensor(-1.3777e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.071901
Average KL loss: 0.354686
Average total loss: 0.426587
tensor(-12.9399, device='cuda:0') tensor(1.5795, device='cuda:0') tensor(-7.2036e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.072334
Average KL loss: 0.354670
Average total loss: 0.427004
tensor(-12.9410, device='cuda:0') tensor(1.5794, device='cuda:0') tensor(2.5318e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.070289
Average KL loss: 0.354649
Average total loss: 0.424938
tensor(-12.9420, device='cuda:0') tensor(1.5793, device='cuda:0') tensor(-5.9447e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.071203
Average KL loss: 0.354625
Average total loss: 0.425827
tensor(-12.9431, device='cuda:0') tensor(1.5793, device='cuda:0') tensor(-1.0892e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.070640
Average KL loss: 0.354604
Average total loss: 0.425244
tensor(-12.9442, device='cuda:0') tensor(1.5792, device='cuda:0') tensor(-5.0050e-11, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.071551
Average KL loss: 0.354588
Average total loss: 0.426140
tensor(-12.9453, device='cuda:0') tensor(1.5791, device='cuda:0') tensor(-2.6370e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.071556
Average KL loss: 0.354566
Average total loss: 0.426123
tensor(-12.9464, device='cuda:0') tensor(1.5790, device='cuda:0') tensor(8.9115e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.071430
Average KL loss: 0.354543
Average total loss: 0.425973
tensor(-12.9475, device='cuda:0') tensor(1.5789, device='cuda:0') tensor(-5.1900e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.069958
Average KL loss: 0.354527
Average total loss: 0.424486
tensor(-12.9485, device='cuda:0') tensor(1.5789, device='cuda:0') tensor(6.0090e-11, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.070897
Average KL loss: 0.354514
Average total loss: 0.425410
tensor(-12.9496, device='cuda:0') tensor(1.5789, device='cuda:0') tensor(-5.1329e-11, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.070462
Average KL loss: 0.354503
Average total loss: 0.424964
tensor(-12.9507, device='cuda:0') tensor(1.5789, device='cuda:0') tensor(-8.7991e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.071162
Average KL loss: 0.354493
Average total loss: 0.425655
tensor(-12.9518, device='cuda:0') tensor(1.5789, device='cuda:0') tensor(1.2319e-11, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.070424
Average KL loss: 0.354479
Average total loss: 0.424903
tensor(-12.9528, device='cuda:0') tensor(1.5788, device='cuda:0') tensor(-9.8427e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.070189
Average KL loss: 0.354465
Average total loss: 0.424654
tensor(-12.9539, device='cuda:0') tensor(1.5788, device='cuda:0') tensor(-9.3419e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.069079
Average KL loss: 0.354455
Average total loss: 0.423534
 Percentile value: -12.872237205505371
Non-zero model percentage: 20.971534729003906%, Non-zero mask percentage: 20.971534729003906%

--- Pruning Level [7/24]: ---
conv1.weight         | nonzeros =    1654 /    1728             ( 95.72%) | total_pruned =      74 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   23464 /   36864             ( 63.65%) | total_pruned =   13400 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   24011 /   36864             ( 65.13%) | total_pruned =   12853 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   22251 /   36864             ( 60.36%) | total_pruned =   14613 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   21727 /   36864             ( 58.94%) | total_pruned =   15137 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   44835 /   73728             ( 60.81%) | total_pruned =   28893 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   82197 /  147456             ( 55.74%) | total_pruned =   65259 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    6471 /    8192             ( 78.99%) | total_pruned =    1721 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   70219 /  147456             ( 47.62%) | total_pruned =   77237 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   71150 /  147456             ( 48.25%) | total_pruned =   76306 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  148208 /  294912             ( 50.25%) | total_pruned =  146704 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  257753 /  589824             ( 43.70%) | total_pruned =  332071 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   21891 /   32768             ( 66.81%) | total_pruned =   10877 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  156206 /  589824             ( 26.48%) | total_pruned =  433618 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     188 /     256             ( 73.44%) | total_pruned =      68 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  157422 /  589824             ( 26.69%) | total_pruned =  432402 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  324139 / 1179648             ( 27.48%) | total_pruned =  855509 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     472 /     512             ( 92.19%) | total_pruned =      40 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  398249 / 2359296             ( 16.88%) | total_pruned = 1961047 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   47144 /  131072             ( 35.97%) | total_pruned =   83928 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  210051 / 2359296             (  8.90%) | total_pruned = 2149245 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     320 /     512             ( 62.50%) | total_pruned =     192 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     200 /     512             ( 39.06%) | total_pruned =     312 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  241717 / 2359296             ( 10.25%) | total_pruned = 2117579 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
linear.weight        | nonzeros =    4849 /    5120             ( 94.71%) | total_pruned =     271 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       8 /      10             ( 80.00%) | total_pruned =       2 | shape = torch.Size([10])
alive: 2344358, pruned : 8834404, total: 11178762, Compression rate :       4.77x  ( 79.03% pruned)
Train Epoch: 22/100 Loss: 0.000007 Accuracy: 86.71 100.00 % Best test Accuracy: 86.71%
tensor(-12.9550, device='cuda:0') tensor(1.5787, device='cuda:0') tensor(-3.5666e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.151215
Average KL loss: 0.353705
Average total loss: 0.504920
tensor(-12.9581, device='cuda:0') tensor(1.5381, device='cuda:0') tensor(-2.1270e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.144451
Average KL loss: 0.353182
Average total loss: 0.497633
tensor(-12.9605, device='cuda:0') tensor(1.5155, device='cuda:0') tensor(2.0208e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.144918
Average KL loss: 0.352955
Average total loss: 0.497873
tensor(-12.9625, device='cuda:0') tensor(1.5006, device='cuda:0') tensor(-6.7810e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.142872
Average KL loss: 0.352832
Average total loss: 0.495703
tensor(-12.9643, device='cuda:0') tensor(1.4900, device='cuda:0') tensor(2.3397e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.139404
Average KL loss: 0.352749
Average total loss: 0.492153
tensor(-12.9660, device='cuda:0') tensor(1.4821, device='cuda:0') tensor(-1.1380e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.137260
Average KL loss: 0.352681
Average total loss: 0.489941
tensor(-12.9676, device='cuda:0') tensor(1.4760, device='cuda:0') tensor(-2.7674e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.135564
Average KL loss: 0.352628
Average total loss: 0.488192
tensor(-12.9691, device='cuda:0') tensor(1.4711, device='cuda:0') tensor(-6.8030e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.134865
Average KL loss: 0.352593
Average total loss: 0.487458
tensor(-12.9705, device='cuda:0') tensor(1.4671, device='cuda:0') tensor(-4.1844e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.132114
Average KL loss: 0.352564
Average total loss: 0.484678
tensor(-12.9720, device='cuda:0') tensor(1.4637, device='cuda:0') tensor(2.4252e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.132015
Average KL loss: 0.352540
Average total loss: 0.484555
tensor(-12.9734, device='cuda:0') tensor(1.4608, device='cuda:0') tensor(-5.5905e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.126839
Average KL loss: 0.352516
Average total loss: 0.479355
tensor(-12.9747, device='cuda:0') tensor(1.4582, device='cuda:0') tensor(-4.5026e-11, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.131707
Average KL loss: 0.352488
Average total loss: 0.484195
tensor(-12.9761, device='cuda:0') tensor(1.4559, device='cuda:0') tensor(-4.4765e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.127895
Average KL loss: 0.352462
Average total loss: 0.480357
tensor(-12.9774, device='cuda:0') tensor(1.4539, device='cuda:0') tensor(-2.8542e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.125364
Average KL loss: 0.352443
Average total loss: 0.477807
tensor(-12.9787, device='cuda:0') tensor(1.4520, device='cuda:0') tensor(-1.8727e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.124791
Average KL loss: 0.352433
Average total loss: 0.477224
tensor(-12.9800, device='cuda:0') tensor(1.4503, device='cuda:0') tensor(-1.2151e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.125216
Average KL loss: 0.352412
Average total loss: 0.477627
tensor(-12.9812, device='cuda:0') tensor(1.4488, device='cuda:0') tensor(-6.7503e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.123480
Average KL loss: 0.352403
Average total loss: 0.475884
tensor(-12.9825, device='cuda:0') tensor(1.4474, device='cuda:0') tensor(-1.1330e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.122212
Average KL loss: 0.352396
Average total loss: 0.474608
tensor(-12.9837, device='cuda:0') tensor(1.4460, device='cuda:0') tensor(1.6518e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.121333
Average KL loss: 0.352385
Average total loss: 0.473719
tensor(-12.9850, device='cuda:0') tensor(1.4448, device='cuda:0') tensor(-1.3043e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.120449
Average KL loss: 0.352386
Average total loss: 0.472835
tensor(-12.9862, device='cuda:0') tensor(1.4437, device='cuda:0') tensor(4.4538e-11, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.120804
Average KL loss: 0.352385
Average total loss: 0.473188
tensor(-12.9874, device='cuda:0') tensor(1.4426, device='cuda:0') tensor(2.1828e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.119447
Average KL loss: 0.352375
Average total loss: 0.471822
tensor(-12.9886, device='cuda:0') tensor(1.4416, device='cuda:0') tensor(8.4721e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.118684
Average KL loss: 0.352359
Average total loss: 0.471043
tensor(-12.9898, device='cuda:0') tensor(1.4405, device='cuda:0') tensor(-1.7907e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.117773
Average KL loss: 0.352340
Average total loss: 0.470113
tensor(-12.9910, device='cuda:0') tensor(1.4396, device='cuda:0') tensor(-1.0485e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.116882
Average KL loss: 0.352329
Average total loss: 0.469211
tensor(-12.9922, device='cuda:0') tensor(1.4387, device='cuda:0') tensor(-2.3710e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.115821
Average KL loss: 0.352324
Average total loss: 0.468145
tensor(-12.9934, device='cuda:0') tensor(1.4379, device='cuda:0') tensor(1.8611e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.114635
Average KL loss: 0.352325
Average total loss: 0.466960
tensor(-12.9946, device='cuda:0') tensor(1.4372, device='cuda:0') tensor(-7.9974e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.115297
Average KL loss: 0.352307
Average total loss: 0.467604
tensor(-12.9958, device='cuda:0') tensor(1.4365, device='cuda:0') tensor(-8.9946e-11, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.111993
Average KL loss: 0.352285
Average total loss: 0.464279
tensor(-12.9969, device='cuda:0') tensor(1.4357, device='cuda:0') tensor(-5.3708e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.113286
Average KL loss: 0.352267
Average total loss: 0.465553
tensor(-12.9981, device='cuda:0') tensor(1.4351, device='cuda:0') tensor(-1.2208e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.112603
Average KL loss: 0.352255
Average total loss: 0.464858
tensor(-12.9992, device='cuda:0') tensor(1.4344, device='cuda:0') tensor(-4.3367e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.110576
Average KL loss: 0.352237
Average total loss: 0.462812
tensor(-13.0004, device='cuda:0') tensor(1.4338, device='cuda:0') tensor(-1.9820e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.113039
Average KL loss: 0.352220
Average total loss: 0.465259
tensor(-13.0015, device='cuda:0') tensor(1.4332, device='cuda:0') tensor(1.4594e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.109557
Average KL loss: 0.352210
Average total loss: 0.461767
tensor(-13.0027, device='cuda:0') tensor(1.4326, device='cuda:0') tensor(3.6944e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.111189
Average KL loss: 0.352199
Average total loss: 0.463387
tensor(-13.0038, device='cuda:0') tensor(1.4320, device='cuda:0') tensor(-2.3744e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.108964
Average KL loss: 0.352188
Average total loss: 0.461152
tensor(-13.0049, device='cuda:0') tensor(1.4315, device='cuda:0') tensor(-3.1552e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.110864
Average KL loss: 0.352165
Average total loss: 0.463029
tensor(-13.0061, device='cuda:0') tensor(1.4310, device='cuda:0') tensor(-1.4134e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.106788
Average KL loss: 0.352143
Average total loss: 0.458931
tensor(-13.0072, device='cuda:0') tensor(1.4306, device='cuda:0') tensor(-7.9514e-12, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.107215
Average KL loss: 0.352115
Average total loss: 0.459330
tensor(-13.0083, device='cuda:0') tensor(1.4302, device='cuda:0') tensor(-3.2014e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.106124
Average KL loss: 0.352099
Average total loss: 0.458224
tensor(-13.0094, device='cuda:0') tensor(1.4298, device='cuda:0') tensor(-1.9752e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.106813
Average KL loss: 0.352081
Average total loss: 0.458894
tensor(-13.0105, device='cuda:0') tensor(1.4294, device='cuda:0') tensor(-6.9637e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.107746
Average KL loss: 0.352080
Average total loss: 0.459825
tensor(-13.0117, device='cuda:0') tensor(1.4290, device='cuda:0') tensor(-1.3198e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.106535
Average KL loss: 0.352071
Average total loss: 0.458606
tensor(-13.0128, device='cuda:0') tensor(1.4287, device='cuda:0') tensor(-2.8813e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.107184
Average KL loss: 0.352049
Average total loss: 0.459233
tensor(-13.0139, device='cuda:0') tensor(1.4284, device='cuda:0') tensor(4.7374e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.105023
Average KL loss: 0.352034
Average total loss: 0.457057
tensor(-13.0150, device='cuda:0') tensor(1.4281, device='cuda:0') tensor(-5.6344e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.105059
Average KL loss: 0.352018
Average total loss: 0.457077
tensor(-13.0160, device='cuda:0') tensor(1.4278, device='cuda:0') tensor(-1.4867e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.103922
Average KL loss: 0.351989
Average total loss: 0.455912
tensor(-13.0171, device='cuda:0') tensor(1.4274, device='cuda:0') tensor(-1.2889e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.105793
Average KL loss: 0.351971
Average total loss: 0.457764
tensor(-13.0182, device='cuda:0') tensor(1.4271, device='cuda:0') tensor(3.9448e-11, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.102070
Average KL loss: 0.351961
Average total loss: 0.454032
tensor(-13.0193, device='cuda:0') tensor(1.4269, device='cuda:0') tensor(-1.1188e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.103826
Average KL loss: 0.351953
Average total loss: 0.455779
tensor(-13.0204, device='cuda:0') tensor(1.4266, device='cuda:0') tensor(6.3241e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.101524
Average KL loss: 0.351933
Average total loss: 0.453457
tensor(-13.0215, device='cuda:0') tensor(1.4263, device='cuda:0') tensor(-2.2436e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.101023
Average KL loss: 0.351923
Average total loss: 0.452946
tensor(-13.0226, device='cuda:0') tensor(1.4261, device='cuda:0') tensor(-1.5984e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.101397
Average KL loss: 0.351912
Average total loss: 0.453308
tensor(-13.0237, device='cuda:0') tensor(1.4257, device='cuda:0') tensor(-3.5657e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.102218
Average KL loss: 0.351894
Average total loss: 0.454112
tensor(-13.0247, device='cuda:0') tensor(1.4255, device='cuda:0') tensor(-1.2919e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.100920
Average KL loss: 0.351878
Average total loss: 0.452798
tensor(-13.0258, device='cuda:0') tensor(1.4253, device='cuda:0') tensor(-5.1875e-11, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.097919
Average KL loss: 0.351864
Average total loss: 0.449783
tensor(-13.0269, device='cuda:0') tensor(1.4251, device='cuda:0') tensor(5.6403e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.100649
Average KL loss: 0.351851
Average total loss: 0.452500
tensor(-13.0279, device='cuda:0') tensor(1.4249, device='cuda:0') tensor(-2.5701e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.099399
Average KL loss: 0.351842
Average total loss: 0.451241
tensor(-13.0290, device='cuda:0') tensor(1.4247, device='cuda:0') tensor(-1.2073e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.099383
Average KL loss: 0.351831
Average total loss: 0.451214
tensor(-13.0301, device='cuda:0') tensor(1.4245, device='cuda:0') tensor(-1.1121e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.096883
Average KL loss: 0.351822
Average total loss: 0.448705
tensor(-13.0311, device='cuda:0') tensor(1.4243, device='cuda:0') tensor(-1.0590e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.100152
Average KL loss: 0.351805
Average total loss: 0.451956
tensor(-13.0322, device='cuda:0') tensor(1.4242, device='cuda:0') tensor(1.8337e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.097189
Average KL loss: 0.351788
Average total loss: 0.448977
tensor(-13.0332, device='cuda:0') tensor(1.4240, device='cuda:0') tensor(-2.1785e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.098211
Average KL loss: 0.351777
Average total loss: 0.449988
tensor(-13.0343, device='cuda:0') tensor(1.4239, device='cuda:0') tensor(-1.2157e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.097053
Average KL loss: 0.351779
Average total loss: 0.448832
tensor(-13.0353, device='cuda:0') tensor(1.4237, device='cuda:0') tensor(6.3519e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.096478
Average KL loss: 0.351771
Average total loss: 0.448249
tensor(-13.0364, device='cuda:0') tensor(1.4236, device='cuda:0') tensor(-9.3055e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.097367
Average KL loss: 0.351751
Average total loss: 0.449118
tensor(-13.0374, device='cuda:0') tensor(1.4235, device='cuda:0') tensor(8.2405e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.095603
Average KL loss: 0.351744
Average total loss: 0.447347
tensor(-13.0385, device='cuda:0') tensor(1.4233, device='cuda:0') tensor(-1.2741e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.096236
Average KL loss: 0.351731
Average total loss: 0.447966
tensor(-13.0395, device='cuda:0') tensor(1.4232, device='cuda:0') tensor(-3.2790e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.096170
Average KL loss: 0.351725
Average total loss: 0.447894
tensor(-13.0406, device='cuda:0') tensor(1.4231, device='cuda:0') tensor(1.2006e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.093574
Average KL loss: 0.351700
Average total loss: 0.445274
tensor(-13.0416, device='cuda:0') tensor(1.4230, device='cuda:0') tensor(1.0316e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.095181
Average KL loss: 0.351677
Average total loss: 0.446858
tensor(-13.0427, device='cuda:0') tensor(1.4229, device='cuda:0') tensor(-1.3866e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.095538
Average KL loss: 0.351656
Average total loss: 0.447195
tensor(-13.0437, device='cuda:0') tensor(1.4229, device='cuda:0') tensor(3.8611e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.092086
Average KL loss: 0.351635
Average total loss: 0.443720
tensor(-13.0447, device='cuda:0') tensor(1.4228, device='cuda:0') tensor(-5.1364e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.093969
Average KL loss: 0.351620
Average total loss: 0.445589
tensor(-13.0458, device='cuda:0') tensor(1.4227, device='cuda:0') tensor(-1.9460e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.094660
Average KL loss: 0.351610
Average total loss: 0.446270
tensor(-13.0468, device='cuda:0') tensor(1.4227, device='cuda:0') tensor(-8.2607e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.095283
Average KL loss: 0.351601
Average total loss: 0.446885
tensor(-13.0478, device='cuda:0') tensor(1.4227, device='cuda:0') tensor(5.3588e-11, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.094160
Average KL loss: 0.351600
Average total loss: 0.445760
tensor(-13.0488, device='cuda:0') tensor(1.4227, device='cuda:0') tensor(-1.3911e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.092318
Average KL loss: 0.351591
Average total loss: 0.443910
tensor(-13.0499, device='cuda:0') tensor(1.4227, device='cuda:0') tensor(-8.5225e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.092400
Average KL loss: 0.351576
Average total loss: 0.443976
tensor(-13.0509, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(-6.8370e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.091897
Average KL loss: 0.351564
Average total loss: 0.443460
tensor(-13.0519, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(-1.0954e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.093499
Average KL loss: 0.351557
Average total loss: 0.445056
tensor(-13.0529, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(1.5915e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.091048
Average KL loss: 0.351551
Average total loss: 0.442598
tensor(-13.0539, device='cuda:0') tensor(1.4226, device='cuda:0') tensor(9.5643e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.091656
Average KL loss: 0.351543
Average total loss: 0.443199
tensor(-13.0549, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(-7.2945e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.092615
Average KL loss: 0.351520
Average total loss: 0.444135
tensor(-13.0560, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(1.8926e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.092754
Average KL loss: 0.351504
Average total loss: 0.444258
tensor(-13.0570, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(-2.1704e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.089789
Average KL loss: 0.351475
Average total loss: 0.441264
tensor(-13.0580, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(-2.1132e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.091865
Average KL loss: 0.351451
Average total loss: 0.443316
tensor(-13.0590, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(9.1118e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.087701
Average KL loss: 0.351441
Average total loss: 0.439142
tensor(-13.0600, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(-4.9758e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.088278
Average KL loss: 0.351427
Average total loss: 0.439705
tensor(-13.0610, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(-4.4274e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.088206
Average KL loss: 0.351420
Average total loss: 0.439626
tensor(-13.0620, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(4.1906e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.088671
Average KL loss: 0.351406
Average total loss: 0.440077
tensor(-13.0630, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(-5.1711e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.089695
Average KL loss: 0.351399
Average total loss: 0.441094
tensor(-13.0640, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(-1.8966e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.088079
Average KL loss: 0.351385
Average total loss: 0.439464
tensor(-13.0650, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(-7.8901e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.089286
Average KL loss: 0.351380
Average total loss: 0.440666
tensor(-13.0660, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(-1.5309e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.088142
Average KL loss: 0.351363
Average total loss: 0.439505
tensor(-13.0670, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(-2.5459e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.088201
Average KL loss: 0.351352
Average total loss: 0.439552
tensor(-13.0680, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(-2.7411e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.087551
Average KL loss: 0.351334
Average total loss: 0.438885
tensor(-13.0690, device='cuda:0') tensor(1.4225, device='cuda:0') tensor(-1.7637e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.090528
Average KL loss: 0.351316
Average total loss: 0.441844
tensor(-13.0700, device='cuda:0') tensor(1.4226, device='cuda:0') tensor(-4.0373e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.087893
Average KL loss: 0.351305
Average total loss: 0.439198
tensor(-13.0709, device='cuda:0') tensor(1.4226, device='cuda:0') tensor(-9.9848e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.088412
Average KL loss: 0.351286
Average total loss: 0.439698
tensor(-13.0719, device='cuda:0') tensor(1.4226, device='cuda:0') tensor(-3.7203e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.086706
Average KL loss: 0.351261
Average total loss: 0.437966
tensor(-13.0729, device='cuda:0') tensor(1.4226, device='cuda:0') tensor(-1.1077e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.087132
Average KL loss: 0.351242
Average total loss: 0.438374
tensor(-13.0739, device='cuda:0') tensor(1.4226, device='cuda:0') tensor(-1.5331e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.085843
Average KL loss: 0.351228
Average total loss: 0.437072
tensor(-13.0749, device='cuda:0') tensor(1.4226, device='cuda:0') tensor(-5.0577e-11, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.086058
Average KL loss: 0.351214
Average total loss: 0.437273
tensor(-13.0759, device='cuda:0') tensor(1.4227, device='cuda:0') tensor(1.3962e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.087173
Average KL loss: 0.351202
Average total loss: 0.438375
tensor(-13.0769, device='cuda:0') tensor(1.4227, device='cuda:0') tensor(-7.2885e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.084842
Average KL loss: 0.351186
Average total loss: 0.436029
tensor(-13.0778, device='cuda:0') tensor(1.4227, device='cuda:0') tensor(-6.6738e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.085077
Average KL loss: 0.351181
Average total loss: 0.436258
tensor(-13.0788, device='cuda:0') tensor(1.4228, device='cuda:0') tensor(-8.8348e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.085823
Average KL loss: 0.351175
Average total loss: 0.436997
tensor(-13.0798, device='cuda:0') tensor(1.4228, device='cuda:0') tensor(-1.7176e-11, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.085083
Average KL loss: 0.351165
Average total loss: 0.436247
tensor(-13.0808, device='cuda:0') tensor(1.4229, device='cuda:0') tensor(-1.3508e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.084026
Average KL loss: 0.351148
Average total loss: 0.435174
tensor(-13.0817, device='cuda:0') tensor(1.4229, device='cuda:0') tensor(-1.0883e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.084335
Average KL loss: 0.351116
Average total loss: 0.435450
tensor(-13.0827, device='cuda:0') tensor(1.4229, device='cuda:0') tensor(-1.7873e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.085184
Average KL loss: 0.351094
Average total loss: 0.436278
tensor(-13.0837, device='cuda:0') tensor(1.4229, device='cuda:0') tensor(-1.0271e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.085058
Average KL loss: 0.351089
Average total loss: 0.436147
tensor(-13.0846, device='cuda:0') tensor(1.4230, device='cuda:0') tensor(-1.3749e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.083873
Average KL loss: 0.351081
Average total loss: 0.434954
tensor(-13.0856, device='cuda:0') tensor(1.4230, device='cuda:0') tensor(7.6067e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.085139
Average KL loss: 0.351067
Average total loss: 0.436206
tensor(-13.0866, device='cuda:0') tensor(1.4231, device='cuda:0') tensor(6.0099e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.084449
Average KL loss: 0.351048
Average total loss: 0.435497
tensor(-13.0875, device='cuda:0') tensor(1.4231, device='cuda:0') tensor(-1.1894e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.083159
Average KL loss: 0.351037
Average total loss: 0.434196
tensor(-13.0885, device='cuda:0') tensor(1.4232, device='cuda:0') tensor(3.6455e-11, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.083887
Average KL loss: 0.351038
Average total loss: 0.434926
tensor(-13.0895, device='cuda:0') tensor(1.4234, device='cuda:0') tensor(-7.4181e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.084624
Average KL loss: 0.351026
Average total loss: 0.435651
tensor(-13.0904, device='cuda:0') tensor(1.4234, device='cuda:0') tensor(-6.3391e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.081609
Average KL loss: 0.351008
Average total loss: 0.432617
tensor(-13.0914, device='cuda:0') tensor(1.4235, device='cuda:0') tensor(-4.8841e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.083019
Average KL loss: 0.350994
Average total loss: 0.434013
tensor(-13.0923, device='cuda:0') tensor(1.4236, device='cuda:0') tensor(1.6355e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.083032
Average KL loss: 0.350988
Average total loss: 0.434020
tensor(-13.0933, device='cuda:0') tensor(1.4237, device='cuda:0') tensor(-5.3422e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.082437
Average KL loss: 0.350984
Average total loss: 0.433421
tensor(-13.0942, device='cuda:0') tensor(1.4237, device='cuda:0') tensor(-1.9148e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.081232
Average KL loss: 0.350964
Average total loss: 0.432196
tensor(-13.0952, device='cuda:0') tensor(1.4237, device='cuda:0') tensor(-1.3372e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.080446
Average KL loss: 0.350931
Average total loss: 0.431377
tensor(-13.0962, device='cuda:0') tensor(1.4238, device='cuda:0') tensor(-1.0205e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.081522
Average KL loss: 0.350915
Average total loss: 0.432437
tensor(-13.0971, device='cuda:0') tensor(1.4239, device='cuda:0') tensor(6.9762e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.082455
Average KL loss: 0.350904
Average total loss: 0.433360
tensor(-13.0981, device='cuda:0') tensor(1.4240, device='cuda:0') tensor(7.1452e-11, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.081866
Average KL loss: 0.350892
Average total loss: 0.432758
tensor(-13.0990, device='cuda:0') tensor(1.4240, device='cuda:0') tensor(-1.4104e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.080325
Average KL loss: 0.350881
Average total loss: 0.431205
tensor(-13.1000, device='cuda:0') tensor(1.4241, device='cuda:0') tensor(-6.5869e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.081992
Average KL loss: 0.350868
Average total loss: 0.432861
tensor(-13.1009, device='cuda:0') tensor(1.4242, device='cuda:0') tensor(1.0457e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.080087
Average KL loss: 0.350843
Average total loss: 0.430929
tensor(-13.1018, device='cuda:0') tensor(1.4243, device='cuda:0') tensor(1.2059e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.082354
Average KL loss: 0.350821
Average total loss: 0.433176
tensor(-13.1028, device='cuda:0') tensor(1.4244, device='cuda:0') tensor(-1.1501e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.080294
Average KL loss: 0.350797
Average total loss: 0.431091
tensor(-13.1037, device='cuda:0') tensor(1.4244, device='cuda:0') tensor(-1.6686e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.080445
Average KL loss: 0.350780
Average total loss: 0.431226
tensor(-13.1047, device='cuda:0') tensor(1.4244, device='cuda:0') tensor(-7.5596e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.079964
Average KL loss: 0.350765
Average total loss: 0.430729
tensor(-13.1056, device='cuda:0') tensor(1.4245, device='cuda:0') tensor(1.1469e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.081338
Average KL loss: 0.350759
Average total loss: 0.432097
tensor(-13.1066, device='cuda:0') tensor(1.4246, device='cuda:0') tensor(2.5844e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.078848
Average KL loss: 0.350754
Average total loss: 0.429602
tensor(-13.1075, device='cuda:0') tensor(1.4247, device='cuda:0') tensor(-3.0266e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.080063
Average KL loss: 0.350734
Average total loss: 0.430797
tensor(-13.1085, device='cuda:0') tensor(1.4248, device='cuda:0') tensor(-1.6320e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.080616
Average KL loss: 0.350713
Average total loss: 0.431330
tensor(-13.1094, device='cuda:0') tensor(1.4248, device='cuda:0') tensor(1.3675e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.080658
Average KL loss: 0.350695
Average total loss: 0.431354
tensor(-13.1103, device='cuda:0') tensor(1.4249, device='cuda:0') tensor(-9.1560e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.078566
Average KL loss: 0.350682
Average total loss: 0.429248
tensor(-13.1113, device='cuda:0') tensor(1.4250, device='cuda:0') tensor(-4.3316e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.078870
Average KL loss: 0.350668
Average total loss: 0.429538
tensor(-13.1122, device='cuda:0') tensor(1.4250, device='cuda:0') tensor(-4.6244e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.077852
Average KL loss: 0.350661
Average total loss: 0.428513
tensor(-13.1132, device='cuda:0') tensor(1.4251, device='cuda:0') tensor(6.9827e-11, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.078922
Average KL loss: 0.350647
Average total loss: 0.429569
tensor(-13.1141, device='cuda:0') tensor(1.4252, device='cuda:0') tensor(5.0681e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.079699
Average KL loss: 0.350624
Average total loss: 0.430323
tensor(-13.1150, device='cuda:0') tensor(1.4253, device='cuda:0') tensor(-3.2352e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.079091
Average KL loss: 0.350605
Average total loss: 0.429696
tensor(-13.1160, device='cuda:0') tensor(1.4253, device='cuda:0') tensor(-9.7549e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.077137
Average KL loss: 0.350584
Average total loss: 0.427720
tensor(-13.1169, device='cuda:0') tensor(1.4254, device='cuda:0') tensor(2.8657e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.078112
Average KL loss: 0.350574
Average total loss: 0.428686
tensor(-13.1178, device='cuda:0') tensor(1.4255, device='cuda:0') tensor(-5.2478e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.078010
Average KL loss: 0.350561
Average total loss: 0.428571
tensor(-13.1188, device='cuda:0') tensor(1.4256, device='cuda:0') tensor(-5.3379e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.079434
Average KL loss: 0.350552
Average total loss: 0.429986
tensor(-13.1197, device='cuda:0') tensor(1.4256, device='cuda:0') tensor(-8.0025e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.077126
Average KL loss: 0.350536
Average total loss: 0.427662
tensor(-13.1206, device='cuda:0') tensor(1.4257, device='cuda:0') tensor(7.3918e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.078709
Average KL loss: 0.350511
Average total loss: 0.429220
tensor(-13.1215, device='cuda:0') tensor(1.4259, device='cuda:0') tensor(-1.4909e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.078106
Average KL loss: 0.350507
Average total loss: 0.428613
tensor(-13.1225, device='cuda:0') tensor(1.4260, device='cuda:0') tensor(2.5843e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.077558
Average KL loss: 0.350500
Average total loss: 0.428058
tensor(-13.1234, device='cuda:0') tensor(1.4261, device='cuda:0') tensor(-8.9534e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.078856
Average KL loss: 0.350479
Average total loss: 0.429336
tensor(-13.1243, device='cuda:0') tensor(1.4262, device='cuda:0') tensor(-5.1025e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.077258
Average KL loss: 0.350462
Average total loss: 0.427721
tensor(-13.1252, device='cuda:0') tensor(1.4263, device='cuda:0') tensor(-2.2043e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.075627
Average KL loss: 0.350451
Average total loss: 0.426078
tensor(-13.1262, device='cuda:0') tensor(1.4263, device='cuda:0') tensor(-3.5477e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.076146
Average KL loss: 0.350433
Average total loss: 0.426579
tensor(-13.1271, device='cuda:0') tensor(1.4263, device='cuda:0') tensor(8.1700e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.077331
Average KL loss: 0.350420
Average total loss: 0.427751
tensor(-13.1280, device='cuda:0') tensor(1.4264, device='cuda:0') tensor(-8.1870e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.077884
Average KL loss: 0.350416
Average total loss: 0.428301
tensor(-13.1289, device='cuda:0') tensor(1.4265, device='cuda:0') tensor(2.4466e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.077405
Average KL loss: 0.350409
Average total loss: 0.427815
tensor(-13.1299, device='cuda:0') tensor(1.4266, device='cuda:0') tensor(-6.8639e-11, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.076229
Average KL loss: 0.350397
Average total loss: 0.426626
tensor(-13.1308, device='cuda:0') tensor(1.4267, device='cuda:0') tensor(-5.7636e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.076497
Average KL loss: 0.350377
Average total loss: 0.426874
tensor(-13.1317, device='cuda:0') tensor(1.4269, device='cuda:0') tensor(-3.7191e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.074905
Average KL loss: 0.350359
Average total loss: 0.425264
tensor(-13.1326, device='cuda:0') tensor(1.4270, device='cuda:0') tensor(-1.6644e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.075797
Average KL loss: 0.350346
Average total loss: 0.426143
tensor(-13.1335, device='cuda:0') tensor(1.4270, device='cuda:0') tensor(-6.6174e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.076336
Average KL loss: 0.350338
Average total loss: 0.426673
tensor(-13.1344, device='cuda:0') tensor(1.4271, device='cuda:0') tensor(2.7110e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.075668
Average KL loss: 0.350326
Average total loss: 0.425995
tensor(-13.1353, device='cuda:0') tensor(1.4272, device='cuda:0') tensor(1.7809e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.076024
Average KL loss: 0.350309
Average total loss: 0.426333
tensor(-13.1363, device='cuda:0') tensor(1.4272, device='cuda:0') tensor(-3.4301e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.075288
Average KL loss: 0.350301
Average total loss: 0.425589
tensor(-13.1372, device='cuda:0') tensor(1.4273, device='cuda:0') tensor(-9.7921e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.076872
Average KL loss: 0.350293
Average total loss: 0.427164
tensor(-13.1381, device='cuda:0') tensor(1.4275, device='cuda:0') tensor(4.8525e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.077644
Average KL loss: 0.350285
Average total loss: 0.427929
tensor(-13.1390, device='cuda:0') tensor(1.4276, device='cuda:0') tensor(-3.4594e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.075924
Average KL loss: 0.350276
Average total loss: 0.426200
tensor(-13.1399, device='cuda:0') tensor(1.4278, device='cuda:0') tensor(1.6556e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.074950
Average KL loss: 0.350259
Average total loss: 0.425209
tensor(-13.1408, device='cuda:0') tensor(1.4279, device='cuda:0') tensor(-1.9191e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.075469
Average KL loss: 0.350238
Average total loss: 0.425706
tensor(-13.1417, device='cuda:0') tensor(1.4280, device='cuda:0') tensor(-2.0133e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.074688
Average KL loss: 0.350230
Average total loss: 0.424917
tensor(-13.1426, device='cuda:0') tensor(1.4281, device='cuda:0') tensor(7.4010e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.075350
Average KL loss: 0.350212
Average total loss: 0.425562
tensor(-13.1435, device='cuda:0') tensor(1.4282, device='cuda:0') tensor(-3.1149e-11, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.074566
Average KL loss: 0.350199
Average total loss: 0.424765
tensor(-13.1444, device='cuda:0') tensor(1.4283, device='cuda:0') tensor(-4.8088e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.075534
Average KL loss: 0.350184
Average total loss: 0.425718
tensor(-13.1453, device='cuda:0') tensor(1.4284, device='cuda:0') tensor(-8.7089e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.074248
Average KL loss: 0.350171
Average total loss: 0.424419
tensor(-13.1462, device='cuda:0') tensor(1.4286, device='cuda:0') tensor(-4.9442e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.074346
Average KL loss: 0.350144
Average total loss: 0.424490
tensor(-13.1471, device='cuda:0') tensor(1.4287, device='cuda:0') tensor(2.7599e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.074580
Average KL loss: 0.350126
Average total loss: 0.424706
tensor(-13.1480, device='cuda:0') tensor(1.4288, device='cuda:0') tensor(-2.6484e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.075006
Average KL loss: 0.350105
Average total loss: 0.425111
tensor(-13.1489, device='cuda:0') tensor(1.4290, device='cuda:0') tensor(1.1246e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.073703
Average KL loss: 0.350090
Average total loss: 0.423793
tensor(-13.1498, device='cuda:0') tensor(1.4291, device='cuda:0') tensor(-4.1719e-11, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.073721
Average KL loss: 0.350078
Average total loss: 0.423799
tensor(-13.1507, device='cuda:0') tensor(1.4292, device='cuda:0') tensor(-4.2508e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.073009
Average KL loss: 0.350061
Average total loss: 0.423070
tensor(-13.1516, device='cuda:0') tensor(1.4293, device='cuda:0') tensor(-1.1851e-11, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.073807
Average KL loss: 0.350038
Average total loss: 0.423846
tensor(-13.1525, device='cuda:0') tensor(1.4294, device='cuda:0') tensor(-1.1624e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.073087
Average KL loss: 0.350020
Average total loss: 0.423107
tensor(-13.1533, device='cuda:0') tensor(1.4295, device='cuda:0') tensor(1.3057e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.072652
Average KL loss: 0.349992
Average total loss: 0.422644
tensor(-13.1542, device='cuda:0') tensor(1.4296, device='cuda:0') tensor(4.0297e-11, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.072534
Average KL loss: 0.349974
Average total loss: 0.422508
tensor(-13.1551, device='cuda:0') tensor(1.4297, device='cuda:0') tensor(-1.6815e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.074396
Average KL loss: 0.349958
Average total loss: 0.424354
tensor(-13.1560, device='cuda:0') tensor(1.4298, device='cuda:0') tensor(6.9575e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.073576
Average KL loss: 0.349954
Average total loss: 0.423530
tensor(-13.1569, device='cuda:0') tensor(1.4299, device='cuda:0') tensor(-1.2677e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.072385
Average KL loss: 0.349937
Average total loss: 0.422323
tensor(-13.1578, device='cuda:0') tensor(1.4300, device='cuda:0') tensor(6.7511e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.073433
Average KL loss: 0.349921
Average total loss: 0.423355
tensor(-13.1587, device='cuda:0') tensor(1.4301, device='cuda:0') tensor(2.5365e-11, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.071884
Average KL loss: 0.349908
Average total loss: 0.421792
tensor(-13.1596, device='cuda:0') tensor(1.4302, device='cuda:0') tensor(-8.3891e-12, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.071549
Average KL loss: 0.349890
Average total loss: 0.421439
tensor(-13.1604, device='cuda:0') tensor(1.4303, device='cuda:0') tensor(1.0570e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.070517
Average KL loss: 0.349861
Average total loss: 0.420379
tensor(-13.1613, device='cuda:0') tensor(1.4302, device='cuda:0') tensor(-3.9802e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.073284
Average KL loss: 0.349833
Average total loss: 0.423117
tensor(-13.1622, device='cuda:0') tensor(1.4303, device='cuda:0') tensor(-7.7948e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.072694
Average KL loss: 0.349824
Average total loss: 0.422518
tensor(-13.1631, device='cuda:0') tensor(1.4305, device='cuda:0') tensor(1.1912e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.071138
Average KL loss: 0.349816
Average total loss: 0.420954
tensor(-13.1640, device='cuda:0') tensor(1.4305, device='cuda:0') tensor(3.8086e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.071008
Average KL loss: 0.349791
Average total loss: 0.420799
 Percentile value: -13.038828659057618
Non-zero model percentage: 16.777233123779297%, Non-zero mask percentage: 16.777233123779297%

--- Pruning Level [8/24]: ---
conv1.weight         | nonzeros =    1626 /    1728             ( 94.10%) | total_pruned =     102 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   21219 /   36864             ( 57.56%) | total_pruned =   15645 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   21785 /   36864             ( 59.10%) | total_pruned =   15079 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   19868 /   36864             ( 53.90%) | total_pruned =   16996 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   19254 /   36864             ( 52.23%) | total_pruned =   17610 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   40350 /   73728             ( 54.73%) | total_pruned =   33378 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   72777 /  147456             ( 49.36%) | total_pruned =   74679 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    6114 /    8192             ( 74.63%) | total_pruned =    2078 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   60338 /  147456             ( 40.92%) | total_pruned =   87118 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   61061 /  147456             ( 41.41%) | total_pruned =   86395 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  128877 /  294912             ( 43.70%) | total_pruned =  166035 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  217677 /  589824             ( 36.91%) | total_pruned =  372147 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   19913 /   32768             ( 60.77%) | total_pruned =   12855 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  123694 /  589824             ( 20.97%) | total_pruned =  466130 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     212 /     256             ( 82.81%) | total_pruned =      44 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     180 /     256             ( 70.31%) | total_pruned =      76 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  125192 /  589824             ( 21.23%) | total_pruned =  464632 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  256948 / 1179648             ( 21.78%) | total_pruned =  922700 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     450 /     512             ( 87.89%) | total_pruned =      62 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     372 /     512             ( 72.66%) | total_pruned =     140 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  297862 / 2359296             ( 12.63%) | total_pruned = 2061434 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     491 /     512             ( 95.90%) | total_pruned =      21 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   39328 /  131072             ( 30.00%) | total_pruned =   91744 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     486 /     512             ( 94.92%) | total_pruned =      26 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  151334 / 2359296             (  6.41%) | total_pruned = 2207962 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     300 /     512             ( 58.59%) | total_pruned =     212 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     172 /     512             ( 33.59%) | total_pruned =     340 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  176943 / 2359296             (  7.50%) | total_pruned = 2182353 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     492 /     512             ( 96.09%) | total_pruned =      20 | shape = torch.Size([512])
linear.weight        | nonzeros =    4772 /    5120             ( 93.20%) | total_pruned =     348 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       7 /      10             ( 70.00%) | total_pruned =       3 | shape = torch.Size([10])
alive: 1875487, pruned : 9303275, total: 11178762, Compression rate :       5.96x  ( 83.22% pruned)
Train Epoch: 22/100 Loss: 0.000110 Accuracy: 86.04 100.00 % Best test Accuracy: 86.37%
tensor(-13.1649, device='cuda:0') tensor(1.4305, device='cuda:0') tensor(-3.5184e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.155433
Average KL loss: 0.349235
Average total loss: 0.504668
tensor(-13.1671, device='cuda:0') tensor(1.3973, device='cuda:0') tensor(-3.3647e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.151003
Average KL loss: 0.348832
Average total loss: 0.499835
tensor(-13.1688, device='cuda:0') tensor(1.3788, device='cuda:0') tensor(-1.2408e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.149965
Average KL loss: 0.348651
Average total loss: 0.498616
tensor(-13.1703, device='cuda:0') tensor(1.3666, device='cuda:0') tensor(-3.1395e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.142850
Average KL loss: 0.348540
Average total loss: 0.491390
tensor(-13.1717, device='cuda:0') tensor(1.3581, device='cuda:0') tensor(-5.6412e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.145103
Average KL loss: 0.348460
Average total loss: 0.493563
tensor(-13.1729, device='cuda:0') tensor(1.3521, device='cuda:0') tensor(-6.1429e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.142788
Average KL loss: 0.348399
Average total loss: 0.491187
tensor(-13.1741, device='cuda:0') tensor(1.3477, device='cuda:0') tensor(-6.3364e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.142346
Average KL loss: 0.348355
Average total loss: 0.490701
tensor(-13.1752, device='cuda:0') tensor(1.3443, device='cuda:0') tensor(-2.5594e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.139863
Average KL loss: 0.348324
Average total loss: 0.488187
tensor(-13.1763, device='cuda:0') tensor(1.3417, device='cuda:0') tensor(-1.9117e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.138041
Average KL loss: 0.348296
Average total loss: 0.486338
tensor(-13.1774, device='cuda:0') tensor(1.3395, device='cuda:0') tensor(-3.8834e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.139822
Average KL loss: 0.348276
Average total loss: 0.488098
tensor(-13.1785, device='cuda:0') tensor(1.3377, device='cuda:0') tensor(-1.3071e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.134228
Average KL loss: 0.348261
Average total loss: 0.482489
tensor(-13.1795, device='cuda:0') tensor(1.3362, device='cuda:0') tensor(-1.5494e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.132782
Average KL loss: 0.348246
Average total loss: 0.481028
tensor(-13.1805, device='cuda:0') tensor(1.3348, device='cuda:0') tensor(-2.0517e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.135436
Average KL loss: 0.348233
Average total loss: 0.483668
tensor(-13.1815, device='cuda:0') tensor(1.3338, device='cuda:0') tensor(-2.5499e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.130749
Average KL loss: 0.348224
Average total loss: 0.478973
tensor(-13.1825, device='cuda:0') tensor(1.3328, device='cuda:0') tensor(-1.0829e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.133515
Average KL loss: 0.348213
Average total loss: 0.481728
tensor(-13.1835, device='cuda:0') tensor(1.3319, device='cuda:0') tensor(-1.7991e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.130119
Average KL loss: 0.348198
Average total loss: 0.478317
tensor(-13.1845, device='cuda:0') tensor(1.3311, device='cuda:0') tensor(-7.6203e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.129951
Average KL loss: 0.348188
Average total loss: 0.478139
tensor(-13.1855, device='cuda:0') tensor(1.3304, device='cuda:0') tensor(-1.8801e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.127910
Average KL loss: 0.348177
Average total loss: 0.476087
tensor(-13.1865, device='cuda:0') tensor(1.3298, device='cuda:0') tensor(-1.8988e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.124130
Average KL loss: 0.348167
Average total loss: 0.472297
tensor(-13.1874, device='cuda:0') tensor(1.3291, device='cuda:0') tensor(-1.9722e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.121728
Average KL loss: 0.348150
Average total loss: 0.469879
tensor(-13.1884, device='cuda:0') tensor(1.3285, device='cuda:0') tensor(-4.3531e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.126329
Average KL loss: 0.348147
Average total loss: 0.474475
tensor(-13.1894, device='cuda:0') tensor(1.3280, device='cuda:0') tensor(-4.1830e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.124107
Average KL loss: 0.348150
Average total loss: 0.472256
tensor(-13.1903, device='cuda:0') tensor(1.3276, device='cuda:0') tensor(-4.4602e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.122267
Average KL loss: 0.348148
Average total loss: 0.470415
tensor(-13.1913, device='cuda:0') tensor(1.3273, device='cuda:0') tensor(-9.9385e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.120930
Average KL loss: 0.348134
Average total loss: 0.469064
tensor(-13.1922, device='cuda:0') tensor(1.3269, device='cuda:0') tensor(-4.2839e-11, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.118439
Average KL loss: 0.348121
Average total loss: 0.466560
tensor(-13.1932, device='cuda:0') tensor(1.3265, device='cuda:0') tensor(-1.2005e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.119033
Average KL loss: 0.348114
Average total loss: 0.467148
tensor(-13.1941, device='cuda:0') tensor(1.3262, device='cuda:0') tensor(-2.2544e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.119703
Average KL loss: 0.348106
Average total loss: 0.467809
tensor(-13.1950, device='cuda:0') tensor(1.3259, device='cuda:0') tensor(-5.5664e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.118270
Average KL loss: 0.348098
Average total loss: 0.466367
tensor(-13.1960, device='cuda:0') tensor(1.3257, device='cuda:0') tensor(-1.9165e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.119500
Average KL loss: 0.348088
Average total loss: 0.467589
tensor(-13.1969, device='cuda:0') tensor(1.3255, device='cuda:0') tensor(-6.1444e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.116497
Average KL loss: 0.348076
Average total loss: 0.464573
tensor(-13.1978, device='cuda:0') tensor(1.3252, device='cuda:0') tensor(-1.1932e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.116978
Average KL loss: 0.348066
Average total loss: 0.465044
tensor(-13.1987, device='cuda:0') tensor(1.3250, device='cuda:0') tensor(2.0023e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.116381
Average KL loss: 0.348062
Average total loss: 0.464442
tensor(-13.1997, device='cuda:0') tensor(1.3248, device='cuda:0') tensor(-3.3999e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.112395
Average KL loss: 0.348052
Average total loss: 0.460447
tensor(-13.2006, device='cuda:0') tensor(1.3246, device='cuda:0') tensor(-1.1878e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.116280
Average KL loss: 0.348035
Average total loss: 0.464315
tensor(-13.2015, device='cuda:0') tensor(1.3245, device='cuda:0') tensor(-2.0213e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.112691
Average KL loss: 0.348027
Average total loss: 0.460718
tensor(-13.2024, device='cuda:0') tensor(1.3244, device='cuda:0') tensor(-1.2553e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.111668
Average KL loss: 0.348024
Average total loss: 0.459692
tensor(-13.2033, device='cuda:0') tensor(1.3242, device='cuda:0') tensor(-2.6895e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.113936
Average KL loss: 0.348011
Average total loss: 0.461947
tensor(-13.2042, device='cuda:0') tensor(1.3241, device='cuda:0') tensor(-4.7954e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.113638
Average KL loss: 0.348000
Average total loss: 0.461638
tensor(-13.2051, device='cuda:0') tensor(1.3240, device='cuda:0') tensor(-2.0463e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.113492
Average KL loss: 0.347995
Average total loss: 0.461487
tensor(-13.2060, device='cuda:0') tensor(1.3239, device='cuda:0') tensor(-9.8974e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.110279
Average KL loss: 0.347986
Average total loss: 0.458265
tensor(-13.2069, device='cuda:0') tensor(1.3238, device='cuda:0') tensor(-2.4146e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.109032
Average KL loss: 0.347979
Average total loss: 0.457011
tensor(-13.2078, device='cuda:0') tensor(1.3238, device='cuda:0') tensor(2.0973e-11, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.110649
Average KL loss: 0.347971
Average total loss: 0.458620
tensor(-13.2087, device='cuda:0') tensor(1.3237, device='cuda:0') tensor(2.3490e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.109731
Average KL loss: 0.347966
Average total loss: 0.457697
tensor(-13.2096, device='cuda:0') tensor(1.3236, device='cuda:0') tensor(-9.5629e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.108101
Average KL loss: 0.347956
Average total loss: 0.456057
tensor(-13.2105, device='cuda:0') tensor(1.3236, device='cuda:0') tensor(-2.7456e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.110607
Average KL loss: 0.347955
Average total loss: 0.458561
tensor(-13.2114, device='cuda:0') tensor(1.3236, device='cuda:0') tensor(-1.7928e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.106099
Average KL loss: 0.347951
Average total loss: 0.454050
tensor(-13.2123, device='cuda:0') tensor(1.3235, device='cuda:0') tensor(-3.4994e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.108904
Average KL loss: 0.347947
Average total loss: 0.456850
tensor(-13.2132, device='cuda:0') tensor(1.3235, device='cuda:0') tensor(-1.6613e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.105608
Average KL loss: 0.347943
Average total loss: 0.453551
tensor(-13.2141, device='cuda:0') tensor(1.3235, device='cuda:0') tensor(-3.2258e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.106382
Average KL loss: 0.347935
Average total loss: 0.454318
tensor(-13.2150, device='cuda:0') tensor(1.3235, device='cuda:0') tensor(-1.5660e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.105247
Average KL loss: 0.347924
Average total loss: 0.453171
tensor(-13.2159, device='cuda:0') tensor(1.3235, device='cuda:0') tensor(5.9532e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.107278
Average KL loss: 0.347915
Average total loss: 0.455193
tensor(-13.2168, device='cuda:0') tensor(1.3235, device='cuda:0') tensor(-1.9009e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.104553
Average KL loss: 0.347905
Average total loss: 0.452458
tensor(-13.2176, device='cuda:0') tensor(1.3235, device='cuda:0') tensor(-9.0648e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.104624
Average KL loss: 0.347895
Average total loss: 0.452519
tensor(-13.2185, device='cuda:0') tensor(1.3236, device='cuda:0') tensor(-1.3439e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.104286
Average KL loss: 0.347881
Average total loss: 0.452167
tensor(-13.2194, device='cuda:0') tensor(1.3236, device='cuda:0') tensor(3.3855e-11, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.104933
Average KL loss: 0.347872
Average total loss: 0.452805
tensor(-13.2203, device='cuda:0') tensor(1.3237, device='cuda:0') tensor(-8.2134e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.104249
Average KL loss: 0.347870
Average total loss: 0.452120
tensor(-13.2211, device='cuda:0') tensor(1.3238, device='cuda:0') tensor(-5.7395e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.102926
Average KL loss: 0.347863
Average total loss: 0.450789
tensor(-13.2220, device='cuda:0') tensor(1.3238, device='cuda:0') tensor(1.9847e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.101298
Average KL loss: 0.347856
Average total loss: 0.449154
tensor(-13.2229, device='cuda:0') tensor(1.3238, device='cuda:0') tensor(-2.7970e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.103518
Average KL loss: 0.347850
Average total loss: 0.451368
tensor(-13.2237, device='cuda:0') tensor(1.3239, device='cuda:0') tensor(-5.4180e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.103184
Average KL loss: 0.347833
Average total loss: 0.451017
tensor(-13.2246, device='cuda:0') tensor(1.3239, device='cuda:0') tensor(3.0152e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.102474
Average KL loss: 0.347819
Average total loss: 0.450292
tensor(-13.2255, device='cuda:0') tensor(1.3240, device='cuda:0') tensor(-2.7729e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.100973
Average KL loss: 0.347818
Average total loss: 0.448791
tensor(-13.2263, device='cuda:0') tensor(1.3241, device='cuda:0') tensor(8.2461e-11, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.101753
Average KL loss: 0.347810
Average total loss: 0.449564
tensor(-13.2272, device='cuda:0') tensor(1.3243, device='cuda:0') tensor(2.9333e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.099025
Average KL loss: 0.347802
Average total loss: 0.446827
tensor(-13.2281, device='cuda:0') tensor(1.3244, device='cuda:0') tensor(1.3489e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.102712
Average KL loss: 0.347791
Average total loss: 0.450503
tensor(-13.2289, device='cuda:0') tensor(1.3244, device='cuda:0') tensor(-1.7480e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.100660
Average KL loss: 0.347784
Average total loss: 0.448444
tensor(-13.2298, device='cuda:0') tensor(1.3245, device='cuda:0') tensor(-4.4904e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.101408
Average KL loss: 0.347781
Average total loss: 0.449189
tensor(-13.2306, device='cuda:0') tensor(1.3247, device='cuda:0') tensor(-1.6512e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.099835
Average KL loss: 0.347777
Average total loss: 0.447612
tensor(-13.2315, device='cuda:0') tensor(1.3248, device='cuda:0') tensor(-1.8003e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.098876
Average KL loss: 0.347771
Average total loss: 0.446647
tensor(-13.2323, device='cuda:0') tensor(1.3249, device='cuda:0') tensor(-3.5028e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.099391
Average KL loss: 0.347765
Average total loss: 0.447155
tensor(-13.2332, device='cuda:0') tensor(1.3250, device='cuda:0') tensor(-2.4629e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.096916
Average KL loss: 0.347745
Average total loss: 0.444661
tensor(-13.2340, device='cuda:0') tensor(1.3251, device='cuda:0') tensor(-3.7019e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.100311
Average KL loss: 0.347731
Average total loss: 0.448042
tensor(-13.2349, device='cuda:0') tensor(1.3253, device='cuda:0') tensor(-1.8327e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.098075
Average KL loss: 0.347733
Average total loss: 0.445808
tensor(-13.2357, device='cuda:0') tensor(1.3254, device='cuda:0') tensor(8.5432e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.097669
Average KL loss: 0.347718
Average total loss: 0.445387
tensor(-13.2366, device='cuda:0') tensor(1.3255, device='cuda:0') tensor(3.9655e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.097796
Average KL loss: 0.347699
Average total loss: 0.445495
tensor(-13.2374, device='cuda:0') tensor(1.3256, device='cuda:0') tensor(1.0703e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.097564
Average KL loss: 0.347680
Average total loss: 0.445244
tensor(-13.2383, device='cuda:0') tensor(1.3257, device='cuda:0') tensor(-8.2332e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.097559
Average KL loss: 0.347672
Average total loss: 0.445231
tensor(-13.2391, device='cuda:0') tensor(1.3258, device='cuda:0') tensor(-8.1936e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.096342
Average KL loss: 0.347649
Average total loss: 0.443992
tensor(-13.2400, device='cuda:0') tensor(1.3259, device='cuda:0') tensor(-1.9228e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.096161
Average KL loss: 0.347629
Average total loss: 0.443789
tensor(-13.2408, device='cuda:0') tensor(1.3260, device='cuda:0') tensor(-7.8843e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.093838
Average KL loss: 0.347622
Average total loss: 0.441460
tensor(-13.2416, device='cuda:0') tensor(1.3262, device='cuda:0') tensor(5.8097e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.096199
Average KL loss: 0.347613
Average total loss: 0.443812
tensor(-13.2425, device='cuda:0') tensor(1.3263, device='cuda:0') tensor(3.7989e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.095883
Average KL loss: 0.347601
Average total loss: 0.443484
tensor(-13.2433, device='cuda:0') tensor(1.3264, device='cuda:0') tensor(-8.6543e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.095603
Average KL loss: 0.347590
Average total loss: 0.443193
tensor(-13.2441, device='cuda:0') tensor(1.3265, device='cuda:0') tensor(6.9732e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.094862
Average KL loss: 0.347590
Average total loss: 0.442451
tensor(-13.2450, device='cuda:0') tensor(1.3266, device='cuda:0') tensor(-1.1928e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.094112
Average KL loss: 0.347581
Average total loss: 0.441694
tensor(-13.2458, device='cuda:0') tensor(1.3267, device='cuda:0') tensor(-1.6419e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.095197
Average KL loss: 0.347569
Average total loss: 0.442766
tensor(-13.2466, device='cuda:0') tensor(1.3269, device='cuda:0') tensor(3.7896e-11, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.094525
Average KL loss: 0.347566
Average total loss: 0.442091
tensor(-13.2475, device='cuda:0') tensor(1.3270, device='cuda:0') tensor(-1.2515e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.094802
Average KL loss: 0.347555
Average total loss: 0.442357
tensor(-13.2483, device='cuda:0') tensor(1.3271, device='cuda:0') tensor(-9.5308e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.092579
Average KL loss: 0.347541
Average total loss: 0.440120
tensor(-13.2491, device='cuda:0') tensor(1.3272, device='cuda:0') tensor(-2.0202e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.094725
Average KL loss: 0.347534
Average total loss: 0.442259
tensor(-13.2500, device='cuda:0') tensor(1.3274, device='cuda:0') tensor(1.3665e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.094935
Average KL loss: 0.347517
Average total loss: 0.442452
tensor(-13.2508, device='cuda:0') tensor(1.3275, device='cuda:0') tensor(-1.2187e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.092349
Average KL loss: 0.347504
Average total loss: 0.439854
tensor(-13.2516, device='cuda:0') tensor(1.3277, device='cuda:0') tensor(-1.7146e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.091349
Average KL loss: 0.347498
Average total loss: 0.438847
tensor(-13.2524, device='cuda:0') tensor(1.3278, device='cuda:0') tensor(8.8182e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.092070
Average KL loss: 0.347483
Average total loss: 0.439553
tensor(-13.2533, device='cuda:0') tensor(1.3279, device='cuda:0') tensor(-9.6424e-12, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.091989
Average KL loss: 0.347467
Average total loss: 0.439456
tensor(-13.2541, device='cuda:0') tensor(1.3281, device='cuda:0') tensor(-3.6618e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.093331
Average KL loss: 0.347453
Average total loss: 0.440784
tensor(-13.2549, device='cuda:0') tensor(1.3282, device='cuda:0') tensor(-1.9880e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.090667
Average KL loss: 0.347430
Average total loss: 0.438097
tensor(-13.2557, device='cuda:0') tensor(1.3284, device='cuda:0') tensor(5.2619e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.092833
Average KL loss: 0.347413
Average total loss: 0.440246
tensor(-13.2565, device='cuda:0') tensor(1.3286, device='cuda:0') tensor(9.5788e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.092711
Average KL loss: 0.347392
Average total loss: 0.440103
tensor(-13.2574, device='cuda:0') tensor(1.3288, device='cuda:0') tensor(-1.0505e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.091174
Average KL loss: 0.347377
Average total loss: 0.438551
tensor(-13.2582, device='cuda:0') tensor(1.3290, device='cuda:0') tensor(-1.5339e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.091210
Average KL loss: 0.347367
Average total loss: 0.438578
tensor(-13.2590, device='cuda:0') tensor(1.3292, device='cuda:0') tensor(-4.7871e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.090772
Average KL loss: 0.347365
Average total loss: 0.438137
tensor(-13.2598, device='cuda:0') tensor(1.3294, device='cuda:0') tensor(-2.3331e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.091221
Average KL loss: 0.347354
Average total loss: 0.438576
tensor(-13.2606, device='cuda:0') tensor(1.3296, device='cuda:0') tensor(-1.8781e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.090381
Average KL loss: 0.347350
Average total loss: 0.437731
tensor(-13.2614, device='cuda:0') tensor(1.3298, device='cuda:0') tensor(-3.9093e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.087597
Average KL loss: 0.347334
Average total loss: 0.434931
tensor(-13.2622, device='cuda:0') tensor(1.3299, device='cuda:0') tensor(-5.8942e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.089779
Average KL loss: 0.347319
Average total loss: 0.437099
tensor(-13.2631, device='cuda:0') tensor(1.3300, device='cuda:0') tensor(2.9801e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.088199
Average KL loss: 0.347301
Average total loss: 0.435500
tensor(-13.2639, device='cuda:0') tensor(1.3302, device='cuda:0') tensor(-6.4270e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.090332
Average KL loss: 0.347284
Average total loss: 0.437617
tensor(-13.2647, device='cuda:0') tensor(1.3304, device='cuda:0') tensor(3.8265e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.089510
Average KL loss: 0.347270
Average total loss: 0.436779
tensor(-13.2655, device='cuda:0') tensor(1.3305, device='cuda:0') tensor(-1.0316e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.088745
Average KL loss: 0.347255
Average total loss: 0.436000
tensor(-13.2663, device='cuda:0') tensor(1.3307, device='cuda:0') tensor(-1.4380e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.088375
Average KL loss: 0.347236
Average total loss: 0.435611
tensor(-13.2671, device='cuda:0') tensor(1.3309, device='cuda:0') tensor(-7.7771e-11, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.086650
Average KL loss: 0.347218
Average total loss: 0.433868
tensor(-13.2679, device='cuda:0') tensor(1.3310, device='cuda:0') tensor(-1.3000e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.088984
Average KL loss: 0.347208
Average total loss: 0.436192
tensor(-13.2687, device='cuda:0') tensor(1.3311, device='cuda:0') tensor(-2.2548e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.087648
Average KL loss: 0.347190
Average total loss: 0.434838
tensor(-13.2695, device='cuda:0') tensor(1.3313, device='cuda:0') tensor(1.3438e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.088674
Average KL loss: 0.347178
Average total loss: 0.435852
tensor(-13.2703, device='cuda:0') tensor(1.3315, device='cuda:0') tensor(-4.0618e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.088355
Average KL loss: 0.347175
Average total loss: 0.435530
tensor(-13.2711, device='cuda:0') tensor(1.3318, device='cuda:0') tensor(-5.1551e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.087227
Average KL loss: 0.347177
Average total loss: 0.434404
tensor(-13.2719, device='cuda:0') tensor(1.3320, device='cuda:0') tensor(-4.8209e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.088937
Average KL loss: 0.347169
Average total loss: 0.436106
tensor(-13.2727, device='cuda:0') tensor(1.3322, device='cuda:0') tensor(-1.1412e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.088212
Average KL loss: 0.347157
Average total loss: 0.435369
tensor(-13.2735, device='cuda:0') tensor(1.3324, device='cuda:0') tensor(-1.4244e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.085339
Average KL loss: 0.347134
Average total loss: 0.432474
tensor(-13.2743, device='cuda:0') tensor(1.3325, device='cuda:0') tensor(-5.9590e-12, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.087719
Average KL loss: 0.347112
Average total loss: 0.434830
tensor(-13.2751, device='cuda:0') tensor(1.3327, device='cuda:0') tensor(-1.1863e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.086338
Average KL loss: 0.347101
Average total loss: 0.433439
tensor(-13.2759, device='cuda:0') tensor(1.3329, device='cuda:0') tensor(-9.4488e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.087189
Average KL loss: 0.347081
Average total loss: 0.434270
tensor(-13.2767, device='cuda:0') tensor(1.3331, device='cuda:0') tensor(-1.4505e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.086592
Average KL loss: 0.347065
Average total loss: 0.433657
tensor(-13.2775, device='cuda:0') tensor(1.3333, device='cuda:0') tensor(-2.4801e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.085130
Average KL loss: 0.347049
Average total loss: 0.432179
tensor(-13.2783, device='cuda:0') tensor(1.3336, device='cuda:0') tensor(2.1280e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.085286
Average KL loss: 0.347025
Average total loss: 0.432311
tensor(-13.2791, device='cuda:0') tensor(1.3337, device='cuda:0') tensor(9.8895e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.085536
Average KL loss: 0.347007
Average total loss: 0.432542
tensor(-13.2799, device='cuda:0') tensor(1.3339, device='cuda:0') tensor(-2.0988e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.086643
Average KL loss: 0.346999
Average total loss: 0.433642
tensor(-13.2807, device='cuda:0') tensor(1.3341, device='cuda:0') tensor(1.9017e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.085946
Average KL loss: 0.346986
Average total loss: 0.432933
tensor(-13.2815, device='cuda:0') tensor(1.3343, device='cuda:0') tensor(-9.9590e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.086383
Average KL loss: 0.346979
Average total loss: 0.433362
tensor(-13.2823, device='cuda:0') tensor(1.3345, device='cuda:0') tensor(-2.5270e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.086423
Average KL loss: 0.346965
Average total loss: 0.433388
tensor(-13.2831, device='cuda:0') tensor(1.3347, device='cuda:0') tensor(2.6297e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.083623
Average KL loss: 0.346951
Average total loss: 0.430574
tensor(-13.2839, device='cuda:0') tensor(1.3350, device='cuda:0') tensor(-3.2473e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.085109
Average KL loss: 0.346932
Average total loss: 0.432041
tensor(-13.2847, device='cuda:0') tensor(1.3352, device='cuda:0') tensor(-1.4896e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.084411
Average KL loss: 0.346921
Average total loss: 0.431332
tensor(-13.2854, device='cuda:0') tensor(1.3354, device='cuda:0') tensor(-7.1676e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.085526
Average KL loss: 0.346907
Average total loss: 0.432434
tensor(-13.2862, device='cuda:0') tensor(1.3356, device='cuda:0') tensor(-1.3348e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.083533
Average KL loss: 0.346896
Average total loss: 0.430429
tensor(-13.2870, device='cuda:0') tensor(1.3358, device='cuda:0') tensor(2.4823e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.082965
Average KL loss: 0.346878
Average total loss: 0.429843
tensor(-13.2878, device='cuda:0') tensor(1.3360, device='cuda:0') tensor(-2.5515e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.083109
Average KL loss: 0.346856
Average total loss: 0.429965
tensor(-13.2886, device='cuda:0') tensor(1.3361, device='cuda:0') tensor(-1.1426e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.081812
Average KL loss: 0.346849
Average total loss: 0.428662
tensor(-13.2894, device='cuda:0') tensor(1.3364, device='cuda:0') tensor(2.1358e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.082928
Average KL loss: 0.346841
Average total loss: 0.429769
tensor(-13.2902, device='cuda:0') tensor(1.3366, device='cuda:0') tensor(-6.9535e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.085152
Average KL loss: 0.346815
Average total loss: 0.431968
tensor(-13.2910, device='cuda:0') tensor(1.3368, device='cuda:0') tensor(-7.5740e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.084703
Average KL loss: 0.346797
Average total loss: 0.431500
tensor(-13.2917, device='cuda:0') tensor(1.3370, device='cuda:0') tensor(-1.0844e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.082435
Average KL loss: 0.346781
Average total loss: 0.429216
tensor(-13.2925, device='cuda:0') tensor(1.3372, device='cuda:0') tensor(-3.3130e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.081690
Average KL loss: 0.346767
Average total loss: 0.428457
tensor(-13.2933, device='cuda:0') tensor(1.3373, device='cuda:0') tensor(2.4111e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.083087
Average KL loss: 0.346751
Average total loss: 0.429838
tensor(-13.2941, device='cuda:0') tensor(1.3375, device='cuda:0') tensor(-2.8355e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.083843
Average KL loss: 0.346731
Average total loss: 0.430574
tensor(-13.2949, device='cuda:0') tensor(1.3377, device='cuda:0') tensor(9.1689e-11, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.080869
Average KL loss: 0.346713
Average total loss: 0.427582
tensor(-13.2957, device='cuda:0') tensor(1.3379, device='cuda:0') tensor(3.4894e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.081642
Average KL loss: 0.346690
Average total loss: 0.428332
tensor(-13.2965, device='cuda:0') tensor(1.3381, device='cuda:0') tensor(-7.7913e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.082068
Average KL loss: 0.346678
Average total loss: 0.428746
tensor(-13.2972, device='cuda:0') tensor(1.3382, device='cuda:0') tensor(5.1537e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.082694
Average KL loss: 0.346669
Average total loss: 0.429363
tensor(-13.2980, device='cuda:0') tensor(1.3385, device='cuda:0') tensor(1.0804e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.081757
Average KL loss: 0.346665
Average total loss: 0.428422
tensor(-13.2988, device='cuda:0') tensor(1.3387, device='cuda:0') tensor(-1.3597e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.083618
Average KL loss: 0.346660
Average total loss: 0.430278
tensor(-13.2996, device='cuda:0') tensor(1.3389, device='cuda:0') tensor(-1.4570e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.080944
Average KL loss: 0.346648
Average total loss: 0.427592
tensor(-13.3004, device='cuda:0') tensor(1.3391, device='cuda:0') tensor(3.2025e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.080482
Average KL loss: 0.346641
Average total loss: 0.427123
tensor(-13.3011, device='cuda:0') tensor(1.3393, device='cuda:0') tensor(-2.7777e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.080554
Average KL loss: 0.346628
Average total loss: 0.427182
tensor(-13.3019, device='cuda:0') tensor(1.3396, device='cuda:0') tensor(-3.8536e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.082323
Average KL loss: 0.346610
Average total loss: 0.428933
tensor(-13.3027, device='cuda:0') tensor(1.3398, device='cuda:0') tensor(-2.1608e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.081941
Average KL loss: 0.346597
Average total loss: 0.428537
tensor(-13.3035, device='cuda:0') tensor(1.3400, device='cuda:0') tensor(-1.3344e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.080645
Average KL loss: 0.346588
Average total loss: 0.427232
tensor(-13.3043, device='cuda:0') tensor(1.3402, device='cuda:0') tensor(-7.3429e-11, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.079265
Average KL loss: 0.346569
Average total loss: 0.425834
tensor(-13.3050, device='cuda:0') tensor(1.3404, device='cuda:0') tensor(-1.7021e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.081384
Average KL loss: 0.346559
Average total loss: 0.427943
tensor(-13.3058, device='cuda:0') tensor(1.3406, device='cuda:0') tensor(-1.1991e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.081756
Average KL loss: 0.346544
Average total loss: 0.428300
tensor(-13.3066, device='cuda:0') tensor(1.3408, device='cuda:0') tensor(-1.1342e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.080725
Average KL loss: 0.346529
Average total loss: 0.427254
tensor(-13.3074, device='cuda:0') tensor(1.3411, device='cuda:0') tensor(-1.1423e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.079751
Average KL loss: 0.346514
Average total loss: 0.426265
tensor(-13.3081, device='cuda:0') tensor(1.3412, device='cuda:0') tensor(-1.0227e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.080054
Average KL loss: 0.346497
Average total loss: 0.426550
tensor(-13.3089, device='cuda:0') tensor(1.3414, device='cuda:0') tensor(-5.8120e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.079212
Average KL loss: 0.346481
Average total loss: 0.425693
tensor(-13.3097, device='cuda:0') tensor(1.3416, device='cuda:0') tensor(-1.7757e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.080423
Average KL loss: 0.346472
Average total loss: 0.426895
tensor(-13.3104, device='cuda:0') tensor(1.3418, device='cuda:0') tensor(1.9993e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.078603
Average KL loss: 0.346461
Average total loss: 0.425065
tensor(-13.3112, device='cuda:0') tensor(1.3420, device='cuda:0') tensor(-1.2088e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.079781
Average KL loss: 0.346454
Average total loss: 0.426235
tensor(-13.3120, device='cuda:0') tensor(1.3422, device='cuda:0') tensor(-6.1867e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.079160
Average KL loss: 0.346440
Average total loss: 0.425600
tensor(-13.3127, device='cuda:0') tensor(1.3424, device='cuda:0') tensor(-1.2763e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.078839
Average KL loss: 0.346422
Average total loss: 0.425261
tensor(-13.3135, device='cuda:0') tensor(1.3427, device='cuda:0') tensor(1.1043e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.079337
Average KL loss: 0.346415
Average total loss: 0.425753
tensor(-13.3143, device='cuda:0') tensor(1.3429, device='cuda:0') tensor(1.3643e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.078695
Average KL loss: 0.346401
Average total loss: 0.425096
tensor(-13.3150, device='cuda:0') tensor(1.3431, device='cuda:0') tensor(-3.9333e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.078560
Average KL loss: 0.346387
Average total loss: 0.424947
tensor(-13.3158, device='cuda:0') tensor(1.3433, device='cuda:0') tensor(8.1650e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.079529
Average KL loss: 0.346378
Average total loss: 0.425907
tensor(-13.3166, device='cuda:0') tensor(1.3435, device='cuda:0') tensor(1.3988e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.078395
Average KL loss: 0.346371
Average total loss: 0.424766
tensor(-13.3173, device='cuda:0') tensor(1.3437, device='cuda:0') tensor(3.0230e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.078144
Average KL loss: 0.346360
Average total loss: 0.424504
tensor(-13.3181, device='cuda:0') tensor(1.3438, device='cuda:0') tensor(2.3756e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.078054
Average KL loss: 0.346344
Average total loss: 0.424397
tensor(-13.3188, device='cuda:0') tensor(1.3440, device='cuda:0') tensor(-1.7911e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.079078
Average KL loss: 0.346326
Average total loss: 0.425404
tensor(-13.3196, device='cuda:0') tensor(1.3441, device='cuda:0') tensor(-3.5342e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.077988
Average KL loss: 0.346310
Average total loss: 0.424299
tensor(-13.3204, device='cuda:0') tensor(1.3443, device='cuda:0') tensor(1.9345e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.076238
Average KL loss: 0.346296
Average total loss: 0.422533
tensor(-13.3211, device='cuda:0') tensor(1.3445, device='cuda:0') tensor(-1.8486e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.078803
Average KL loss: 0.346273
Average total loss: 0.425076
tensor(-13.3219, device='cuda:0') tensor(1.3448, device='cuda:0') tensor(-2.1210e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.078071
Average KL loss: 0.346253
Average total loss: 0.424324
tensor(-13.3226, device='cuda:0') tensor(1.3450, device='cuda:0') tensor(-1.2325e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.077089
Average KL loss: 0.346246
Average total loss: 0.423334
tensor(-13.3234, device='cuda:0') tensor(1.3452, device='cuda:0') tensor(-9.1705e-11, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.077003
Average KL loss: 0.346229
Average total loss: 0.423232
tensor(-13.3241, device='cuda:0') tensor(1.3454, device='cuda:0') tensor(5.1808e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.078683
Average KL loss: 0.346214
Average total loss: 0.424897
tensor(-13.3249, device='cuda:0') tensor(1.3457, device='cuda:0') tensor(-1.0023e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.077516
Average KL loss: 0.346197
Average total loss: 0.423714
tensor(-13.3257, device='cuda:0') tensor(1.3459, device='cuda:0') tensor(1.2437e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.077822
Average KL loss: 0.346179
Average total loss: 0.424001
tensor(-13.3264, device='cuda:0') tensor(1.3461, device='cuda:0') tensor(-4.0036e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.077606
Average KL loss: 0.346160
Average total loss: 0.423766
tensor(-13.3272, device='cuda:0') tensor(1.3463, device='cuda:0') tensor(-9.1833e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.077765
Average KL loss: 0.346140
Average total loss: 0.423905
tensor(-13.3279, device='cuda:0') tensor(1.3465, device='cuda:0') tensor(-6.6924e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.076850
Average KL loss: 0.346135
Average total loss: 0.422986
tensor(-13.3287, device='cuda:0') tensor(1.3467, device='cuda:0') tensor(-1.4364e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.076099
Average KL loss: 0.346126
Average total loss: 0.422224
tensor(-13.3294, device='cuda:0') tensor(1.3470, device='cuda:0') tensor(-1.0527e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.076989
Average KL loss: 0.346108
Average total loss: 0.423097
tensor(-13.3302, device='cuda:0') tensor(1.3472, device='cuda:0') tensor(-2.2601e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.076263
Average KL loss: 0.346097
Average total loss: 0.422360
tensor(-13.3309, device='cuda:0') tensor(1.3474, device='cuda:0') tensor(-1.1130e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.079001
Average KL loss: 0.346076
Average total loss: 0.425078
tensor(-13.3316, device='cuda:0') tensor(1.3476, device='cuda:0') tensor(-1.5732e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.075541
Average KL loss: 0.346061
Average total loss: 0.421602
tensor(-13.3324, device='cuda:0') tensor(1.3478, device='cuda:0') tensor(-2.8023e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.075262
Average KL loss: 0.346046
Average total loss: 0.421308
tensor(-13.3331, device='cuda:0') tensor(1.3479, device='cuda:0') tensor(-1.3819e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.076012
Average KL loss: 0.346021
Average total loss: 0.422033
tensor(-13.3339, device='cuda:0') tensor(1.3481, device='cuda:0') tensor(2.2222e-11, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.076191
Average KL loss: 0.346004
Average total loss: 0.422195
tensor(-13.3346, device='cuda:0') tensor(1.3483, device='cuda:0') tensor(-8.3803e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.075440
Average KL loss: 0.345988
Average total loss: 0.421428
tensor(-13.3354, device='cuda:0') tensor(1.3486, device='cuda:0') tensor(-4.0016e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.075736
Average KL loss: 0.345971
Average total loss: 0.421707
 Percentile value: -13.153203010559082
Non-zero model percentage: 13.42179012298584%, Non-zero mask percentage: 13.42179012298584%

--- Pruning Level [9/24]: ---
conv1.weight         | nonzeros =    1593 /    1728             ( 92.19%) | total_pruned =     135 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   19119 /   36864             ( 51.86%) | total_pruned =   17745 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   19666 /   36864             ( 53.35%) | total_pruned =   17198 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   17312 /   36864             ( 46.96%) | total_pruned =   19552 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   16818 /   36864             ( 45.62%) | total_pruned =   20046 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   35996 /   73728             ( 48.82%) | total_pruned =   37732 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   64031 /  147456             ( 43.42%) | total_pruned =   83425 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5742 /    8192             ( 70.09%) | total_pruned =    2450 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   50940 /  147456             ( 34.55%) | total_pruned =   96516 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   51336 /  147456             ( 34.81%) | total_pruned =   96120 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  110747 /  294912             ( 37.55%) | total_pruned =  184165 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  182315 /  589824             ( 30.91%) | total_pruned =  407509 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   17704 /   32768             ( 54.03%) | total_pruned =   15064 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   95677 /  589824             ( 16.22%) | total_pruned =  494147 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     149 /     256             ( 58.20%) | total_pruned =     107 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   97420 /  589824             ( 16.52%) | total_pruned =  492404 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  203460 / 1179648             ( 17.25%) | total_pruned =  976188 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     390 /     512             ( 76.17%) | total_pruned =     122 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     326 /     512             ( 63.67%) | total_pruned =     186 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  225765 / 2359296             (  9.57%) | total_pruned = 2133531 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     489 /     512             ( 95.51%) | total_pruned =      23 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     448 /     512             ( 87.50%) | total_pruned =      64 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   31307 /  131072             ( 23.89%) | total_pruned =   99765 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     425 /     512             ( 83.01%) | total_pruned =      87 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     446 /     512             ( 87.11%) | total_pruned =      66 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  110994 / 2359296             (  4.70%) | total_pruned = 2248302 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     255 /     512             ( 49.80%) | total_pruned =     257 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     137 /     512             ( 26.76%) | total_pruned =     375 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  129851 / 2359296             (  5.50%) | total_pruned = 2229445 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     501 /     512             ( 97.85%) | total_pruned =      11 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     464 /     512             ( 90.62%) | total_pruned =      48 | shape = torch.Size([512])
linear.weight        | nonzeros =    4588 /    5120             ( 89.61%) | total_pruned =     532 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       6 /      10             ( 60.00%) | total_pruned =       4 | shape = torch.Size([10])
alive: 1500390, pruned : 9678372, total: 11178762, Compression rate :       7.45x  ( 86.58% pruned)
Train Epoch: 22/100 Loss: 0.000003 Accuracy: 86.41 100.00 % Best test Accuracy: 86.71%
tensor(-13.3361, device='cuda:0') tensor(1.3487, device='cuda:0') tensor(-2.3598e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.147784
Average KL loss: 0.345518
Average total loss: 0.493301
tensor(-13.3379, device='cuda:0') tensor(1.3193, device='cuda:0') tensor(-2.2025e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.144890
Average KL loss: 0.345187
Average total loss: 0.490077
tensor(-13.3393, device='cuda:0') tensor(1.3026, device='cuda:0') tensor(-1.5002e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.147864
Average KL loss: 0.345030
Average total loss: 0.492893
tensor(-13.3405, device='cuda:0') tensor(1.2915, device='cuda:0') tensor(-5.7714e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.143821
Average KL loss: 0.344922
Average total loss: 0.488743
tensor(-13.3415, device='cuda:0') tensor(1.2840, device='cuda:0') tensor(-2.3666e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.141132
Average KL loss: 0.344841
Average total loss: 0.485974
tensor(-13.3425, device='cuda:0') tensor(1.2788, device='cuda:0') tensor(4.0602e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.140211
Average KL loss: 0.344779
Average total loss: 0.484991
tensor(-13.3435, device='cuda:0') tensor(1.2751, device='cuda:0') tensor(3.6246e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.141782
Average KL loss: 0.344725
Average total loss: 0.486507
tensor(-13.3444, device='cuda:0') tensor(1.2724, device='cuda:0') tensor(-9.2977e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.137914
Average KL loss: 0.344694
Average total loss: 0.482608
tensor(-13.3452, device='cuda:0') tensor(1.2704, device='cuda:0') tensor(-9.8863e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.134981
Average KL loss: 0.344658
Average total loss: 0.479640
tensor(-13.3461, device='cuda:0') tensor(1.2689, device='cuda:0') tensor(-2.3201e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.133732
Average KL loss: 0.344633
Average total loss: 0.478364
tensor(-13.3469, device='cuda:0') tensor(1.2677, device='cuda:0') tensor(-1.1845e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.131113
Average KL loss: 0.344612
Average total loss: 0.475726
tensor(-13.3478, device='cuda:0') tensor(1.2668, device='cuda:0') tensor(-3.6627e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.134251
Average KL loss: 0.344587
Average total loss: 0.478838
tensor(-13.3486, device='cuda:0') tensor(1.2660, device='cuda:0') tensor(-1.3390e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.129514
Average KL loss: 0.344565
Average total loss: 0.474079
tensor(-13.3494, device='cuda:0') tensor(1.2654, device='cuda:0') tensor(9.1112e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.127936
Average KL loss: 0.344550
Average total loss: 0.472487
tensor(-13.3502, device='cuda:0') tensor(1.2648, device='cuda:0') tensor(5.6165e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.128336
Average KL loss: 0.344530
Average total loss: 0.472866
tensor(-13.3510, device='cuda:0') tensor(1.2643, device='cuda:0') tensor(-2.6847e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.126964
Average KL loss: 0.344507
Average total loss: 0.471471
tensor(-13.3518, device='cuda:0') tensor(1.2639, device='cuda:0') tensor(-2.7480e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.127336
Average KL loss: 0.344485
Average total loss: 0.471821
tensor(-13.3526, device='cuda:0') tensor(1.2636, device='cuda:0') tensor(-1.1556e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.125896
Average KL loss: 0.344464
Average total loss: 0.470360
tensor(-13.3534, device='cuda:0') tensor(1.2633, device='cuda:0') tensor(-1.5470e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.124936
Average KL loss: 0.344453
Average total loss: 0.469389
tensor(-13.3542, device='cuda:0') tensor(1.2631, device='cuda:0') tensor(-2.0937e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.127129
Average KL loss: 0.344439
Average total loss: 0.471568
tensor(-13.3550, device='cuda:0') tensor(1.2629, device='cuda:0') tensor(4.4238e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.122393
Average KL loss: 0.344409
Average total loss: 0.466802
tensor(-13.3558, device='cuda:0') tensor(1.2627, device='cuda:0') tensor(1.6588e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.123865
Average KL loss: 0.344379
Average total loss: 0.468244
tensor(-13.3566, device='cuda:0') tensor(1.2625, device='cuda:0') tensor(-1.1780e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.121010
Average KL loss: 0.344355
Average total loss: 0.465365
tensor(-13.3573, device='cuda:0') tensor(1.2624, device='cuda:0') tensor(-6.3578e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.122089
Average KL loss: 0.344336
Average total loss: 0.466426
tensor(-13.3581, device='cuda:0') tensor(1.2623, device='cuda:0') tensor(-3.5031e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.121201
Average KL loss: 0.344322
Average total loss: 0.465523
tensor(-13.3589, device='cuda:0') tensor(1.2623, device='cuda:0') tensor(1.3179e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.122060
Average KL loss: 0.344302
Average total loss: 0.466361
tensor(-13.3597, device='cuda:0') tensor(1.2623, device='cuda:0') tensor(-3.8136e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.120904
Average KL loss: 0.344284
Average total loss: 0.465188
tensor(-13.3604, device='cuda:0') tensor(1.2623, device='cuda:0') tensor(-3.8647e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.115986
Average KL loss: 0.344267
Average total loss: 0.460253
tensor(-13.3612, device='cuda:0') tensor(1.2622, device='cuda:0') tensor(-2.3508e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.117953
Average KL loss: 0.344249
Average total loss: 0.462202
tensor(-13.3620, device='cuda:0') tensor(1.2623, device='cuda:0') tensor(-2.2220e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.116976
Average KL loss: 0.344230
Average total loss: 0.461206
tensor(-13.3627, device='cuda:0') tensor(1.2623, device='cuda:0') tensor(-1.7422e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.115573
Average KL loss: 0.344217
Average total loss: 0.459790
tensor(-13.3635, device='cuda:0') tensor(1.2623, device='cuda:0') tensor(-7.6265e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.116062
Average KL loss: 0.344190
Average total loss: 0.460252
tensor(-13.3643, device='cuda:0') tensor(1.2624, device='cuda:0') tensor(-5.3911e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.116649
Average KL loss: 0.344159
Average total loss: 0.460809
tensor(-13.3650, device='cuda:0') tensor(1.2624, device='cuda:0') tensor(-9.5180e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.114727
Average KL loss: 0.344139
Average total loss: 0.458865
tensor(-13.3658, device='cuda:0') tensor(1.2626, device='cuda:0') tensor(-3.4216e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.113594
Average KL loss: 0.344114
Average total loss: 0.457708
tensor(-13.3665, device='cuda:0') tensor(1.2627, device='cuda:0') tensor(4.7272e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.112988
Average KL loss: 0.344090
Average total loss: 0.457078
tensor(-13.3673, device='cuda:0') tensor(1.2627, device='cuda:0') tensor(-1.6546e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.114040
Average KL loss: 0.344070
Average total loss: 0.458109
tensor(-13.3680, device='cuda:0') tensor(1.2629, device='cuda:0') tensor(-1.1579e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.112729
Average KL loss: 0.344054
Average total loss: 0.456783
tensor(-13.3688, device='cuda:0') tensor(1.2630, device='cuda:0') tensor(-3.0210e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.110947
Average KL loss: 0.344041
Average total loss: 0.454988
tensor(-13.3695, device='cuda:0') tensor(1.2631, device='cuda:0') tensor(-1.5840e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.112874
Average KL loss: 0.344022
Average total loss: 0.456897
tensor(-13.3703, device='cuda:0') tensor(1.2631, device='cuda:0') tensor(3.3884e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.110428
Average KL loss: 0.344008
Average total loss: 0.454435
tensor(-13.3710, device='cuda:0') tensor(1.2632, device='cuda:0') tensor(-1.1027e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.111829
Average KL loss: 0.343993
Average total loss: 0.455822
tensor(-13.3718, device='cuda:0') tensor(1.2633, device='cuda:0') tensor(-2.2248e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.109078
Average KL loss: 0.343977
Average total loss: 0.453054
tensor(-13.3725, device='cuda:0') tensor(1.2634, device='cuda:0') tensor(-5.9449e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.107859
Average KL loss: 0.343965
Average total loss: 0.451824
tensor(-13.3733, device='cuda:0') tensor(1.2636, device='cuda:0') tensor(-1.3751e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.108196
Average KL loss: 0.343955
Average total loss: 0.452152
tensor(-13.3740, device='cuda:0') tensor(1.2638, device='cuda:0') tensor(5.5137e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.109814
Average KL loss: 0.343939
Average total loss: 0.453752
tensor(-13.3748, device='cuda:0') tensor(1.2640, device='cuda:0') tensor(5.3080e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.108869
Average KL loss: 0.343922
Average total loss: 0.452790
tensor(-13.3755, device='cuda:0') tensor(1.2641, device='cuda:0') tensor(6.5956e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.107748
Average KL loss: 0.343904
Average total loss: 0.451652
tensor(-13.3762, device='cuda:0') tensor(1.2642, device='cuda:0') tensor(-1.0338e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.107024
Average KL loss: 0.343888
Average total loss: 0.450912
tensor(-13.3770, device='cuda:0') tensor(1.2644, device='cuda:0') tensor(-5.9433e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.107021
Average KL loss: 0.343875
Average total loss: 0.450896
tensor(-13.3777, device='cuda:0') tensor(1.2646, device='cuda:0') tensor(-7.9376e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.104570
Average KL loss: 0.343852
Average total loss: 0.448422
tensor(-13.3785, device='cuda:0') tensor(1.2648, device='cuda:0') tensor(1.3420e-12, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.104774
Average KL loss: 0.343832
Average total loss: 0.448606
tensor(-13.3792, device='cuda:0') tensor(1.2649, device='cuda:0') tensor(-1.3335e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.108050
Average KL loss: 0.343812
Average total loss: 0.451862
tensor(-13.3799, device='cuda:0') tensor(1.2650, device='cuda:0') tensor(-1.5269e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.107933
Average KL loss: 0.343789
Average total loss: 0.451722
tensor(-13.3807, device='cuda:0') tensor(1.2651, device='cuda:0') tensor(-2.5827e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.104188
Average KL loss: 0.343764
Average total loss: 0.447952
tensor(-13.3814, device='cuda:0') tensor(1.2653, device='cuda:0') tensor(-5.9989e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.106062
Average KL loss: 0.343745
Average total loss: 0.449807
tensor(-13.3821, device='cuda:0') tensor(1.2655, device='cuda:0') tensor(-1.3568e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.105555
Average KL loss: 0.343734
Average total loss: 0.449289
tensor(-13.3829, device='cuda:0') tensor(1.2657, device='cuda:0') tensor(2.9076e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.106608
Average KL loss: 0.343724
Average total loss: 0.450332
tensor(-13.3836, device='cuda:0') tensor(1.2660, device='cuda:0') tensor(-1.1434e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.102957
Average KL loss: 0.343702
Average total loss: 0.446659
tensor(-13.3843, device='cuda:0') tensor(1.2661, device='cuda:0') tensor(-6.6464e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.104790
Average KL loss: 0.343686
Average total loss: 0.448476
tensor(-13.3851, device='cuda:0') tensor(1.2664, device='cuda:0') tensor(-1.3973e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.104299
Average KL loss: 0.343678
Average total loss: 0.447977
tensor(-13.3858, device='cuda:0') tensor(1.2666, device='cuda:0') tensor(3.6283e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.103728
Average KL loss: 0.343668
Average total loss: 0.447396
tensor(-13.3865, device='cuda:0') tensor(1.2669, device='cuda:0') tensor(3.8123e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.102402
Average KL loss: 0.343655
Average total loss: 0.446057
tensor(-13.3872, device='cuda:0') tensor(1.2671, device='cuda:0') tensor(-4.5692e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.102727
Average KL loss: 0.343634
Average total loss: 0.446361
tensor(-13.3880, device='cuda:0') tensor(1.2673, device='cuda:0') tensor(-1.2875e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.099164
Average KL loss: 0.343610
Average total loss: 0.442774
tensor(-13.3887, device='cuda:0') tensor(1.2674, device='cuda:0') tensor(-1.0643e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.100104
Average KL loss: 0.343588
Average total loss: 0.443693
tensor(-13.3894, device='cuda:0') tensor(1.2676, device='cuda:0') tensor(-3.2289e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.103404
Average KL loss: 0.343571
Average total loss: 0.446975
tensor(-13.3902, device='cuda:0') tensor(1.2678, device='cuda:0') tensor(-7.8842e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.101892
Average KL loss: 0.343558
Average total loss: 0.445450
tensor(-13.3909, device='cuda:0') tensor(1.2681, device='cuda:0') tensor(-1.6093e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.100172
Average KL loss: 0.343543
Average total loss: 0.443715
tensor(-13.3916, device='cuda:0') tensor(1.2682, device='cuda:0') tensor(-1.1267e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.101578
Average KL loss: 0.343531
Average total loss: 0.445108
tensor(-13.3923, device='cuda:0') tensor(1.2684, device='cuda:0') tensor(-6.3059e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.099696
Average KL loss: 0.343509
Average total loss: 0.443206
tensor(-13.3931, device='cuda:0') tensor(1.2686, device='cuda:0') tensor(-1.6961e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.099688
Average KL loss: 0.343496
Average total loss: 0.443184
tensor(-13.3938, device='cuda:0') tensor(1.2689, device='cuda:0') tensor(-1.7612e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.100069
Average KL loss: 0.343480
Average total loss: 0.443549
tensor(-13.3945, device='cuda:0') tensor(1.2691, device='cuda:0') tensor(-1.1393e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.101436
Average KL loss: 0.343470
Average total loss: 0.444906
tensor(-13.3952, device='cuda:0') tensor(1.2694, device='cuda:0') tensor(2.9050e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.098495
Average KL loss: 0.343454
Average total loss: 0.441949
tensor(-13.3959, device='cuda:0') tensor(1.2696, device='cuda:0') tensor(-5.8886e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.098929
Average KL loss: 0.343438
Average total loss: 0.442366
tensor(-13.3967, device='cuda:0') tensor(1.2698, device='cuda:0') tensor(-1.9866e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.100056
Average KL loss: 0.343419
Average total loss: 0.443476
tensor(-13.3974, device='cuda:0') tensor(1.2700, device='cuda:0') tensor(-4.5974e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.099060
Average KL loss: 0.343406
Average total loss: 0.442466
tensor(-13.3981, device='cuda:0') tensor(1.2702, device='cuda:0') tensor(-9.6662e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.097130
Average KL loss: 0.343388
Average total loss: 0.440518
tensor(-13.3988, device='cuda:0') tensor(1.2705, device='cuda:0') tensor(4.6694e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.098439
Average KL loss: 0.343371
Average total loss: 0.441810
tensor(-13.3995, device='cuda:0') tensor(1.2708, device='cuda:0') tensor(1.5444e-11, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.097735
Average KL loss: 0.343354
Average total loss: 0.441090
tensor(-13.4002, device='cuda:0') tensor(1.2710, device='cuda:0') tensor(-1.9108e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.096649
Average KL loss: 0.343342
Average total loss: 0.439991
tensor(-13.4010, device='cuda:0') tensor(1.2712, device='cuda:0') tensor(-2.0105e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.096220
Average KL loss: 0.343332
Average total loss: 0.439552
tensor(-13.4017, device='cuda:0') tensor(1.2715, device='cuda:0') tensor(-1.7808e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.094870
Average KL loss: 0.343315
Average total loss: 0.438185
tensor(-13.4024, device='cuda:0') tensor(1.2717, device='cuda:0') tensor(-9.3156e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.094168
Average KL loss: 0.343302
Average total loss: 0.437470
tensor(-13.4031, device='cuda:0') tensor(1.2719, device='cuda:0') tensor(-9.1774e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.095273
Average KL loss: 0.343294
Average total loss: 0.438567
tensor(-13.4038, device='cuda:0') tensor(1.2722, device='cuda:0') tensor(-1.0303e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.094787
Average KL loss: 0.343283
Average total loss: 0.438070
tensor(-13.4045, device='cuda:0') tensor(1.2724, device='cuda:0') tensor(-2.0118e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.095430
Average KL loss: 0.343269
Average total loss: 0.438700
tensor(-13.4052, device='cuda:0') tensor(1.2726, device='cuda:0') tensor(-1.8735e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.094029
Average KL loss: 0.343254
Average total loss: 0.437283
tensor(-13.4059, device='cuda:0') tensor(1.2729, device='cuda:0') tensor(-1.1193e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.095043
Average KL loss: 0.343238
Average total loss: 0.438281
tensor(-13.4067, device='cuda:0') tensor(1.2731, device='cuda:0') tensor(-1.9622e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.092373
Average KL loss: 0.343219
Average total loss: 0.435593
tensor(-13.4074, device='cuda:0') tensor(1.2733, device='cuda:0') tensor(-6.9827e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.093678
Average KL loss: 0.343207
Average total loss: 0.436885
tensor(-13.4081, device='cuda:0') tensor(1.2736, device='cuda:0') tensor(-6.5331e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.095973
Average KL loss: 0.343192
Average total loss: 0.439166
tensor(-13.4088, device='cuda:0') tensor(1.2738, device='cuda:0') tensor(-1.6044e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.095005
Average KL loss: 0.343172
Average total loss: 0.438177
tensor(-13.4095, device='cuda:0') tensor(1.2740, device='cuda:0') tensor(-1.0471e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.094562
Average KL loss: 0.343168
Average total loss: 0.437729
tensor(-13.4102, device='cuda:0') tensor(1.2743, device='cuda:0') tensor(-1.3434e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.092959
Average KL loss: 0.343161
Average total loss: 0.436120
tensor(-13.4109, device='cuda:0') tensor(1.2745, device='cuda:0') tensor(-1.0954e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.094889
Average KL loss: 0.343142
Average total loss: 0.438032
tensor(-13.4116, device='cuda:0') tensor(1.2747, device='cuda:0') tensor(-1.8094e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.092782
Average KL loss: 0.343134
Average total loss: 0.435916
tensor(-13.4123, device='cuda:0') tensor(1.2750, device='cuda:0') tensor(-1.8201e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.093284
Average KL loss: 0.343128
Average total loss: 0.436412
tensor(-13.4130, device='cuda:0') tensor(1.2753, device='cuda:0') tensor(-8.4880e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.093549
Average KL loss: 0.343119
Average total loss: 0.436668
tensor(-13.4137, device='cuda:0') tensor(1.2755, device='cuda:0') tensor(-7.2401e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.092573
Average KL loss: 0.343106
Average total loss: 0.435679
tensor(-13.4144, device='cuda:0') tensor(1.2757, device='cuda:0') tensor(-2.6824e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.092614
Average KL loss: 0.343094
Average total loss: 0.435708
tensor(-13.4151, device='cuda:0') tensor(1.2760, device='cuda:0') tensor(-1.0632e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.092275
Average KL loss: 0.343088
Average total loss: 0.435363
tensor(-13.4151, device='cuda:0') tensor(1.2760, device='cuda:0') tensor(-5.0829e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.091268
Average KL loss: 0.343087
Average total loss: 0.434355
tensor(-13.4152, device='cuda:0') tensor(1.2760, device='cuda:0') tensor(-1.3859e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.093940
Average KL loss: 0.343086
Average total loss: 0.437026
tensor(-13.4153, device='cuda:0') tensor(1.2760, device='cuda:0') tensor(6.3141e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.092916
Average KL loss: 0.343085
Average total loss: 0.436000
tensor(-13.4153, device='cuda:0') tensor(1.2760, device='cuda:0') tensor(-1.5861e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.091503
Average KL loss: 0.343084
Average total loss: 0.434586
tensor(-13.4154, device='cuda:0') tensor(1.2761, device='cuda:0') tensor(-1.5753e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.091596
Average KL loss: 0.343082
Average total loss: 0.434678
tensor(-13.4155, device='cuda:0') tensor(1.2761, device='cuda:0') tensor(-5.8422e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.093386
Average KL loss: 0.343080
Average total loss: 0.436466
tensor(-13.4155, device='cuda:0') tensor(1.2761, device='cuda:0') tensor(2.2625e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.090996
Average KL loss: 0.343078
Average total loss: 0.434075
tensor(-13.4156, device='cuda:0') tensor(1.2761, device='cuda:0') tensor(-5.5509e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.091522
Average KL loss: 0.343078
Average total loss: 0.434599
tensor(-13.4156, device='cuda:0') tensor(1.2761, device='cuda:0') tensor(1.0253e-11, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.092935
Average KL loss: 0.343077
Average total loss: 0.436012
tensor(-13.4157, device='cuda:0') tensor(1.2761, device='cuda:0') tensor(-1.3271e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.092170
Average KL loss: 0.343076
Average total loss: 0.435246
tensor(-13.4158, device='cuda:0') tensor(1.2762, device='cuda:0') tensor(5.6720e-11, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.089637
Average KL loss: 0.343075
Average total loss: 0.432712
tensor(-13.4158, device='cuda:0') tensor(1.2762, device='cuda:0') tensor(-2.0920e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.091530
Average KL loss: 0.343074
Average total loss: 0.434604
tensor(-13.4159, device='cuda:0') tensor(1.2762, device='cuda:0') tensor(-6.5324e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.093497
Average KL loss: 0.343072
Average total loss: 0.436569
tensor(-13.4159, device='cuda:0') tensor(1.2762, device='cuda:0') tensor(-1.1813e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.091278
Average KL loss: 0.343071
Average total loss: 0.434349
tensor(-13.4160, device='cuda:0') tensor(1.2762, device='cuda:0') tensor(-2.2994e-11, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.092525
Average KL loss: 0.343070
Average total loss: 0.435595
tensor(-13.4161, device='cuda:0') tensor(1.2763, device='cuda:0') tensor(-2.3117e-12, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.090737
Average KL loss: 0.343069
Average total loss: 0.433806
tensor(-13.4161, device='cuda:0') tensor(1.2763, device='cuda:0') tensor(1.2182e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.092153
Average KL loss: 0.343068
Average total loss: 0.435221
tensor(-13.4162, device='cuda:0') tensor(1.2763, device='cuda:0') tensor(2.0045e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.090940
Average KL loss: 0.343066
Average total loss: 0.434007
tensor(-13.4162, device='cuda:0') tensor(1.2763, device='cuda:0') tensor(-1.3723e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.092852
Average KL loss: 0.343065
Average total loss: 0.435917
tensor(-13.4163, device='cuda:0') tensor(1.2763, device='cuda:0') tensor(-2.4719e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.092615
Average KL loss: 0.343066
Average total loss: 0.435680
tensor(-13.4164, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-8.0241e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.092160
Average KL loss: 0.343066
Average total loss: 0.435226
tensor(-13.4164, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-2.2663e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.092891
Average KL loss: 0.343065
Average total loss: 0.435956
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(3.8116e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.092622
Average KL loss: 0.343064
Average total loss: 0.435686
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-8.6546e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.092139
Average KL loss: 0.343064
Average total loss: 0.435204
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-1.2542e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.091885
Average KL loss: 0.343064
Average total loss: 0.434949
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(7.9011e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.093122
Average KL loss: 0.343064
Average total loss: 0.436186
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-8.9816e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.091393
Average KL loss: 0.343064
Average total loss: 0.434457
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(2.3408e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.091291
Average KL loss: 0.343064
Average total loss: 0.434355
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-1.2565e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.090140
Average KL loss: 0.343064
Average total loss: 0.433203
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-7.9765e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.093434
Average KL loss: 0.343063
Average total loss: 0.436498
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-1.0256e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.091701
Average KL loss: 0.343063
Average total loss: 0.434764
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-1.3181e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.093234
Average KL loss: 0.343063
Average total loss: 0.436297
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(2.9630e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.092739
Average KL loss: 0.343063
Average total loss: 0.435802
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-1.0470e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.090815
Average KL loss: 0.343063
Average total loss: 0.433878
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-5.1258e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.091205
Average KL loss: 0.343063
Average total loss: 0.434268
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(3.5970e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.092586
Average KL loss: 0.343063
Average total loss: 0.435649
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(9.4734e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.090531
Average KL loss: 0.343063
Average total loss: 0.433594
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-7.4919e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.091832
Average KL loss: 0.343063
Average total loss: 0.434895
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-5.0629e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.092319
Average KL loss: 0.343063
Average total loss: 0.435382
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-1.4247e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.090789
Average KL loss: 0.343063
Average total loss: 0.433851
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-5.8997e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.090877
Average KL loss: 0.343063
Average total loss: 0.433940
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(4.0703e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.091729
Average KL loss: 0.343063
Average total loss: 0.434792
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-8.4486e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.090741
Average KL loss: 0.343063
Average total loss: 0.433804
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(-1.1679e-09, device='cuda:0')
 Percentile value: -13.190760612487793
Non-zero model percentage: 10.737431526184082%, Non-zero mask percentage: 10.737431526184082%

--- Pruning Level [10/24]: ---
conv1.weight         | nonzeros =    1561 /    1728             ( 90.34%) | total_pruned =     167 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   16782 /   36864             ( 45.52%) | total_pruned =   20082 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   17330 /   36864             ( 47.01%) | total_pruned =   19534 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   15264 /   36864             ( 41.41%) | total_pruned =   21600 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   14666 /   36864             ( 39.78%) | total_pruned =   22198 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   31354 /   73728             ( 42.53%) | total_pruned =   42374 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   54790 /  147456             ( 37.16%) | total_pruned =   92666 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5293 /    8192             ( 64.61%) | total_pruned =    2899 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   42740 /  147456             ( 28.98%) | total_pruned =  104716 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   43139 /  147456             ( 29.26%) | total_pruned =  104317 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   92534 /  294912             ( 31.38%) | total_pruned =  202378 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  148737 /  589824             ( 25.22%) | total_pruned =  441087 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   15696 /   32768             ( 47.90%) | total_pruned =   17072 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   75553 /  589824             ( 12.81%) | total_pruned =  514271 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     175 /     256             ( 68.36%) | total_pruned =      81 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     141 /     256             ( 55.08%) | total_pruned =     115 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   77760 /  589824             ( 13.18%) | total_pruned =  512064 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  160311 / 1179648             ( 13.59%) | total_pruned = 1019337 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     364 /     512             ( 71.09%) | total_pruned =     148 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     312 /     512             ( 60.94%) | total_pruned =     200 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  170398 / 2359296             (  7.22%) | total_pruned = 2188898 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     456 /     512             ( 89.06%) | total_pruned =      56 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     424 /     512             ( 82.81%) | total_pruned =      88 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   25662 /  131072             ( 19.58%) | total_pruned =  105410 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     381 /     512             ( 74.41%) | total_pruned =     131 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     424 /     512             ( 82.81%) | total_pruned =      88 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   81890 / 2359296             (  3.47%) | total_pruned = 2277406 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     235 /     512             ( 45.90%) | total_pruned =     277 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     124 /     512             ( 24.22%) | total_pruned =     388 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   96769 / 2359296             (  4.10%) | total_pruned = 2262527 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     478 /     512             ( 93.36%) | total_pruned =      34 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     442 /     512             ( 86.33%) | total_pruned =      70 | shape = torch.Size([512])
linear.weight        | nonzeros =    4412 /    5120             ( 86.17%) | total_pruned =     708 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       6 /      10             ( 60.00%) | total_pruned =       4 | shape = torch.Size([10])
alive: 1200312, pruned : 9978450, total: 11178762, Compression rate :       9.31x  ( 89.26% pruned)
Train Epoch: 23/100 Loss: 0.000002 Accuracy: 86.72 100.00 % Best test Accuracy: 86.75%
tensor(-13.4165, device='cuda:0') tensor(1.2764, device='cuda:0') tensor(6.6280e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.172113
Average KL loss: 0.342613
Average total loss: 0.514726
tensor(-13.4181, device='cuda:0') tensor(1.2491, device='cuda:0') tensor(-1.5521e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.167532
Average KL loss: 0.342265
Average total loss: 0.509797
tensor(-13.4193, device='cuda:0') tensor(1.2351, device='cuda:0') tensor(-3.5609e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.168408
Average KL loss: 0.342097
Average total loss: 0.510505
tensor(-13.4203, device='cuda:0') tensor(1.2265, device='cuda:0') tensor(-2.2375e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.166298
Average KL loss: 0.341993
Average total loss: 0.508291
tensor(-13.4212, device='cuda:0') tensor(1.2211, device='cuda:0') tensor(-1.4811e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.167752
Average KL loss: 0.341914
Average total loss: 0.509666
tensor(-13.4220, device='cuda:0') tensor(1.2175, device='cuda:0') tensor(1.1415e-11, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.165561
Average KL loss: 0.341858
Average total loss: 0.507419
tensor(-13.4228, device='cuda:0') tensor(1.2152, device='cuda:0') tensor(6.3123e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.163674
Average KL loss: 0.341810
Average total loss: 0.505485
tensor(-13.4236, device='cuda:0') tensor(1.2137, device='cuda:0') tensor(-2.7603e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.158239
Average KL loss: 0.341772
Average total loss: 0.500011
tensor(-13.4244, device='cuda:0') tensor(1.2125, device='cuda:0') tensor(5.5476e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.161263
Average KL loss: 0.341733
Average total loss: 0.502997
tensor(-13.4252, device='cuda:0') tensor(1.2117, device='cuda:0') tensor(-1.2692e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.154805
Average KL loss: 0.341700
Average total loss: 0.496505
tensor(-13.4259, device='cuda:0') tensor(1.2111, device='cuda:0') tensor(-1.8731e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.153271
Average KL loss: 0.341669
Average total loss: 0.494939
tensor(-13.4267, device='cuda:0') tensor(1.2107, device='cuda:0') tensor(-1.1742e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.154239
Average KL loss: 0.341646
Average total loss: 0.495885
tensor(-13.4274, device='cuda:0') tensor(1.2103, device='cuda:0') tensor(-1.0125e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.150330
Average KL loss: 0.341616
Average total loss: 0.491947
tensor(-13.4281, device='cuda:0') tensor(1.2100, device='cuda:0') tensor(-3.6350e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.152985
Average KL loss: 0.341591
Average total loss: 0.494576
tensor(-13.4289, device='cuda:0') tensor(1.2098, device='cuda:0') tensor(-1.0590e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.149142
Average KL loss: 0.341562
Average total loss: 0.490705
tensor(-13.4296, device='cuda:0') tensor(1.2096, device='cuda:0') tensor(-7.5403e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.147784
Average KL loss: 0.341545
Average total loss: 0.489329
tensor(-13.4303, device='cuda:0') tensor(1.2095, device='cuda:0') tensor(-3.8988e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.147111
Average KL loss: 0.341520
Average total loss: 0.488631
tensor(-13.4310, device='cuda:0') tensor(1.2094, device='cuda:0') tensor(-1.1508e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.145175
Average KL loss: 0.341496
Average total loss: 0.486671
tensor(-13.4318, device='cuda:0') tensor(1.2094, device='cuda:0') tensor(-2.4152e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.145304
Average KL loss: 0.341467
Average total loss: 0.486771
tensor(-13.4325, device='cuda:0') tensor(1.2094, device='cuda:0') tensor(-2.6172e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.143442
Average KL loss: 0.341447
Average total loss: 0.484888
tensor(-13.4332, device='cuda:0') tensor(1.2094, device='cuda:0') tensor(-6.0759e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.142184
Average KL loss: 0.341428
Average total loss: 0.483612
tensor(-13.4339, device='cuda:0') tensor(1.2094, device='cuda:0') tensor(-1.9940e-12, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.144016
Average KL loss: 0.341407
Average total loss: 0.485423
tensor(-13.4346, device='cuda:0') tensor(1.2095, device='cuda:0') tensor(-2.0363e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.140640
Average KL loss: 0.341389
Average total loss: 0.482029
tensor(-13.4353, device='cuda:0') tensor(1.2095, device='cuda:0') tensor(-2.5881e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.143671
Average KL loss: 0.341370
Average total loss: 0.485040
tensor(-13.4360, device='cuda:0') tensor(1.2096, device='cuda:0') tensor(-1.7738e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.141976
Average KL loss: 0.341348
Average total loss: 0.483324
tensor(-13.4367, device='cuda:0') tensor(1.2097, device='cuda:0') tensor(-1.7081e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.138643
Average KL loss: 0.341334
Average total loss: 0.479976
tensor(-13.4374, device='cuda:0') tensor(1.2098, device='cuda:0') tensor(-8.9787e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.139534
Average KL loss: 0.341316
Average total loss: 0.480850
tensor(-13.4381, device='cuda:0') tensor(1.2100, device='cuda:0') tensor(-3.8051e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.137598
Average KL loss: 0.341298
Average total loss: 0.478896
tensor(-13.4388, device='cuda:0') tensor(1.2101, device='cuda:0') tensor(-8.1082e-11, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.137685
Average KL loss: 0.341274
Average total loss: 0.478959
tensor(-13.4395, device='cuda:0') tensor(1.2102, device='cuda:0') tensor(6.2850e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.135027
Average KL loss: 0.341258
Average total loss: 0.476285
tensor(-13.4402, device='cuda:0') tensor(1.2104, device='cuda:0') tensor(-4.8989e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.135556
Average KL loss: 0.341241
Average total loss: 0.476797
tensor(-13.4409, device='cuda:0') tensor(1.2106, device='cuda:0') tensor(-5.4893e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.134475
Average KL loss: 0.341222
Average total loss: 0.475697
tensor(-13.4416, device='cuda:0') tensor(1.2107, device='cuda:0') tensor(-7.1344e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.133625
Average KL loss: 0.341199
Average total loss: 0.474824
tensor(-13.4423, device='cuda:0') tensor(1.2109, device='cuda:0') tensor(9.8481e-11, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.132974
Average KL loss: 0.341171
Average total loss: 0.474145
tensor(-13.4430, device='cuda:0') tensor(1.2110, device='cuda:0') tensor(-2.0700e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.129571
Average KL loss: 0.341149
Average total loss: 0.470721
tensor(-13.4437, device='cuda:0') tensor(1.2112, device='cuda:0') tensor(-1.9507e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.132310
Average KL loss: 0.341126
Average total loss: 0.473437
tensor(-13.4444, device='cuda:0') tensor(1.2114, device='cuda:0') tensor(3.3852e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.131573
Average KL loss: 0.341109
Average total loss: 0.472682
tensor(-13.4451, device='cuda:0') tensor(1.2115, device='cuda:0') tensor(1.1359e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.131579
Average KL loss: 0.341079
Average total loss: 0.472658
tensor(-13.4457, device='cuda:0') tensor(1.2117, device='cuda:0') tensor(-7.0228e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.130971
Average KL loss: 0.341053
Average total loss: 0.472024
tensor(-13.4464, device='cuda:0') tensor(1.2119, device='cuda:0') tensor(-1.5161e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.129836
Average KL loss: 0.341041
Average total loss: 0.470877
tensor(-13.4471, device='cuda:0') tensor(1.2121, device='cuda:0') tensor(-1.8737e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.127712
Average KL loss: 0.341032
Average total loss: 0.468744
tensor(-13.4478, device='cuda:0') tensor(1.2123, device='cuda:0') tensor(-1.9092e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.126643
Average KL loss: 0.341018
Average total loss: 0.467661
tensor(-13.4485, device='cuda:0') tensor(1.2125, device='cuda:0') tensor(-1.2879e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.127622
Average KL loss: 0.341006
Average total loss: 0.468628
tensor(-13.4492, device='cuda:0') tensor(1.2128, device='cuda:0') tensor(-2.6182e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.124418
Average KL loss: 0.340986
Average total loss: 0.465404
tensor(-13.4498, device='cuda:0') tensor(1.2130, device='cuda:0') tensor(5.9234e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.127320
Average KL loss: 0.340962
Average total loss: 0.468282
tensor(-13.4505, device='cuda:0') tensor(1.2133, device='cuda:0') tensor(-4.8962e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.126337
Average KL loss: 0.340935
Average total loss: 0.467272
tensor(-13.4512, device='cuda:0') tensor(1.2135, device='cuda:0') tensor(-1.3565e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.123135
Average KL loss: 0.340916
Average total loss: 0.464051
tensor(-13.4519, device='cuda:0') tensor(1.2137, device='cuda:0') tensor(-1.9261e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.122484
Average KL loss: 0.340888
Average total loss: 0.463372
tensor(-13.4526, device='cuda:0') tensor(1.2139, device='cuda:0') tensor(-6.5582e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.123327
Average KL loss: 0.340866
Average total loss: 0.464194
tensor(-13.4532, device='cuda:0') tensor(1.2142, device='cuda:0') tensor(-8.9439e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.125659
Average KL loss: 0.340843
Average total loss: 0.466502
tensor(-13.4539, device='cuda:0') tensor(1.2145, device='cuda:0') tensor(-1.9159e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.121038
Average KL loss: 0.340816
Average total loss: 0.461854
tensor(-13.4546, device='cuda:0') tensor(1.2146, device='cuda:0') tensor(-1.8699e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.123543
Average KL loss: 0.340791
Average total loss: 0.464333
tensor(-13.4553, device='cuda:0') tensor(1.2149, device='cuda:0') tensor(-5.7263e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.122363
Average KL loss: 0.340772
Average total loss: 0.463135
tensor(-13.4559, device='cuda:0') tensor(1.2152, device='cuda:0') tensor(-1.2551e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.122561
Average KL loss: 0.340748
Average total loss: 0.463309
tensor(-13.4566, device='cuda:0') tensor(1.2155, device='cuda:0') tensor(-7.4733e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.122345
Average KL loss: 0.340719
Average total loss: 0.463064
tensor(-13.4573, device='cuda:0') tensor(1.2158, device='cuda:0') tensor(-1.4470e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.123794
Average KL loss: 0.340698
Average total loss: 0.464492
tensor(-13.4580, device='cuda:0') tensor(1.2161, device='cuda:0') tensor(8.2060e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.120416
Average KL loss: 0.340681
Average total loss: 0.461097
tensor(-13.4586, device='cuda:0') tensor(1.2164, device='cuda:0') tensor(-1.3136e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.122113
Average KL loss: 0.340662
Average total loss: 0.462775
tensor(-13.4593, device='cuda:0') tensor(1.2167, device='cuda:0') tensor(-7.9084e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.118178
Average KL loss: 0.340640
Average total loss: 0.458818
tensor(-13.4600, device='cuda:0') tensor(1.2169, device='cuda:0') tensor(-8.3219e-11, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.118141
Average KL loss: 0.340610
Average total loss: 0.458750
tensor(-13.4606, device='cuda:0') tensor(1.2171, device='cuda:0') tensor(-5.7659e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.122546
Average KL loss: 0.340589
Average total loss: 0.463134
tensor(-13.4613, device='cuda:0') tensor(1.2174, device='cuda:0') tensor(-5.9528e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.121613
Average KL loss: 0.340565
Average total loss: 0.462179
tensor(-13.4620, device='cuda:0') tensor(1.2176, device='cuda:0') tensor(-2.1693e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.116238
Average KL loss: 0.340540
Average total loss: 0.456779
tensor(-13.4627, device='cuda:0') tensor(1.2179, device='cuda:0') tensor(-6.8135e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.119404
Average KL loss: 0.340519
Average total loss: 0.459923
tensor(-13.4633, device='cuda:0') tensor(1.2182, device='cuda:0') tensor(-8.4616e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.119224
Average KL loss: 0.340505
Average total loss: 0.459729
tensor(-13.4640, device='cuda:0') tensor(1.2185, device='cuda:0') tensor(-1.8643e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.118023
Average KL loss: 0.340483
Average total loss: 0.458506
tensor(-13.4647, device='cuda:0') tensor(1.2187, device='cuda:0') tensor(6.7655e-11, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.117135
Average KL loss: 0.340459
Average total loss: 0.457594
tensor(-13.4653, device='cuda:0') tensor(1.2190, device='cuda:0') tensor(-1.5477e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.115863
Average KL loss: 0.340456
Average total loss: 0.456318
tensor(-13.4660, device='cuda:0') tensor(1.2193, device='cuda:0') tensor(-8.8207e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.115661
Average KL loss: 0.340450
Average total loss: 0.456111
tensor(-13.4666, device='cuda:0') tensor(1.2196, device='cuda:0') tensor(-1.3692e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.116433
Average KL loss: 0.340445
Average total loss: 0.456878
tensor(-13.4673, device='cuda:0') tensor(1.2199, device='cuda:0') tensor(-1.5926e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.116760
Average KL loss: 0.340429
Average total loss: 0.457189
tensor(-13.4680, device='cuda:0') tensor(1.2202, device='cuda:0') tensor(1.2079e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.114407
Average KL loss: 0.340420
Average total loss: 0.454826
tensor(-13.4686, device='cuda:0') tensor(1.2205, device='cuda:0') tensor(-2.4127e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.113883
Average KL loss: 0.340404
Average total loss: 0.454287
tensor(-13.4693, device='cuda:0') tensor(1.2208, device='cuda:0') tensor(-3.9244e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.116248
Average KL loss: 0.340389
Average total loss: 0.456637
tensor(-13.4700, device='cuda:0') tensor(1.2210, device='cuda:0') tensor(-3.3618e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.114210
Average KL loss: 0.340381
Average total loss: 0.454592
tensor(-13.4706, device='cuda:0') tensor(1.2213, device='cuda:0') tensor(1.2016e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.111465
Average KL loss: 0.340371
Average total loss: 0.451837
tensor(-13.4713, device='cuda:0') tensor(1.2216, device='cuda:0') tensor(3.5460e-11, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.112170
Average KL loss: 0.340358
Average total loss: 0.452528
tensor(-13.4719, device='cuda:0') tensor(1.2218, device='cuda:0') tensor(8.0398e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.114386
Average KL loss: 0.340342
Average total loss: 0.454727
tensor(-13.4726, device='cuda:0') tensor(1.2221, device='cuda:0') tensor(-1.8869e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.113973
Average KL loss: 0.340319
Average total loss: 0.454292
tensor(-13.4733, device='cuda:0') tensor(1.2224, device='cuda:0') tensor(-4.2179e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.113836
Average KL loss: 0.340309
Average total loss: 0.454145
tensor(-13.4739, device='cuda:0') tensor(1.2227, device='cuda:0') tensor(-5.9708e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.111579
Average KL loss: 0.340287
Average total loss: 0.451865
tensor(-13.4746, device='cuda:0') tensor(1.2229, device='cuda:0') tensor(-7.5705e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.111753
Average KL loss: 0.340266
Average total loss: 0.452019
tensor(-13.4752, device='cuda:0') tensor(1.2232, device='cuda:0') tensor(-8.0803e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.110838
Average KL loss: 0.340248
Average total loss: 0.451086
tensor(-13.4759, device='cuda:0') tensor(1.2235, device='cuda:0') tensor(-1.6301e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.113207
Average KL loss: 0.340226
Average total loss: 0.453433
tensor(-13.4766, device='cuda:0') tensor(1.2238, device='cuda:0') tensor(-2.1641e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.111541
Average KL loss: 0.340209
Average total loss: 0.451750
tensor(-13.4772, device='cuda:0') tensor(1.2241, device='cuda:0') tensor(-2.0019e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.109329
Average KL loss: 0.340188
Average total loss: 0.449518
tensor(-13.4779, device='cuda:0') tensor(1.2244, device='cuda:0') tensor(-4.7110e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.112756
Average KL loss: 0.340169
Average total loss: 0.452925
tensor(-13.4785, device='cuda:0') tensor(1.2247, device='cuda:0') tensor(1.1443e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.108918
Average KL loss: 0.340147
Average total loss: 0.449065
tensor(-13.4792, device='cuda:0') tensor(1.2250, device='cuda:0') tensor(-2.0306e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.108702
Average KL loss: 0.340133
Average total loss: 0.448836
tensor(-13.4798, device='cuda:0') tensor(1.2253, device='cuda:0') tensor(-2.0981e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.108201
Average KL loss: 0.340120
Average total loss: 0.448321
tensor(-13.4805, device='cuda:0') tensor(1.2256, device='cuda:0') tensor(-8.9985e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.108362
Average KL loss: 0.340108
Average total loss: 0.448470
tensor(-13.4811, device='cuda:0') tensor(1.2259, device='cuda:0') tensor(-1.0049e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.108733
Average KL loss: 0.340088
Average total loss: 0.448821
tensor(-13.4818, device='cuda:0') tensor(1.2262, device='cuda:0') tensor(-8.9189e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.108262
Average KL loss: 0.340080
Average total loss: 0.448341
tensor(-13.4824, device='cuda:0') tensor(1.2265, device='cuda:0') tensor(-1.5374e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.108625
Average KL loss: 0.340063
Average total loss: 0.448688
tensor(-13.4831, device='cuda:0') tensor(1.2268, device='cuda:0') tensor(-8.2560e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.108116
Average KL loss: 0.340044
Average total loss: 0.448160
tensor(-13.4837, device='cuda:0') tensor(1.2271, device='cuda:0') tensor(-3.8906e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.109042
Average KL loss: 0.340031
Average total loss: 0.449073
tensor(-13.4844, device='cuda:0') tensor(1.2274, device='cuda:0') tensor(-3.9555e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.106155
Average KL loss: 0.340018
Average total loss: 0.446173
tensor(-13.4850, device='cuda:0') tensor(1.2277, device='cuda:0') tensor(-6.6725e-11, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.105787
Average KL loss: 0.339997
Average total loss: 0.445783
tensor(-13.4857, device='cuda:0') tensor(1.2280, device='cuda:0') tensor(-2.6084e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.107101
Average KL loss: 0.339981
Average total loss: 0.447082
tensor(-13.4863, device='cuda:0') tensor(1.2283, device='cuda:0') tensor(-9.8941e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.105207
Average KL loss: 0.339969
Average total loss: 0.445175
tensor(-13.4870, device='cuda:0') tensor(1.2286, device='cuda:0') tensor(-4.3614e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.104293
Average KL loss: 0.339957
Average total loss: 0.444250
tensor(-13.4876, device='cuda:0') tensor(1.2289, device='cuda:0') tensor(5.8659e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.108876
Average KL loss: 0.339942
Average total loss: 0.448818
tensor(-13.4883, device='cuda:0') tensor(1.2292, device='cuda:0') tensor(-6.0195e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.105298
Average KL loss: 0.339921
Average total loss: 0.445219
tensor(-13.4889, device='cuda:0') tensor(1.2295, device='cuda:0') tensor(-1.7966e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.106529
Average KL loss: 0.339903
Average total loss: 0.446432
tensor(-13.4896, device='cuda:0') tensor(1.2298, device='cuda:0') tensor(1.3117e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.104509
Average KL loss: 0.339887
Average total loss: 0.444396
tensor(-13.4902, device='cuda:0') tensor(1.2301, device='cuda:0') tensor(-1.7639e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.108467
Average KL loss: 0.339872
Average total loss: 0.448339
tensor(-13.4909, device='cuda:0') tensor(1.2304, device='cuda:0') tensor(-1.0791e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.105910
Average KL loss: 0.339859
Average total loss: 0.445769
tensor(-13.4915, device='cuda:0') tensor(1.2307, device='cuda:0') tensor(1.3771e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.103926
Average KL loss: 0.339837
Average total loss: 0.443763
tensor(-13.4922, device='cuda:0') tensor(1.2310, device='cuda:0') tensor(3.1043e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.102871
Average KL loss: 0.339821
Average total loss: 0.442692
tensor(-13.4928, device='cuda:0') tensor(1.2313, device='cuda:0') tensor(-1.3189e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.103609
Average KL loss: 0.339799
Average total loss: 0.443408
tensor(-13.4935, device='cuda:0') tensor(1.2315, device='cuda:0') tensor(-1.2911e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.104522
Average KL loss: 0.339775
Average total loss: 0.444297
tensor(-13.4941, device='cuda:0') tensor(1.2318, device='cuda:0') tensor(-4.5104e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.105488
Average KL loss: 0.339752
Average total loss: 0.445239
tensor(-13.4947, device='cuda:0') tensor(1.2321, device='cuda:0') tensor(-1.8362e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.103039
Average KL loss: 0.339736
Average total loss: 0.442775
tensor(-13.4954, device='cuda:0') tensor(1.2324, device='cuda:0') tensor(-2.3419e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.103263
Average KL loss: 0.339717
Average total loss: 0.442981
tensor(-13.4960, device='cuda:0') tensor(1.2327, device='cuda:0') tensor(-3.8954e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.102657
Average KL loss: 0.339706
Average total loss: 0.442363
tensor(-13.4967, device='cuda:0') tensor(1.2330, device='cuda:0') tensor(-4.5899e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.102890
Average KL loss: 0.339685
Average total loss: 0.442576
tensor(-13.4973, device='cuda:0') tensor(1.2333, device='cuda:0') tensor(-1.6787e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.105291
Average KL loss: 0.339673
Average total loss: 0.444964
tensor(-13.4980, device='cuda:0') tensor(1.2336, device='cuda:0') tensor(-1.0937e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.106137
Average KL loss: 0.339665
Average total loss: 0.445802
tensor(-13.4986, device='cuda:0') tensor(1.2339, device='cuda:0') tensor(-1.4273e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.104262
Average KL loss: 0.339656
Average total loss: 0.443918
tensor(-13.4992, device='cuda:0') tensor(1.2342, device='cuda:0') tensor(1.7252e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.103011
Average KL loss: 0.339643
Average total loss: 0.442653
tensor(-13.4999, device='cuda:0') tensor(1.2345, device='cuda:0') tensor(2.8217e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.101723
Average KL loss: 0.339626
Average total loss: 0.441349
tensor(-13.5005, device='cuda:0') tensor(1.2348, device='cuda:0') tensor(2.3221e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.102695
Average KL loss: 0.339612
Average total loss: 0.442307
tensor(-13.5012, device='cuda:0') tensor(1.2351, device='cuda:0') tensor(-3.0152e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.101936
Average KL loss: 0.339605
Average total loss: 0.441541
tensor(-13.5018, device='cuda:0') tensor(1.2355, device='cuda:0') tensor(-1.0006e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.100737
Average KL loss: 0.339601
Average total loss: 0.440337
tensor(-13.5024, device='cuda:0') tensor(1.2358, device='cuda:0') tensor(1.6314e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.101973
Average KL loss: 0.339585
Average total loss: 0.441558
tensor(-13.5031, device='cuda:0') tensor(1.2362, device='cuda:0') tensor(-9.6847e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.101221
Average KL loss: 0.339567
Average total loss: 0.440788
tensor(-13.5037, device='cuda:0') tensor(1.2365, device='cuda:0') tensor(-4.8501e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.102984
Average KL loss: 0.339546
Average total loss: 0.442530
tensor(-13.5043, device='cuda:0') tensor(1.2368, device='cuda:0') tensor(1.4181e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.101451
Average KL loss: 0.339526
Average total loss: 0.440977
tensor(-13.5050, device='cuda:0') tensor(1.2371, device='cuda:0') tensor(1.0421e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.100807
Average KL loss: 0.339504
Average total loss: 0.440311
tensor(-13.5056, device='cuda:0') tensor(1.2374, device='cuda:0') tensor(8.2609e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.099227
Average KL loss: 0.339488
Average total loss: 0.438716
tensor(-13.5063, device='cuda:0') tensor(1.2377, device='cuda:0') tensor(-1.1310e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.098148
Average KL loss: 0.339468
Average total loss: 0.437616
tensor(-13.5069, device='cuda:0') tensor(1.2380, device='cuda:0') tensor(-1.7498e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.099692
Average KL loss: 0.339447
Average total loss: 0.439139
tensor(-13.5075, device='cuda:0') tensor(1.2383, device='cuda:0') tensor(-4.3669e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.099494
Average KL loss: 0.339427
Average total loss: 0.438922
tensor(-13.5082, device='cuda:0') tensor(1.2385, device='cuda:0') tensor(-2.7207e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.099505
Average KL loss: 0.339403
Average total loss: 0.438908
tensor(-13.5088, device='cuda:0') tensor(1.2388, device='cuda:0') tensor(-5.9128e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.099256
Average KL loss: 0.339381
Average total loss: 0.438638
tensor(-13.5094, device='cuda:0') tensor(1.2391, device='cuda:0') tensor(-2.2038e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.098873
Average KL loss: 0.339368
Average total loss: 0.438242
tensor(-13.5101, device='cuda:0') tensor(1.2394, device='cuda:0') tensor(-1.5745e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.098044
Average KL loss: 0.339353
Average total loss: 0.437397
tensor(-13.5107, device='cuda:0') tensor(1.2397, device='cuda:0') tensor(-3.3074e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.099428
Average KL loss: 0.339335
Average total loss: 0.438763
tensor(-13.5113, device='cuda:0') tensor(1.2400, device='cuda:0') tensor(-1.4626e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.096347
Average KL loss: 0.339318
Average total loss: 0.435665
tensor(-13.5120, device='cuda:0') tensor(1.2404, device='cuda:0') tensor(-7.8818e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.098731
Average KL loss: 0.339310
Average total loss: 0.438041
tensor(-13.5126, device='cuda:0') tensor(1.2407, device='cuda:0') tensor(1.2727e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.097460
Average KL loss: 0.339297
Average total loss: 0.436757
tensor(-13.5132, device='cuda:0') tensor(1.2410, device='cuda:0') tensor(2.2371e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.099248
Average KL loss: 0.339282
Average total loss: 0.438530
tensor(-13.5139, device='cuda:0') tensor(1.2413, device='cuda:0') tensor(-8.4236e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.095694
Average KL loss: 0.339270
Average total loss: 0.434964
tensor(-13.5145, device='cuda:0') tensor(1.2416, device='cuda:0') tensor(-1.1199e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.098934
Average KL loss: 0.339253
Average total loss: 0.438187
tensor(-13.5151, device='cuda:0') tensor(1.2419, device='cuda:0') tensor(5.2891e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.097603
Average KL loss: 0.339238
Average total loss: 0.436840
tensor(-13.5157, device='cuda:0') tensor(1.2422, device='cuda:0') tensor(-6.4227e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.098704
Average KL loss: 0.339226
Average total loss: 0.437930
tensor(-13.5164, device='cuda:0') tensor(1.2425, device='cuda:0') tensor(-1.1214e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.097940
Average KL loss: 0.339208
Average total loss: 0.437148
tensor(-13.5170, device='cuda:0') tensor(1.2428, device='cuda:0') tensor(-6.3236e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.097064
Average KL loss: 0.339198
Average total loss: 0.436261
tensor(-13.5176, device='cuda:0') tensor(1.2432, device='cuda:0') tensor(-4.3682e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.097485
Average KL loss: 0.339190
Average total loss: 0.436675
tensor(-13.5182, device='cuda:0') tensor(1.2435, device='cuda:0') tensor(3.4541e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.097502
Average KL loss: 0.339177
Average total loss: 0.436679
tensor(-13.5189, device='cuda:0') tensor(1.2438, device='cuda:0') tensor(-1.8468e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.096193
Average KL loss: 0.339162
Average total loss: 0.435354
tensor(-13.5195, device='cuda:0') tensor(1.2442, device='cuda:0') tensor(-3.6068e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.094845
Average KL loss: 0.339146
Average total loss: 0.433991
tensor(-13.5201, device='cuda:0') tensor(1.2445, device='cuda:0') tensor(1.4558e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.095245
Average KL loss: 0.339130
Average total loss: 0.434375
tensor(-13.5207, device='cuda:0') tensor(1.2447, device='cuda:0') tensor(-8.5498e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.094931
Average KL loss: 0.339113
Average total loss: 0.434044
tensor(-13.5213, device='cuda:0') tensor(1.2450, device='cuda:0') tensor(-8.8061e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.095282
Average KL loss: 0.339092
Average total loss: 0.434373
tensor(-13.5220, device='cuda:0') tensor(1.2453, device='cuda:0') tensor(-9.3482e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.095481
Average KL loss: 0.339073
Average total loss: 0.434553
tensor(-13.5226, device='cuda:0') tensor(1.2457, device='cuda:0') tensor(-2.0624e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.096410
Average KL loss: 0.339058
Average total loss: 0.435468
tensor(-13.5232, device='cuda:0') tensor(1.2460, device='cuda:0') tensor(1.0183e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.096142
Average KL loss: 0.339032
Average total loss: 0.435174
tensor(-13.5238, device='cuda:0') tensor(1.2463, device='cuda:0') tensor(-6.8573e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.094957
Average KL loss: 0.339018
Average total loss: 0.433974
tensor(-13.5244, device='cuda:0') tensor(1.2465, device='cuda:0') tensor(-1.7478e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.096638
Average KL loss: 0.339003
Average total loss: 0.435641
tensor(-13.5250, device='cuda:0') tensor(1.2468, device='cuda:0') tensor(-1.4329e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.096419
Average KL loss: 0.338995
Average total loss: 0.435414
tensor(-13.5257, device='cuda:0') tensor(1.2472, device='cuda:0') tensor(-1.4218e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.095219
Average KL loss: 0.338988
Average total loss: 0.434207
tensor(-13.5263, device='cuda:0') tensor(1.2475, device='cuda:0') tensor(-8.9011e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.097038
Average KL loss: 0.338975
Average total loss: 0.436013
tensor(-13.5269, device='cuda:0') tensor(1.2478, device='cuda:0') tensor(-6.8779e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.094386
Average KL loss: 0.338969
Average total loss: 0.433355
tensor(-13.5270, device='cuda:0') tensor(1.2478, device='cuda:0') tensor(-1.7237e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.092361
Average KL loss: 0.338967
Average total loss: 0.431328
tensor(-13.5270, device='cuda:0') tensor(1.2479, device='cuda:0') tensor(-4.9245e-11, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.095071
Average KL loss: 0.338966
Average total loss: 0.434037
tensor(-13.5271, device='cuda:0') tensor(1.2479, device='cuda:0') tensor(3.6324e-11, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.093263
Average KL loss: 0.338966
Average total loss: 0.432229
tensor(-13.5271, device='cuda:0') tensor(1.2479, device='cuda:0') tensor(1.2774e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.096864
Average KL loss: 0.338964
Average total loss: 0.435828
tensor(-13.5272, device='cuda:0') tensor(1.2479, device='cuda:0') tensor(7.8756e-11, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.095009
Average KL loss: 0.338963
Average total loss: 0.433972
tensor(-13.5272, device='cuda:0') tensor(1.2480, device='cuda:0') tensor(-9.4480e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.093837
Average KL loss: 0.338962
Average total loss: 0.432800
tensor(-13.5273, device='cuda:0') tensor(1.2480, device='cuda:0') tensor(4.5950e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.095465
Average KL loss: 0.338962
Average total loss: 0.434427
tensor(-13.5273, device='cuda:0') tensor(1.2480, device='cuda:0') tensor(2.5314e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.093981
Average KL loss: 0.338960
Average total loss: 0.432941
tensor(-13.5274, device='cuda:0') tensor(1.2481, device='cuda:0') tensor(-9.0043e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.092839
Average KL loss: 0.338959
Average total loss: 0.431798
tensor(-13.5274, device='cuda:0') tensor(1.2481, device='cuda:0') tensor(-4.1663e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.095341
Average KL loss: 0.338958
Average total loss: 0.434299
tensor(-13.5275, device='cuda:0') tensor(1.2481, device='cuda:0') tensor(-1.1018e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.094435
Average KL loss: 0.338958
Average total loss: 0.433392
tensor(-13.5275, device='cuda:0') tensor(1.2481, device='cuda:0') tensor(-1.4215e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.094561
Average KL loss: 0.338956
Average total loss: 0.433518
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-1.5932e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.093749
Average KL loss: 0.338956
Average total loss: 0.432705
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-2.2386e-11, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.094753
Average KL loss: 0.338956
Average total loss: 0.433709
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-1.0016e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.095096
Average KL loss: 0.338955
Average total loss: 0.434051
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-1.3143e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.094893
Average KL loss: 0.338955
Average total loss: 0.433848
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(7.9740e-11, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.093024
Average KL loss: 0.338955
Average total loss: 0.431980
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(2.5416e-11, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.093913
Average KL loss: 0.338955
Average total loss: 0.432868
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-1.2376e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.094575
Average KL loss: 0.338955
Average total loss: 0.433530
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-9.4104e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.095597
Average KL loss: 0.338955
Average total loss: 0.434552
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(3.9525e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.094360
Average KL loss: 0.338955
Average total loss: 0.433315
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-2.7614e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.093270
Average KL loss: 0.338955
Average total loss: 0.432225
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-2.3443e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.095018
Average KL loss: 0.338954
Average total loss: 0.433973
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-1.6515e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.093425
Average KL loss: 0.338954
Average total loss: 0.432380
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-5.9862e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.094040
Average KL loss: 0.338954
Average total loss: 0.432994
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-1.0504e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.095522
Average KL loss: 0.338954
Average total loss: 0.434476
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-1.3578e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.095641
Average KL loss: 0.338954
Average total loss: 0.434595
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-1.4205e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.094485
Average KL loss: 0.338954
Average total loss: 0.433440
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-1.5645e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.096130
Average KL loss: 0.338954
Average total loss: 0.435085
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-1.0239e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.095191
Average KL loss: 0.338954
Average total loss: 0.434145
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-1.5807e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.094824
Average KL loss: 0.338954
Average total loss: 0.433778
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(6.6834e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.094367
Average KL loss: 0.338954
Average total loss: 0.433321
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-4.5750e-11, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.091893
Average KL loss: 0.338954
Average total loss: 0.430847
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-7.0540e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.097595
Average KL loss: 0.338954
Average total loss: 0.436549
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(3.0562e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.095400
Average KL loss: 0.338954
Average total loss: 0.434354
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-6.3659e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.095657
Average KL loss: 0.338954
Average total loss: 0.434612
 Percentile value: -13.267294120788574
Non-zero model percentage: 8.589949607849121%, Non-zero mask percentage: 8.589949607849121%

--- Pruning Level [11/24]: ---
conv1.weight         | nonzeros =    1517 /    1728             ( 87.79%) | total_pruned =     211 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   14758 /   36864             ( 40.03%) | total_pruned =   22106 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   15204 /   36864             ( 41.24%) | total_pruned =   21660 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   13386 /   36864             ( 36.31%) | total_pruned =   23478 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   12817 /   36864             ( 34.77%) | total_pruned =   24047 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   27445 /   73728             ( 37.22%) | total_pruned =   46283 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   46909 /  147456             ( 31.81%) | total_pruned =  100547 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4904 /    8192             ( 59.86%) | total_pruned =    3288 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   35859 /  147456             ( 24.32%) | total_pruned =  111597 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   35942 /  147456             ( 24.37%) | total_pruned =  111514 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   77667 /  294912             ( 26.34%) | total_pruned =  217245 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     227 /     256             ( 88.67%) | total_pruned =      29 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  121344 /  589824             ( 20.57%) | total_pruned =  468480 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   13866 /   32768             ( 42.32%) | total_pruned =   18902 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   59179 /  589824             ( 10.03%) | total_pruned =  530645 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     169 /     256             ( 66.02%) | total_pruned =      87 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   60681 /  589824             ( 10.29%) | total_pruned =  529143 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  126065 / 1179648             ( 10.69%) | total_pruned = 1053583 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     345 /     512             ( 67.38%) | total_pruned =     167 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     299 /     512             ( 58.40%) | total_pruned =     213 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  129083 / 2359296             (  5.47%) | total_pruned = 2230213 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     442 /     512             ( 86.33%) | total_pruned =      70 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     407 /     512             ( 79.49%) | total_pruned =     105 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   21094 /  131072             ( 16.09%) | total_pruned =  109978 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     355 /     512             ( 69.34%) | total_pruned =     157 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     406 /     512             ( 79.30%) | total_pruned =     106 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   60261 / 2359296             (  2.55%) | total_pruned = 2299035 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     219 /     512             ( 42.77%) | total_pruned =     293 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     100 /     512             ( 19.53%) | total_pruned =     412 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   70630 / 2359296             (  2.99%) | total_pruned = 2288666 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     465 /     512             ( 90.82%) | total_pruned =      47 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     421 /     512             ( 82.23%) | total_pruned =      91 | shape = torch.Size([512])
linear.weight        | nonzeros =    4252 /    5120             ( 83.05%) | total_pruned =     868 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       6 /      10             ( 60.00%) | total_pruned =       4 | shape = torch.Size([10])
alive: 960250, pruned : 10218512, total: 11178762, Compression rate :      11.64x  ( 91.41% pruned)
Train Epoch: 21/100 Loss: 0.000058 Accuracy: 86.61 100.00 % Best test Accuracy: 86.76%
tensor(-13.5276, device='cuda:0') tensor(1.2482, device='cuda:0') tensor(-6.6232e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.166088
Average KL loss: 0.338565
Average total loss: 0.504653
tensor(-13.5290, device='cuda:0') tensor(1.2218, device='cuda:0') tensor(2.2659e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.163677
Average KL loss: 0.338259
Average total loss: 0.501936
tensor(-13.5301, device='cuda:0') tensor(1.2077, device='cuda:0') tensor(-1.3193e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.161800
Average KL loss: 0.338105
Average total loss: 0.499905
tensor(-13.5310, device='cuda:0') tensor(1.1990, device='cuda:0') tensor(-4.7295e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.163384
Average KL loss: 0.337992
Average total loss: 0.501376
tensor(-13.5318, device='cuda:0') tensor(1.1936, device='cuda:0') tensor(1.4399e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.160350
Average KL loss: 0.337910
Average total loss: 0.498260
tensor(-13.5325, device='cuda:0') tensor(1.1901, device='cuda:0') tensor(-1.6895e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.158932
Average KL loss: 0.337842
Average total loss: 0.496775
tensor(-13.5332, device='cuda:0') tensor(1.1880, device='cuda:0') tensor(4.6660e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.159538
Average KL loss: 0.337770
Average total loss: 0.497308
tensor(-13.5339, device='cuda:0') tensor(1.1865, device='cuda:0') tensor(3.8237e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.161407
Average KL loss: 0.337720
Average total loss: 0.499127
tensor(-13.5346, device='cuda:0') tensor(1.1855, device='cuda:0') tensor(-1.0552e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.157211
Average KL loss: 0.337681
Average total loss: 0.494892
tensor(-13.5353, device='cuda:0') tensor(1.1849, device='cuda:0') tensor(1.0653e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.156378
Average KL loss: 0.337648
Average total loss: 0.494026
tensor(-13.5359, device='cuda:0') tensor(1.1845, device='cuda:0') tensor(1.5466e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.153936
Average KL loss: 0.337612
Average total loss: 0.491549
tensor(-13.5366, device='cuda:0') tensor(1.1842, device='cuda:0') tensor(-1.8665e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.151318
Average KL loss: 0.337579
Average total loss: 0.488897
tensor(-13.5372, device='cuda:0') tensor(1.1840, device='cuda:0') tensor(-2.1422e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.152630
Average KL loss: 0.337542
Average total loss: 0.490172
tensor(-13.5379, device='cuda:0') tensor(1.1839, device='cuda:0') tensor(-2.4595e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.150161
Average KL loss: 0.337510
Average total loss: 0.487671
tensor(-13.5385, device='cuda:0') tensor(1.1839, device='cuda:0') tensor(-7.9803e-11, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.147729
Average KL loss: 0.337475
Average total loss: 0.485204
tensor(-13.5391, device='cuda:0') tensor(1.1839, device='cuda:0') tensor(-1.9795e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.148789
Average KL loss: 0.337451
Average total loss: 0.486240
tensor(-13.5398, device='cuda:0') tensor(1.1840, device='cuda:0') tensor(-1.7320e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.147963
Average KL loss: 0.337424
Average total loss: 0.485387
tensor(-13.5404, device='cuda:0') tensor(1.1841, device='cuda:0') tensor(-7.8885e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.146691
Average KL loss: 0.337393
Average total loss: 0.484085
tensor(-13.5410, device='cuda:0') tensor(1.1842, device='cuda:0') tensor(-7.8840e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.145077
Average KL loss: 0.337365
Average total loss: 0.482442
tensor(-13.5417, device='cuda:0') tensor(1.1843, device='cuda:0') tensor(-5.1830e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.146225
Average KL loss: 0.337340
Average total loss: 0.483565
tensor(-13.5423, device='cuda:0') tensor(1.1844, device='cuda:0') tensor(-2.2237e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.146286
Average KL loss: 0.337323
Average total loss: 0.483609
tensor(-13.5429, device='cuda:0') tensor(1.1846, device='cuda:0') tensor(-2.9264e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.142875
Average KL loss: 0.337309
Average total loss: 0.480183
tensor(-13.5435, device='cuda:0') tensor(1.1848, device='cuda:0') tensor(-6.4650e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.143652
Average KL loss: 0.337285
Average total loss: 0.480938
tensor(-13.5442, device='cuda:0') tensor(1.1850, device='cuda:0') tensor(-2.1624e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.138747
Average KL loss: 0.337259
Average total loss: 0.476007
tensor(-13.5448, device='cuda:0') tensor(1.1851, device='cuda:0') tensor(-2.9201e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.140118
Average KL loss: 0.337241
Average total loss: 0.477359
tensor(-13.5454, device='cuda:0') tensor(1.1853, device='cuda:0') tensor(-2.1950e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.142154
Average KL loss: 0.337219
Average total loss: 0.479373
tensor(-13.5460, device='cuda:0') tensor(1.1856, device='cuda:0') tensor(-2.3845e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.142558
Average KL loss: 0.337201
Average total loss: 0.479759
tensor(-13.5466, device='cuda:0') tensor(1.1859, device='cuda:0') tensor(-1.5889e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.139491
Average KL loss: 0.337181
Average total loss: 0.476671
tensor(-13.5472, device='cuda:0') tensor(1.1861, device='cuda:0') tensor(1.6534e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.141445
Average KL loss: 0.337155
Average total loss: 0.478600
tensor(-13.5479, device='cuda:0') tensor(1.1863, device='cuda:0') tensor(1.4306e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.141162
Average KL loss: 0.337127
Average total loss: 0.478289
tensor(-13.5485, device='cuda:0') tensor(1.1865, device='cuda:0') tensor(-9.9559e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.137652
Average KL loss: 0.337101
Average total loss: 0.474753
tensor(-13.5491, device='cuda:0') tensor(1.1868, device='cuda:0') tensor(2.0814e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.135446
Average KL loss: 0.337080
Average total loss: 0.472526
tensor(-13.5497, device='cuda:0') tensor(1.1871, device='cuda:0') tensor(8.2499e-11, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.135133
Average KL loss: 0.337049
Average total loss: 0.472182
tensor(-13.5503, device='cuda:0') tensor(1.1873, device='cuda:0') tensor(-1.4133e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.138054
Average KL loss: 0.337035
Average total loss: 0.475089
tensor(-13.5509, device='cuda:0') tensor(1.1876, device='cuda:0') tensor(-2.3381e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.137698
Average KL loss: 0.337017
Average total loss: 0.474715
tensor(-13.5515, device='cuda:0') tensor(1.1879, device='cuda:0') tensor(-1.2950e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.137069
Average KL loss: 0.337002
Average total loss: 0.474071
tensor(-13.5521, device='cuda:0') tensor(1.1882, device='cuda:0') tensor(-1.7227e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.134118
Average KL loss: 0.336993
Average total loss: 0.471111
tensor(-13.5528, device='cuda:0') tensor(1.1885, device='cuda:0') tensor(-5.1876e-11, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.134490
Average KL loss: 0.336972
Average total loss: 0.471462
tensor(-13.5534, device='cuda:0') tensor(1.1887, device='cuda:0') tensor(4.8902e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.135253
Average KL loss: 0.336947
Average total loss: 0.472200
tensor(-13.5540, device='cuda:0') tensor(1.1890, device='cuda:0') tensor(-1.9578e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.134482
Average KL loss: 0.336923
Average total loss: 0.471405
tensor(-13.5546, device='cuda:0') tensor(1.1893, device='cuda:0') tensor(-5.2354e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.135291
Average KL loss: 0.336908
Average total loss: 0.472200
tensor(-13.5552, device='cuda:0') tensor(1.1896, device='cuda:0') tensor(-2.0333e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.131856
Average KL loss: 0.336888
Average total loss: 0.468744
tensor(-13.5558, device='cuda:0') tensor(1.1899, device='cuda:0') tensor(-2.7750e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.131412
Average KL loss: 0.336867
Average total loss: 0.468279
tensor(-13.5564, device='cuda:0') tensor(1.1902, device='cuda:0') tensor(-1.3181e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.128618
Average KL loss: 0.336850
Average total loss: 0.465468
tensor(-13.5570, device='cuda:0') tensor(1.1905, device='cuda:0') tensor(-2.3180e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.132317
Average KL loss: 0.336830
Average total loss: 0.469146
tensor(-13.5576, device='cuda:0') tensor(1.1908, device='cuda:0') tensor(-1.3125e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.131241
Average KL loss: 0.336812
Average total loss: 0.468053
tensor(-13.5582, device='cuda:0') tensor(1.1911, device='cuda:0') tensor(2.0407e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.128871
Average KL loss: 0.336790
Average total loss: 0.465660
tensor(-13.5588, device='cuda:0') tensor(1.1915, device='cuda:0') tensor(-5.6066e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.128667
Average KL loss: 0.336760
Average total loss: 0.465428
tensor(-13.5594, device='cuda:0') tensor(1.1917, device='cuda:0') tensor(-8.4487e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.132034
Average KL loss: 0.336733
Average total loss: 0.468768
tensor(-13.5600, device='cuda:0') tensor(1.1920, device='cuda:0') tensor(-2.1617e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.129344
Average KL loss: 0.336707
Average total loss: 0.466051
tensor(-13.5606, device='cuda:0') tensor(1.1924, device='cuda:0') tensor(-1.5089e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.127405
Average KL loss: 0.336687
Average total loss: 0.464092
tensor(-13.5612, device='cuda:0') tensor(1.1927, device='cuda:0') tensor(-2.0173e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.127102
Average KL loss: 0.336672
Average total loss: 0.463774
tensor(-13.5618, device='cuda:0') tensor(1.1930, device='cuda:0') tensor(-2.6471e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.127814
Average KL loss: 0.336647
Average total loss: 0.464460
tensor(-13.5624, device='cuda:0') tensor(1.1933, device='cuda:0') tensor(4.3283e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.128969
Average KL loss: 0.336612
Average total loss: 0.465581
tensor(-13.5630, device='cuda:0') tensor(1.1935, device='cuda:0') tensor(-1.6124e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.126833
Average KL loss: 0.336595
Average total loss: 0.463428
tensor(-13.5636, device='cuda:0') tensor(1.1939, device='cuda:0') tensor(-2.9813e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.126040
Average KL loss: 0.336583
Average total loss: 0.462623
tensor(-13.5642, device='cuda:0') tensor(1.1942, device='cuda:0') tensor(-1.7171e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.125270
Average KL loss: 0.336564
Average total loss: 0.461835
tensor(-13.5648, device='cuda:0') tensor(1.1945, device='cuda:0') tensor(-5.3622e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.127484
Average KL loss: 0.336548
Average total loss: 0.464032
tensor(-13.5654, device='cuda:0') tensor(1.1948, device='cuda:0') tensor(-2.1283e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.125939
Average KL loss: 0.336524
Average total loss: 0.462463
tensor(-13.5660, device='cuda:0') tensor(1.1951, device='cuda:0') tensor(-1.5049e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.125866
Average KL loss: 0.336492
Average total loss: 0.462358
tensor(-13.5666, device='cuda:0') tensor(1.1954, device='cuda:0') tensor(1.5815e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.126753
Average KL loss: 0.336467
Average total loss: 0.463220
tensor(-13.5672, device='cuda:0') tensor(1.1958, device='cuda:0') tensor(-7.9989e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.123808
Average KL loss: 0.336446
Average total loss: 0.460254
tensor(-13.5678, device='cuda:0') tensor(1.1961, device='cuda:0') tensor(-1.0470e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.124269
Average KL loss: 0.336420
Average total loss: 0.460689
tensor(-13.5684, device='cuda:0') tensor(1.1964, device='cuda:0') tensor(-1.0339e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.120436
Average KL loss: 0.336397
Average total loss: 0.456834
tensor(-13.5690, device='cuda:0') tensor(1.1967, device='cuda:0') tensor(-1.0334e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.124180
Average KL loss: 0.336374
Average total loss: 0.460554
tensor(-13.5696, device='cuda:0') tensor(1.1970, device='cuda:0') tensor(-1.9056e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.120991
Average KL loss: 0.336359
Average total loss: 0.457350
tensor(-13.5702, device='cuda:0') tensor(1.1973, device='cuda:0') tensor(-7.7706e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.121550
Average KL loss: 0.336337
Average total loss: 0.457887
tensor(-13.5708, device='cuda:0') tensor(1.1976, device='cuda:0') tensor(-1.5647e-11, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.123682
Average KL loss: 0.336308
Average total loss: 0.459991
tensor(-13.5714, device='cuda:0') tensor(1.1979, device='cuda:0') tensor(-2.6527e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.124258
Average KL loss: 0.336283
Average total loss: 0.460541
tensor(-13.5719, device='cuda:0') tensor(1.1982, device='cuda:0') tensor(-2.3824e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.122673
Average KL loss: 0.336263
Average total loss: 0.458936
tensor(-13.5725, device='cuda:0') tensor(1.1985, device='cuda:0') tensor(-1.2478e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.122207
Average KL loss: 0.336236
Average total loss: 0.458443
tensor(-13.5731, device='cuda:0') tensor(1.1988, device='cuda:0') tensor(-5.5529e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.119351
Average KL loss: 0.336217
Average total loss: 0.455568
tensor(-13.5737, device='cuda:0') tensor(1.1991, device='cuda:0') tensor(-1.3517e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.120193
Average KL loss: 0.336207
Average total loss: 0.456399
tensor(-13.5743, device='cuda:0') tensor(1.1995, device='cuda:0') tensor(-1.4754e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.119456
Average KL loss: 0.336191
Average total loss: 0.455647
tensor(-13.5749, device='cuda:0') tensor(1.1998, device='cuda:0') tensor(-1.4524e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.119803
Average KL loss: 0.336172
Average total loss: 0.455975
tensor(-13.5755, device='cuda:0') tensor(1.2002, device='cuda:0') tensor(-2.8084e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.119654
Average KL loss: 0.336156
Average total loss: 0.455810
tensor(-13.5761, device='cuda:0') tensor(1.2005, device='cuda:0') tensor(-8.9428e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.120207
Average KL loss: 0.336138
Average total loss: 0.456344
tensor(-13.5767, device='cuda:0') tensor(1.2008, device='cuda:0') tensor(-3.1644e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.120002
Average KL loss: 0.336129
Average total loss: 0.456130
tensor(-13.5773, device='cuda:0') tensor(1.2012, device='cuda:0') tensor(-7.7671e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.117678
Average KL loss: 0.336115
Average total loss: 0.453792
tensor(-13.5779, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-1.6598e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.117787
Average KL loss: 0.336096
Average total loss: 0.453883
tensor(-13.5784, device='cuda:0') tensor(1.2018, device='cuda:0') tensor(-3.3703e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.116758
Average KL loss: 0.336084
Average total loss: 0.452841
tensor(-13.5790, device='cuda:0') tensor(1.2022, device='cuda:0') tensor(-1.7722e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.118029
Average KL loss: 0.336062
Average total loss: 0.454091
tensor(-13.5796, device='cuda:0') tensor(1.2025, device='cuda:0') tensor(-4.2707e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.118362
Average KL loss: 0.336046
Average total loss: 0.454408
tensor(-13.5802, device='cuda:0') tensor(1.2029, device='cuda:0') tensor(-2.8400e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.120190
Average KL loss: 0.336032
Average total loss: 0.456222
tensor(-13.5808, device='cuda:0') tensor(1.2033, device='cuda:0') tensor(-7.8616e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.116032
Average KL loss: 0.336022
Average total loss: 0.452054
tensor(-13.5814, device='cuda:0') tensor(1.2036, device='cuda:0') tensor(3.6586e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.118719
Average KL loss: 0.336004
Average total loss: 0.454723
tensor(-13.5820, device='cuda:0') tensor(1.2039, device='cuda:0') tensor(-1.6877e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.117746
Average KL loss: 0.335987
Average total loss: 0.453733
tensor(-13.5826, device='cuda:0') tensor(1.2043, device='cuda:0') tensor(-1.1585e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.115208
Average KL loss: 0.335973
Average total loss: 0.451181
tensor(-13.5831, device='cuda:0') tensor(1.2046, device='cuda:0') tensor(1.3817e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.115912
Average KL loss: 0.335963
Average total loss: 0.451875
tensor(-13.5837, device='cuda:0') tensor(1.2049, device='cuda:0') tensor(7.2498e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.114490
Average KL loss: 0.335945
Average total loss: 0.450435
tensor(-13.5843, device='cuda:0') tensor(1.2052, device='cuda:0') tensor(-1.9281e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.114719
Average KL loss: 0.335926
Average total loss: 0.450645
tensor(-13.5849, device='cuda:0') tensor(1.2055, device='cuda:0') tensor(2.0422e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.115158
Average KL loss: 0.335908
Average total loss: 0.451066
tensor(-13.5855, device='cuda:0') tensor(1.2058, device='cuda:0') tensor(-2.8214e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.114002
Average KL loss: 0.335901
Average total loss: 0.449903
tensor(-13.5861, device='cuda:0') tensor(1.2062, device='cuda:0') tensor(-2.0099e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.114482
Average KL loss: 0.335890
Average total loss: 0.450372
tensor(-13.5866, device='cuda:0') tensor(1.2065, device='cuda:0') tensor(-1.1316e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.111981
Average KL loss: 0.335881
Average total loss: 0.447862
tensor(-13.5872, device='cuda:0') tensor(1.2069, device='cuda:0') tensor(2.4770e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.113544
Average KL loss: 0.335873
Average total loss: 0.449417
tensor(-13.5878, device='cuda:0') tensor(1.2073, device='cuda:0') tensor(-1.5904e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.113252
Average KL loss: 0.335861
Average total loss: 0.449113
tensor(-13.5884, device='cuda:0') tensor(1.2076, device='cuda:0') tensor(-5.9833e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.114346
Average KL loss: 0.335838
Average total loss: 0.450185
tensor(-13.5890, device='cuda:0') tensor(1.2079, device='cuda:0') tensor(4.7147e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.110889
Average KL loss: 0.335821
Average total loss: 0.446709
tensor(-13.5896, device='cuda:0') tensor(1.2082, device='cuda:0') tensor(7.6874e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.112923
Average KL loss: 0.335812
Average total loss: 0.448735
tensor(-13.5901, device='cuda:0') tensor(1.2086, device='cuda:0') tensor(-7.3815e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.112354
Average KL loss: 0.335795
Average total loss: 0.448149
tensor(-13.5907, device='cuda:0') tensor(1.2089, device='cuda:0') tensor(-7.2454e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.114405
Average KL loss: 0.335784
Average total loss: 0.450188
tensor(-13.5913, device='cuda:0') tensor(1.2092, device='cuda:0') tensor(-9.9500e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.111943
Average KL loss: 0.335780
Average total loss: 0.447723
tensor(-13.5919, device='cuda:0') tensor(1.2096, device='cuda:0') tensor(-2.9781e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.112089
Average KL loss: 0.335763
Average total loss: 0.447853
tensor(-13.5925, device='cuda:0') tensor(1.2099, device='cuda:0') tensor(-6.1224e-11, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.110647
Average KL loss: 0.335744
Average total loss: 0.446390
tensor(-13.5931, device='cuda:0') tensor(1.2102, device='cuda:0') tensor(-9.2107e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.112489
Average KL loss: 0.335734
Average total loss: 0.448223
tensor(-13.5936, device='cuda:0') tensor(1.2106, device='cuda:0') tensor(-1.2127e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.112148
Average KL loss: 0.335723
Average total loss: 0.447871
tensor(-13.5942, device='cuda:0') tensor(1.2110, device='cuda:0') tensor(-2.1828e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.112146
Average KL loss: 0.335708
Average total loss: 0.447854
tensor(-13.5948, device='cuda:0') tensor(1.2114, device='cuda:0') tensor(4.0863e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.110638
Average KL loss: 0.335694
Average total loss: 0.446331
tensor(-13.5954, device='cuda:0') tensor(1.2117, device='cuda:0') tensor(-2.9494e-11, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.108991
Average KL loss: 0.335681
Average total loss: 0.444671
tensor(-13.5959, device='cuda:0') tensor(1.2120, device='cuda:0') tensor(-2.0650e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.109009
Average KL loss: 0.335668
Average total loss: 0.444677
tensor(-13.5965, device='cuda:0') tensor(1.2124, device='cuda:0') tensor(-2.2443e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.110921
Average KL loss: 0.335663
Average total loss: 0.446584
tensor(-13.5971, device='cuda:0') tensor(1.2128, device='cuda:0') tensor(-1.2409e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.108780
Average KL loss: 0.335651
Average total loss: 0.444431
tensor(-13.5977, device='cuda:0') tensor(1.2131, device='cuda:0') tensor(-2.8125e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.110178
Average KL loss: 0.335637
Average total loss: 0.445815
tensor(-13.5983, device='cuda:0') tensor(1.2135, device='cuda:0') tensor(-1.2544e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.108358
Average KL loss: 0.335621
Average total loss: 0.443979
tensor(-13.5988, device='cuda:0') tensor(1.2138, device='cuda:0') tensor(-1.5109e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.109962
Average KL loss: 0.335610
Average total loss: 0.445572
tensor(-13.5994, device='cuda:0') tensor(1.2142, device='cuda:0') tensor(-1.4940e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.108220
Average KL loss: 0.335598
Average total loss: 0.443818
tensor(-13.6000, device='cuda:0') tensor(1.2145, device='cuda:0') tensor(-1.9698e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.109632
Average KL loss: 0.335572
Average total loss: 0.445204
tensor(-13.6006, device='cuda:0') tensor(1.2148, device='cuda:0') tensor(4.8463e-11, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.109878
Average KL loss: 0.335539
Average total loss: 0.445417
tensor(-13.6012, device='cuda:0') tensor(1.2151, device='cuda:0') tensor(-1.1185e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.110368
Average KL loss: 0.335518
Average total loss: 0.445886
tensor(-13.6017, device='cuda:0') tensor(1.2154, device='cuda:0') tensor(-5.8650e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.107075
Average KL loss: 0.335501
Average total loss: 0.442576
tensor(-13.6023, device='cuda:0') tensor(1.2157, device='cuda:0') tensor(-1.1203e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.108179
Average KL loss: 0.335490
Average total loss: 0.443669
tensor(-13.6029, device='cuda:0') tensor(1.2160, device='cuda:0') tensor(-1.1745e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.109061
Average KL loss: 0.335473
Average total loss: 0.444535
tensor(-13.6035, device='cuda:0') tensor(1.2163, device='cuda:0') tensor(-2.2989e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.108311
Average KL loss: 0.335453
Average total loss: 0.443764
tensor(-13.6040, device='cuda:0') tensor(1.2167, device='cuda:0') tensor(-7.1061e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.108027
Average KL loss: 0.335439
Average total loss: 0.443466
tensor(-13.6046, device='cuda:0') tensor(1.2170, device='cuda:0') tensor(-2.3787e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.109179
Average KL loss: 0.335431
Average total loss: 0.444610
tensor(-13.6052, device='cuda:0') tensor(1.2173, device='cuda:0') tensor(-6.4323e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.105568
Average KL loss: 0.335411
Average total loss: 0.440979
tensor(-13.6058, device='cuda:0') tensor(1.2177, device='cuda:0') tensor(-8.4557e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.106947
Average KL loss: 0.335400
Average total loss: 0.442347
tensor(-13.6063, device='cuda:0') tensor(1.2180, device='cuda:0') tensor(-1.1691e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.105756
Average KL loss: 0.335388
Average total loss: 0.441144
tensor(-13.6069, device='cuda:0') tensor(1.2184, device='cuda:0') tensor(-5.9534e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.108140
Average KL loss: 0.335375
Average total loss: 0.443516
tensor(-13.6075, device='cuda:0') tensor(1.2188, device='cuda:0') tensor(2.7572e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.106618
Average KL loss: 0.335363
Average total loss: 0.441982
tensor(-13.6080, device='cuda:0') tensor(1.2191, device='cuda:0') tensor(-2.0176e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.104323
Average KL loss: 0.335345
Average total loss: 0.439668
tensor(-13.6086, device='cuda:0') tensor(1.2195, device='cuda:0') tensor(-3.5479e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.107535
Average KL loss: 0.335332
Average total loss: 0.442867
tensor(-13.6092, device='cuda:0') tensor(1.2199, device='cuda:0') tensor(3.3370e-11, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.109072
Average KL loss: 0.335317
Average total loss: 0.444389
tensor(-13.6098, device='cuda:0') tensor(1.2202, device='cuda:0') tensor(6.6827e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.106575
Average KL loss: 0.335297
Average total loss: 0.441872
tensor(-13.6103, device='cuda:0') tensor(1.2206, device='cuda:0') tensor(-1.1348e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.105611
Average KL loss: 0.335279
Average total loss: 0.440890
tensor(-13.6109, device='cuda:0') tensor(1.2209, device='cuda:0') tensor(-5.8272e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.104636
Average KL loss: 0.335267
Average total loss: 0.439903
tensor(-13.6115, device='cuda:0') tensor(1.2212, device='cuda:0') tensor(-1.0827e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.105546
Average KL loss: 0.335249
Average total loss: 0.440795
tensor(-13.6121, device='cuda:0') tensor(1.2216, device='cuda:0') tensor(-1.6361e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.105357
Average KL loss: 0.335230
Average total loss: 0.440587
tensor(-13.6126, device='cuda:0') tensor(1.2219, device='cuda:0') tensor(-5.6460e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.104097
Average KL loss: 0.335215
Average total loss: 0.439311
tensor(-13.6132, device='cuda:0') tensor(1.2223, device='cuda:0') tensor(5.5123e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.105421
Average KL loss: 0.335201
Average total loss: 0.440623
tensor(-13.6138, device='cuda:0') tensor(1.2226, device='cuda:0') tensor(-3.3522e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.106541
Average KL loss: 0.335194
Average total loss: 0.441735
tensor(-13.6143, device='cuda:0') tensor(1.2230, device='cuda:0') tensor(-1.5894e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.104970
Average KL loss: 0.335178
Average total loss: 0.440149
tensor(-13.6149, device='cuda:0') tensor(1.2234, device='cuda:0') tensor(7.4380e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.101956
Average KL loss: 0.335167
Average total loss: 0.437124
tensor(-13.6155, device='cuda:0') tensor(1.2237, device='cuda:0') tensor(-2.2582e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.104385
Average KL loss: 0.335153
Average total loss: 0.439539
tensor(-13.6160, device='cuda:0') tensor(1.2240, device='cuda:0') tensor(4.3353e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.104027
Average KL loss: 0.335133
Average total loss: 0.439160
tensor(-13.6166, device='cuda:0') tensor(1.2243, device='cuda:0') tensor(-2.9822e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.103759
Average KL loss: 0.335118
Average total loss: 0.438877
tensor(-13.6172, device='cuda:0') tensor(1.2247, device='cuda:0') tensor(4.4924e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.101990
Average KL loss: 0.335103
Average total loss: 0.437093
tensor(-13.6177, device='cuda:0') tensor(1.2250, device='cuda:0') tensor(-1.4155e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.102271
Average KL loss: 0.335087
Average total loss: 0.437358
tensor(-13.6183, device='cuda:0') tensor(1.2253, device='cuda:0') tensor(5.3470e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.103590
Average KL loss: 0.335073
Average total loss: 0.438663
tensor(-13.6189, device='cuda:0') tensor(1.2257, device='cuda:0') tensor(-1.1991e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.102177
Average KL loss: 0.335057
Average total loss: 0.437234
tensor(-13.6194, device='cuda:0') tensor(1.2260, device='cuda:0') tensor(-4.1798e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.101504
Average KL loss: 0.335046
Average total loss: 0.436549
tensor(-13.6200, device='cuda:0') tensor(1.2264, device='cuda:0') tensor(-1.1021e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.103621
Average KL loss: 0.335028
Average total loss: 0.438649
tensor(-13.6206, device='cuda:0') tensor(1.2268, device='cuda:0') tensor(-2.3695e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.101505
Average KL loss: 0.335017
Average total loss: 0.436522
tensor(-13.6211, device='cuda:0') tensor(1.2272, device='cuda:0') tensor(-7.8957e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.102096
Average KL loss: 0.335002
Average total loss: 0.437098
tensor(-13.6217, device='cuda:0') tensor(1.2275, device='cuda:0') tensor(-6.8807e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.099980
Average KL loss: 0.334986
Average total loss: 0.434966
tensor(-13.6223, device='cuda:0') tensor(1.2279, device='cuda:0') tensor(6.7451e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.101319
Average KL loss: 0.334966
Average total loss: 0.436285
tensor(-13.6228, device='cuda:0') tensor(1.2281, device='cuda:0') tensor(8.4025e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.101830
Average KL loss: 0.334949
Average total loss: 0.436780
tensor(-13.6234, device='cuda:0') tensor(1.2285, device='cuda:0') tensor(-8.4982e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.099865
Average KL loss: 0.334931
Average total loss: 0.434796
tensor(-13.6239, device='cuda:0') tensor(1.2288, device='cuda:0') tensor(-5.6919e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.100422
Average KL loss: 0.334918
Average total loss: 0.435340
tensor(-13.6245, device='cuda:0') tensor(1.2292, device='cuda:0') tensor(-3.3348e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.100192
Average KL loss: 0.334901
Average total loss: 0.435092
tensor(-13.6251, device='cuda:0') tensor(1.2295, device='cuda:0') tensor(-8.6984e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.100173
Average KL loss: 0.334890
Average total loss: 0.435062
tensor(-13.6256, device='cuda:0') tensor(1.2299, device='cuda:0') tensor(-1.0205e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.102446
Average KL loss: 0.334875
Average total loss: 0.437321
tensor(-13.6262, device='cuda:0') tensor(1.2302, device='cuda:0') tensor(-5.6230e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.102298
Average KL loss: 0.334857
Average total loss: 0.437154
tensor(-13.6267, device='cuda:0') tensor(1.2305, device='cuda:0') tensor(-1.1421e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.101006
Average KL loss: 0.334840
Average total loss: 0.435846
tensor(-13.6273, device='cuda:0') tensor(1.2309, device='cuda:0') tensor(-6.4349e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.101902
Average KL loss: 0.334827
Average total loss: 0.436729
tensor(-13.6278, device='cuda:0') tensor(1.2312, device='cuda:0') tensor(-3.0017e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.101870
Average KL loss: 0.334811
Average total loss: 0.436682
tensor(-13.6284, device='cuda:0') tensor(1.2315, device='cuda:0') tensor(-1.5260e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.098918
Average KL loss: 0.334794
Average total loss: 0.433712
tensor(-13.6289, device='cuda:0') tensor(1.2319, device='cuda:0') tensor(-1.4230e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.098857
Average KL loss: 0.334771
Average total loss: 0.433628
tensor(-13.6295, device='cuda:0') tensor(1.2321, device='cuda:0') tensor(-1.0420e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.099002
Average KL loss: 0.334756
Average total loss: 0.433758
tensor(-13.6301, device='cuda:0') tensor(1.2324, device='cuda:0') tensor(-5.1448e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.100090
Average KL loss: 0.334736
Average total loss: 0.434826
tensor(-13.6306, device='cuda:0') tensor(1.2327, device='cuda:0') tensor(-1.3420e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.101294
Average KL loss: 0.334717
Average total loss: 0.436011
tensor(-13.6312, device='cuda:0') tensor(1.2330, device='cuda:0') tensor(-1.2115e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.100252
Average KL loss: 0.334698
Average total loss: 0.434949
tensor(-13.6317, device='cuda:0') tensor(1.2334, device='cuda:0') tensor(-1.2066e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.100882
Average KL loss: 0.334676
Average total loss: 0.435558
tensor(-13.6323, device='cuda:0') tensor(1.2337, device='cuda:0') tensor(-2.7121e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.100406
Average KL loss: 0.334660
Average total loss: 0.435066
tensor(-13.6328, device='cuda:0') tensor(1.2340, device='cuda:0') tensor(-1.0492e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.098385
Average KL loss: 0.334647
Average total loss: 0.433032
tensor(-13.6334, device='cuda:0') tensor(1.2344, device='cuda:0') tensor(3.1349e-11, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.100451
Average KL loss: 0.334637
Average total loss: 0.435088
tensor(-13.6339, device='cuda:0') tensor(1.2346, device='cuda:0') tensor(2.9234e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.099447
Average KL loss: 0.334616
Average total loss: 0.434063
tensor(-13.6345, device='cuda:0') tensor(1.2349, device='cuda:0') tensor(-3.2200e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.099414
Average KL loss: 0.334596
Average total loss: 0.434010
tensor(-13.6350, device='cuda:0') tensor(1.2352, device='cuda:0') tensor(4.0665e-11, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.096587
Average KL loss: 0.334577
Average total loss: 0.431164
tensor(-13.6356, device='cuda:0') tensor(1.2355, device='cuda:0') tensor(6.5272e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.099709
Average KL loss: 0.334566
Average total loss: 0.434275
tensor(-13.6361, device='cuda:0') tensor(1.2358, device='cuda:0') tensor(-6.4041e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.098194
Average KL loss: 0.334557
Average total loss: 0.432752
tensor(-13.6367, device='cuda:0') tensor(1.2361, device='cuda:0') tensor(-9.0846e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.098044
Average KL loss: 0.334540
Average total loss: 0.432584
tensor(-13.6372, device='cuda:0') tensor(1.2365, device='cuda:0') tensor(1.7788e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.097358
Average KL loss: 0.334518
Average total loss: 0.431876
tensor(-13.6378, device='cuda:0') tensor(1.2367, device='cuda:0') tensor(-1.5175e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.097321
Average KL loss: 0.334506
Average total loss: 0.431827
tensor(-13.6383, device='cuda:0') tensor(1.2370, device='cuda:0') tensor(1.3568e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.096296
Average KL loss: 0.334487
Average total loss: 0.430783
tensor(-13.6389, device='cuda:0') tensor(1.2373, device='cuda:0') tensor(-6.0418e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.096444
Average KL loss: 0.334477
Average total loss: 0.430921
tensor(-13.6394, device='cuda:0') tensor(1.2376, device='cuda:0') tensor(-8.1662e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.097882
Average KL loss: 0.334463
Average total loss: 0.432345
tensor(-13.6400, device='cuda:0') tensor(1.2379, device='cuda:0') tensor(-7.4382e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.096035
Average KL loss: 0.334449
Average total loss: 0.430484
tensor(-13.6405, device='cuda:0') tensor(1.2383, device='cuda:0') tensor(-7.7287e-12, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.098563
Average KL loss: 0.334436
Average total loss: 0.432999
tensor(-13.6410, device='cuda:0') tensor(1.2386, device='cuda:0') tensor(-2.2651e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.098094
Average KL loss: 0.334422
Average total loss: 0.432516
tensor(-13.6416, device='cuda:0') tensor(1.2390, device='cuda:0') tensor(-1.6805e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.097644
Average KL loss: 0.334412
Average total loss: 0.432056
tensor(-13.6421, device='cuda:0') tensor(1.2393, device='cuda:0') tensor(-8.6095e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.095001
Average KL loss: 0.334391
Average total loss: 0.429392
tensor(-13.6427, device='cuda:0') tensor(1.2396, device='cuda:0') tensor(3.2688e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.095361
Average KL loss: 0.334372
Average total loss: 0.429732
tensor(-13.6432, device='cuda:0') tensor(1.2398, device='cuda:0') tensor(-2.5429e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.095002
Average KL loss: 0.334349
Average total loss: 0.429352
tensor(-13.6438, device='cuda:0') tensor(1.2402, device='cuda:0') tensor(-3.0055e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.095760
Average KL loss: 0.334333
Average total loss: 0.430093
tensor(-13.6443, device='cuda:0') tensor(1.2405, device='cuda:0') tensor(-6.7536e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.094825
Average KL loss: 0.334319
Average total loss: 0.429144
tensor(-13.6448, device='cuda:0') tensor(1.2407, device='cuda:0') tensor(1.3915e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.096320
Average KL loss: 0.334305
Average total loss: 0.430626
tensor(-13.6454, device='cuda:0') tensor(1.2411, device='cuda:0') tensor(-4.4747e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.095692
Average KL loss: 0.334290
Average total loss: 0.429983
tensor(-13.6459, device='cuda:0') tensor(1.2414, device='cuda:0') tensor(-5.5476e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.093461
Average KL loss: 0.334269
Average total loss: 0.427730
 Percentile value: -13.360013961791992
Non-zero model percentage: 6.871959686279297%, Non-zero mask percentage: 6.871959686279297%

--- Pruning Level [12/24]: ---
conv1.weight         | nonzeros =    1467 /    1728             ( 84.90%) | total_pruned =     261 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   12793 /   36864             ( 34.70%) | total_pruned =   24071 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   13212 /   36864             ( 35.84%) | total_pruned =   23652 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   11609 /   36864             ( 31.49%) | total_pruned =   25255 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   11118 /   36864             ( 30.16%) | total_pruned =   25746 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   23544 /   73728             ( 31.93%) | total_pruned =   50184 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   39708 /  147456             ( 26.93%) | total_pruned =  107748 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4454 /    8192             ( 54.37%) | total_pruned =    3738 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   29659 /  147456             ( 20.11%) | total_pruned =  117797 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   29654 /  147456             ( 20.11%) | total_pruned =  117802 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   64321 /  294912             ( 21.81%) | total_pruned =  230591 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     213 /     256             ( 83.20%) | total_pruned =      43 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   98249 /  589824             ( 16.66%) | total_pruned =  491575 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     217 /     256             ( 84.77%) | total_pruned =      39 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   12115 /   32768             ( 36.97%) | total_pruned =   20653 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   46369 /  589824             (  7.86%) | total_pruned =  543455 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     144 /     256             ( 56.25%) | total_pruned =     112 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     120 /     256             ( 46.88%) | total_pruned =     136 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   47598 /  589824             (  8.07%) | total_pruned =  542226 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     205 /     256             ( 80.08%) | total_pruned =      51 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   98709 / 1179648             (  8.37%) | total_pruned = 1080939 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     315 /     512             ( 61.52%) | total_pruned =     197 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     272 /     512             ( 53.12%) | total_pruned =     240 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   98207 / 2359296             (  4.16%) | total_pruned = 2261089 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     394 /     512             ( 76.95%) | total_pruned =     118 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     367 /     512             ( 71.68%) | total_pruned =     145 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   17029 /  131072             ( 12.99%) | total_pruned =  114043 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     310 /     512             ( 60.55%) | total_pruned =     202 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     373 /     512             ( 72.85%) | total_pruned =     139 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   45086 / 2359296             (  1.91%) | total_pruned = 2314210 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     180 /     512             ( 35.16%) | total_pruned =     332 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      90 /     512             ( 17.58%) | total_pruned =     422 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   52467 / 2359296             (  2.22%) | total_pruned = 2306829 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     430 /     512             ( 83.98%) | total_pruned =      82 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     389 /     512             ( 75.98%) | total_pruned =     123 | shape = torch.Size([512])
linear.weight        | nonzeros =    3983 /    5120             ( 77.79%) | total_pruned =    1137 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 768200, pruned : 10410562, total: 11178762, Compression rate :      14.55x  ( 93.13% pruned)
Train Epoch: 21/100 Loss: 0.000015 Accuracy: 86.56 100.00 % Best test Accuracy: 86.69%
tensor(-13.6465, device='cuda:0') tensor(1.2417, device='cuda:0') tensor(-1.4726e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.158367
Average KL loss: 0.333928
Average total loss: 0.492294
tensor(-13.6477, device='cuda:0') tensor(1.2161, device='cuda:0') tensor(-6.6183e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.157586
Average KL loss: 0.333656
Average total loss: 0.491243
tensor(-13.6487, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(2.2549e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.159103
Average KL loss: 0.333515
Average total loss: 0.492618
tensor(-13.6495, device='cuda:0') tensor(1.1921, device='cuda:0') tensor(-2.2137e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.158781
Average KL loss: 0.333425
Average total loss: 0.492206
tensor(-13.6503, device='cuda:0') tensor(1.1859, device='cuda:0') tensor(-2.2827e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.157817
Average KL loss: 0.333349
Average total loss: 0.491166
tensor(-13.6509, device='cuda:0') tensor(1.1817, device='cuda:0') tensor(-2.4793e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.156139
Average KL loss: 0.333289
Average total loss: 0.489428
tensor(-13.6516, device='cuda:0') tensor(1.1790, device='cuda:0') tensor(-1.7522e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.153977
Average KL loss: 0.333249
Average total loss: 0.487226
tensor(-13.6522, device='cuda:0') tensor(1.1771, device='cuda:0') tensor(-1.5162e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.157598
Average KL loss: 0.333217
Average total loss: 0.490815
tensor(-13.6528, device='cuda:0') tensor(1.1759, device='cuda:0') tensor(-1.2557e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.154430
Average KL loss: 0.333188
Average total loss: 0.487618
tensor(-13.6534, device='cuda:0') tensor(1.1751, device='cuda:0') tensor(-1.0504e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.155872
Average KL loss: 0.333167
Average total loss: 0.489039
tensor(-13.6540, device='cuda:0') tensor(1.1746, device='cuda:0') tensor(-2.2128e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.152612
Average KL loss: 0.333152
Average total loss: 0.485764
tensor(-13.6545, device='cuda:0') tensor(1.1743, device='cuda:0') tensor(-3.5552e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.151790
Average KL loss: 0.333139
Average total loss: 0.484929
tensor(-13.6551, device='cuda:0') tensor(1.1742, device='cuda:0') tensor(-1.0070e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.151628
Average KL loss: 0.333124
Average total loss: 0.484752
tensor(-13.6556, device='cuda:0') tensor(1.1740, device='cuda:0') tensor(-1.1508e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.147775
Average KL loss: 0.333108
Average total loss: 0.480883
tensor(-13.6562, device='cuda:0') tensor(1.1740, device='cuda:0') tensor(-3.9669e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.146300
Average KL loss: 0.333091
Average total loss: 0.479391
tensor(-13.6568, device='cuda:0') tensor(1.1740, device='cuda:0') tensor(-1.3122e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.148826
Average KL loss: 0.333078
Average total loss: 0.481904
tensor(-13.6573, device='cuda:0') tensor(1.1742, device='cuda:0') tensor(-2.9783e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.146996
Average KL loss: 0.333063
Average total loss: 0.480059
tensor(-13.6579, device='cuda:0') tensor(1.1744, device='cuda:0') tensor(-2.0823e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.143764
Average KL loss: 0.333041
Average total loss: 0.476805
tensor(-13.6584, device='cuda:0') tensor(1.1745, device='cuda:0') tensor(1.1720e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.145930
Average KL loss: 0.333022
Average total loss: 0.478952
tensor(-13.6590, device='cuda:0') tensor(1.1746, device='cuda:0') tensor(-9.3724e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.144647
Average KL loss: 0.333016
Average total loss: 0.477662
tensor(-13.6595, device='cuda:0') tensor(1.1749, device='cuda:0') tensor(-4.2310e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.149202
Average KL loss: 0.333007
Average total loss: 0.482209
tensor(-13.6600, device='cuda:0') tensor(1.1752, device='cuda:0') tensor(-3.2283e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.141552
Average KL loss: 0.332998
Average total loss: 0.474550
tensor(-13.6606, device='cuda:0') tensor(1.1754, device='cuda:0') tensor(-6.9921e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.143744
Average KL loss: 0.332980
Average total loss: 0.476723
tensor(-13.6611, device='cuda:0') tensor(1.1757, device='cuda:0') tensor(2.5803e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.141639
Average KL loss: 0.332962
Average total loss: 0.474601
tensor(-13.6617, device='cuda:0') tensor(1.1759, device='cuda:0') tensor(-6.0393e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.142532
Average KL loss: 0.332950
Average total loss: 0.475482
tensor(-13.6622, device='cuda:0') tensor(1.1762, device='cuda:0') tensor(-7.3941e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.140413
Average KL loss: 0.332932
Average total loss: 0.473345
tensor(-13.6628, device='cuda:0') tensor(1.1765, device='cuda:0') tensor(-1.2786e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.141046
Average KL loss: 0.332913
Average total loss: 0.473958
tensor(-13.6633, device='cuda:0') tensor(1.1767, device='cuda:0') tensor(-6.5943e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.139977
Average KL loss: 0.332895
Average total loss: 0.472872
tensor(-13.6638, device='cuda:0') tensor(1.1769, device='cuda:0') tensor(-1.1698e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.138009
Average KL loss: 0.332883
Average total loss: 0.470892
tensor(-13.6644, device='cuda:0') tensor(1.1772, device='cuda:0') tensor(-2.4487e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.137669
Average KL loss: 0.332870
Average total loss: 0.470539
tensor(-13.6649, device='cuda:0') tensor(1.1775, device='cuda:0') tensor(-1.5877e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.139550
Average KL loss: 0.332858
Average total loss: 0.472409
tensor(-13.6655, device='cuda:0') tensor(1.1779, device='cuda:0') tensor(-7.8215e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.138135
Average KL loss: 0.332845
Average total loss: 0.470980
tensor(-13.6660, device='cuda:0') tensor(1.1782, device='cuda:0') tensor(-7.5805e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.135037
Average KL loss: 0.332839
Average total loss: 0.467876
tensor(-13.6665, device='cuda:0') tensor(1.1786, device='cuda:0') tensor(-1.3721e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.137763
Average KL loss: 0.332831
Average total loss: 0.470594
tensor(-13.6671, device='cuda:0') tensor(1.1789, device='cuda:0') tensor(-1.8468e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.135933
Average KL loss: 0.332819
Average total loss: 0.468751
tensor(-13.6676, device='cuda:0') tensor(1.1792, device='cuda:0') tensor(-1.7417e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.134889
Average KL loss: 0.332802
Average total loss: 0.467692
tensor(-13.6681, device='cuda:0') tensor(1.1795, device='cuda:0') tensor(-9.5611e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.135117
Average KL loss: 0.332782
Average total loss: 0.467898
tensor(-13.6687, device='cuda:0') tensor(1.1798, device='cuda:0') tensor(-2.4227e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.135740
Average KL loss: 0.332772
Average total loss: 0.468512
tensor(-13.6692, device='cuda:0') tensor(1.1801, device='cuda:0') tensor(4.0812e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.134837
Average KL loss: 0.332760
Average total loss: 0.467597
tensor(-13.6697, device='cuda:0') tensor(1.1804, device='cuda:0') tensor(-4.3506e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.131947
Average KL loss: 0.332749
Average total loss: 0.464696
tensor(-13.6703, device='cuda:0') tensor(1.1807, device='cuda:0') tensor(-1.4651e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.136096
Average KL loss: 0.332746
Average total loss: 0.468842
tensor(-13.6708, device='cuda:0') tensor(1.1810, device='cuda:0') tensor(-1.1399e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.131522
Average KL loss: 0.332734
Average total loss: 0.464255
tensor(-13.6714, device='cuda:0') tensor(1.1814, device='cuda:0') tensor(-1.4374e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.133944
Average KL loss: 0.332724
Average total loss: 0.466668
tensor(-13.6719, device='cuda:0') tensor(1.1817, device='cuda:0') tensor(-8.6809e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.133870
Average KL loss: 0.332712
Average total loss: 0.466582
tensor(-13.6724, device='cuda:0') tensor(1.1820, device='cuda:0') tensor(-1.1205e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.129697
Average KL loss: 0.332698
Average total loss: 0.462396
tensor(-13.6729, device='cuda:0') tensor(1.1824, device='cuda:0') tensor(-1.7492e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.133786
Average KL loss: 0.332678
Average total loss: 0.466464
tensor(-13.6735, device='cuda:0') tensor(1.1827, device='cuda:0') tensor(-1.7986e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.131520
Average KL loss: 0.332663
Average total loss: 0.464184
tensor(-13.6740, device='cuda:0') tensor(1.1830, device='cuda:0') tensor(-2.4363e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.129861
Average KL loss: 0.332650
Average total loss: 0.462511
tensor(-13.6745, device='cuda:0') tensor(1.1833, device='cuda:0') tensor(-4.2809e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.129922
Average KL loss: 0.332635
Average total loss: 0.462557
tensor(-13.6751, device='cuda:0') tensor(1.1837, device='cuda:0') tensor(-1.5547e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.128191
Average KL loss: 0.332614
Average total loss: 0.460805
tensor(-13.6756, device='cuda:0') tensor(1.1840, device='cuda:0') tensor(-9.9154e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.127557
Average KL loss: 0.332597
Average total loss: 0.460154
tensor(-13.6761, device='cuda:0') tensor(1.1844, device='cuda:0') tensor(-2.3838e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.128081
Average KL loss: 0.332583
Average total loss: 0.460663
tensor(-13.6767, device='cuda:0') tensor(1.1847, device='cuda:0') tensor(-4.4201e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.127904
Average KL loss: 0.332565
Average total loss: 0.460469
tensor(-13.6772, device='cuda:0') tensor(1.1850, device='cuda:0') tensor(-2.8858e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.126943
Average KL loss: 0.332547
Average total loss: 0.459490
tensor(-13.6777, device='cuda:0') tensor(1.1854, device='cuda:0') tensor(-1.0721e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.129312
Average KL loss: 0.332540
Average total loss: 0.461852
tensor(-13.6783, device='cuda:0') tensor(1.1858, device='cuda:0') tensor(-2.1565e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.125650
Average KL loss: 0.332525
Average total loss: 0.458175
tensor(-13.6788, device='cuda:0') tensor(1.1861, device='cuda:0') tensor(-3.4326e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.126200
Average KL loss: 0.332518
Average total loss: 0.458719
tensor(-13.6793, device='cuda:0') tensor(1.1866, device='cuda:0') tensor(-9.4954e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.127759
Average KL loss: 0.332510
Average total loss: 0.460269
tensor(-13.6798, device='cuda:0') tensor(1.1869, device='cuda:0') tensor(-3.4710e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.126606
Average KL loss: 0.332494
Average total loss: 0.459099
tensor(-13.6804, device='cuda:0') tensor(1.1872, device='cuda:0') tensor(1.0920e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.126476
Average KL loss: 0.332479
Average total loss: 0.458955
tensor(-13.6809, device='cuda:0') tensor(1.1875, device='cuda:0') tensor(-3.5279e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.124451
Average KL loss: 0.332464
Average total loss: 0.456915
tensor(-13.6814, device='cuda:0') tensor(1.1879, device='cuda:0') tensor(-6.0869e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.125033
Average KL loss: 0.332455
Average total loss: 0.457488
tensor(-13.6820, device='cuda:0') tensor(1.1882, device='cuda:0') tensor(5.1771e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.125236
Average KL loss: 0.332440
Average total loss: 0.457676
tensor(-13.6825, device='cuda:0') tensor(1.1885, device='cuda:0') tensor(-1.1969e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.125315
Average KL loss: 0.332427
Average total loss: 0.457742
tensor(-13.6830, device='cuda:0') tensor(1.1888, device='cuda:0') tensor(-5.7428e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.123608
Average KL loss: 0.332413
Average total loss: 0.456021
tensor(-13.6835, device='cuda:0') tensor(1.1892, device='cuda:0') tensor(-1.5935e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.123366
Average KL loss: 0.332395
Average total loss: 0.455761
tensor(-13.6841, device='cuda:0') tensor(1.1895, device='cuda:0') tensor(-9.8142e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.122783
Average KL loss: 0.332375
Average total loss: 0.455158
tensor(-13.6846, device='cuda:0') tensor(1.1899, device='cuda:0') tensor(2.8787e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.124789
Average KL loss: 0.332368
Average total loss: 0.457157
tensor(-13.6851, device='cuda:0') tensor(1.1902, device='cuda:0') tensor(-4.1661e-11, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.121114
Average KL loss: 0.332361
Average total loss: 0.453475
tensor(-13.6856, device='cuda:0') tensor(1.1906, device='cuda:0') tensor(2.7075e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.124279
Average KL loss: 0.332350
Average total loss: 0.456630
tensor(-13.6862, device='cuda:0') tensor(1.1910, device='cuda:0') tensor(4.5447e-11, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.122563
Average KL loss: 0.332340
Average total loss: 0.454903
tensor(-13.6867, device='cuda:0') tensor(1.1913, device='cuda:0') tensor(-1.4472e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.120565
Average KL loss: 0.332329
Average total loss: 0.452894
tensor(-13.6872, device='cuda:0') tensor(1.1916, device='cuda:0') tensor(-1.1436e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.120723
Average KL loss: 0.332318
Average total loss: 0.453041
tensor(-13.6877, device='cuda:0') tensor(1.1920, device='cuda:0') tensor(9.4444e-12, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.120592
Average KL loss: 0.332305
Average total loss: 0.452897
tensor(-13.6883, device='cuda:0') tensor(1.1923, device='cuda:0') tensor(-1.6446e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.121283
Average KL loss: 0.332290
Average total loss: 0.453573
tensor(-13.6888, device='cuda:0') tensor(1.1926, device='cuda:0') tensor(-2.2813e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.122003
Average KL loss: 0.332271
Average total loss: 0.454274
tensor(-13.6893, device='cuda:0') tensor(1.1930, device='cuda:0') tensor(-1.5248e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.122880
Average KL loss: 0.332258
Average total loss: 0.455138
tensor(-13.6898, device='cuda:0') tensor(1.1933, device='cuda:0') tensor(-2.3144e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.120336
Average KL loss: 0.332250
Average total loss: 0.452586
tensor(-13.6904, device='cuda:0') tensor(1.1937, device='cuda:0') tensor(-1.4840e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.120346
Average KL loss: 0.332236
Average total loss: 0.452582
tensor(-13.6909, device='cuda:0') tensor(1.1940, device='cuda:0') tensor(-1.2915e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.120840
Average KL loss: 0.332216
Average total loss: 0.453056
tensor(-13.6914, device='cuda:0') tensor(1.1943, device='cuda:0') tensor(-1.4476e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.121233
Average KL loss: 0.332195
Average total loss: 0.453428
tensor(-13.6919, device='cuda:0') tensor(1.1946, device='cuda:0') tensor(4.4006e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.118499
Average KL loss: 0.332180
Average total loss: 0.450678
tensor(-13.6924, device='cuda:0') tensor(1.1950, device='cuda:0') tensor(-9.2729e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.119256
Average KL loss: 0.332164
Average total loss: 0.451420
tensor(-13.6930, device='cuda:0') tensor(1.1953, device='cuda:0') tensor(-1.2485e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.118524
Average KL loss: 0.332146
Average total loss: 0.450670
tensor(-13.6935, device='cuda:0') tensor(1.1956, device='cuda:0') tensor(-2.5750e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.118725
Average KL loss: 0.332126
Average total loss: 0.450851
tensor(-13.6940, device='cuda:0') tensor(1.1959, device='cuda:0') tensor(2.4751e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.118734
Average KL loss: 0.332104
Average total loss: 0.450838
tensor(-13.6945, device='cuda:0') tensor(1.1962, device='cuda:0') tensor(-4.7490e-11, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.117149
Average KL loss: 0.332085
Average total loss: 0.449234
tensor(-13.6951, device='cuda:0') tensor(1.1965, device='cuda:0') tensor(3.3016e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.113558
Average KL loss: 0.332071
Average total loss: 0.445628
tensor(-13.6956, device='cuda:0') tensor(1.1969, device='cuda:0') tensor(-2.2859e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.119768
Average KL loss: 0.332058
Average total loss: 0.451826
tensor(-13.6961, device='cuda:0') tensor(1.1972, device='cuda:0') tensor(-1.7554e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.115350
Average KL loss: 0.332043
Average total loss: 0.447393
tensor(-13.6966, device='cuda:0') tensor(1.1976, device='cuda:0') tensor(-1.1847e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.117449
Average KL loss: 0.332028
Average total loss: 0.449478
tensor(-13.6971, device='cuda:0') tensor(1.1979, device='cuda:0') tensor(-1.0981e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.117317
Average KL loss: 0.332014
Average total loss: 0.449331
tensor(-13.6977, device='cuda:0') tensor(1.1983, device='cuda:0') tensor(-1.3109e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.115971
Average KL loss: 0.332001
Average total loss: 0.447972
tensor(-13.6982, device='cuda:0') tensor(1.1986, device='cuda:0') tensor(-2.3402e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.116558
Average KL loss: 0.331988
Average total loss: 0.448545
tensor(-13.6987, device='cuda:0') tensor(1.1990, device='cuda:0') tensor(-9.9585e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.116657
Average KL loss: 0.331975
Average total loss: 0.448633
tensor(-13.6992, device='cuda:0') tensor(1.1993, device='cuda:0') tensor(-4.1777e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.115678
Average KL loss: 0.331963
Average total loss: 0.447641
tensor(-13.6997, device='cuda:0') tensor(1.1997, device='cuda:0') tensor(-2.3872e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.115746
Average KL loss: 0.331952
Average total loss: 0.447698
tensor(-13.7003, device='cuda:0') tensor(1.2000, device='cuda:0') tensor(-2.8070e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.116361
Average KL loss: 0.331938
Average total loss: 0.448299
tensor(-13.7008, device='cuda:0') tensor(1.2004, device='cuda:0') tensor(-7.6975e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.115517
Average KL loss: 0.331925
Average total loss: 0.447442
tensor(-13.7013, device='cuda:0') tensor(1.2007, device='cuda:0') tensor(-1.8976e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.116868
Average KL loss: 0.331919
Average total loss: 0.448787
tensor(-13.7014, device='cuda:0') tensor(1.2008, device='cuda:0') tensor(-1.6120e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.114101
Average KL loss: 0.331918
Average total loss: 0.446019
tensor(-13.7014, device='cuda:0') tensor(1.2008, device='cuda:0') tensor(-8.4964e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.115577
Average KL loss: 0.331916
Average total loss: 0.447493
tensor(-13.7015, device='cuda:0') tensor(1.2008, device='cuda:0') tensor(-1.8605e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.116061
Average KL loss: 0.331916
Average total loss: 0.447977
tensor(-13.7015, device='cuda:0') tensor(1.2008, device='cuda:0') tensor(-7.9025e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.114870
Average KL loss: 0.331915
Average total loss: 0.446785
tensor(-13.7015, device='cuda:0') tensor(1.2009, device='cuda:0') tensor(2.6313e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.113382
Average KL loss: 0.331913
Average total loss: 0.445295
tensor(-13.7016, device='cuda:0') tensor(1.2009, device='cuda:0') tensor(2.1105e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.113614
Average KL loss: 0.331911
Average total loss: 0.445525
tensor(-13.7016, device='cuda:0') tensor(1.2009, device='cuda:0') tensor(-2.5646e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.114471
Average KL loss: 0.331910
Average total loss: 0.446381
tensor(-13.7017, device='cuda:0') tensor(1.2010, device='cuda:0') tensor(1.2048e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.113298
Average KL loss: 0.331908
Average total loss: 0.445206
tensor(-13.7017, device='cuda:0') tensor(1.2010, device='cuda:0') tensor(-1.4589e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.114518
Average KL loss: 0.331906
Average total loss: 0.446424
tensor(-13.7018, device='cuda:0') tensor(1.2010, device='cuda:0') tensor(-1.1258e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.112600
Average KL loss: 0.331905
Average total loss: 0.444505
tensor(-13.7018, device='cuda:0') tensor(1.2011, device='cuda:0') tensor(-1.3996e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.114237
Average KL loss: 0.331903
Average total loss: 0.446140
tensor(-13.7019, device='cuda:0') tensor(1.2011, device='cuda:0') tensor(4.2161e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.114847
Average KL loss: 0.331902
Average total loss: 0.446749
tensor(-13.7019, device='cuda:0') tensor(1.2011, device='cuda:0') tensor(-1.6754e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.115747
Average KL loss: 0.331901
Average total loss: 0.447648
tensor(-13.7020, device='cuda:0') tensor(1.2012, device='cuda:0') tensor(-1.8334e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.114168
Average KL loss: 0.331899
Average total loss: 0.446067
tensor(-13.7020, device='cuda:0') tensor(1.2012, device='cuda:0') tensor(-2.1347e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.114492
Average KL loss: 0.331897
Average total loss: 0.446389
tensor(-13.7021, device='cuda:0') tensor(1.2012, device='cuda:0') tensor(-2.0934e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.114470
Average KL loss: 0.331895
Average total loss: 0.446365
tensor(-13.7021, device='cuda:0') tensor(1.2013, device='cuda:0') tensor(-6.7426e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.115179
Average KL loss: 0.331893
Average total loss: 0.447073
tensor(-13.7022, device='cuda:0') tensor(1.2013, device='cuda:0') tensor(-9.7250e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.115206
Average KL loss: 0.331892
Average total loss: 0.447099
tensor(-13.7022, device='cuda:0') tensor(1.2014, device='cuda:0') tensor(-7.3357e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.115205
Average KL loss: 0.331892
Average total loss: 0.447096
tensor(-13.7023, device='cuda:0') tensor(1.2014, device='cuda:0') tensor(-2.2806e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.114698
Average KL loss: 0.331890
Average total loss: 0.446588
tensor(-13.7023, device='cuda:0') tensor(1.2014, device='cuda:0') tensor(-6.6942e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.113833
Average KL loss: 0.331889
Average total loss: 0.445722
tensor(-13.7024, device='cuda:0') tensor(1.2014, device='cuda:0') tensor(8.7900e-11, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.113455
Average KL loss: 0.331889
Average total loss: 0.445344
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-1.2191e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.114443
Average KL loss: 0.331889
Average total loss: 0.446332
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-3.1223e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.113776
Average KL loss: 0.331889
Average total loss: 0.445665
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-4.4214e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.114395
Average KL loss: 0.331889
Average total loss: 0.446284
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-7.4201e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.112422
Average KL loss: 0.331889
Average total loss: 0.444311
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-3.5471e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.114498
Average KL loss: 0.331889
Average total loss: 0.446387
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-2.2501e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.114797
Average KL loss: 0.331889
Average total loss: 0.446685
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-4.9399e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.113576
Average KL loss: 0.331888
Average total loss: 0.445464
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-1.5987e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.114406
Average KL loss: 0.331888
Average total loss: 0.446294
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-5.9897e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.114188
Average KL loss: 0.331888
Average total loss: 0.446076
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-1.2691e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.116168
Average KL loss: 0.331888
Average total loss: 0.448056
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-3.3107e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.113443
Average KL loss: 0.331888
Average total loss: 0.445331
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(3.3800e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.113906
Average KL loss: 0.331888
Average total loss: 0.445794
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-1.2512e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.115451
Average KL loss: 0.331888
Average total loss: 0.447338
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(3.0332e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.113586
Average KL loss: 0.331888
Average total loss: 0.445474
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-1.4977e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.113107
Average KL loss: 0.331887
Average total loss: 0.444995
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-5.9103e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.114699
Average KL loss: 0.331887
Average total loss: 0.446587
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-3.7050e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.116044
Average KL loss: 0.331887
Average total loss: 0.447931
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(2.9146e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.113345
Average KL loss: 0.331887
Average total loss: 0.445232
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-8.3858e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.114802
Average KL loss: 0.331887
Average total loss: 0.446689
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-8.6210e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.114117
Average KL loss: 0.331887
Average total loss: 0.446005
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-1.5964e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.113491
Average KL loss: 0.331887
Average total loss: 0.445379
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-2.8111e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.116394
Average KL loss: 0.331887
Average total loss: 0.448281
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-1.7405e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.115559
Average KL loss: 0.331887
Average total loss: 0.447446
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(3.2398e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.113957
Average KL loss: 0.331887
Average total loss: 0.445844
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-1.0221e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.115410
Average KL loss: 0.331887
Average total loss: 0.447297
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-7.1436e-10, device='cuda:0')
 Percentile value: -13.380385589599609
Non-zero model percentage: 5.497567176818848%, Non-zero mask percentage: 5.497567176818848%

--- Pruning Level [13/24]: ---
conv1.weight         | nonzeros =    1405 /    1728             ( 81.31%) | total_pruned =     323 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   10927 /   36864             ( 29.64%) | total_pruned =   25937 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   11314 /   36864             ( 30.69%) | total_pruned =   25550 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    9945 /   36864             ( 26.98%) | total_pruned =   26919 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    9509 /   36864             ( 25.79%) | total_pruned =   27355 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   20124 /   73728             ( 27.29%) | total_pruned =   53604 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   33059 /  147456             ( 22.42%) | total_pruned =  114397 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4065 /    8192             ( 49.62%) | total_pruned =    4127 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   24514 /  147456             ( 16.62%) | total_pruned =  122942 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   24393 /  147456             ( 16.54%) | total_pruned =  123063 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   52911 /  294912             ( 17.94%) | total_pruned =  242001 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     238 /     256             ( 92.97%) | total_pruned =      18 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     202 /     256             ( 78.91%) | total_pruned =      54 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   78490 /  589824             ( 13.31%) | total_pruned =  511334 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   10495 /   32768             ( 32.03%) | total_pruned =   22273 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   36505 /  589824             (  6.19%) | total_pruned =  553319 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     139 /     256             ( 54.30%) | total_pruned =     117 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     113 /     256             ( 44.14%) | total_pruned =     143 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   37738 /  589824             (  6.40%) | total_pruned =  552086 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     227 /     256             ( 88.67%) | total_pruned =      29 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     192 /     256             ( 75.00%) | total_pruned =      64 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   76810 / 1179648             (  6.51%) | total_pruned = 1102838 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     309 /     512             ( 60.35%) | total_pruned =     203 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     258 /     512             ( 50.39%) | total_pruned =     254 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   74261 / 2359296             (  3.15%) | total_pruned = 2285035 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     385 /     512             ( 75.20%) | total_pruned =     127 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     353 /     512             ( 68.95%) | total_pruned =     159 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   13881 /  131072             ( 10.59%) | total_pruned =  117191 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     298 /     512             ( 58.20%) | total_pruned =     214 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     362 /     512             ( 70.70%) | total_pruned =     150 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   34094 / 2359296             (  1.45%) | total_pruned = 2325202 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     171 /     512             ( 33.40%) | total_pruned =     341 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      79 /     512             ( 15.43%) | total_pruned =     433 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   39705 / 2359296             (  1.68%) | total_pruned = 2319591 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     421 /     512             ( 82.23%) | total_pruned =      91 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     350 /     512             ( 68.36%) | total_pruned =     162 | shape = torch.Size([512])
linear.weight        | nonzeros =    3822 /    5120             ( 74.65%) | total_pruned =    1298 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 614560, pruned : 10564202, total: 11178762, Compression rate :      18.19x  ( 94.50% pruned)
Train Epoch: 22/100 Loss: 0.000008 Accuracy: 86.45 100.00 % Best test Accuracy: 86.83%
tensor(-13.7024, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(-2.4511e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.211236
Average KL loss: 0.331547
Average total loss: 0.542783
tensor(-13.7036, device='cuda:0') tensor(1.1768, device='cuda:0') tensor(-1.7414e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.208024
Average KL loss: 0.331280
Average total loss: 0.539304
tensor(-13.7045, device='cuda:0') tensor(1.1642, device='cuda:0') tensor(-4.2034e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.208783
Average KL loss: 0.331155
Average total loss: 0.539938
tensor(-13.7052, device='cuda:0') tensor(1.1569, device='cuda:0') tensor(-3.5602e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.206963
Average KL loss: 0.331073
Average total loss: 0.538036
tensor(-13.7059, device='cuda:0') tensor(1.1524, device='cuda:0') tensor(1.0914e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.208008
Average KL loss: 0.331010
Average total loss: 0.539018
tensor(-13.7065, device='cuda:0') tensor(1.1496, device='cuda:0') tensor(-2.0824e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.203076
Average KL loss: 0.330966
Average total loss: 0.534041
tensor(-13.7071, device='cuda:0') tensor(1.1480, device='cuda:0') tensor(-3.3261e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.203546
Average KL loss: 0.330924
Average total loss: 0.534470
tensor(-13.7076, device='cuda:0') tensor(1.1470, device='cuda:0') tensor(-2.3773e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.200608
Average KL loss: 0.330879
Average total loss: 0.531487
tensor(-13.7082, device='cuda:0') tensor(1.1463, device='cuda:0') tensor(-3.2689e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.199070
Average KL loss: 0.330835
Average total loss: 0.529905
tensor(-13.7087, device='cuda:0') tensor(1.1460, device='cuda:0') tensor(-1.6535e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.201099
Average KL loss: 0.330804
Average total loss: 0.531903
tensor(-13.7093, device='cuda:0') tensor(1.1458, device='cuda:0') tensor(-1.4505e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.195690
Average KL loss: 0.330776
Average total loss: 0.526465
tensor(-13.7098, device='cuda:0') tensor(1.1458, device='cuda:0') tensor(-2.5965e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.196129
Average KL loss: 0.330757
Average total loss: 0.526886
tensor(-13.7104, device='cuda:0') tensor(1.1459, device='cuda:0') tensor(-2.8746e-11, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.190401
Average KL loss: 0.330742
Average total loss: 0.521143
tensor(-13.7109, device='cuda:0') tensor(1.1459, device='cuda:0') tensor(-4.6367e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.190557
Average KL loss: 0.330725
Average total loss: 0.521282
tensor(-13.7114, device='cuda:0') tensor(1.1460, device='cuda:0') tensor(-2.1750e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.190853
Average KL loss: 0.330698
Average total loss: 0.521551
tensor(-13.7119, device='cuda:0') tensor(1.1461, device='cuda:0') tensor(-9.5978e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.189085
Average KL loss: 0.330671
Average total loss: 0.519755
tensor(-13.7125, device='cuda:0') tensor(1.1464, device='cuda:0') tensor(-8.8608e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.187824
Average KL loss: 0.330635
Average total loss: 0.518459
tensor(-13.7130, device='cuda:0') tensor(1.1466, device='cuda:0') tensor(-1.1673e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.188554
Average KL loss: 0.330604
Average total loss: 0.519158
tensor(-13.7135, device='cuda:0') tensor(1.1467, device='cuda:0') tensor(-2.2830e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.188454
Average KL loss: 0.330577
Average total loss: 0.519031
tensor(-13.7141, device='cuda:0') tensor(1.1470, device='cuda:0') tensor(-2.8608e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.181525
Average KL loss: 0.330555
Average total loss: 0.512080
tensor(-13.7146, device='cuda:0') tensor(1.1473, device='cuda:0') tensor(-3.8409e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.183046
Average KL loss: 0.330532
Average total loss: 0.513578
tensor(-13.7151, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(-8.4545e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.185787
Average KL loss: 0.330502
Average total loss: 0.516289
tensor(-13.7156, device='cuda:0') tensor(1.1479, device='cuda:0') tensor(-1.9809e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.181029
Average KL loss: 0.330471
Average total loss: 0.511500
tensor(-13.7161, device='cuda:0') tensor(1.1482, device='cuda:0') tensor(-3.0227e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.179208
Average KL loss: 0.330447
Average total loss: 0.509654
tensor(-13.7167, device='cuda:0') tensor(1.1485, device='cuda:0') tensor(-1.9118e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.182304
Average KL loss: 0.330428
Average total loss: 0.512731
tensor(-13.7172, device='cuda:0') tensor(1.1488, device='cuda:0') tensor(-1.4502e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.176739
Average KL loss: 0.330398
Average total loss: 0.507137
tensor(-13.7177, device='cuda:0') tensor(1.1491, device='cuda:0') tensor(-1.7734e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.178532
Average KL loss: 0.330370
Average total loss: 0.508902
tensor(-13.7182, device='cuda:0') tensor(1.1494, device='cuda:0') tensor(-1.0659e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.179939
Average KL loss: 0.330363
Average total loss: 0.510302
tensor(-13.7187, device='cuda:0') tensor(1.1497, device='cuda:0') tensor(-2.0410e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.176748
Average KL loss: 0.330352
Average total loss: 0.507100
tensor(-13.7193, device='cuda:0') tensor(1.1500, device='cuda:0') tensor(-1.0517e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.172618
Average KL loss: 0.330333
Average total loss: 0.502951
tensor(-13.7198, device='cuda:0') tensor(1.1504, device='cuda:0') tensor(-4.3006e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.174185
Average KL loss: 0.330311
Average total loss: 0.504496
tensor(-13.7203, device='cuda:0') tensor(1.1508, device='cuda:0') tensor(1.7194e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.175337
Average KL loss: 0.330294
Average total loss: 0.505631
tensor(-13.7208, device='cuda:0') tensor(1.1511, device='cuda:0') tensor(-1.0668e-11, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.173526
Average KL loss: 0.330275
Average total loss: 0.503802
tensor(-13.7213, device='cuda:0') tensor(1.1515, device='cuda:0') tensor(-3.5147e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.172826
Average KL loss: 0.330260
Average total loss: 0.503087
tensor(-13.7218, device='cuda:0') tensor(1.1518, device='cuda:0') tensor(-4.2743e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.172187
Average KL loss: 0.330236
Average total loss: 0.502423
tensor(-13.7224, device='cuda:0') tensor(1.1521, device='cuda:0') tensor(-1.6854e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.174125
Average KL loss: 0.330210
Average total loss: 0.504335
tensor(-13.7229, device='cuda:0') tensor(1.1524, device='cuda:0') tensor(-1.0410e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.171360
Average KL loss: 0.330185
Average total loss: 0.501545
tensor(-13.7234, device='cuda:0') tensor(1.1527, device='cuda:0') tensor(-1.2107e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.172536
Average KL loss: 0.330165
Average total loss: 0.502701
tensor(-13.7239, device='cuda:0') tensor(1.1531, device='cuda:0') tensor(2.8584e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.167143
Average KL loss: 0.330144
Average total loss: 0.497287
tensor(-13.7244, device='cuda:0') tensor(1.1534, device='cuda:0') tensor(8.2055e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.168378
Average KL loss: 0.330122
Average total loss: 0.498500
tensor(-13.7249, device='cuda:0') tensor(1.1538, device='cuda:0') tensor(-5.3054e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.168739
Average KL loss: 0.330096
Average total loss: 0.498835
tensor(-13.7254, device='cuda:0') tensor(1.1541, device='cuda:0') tensor(-2.8391e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.166377
Average KL loss: 0.330070
Average total loss: 0.496446
tensor(-13.7260, device='cuda:0') tensor(1.1544, device='cuda:0') tensor(-1.0520e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.169036
Average KL loss: 0.330047
Average total loss: 0.499083
tensor(-13.7265, device='cuda:0') tensor(1.1547, device='cuda:0') tensor(-3.6207e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.166234
Average KL loss: 0.330027
Average total loss: 0.496261
tensor(-13.7270, device='cuda:0') tensor(1.1550, device='cuda:0') tensor(-3.0298e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.166000
Average KL loss: 0.330004
Average total loss: 0.496004
tensor(-13.7275, device='cuda:0') tensor(1.1554, device='cuda:0') tensor(-1.5848e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.164572
Average KL loss: 0.329985
Average total loss: 0.494556
tensor(-13.7280, device='cuda:0') tensor(1.1558, device='cuda:0') tensor(-1.2476e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.163534
Average KL loss: 0.329959
Average total loss: 0.493493
tensor(-13.7285, device='cuda:0') tensor(1.1561, device='cuda:0') tensor(-1.2822e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.164105
Average KL loss: 0.329940
Average total loss: 0.494044
tensor(-13.7290, device='cuda:0') tensor(1.1565, device='cuda:0') tensor(-1.2394e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.165869
Average KL loss: 0.329920
Average total loss: 0.495789
tensor(-13.7296, device='cuda:0') tensor(1.1569, device='cuda:0') tensor(-1.2844e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.165196
Average KL loss: 0.329905
Average total loss: 0.495101
tensor(-13.7301, device='cuda:0') tensor(1.1572, device='cuda:0') tensor(-1.7207e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.160978
Average KL loss: 0.329886
Average total loss: 0.490864
tensor(-13.7306, device='cuda:0') tensor(1.1575, device='cuda:0') tensor(-2.4165e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.160214
Average KL loss: 0.329869
Average total loss: 0.490083
tensor(-13.7311, device='cuda:0') tensor(1.1579, device='cuda:0') tensor(-3.3148e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.160319
Average KL loss: 0.329851
Average total loss: 0.490169
tensor(-13.7316, device='cuda:0') tensor(1.1583, device='cuda:0') tensor(-1.7853e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.162999
Average KL loss: 0.329833
Average total loss: 0.492831
tensor(-13.7321, device='cuda:0') tensor(1.1587, device='cuda:0') tensor(7.9550e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.160267
Average KL loss: 0.329817
Average total loss: 0.490084
tensor(-13.7326, device='cuda:0') tensor(1.1590, device='cuda:0') tensor(-2.2606e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.162934
Average KL loss: 0.329793
Average total loss: 0.492728
tensor(-13.7331, device='cuda:0') tensor(1.1593, device='cuda:0') tensor(-1.8202e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.159604
Average KL loss: 0.329770
Average total loss: 0.489374
tensor(-13.7336, device='cuda:0') tensor(1.1597, device='cuda:0') tensor(-4.6483e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.157021
Average KL loss: 0.329752
Average total loss: 0.486773
tensor(-13.7341, device='cuda:0') tensor(1.1601, device='cuda:0') tensor(-2.2772e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.155654
Average KL loss: 0.329738
Average total loss: 0.485392
tensor(-13.7347, device='cuda:0') tensor(1.1604, device='cuda:0') tensor(-3.2036e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.155807
Average KL loss: 0.329730
Average total loss: 0.485537
tensor(-13.7352, device='cuda:0') tensor(1.1608, device='cuda:0') tensor(4.2087e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.156349
Average KL loss: 0.329712
Average total loss: 0.486062
tensor(-13.7357, device='cuda:0') tensor(1.1611, device='cuda:0') tensor(-1.3505e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.157712
Average KL loss: 0.329687
Average total loss: 0.487400
tensor(-13.7362, device='cuda:0') tensor(1.1615, device='cuda:0') tensor(-1.1384e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.157483
Average KL loss: 0.329664
Average total loss: 0.487147
tensor(-13.7367, device='cuda:0') tensor(1.1618, device='cuda:0') tensor(-1.0078e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.155230
Average KL loss: 0.329641
Average total loss: 0.484871
tensor(-13.7372, device='cuda:0') tensor(1.1622, device='cuda:0') tensor(-8.2818e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.155464
Average KL loss: 0.329616
Average total loss: 0.485080
tensor(-13.7377, device='cuda:0') tensor(1.1625, device='cuda:0') tensor(-2.0739e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.153030
Average KL loss: 0.329591
Average total loss: 0.482621
tensor(-13.7382, device='cuda:0') tensor(1.1628, device='cuda:0') tensor(-4.2814e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.152285
Average KL loss: 0.329568
Average total loss: 0.481853
tensor(-13.7387, device='cuda:0') tensor(1.1632, device='cuda:0') tensor(-1.0212e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.155242
Average KL loss: 0.329553
Average total loss: 0.484796
tensor(-13.7392, device='cuda:0') tensor(1.1635, device='cuda:0') tensor(-1.2319e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.153536
Average KL loss: 0.329538
Average total loss: 0.483074
tensor(-13.7397, device='cuda:0') tensor(1.1639, device='cuda:0') tensor(2.3379e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.155276
Average KL loss: 0.329520
Average total loss: 0.484796
tensor(-13.7402, device='cuda:0') tensor(1.1642, device='cuda:0') tensor(-1.2551e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.152516
Average KL loss: 0.329504
Average total loss: 0.482020
tensor(-13.7407, device='cuda:0') tensor(1.1646, device='cuda:0') tensor(-2.4120e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.151472
Average KL loss: 0.329488
Average total loss: 0.480959
tensor(-13.7412, device='cuda:0') tensor(1.1649, device='cuda:0') tensor(-1.4740e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.151254
Average KL loss: 0.329473
Average total loss: 0.480727
tensor(-13.7417, device='cuda:0') tensor(1.1653, device='cuda:0') tensor(-1.5709e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.151245
Average KL loss: 0.329455
Average total loss: 0.480700
tensor(-13.7422, device='cuda:0') tensor(1.1656, device='cuda:0') tensor(3.4541e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.152560
Average KL loss: 0.329436
Average total loss: 0.481996
tensor(-13.7427, device='cuda:0') tensor(1.1660, device='cuda:0') tensor(5.5520e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.149572
Average KL loss: 0.329421
Average total loss: 0.478993
tensor(-13.7432, device='cuda:0') tensor(1.1664, device='cuda:0') tensor(-4.7752e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.151059
Average KL loss: 0.329404
Average total loss: 0.480463
tensor(-13.7437, device='cuda:0') tensor(1.1667, device='cuda:0') tensor(-2.5177e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.153389
Average KL loss: 0.329377
Average total loss: 0.482766
tensor(-13.7442, device='cuda:0') tensor(1.1671, device='cuda:0') tensor(-8.4491e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.150151
Average KL loss: 0.329358
Average total loss: 0.479509
tensor(-13.7447, device='cuda:0') tensor(1.1675, device='cuda:0') tensor(-3.4860e-11, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.150158
Average KL loss: 0.329340
Average total loss: 0.479498
tensor(-13.7452, device='cuda:0') tensor(1.1678, device='cuda:0') tensor(-1.4388e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.147208
Average KL loss: 0.329319
Average total loss: 0.476526
tensor(-13.7457, device='cuda:0') tensor(1.1682, device='cuda:0') tensor(-1.8032e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.144124
Average KL loss: 0.329307
Average total loss: 0.473431
tensor(-13.7462, device='cuda:0') tensor(1.1686, device='cuda:0') tensor(8.5890e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.147248
Average KL loss: 0.329288
Average total loss: 0.476535
tensor(-13.7466, device='cuda:0') tensor(1.1690, device='cuda:0') tensor(-2.9299e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.148077
Average KL loss: 0.329268
Average total loss: 0.477345
tensor(-13.7471, device='cuda:0') tensor(1.1693, device='cuda:0') tensor(2.2617e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.146069
Average KL loss: 0.329243
Average total loss: 0.475312
tensor(-13.7476, device='cuda:0') tensor(1.1696, device='cuda:0') tensor(-7.7183e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.148683
Average KL loss: 0.329219
Average total loss: 0.477902
tensor(-13.7481, device='cuda:0') tensor(1.1700, device='cuda:0') tensor(-3.1243e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.146834
Average KL loss: 0.329197
Average total loss: 0.476031
tensor(-13.7486, device='cuda:0') tensor(1.1704, device='cuda:0') tensor(-5.8432e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.147853
Average KL loss: 0.329176
Average total loss: 0.477029
tensor(-13.7491, device='cuda:0') tensor(1.1707, device='cuda:0') tensor(-5.5741e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.148404
Average KL loss: 0.329158
Average total loss: 0.477563
tensor(-13.7496, device='cuda:0') tensor(1.1710, device='cuda:0') tensor(-1.4212e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.148503
Average KL loss: 0.329138
Average total loss: 0.477641
tensor(-13.7501, device='cuda:0') tensor(1.1714, device='cuda:0') tensor(-1.7844e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.148582
Average KL loss: 0.329120
Average total loss: 0.477703
tensor(-13.7506, device='cuda:0') tensor(1.1718, device='cuda:0') tensor(-1.6255e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.144705
Average KL loss: 0.329101
Average total loss: 0.473806
tensor(-13.7511, device='cuda:0') tensor(1.1722, device='cuda:0') tensor(-1.2419e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.144249
Average KL loss: 0.329086
Average total loss: 0.473336
tensor(-13.7515, device='cuda:0') tensor(1.1725, device='cuda:0') tensor(-8.5325e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.143163
Average KL loss: 0.329064
Average total loss: 0.472227
tensor(-13.7520, device='cuda:0') tensor(1.1728, device='cuda:0') tensor(-3.9900e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.143273
Average KL loss: 0.329038
Average total loss: 0.472311
tensor(-13.7525, device='cuda:0') tensor(1.1732, device='cuda:0') tensor(7.6281e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.141981
Average KL loss: 0.329012
Average total loss: 0.470993
tensor(-13.7530, device='cuda:0') tensor(1.1735, device='cuda:0') tensor(-2.6389e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.144606
Average KL loss: 0.328989
Average total loss: 0.473596
tensor(-13.7535, device='cuda:0') tensor(1.1739, device='cuda:0') tensor(-2.3878e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.143807
Average KL loss: 0.328968
Average total loss: 0.472775
tensor(-13.7540, device='cuda:0') tensor(1.1743, device='cuda:0') tensor(-1.0711e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.142156
Average KL loss: 0.328943
Average total loss: 0.471098
tensor(-13.7545, device='cuda:0') tensor(1.1746, device='cuda:0') tensor(1.0873e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.141885
Average KL loss: 0.328915
Average total loss: 0.470800
tensor(-13.7549, device='cuda:0') tensor(1.1750, device='cuda:0') tensor(-1.3030e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.141824
Average KL loss: 0.328888
Average total loss: 0.470712
tensor(-13.7554, device='cuda:0') tensor(1.1753, device='cuda:0') tensor(-1.8957e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.143407
Average KL loss: 0.328877
Average total loss: 0.472283
tensor(-13.7559, device='cuda:0') tensor(1.1757, device='cuda:0') tensor(3.2193e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.140890
Average KL loss: 0.328861
Average total loss: 0.469750
tensor(-13.7564, device='cuda:0') tensor(1.1761, device='cuda:0') tensor(-1.2736e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.139745
Average KL loss: 0.328825
Average total loss: 0.468570
tensor(-13.7569, device='cuda:0') tensor(1.1764, device='cuda:0') tensor(-9.9566e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.140999
Average KL loss: 0.328795
Average total loss: 0.469794
tensor(-13.7574, device='cuda:0') tensor(1.1766, device='cuda:0') tensor(-4.1669e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.141442
Average KL loss: 0.328772
Average total loss: 0.470214
tensor(-13.7578, device='cuda:0') tensor(1.1770, device='cuda:0') tensor(-2.7285e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.142520
Average KL loss: 0.328744
Average total loss: 0.471264
tensor(-13.7583, device='cuda:0') tensor(1.1773, device='cuda:0') tensor(-1.1173e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.140292
Average KL loss: 0.328717
Average total loss: 0.469009
tensor(-13.7588, device='cuda:0') tensor(1.1776, device='cuda:0') tensor(-8.2576e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.141435
Average KL loss: 0.328686
Average total loss: 0.470121
tensor(-13.7593, device='cuda:0') tensor(1.1779, device='cuda:0') tensor(-3.8628e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.140413
Average KL loss: 0.328665
Average total loss: 0.469077
tensor(-13.7598, device='cuda:0') tensor(1.1783, device='cuda:0') tensor(-7.6516e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.140342
Average KL loss: 0.328638
Average total loss: 0.468980
tensor(-13.7602, device='cuda:0') tensor(1.1786, device='cuda:0') tensor(-1.1817e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.139015
Average KL loss: 0.328611
Average total loss: 0.467626
tensor(-13.7607, device='cuda:0') tensor(1.1790, device='cuda:0') tensor(-1.1475e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.140362
Average KL loss: 0.328600
Average total loss: 0.468962
tensor(-13.7612, device='cuda:0') tensor(1.1794, device='cuda:0') tensor(-1.9295e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.137932
Average KL loss: 0.328584
Average total loss: 0.466516
tensor(-13.7617, device='cuda:0') tensor(1.1797, device='cuda:0') tensor(-6.5429e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.138419
Average KL loss: 0.328563
Average total loss: 0.466982
tensor(-13.7622, device='cuda:0') tensor(1.1801, device='cuda:0') tensor(-4.7382e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.136815
Average KL loss: 0.328543
Average total loss: 0.465357
tensor(-13.7626, device='cuda:0') tensor(1.1804, device='cuda:0') tensor(2.5819e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.138128
Average KL loss: 0.328517
Average total loss: 0.466645
tensor(-13.7631, device='cuda:0') tensor(1.1808, device='cuda:0') tensor(-1.3928e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.136069
Average KL loss: 0.328497
Average total loss: 0.464567
tensor(-13.7636, device='cuda:0') tensor(1.1811, device='cuda:0') tensor(1.2451e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.137061
Average KL loss: 0.328471
Average total loss: 0.465532
tensor(-13.7641, device='cuda:0') tensor(1.1814, device='cuda:0') tensor(8.2987e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.137631
Average KL loss: 0.328450
Average total loss: 0.466081
tensor(-13.7645, device='cuda:0') tensor(1.1818, device='cuda:0') tensor(-3.2905e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.136757
Average KL loss: 0.328423
Average total loss: 0.465181
tensor(-13.7650, device='cuda:0') tensor(1.1822, device='cuda:0') tensor(-1.8842e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.135358
Average KL loss: 0.328395
Average total loss: 0.463753
tensor(-13.7655, device='cuda:0') tensor(1.1825, device='cuda:0') tensor(1.2067e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.135608
Average KL loss: 0.328362
Average total loss: 0.463970
tensor(-13.7660, device='cuda:0') tensor(1.1828, device='cuda:0') tensor(-3.0731e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.135660
Average KL loss: 0.328345
Average total loss: 0.464005
tensor(-13.7665, device='cuda:0') tensor(1.1831, device='cuda:0') tensor(-9.2987e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.135124
Average KL loss: 0.328337
Average total loss: 0.463461
tensor(-13.7669, device='cuda:0') tensor(1.1835, device='cuda:0') tensor(-1.5966e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.138361
Average KL loss: 0.328318
Average total loss: 0.466679
tensor(-13.7674, device='cuda:0') tensor(1.1839, device='cuda:0') tensor(1.6322e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.134234
Average KL loss: 0.328300
Average total loss: 0.462534
tensor(-13.7679, device='cuda:0') tensor(1.1842, device='cuda:0') tensor(4.8727e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.134408
Average KL loss: 0.328285
Average total loss: 0.462693
tensor(-13.7684, device='cuda:0') tensor(1.1845, device='cuda:0') tensor(1.4259e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.137089
Average KL loss: 0.328262
Average total loss: 0.465351
tensor(-13.7688, device='cuda:0') tensor(1.1848, device='cuda:0') tensor(-1.1023e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.137457
Average KL loss: 0.328240
Average total loss: 0.465697
tensor(-13.7693, device='cuda:0') tensor(1.1851, device='cuda:0') tensor(1.5823e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.134049
Average KL loss: 0.328219
Average total loss: 0.462268
tensor(-13.7698, device='cuda:0') tensor(1.1855, device='cuda:0') tensor(-4.2383e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.135654
Average KL loss: 0.328206
Average total loss: 0.463861
tensor(-13.7703, device='cuda:0') tensor(1.1859, device='cuda:0') tensor(-7.5328e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.134147
Average KL loss: 0.328185
Average total loss: 0.462332
tensor(-13.7707, device='cuda:0') tensor(1.1862, device='cuda:0') tensor(-2.9039e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.135300
Average KL loss: 0.328170
Average total loss: 0.463469
tensor(-13.7712, device='cuda:0') tensor(1.1865, device='cuda:0') tensor(-7.2400e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.133941
Average KL loss: 0.328161
Average total loss: 0.462102
tensor(-13.7717, device='cuda:0') tensor(1.1869, device='cuda:0') tensor(-2.2399e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.134476
Average KL loss: 0.328142
Average total loss: 0.462618
tensor(-13.7722, device='cuda:0') tensor(1.1872, device='cuda:0') tensor(5.8689e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.135388
Average KL loss: 0.328123
Average total loss: 0.463511
tensor(-13.7726, device='cuda:0') tensor(1.1876, device='cuda:0') tensor(-4.9261e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.133326
Average KL loss: 0.328104
Average total loss: 0.461430
tensor(-13.7731, device='cuda:0') tensor(1.1879, device='cuda:0') tensor(-1.0738e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.133136
Average KL loss: 0.328084
Average total loss: 0.461221
tensor(-13.7736, device='cuda:0') tensor(1.1883, device='cuda:0') tensor(-7.4349e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.133379
Average KL loss: 0.328059
Average total loss: 0.461439
tensor(-13.7740, device='cuda:0') tensor(1.1886, device='cuda:0') tensor(-4.0330e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.134343
Average KL loss: 0.328039
Average total loss: 0.462381
tensor(-13.7745, device='cuda:0') tensor(1.1889, device='cuda:0') tensor(-7.7231e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.132292
Average KL loss: 0.328012
Average total loss: 0.460304
tensor(-13.7750, device='cuda:0') tensor(1.1893, device='cuda:0') tensor(1.0892e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.132199
Average KL loss: 0.327988
Average total loss: 0.460187
tensor(-13.7755, device='cuda:0') tensor(1.1896, device='cuda:0') tensor(1.7684e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.132148
Average KL loss: 0.327974
Average total loss: 0.460122
tensor(-13.7759, device='cuda:0') tensor(1.1899, device='cuda:0') tensor(1.5921e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.132674
Average KL loss: 0.327959
Average total loss: 0.460633
tensor(-13.7764, device='cuda:0') tensor(1.1902, device='cuda:0') tensor(-1.3945e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.132809
Average KL loss: 0.327947
Average total loss: 0.460756
tensor(-13.7769, device='cuda:0') tensor(1.1906, device='cuda:0') tensor(-5.5756e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.133097
Average KL loss: 0.327930
Average total loss: 0.461027
tensor(-13.7774, device='cuda:0') tensor(1.1909, device='cuda:0') tensor(-3.2756e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.131511
Average KL loss: 0.327905
Average total loss: 0.459416
tensor(-13.7778, device='cuda:0') tensor(1.1912, device='cuda:0') tensor(-1.3657e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.130420
Average KL loss: 0.327892
Average total loss: 0.458312
tensor(-13.7783, device='cuda:0') tensor(1.1916, device='cuda:0') tensor(-1.2672e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.132406
Average KL loss: 0.327881
Average total loss: 0.460287
tensor(-13.7788, device='cuda:0') tensor(1.1920, device='cuda:0') tensor(6.0846e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.130879
Average KL loss: 0.327861
Average total loss: 0.458741
tensor(-13.7792, device='cuda:0') tensor(1.1923, device='cuda:0') tensor(9.3121e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.131205
Average KL loss: 0.327848
Average total loss: 0.459053
tensor(-13.7797, device='cuda:0') tensor(1.1926, device='cuda:0') tensor(-1.0927e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.132399
Average KL loss: 0.327838
Average total loss: 0.460237
tensor(-13.7802, device='cuda:0') tensor(1.1930, device='cuda:0') tensor(-1.3116e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.131590
Average KL loss: 0.327825
Average total loss: 0.459415
tensor(-13.7807, device='cuda:0') tensor(1.1934, device='cuda:0') tensor(7.7189e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.130659
Average KL loss: 0.327803
Average total loss: 0.458462
tensor(-13.7811, device='cuda:0') tensor(1.1938, device='cuda:0') tensor(4.5499e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.129736
Average KL loss: 0.327776
Average total loss: 0.457513
tensor(-13.7816, device='cuda:0') tensor(1.1941, device='cuda:0') tensor(-1.8102e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.130669
Average KL loss: 0.327766
Average total loss: 0.458434
tensor(-13.7821, device='cuda:0') tensor(1.1944, device='cuda:0') tensor(-1.3187e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.128466
Average KL loss: 0.327743
Average total loss: 0.456209
tensor(-13.7825, device='cuda:0') tensor(1.1947, device='cuda:0') tensor(-1.3710e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.128816
Average KL loss: 0.327718
Average total loss: 0.456534
tensor(-13.7830, device='cuda:0') tensor(1.1951, device='cuda:0') tensor(2.6252e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.127345
Average KL loss: 0.327697
Average total loss: 0.455041
tensor(-13.7835, device='cuda:0') tensor(1.1954, device='cuda:0') tensor(-5.5456e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.128288
Average KL loss: 0.327682
Average total loss: 0.455970
tensor(-13.7839, device='cuda:0') tensor(1.1957, device='cuda:0') tensor(-3.5997e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.129654
Average KL loss: 0.327666
Average total loss: 0.457320
tensor(-13.7844, device='cuda:0') tensor(1.1961, device='cuda:0') tensor(-4.2562e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.129581
Average KL loss: 0.327652
Average total loss: 0.457232
tensor(-13.7849, device='cuda:0') tensor(1.1965, device='cuda:0') tensor(-4.0384e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.129385
Average KL loss: 0.327635
Average total loss: 0.457021
tensor(-13.7854, device='cuda:0') tensor(1.1968, device='cuda:0') tensor(-3.4170e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.127919
Average KL loss: 0.327613
Average total loss: 0.455532
tensor(-13.7858, device='cuda:0') tensor(1.1972, device='cuda:0') tensor(1.2557e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.127596
Average KL loss: 0.327594
Average total loss: 0.455191
tensor(-13.7863, device='cuda:0') tensor(1.1975, device='cuda:0') tensor(-1.2305e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.127553
Average KL loss: 0.327572
Average total loss: 0.455125
tensor(-13.7868, device='cuda:0') tensor(1.1979, device='cuda:0') tensor(-1.0288e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.127916
Average KL loss: 0.327556
Average total loss: 0.455471
tensor(-13.7872, device='cuda:0') tensor(1.1982, device='cuda:0') tensor(-1.0806e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.128056
Average KL loss: 0.327536
Average total loss: 0.455591
tensor(-13.7877, device='cuda:0') tensor(1.1985, device='cuda:0') tensor(-5.4145e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.124821
Average KL loss: 0.327517
Average total loss: 0.452338
tensor(-13.7882, device='cuda:0') tensor(1.1988, device='cuda:0') tensor(-9.8024e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.127755
Average KL loss: 0.327495
Average total loss: 0.455250
tensor(-13.7886, device='cuda:0') tensor(1.1992, device='cuda:0') tensor(-6.6562e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.128887
Average KL loss: 0.327479
Average total loss: 0.456366
tensor(-13.7891, device='cuda:0') tensor(1.1995, device='cuda:0') tensor(-8.4466e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.127856
Average KL loss: 0.327461
Average total loss: 0.455316
tensor(-13.7896, device='cuda:0') tensor(1.1999, device='cuda:0') tensor(-7.7563e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.126370
Average KL loss: 0.327443
Average total loss: 0.453813
tensor(-13.7900, device='cuda:0') tensor(1.2002, device='cuda:0') tensor(2.7386e-11, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.126107
Average KL loss: 0.327427
Average total loss: 0.453534
tensor(-13.7905, device='cuda:0') tensor(1.2005, device='cuda:0') tensor(-8.8371e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.126317
Average KL loss: 0.327410
Average total loss: 0.453727
tensor(-13.7910, device='cuda:0') tensor(1.2008, device='cuda:0') tensor(-8.0380e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.124260
Average KL loss: 0.327395
Average total loss: 0.451655
tensor(-13.7914, device='cuda:0') tensor(1.2012, device='cuda:0') tensor(-1.4312e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.127647
Average KL loss: 0.327374
Average total loss: 0.455021
tensor(-13.7919, device='cuda:0') tensor(1.2015, device='cuda:0') tensor(4.9657e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.124535
Average KL loss: 0.327349
Average total loss: 0.451884
tensor(-13.7924, device='cuda:0') tensor(1.2018, device='cuda:0') tensor(-1.4518e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.124651
Average KL loss: 0.327328
Average total loss: 0.451979
tensor(-13.7928, device='cuda:0') tensor(1.2022, device='cuda:0') tensor(6.1666e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.126082
Average KL loss: 0.327310
Average total loss: 0.453391
tensor(-13.7933, device='cuda:0') tensor(1.2025, device='cuda:0') tensor(-4.8836e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.123877
Average KL loss: 0.327289
Average total loss: 0.451166
tensor(-13.7938, device='cuda:0') tensor(1.2028, device='cuda:0') tensor(-7.7695e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.123744
Average KL loss: 0.327270
Average total loss: 0.451014
tensor(-13.7942, device='cuda:0') tensor(1.2031, device='cuda:0') tensor(1.1700e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.124797
Average KL loss: 0.327247
Average total loss: 0.452045
tensor(-13.7947, device='cuda:0') tensor(1.2034, device='cuda:0') tensor(-1.3099e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.124754
Average KL loss: 0.327226
Average total loss: 0.451980
tensor(-13.7952, device='cuda:0') tensor(1.2038, device='cuda:0') tensor(6.4921e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.122605
Average KL loss: 0.327200
Average total loss: 0.449805
tensor(-13.7956, device='cuda:0') tensor(1.2040, device='cuda:0') tensor(7.4168e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.124370
Average KL loss: 0.327178
Average total loss: 0.451548
tensor(-13.7961, device='cuda:0') tensor(1.2043, device='cuda:0') tensor(-5.2756e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.123665
Average KL loss: 0.327156
Average total loss: 0.450821
tensor(-13.7966, device='cuda:0') tensor(1.2046, device='cuda:0') tensor(-6.2429e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.127215
Average KL loss: 0.327140
Average total loss: 0.454355
tensor(-13.7970, device='cuda:0') tensor(1.2049, device='cuda:0') tensor(1.2386e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.122225
Average KL loss: 0.327123
Average total loss: 0.449348
tensor(-13.7975, device='cuda:0') tensor(1.2052, device='cuda:0') tensor(-2.7897e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.125147
Average KL loss: 0.327107
Average total loss: 0.452254
tensor(-13.7980, device='cuda:0') tensor(1.2056, device='cuda:0') tensor(-1.7516e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.124142
Average KL loss: 0.327093
Average total loss: 0.451235
tensor(-13.7984, device='cuda:0') tensor(1.2060, device='cuda:0') tensor(-1.2174e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.125498
Average KL loss: 0.327074
Average total loss: 0.452572
tensor(-13.7989, device='cuda:0') tensor(1.2064, device='cuda:0') tensor(-6.1811e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.121627
Average KL loss: 0.327064
Average total loss: 0.448691
tensor(-13.7994, device='cuda:0') tensor(1.2067, device='cuda:0') tensor(4.8535e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.122521
Average KL loss: 0.327049
Average total loss: 0.449570
tensor(-13.7998, device='cuda:0') tensor(1.2071, device='cuda:0') tensor(-1.0371e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.124686
Average KL loss: 0.327035
Average total loss: 0.451721
tensor(-13.8003, device='cuda:0') tensor(1.2074, device='cuda:0') tensor(1.6776e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.124759
Average KL loss: 0.327011
Average total loss: 0.451770
tensor(-13.8008, device='cuda:0') tensor(1.2077, device='cuda:0') tensor(7.3810e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.123322
Average KL loss: 0.327001
Average total loss: 0.450323
tensor(-13.8012, device='cuda:0') tensor(1.2081, device='cuda:0') tensor(-5.7015e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.122678
Average KL loss: 0.326985
Average total loss: 0.449663
tensor(-13.8017, device='cuda:0') tensor(1.2084, device='cuda:0') tensor(-7.5787e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.121213
Average KL loss: 0.326965
Average total loss: 0.448177
 Percentile value: -13.460029220581054
Non-zero model percentage: 4.398054122924805%, Non-zero mask percentage: 4.398054122924805%

--- Pruning Level [14/24]: ---
conv1.weight         | nonzeros =    1342 /    1728             ( 77.66%) | total_pruned =     386 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    9342 /   36864             ( 25.34%) | total_pruned =   27522 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    9661 /   36864             ( 26.21%) | total_pruned =   27203 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    8476 /   36864             ( 22.99%) | total_pruned =   28388 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    8103 /   36864             ( 21.98%) | total_pruned =   28761 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   17097 /   73728             ( 23.19%) | total_pruned =   56631 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   27546 /  147456             ( 18.68%) | total_pruned =  119910 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3659 /    8192             ( 44.67%) | total_pruned =    4533 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   20203 /  147456             ( 13.70%) | total_pruned =  127253 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   20028 /  147456             ( 13.58%) | total_pruned =  127428 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   43600 /  294912             ( 14.78%) | total_pruned =  251312 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     187 /     256             ( 73.05%) | total_pruned =      69 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   63137 /  589824             ( 10.70%) | total_pruned =  526687 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     237 /     256             ( 92.58%) | total_pruned =      19 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     192 /     256             ( 75.00%) | total_pruned =      64 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    9058 /   32768             ( 27.64%) | total_pruned =   23710 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     188 /     256             ( 73.44%) | total_pruned =      68 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   28562 /  589824             (  4.84%) | total_pruned =  561262 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     130 /     256             ( 50.78%) | total_pruned =     126 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     102 /     256             ( 39.84%) | total_pruned =     154 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   29404 /  589824             (  4.99%) | total_pruned =  560420 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     167 /     256             ( 65.23%) | total_pruned =      89 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   60195 / 1179648             (  5.10%) | total_pruned = 1119453 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     294 /     512             ( 57.42%) | total_pruned =     218 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     239 /     512             ( 46.68%) | total_pruned =     273 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   56489 / 2359296             (  2.39%) | total_pruned = 2302807 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     360 /     512             ( 70.31%) | total_pruned =     152 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     339 /     512             ( 66.21%) | total_pruned =     173 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   11132 /  131072             (  8.49%) | total_pruned =  119940 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     281 /     512             ( 54.88%) | total_pruned =     231 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     339 /     512             ( 66.21%) | total_pruned =     173 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   25690 / 2359296             (  1.09%) | total_pruned = 2333606 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     147 /     512             ( 28.71%) | total_pruned =     365 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      66 /     512             ( 12.89%) | total_pruned =     446 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   29084 / 2359296             (  1.23%) | total_pruned = 2330212 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     408 /     512             ( 79.69%) | total_pruned =     104 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     317 /     512             ( 61.91%) | total_pruned =     195 | shape = torch.Size([512])
linear.weight        | nonzeros =    3616 /    5120             ( 70.62%) | total_pruned =    1504 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 491648, pruned : 10687114, total: 11178762, Compression rate :      22.74x  ( 95.60% pruned)
Train Epoch: 21/100 Loss: 0.000008 Accuracy: 86.48 100.00 % Best test Accuracy: 86.72%
tensor(-13.8021, device='cuda:0') tensor(1.2087, device='cuda:0') tensor(7.7597e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.212223
Average KL loss: 0.326644
Average total loss: 0.538867
tensor(-13.8033, device='cuda:0') tensor(1.1843, device='cuda:0') tensor(-1.6806e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.214756
Average KL loss: 0.326388
Average total loss: 0.541144
tensor(-13.8041, device='cuda:0') tensor(1.1706, device='cuda:0') tensor(3.1136e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.211848
Average KL loss: 0.326248
Average total loss: 0.538096
tensor(-13.8048, device='cuda:0') tensor(1.1620, device='cuda:0') tensor(1.3215e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.201142
Average KL loss: 0.326149
Average total loss: 0.527291
tensor(-13.8055, device='cuda:0') tensor(1.1563, device='cuda:0') tensor(-1.3584e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.206957
Average KL loss: 0.326068
Average total loss: 0.533025
tensor(-13.8060, device='cuda:0') tensor(1.1527, device='cuda:0') tensor(7.6259e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.205738
Average KL loss: 0.326003
Average total loss: 0.531741
tensor(-13.8066, device='cuda:0') tensor(1.1504, device='cuda:0') tensor(-4.0636e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.204324
Average KL loss: 0.325956
Average total loss: 0.530279
tensor(-13.8071, device='cuda:0') tensor(1.1489, device='cuda:0') tensor(4.5260e-11, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.198568
Average KL loss: 0.325922
Average total loss: 0.524489
tensor(-13.8076, device='cuda:0') tensor(1.1479, device='cuda:0') tensor(2.3298e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.196641
Average KL loss: 0.325883
Average total loss: 0.522524
tensor(-13.8081, device='cuda:0') tensor(1.1472, device='cuda:0') tensor(-2.0522e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.196740
Average KL loss: 0.325846
Average total loss: 0.522587
tensor(-13.8086, device='cuda:0') tensor(1.1469, device='cuda:0') tensor(-1.5133e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.192694
Average KL loss: 0.325814
Average total loss: 0.518508
tensor(-13.8091, device='cuda:0') tensor(1.1466, device='cuda:0') tensor(-1.6835e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.191961
Average KL loss: 0.325787
Average total loss: 0.517748
tensor(-13.8096, device='cuda:0') tensor(1.1465, device='cuda:0') tensor(-2.6950e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.193568
Average KL loss: 0.325762
Average total loss: 0.519330
tensor(-13.8100, device='cuda:0') tensor(1.1465, device='cuda:0') tensor(-1.9302e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.188180
Average KL loss: 0.325738
Average total loss: 0.513918
tensor(-13.8105, device='cuda:0') tensor(1.1466, device='cuda:0') tensor(-1.1411e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.192986
Average KL loss: 0.325708
Average total loss: 0.518694
tensor(-13.8110, device='cuda:0') tensor(1.1467, device='cuda:0') tensor(-6.6417e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.188583
Average KL loss: 0.325681
Average total loss: 0.514264
tensor(-13.8115, device='cuda:0') tensor(1.1469, device='cuda:0') tensor(-8.0957e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.187032
Average KL loss: 0.325661
Average total loss: 0.512693
tensor(-13.8119, device='cuda:0') tensor(1.1471, device='cuda:0') tensor(-4.7592e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.184524
Average KL loss: 0.325638
Average total loss: 0.510162
tensor(-13.8124, device='cuda:0') tensor(1.1474, device='cuda:0') tensor(-1.8651e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.184688
Average KL loss: 0.325611
Average total loss: 0.510299
tensor(-13.8129, device='cuda:0') tensor(1.1477, device='cuda:0') tensor(-4.0737e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.184218
Average KL loss: 0.325594
Average total loss: 0.509812
tensor(-13.8133, device='cuda:0') tensor(1.1480, device='cuda:0') tensor(9.4393e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.178903
Average KL loss: 0.325581
Average total loss: 0.504484
tensor(-13.8138, device='cuda:0') tensor(1.1483, device='cuda:0') tensor(-3.2134e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.179018
Average KL loss: 0.325562
Average total loss: 0.504580
tensor(-13.8143, device='cuda:0') tensor(1.1486, device='cuda:0') tensor(-1.7258e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.181265
Average KL loss: 0.325542
Average total loss: 0.506806
tensor(-13.8147, device='cuda:0') tensor(1.1489, device='cuda:0') tensor(1.4610e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.177643
Average KL loss: 0.325526
Average total loss: 0.503168
tensor(-13.8152, device='cuda:0') tensor(1.1492, device='cuda:0') tensor(2.0828e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.178765
Average KL loss: 0.325507
Average total loss: 0.504272
tensor(-13.8157, device='cuda:0') tensor(1.1495, device='cuda:0') tensor(-1.5539e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.176016
Average KL loss: 0.325479
Average total loss: 0.501495
tensor(-13.8161, device='cuda:0') tensor(1.1498, device='cuda:0') tensor(-4.3708e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.178051
Average KL loss: 0.325459
Average total loss: 0.503510
tensor(-13.8166, device='cuda:0') tensor(1.1501, device='cuda:0') tensor(4.5201e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.175881
Average KL loss: 0.325439
Average total loss: 0.501320
tensor(-13.8171, device='cuda:0') tensor(1.1504, device='cuda:0') tensor(1.2712e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.176235
Average KL loss: 0.325426
Average total loss: 0.501661
tensor(-13.8175, device='cuda:0') tensor(1.1508, device='cuda:0') tensor(-4.3537e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.174261
Average KL loss: 0.325418
Average total loss: 0.499679
tensor(-13.8180, device='cuda:0') tensor(1.1511, device='cuda:0') tensor(-2.8682e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.175641
Average KL loss: 0.325399
Average total loss: 0.501040
tensor(-13.8184, device='cuda:0') tensor(1.1515, device='cuda:0') tensor(4.5500e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.173502
Average KL loss: 0.325378
Average total loss: 0.498880
tensor(-13.8189, device='cuda:0') tensor(1.1518, device='cuda:0') tensor(6.5406e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.169156
Average KL loss: 0.325358
Average total loss: 0.494514
tensor(-13.8194, device='cuda:0') tensor(1.1522, device='cuda:0') tensor(-1.9313e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.170609
Average KL loss: 0.325347
Average total loss: 0.495957
tensor(-13.8198, device='cuda:0') tensor(1.1525, device='cuda:0') tensor(-1.5877e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.170650
Average KL loss: 0.325329
Average total loss: 0.495980
tensor(-13.8203, device='cuda:0') tensor(1.1529, device='cuda:0') tensor(1.3816e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.168198
Average KL loss: 0.325310
Average total loss: 0.493508
tensor(-13.8208, device='cuda:0') tensor(1.1532, device='cuda:0') tensor(-6.8746e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.169081
Average KL loss: 0.325296
Average total loss: 0.494376
tensor(-13.8212, device='cuda:0') tensor(1.1536, device='cuda:0') tensor(6.7724e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.170334
Average KL loss: 0.325279
Average total loss: 0.495613
tensor(-13.8217, device='cuda:0') tensor(1.1540, device='cuda:0') tensor(-3.6813e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.168053
Average KL loss: 0.325262
Average total loss: 0.493315
tensor(-13.8221, device='cuda:0') tensor(1.1544, device='cuda:0') tensor(4.8827e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.165117
Average KL loss: 0.325241
Average total loss: 0.490358
tensor(-13.8226, device='cuda:0') tensor(1.1548, device='cuda:0') tensor(-2.2112e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.169611
Average KL loss: 0.325216
Average total loss: 0.494827
tensor(-13.8231, device='cuda:0') tensor(1.1550, device='cuda:0') tensor(-1.0373e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.164604
Average KL loss: 0.325197
Average total loss: 0.489801
tensor(-13.8235, device='cuda:0') tensor(1.1554, device='cuda:0') tensor(-1.6247e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.167892
Average KL loss: 0.325184
Average total loss: 0.493076
tensor(-13.8240, device='cuda:0') tensor(1.1558, device='cuda:0') tensor(3.6305e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.165428
Average KL loss: 0.325164
Average total loss: 0.490592
tensor(-13.8244, device='cuda:0') tensor(1.1561, device='cuda:0') tensor(-1.1500e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.167062
Average KL loss: 0.325140
Average total loss: 0.492202
tensor(-13.8249, device='cuda:0') tensor(1.1565, device='cuda:0') tensor(-6.7771e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.164860
Average KL loss: 0.325112
Average total loss: 0.489972
tensor(-13.8254, device='cuda:0') tensor(1.1568, device='cuda:0') tensor(-4.1210e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.162641
Average KL loss: 0.325080
Average total loss: 0.487721
tensor(-13.8258, device='cuda:0') tensor(1.1571, device='cuda:0') tensor(6.2602e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.167148
Average KL loss: 0.325053
Average total loss: 0.492201
tensor(-13.8263, device='cuda:0') tensor(1.1575, device='cuda:0') tensor(-1.1504e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.160922
Average KL loss: 0.325030
Average total loss: 0.485952
tensor(-13.8267, device='cuda:0') tensor(1.1579, device='cuda:0') tensor(7.8030e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.163364
Average KL loss: 0.325011
Average total loss: 0.488375
tensor(-13.8272, device='cuda:0') tensor(1.1582, device='cuda:0') tensor(-1.1501e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.164325
Average KL loss: 0.324999
Average total loss: 0.489324
tensor(-13.8276, device='cuda:0') tensor(1.1586, device='cuda:0') tensor(3.6184e-11, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.160404
Average KL loss: 0.324978
Average total loss: 0.485382
tensor(-13.8281, device='cuda:0') tensor(1.1590, device='cuda:0') tensor(-2.7151e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.159309
Average KL loss: 0.324951
Average total loss: 0.484260
tensor(-13.8286, device='cuda:0') tensor(1.1593, device='cuda:0') tensor(-1.0538e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.159265
Average KL loss: 0.324927
Average total loss: 0.484192
tensor(-13.8290, device='cuda:0') tensor(1.1596, device='cuda:0') tensor(-1.6171e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.161536
Average KL loss: 0.324914
Average total loss: 0.486450
tensor(-13.8295, device='cuda:0') tensor(1.1600, device='cuda:0') tensor(-6.3617e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.156127
Average KL loss: 0.324896
Average total loss: 0.481024
tensor(-13.8299, device='cuda:0') tensor(1.1604, device='cuda:0') tensor(1.9284e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.159104
Average KL loss: 0.324879
Average total loss: 0.483984
tensor(-13.8304, device='cuda:0') tensor(1.1607, device='cuda:0') tensor(-1.4678e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.157841
Average KL loss: 0.324851
Average total loss: 0.482692
tensor(-13.8309, device='cuda:0') tensor(1.1611, device='cuda:0') tensor(-1.3506e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.157851
Average KL loss: 0.324832
Average total loss: 0.482683
tensor(-13.8313, device='cuda:0') tensor(1.1614, device='cuda:0') tensor(-2.3570e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.159021
Average KL loss: 0.324815
Average total loss: 0.483836
tensor(-13.8318, device='cuda:0') tensor(1.1618, device='cuda:0') tensor(-1.8145e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.155926
Average KL loss: 0.324792
Average total loss: 0.480719
tensor(-13.8322, device='cuda:0') tensor(1.1621, device='cuda:0') tensor(-9.0370e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.160736
Average KL loss: 0.324773
Average total loss: 0.485509
tensor(-13.8327, device='cuda:0') tensor(1.1625, device='cuda:0') tensor(-1.8773e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.157409
Average KL loss: 0.324760
Average total loss: 0.482169
tensor(-13.8331, device='cuda:0') tensor(1.1629, device='cuda:0') tensor(-7.1894e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.155410
Average KL loss: 0.324743
Average total loss: 0.480153
tensor(-13.8336, device='cuda:0') tensor(1.1632, device='cuda:0') tensor(1.0408e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.154558
Average KL loss: 0.324716
Average total loss: 0.479274
tensor(-13.8340, device='cuda:0') tensor(1.1636, device='cuda:0') tensor(-2.6773e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.157813
Average KL loss: 0.324697
Average total loss: 0.482510
tensor(-13.8345, device='cuda:0') tensor(1.1640, device='cuda:0') tensor(-1.7911e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.155126
Average KL loss: 0.324678
Average total loss: 0.479804
tensor(-13.8350, device='cuda:0') tensor(1.1643, device='cuda:0') tensor(-3.0868e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.156733
Average KL loss: 0.324665
Average total loss: 0.481397
tensor(-13.8354, device='cuda:0') tensor(1.1647, device='cuda:0') tensor(-1.7478e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.152848
Average KL loss: 0.324658
Average total loss: 0.477505
tensor(-13.8359, device='cuda:0') tensor(1.1650, device='cuda:0') tensor(-2.5227e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.153364
Average KL loss: 0.324645
Average total loss: 0.478009
tensor(-13.8363, device='cuda:0') tensor(1.1653, device='cuda:0') tensor(-6.0474e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.152868
Average KL loss: 0.324628
Average total loss: 0.477496
tensor(-13.8368, device='cuda:0') tensor(1.1657, device='cuda:0') tensor(2.3850e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.152713
Average KL loss: 0.324618
Average total loss: 0.477331
tensor(-13.8372, device='cuda:0') tensor(1.1661, device='cuda:0') tensor(-7.0221e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.150413
Average KL loss: 0.324607
Average total loss: 0.475020
tensor(-13.8377, device='cuda:0') tensor(1.1664, device='cuda:0') tensor(-5.4548e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.152414
Average KL loss: 0.324594
Average total loss: 0.477009
tensor(-13.8381, device='cuda:0') tensor(1.1668, device='cuda:0') tensor(2.0874e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.152102
Average KL loss: 0.324577
Average total loss: 0.476679
tensor(-13.8386, device='cuda:0') tensor(1.1671, device='cuda:0') tensor(-1.6222e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.151644
Average KL loss: 0.324567
Average total loss: 0.476211
tensor(-13.8390, device='cuda:0') tensor(1.1675, device='cuda:0') tensor(-1.4907e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.152005
Average KL loss: 0.324555
Average total loss: 0.476560
tensor(-13.8395, device='cuda:0') tensor(1.1678, device='cuda:0') tensor(-2.2371e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.150532
Average KL loss: 0.324544
Average total loss: 0.475076
tensor(-13.8399, device='cuda:0') tensor(1.1682, device='cuda:0') tensor(-1.1969e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.152779
Average KL loss: 0.324539
Average total loss: 0.477318
tensor(-13.8404, device='cuda:0') tensor(1.1686, device='cuda:0') tensor(5.7847e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.149821
Average KL loss: 0.324528
Average total loss: 0.474348
tensor(-13.8408, device='cuda:0') tensor(1.1690, device='cuda:0') tensor(-3.5569e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.151451
Average KL loss: 0.324516
Average total loss: 0.475966
tensor(-13.8413, device='cuda:0') tensor(1.1693, device='cuda:0') tensor(-2.5738e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.151497
Average KL loss: 0.324501
Average total loss: 0.475998
tensor(-13.8417, device='cuda:0') tensor(1.1697, device='cuda:0') tensor(-1.7669e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.151679
Average KL loss: 0.324484
Average total loss: 0.476163
tensor(-13.8422, device='cuda:0') tensor(1.1702, device='cuda:0') tensor(1.4464e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.148030
Average KL loss: 0.324468
Average total loss: 0.472499
tensor(-13.8426, device='cuda:0') tensor(1.1706, device='cuda:0') tensor(-2.8101e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.151198
Average KL loss: 0.324453
Average total loss: 0.475651
tensor(-13.8431, device='cuda:0') tensor(1.1709, device='cuda:0') tensor(-3.6167e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.147670
Average KL loss: 0.324439
Average total loss: 0.472109
tensor(-13.8435, device='cuda:0') tensor(1.1713, device='cuda:0') tensor(-2.0714e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.146270
Average KL loss: 0.324425
Average total loss: 0.470695
tensor(-13.8440, device='cuda:0') tensor(1.1716, device='cuda:0') tensor(-2.3394e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.147719
Average KL loss: 0.324411
Average total loss: 0.472131
tensor(-13.8445, device='cuda:0') tensor(1.1720, device='cuda:0') tensor(-3.3948e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.143360
Average KL loss: 0.324400
Average total loss: 0.467760
tensor(-13.8449, device='cuda:0') tensor(1.1723, device='cuda:0') tensor(-2.2007e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.147484
Average KL loss: 0.324377
Average total loss: 0.471861
tensor(-13.8454, device='cuda:0') tensor(1.1727, device='cuda:0') tensor(-2.0131e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.148415
Average KL loss: 0.324361
Average total loss: 0.472777
tensor(-13.8458, device='cuda:0') tensor(1.1731, device='cuda:0') tensor(6.6528e-11, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.147456
Average KL loss: 0.324340
Average total loss: 0.471796
tensor(-13.8462, device='cuda:0') tensor(1.1734, device='cuda:0') tensor(-1.7500e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.149333
Average KL loss: 0.324317
Average total loss: 0.473650
tensor(-13.8467, device='cuda:0') tensor(1.1738, device='cuda:0') tensor(-5.3170e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.146595
Average KL loss: 0.324301
Average total loss: 0.470896
tensor(-13.8471, device='cuda:0') tensor(1.1742, device='cuda:0') tensor(-1.4187e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.147988
Average KL loss: 0.324289
Average total loss: 0.472277
tensor(-13.8476, device='cuda:0') tensor(1.1746, device='cuda:0') tensor(-7.6773e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.146422
Average KL loss: 0.324279
Average total loss: 0.470701
tensor(-13.8480, device='cuda:0') tensor(1.1749, device='cuda:0') tensor(-1.3906e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.147114
Average KL loss: 0.324260
Average total loss: 0.471374
tensor(-13.8485, device='cuda:0') tensor(1.1753, device='cuda:0') tensor(-1.0349e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.146203
Average KL loss: 0.324240
Average total loss: 0.470443
tensor(-13.8489, device='cuda:0') tensor(1.1757, device='cuda:0') tensor(-4.6471e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.147504
Average KL loss: 0.324226
Average total loss: 0.471730
tensor(-13.8494, device='cuda:0') tensor(1.1760, device='cuda:0') tensor(1.2240e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.141955
Average KL loss: 0.324206
Average total loss: 0.466161
tensor(-13.8498, device='cuda:0') tensor(1.1764, device='cuda:0') tensor(1.1127e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.146298
Average KL loss: 0.324187
Average total loss: 0.470485
tensor(-13.8503, device='cuda:0') tensor(1.1767, device='cuda:0') tensor(-2.8881e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.143128
Average KL loss: 0.324173
Average total loss: 0.467301
tensor(-13.8507, device='cuda:0') tensor(1.1771, device='cuda:0') tensor(-5.8888e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.143277
Average KL loss: 0.324161
Average total loss: 0.467439
tensor(-13.8512, device='cuda:0') tensor(1.1774, device='cuda:0') tensor(8.1729e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.145775
Average KL loss: 0.324142
Average total loss: 0.469917
tensor(-13.8516, device='cuda:0') tensor(1.1777, device='cuda:0') tensor(-5.1473e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.145854
Average KL loss: 0.324118
Average total loss: 0.469972
tensor(-13.8521, device='cuda:0') tensor(1.1782, device='cuda:0') tensor(-3.7454e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.142667
Average KL loss: 0.324098
Average total loss: 0.466765
tensor(-13.8525, device='cuda:0') tensor(1.1785, device='cuda:0') tensor(-4.3535e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.145693
Average KL loss: 0.324087
Average total loss: 0.469779
tensor(-13.8530, device='cuda:0') tensor(1.1788, device='cuda:0') tensor(-2.1382e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.140108
Average KL loss: 0.324068
Average total loss: 0.464176
tensor(-13.8534, device='cuda:0') tensor(1.1791, device='cuda:0') tensor(-8.7514e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.140687
Average KL loss: 0.324054
Average total loss: 0.464741
tensor(-13.8539, device='cuda:0') tensor(1.1795, device='cuda:0') tensor(4.3149e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.144460
Average KL loss: 0.324046
Average total loss: 0.468506
tensor(-13.8543, device='cuda:0') tensor(1.1799, device='cuda:0') tensor(-5.6882e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.143507
Average KL loss: 0.324039
Average total loss: 0.467546
tensor(-13.8547, device='cuda:0') tensor(1.1802, device='cuda:0') tensor(-1.1729e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.143766
Average KL loss: 0.324023
Average total loss: 0.467789
tensor(-13.8552, device='cuda:0') tensor(1.1806, device='cuda:0') tensor(-2.6647e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.141276
Average KL loss: 0.324006
Average total loss: 0.465283
tensor(-13.8556, device='cuda:0') tensor(1.1810, device='cuda:0') tensor(2.8893e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.143468
Average KL loss: 0.323992
Average total loss: 0.467460
tensor(-13.8561, device='cuda:0') tensor(1.1813, device='cuda:0') tensor(-1.7680e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.142830
Average KL loss: 0.323980
Average total loss: 0.466810
tensor(-13.8565, device='cuda:0') tensor(1.1817, device='cuda:0') tensor(-1.5087e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.142146
Average KL loss: 0.323966
Average total loss: 0.466112
tensor(-13.8570, device='cuda:0') tensor(1.1820, device='cuda:0') tensor(1.1680e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.139589
Average KL loss: 0.323940
Average total loss: 0.463529
tensor(-13.8574, device='cuda:0') tensor(1.1824, device='cuda:0') tensor(-8.6634e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.139254
Average KL loss: 0.323924
Average total loss: 0.463178
tensor(-13.8579, device='cuda:0') tensor(1.1827, device='cuda:0') tensor(2.6853e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.141604
Average KL loss: 0.323899
Average total loss: 0.465503
tensor(-13.8583, device='cuda:0') tensor(1.1831, device='cuda:0') tensor(1.4422e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.138339
Average KL loss: 0.323881
Average total loss: 0.462220
tensor(-13.8588, device='cuda:0') tensor(1.1835, device='cuda:0') tensor(-9.0869e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.139532
Average KL loss: 0.323868
Average total loss: 0.463400
tensor(-13.8592, device='cuda:0') tensor(1.1838, device='cuda:0') tensor(-1.6518e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.138319
Average KL loss: 0.323855
Average total loss: 0.462173
tensor(-13.8596, device='cuda:0') tensor(1.1842, device='cuda:0') tensor(-1.7988e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.138786
Average KL loss: 0.323838
Average total loss: 0.462623
tensor(-13.8601, device='cuda:0') tensor(1.1845, device='cuda:0') tensor(-8.6578e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.139093
Average KL loss: 0.323815
Average total loss: 0.462908
tensor(-13.8605, device='cuda:0') tensor(1.1849, device='cuda:0') tensor(-9.3393e-11, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.139123
Average KL loss: 0.323799
Average total loss: 0.462922
tensor(-13.8610, device='cuda:0') tensor(1.1852, device='cuda:0') tensor(1.0959e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.140137
Average KL loss: 0.323785
Average total loss: 0.463922
tensor(-13.8614, device='cuda:0') tensor(1.1856, device='cuda:0') tensor(-1.9575e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.138643
Average KL loss: 0.323766
Average total loss: 0.462409
tensor(-13.8619, device='cuda:0') tensor(1.1859, device='cuda:0') tensor(-6.4082e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.138163
Average KL loss: 0.323749
Average total loss: 0.461912
tensor(-13.8623, device='cuda:0') tensor(1.1863, device='cuda:0') tensor(6.4064e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.136277
Average KL loss: 0.323732
Average total loss: 0.460009
tensor(-13.8627, device='cuda:0') tensor(1.1866, device='cuda:0') tensor(2.8734e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.137987
Average KL loss: 0.323715
Average total loss: 0.461702
tensor(-13.8632, device='cuda:0') tensor(1.1870, device='cuda:0') tensor(-7.3647e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.137685
Average KL loss: 0.323690
Average total loss: 0.461375
tensor(-13.8636, device='cuda:0') tensor(1.1873, device='cuda:0') tensor(6.7613e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.139744
Average KL loss: 0.323670
Average total loss: 0.463414
tensor(-13.8640, device='cuda:0') tensor(1.1877, device='cuda:0') tensor(-5.1991e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.138290
Average KL loss: 0.323655
Average total loss: 0.461945
tensor(-13.8645, device='cuda:0') tensor(1.1880, device='cuda:0') tensor(-1.9462e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.137115
Average KL loss: 0.323636
Average total loss: 0.460750
tensor(-13.8649, device='cuda:0') tensor(1.1884, device='cuda:0') tensor(-1.1298e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.139071
Average KL loss: 0.323616
Average total loss: 0.462687
tensor(-13.8654, device='cuda:0') tensor(1.1887, device='cuda:0') tensor(-1.2807e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.138156
Average KL loss: 0.323597
Average total loss: 0.461753
tensor(-13.8658, device='cuda:0') tensor(1.1891, device='cuda:0') tensor(-1.5429e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.137599
Average KL loss: 0.323579
Average total loss: 0.461178
tensor(-13.8662, device='cuda:0') tensor(1.1895, device='cuda:0') tensor(4.5815e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.137522
Average KL loss: 0.323563
Average total loss: 0.461086
tensor(-13.8667, device='cuda:0') tensor(1.1898, device='cuda:0') tensor(1.1908e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.136785
Average KL loss: 0.323548
Average total loss: 0.460333
tensor(-13.8671, device='cuda:0') tensor(1.1902, device='cuda:0') tensor(8.2487e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.136262
Average KL loss: 0.323527
Average total loss: 0.459789
tensor(-13.8675, device='cuda:0') tensor(1.1905, device='cuda:0') tensor(-1.4328e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.134844
Average KL loss: 0.323501
Average total loss: 0.458344
tensor(-13.8680, device='cuda:0') tensor(1.1908, device='cuda:0') tensor(-1.5058e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.134899
Average KL loss: 0.323482
Average total loss: 0.458381
tensor(-13.8684, device='cuda:0') tensor(1.1911, device='cuda:0') tensor(8.3712e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.137914
Average KL loss: 0.323464
Average total loss: 0.461379
tensor(-13.8688, device='cuda:0') tensor(1.1914, device='cuda:0') tensor(-9.6098e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.136829
Average KL loss: 0.323442
Average total loss: 0.460271
tensor(-13.8693, device='cuda:0') tensor(1.1918, device='cuda:0') tensor(-1.8788e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.135424
Average KL loss: 0.323419
Average total loss: 0.458843
tensor(-13.8697, device='cuda:0') tensor(1.1921, device='cuda:0') tensor(-2.3181e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.134394
Average KL loss: 0.323402
Average total loss: 0.457796
tensor(-13.8701, device='cuda:0') tensor(1.1924, device='cuda:0') tensor(-8.7101e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.135214
Average KL loss: 0.323389
Average total loss: 0.458603
tensor(-13.8706, device='cuda:0') tensor(1.1928, device='cuda:0') tensor(5.6545e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.136236
Average KL loss: 0.323373
Average total loss: 0.459609
tensor(-13.8710, device='cuda:0') tensor(1.1932, device='cuda:0') tensor(-1.3712e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.136512
Average KL loss: 0.323360
Average total loss: 0.459872
tensor(-13.8714, device='cuda:0') tensor(1.1936, device='cuda:0') tensor(-5.5487e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.136181
Average KL loss: 0.323339
Average total loss: 0.459520
tensor(-13.8719, device='cuda:0') tensor(1.1938, device='cuda:0') tensor(-1.0719e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.136182
Average KL loss: 0.323324
Average total loss: 0.459507
tensor(-13.8723, device='cuda:0') tensor(1.1942, device='cuda:0') tensor(-1.7296e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.133360
Average KL loss: 0.323314
Average total loss: 0.456674
tensor(-13.8727, device='cuda:0') tensor(1.1946, device='cuda:0') tensor(-1.2554e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.134270
Average KL loss: 0.323304
Average total loss: 0.457573
tensor(-13.8732, device='cuda:0') tensor(1.1949, device='cuda:0') tensor(-1.0403e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.133355
Average KL loss: 0.323288
Average total loss: 0.456643
tensor(-13.8736, device='cuda:0') tensor(1.1952, device='cuda:0') tensor(-1.4643e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.133826
Average KL loss: 0.323275
Average total loss: 0.457101
tensor(-13.8740, device='cuda:0') tensor(1.1956, device='cuda:0') tensor(8.7469e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.133824
Average KL loss: 0.323261
Average total loss: 0.457086
tensor(-13.8744, device='cuda:0') tensor(1.1959, device='cuda:0') tensor(-1.3926e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.133459
Average KL loss: 0.323253
Average total loss: 0.456711
tensor(-13.8749, device='cuda:0') tensor(1.1962, device='cuda:0') tensor(9.8049e-12, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.133834
Average KL loss: 0.323237
Average total loss: 0.457072
tensor(-13.8753, device='cuda:0') tensor(1.1966, device='cuda:0') tensor(1.0836e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.135299
Average KL loss: 0.323219
Average total loss: 0.458519
tensor(-13.8757, device='cuda:0') tensor(1.1969, device='cuda:0') tensor(-6.9181e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.133528
Average KL loss: 0.323211
Average total loss: 0.456739
tensor(-13.8762, device='cuda:0') tensor(1.1972, device='cuda:0') tensor(-1.4723e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.133134
Average KL loss: 0.323196
Average total loss: 0.456329
tensor(-13.8766, device='cuda:0') tensor(1.1976, device='cuda:0') tensor(-5.8841e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.131291
Average KL loss: 0.323178
Average total loss: 0.454470
tensor(-13.8770, device='cuda:0') tensor(1.1979, device='cuda:0') tensor(7.6339e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.132164
Average KL loss: 0.323171
Average total loss: 0.455335
tensor(-13.8774, device='cuda:0') tensor(1.1983, device='cuda:0') tensor(1.0037e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.131939
Average KL loss: 0.323161
Average total loss: 0.455100
tensor(-13.8779, device='cuda:0') tensor(1.1987, device='cuda:0') tensor(-6.1201e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.129628
Average KL loss: 0.323149
Average total loss: 0.452777
tensor(-13.8783, device='cuda:0') tensor(1.1990, device='cuda:0') tensor(-8.4526e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.134436
Average KL loss: 0.323140
Average total loss: 0.457575
tensor(-13.8787, device='cuda:0') tensor(1.1993, device='cuda:0') tensor(-2.9352e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.134948
Average KL loss: 0.323126
Average total loss: 0.458074
tensor(-13.8791, device='cuda:0') tensor(1.1997, device='cuda:0') tensor(-2.0510e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.133819
Average KL loss: 0.323106
Average total loss: 0.456925
tensor(-13.8795, device='cuda:0') tensor(1.2001, device='cuda:0') tensor(-1.0031e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.130428
Average KL loss: 0.323084
Average total loss: 0.453512
tensor(-13.8800, device='cuda:0') tensor(1.2003, device='cuda:0') tensor(-8.9687e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.131943
Average KL loss: 0.323061
Average total loss: 0.455004
tensor(-13.8804, device='cuda:0') tensor(1.2006, device='cuda:0') tensor(-1.3894e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.131793
Average KL loss: 0.323046
Average total loss: 0.454839
tensor(-13.8808, device='cuda:0') tensor(1.2010, device='cuda:0') tensor(-1.0634e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.132929
Average KL loss: 0.323027
Average total loss: 0.455956
tensor(-13.8812, device='cuda:0') tensor(1.2013, device='cuda:0') tensor(7.6379e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.131990
Average KL loss: 0.323011
Average total loss: 0.455001
tensor(-13.8817, device='cuda:0') tensor(1.2017, device='cuda:0') tensor(-1.5954e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.131829
Average KL loss: 0.323005
Average total loss: 0.454835
tensor(-13.8821, device='cuda:0') tensor(1.2021, device='cuda:0') tensor(-1.5610e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.130149
Average KL loss: 0.322991
Average total loss: 0.453140
tensor(-13.8825, device='cuda:0') tensor(1.2024, device='cuda:0') tensor(-9.5675e-11, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.131562
Average KL loss: 0.322970
Average total loss: 0.454532
tensor(-13.8829, device='cuda:0') tensor(1.2027, device='cuda:0') tensor(-1.8955e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.129905
Average KL loss: 0.322962
Average total loss: 0.452867
tensor(-13.8830, device='cuda:0') tensor(1.2027, device='cuda:0') tensor(8.3473e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.129239
Average KL loss: 0.322961
Average total loss: 0.452200
tensor(-13.8830, device='cuda:0') tensor(1.2028, device='cuda:0') tensor(6.2070e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.131254
Average KL loss: 0.322960
Average total loss: 0.454214
tensor(-13.8831, device='cuda:0') tensor(1.2028, device='cuda:0') tensor(-1.3887e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.129700
Average KL loss: 0.322958
Average total loss: 0.452658
tensor(-13.8831, device='cuda:0') tensor(1.2028, device='cuda:0') tensor(8.1789e-11, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.129041
Average KL loss: 0.322956
Average total loss: 0.451997
tensor(-13.8832, device='cuda:0') tensor(1.2029, device='cuda:0') tensor(-2.1530e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.130812
Average KL loss: 0.322955
Average total loss: 0.453767
tensor(-13.8832, device='cuda:0') tensor(1.2029, device='cuda:0') tensor(2.7588e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.132037
Average KL loss: 0.322953
Average total loss: 0.454990
tensor(-13.8833, device='cuda:0') tensor(1.2029, device='cuda:0') tensor(-7.0200e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.132221
Average KL loss: 0.322952
Average total loss: 0.455173
tensor(-13.8833, device='cuda:0') tensor(1.2030, device='cuda:0') tensor(-1.2233e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.129331
Average KL loss: 0.322951
Average total loss: 0.452281
tensor(-13.8834, device='cuda:0') tensor(1.2030, device='cuda:0') tensor(-9.7398e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.130675
Average KL loss: 0.322949
Average total loss: 0.453624
tensor(-13.8834, device='cuda:0') tensor(1.2030, device='cuda:0') tensor(-1.2006e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.129587
Average KL loss: 0.322948
Average total loss: 0.452535
tensor(-13.8834, device='cuda:0') tensor(1.2031, device='cuda:0') tensor(-1.0195e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.130216
Average KL loss: 0.322947
Average total loss: 0.453163
tensor(-13.8835, device='cuda:0') tensor(1.2031, device='cuda:0') tensor(4.8931e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.131015
Average KL loss: 0.322945
Average total loss: 0.453960
tensor(-13.8835, device='cuda:0') tensor(1.2031, device='cuda:0') tensor(-7.1330e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.129178
Average KL loss: 0.322944
Average total loss: 0.452122
tensor(-13.8836, device='cuda:0') tensor(1.2032, device='cuda:0') tensor(1.4008e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.130030
Average KL loss: 0.322943
Average total loss: 0.452972
tensor(-13.8836, device='cuda:0') tensor(1.2032, device='cuda:0') tensor(-3.0204e-11, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.129197
Average KL loss: 0.322941
Average total loss: 0.452138
tensor(-13.8837, device='cuda:0') tensor(1.2032, device='cuda:0') tensor(1.0422e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.131674
Average KL loss: 0.322941
Average total loss: 0.454615
tensor(-13.8837, device='cuda:0') tensor(1.2032, device='cuda:0') tensor(-9.7427e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.130149
Average KL loss: 0.322941
Average total loss: 0.453090
tensor(-13.8837, device='cuda:0') tensor(1.2032, device='cuda:0') tensor(-7.2653e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.130796
Average KL loss: 0.322941
Average total loss: 0.453737
tensor(-13.8837, device='cuda:0') tensor(1.2032, device='cuda:0') tensor(-1.8421e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.130573
Average KL loss: 0.322941
Average total loss: 0.453514
tensor(-13.8837, device='cuda:0') tensor(1.2032, device='cuda:0') tensor(-1.1699e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.130770
Average KL loss: 0.322940
Average total loss: 0.453711
tensor(-13.8837, device='cuda:0') tensor(1.2033, device='cuda:0') tensor(-6.7967e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.128908
Average KL loss: 0.322940
Average total loss: 0.451848
tensor(-13.8837, device='cuda:0') tensor(1.2033, device='cuda:0') tensor(-1.6540e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.130993
Average KL loss: 0.322940
Average total loss: 0.453933
tensor(-13.8837, device='cuda:0') tensor(1.2033, device='cuda:0') tensor(-2.0482e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.130870
Average KL loss: 0.322940
Average total loss: 0.453810
 Percentile value: -13.52331256866455
Non-zero model percentage: 3.5184483528137207%, Non-zero mask percentage: 3.5184483528137207%

--- Pruning Level [15/24]: ---
conv1.weight         | nonzeros =    1288 /    1728             ( 74.54%) | total_pruned =     440 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    7883 /   36864             ( 21.38%) | total_pruned =   28981 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    8146 /   36864             ( 22.10%) | total_pruned =   28718 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    7063 /   36864             ( 19.16%) | total_pruned =   29801 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    6797 /   36864             ( 18.44%) | total_pruned =   30067 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   14292 /   73728             ( 19.38%) | total_pruned =   59436 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   22775 /  147456             ( 15.45%) | total_pruned =  124681 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3274 /    8192             ( 39.97%) | total_pruned =    4918 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   16521 /  147456             ( 11.20%) | total_pruned =  130935 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   16301 /  147456             ( 11.05%) | total_pruned =  131155 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   35226 /  294912             ( 11.94%) | total_pruned =  259686 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     176 /     256             ( 68.75%) | total_pruned =      80 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   50259 /  589824             (  8.52%) | total_pruned =  539565 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     172 /     256             ( 67.19%) | total_pruned =      84 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    7737 /   32768             ( 23.61%) | total_pruned =   25031 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     170 /     256             ( 66.41%) | total_pruned =      86 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   22466 /  589824             (  3.81%) | total_pruned =  567358 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      89 /     256             ( 34.77%) | total_pruned =     167 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   23191 /  589824             (  3.93%) | total_pruned =  566633 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     217 /     256             ( 84.77%) | total_pruned =      39 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     146 /     256             ( 57.03%) | total_pruned =     110 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   46727 / 1179648             (  3.96%) | total_pruned = 1132921 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     287 /     512             ( 56.05%) | total_pruned =     225 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     222 /     512             ( 43.36%) | total_pruned =     290 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   42920 / 2359296             (  1.82%) | total_pruned = 2316376 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     352 /     512             ( 68.75%) | total_pruned =     160 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     319 /     512             ( 62.30%) | total_pruned =     193 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    9017 /  131072             (  6.88%) | total_pruned =  122055 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     274 /     512             ( 53.52%) | total_pruned =     238 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     320 /     512             ( 62.50%) | total_pruned =     192 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   19747 / 2359296             (  0.84%) | total_pruned = 2339549 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     134 /     512             ( 26.17%) | total_pruned =     378 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      54 /     512             ( 10.55%) | total_pruned =     458 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   22324 / 2359296             (  0.95%) | total_pruned = 2336972 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     276 /     512             ( 53.91%) | total_pruned =     236 | shape = torch.Size([512])
linear.weight        | nonzeros =    3442 /    5120             ( 67.23%) | total_pruned =    1678 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 393319, pruned : 10785443, total: 11178762, Compression rate :      28.42x  ( 96.48% pruned)
Train Epoch: 21/100 Loss: 0.000202 Accuracy: 85.79 99.98 % Best test Accuracy: 86.58%
tensor(-13.8837, device='cuda:0') tensor(1.2033, device='cuda:0') tensor(-1.9232e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.231226
Average KL loss: 0.322670
Average total loss: 0.553896
tensor(-13.8848, device='cuda:0') tensor(1.1793, device='cuda:0') tensor(1.5493e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.226447
Average KL loss: 0.322438
Average total loss: 0.548885
tensor(-13.8855, device='cuda:0') tensor(1.1656, device='cuda:0') tensor(-6.8795e-11, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.228809
Average KL loss: 0.322307
Average total loss: 0.551116
tensor(-13.8862, device='cuda:0') tensor(1.1568, device='cuda:0') tensor(-1.6770e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.229571
Average KL loss: 0.322220
Average total loss: 0.551791
tensor(-13.8868, device='cuda:0') tensor(1.1512, device='cuda:0') tensor(-1.4655e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.225804
Average KL loss: 0.322161
Average total loss: 0.547965
tensor(-13.8873, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(-3.4060e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.223387
Average KL loss: 0.322114
Average total loss: 0.545502
tensor(-13.8878, device='cuda:0') tensor(1.1450, device='cuda:0') tensor(-1.2191e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.221192
Average KL loss: 0.322075
Average total loss: 0.543267
tensor(-13.8883, device='cuda:0') tensor(1.1434, device='cuda:0') tensor(-1.9908e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.218141
Average KL loss: 0.322036
Average total loss: 0.540177
tensor(-13.8888, device='cuda:0') tensor(1.1422, device='cuda:0') tensor(-2.6773e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.217897
Average KL loss: 0.322011
Average total loss: 0.539908
tensor(-13.8892, device='cuda:0') tensor(1.1417, device='cuda:0') tensor(-7.2958e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.220289
Average KL loss: 0.321985
Average total loss: 0.542274
tensor(-13.8897, device='cuda:0') tensor(1.1412, device='cuda:0') tensor(-3.9307e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.219511
Average KL loss: 0.321959
Average total loss: 0.541470
tensor(-13.8901, device='cuda:0') tensor(1.1410, device='cuda:0') tensor(-1.9243e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.217045
Average KL loss: 0.321932
Average total loss: 0.538977
tensor(-13.8905, device='cuda:0') tensor(1.1409, device='cuda:0') tensor(-1.2798e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.214326
Average KL loss: 0.321903
Average total loss: 0.536228
tensor(-13.8910, device='cuda:0') tensor(1.1409, device='cuda:0') tensor(-3.1778e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.213455
Average KL loss: 0.321880
Average total loss: 0.535334
tensor(-13.8914, device='cuda:0') tensor(1.1409, device='cuda:0') tensor(-9.0657e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.214504
Average KL loss: 0.321860
Average total loss: 0.536364
tensor(-13.8918, device='cuda:0') tensor(1.1410, device='cuda:0') tensor(-1.7003e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.208565
Average KL loss: 0.321830
Average total loss: 0.530395
tensor(-13.8923, device='cuda:0') tensor(1.1412, device='cuda:0') tensor(-2.1757e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.209563
Average KL loss: 0.321808
Average total loss: 0.531371
tensor(-13.8927, device='cuda:0') tensor(1.1414, device='cuda:0') tensor(-2.1025e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.209280
Average KL loss: 0.321779
Average total loss: 0.531058
tensor(-13.8931, device='cuda:0') tensor(1.1415, device='cuda:0') tensor(-2.4019e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.211348
Average KL loss: 0.321756
Average total loss: 0.533104
tensor(-13.8935, device='cuda:0') tensor(1.1417, device='cuda:0') tensor(-4.1113e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.205434
Average KL loss: 0.321726
Average total loss: 0.527160
tensor(-13.8940, device='cuda:0') tensor(1.1419, device='cuda:0') tensor(-5.7728e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.202654
Average KL loss: 0.321701
Average total loss: 0.524355
tensor(-13.8944, device='cuda:0') tensor(1.1422, device='cuda:0') tensor(-3.6225e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.205647
Average KL loss: 0.321680
Average total loss: 0.527328
tensor(-13.8948, device='cuda:0') tensor(1.1425, device='cuda:0') tensor(-1.4299e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.204688
Average KL loss: 0.321657
Average total loss: 0.526345
tensor(-13.8952, device='cuda:0') tensor(1.1428, device='cuda:0') tensor(2.2267e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.205775
Average KL loss: 0.321636
Average total loss: 0.527411
tensor(-13.8957, device='cuda:0') tensor(1.1431, device='cuda:0') tensor(-6.8889e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.202708
Average KL loss: 0.321615
Average total loss: 0.524323
tensor(-13.8961, device='cuda:0') tensor(1.1434, device='cuda:0') tensor(1.4287e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.201832
Average KL loss: 0.321591
Average total loss: 0.523423
tensor(-13.8965, device='cuda:0') tensor(1.1437, device='cuda:0') tensor(-1.5345e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.200582
Average KL loss: 0.321576
Average total loss: 0.522158
tensor(-13.8969, device='cuda:0') tensor(1.1440, device='cuda:0') tensor(-3.1054e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.200363
Average KL loss: 0.321564
Average total loss: 0.521926
tensor(-13.8973, device='cuda:0') tensor(1.1443, device='cuda:0') tensor(-2.4118e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.199951
Average KL loss: 0.321549
Average total loss: 0.521499
tensor(-13.8978, device='cuda:0') tensor(1.1446, device='cuda:0') tensor(9.2600e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.198945
Average KL loss: 0.321531
Average total loss: 0.520476
tensor(-13.8982, device='cuda:0') tensor(1.1450, device='cuda:0') tensor(-1.6550e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.195332
Average KL loss: 0.321515
Average total loss: 0.516847
tensor(-13.8986, device='cuda:0') tensor(1.1453, device='cuda:0') tensor(-1.2160e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.194794
Average KL loss: 0.321493
Average total loss: 0.516287
tensor(-13.8990, device='cuda:0') tensor(1.1456, device='cuda:0') tensor(-8.1347e-11, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.195428
Average KL loss: 0.321472
Average total loss: 0.516900
tensor(-13.8994, device='cuda:0') tensor(1.1459, device='cuda:0') tensor(-2.3290e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.195738
Average KL loss: 0.321449
Average total loss: 0.517188
tensor(-13.8999, device='cuda:0') tensor(1.1463, device='cuda:0') tensor(-1.4436e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.192905
Average KL loss: 0.321430
Average total loss: 0.514334
tensor(-13.9003, device='cuda:0') tensor(1.1466, device='cuda:0') tensor(-1.7611e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.194565
Average KL loss: 0.321406
Average total loss: 0.515971
tensor(-13.9007, device='cuda:0') tensor(1.1469, device='cuda:0') tensor(-5.7920e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.192130
Average KL loss: 0.321382
Average total loss: 0.513512
tensor(-13.9011, device='cuda:0') tensor(1.1472, device='cuda:0') tensor(-3.5237e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.192825
Average KL loss: 0.321369
Average total loss: 0.514193
tensor(-13.9015, device='cuda:0') tensor(1.1476, device='cuda:0') tensor(-3.8320e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.187442
Average KL loss: 0.321355
Average total loss: 0.508797
tensor(-13.9019, device='cuda:0') tensor(1.1479, device='cuda:0') tensor(-3.2897e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.190732
Average KL loss: 0.321333
Average total loss: 0.512066
tensor(-13.9024, device='cuda:0') tensor(1.1482, device='cuda:0') tensor(5.9996e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.193845
Average KL loss: 0.321316
Average total loss: 0.515160
tensor(-13.9028, device='cuda:0') tensor(1.1486, device='cuda:0') tensor(-3.9805e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.186184
Average KL loss: 0.321300
Average total loss: 0.507484
tensor(-13.9032, device='cuda:0') tensor(1.1489, device='cuda:0') tensor(-1.8135e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.186061
Average KL loss: 0.321287
Average total loss: 0.507348
tensor(-13.9036, device='cuda:0') tensor(1.1492, device='cuda:0') tensor(-1.7872e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.188523
Average KL loss: 0.321272
Average total loss: 0.509795
tensor(-13.9040, device='cuda:0') tensor(1.1496, device='cuda:0') tensor(-3.0064e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.190858
Average KL loss: 0.321253
Average total loss: 0.512111
tensor(-13.9044, device='cuda:0') tensor(1.1499, device='cuda:0') tensor(-2.6750e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.188132
Average KL loss: 0.321237
Average total loss: 0.509369
tensor(-13.9049, device='cuda:0') tensor(1.1503, device='cuda:0') tensor(-3.6821e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.187924
Average KL loss: 0.321221
Average total loss: 0.509146
tensor(-13.9053, device='cuda:0') tensor(1.1506, device='cuda:0') tensor(-1.7287e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.185127
Average KL loss: 0.321195
Average total loss: 0.506322
tensor(-13.9057, device='cuda:0') tensor(1.1509, device='cuda:0') tensor(-3.7531e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.186636
Average KL loss: 0.321176
Average total loss: 0.507812
tensor(-13.9061, device='cuda:0') tensor(1.1513, device='cuda:0') tensor(-1.8565e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.185273
Average KL loss: 0.321155
Average total loss: 0.506428
tensor(-13.9065, device='cuda:0') tensor(1.1516, device='cuda:0') tensor(-2.9312e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.187076
Average KL loss: 0.321134
Average total loss: 0.508210
tensor(-13.9069, device='cuda:0') tensor(1.1519, device='cuda:0') tensor(-6.0306e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.185503
Average KL loss: 0.321108
Average total loss: 0.506611
tensor(-13.9074, device='cuda:0') tensor(1.1522, device='cuda:0') tensor(1.7889e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.183370
Average KL loss: 0.321086
Average total loss: 0.504457
tensor(-13.9078, device='cuda:0') tensor(1.1525, device='cuda:0') tensor(-3.9662e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.181939
Average KL loss: 0.321066
Average total loss: 0.503005
tensor(-13.9082, device='cuda:0') tensor(1.1528, device='cuda:0') tensor(-7.7131e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.180207
Average KL loss: 0.321042
Average total loss: 0.501249
tensor(-13.9086, device='cuda:0') tensor(1.1531, device='cuda:0') tensor(-1.9902e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.178796
Average KL loss: 0.321013
Average total loss: 0.499810
tensor(-13.9090, device='cuda:0') tensor(1.1534, device='cuda:0') tensor(-7.5161e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.182131
Average KL loss: 0.320989
Average total loss: 0.503119
tensor(-13.9094, device='cuda:0') tensor(1.1537, device='cuda:0') tensor(-4.7532e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.178434
Average KL loss: 0.320968
Average total loss: 0.499401
tensor(-13.9099, device='cuda:0') tensor(1.1541, device='cuda:0') tensor(-4.5434e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.178971
Average KL loss: 0.320945
Average total loss: 0.499916
tensor(-13.9103, device='cuda:0') tensor(1.1544, device='cuda:0') tensor(-1.3449e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.178267
Average KL loss: 0.320918
Average total loss: 0.499185
tensor(-13.9107, device='cuda:0') tensor(1.1547, device='cuda:0') tensor(-2.1292e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.180485
Average KL loss: 0.320901
Average total loss: 0.501385
tensor(-13.9111, device='cuda:0') tensor(1.1551, device='cuda:0') tensor(-3.0230e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.180703
Average KL loss: 0.320880
Average total loss: 0.501582
tensor(-13.9115, device='cuda:0') tensor(1.1554, device='cuda:0') tensor(-2.0532e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.173988
Average KL loss: 0.320858
Average total loss: 0.494846
tensor(-13.9119, device='cuda:0') tensor(1.1557, device='cuda:0') tensor(1.0539e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.178337
Average KL loss: 0.320833
Average total loss: 0.499170
tensor(-13.9123, device='cuda:0') tensor(1.1560, device='cuda:0') tensor(-1.9115e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.175501
Average KL loss: 0.320812
Average total loss: 0.496314
tensor(-13.9127, device='cuda:0') tensor(1.1564, device='cuda:0') tensor(4.8503e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.176926
Average KL loss: 0.320792
Average total loss: 0.497718
tensor(-13.9132, device='cuda:0') tensor(1.1567, device='cuda:0') tensor(-1.0967e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.173525
Average KL loss: 0.320773
Average total loss: 0.494298
tensor(-13.9136, device='cuda:0') tensor(1.1571, device='cuda:0') tensor(-1.4354e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.177736
Average KL loss: 0.320754
Average total loss: 0.498491
tensor(-13.9140, device='cuda:0') tensor(1.1574, device='cuda:0') tensor(1.3900e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.177325
Average KL loss: 0.320734
Average total loss: 0.498060
tensor(-13.9144, device='cuda:0') tensor(1.1577, device='cuda:0') tensor(-1.1363e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.174599
Average KL loss: 0.320716
Average total loss: 0.495314
tensor(-13.9148, device='cuda:0') tensor(1.1581, device='cuda:0') tensor(-4.5165e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.174192
Average KL loss: 0.320701
Average total loss: 0.494893
tensor(-13.9152, device='cuda:0') tensor(1.1584, device='cuda:0') tensor(-2.7351e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.173874
Average KL loss: 0.320681
Average total loss: 0.494555
tensor(-13.9156, device='cuda:0') tensor(1.1588, device='cuda:0') tensor(-1.9299e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.169494
Average KL loss: 0.320661
Average total loss: 0.490155
tensor(-13.9160, device='cuda:0') tensor(1.1591, device='cuda:0') tensor(-4.4220e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.171638
Average KL loss: 0.320644
Average total loss: 0.492283
tensor(-13.9165, device='cuda:0') tensor(1.1594, device='cuda:0') tensor(-8.1039e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.172554
Average KL loss: 0.320624
Average total loss: 0.493177
tensor(-13.9169, device='cuda:0') tensor(1.1597, device='cuda:0') tensor(-4.6950e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.173485
Average KL loss: 0.320596
Average total loss: 0.494080
tensor(-13.9173, device='cuda:0') tensor(1.1601, device='cuda:0') tensor(-1.2597e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.172852
Average KL loss: 0.320572
Average total loss: 0.493424
tensor(-13.9177, device='cuda:0') tensor(1.1604, device='cuda:0') tensor(-2.3494e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.174272
Average KL loss: 0.320554
Average total loss: 0.494826
tensor(-13.9181, device='cuda:0') tensor(1.1607, device='cuda:0') tensor(1.0946e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.170416
Average KL loss: 0.320529
Average total loss: 0.490945
tensor(-13.9185, device='cuda:0') tensor(1.1610, device='cuda:0') tensor(-1.2468e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.169578
Average KL loss: 0.320507
Average total loss: 0.490085
tensor(-13.9189, device='cuda:0') tensor(1.1613, device='cuda:0') tensor(-1.3329e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.172833
Average KL loss: 0.320486
Average total loss: 0.493320
tensor(-13.9193, device='cuda:0') tensor(1.1617, device='cuda:0') tensor(-6.5110e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.170780
Average KL loss: 0.320467
Average total loss: 0.491248
tensor(-13.9197, device='cuda:0') tensor(1.1621, device='cuda:0') tensor(-2.8737e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.169784
Average KL loss: 0.320445
Average total loss: 0.490229
tensor(-13.9202, device='cuda:0') tensor(1.1623, device='cuda:0') tensor(-2.4408e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.169285
Average KL loss: 0.320426
Average total loss: 0.489711
tensor(-13.9206, device='cuda:0') tensor(1.1627, device='cuda:0') tensor(-2.5715e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.168043
Average KL loss: 0.320409
Average total loss: 0.488451
tensor(-13.9210, device='cuda:0') tensor(1.1630, device='cuda:0') tensor(-1.2458e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.169177
Average KL loss: 0.320389
Average total loss: 0.489566
tensor(-13.9214, device='cuda:0') tensor(1.1634, device='cuda:0') tensor(-3.6015e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.167763
Average KL loss: 0.320371
Average total loss: 0.488134
tensor(-13.9218, device='cuda:0') tensor(1.1637, device='cuda:0') tensor(-3.2334e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.168824
Average KL loss: 0.320349
Average total loss: 0.489174
tensor(-13.9222, device='cuda:0') tensor(1.1641, device='cuda:0') tensor(-7.5879e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.167926
Average KL loss: 0.320326
Average total loss: 0.488252
tensor(-13.9226, device='cuda:0') tensor(1.1644, device='cuda:0') tensor(-1.9488e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.169103
Average KL loss: 0.320303
Average total loss: 0.489406
tensor(-13.9230, device='cuda:0') tensor(1.1648, device='cuda:0') tensor(-3.6683e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.168506
Average KL loss: 0.320285
Average total loss: 0.488791
tensor(-13.9234, device='cuda:0') tensor(1.1651, device='cuda:0') tensor(-2.6388e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.169064
Average KL loss: 0.320269
Average total loss: 0.489334
tensor(-13.9238, device='cuda:0') tensor(1.1655, device='cuda:0') tensor(-1.5538e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.167834
Average KL loss: 0.320255
Average total loss: 0.488089
tensor(-13.9243, device='cuda:0') tensor(1.1659, device='cuda:0') tensor(-9.9277e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.168191
Average KL loss: 0.320236
Average total loss: 0.488427
tensor(-13.9247, device='cuda:0') tensor(1.1663, device='cuda:0') tensor(-6.0523e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.167043
Average KL loss: 0.320216
Average total loss: 0.487259
tensor(-13.9251, device='cuda:0') tensor(1.1667, device='cuda:0') tensor(-3.6910e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.167352
Average KL loss: 0.320204
Average total loss: 0.487556
tensor(-13.9255, device='cuda:0') tensor(1.1671, device='cuda:0') tensor(-2.5195e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.163983
Average KL loss: 0.320179
Average total loss: 0.484162
tensor(-13.9259, device='cuda:0') tensor(1.1674, device='cuda:0') tensor(-1.7909e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.163166
Average KL loss: 0.320160
Average total loss: 0.483326
tensor(-13.9263, device='cuda:0') tensor(1.1678, device='cuda:0') tensor(-1.5064e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.167810
Average KL loss: 0.320143
Average total loss: 0.487953
tensor(-13.9267, device='cuda:0') tensor(1.1681, device='cuda:0') tensor(-1.9790e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.163355
Average KL loss: 0.320128
Average total loss: 0.483483
tensor(-13.9271, device='cuda:0') tensor(1.1684, device='cuda:0') tensor(-2.1407e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.162246
Average KL loss: 0.320109
Average total loss: 0.482355
tensor(-13.9275, device='cuda:0') tensor(1.1688, device='cuda:0') tensor(2.4671e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.161835
Average KL loss: 0.320090
Average total loss: 0.481924
tensor(-13.9279, device='cuda:0') tensor(1.1692, device='cuda:0') tensor(-2.7890e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.163588
Average KL loss: 0.320065
Average total loss: 0.483653
tensor(-13.9283, device='cuda:0') tensor(1.1695, device='cuda:0') tensor(4.0002e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.161308
Average KL loss: 0.320044
Average total loss: 0.481353
tensor(-13.9287, device='cuda:0') tensor(1.1698, device='cuda:0') tensor(-1.3165e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.162635
Average KL loss: 0.320028
Average total loss: 0.482664
tensor(-13.9291, device='cuda:0') tensor(1.1701, device='cuda:0') tensor(-2.2965e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.159991
Average KL loss: 0.320013
Average total loss: 0.480004
tensor(-13.9296, device='cuda:0') tensor(1.1705, device='cuda:0') tensor(-6.7840e-11, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.162344
Average KL loss: 0.320005
Average total loss: 0.482349
tensor(-13.9300, device='cuda:0') tensor(1.1709, device='cuda:0') tensor(-1.7273e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.160254
Average KL loss: 0.319993
Average total loss: 0.480247
tensor(-13.9304, device='cuda:0') tensor(1.1712, device='cuda:0') tensor(-2.8785e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.159720
Average KL loss: 0.319976
Average total loss: 0.479696
tensor(-13.9308, device='cuda:0') tensor(1.1715, device='cuda:0') tensor(-2.7373e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.165784
Average KL loss: 0.319956
Average total loss: 0.485740
tensor(-13.9312, device='cuda:0') tensor(1.1719, device='cuda:0') tensor(-3.7437e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.161304
Average KL loss: 0.319932
Average total loss: 0.481236
tensor(-13.9316, device='cuda:0') tensor(1.1722, device='cuda:0') tensor(-4.4697e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.159666
Average KL loss: 0.319910
Average total loss: 0.479575
tensor(-13.9320, device='cuda:0') tensor(1.1725, device='cuda:0') tensor(-1.5180e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.161988
Average KL loss: 0.319898
Average total loss: 0.481885
tensor(-13.9324, device='cuda:0') tensor(1.1729, device='cuda:0') tensor(-1.0805e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.160187
Average KL loss: 0.319879
Average total loss: 0.480066
tensor(-13.9328, device='cuda:0') tensor(1.1732, device='cuda:0') tensor(-2.2893e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.156243
Average KL loss: 0.319860
Average total loss: 0.476102
tensor(-13.9332, device='cuda:0') tensor(1.1735, device='cuda:0') tensor(-1.6272e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.160287
Average KL loss: 0.319841
Average total loss: 0.480128
tensor(-13.9336, device='cuda:0') tensor(1.1738, device='cuda:0') tensor(-9.1683e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.157533
Average KL loss: 0.319820
Average total loss: 0.477354
tensor(-13.9340, device='cuda:0') tensor(1.1741, device='cuda:0') tensor(-1.8475e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.158555
Average KL loss: 0.319801
Average total loss: 0.478356
tensor(-13.9344, device='cuda:0') tensor(1.1745, device='cuda:0') tensor(-1.5986e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.158012
Average KL loss: 0.319781
Average total loss: 0.477794
tensor(-13.9348, device='cuda:0') tensor(1.1748, device='cuda:0') tensor(-2.9946e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.158186
Average KL loss: 0.319769
Average total loss: 0.477954
tensor(-13.9352, device='cuda:0') tensor(1.1752, device='cuda:0') tensor(1.1744e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.156907
Average KL loss: 0.319751
Average total loss: 0.476658
tensor(-13.9356, device='cuda:0') tensor(1.1755, device='cuda:0') tensor(1.4791e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.156588
Average KL loss: 0.319732
Average total loss: 0.476321
tensor(-13.9360, device='cuda:0') tensor(1.1759, device='cuda:0') tensor(-2.1462e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.157397
Average KL loss: 0.319719
Average total loss: 0.477116
tensor(-13.9364, device='cuda:0') tensor(1.1762, device='cuda:0') tensor(-1.4471e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.158560
Average KL loss: 0.319706
Average total loss: 0.478266
tensor(-13.9369, device='cuda:0') tensor(1.1765, device='cuda:0') tensor(1.1716e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.159716
Average KL loss: 0.319686
Average total loss: 0.479402
tensor(-13.9373, device='cuda:0') tensor(1.1770, device='cuda:0') tensor(-5.9624e-11, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.155520
Average KL loss: 0.319673
Average total loss: 0.475193
tensor(-13.9377, device='cuda:0') tensor(1.1773, device='cuda:0') tensor(-1.0744e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.155992
Average KL loss: 0.319658
Average total loss: 0.475650
tensor(-13.9381, device='cuda:0') tensor(1.1777, device='cuda:0') tensor(3.2778e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.155242
Average KL loss: 0.319640
Average total loss: 0.474883
tensor(-13.9385, device='cuda:0') tensor(1.1780, device='cuda:0') tensor(-3.4417e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.154935
Average KL loss: 0.319624
Average total loss: 0.474559
tensor(-13.9389, device='cuda:0') tensor(1.1784, device='cuda:0') tensor(-4.7181e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.155379
Average KL loss: 0.319609
Average total loss: 0.474988
tensor(-13.9393, device='cuda:0') tensor(1.1787, device='cuda:0') tensor(-2.4061e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.154175
Average KL loss: 0.319596
Average total loss: 0.473771
tensor(-13.9397, device='cuda:0') tensor(1.1791, device='cuda:0') tensor(-1.0137e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.153018
Average KL loss: 0.319577
Average total loss: 0.472595
tensor(-13.9401, device='cuda:0') tensor(1.1794, device='cuda:0') tensor(-2.4890e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.157276
Average KL loss: 0.319554
Average total loss: 0.476830
tensor(-13.9405, device='cuda:0') tensor(1.1797, device='cuda:0') tensor(-8.8674e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.153509
Average KL loss: 0.319534
Average total loss: 0.473043
tensor(-13.9409, device='cuda:0') tensor(1.1800, device='cuda:0') tensor(6.9095e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.155157
Average KL loss: 0.319520
Average total loss: 0.474677
tensor(-13.9413, device='cuda:0') tensor(1.1804, device='cuda:0') tensor(-7.6669e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.156771
Average KL loss: 0.319505
Average total loss: 0.476276
tensor(-13.9417, device='cuda:0') tensor(1.1807, device='cuda:0') tensor(-1.4162e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.155169
Average KL loss: 0.319495
Average total loss: 0.474664
tensor(-13.9421, device='cuda:0') tensor(1.1810, device='cuda:0') tensor(-1.5254e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.153756
Average KL loss: 0.319480
Average total loss: 0.473236
tensor(-13.9425, device='cuda:0') tensor(1.1813, device='cuda:0') tensor(9.7174e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.154557
Average KL loss: 0.319459
Average total loss: 0.474016
tensor(-13.9429, device='cuda:0') tensor(1.1816, device='cuda:0') tensor(-2.9389e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.154017
Average KL loss: 0.319438
Average total loss: 0.473455
tensor(-13.9433, device='cuda:0') tensor(1.1819, device='cuda:0') tensor(5.9620e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.153632
Average KL loss: 0.319417
Average total loss: 0.473050
tensor(-13.9437, device='cuda:0') tensor(1.1823, device='cuda:0') tensor(-2.6581e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.150441
Average KL loss: 0.319396
Average total loss: 0.469837
tensor(-13.9441, device='cuda:0') tensor(1.1826, device='cuda:0') tensor(-1.4704e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.150684
Average KL loss: 0.319376
Average total loss: 0.470060
tensor(-13.9445, device='cuda:0') tensor(1.1830, device='cuda:0') tensor(-1.5222e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.152024
Average KL loss: 0.319356
Average total loss: 0.471380
tensor(-13.9449, device='cuda:0') tensor(1.1833, device='cuda:0') tensor(1.1497e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.151708
Average KL loss: 0.319341
Average total loss: 0.471049
tensor(-13.9453, device='cuda:0') tensor(1.1835, device='cuda:0') tensor(-2.2865e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.152772
Average KL loss: 0.319326
Average total loss: 0.472098
tensor(-13.9457, device='cuda:0') tensor(1.1839, device='cuda:0') tensor(9.4005e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.150621
Average KL loss: 0.319309
Average total loss: 0.469930
tensor(-13.9461, device='cuda:0') tensor(1.1842, device='cuda:0') tensor(-1.5001e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.151600
Average KL loss: 0.319298
Average total loss: 0.470898
tensor(-13.9465, device='cuda:0') tensor(1.1845, device='cuda:0') tensor(-1.0056e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.151980
Average KL loss: 0.319281
Average total loss: 0.471260
tensor(-13.9469, device='cuda:0') tensor(1.1849, device='cuda:0') tensor(7.6789e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.150065
Average KL loss: 0.319264
Average total loss: 0.469328
tensor(-13.9473, device='cuda:0') tensor(1.1852, device='cuda:0') tensor(5.2234e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.153266
Average KL loss: 0.319245
Average total loss: 0.472511
tensor(-13.9477, device='cuda:0') tensor(1.1855, device='cuda:0') tensor(-5.8018e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.151200
Average KL loss: 0.319228
Average total loss: 0.470428
tensor(-13.9481, device='cuda:0') tensor(1.1858, device='cuda:0') tensor(-1.9963e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.150627
Average KL loss: 0.319214
Average total loss: 0.469841
tensor(-13.9485, device='cuda:0') tensor(1.1862, device='cuda:0') tensor(-5.7691e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.147581
Average KL loss: 0.319199
Average total loss: 0.466779
tensor(-13.9489, device='cuda:0') tensor(1.1865, device='cuda:0') tensor(-1.4169e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.152618
Average KL loss: 0.319182
Average total loss: 0.471800
tensor(-13.9493, device='cuda:0') tensor(1.1868, device='cuda:0') tensor(-2.6816e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.151970
Average KL loss: 0.319169
Average total loss: 0.471139
tensor(-13.9497, device='cuda:0') tensor(1.1872, device='cuda:0') tensor(7.8307e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.151102
Average KL loss: 0.319157
Average total loss: 0.470259
tensor(-13.9501, device='cuda:0') tensor(1.1876, device='cuda:0') tensor(-5.8974e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.149455
Average KL loss: 0.319151
Average total loss: 0.468606
tensor(-13.9505, device='cuda:0') tensor(1.1878, device='cuda:0') tensor(-5.7920e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.146904
Average KL loss: 0.319131
Average total loss: 0.466035
tensor(-13.9509, device='cuda:0') tensor(1.1882, device='cuda:0') tensor(-3.2205e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.149548
Average KL loss: 0.319112
Average total loss: 0.468660
tensor(-13.9513, device='cuda:0') tensor(1.1885, device='cuda:0') tensor(-1.0784e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.148695
Average KL loss: 0.319101
Average total loss: 0.467796
tensor(-13.9517, device='cuda:0') tensor(1.1888, device='cuda:0') tensor(1.0768e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.148122
Average KL loss: 0.319088
Average total loss: 0.467210
tensor(-13.9521, device='cuda:0') tensor(1.1892, device='cuda:0') tensor(2.3735e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.148638
Average KL loss: 0.319068
Average total loss: 0.467706
tensor(-13.9525, device='cuda:0') tensor(1.1895, device='cuda:0') tensor(1.7472e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.148601
Average KL loss: 0.319050
Average total loss: 0.467650
tensor(-13.9529, device='cuda:0') tensor(1.1899, device='cuda:0') tensor(5.2263e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.147258
Average KL loss: 0.319030
Average total loss: 0.466287
tensor(-13.9533, device='cuda:0') tensor(1.1901, device='cuda:0') tensor(7.7770e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.148841
Average KL loss: 0.319005
Average total loss: 0.467846
tensor(-13.9537, device='cuda:0') tensor(1.1904, device='cuda:0') tensor(-3.3193e-11, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.150148
Average KL loss: 0.318995
Average total loss: 0.469143
tensor(-13.9541, device='cuda:0') tensor(1.1908, device='cuda:0') tensor(5.7956e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.148149
Average KL loss: 0.318978
Average total loss: 0.467127
tensor(-13.9545, device='cuda:0') tensor(1.1911, device='cuda:0') tensor(5.9074e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.149270
Average KL loss: 0.318963
Average total loss: 0.468233
tensor(-13.9549, device='cuda:0') tensor(1.1914, device='cuda:0') tensor(-8.0168e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.147493
Average KL loss: 0.318950
Average total loss: 0.466442
tensor(-13.9553, device='cuda:0') tensor(1.1917, device='cuda:0') tensor(-3.2817e-11, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.149244
Average KL loss: 0.318945
Average total loss: 0.468188
tensor(-13.9554, device='cuda:0') tensor(1.1918, device='cuda:0') tensor(-4.1176e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.147091
Average KL loss: 0.318943
Average total loss: 0.466035
tensor(-13.9554, device='cuda:0') tensor(1.1918, device='cuda:0') tensor(-7.7039e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.146269
Average KL loss: 0.318943
Average total loss: 0.465212
tensor(-13.9555, device='cuda:0') tensor(1.1918, device='cuda:0') tensor(2.8319e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.147287
Average KL loss: 0.318942
Average total loss: 0.466229
tensor(-13.9555, device='cuda:0') tensor(1.1919, device='cuda:0') tensor(2.6849e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.148162
Average KL loss: 0.318940
Average total loss: 0.467102
tensor(-13.9555, device='cuda:0') tensor(1.1919, device='cuda:0') tensor(-1.4270e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.146301
Average KL loss: 0.318939
Average total loss: 0.465241
tensor(-13.9556, device='cuda:0') tensor(1.1919, device='cuda:0') tensor(-6.4801e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.146428
Average KL loss: 0.318938
Average total loss: 0.465366
tensor(-13.9556, device='cuda:0') tensor(1.1920, device='cuda:0') tensor(-4.7106e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.145608
Average KL loss: 0.318937
Average total loss: 0.464545
tensor(-13.9557, device='cuda:0') tensor(1.1920, device='cuda:0') tensor(-5.4616e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.147769
Average KL loss: 0.318936
Average total loss: 0.466704
tensor(-13.9557, device='cuda:0') tensor(1.1920, device='cuda:0') tensor(-6.8707e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.146917
Average KL loss: 0.318935
Average total loss: 0.465852
tensor(-13.9558, device='cuda:0') tensor(1.1921, device='cuda:0') tensor(3.0160e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.147229
Average KL loss: 0.318933
Average total loss: 0.466162
tensor(-13.9558, device='cuda:0') tensor(1.1921, device='cuda:0') tensor(4.3029e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.147028
Average KL loss: 0.318932
Average total loss: 0.465960
tensor(-13.9559, device='cuda:0') tensor(1.1921, device='cuda:0') tensor(-1.6018e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.146094
Average KL loss: 0.318931
Average total loss: 0.465025
tensor(-13.9559, device='cuda:0') tensor(1.1922, device='cuda:0') tensor(-9.9236e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.147816
Average KL loss: 0.318930
Average total loss: 0.466747
tensor(-13.9560, device='cuda:0') tensor(1.1922, device='cuda:0') tensor(-1.4170e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.149201
Average KL loss: 0.318929
Average total loss: 0.468130
tensor(-13.9560, device='cuda:0') tensor(1.1922, device='cuda:0') tensor(7.3252e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.146873
Average KL loss: 0.318927
Average total loss: 0.465800
tensor(-13.9561, device='cuda:0') tensor(1.1923, device='cuda:0') tensor(-9.7654e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.145527
Average KL loss: 0.318926
Average total loss: 0.464453
tensor(-13.9561, device='cuda:0') tensor(1.1923, device='cuda:0') tensor(-1.0815e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.146276
Average KL loss: 0.318924
Average total loss: 0.465200
tensor(-13.9562, device='cuda:0') tensor(1.1923, device='cuda:0') tensor(-1.0540e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.149473
Average KL loss: 0.318922
Average total loss: 0.468396
tensor(-13.9562, device='cuda:0') tensor(1.1924, device='cuda:0') tensor(-1.4841e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.145235
Average KL loss: 0.318921
Average total loss: 0.464156
tensor(-13.9562, device='cuda:0') tensor(1.1924, device='cuda:0') tensor(-6.4421e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.143335
Average KL loss: 0.318920
Average total loss: 0.462255
tensor(-13.9563, device='cuda:0') tensor(1.1924, device='cuda:0') tensor(-2.0472e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.146445
Average KL loss: 0.318919
Average total loss: 0.465364
tensor(-13.9563, device='cuda:0') tensor(1.1925, device='cuda:0') tensor(-3.8334e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.146842
Average KL loss: 0.318918
Average total loss: 0.465760
tensor(-13.9564, device='cuda:0') tensor(1.1925, device='cuda:0') tensor(-1.4264e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.148664
Average KL loss: 0.318916
Average total loss: 0.467580
tensor(-13.9564, device='cuda:0') tensor(1.1925, device='cuda:0') tensor(-1.1132e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.148268
Average KL loss: 0.318915
Average total loss: 0.467182
tensor(-13.9565, device='cuda:0') tensor(1.1925, device='cuda:0') tensor(-1.2716e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.148102
Average KL loss: 0.318913
Average total loss: 0.467015
tensor(-13.9565, device='cuda:0') tensor(1.1926, device='cuda:0') tensor(-1.5106e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.148774
Average KL loss: 0.318913
Average total loss: 0.467687
tensor(-13.9566, device='cuda:0') tensor(1.1926, device='cuda:0') tensor(-3.1078e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.147950
Average KL loss: 0.318912
Average total loss: 0.466861
tensor(-13.9566, device='cuda:0') tensor(1.1927, device='cuda:0') tensor(-1.2275e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.149870
Average KL loss: 0.318911
Average total loss: 0.468781
tensor(-13.9567, device='cuda:0') tensor(1.1927, device='cuda:0') tensor(7.9822e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.145266
Average KL loss: 0.318909
Average total loss: 0.464176
 Percentile value: -13.573113441467285
Non-zero model percentage: 2.8147659301757812%, Non-zero mask percentage: 2.8147659301757812%

--- Pruning Level [16/24]: ---
conv1.weight         | nonzeros =    1230 /    1728             ( 71.18%) | total_pruned =     498 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    6612 /   36864             ( 17.94%) | total_pruned =   30252 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    6918 /   36864             ( 18.77%) | total_pruned =   29946 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    5925 /   36864             ( 16.07%) | total_pruned =   30939 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    5730 /   36864             ( 15.54%) | total_pruned =   31134 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   11955 /   73728             ( 16.22%) | total_pruned =   61773 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   18734 /  147456             ( 12.70%) | total_pruned =  128722 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2905 /    8192             ( 35.46%) | total_pruned =    5287 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   13391 /  147456             (  9.08%) | total_pruned =  134065 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   13226 /  147456             (  8.97%) | total_pruned =  134230 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   28592 /  294912             (  9.70%) | total_pruned =  266320 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     169 /     256             ( 66.02%) | total_pruned =      87 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   39806 /  589824             (  6.75%) | total_pruned =  550018 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     158 /     256             ( 61.72%) | total_pruned =      98 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6594 /   32768             ( 20.12%) | total_pruned =   26174 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     156 /     256             ( 60.94%) | total_pruned =     100 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   17651 /  589824             (  2.99%) | total_pruned =  572173 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     120 /     256             ( 46.88%) | total_pruned =     136 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      84 /     256             ( 32.81%) | total_pruned =     172 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   18111 /  589824             (  3.07%) | total_pruned =  571713 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     212 /     256             ( 82.81%) | total_pruned =      44 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     126 /     256             ( 49.22%) | total_pruned =     130 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   36226 / 1179648             (  3.07%) | total_pruned = 1143422 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     283 /     512             ( 55.27%) | total_pruned =     229 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     202 /     512             ( 39.45%) | total_pruned =     310 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   32603 / 2359296             (  1.38%) | total_pruned = 2326693 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     345 /     512             ( 67.38%) | total_pruned =     167 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     302 /     512             ( 58.98%) | total_pruned =     210 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    7307 /  131072             (  5.57%) | total_pruned =  123765 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     270 /     512             ( 52.73%) | total_pruned =     242 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     297 /     512             ( 58.01%) | total_pruned =     215 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   15241 / 2359296             (  0.65%) | total_pruned = 2344055 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     125 /     512             ( 24.41%) | total_pruned =     387 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      48 /     512             (  9.38%) | total_pruned =     464 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   17018 / 2359296             (  0.72%) | total_pruned = 2342278 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     401 /     512             ( 78.32%) | total_pruned =     111 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     220 /     512             ( 42.97%) | total_pruned =     292 | shape = torch.Size([512])
linear.weight        | nonzeros =    3243 /    5120             ( 63.34%) | total_pruned =    1877 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 314656, pruned : 10864106, total: 11178762, Compression rate :      35.53x  ( 97.19% pruned)
Train Epoch: 22/100 Loss: 0.000006 Accuracy: 86.45 100.00 % Best test Accuracy: 86.45%
tensor(-13.9567, device='cuda:0') tensor(1.1927, device='cuda:0') tensor(1.0965e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.226633
Average KL loss: 0.318653
Average total loss: 0.545287
tensor(-13.9577, device='cuda:0') tensor(1.1690, device='cuda:0') tensor(-1.5504e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.223357
Average KL loss: 0.318439
Average total loss: 0.541796
tensor(-13.9585, device='cuda:0') tensor(1.1553, device='cuda:0') tensor(-3.6407e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.227081
Average KL loss: 0.318315
Average total loss: 0.545397
tensor(-13.9591, device='cuda:0') tensor(1.1466, device='cuda:0') tensor(-1.3142e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.223928
Average KL loss: 0.318236
Average total loss: 0.542164
tensor(-13.9597, device='cuda:0') tensor(1.1408, device='cuda:0') tensor(-6.7353e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.220169
Average KL loss: 0.318181
Average total loss: 0.538350
tensor(-13.9602, device='cuda:0') tensor(1.1369, device='cuda:0') tensor(-1.3296e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.220846
Average KL loss: 0.318135
Average total loss: 0.538981
tensor(-13.9607, device='cuda:0') tensor(1.1344, device='cuda:0') tensor(1.2230e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.214210
Average KL loss: 0.318095
Average total loss: 0.532306
tensor(-13.9611, device='cuda:0') tensor(1.1327, device='cuda:0') tensor(1.2809e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.219380
Average KL loss: 0.318055
Average total loss: 0.537435
tensor(-13.9616, device='cuda:0') tensor(1.1317, device='cuda:0') tensor(-3.2718e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.213813
Average KL loss: 0.318014
Average total loss: 0.531827
tensor(-13.9620, device='cuda:0') tensor(1.1310, device='cuda:0') tensor(-9.6511e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.209786
Average KL loss: 0.317974
Average total loss: 0.527760
tensor(-13.9624, device='cuda:0') tensor(1.1306, device='cuda:0') tensor(3.9418e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.209848
Average KL loss: 0.317940
Average total loss: 0.527787
tensor(-13.9628, device='cuda:0') tensor(1.1304, device='cuda:0') tensor(1.9005e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.209262
Average KL loss: 0.317914
Average total loss: 0.527176
tensor(-13.9632, device='cuda:0') tensor(1.1304, device='cuda:0') tensor(-1.0601e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.207141
Average KL loss: 0.317889
Average total loss: 0.525030
tensor(-13.9637, device='cuda:0') tensor(1.1304, device='cuda:0') tensor(-1.7032e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.203551
Average KL loss: 0.317867
Average total loss: 0.521418
tensor(-13.9641, device='cuda:0') tensor(1.1305, device='cuda:0') tensor(-1.5198e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.206820
Average KL loss: 0.317848
Average total loss: 0.524668
tensor(-13.9645, device='cuda:0') tensor(1.1305, device='cuda:0') tensor(-1.8021e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.206630
Average KL loss: 0.317824
Average total loss: 0.524454
tensor(-13.9649, device='cuda:0') tensor(1.1307, device='cuda:0') tensor(8.4010e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.206880
Average KL loss: 0.317807
Average total loss: 0.524687
tensor(-13.9653, device='cuda:0') tensor(1.1309, device='cuda:0') tensor(-2.7498e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.202102
Average KL loss: 0.317787
Average total loss: 0.519889
tensor(-13.9657, device='cuda:0') tensor(1.1312, device='cuda:0') tensor(-1.2453e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.203091
Average KL loss: 0.317764
Average total loss: 0.520855
tensor(-13.9661, device='cuda:0') tensor(1.1315, device='cuda:0') tensor(-3.1209e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.198224
Average KL loss: 0.317747
Average total loss: 0.515971
tensor(-13.9665, device='cuda:0') tensor(1.1318, device='cuda:0') tensor(-3.4263e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.200845
Average KL loss: 0.317731
Average total loss: 0.518576
tensor(-13.9669, device='cuda:0') tensor(1.1321, device='cuda:0') tensor(-4.3400e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.196814
Average KL loss: 0.317719
Average total loss: 0.514533
tensor(-13.9673, device='cuda:0') tensor(1.1324, device='cuda:0') tensor(-5.1815e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.197156
Average KL loss: 0.317705
Average total loss: 0.514861
tensor(-13.9677, device='cuda:0') tensor(1.1328, device='cuda:0') tensor(-1.1519e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.195924
Average KL loss: 0.317687
Average total loss: 0.513611
tensor(-13.9681, device='cuda:0') tensor(1.1331, device='cuda:0') tensor(-1.4850e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.197833
Average KL loss: 0.317665
Average total loss: 0.515498
tensor(-13.9684, device='cuda:0') tensor(1.1334, device='cuda:0') tensor(2.7357e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.194741
Average KL loss: 0.317643
Average total loss: 0.512384
tensor(-13.9688, device='cuda:0') tensor(1.1337, device='cuda:0') tensor(1.9398e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.197196
Average KL loss: 0.317616
Average total loss: 0.514813
tensor(-13.9692, device='cuda:0') tensor(1.1340, device='cuda:0') tensor(-2.1150e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.196771
Average KL loss: 0.317597
Average total loss: 0.514369
tensor(-13.9696, device='cuda:0') tensor(1.1344, device='cuda:0') tensor(-6.8034e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.196275
Average KL loss: 0.317572
Average total loss: 0.513847
tensor(-13.9700, device='cuda:0') tensor(1.1348, device='cuda:0') tensor(-6.0509e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.188230
Average KL loss: 0.317548
Average total loss: 0.505779
tensor(-13.9704, device='cuda:0') tensor(1.1351, device='cuda:0') tensor(-8.9102e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.193499
Average KL loss: 0.317527
Average total loss: 0.511026
tensor(-13.9708, device='cuda:0') tensor(1.1354, device='cuda:0') tensor(-4.7460e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.189623
Average KL loss: 0.317505
Average total loss: 0.507129
tensor(-13.9712, device='cuda:0') tensor(1.1357, device='cuda:0') tensor(4.7861e-11, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.192870
Average KL loss: 0.317487
Average total loss: 0.510356
tensor(-13.9716, device='cuda:0') tensor(1.1361, device='cuda:0') tensor(-1.2737e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.191327
Average KL loss: 0.317468
Average total loss: 0.508795
tensor(-13.9720, device='cuda:0') tensor(1.1364, device='cuda:0') tensor(-2.0968e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.189783
Average KL loss: 0.317447
Average total loss: 0.507230
tensor(-13.9724, device='cuda:0') tensor(1.1367, device='cuda:0') tensor(-1.3707e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.187367
Average KL loss: 0.317433
Average total loss: 0.504800
tensor(-13.9728, device='cuda:0') tensor(1.1371, device='cuda:0') tensor(-9.5505e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.189512
Average KL loss: 0.317413
Average total loss: 0.506925
tensor(-13.9732, device='cuda:0') tensor(1.1374, device='cuda:0') tensor(-3.2340e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.188396
Average KL loss: 0.317385
Average total loss: 0.505781
tensor(-13.9736, device='cuda:0') tensor(1.1377, device='cuda:0') tensor(-1.8530e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.185375
Average KL loss: 0.317365
Average total loss: 0.502740
tensor(-13.9740, device='cuda:0') tensor(1.1380, device='cuda:0') tensor(-1.5822e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.188173
Average KL loss: 0.317345
Average total loss: 0.505518
tensor(-13.9744, device='cuda:0') tensor(1.1384, device='cuda:0') tensor(-2.5382e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.186856
Average KL loss: 0.317326
Average total loss: 0.504182
tensor(-13.9748, device='cuda:0') tensor(1.1388, device='cuda:0') tensor(-1.2790e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.185364
Average KL loss: 0.317309
Average total loss: 0.502673
tensor(-13.9752, device='cuda:0') tensor(1.1392, device='cuda:0') tensor(-4.5650e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.184633
Average KL loss: 0.317294
Average total loss: 0.501927
tensor(-13.9756, device='cuda:0') tensor(1.1396, device='cuda:0') tensor(-1.7816e-11, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.184968
Average KL loss: 0.317280
Average total loss: 0.502248
tensor(-13.9760, device='cuda:0') tensor(1.1399, device='cuda:0') tensor(-1.8166e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.185133
Average KL loss: 0.317263
Average total loss: 0.502395
tensor(-13.9763, device='cuda:0') tensor(1.1403, device='cuda:0') tensor(-2.9860e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.182902
Average KL loss: 0.317230
Average total loss: 0.500132
tensor(-13.9767, device='cuda:0') tensor(1.1406, device='cuda:0') tensor(-1.8223e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.182696
Average KL loss: 0.317205
Average total loss: 0.499901
tensor(-13.9771, device='cuda:0') tensor(1.1410, device='cuda:0') tensor(1.4857e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.185840
Average KL loss: 0.317177
Average total loss: 0.503017
tensor(-13.9775, device='cuda:0') tensor(1.1414, device='cuda:0') tensor(2.1413e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.182817
Average KL loss: 0.317161
Average total loss: 0.499978
tensor(-13.9779, device='cuda:0') tensor(1.1418, device='cuda:0') tensor(-3.0051e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.182730
Average KL loss: 0.317148
Average total loss: 0.499879
tensor(-13.9783, device='cuda:0') tensor(1.1422, device='cuda:0') tensor(-2.0987e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.178281
Average KL loss: 0.317128
Average total loss: 0.495409
tensor(-13.9787, device='cuda:0') tensor(1.1425, device='cuda:0') tensor(-3.4742e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.184207
Average KL loss: 0.317107
Average total loss: 0.501314
tensor(-13.9791, device='cuda:0') tensor(1.1429, device='cuda:0') tensor(-3.7495e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.180167
Average KL loss: 0.317087
Average total loss: 0.497254
tensor(-13.9795, device='cuda:0') tensor(1.1433, device='cuda:0') tensor(-2.3969e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.180983
Average KL loss: 0.317070
Average total loss: 0.498052
tensor(-13.9799, device='cuda:0') tensor(1.1436, device='cuda:0') tensor(-1.2398e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.177532
Average KL loss: 0.317050
Average total loss: 0.494582
tensor(-13.9803, device='cuda:0') tensor(1.1441, device='cuda:0') tensor(-1.2598e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.180485
Average KL loss: 0.317028
Average total loss: 0.497513
tensor(-13.9807, device='cuda:0') tensor(1.1444, device='cuda:0') tensor(-6.9506e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.181978
Average KL loss: 0.317002
Average total loss: 0.498980
tensor(-13.9810, device='cuda:0') tensor(1.1448, device='cuda:0') tensor(4.6526e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.178829
Average KL loss: 0.316981
Average total loss: 0.495810
tensor(-13.9814, device='cuda:0') tensor(1.1452, device='cuda:0') tensor(-8.2191e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.178728
Average KL loss: 0.316961
Average total loss: 0.495689
tensor(-13.9818, device='cuda:0') tensor(1.1455, device='cuda:0') tensor(-2.7112e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.177724
Average KL loss: 0.316935
Average total loss: 0.494659
tensor(-13.9822, device='cuda:0') tensor(1.1458, device='cuda:0') tensor(-1.6789e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.175016
Average KL loss: 0.316911
Average total loss: 0.491927
tensor(-13.9826, device='cuda:0') tensor(1.1461, device='cuda:0') tensor(1.1588e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.178823
Average KL loss: 0.316885
Average total loss: 0.495708
tensor(-13.9830, device='cuda:0') tensor(1.1464, device='cuda:0') tensor(1.1752e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.177737
Average KL loss: 0.316868
Average total loss: 0.494605
tensor(-13.9834, device='cuda:0') tensor(1.1468, device='cuda:0') tensor(-1.8001e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.178319
Average KL loss: 0.316850
Average total loss: 0.495169
tensor(-13.9838, device='cuda:0') tensor(1.1472, device='cuda:0') tensor(-2.3495e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.175818
Average KL loss: 0.316832
Average total loss: 0.492650
tensor(-13.9842, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(-1.4758e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.178844
Average KL loss: 0.316811
Average total loss: 0.495654
tensor(-13.9846, device='cuda:0') tensor(1.1480, device='cuda:0') tensor(-1.0197e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.177612
Average KL loss: 0.316794
Average total loss: 0.494406
tensor(-13.9850, device='cuda:0') tensor(1.1483, device='cuda:0') tensor(-3.7991e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.174622
Average KL loss: 0.316770
Average total loss: 0.491392
tensor(-13.9854, device='cuda:0') tensor(1.1487, device='cuda:0') tensor(-6.5249e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.178694
Average KL loss: 0.316745
Average total loss: 0.495439
tensor(-13.9857, device='cuda:0') tensor(1.1490, device='cuda:0') tensor(-2.7784e-11, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.178135
Average KL loss: 0.316723
Average total loss: 0.494858
tensor(-13.9861, device='cuda:0') tensor(1.1493, device='cuda:0') tensor(-4.7278e-11, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.175396
Average KL loss: 0.316706
Average total loss: 0.492102
tensor(-13.9865, device='cuda:0') tensor(1.1497, device='cuda:0') tensor(-1.0972e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.174707
Average KL loss: 0.316690
Average total loss: 0.491397
tensor(-13.9869, device='cuda:0') tensor(1.1501, device='cuda:0') tensor(-1.2700e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.173919
Average KL loss: 0.316670
Average total loss: 0.490589
tensor(-13.9873, device='cuda:0') tensor(1.1504, device='cuda:0') tensor(-8.8839e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.172037
Average KL loss: 0.316648
Average total loss: 0.488686
tensor(-13.9877, device='cuda:0') tensor(1.1508, device='cuda:0') tensor(-8.9924e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.172933
Average KL loss: 0.316634
Average total loss: 0.489567
tensor(-13.9881, device='cuda:0') tensor(1.1512, device='cuda:0') tensor(-1.1191e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.172550
Average KL loss: 0.316616
Average total loss: 0.489166
tensor(-13.9885, device='cuda:0') tensor(1.1516, device='cuda:0') tensor(7.5528e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.170035
Average KL loss: 0.316595
Average total loss: 0.486630
tensor(-13.9889, device='cuda:0') tensor(1.1520, device='cuda:0') tensor(-9.0859e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.173288
Average KL loss: 0.316572
Average total loss: 0.489860
tensor(-13.9893, device='cuda:0') tensor(1.1523, device='cuda:0') tensor(-6.7379e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.171208
Average KL loss: 0.316552
Average total loss: 0.487760
tensor(-13.9896, device='cuda:0') tensor(1.1526, device='cuda:0') tensor(-2.0648e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.172962
Average KL loss: 0.316530
Average total loss: 0.489492
tensor(-13.9900, device='cuda:0') tensor(1.1529, device='cuda:0') tensor(-1.5892e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.173393
Average KL loss: 0.316515
Average total loss: 0.489908
tensor(-13.9904, device='cuda:0') tensor(1.1532, device='cuda:0') tensor(-8.9945e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.173819
Average KL loss: 0.316501
Average total loss: 0.490320
tensor(-13.9908, device='cuda:0') tensor(1.1536, device='cuda:0') tensor(2.1517e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.170892
Average KL loss: 0.316481
Average total loss: 0.487373
tensor(-13.9912, device='cuda:0') tensor(1.1540, device='cuda:0') tensor(-1.7488e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.171799
Average KL loss: 0.316455
Average total loss: 0.488254
tensor(-13.9916, device='cuda:0') tensor(1.1543, device='cuda:0') tensor(-5.0950e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.171288
Average KL loss: 0.316434
Average total loss: 0.487722
tensor(-13.9920, device='cuda:0') tensor(1.1547, device='cuda:0') tensor(1.5169e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.171880
Average KL loss: 0.316417
Average total loss: 0.488297
tensor(-13.9924, device='cuda:0') tensor(1.1551, device='cuda:0') tensor(1.4071e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.167501
Average KL loss: 0.316396
Average total loss: 0.483897
tensor(-13.9928, device='cuda:0') tensor(1.1555, device='cuda:0') tensor(-3.9612e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.171776
Average KL loss: 0.316375
Average total loss: 0.488152
tensor(-13.9932, device='cuda:0') tensor(1.1559, device='cuda:0') tensor(3.3717e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.171127
Average KL loss: 0.316348
Average total loss: 0.487475
tensor(-13.9935, device='cuda:0') tensor(1.1563, device='cuda:0') tensor(-7.7853e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.166358
Average KL loss: 0.316324
Average total loss: 0.482682
tensor(-13.9939, device='cuda:0') tensor(1.1566, device='cuda:0') tensor(1.6076e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.170960
Average KL loss: 0.316301
Average total loss: 0.487261
tensor(-13.9943, device='cuda:0') tensor(1.1570, device='cuda:0') tensor(-2.7534e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.170240
Average KL loss: 0.316284
Average total loss: 0.486523
tensor(-13.9947, device='cuda:0') tensor(1.1574, device='cuda:0') tensor(-1.2204e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.168335
Average KL loss: 0.316263
Average total loss: 0.484598
tensor(-13.9951, device='cuda:0') tensor(1.1578, device='cuda:0') tensor(7.7794e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.166896
Average KL loss: 0.316248
Average total loss: 0.483144
tensor(-13.9955, device='cuda:0') tensor(1.1581, device='cuda:0') tensor(-2.4833e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.165094
Average KL loss: 0.316229
Average total loss: 0.481324
tensor(-13.9959, device='cuda:0') tensor(1.1585, device='cuda:0') tensor(-8.5205e-11, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.165178
Average KL loss: 0.316210
Average total loss: 0.481387
tensor(-13.9963, device='cuda:0') tensor(1.1589, device='cuda:0') tensor(8.3263e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.167618
Average KL loss: 0.316186
Average total loss: 0.483804
tensor(-13.9966, device='cuda:0') tensor(1.1592, device='cuda:0') tensor(-1.6500e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.165415
Average KL loss: 0.316160
Average total loss: 0.481575
tensor(-13.9970, device='cuda:0') tensor(1.1595, device='cuda:0') tensor(-2.7890e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.168736
Average KL loss: 0.316144
Average total loss: 0.484879
tensor(-13.9974, device='cuda:0') tensor(1.1599, device='cuda:0') tensor(-9.6293e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.166653
Average KL loss: 0.316133
Average total loss: 0.482786
tensor(-13.9978, device='cuda:0') tensor(1.1603, device='cuda:0') tensor(-1.7758e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.165155
Average KL loss: 0.316119
Average total loss: 0.481274
tensor(-13.9982, device='cuda:0') tensor(1.1606, device='cuda:0') tensor(-1.0789e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.165539
Average KL loss: 0.316091
Average total loss: 0.481630
tensor(-13.9986, device='cuda:0') tensor(1.1610, device='cuda:0') tensor(1.0427e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.164112
Average KL loss: 0.316073
Average total loss: 0.480185
tensor(-13.9990, device='cuda:0') tensor(1.1613, device='cuda:0') tensor(4.1960e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.164614
Average KL loss: 0.316051
Average total loss: 0.480665
tensor(-13.9994, device='cuda:0') tensor(1.1617, device='cuda:0') tensor(-8.8529e-11, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.164632
Average KL loss: 0.316036
Average total loss: 0.480669
tensor(-13.9998, device='cuda:0') tensor(1.1620, device='cuda:0') tensor(-4.7748e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.163739
Average KL loss: 0.316019
Average total loss: 0.479758
tensor(-14.0001, device='cuda:0') tensor(1.1624, device='cuda:0') tensor(-2.9169e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.163766
Average KL loss: 0.316002
Average total loss: 0.479767
tensor(-14.0005, device='cuda:0') tensor(1.1627, device='cuda:0') tensor(-1.2239e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.162094
Average KL loss: 0.315981
Average total loss: 0.478075
tensor(-14.0009, device='cuda:0') tensor(1.1630, device='cuda:0') tensor(-6.1926e-11, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.161189
Average KL loss: 0.315963
Average total loss: 0.477152
tensor(-14.0013, device='cuda:0') tensor(1.1634, device='cuda:0') tensor(-1.2806e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.160652
Average KL loss: 0.315953
Average total loss: 0.476605
tensor(-14.0017, device='cuda:0') tensor(1.1637, device='cuda:0') tensor(-6.4730e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.163760
Average KL loss: 0.315938
Average total loss: 0.479698
tensor(-14.0021, device='cuda:0') tensor(1.1640, device='cuda:0') tensor(-2.5792e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.164840
Average KL loss: 0.315923
Average total loss: 0.480763
tensor(-14.0024, device='cuda:0') tensor(1.1644, device='cuda:0') tensor(-1.3330e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.162381
Average KL loss: 0.315904
Average total loss: 0.478285
tensor(-14.0028, device='cuda:0') tensor(1.1648, device='cuda:0') tensor(-1.8013e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.164931
Average KL loss: 0.315887
Average total loss: 0.480818
tensor(-14.0032, device='cuda:0') tensor(1.1651, device='cuda:0') tensor(-1.2526e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.165097
Average KL loss: 0.315867
Average total loss: 0.480964
tensor(-14.0036, device='cuda:0') tensor(1.1655, device='cuda:0') tensor(-1.8686e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.164786
Average KL loss: 0.315852
Average total loss: 0.480639
tensor(-14.0040, device='cuda:0') tensor(1.1659, device='cuda:0') tensor(-1.7009e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.161264
Average KL loss: 0.315838
Average total loss: 0.477101
tensor(-14.0044, device='cuda:0') tensor(1.1662, device='cuda:0') tensor(-1.0576e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.160847
Average KL loss: 0.315820
Average total loss: 0.476667
tensor(-14.0047, device='cuda:0') tensor(1.1666, device='cuda:0') tensor(-1.2653e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.161781
Average KL loss: 0.315803
Average total loss: 0.477584
tensor(-14.0051, device='cuda:0') tensor(1.1669, device='cuda:0') tensor(1.8331e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.160173
Average KL loss: 0.315783
Average total loss: 0.475955
tensor(-14.0055, device='cuda:0') tensor(1.1672, device='cuda:0') tensor(-1.3074e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.163591
Average KL loss: 0.315762
Average total loss: 0.479353
tensor(-14.0059, device='cuda:0') tensor(1.1676, device='cuda:0') tensor(-6.4677e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.158921
Average KL loss: 0.315745
Average total loss: 0.474666
tensor(-14.0063, device='cuda:0') tensor(1.1679, device='cuda:0') tensor(-1.7360e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.159888
Average KL loss: 0.315726
Average total loss: 0.475614
tensor(-14.0066, device='cuda:0') tensor(1.1682, device='cuda:0') tensor(-1.7778e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.159750
Average KL loss: 0.315703
Average total loss: 0.475454
tensor(-14.0070, device='cuda:0') tensor(1.1686, device='cuda:0') tensor(-3.3688e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.160208
Average KL loss: 0.315686
Average total loss: 0.475894
tensor(-14.0074, device='cuda:0') tensor(1.1689, device='cuda:0') tensor(-1.9221e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.160483
Average KL loss: 0.315667
Average total loss: 0.476150
tensor(-14.0078, device='cuda:0') tensor(1.1693, device='cuda:0') tensor(7.6717e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.157920
Average KL loss: 0.315652
Average total loss: 0.473572
tensor(-14.0082, device='cuda:0') tensor(1.1696, device='cuda:0') tensor(-1.6649e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.159186
Average KL loss: 0.315636
Average total loss: 0.474822
tensor(-14.0085, device='cuda:0') tensor(1.1700, device='cuda:0') tensor(-1.3157e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.158082
Average KL loss: 0.315615
Average total loss: 0.473697
tensor(-14.0089, device='cuda:0') tensor(1.1703, device='cuda:0') tensor(-9.4539e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.162232
Average KL loss: 0.315588
Average total loss: 0.477820
tensor(-14.0093, device='cuda:0') tensor(1.1706, device='cuda:0') tensor(-1.6376e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.157120
Average KL loss: 0.315569
Average total loss: 0.472689
tensor(-14.0097, device='cuda:0') tensor(1.1709, device='cuda:0') tensor(2.2606e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.159070
Average KL loss: 0.315557
Average total loss: 0.474627
tensor(-14.0100, device='cuda:0') tensor(1.1712, device='cuda:0') tensor(-1.8356e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.158778
Average KL loss: 0.315542
Average total loss: 0.474320
tensor(-14.0104, device='cuda:0') tensor(1.1716, device='cuda:0') tensor(1.6397e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.158466
Average KL loss: 0.315526
Average total loss: 0.473993
tensor(-14.0108, device='cuda:0') tensor(1.1719, device='cuda:0') tensor(-5.6422e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.160218
Average KL loss: 0.315511
Average total loss: 0.475729
tensor(-14.0112, device='cuda:0') tensor(1.1723, device='cuda:0') tensor(-1.3250e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.158898
Average KL loss: 0.315495
Average total loss: 0.474393
tensor(-14.0115, device='cuda:0') tensor(1.1727, device='cuda:0') tensor(-7.0704e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.156070
Average KL loss: 0.315477
Average total loss: 0.471547
tensor(-14.0119, device='cuda:0') tensor(1.1730, device='cuda:0') tensor(-1.2361e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.157151
Average KL loss: 0.315456
Average total loss: 0.472607
tensor(-14.0123, device='cuda:0') tensor(1.1733, device='cuda:0') tensor(-8.8322e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.156441
Average KL loss: 0.315439
Average total loss: 0.471880
tensor(-14.0127, device='cuda:0') tensor(1.1737, device='cuda:0') tensor(-1.5337e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.158280
Average KL loss: 0.315424
Average total loss: 0.473704
tensor(-14.0130, device='cuda:0') tensor(1.1740, device='cuda:0') tensor(2.3737e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.158255
Average KL loss: 0.315404
Average total loss: 0.473659
tensor(-14.0134, device='cuda:0') tensor(1.1744, device='cuda:0') tensor(-9.5712e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.159969
Average KL loss: 0.315382
Average total loss: 0.475351
tensor(-14.0138, device='cuda:0') tensor(1.1747, device='cuda:0') tensor(1.4163e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.157333
Average KL loss: 0.315358
Average total loss: 0.472692
tensor(-14.0141, device='cuda:0') tensor(1.1750, device='cuda:0') tensor(-3.6786e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.154634
Average KL loss: 0.315340
Average total loss: 0.469973
tensor(-14.0145, device='cuda:0') tensor(1.1753, device='cuda:0') tensor(-2.4335e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.154935
Average KL loss: 0.315321
Average total loss: 0.470257
tensor(-14.0149, device='cuda:0') tensor(1.1757, device='cuda:0') tensor(2.1836e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.155032
Average KL loss: 0.315297
Average total loss: 0.470329
tensor(-14.0153, device='cuda:0') tensor(1.1761, device='cuda:0') tensor(-3.3676e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.154349
Average KL loss: 0.315276
Average total loss: 0.469626
tensor(-14.0156, device='cuda:0') tensor(1.1764, device='cuda:0') tensor(1.4481e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.154294
Average KL loss: 0.315256
Average total loss: 0.469550
tensor(-14.0160, device='cuda:0') tensor(1.1766, device='cuda:0') tensor(-9.0120e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.154965
Average KL loss: 0.315243
Average total loss: 0.470208
tensor(-14.0164, device='cuda:0') tensor(1.1769, device='cuda:0') tensor(-3.7754e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.157867
Average KL loss: 0.315225
Average total loss: 0.473092
tensor(-14.0167, device='cuda:0') tensor(1.1772, device='cuda:0') tensor(-2.6171e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.154658
Average KL loss: 0.315205
Average total loss: 0.469863
tensor(-14.0171, device='cuda:0') tensor(1.1776, device='cuda:0') tensor(6.9827e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.156323
Average KL loss: 0.315184
Average total loss: 0.471507
tensor(-14.0175, device='cuda:0') tensor(1.1779, device='cuda:0') tensor(-2.5851e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.154125
Average KL loss: 0.315163
Average total loss: 0.469287
tensor(-14.0178, device='cuda:0') tensor(1.1782, device='cuda:0') tensor(-3.8679e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.153487
Average KL loss: 0.315139
Average total loss: 0.468625
tensor(-14.0182, device='cuda:0') tensor(1.1786, device='cuda:0') tensor(-2.5936e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.153983
Average KL loss: 0.315118
Average total loss: 0.469102
tensor(-14.0186, device='cuda:0') tensor(1.1789, device='cuda:0') tensor(-2.5452e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.153763
Average KL loss: 0.315104
Average total loss: 0.468867
tensor(-14.0189, device='cuda:0') tensor(1.1792, device='cuda:0') tensor(-9.5988e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.153432
Average KL loss: 0.315082
Average total loss: 0.468514
tensor(-14.0193, device='cuda:0') tensor(1.1795, device='cuda:0') tensor(-1.1566e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.156111
Average KL loss: 0.315063
Average total loss: 0.471173
tensor(-14.0197, device='cuda:0') tensor(1.1798, device='cuda:0') tensor(-3.5607e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.150954
Average KL loss: 0.315039
Average total loss: 0.465993
tensor(-14.0201, device='cuda:0') tensor(1.1801, device='cuda:0') tensor(1.1162e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.154788
Average KL loss: 0.315020
Average total loss: 0.469808
tensor(-14.0204, device='cuda:0') tensor(1.1804, device='cuda:0') tensor(-5.4746e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.152601
Average KL loss: 0.315003
Average total loss: 0.467605
tensor(-14.0208, device='cuda:0') tensor(1.1808, device='cuda:0') tensor(-1.7371e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.151640
Average KL loss: 0.314985
Average total loss: 0.466625
tensor(-14.0212, device='cuda:0') tensor(1.1810, device='cuda:0') tensor(-1.3833e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.151695
Average KL loss: 0.314968
Average total loss: 0.466663
tensor(-14.0215, device='cuda:0') tensor(1.1814, device='cuda:0') tensor(6.2508e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.151632
Average KL loss: 0.314948
Average total loss: 0.466579
tensor(-14.0219, device='cuda:0') tensor(1.1816, device='cuda:0') tensor(-4.1477e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.151948
Average KL loss: 0.314925
Average total loss: 0.466873
tensor(-14.0223, device='cuda:0') tensor(1.1819, device='cuda:0') tensor(3.8167e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.151770
Average KL loss: 0.314904
Average total loss: 0.466674
tensor(-14.0226, device='cuda:0') tensor(1.1823, device='cuda:0') tensor(-1.6664e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.149040
Average KL loss: 0.314882
Average total loss: 0.463922
tensor(-14.0230, device='cuda:0') tensor(1.1826, device='cuda:0') tensor(-1.5347e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.148381
Average KL loss: 0.314868
Average total loss: 0.463249
tensor(-14.0233, device='cuda:0') tensor(1.1829, device='cuda:0') tensor(3.9814e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.152731
Average KL loss: 0.314856
Average total loss: 0.467587
tensor(-14.0237, device='cuda:0') tensor(1.1832, device='cuda:0') tensor(3.8652e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.149154
Average KL loss: 0.314837
Average total loss: 0.463991
tensor(-14.0241, device='cuda:0') tensor(1.1835, device='cuda:0') tensor(-1.7517e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.149684
Average KL loss: 0.314820
Average total loss: 0.464504
tensor(-14.0244, device='cuda:0') tensor(1.1839, device='cuda:0') tensor(5.1819e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.148415
Average KL loss: 0.314800
Average total loss: 0.463215
tensor(-14.0248, device='cuda:0') tensor(1.1842, device='cuda:0') tensor(-1.5435e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.150016
Average KL loss: 0.314786
Average total loss: 0.464802
tensor(-14.0252, device='cuda:0') tensor(1.1845, device='cuda:0') tensor(-1.9585e-11, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.151805
Average KL loss: 0.314768
Average total loss: 0.466572
tensor(-14.0255, device='cuda:0') tensor(1.1848, device='cuda:0') tensor(1.1967e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.152474
Average KL loss: 0.314746
Average total loss: 0.467219
tensor(-14.0259, device='cuda:0') tensor(1.1852, device='cuda:0') tensor(-7.3620e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.150813
Average KL loss: 0.314730
Average total loss: 0.465543
tensor(-14.0263, device='cuda:0') tensor(1.1855, device='cuda:0') tensor(4.6320e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.150060
Average KL loss: 0.314717
Average total loss: 0.464777
tensor(-14.0266, device='cuda:0') tensor(1.1859, device='cuda:0') tensor(-4.3892e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.151411
Average KL loss: 0.314705
Average total loss: 0.466116
tensor(-14.0270, device='cuda:0') tensor(1.1862, device='cuda:0') tensor(1.1799e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.148630
Average KL loss: 0.314694
Average total loss: 0.463324
tensor(-14.0274, device='cuda:0') tensor(1.1865, device='cuda:0') tensor(-3.8051e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.148448
Average KL loss: 0.314688
Average total loss: 0.463136
tensor(-14.0274, device='cuda:0') tensor(1.1866, device='cuda:0') tensor(8.9230e-11, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.148726
Average KL loss: 0.314686
Average total loss: 0.463412
tensor(-14.0274, device='cuda:0') tensor(1.1866, device='cuda:0') tensor(4.4104e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.149651
Average KL loss: 0.314685
Average total loss: 0.464336
tensor(-14.0275, device='cuda:0') tensor(1.1866, device='cuda:0') tensor(-1.3755e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.151629
Average KL loss: 0.314683
Average total loss: 0.466313
tensor(-14.0275, device='cuda:0') tensor(1.1867, device='cuda:0') tensor(-1.0311e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.150510
Average KL loss: 0.314682
Average total loss: 0.465192
tensor(-14.0276, device='cuda:0') tensor(1.1867, device='cuda:0') tensor(-7.4020e-11, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.150536
Average KL loss: 0.314682
Average total loss: 0.465218
tensor(-14.0276, device='cuda:0') tensor(1.1867, device='cuda:0') tensor(4.6237e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.150352
Average KL loss: 0.314681
Average total loss: 0.465033
tensor(-14.0277, device='cuda:0') tensor(1.1868, device='cuda:0') tensor(-3.4538e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.151366
Average KL loss: 0.314680
Average total loss: 0.466046
tensor(-14.0277, device='cuda:0') tensor(1.1868, device='cuda:0') tensor(1.1830e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.149792
Average KL loss: 0.314678
Average total loss: 0.464471
tensor(-14.0278, device='cuda:0') tensor(1.1868, device='cuda:0') tensor(-1.2678e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.148445
Average KL loss: 0.314676
Average total loss: 0.463122
tensor(-14.0278, device='cuda:0') tensor(1.1869, device='cuda:0') tensor(-9.8801e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.148554
Average KL loss: 0.314675
Average total loss: 0.463229
tensor(-14.0279, device='cuda:0') tensor(1.1869, device='cuda:0') tensor(-1.1884e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.151887
Average KL loss: 0.314674
Average total loss: 0.466560
tensor(-14.0279, device='cuda:0') tensor(1.1869, device='cuda:0') tensor(-2.1387e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.146628
Average KL loss: 0.314673
Average total loss: 0.461301
tensor(-14.0279, device='cuda:0') tensor(1.1869, device='cuda:0') tensor(-2.2025e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.150569
Average KL loss: 0.314673
Average total loss: 0.465241
tensor(-14.0279, device='cuda:0') tensor(1.1869, device='cuda:0') tensor(2.6552e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.147762
Average KL loss: 0.314672
Average total loss: 0.462434
tensor(-14.0279, device='cuda:0') tensor(1.1869, device='cuda:0') tensor(-1.5595e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.147411
Average KL loss: 0.314672
Average total loss: 0.462084
tensor(-14.0279, device='cuda:0') tensor(1.1869, device='cuda:0') tensor(-9.7506e-11, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.151902
Average KL loss: 0.314672
Average total loss: 0.466574
tensor(-14.0279, device='cuda:0') tensor(1.1869, device='cuda:0') tensor(3.3550e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.147763
Average KL loss: 0.314672
Average total loss: 0.462435
tensor(-14.0279, device='cuda:0') tensor(1.1869, device='cuda:0') tensor(-8.3456e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.148554
Average KL loss: 0.314672
Average total loss: 0.463226
tensor(-14.0279, device='cuda:0') tensor(1.1869, device='cuda:0') tensor(-5.1306e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.151507
Average KL loss: 0.314672
Average total loss: 0.466179
tensor(-14.0279, device='cuda:0') tensor(1.1869, device='cuda:0') tensor(-6.4747e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.146498
Average KL loss: 0.314672
Average total loss: 0.461169
 Percentile value: -13.625271224975586
Non-zero model percentage: 2.251814603805542%, Non-zero mask percentage: 2.251814603805542%

--- Pruning Level [17/24]: ---
conv1.weight         | nonzeros =    1160 /    1728             ( 67.13%) | total_pruned =     568 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5496 /   36864             ( 14.91%) | total_pruned =   31368 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    5809 /   36864             ( 15.76%) | total_pruned =   31055 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4972 /   36864             ( 13.49%) | total_pruned =   31892 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4789 /   36864             ( 12.99%) | total_pruned =   32075 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    9947 /   73728             ( 13.49%) | total_pruned =   63781 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   15359 /  147456             ( 10.42%) | total_pruned =  132097 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2610 /    8192             ( 31.86%) | total_pruned =    5582 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   10898 /  147456             (  7.39%) | total_pruned =  136558 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   10601 /  147456             (  7.19%) | total_pruned =  136855 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   23066 /  294912             (  7.82%) | total_pruned =  271846 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     227 /     256             ( 88.67%) | total_pruned =      29 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     155 /     256             ( 60.55%) | total_pruned =     101 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   31310 /  589824             (  5.31%) | total_pruned =  558514 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     140 /     256             ( 54.69%) | total_pruned =     116 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    5535 /   32768             ( 16.89%) | total_pruned =   27233 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   13782 /  589824             (  2.34%) | total_pruned =  576042 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     117 /     256             ( 45.70%) | total_pruned =     139 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      78 /     256             ( 30.47%) | total_pruned =     178 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   14268 /  589824             (  2.42%) | total_pruned =  575556 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     107 /     256             ( 41.80%) | total_pruned =     149 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   28127 / 1179648             (  2.38%) | total_pruned = 1151521 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     276 /     512             ( 53.91%) | total_pruned =     236 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     182 /     512             ( 35.55%) | total_pruned =     330 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   24823 / 2359296             (  1.05%) | total_pruned = 2334473 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     341 /     512             ( 66.60%) | total_pruned =     171 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     274 /     512             ( 53.52%) | total_pruned =     238 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    5828 /  131072             (  4.45%) | total_pruned =  125244 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     264 /     512             ( 51.56%) | total_pruned =     248 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     277 /     512             ( 54.10%) | total_pruned =     235 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   11776 / 2359296             (  0.50%) | total_pruned = 2347520 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     118 /     512             ( 23.05%) | total_pruned =     394 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   13175 / 2359296             (  0.56%) | total_pruned = 2346121 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     398 /     512             ( 77.73%) | total_pruned =     114 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     174 /     512             ( 33.98%) | total_pruned =     338 | shape = torch.Size([512])
linear.weight        | nonzeros =    3041 /    5120             ( 59.39%) | total_pruned =    2079 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 251725, pruned : 10927037, total: 11178762, Compression rate :      44.41x  ( 97.75% pruned)
Train Epoch: 22/100 Loss: 0.000682 Accuracy: 86.20 100.00 % Best test Accuracy: 86.30%
tensor(-14.0279, device='cuda:0') tensor(1.1870, device='cuda:0') tensor(-3.7848e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.247146
Average KL loss: 0.314421
Average total loss: 0.561567
tensor(-14.0289, device='cuda:0') tensor(1.1637, device='cuda:0') tensor(1.8805e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.244251
Average KL loss: 0.314187
Average total loss: 0.558438
tensor(-14.0296, device='cuda:0') tensor(1.1502, device='cuda:0') tensor(2.4472e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.240598
Average KL loss: 0.314051
Average total loss: 0.554648
tensor(-14.0302, device='cuda:0') tensor(1.1413, device='cuda:0') tensor(-1.3520e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.236666
Average KL loss: 0.313958
Average total loss: 0.550624
tensor(-14.0307, device='cuda:0') tensor(1.1354, device='cuda:0') tensor(-1.7627e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.239952
Average KL loss: 0.313880
Average total loss: 0.553832
tensor(-14.0312, device='cuda:0') tensor(1.1316, device='cuda:0') tensor(1.0684e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.231454
Average KL loss: 0.313821
Average total loss: 0.545274
tensor(-14.0317, device='cuda:0') tensor(1.1290, device='cuda:0') tensor(-1.7355e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.232604
Average KL loss: 0.313764
Average total loss: 0.546368
tensor(-14.0321, device='cuda:0') tensor(1.1273, device='cuda:0') tensor(-1.5825e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.230554
Average KL loss: 0.313716
Average total loss: 0.544270
tensor(-14.0325, device='cuda:0') tensor(1.1261, device='cuda:0') tensor(-1.1633e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.225759
Average KL loss: 0.313667
Average total loss: 0.539426
tensor(-14.0329, device='cuda:0') tensor(1.1254, device='cuda:0') tensor(1.5041e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.223641
Average KL loss: 0.313624
Average total loss: 0.537265
tensor(-14.0333, device='cuda:0') tensor(1.1250, device='cuda:0') tensor(7.8381e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.222938
Average KL loss: 0.313588
Average total loss: 0.536526
tensor(-14.0336, device='cuda:0') tensor(1.1248, device='cuda:0') tensor(7.5310e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.221119
Average KL loss: 0.313553
Average total loss: 0.534672
tensor(-14.0340, device='cuda:0') tensor(1.1248, device='cuda:0') tensor(-2.4420e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.217767
Average KL loss: 0.313520
Average total loss: 0.531286
tensor(-14.0344, device='cuda:0') tensor(1.1248, device='cuda:0') tensor(1.6099e-11, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.216662
Average KL loss: 0.313490
Average total loss: 0.530151
tensor(-14.0348, device='cuda:0') tensor(1.1249, device='cuda:0') tensor(-8.4111e-11, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.216301
Average KL loss: 0.313457
Average total loss: 0.529758
tensor(-14.0351, device='cuda:0') tensor(1.1250, device='cuda:0') tensor(-1.3132e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.215044
Average KL loss: 0.313425
Average total loss: 0.528469
tensor(-14.0355, device='cuda:0') tensor(1.1251, device='cuda:0') tensor(6.9125e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.211223
Average KL loss: 0.313400
Average total loss: 0.524623
tensor(-14.0359, device='cuda:0') tensor(1.1253, device='cuda:0') tensor(-2.0861e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.212334
Average KL loss: 0.313369
Average total loss: 0.525703
tensor(-14.0362, device='cuda:0') tensor(1.1254, device='cuda:0') tensor(1.1267e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.212554
Average KL loss: 0.313335
Average total loss: 0.525889
tensor(-14.0366, device='cuda:0') tensor(1.1256, device='cuda:0') tensor(3.4890e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.213185
Average KL loss: 0.313298
Average total loss: 0.526483
tensor(-14.0370, device='cuda:0') tensor(1.1258, device='cuda:0') tensor(-1.4320e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.206730
Average KL loss: 0.313266
Average total loss: 0.519996
tensor(-14.0373, device='cuda:0') tensor(1.1260, device='cuda:0') tensor(4.3850e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.205803
Average KL loss: 0.313233
Average total loss: 0.519036
tensor(-14.0377, device='cuda:0') tensor(1.1263, device='cuda:0') tensor(-1.9619e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.206928
Average KL loss: 0.313200
Average total loss: 0.520129
tensor(-14.0381, device='cuda:0') tensor(1.1266, device='cuda:0') tensor(-2.8841e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.208492
Average KL loss: 0.313177
Average total loss: 0.521668
tensor(-14.0384, device='cuda:0') tensor(1.1269, device='cuda:0') tensor(2.1103e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.203846
Average KL loss: 0.313153
Average total loss: 0.516999
tensor(-14.0388, device='cuda:0') tensor(1.1272, device='cuda:0') tensor(-1.3568e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.208760
Average KL loss: 0.313118
Average total loss: 0.521878
tensor(-14.0392, device='cuda:0') tensor(1.1275, device='cuda:0') tensor(-6.7404e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.206966
Average KL loss: 0.313089
Average total loss: 0.520056
tensor(-14.0395, device='cuda:0') tensor(1.1279, device='cuda:0') tensor(-4.4452e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.206595
Average KL loss: 0.313066
Average total loss: 0.519661
tensor(-14.0399, device='cuda:0') tensor(1.1282, device='cuda:0') tensor(-8.4057e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.201921
Average KL loss: 0.313040
Average total loss: 0.514961
tensor(-14.0402, device='cuda:0') tensor(1.1285, device='cuda:0') tensor(-2.8862e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.199362
Average KL loss: 0.313010
Average total loss: 0.512372
tensor(-14.0406, device='cuda:0') tensor(1.1289, device='cuda:0') tensor(1.1115e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.203098
Average KL loss: 0.312986
Average total loss: 0.516084
tensor(-14.0410, device='cuda:0') tensor(1.1292, device='cuda:0') tensor(-6.6940e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.200541
Average KL loss: 0.312964
Average total loss: 0.513505
tensor(-14.0413, device='cuda:0') tensor(1.1295, device='cuda:0') tensor(-9.8608e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.199810
Average KL loss: 0.312945
Average total loss: 0.512754
tensor(-14.0417, device='cuda:0') tensor(1.1298, device='cuda:0') tensor(-1.6649e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.200838
Average KL loss: 0.312927
Average total loss: 0.513765
tensor(-14.0420, device='cuda:0') tensor(1.1302, device='cuda:0') tensor(2.0327e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.198691
Average KL loss: 0.312905
Average total loss: 0.511596
tensor(-14.0424, device='cuda:0') tensor(1.1306, device='cuda:0') tensor(-6.7341e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.197044
Average KL loss: 0.312885
Average total loss: 0.509928
tensor(-14.0428, device='cuda:0') tensor(1.1309, device='cuda:0') tensor(-2.4896e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.195832
Average KL loss: 0.312862
Average total loss: 0.508694
tensor(-14.0431, device='cuda:0') tensor(1.1313, device='cuda:0') tensor(1.4298e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.198721
Average KL loss: 0.312836
Average total loss: 0.511557
tensor(-14.0435, device='cuda:0') tensor(1.1316, device='cuda:0') tensor(-1.7459e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.195183
Average KL loss: 0.312810
Average total loss: 0.507994
tensor(-14.0438, device='cuda:0') tensor(1.1319, device='cuda:0') tensor(-3.3737e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.195578
Average KL loss: 0.312787
Average total loss: 0.508365
tensor(-14.0442, device='cuda:0') tensor(1.1323, device='cuda:0') tensor(-3.2773e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.193727
Average KL loss: 0.312768
Average total loss: 0.506495
tensor(-14.0446, device='cuda:0') tensor(1.1327, device='cuda:0') tensor(7.8525e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.194102
Average KL loss: 0.312748
Average total loss: 0.506850
tensor(-14.0449, device='cuda:0') tensor(1.1330, device='cuda:0') tensor(-2.1284e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.193930
Average KL loss: 0.312721
Average total loss: 0.506652
tensor(-14.0453, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-2.1399e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.192139
Average KL loss: 0.312700
Average total loss: 0.504839
tensor(-14.0456, device='cuda:0') tensor(1.1336, device='cuda:0') tensor(1.1132e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.191678
Average KL loss: 0.312679
Average total loss: 0.504357
tensor(-14.0460, device='cuda:0') tensor(1.1340, device='cuda:0') tensor(-1.1316e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.191176
Average KL loss: 0.312656
Average total loss: 0.503832
tensor(-14.0464, device='cuda:0') tensor(1.1343, device='cuda:0') tensor(-1.3120e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.193604
Average KL loss: 0.312632
Average total loss: 0.506236
tensor(-14.0467, device='cuda:0') tensor(1.1346, device='cuda:0') tensor(-3.9295e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.190784
Average KL loss: 0.312614
Average total loss: 0.503398
tensor(-14.0471, device='cuda:0') tensor(1.1349, device='cuda:0') tensor(-1.0215e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.194123
Average KL loss: 0.312596
Average total loss: 0.506719
tensor(-14.0474, device='cuda:0') tensor(1.1353, device='cuda:0') tensor(-5.3945e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.191396
Average KL loss: 0.312577
Average total loss: 0.503973
tensor(-14.0478, device='cuda:0') tensor(1.1357, device='cuda:0') tensor(-1.4966e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.191409
Average KL loss: 0.312568
Average total loss: 0.503977
tensor(-14.0481, device='cuda:0') tensor(1.1362, device='cuda:0') tensor(-1.7953e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.188372
Average KL loss: 0.312550
Average total loss: 0.500922
tensor(-14.0485, device='cuda:0') tensor(1.1365, device='cuda:0') tensor(-3.3435e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.188636
Average KL loss: 0.312526
Average total loss: 0.501162
tensor(-14.0489, device='cuda:0') tensor(1.1369, device='cuda:0') tensor(4.1090e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.187420
Average KL loss: 0.312508
Average total loss: 0.499928
tensor(-14.0492, device='cuda:0') tensor(1.1372, device='cuda:0') tensor(-1.0868e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.191200
Average KL loss: 0.312489
Average total loss: 0.503689
tensor(-14.0496, device='cuda:0') tensor(1.1376, device='cuda:0') tensor(-2.3180e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.188954
Average KL loss: 0.312472
Average total loss: 0.501426
tensor(-14.0499, device='cuda:0') tensor(1.1379, device='cuda:0') tensor(-7.6774e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.185197
Average KL loss: 0.312448
Average total loss: 0.497644
tensor(-14.0503, device='cuda:0') tensor(1.1382, device='cuda:0') tensor(-1.3271e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.188843
Average KL loss: 0.312424
Average total loss: 0.501267
tensor(-14.0506, device='cuda:0') tensor(1.1386, device='cuda:0') tensor(-1.5589e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.184483
Average KL loss: 0.312397
Average total loss: 0.496881
tensor(-14.0510, device='cuda:0') tensor(1.1389, device='cuda:0') tensor(-2.6903e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.188920
Average KL loss: 0.312377
Average total loss: 0.501297
tensor(-14.0514, device='cuda:0') tensor(1.1393, device='cuda:0') tensor(-1.0299e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.185917
Average KL loss: 0.312358
Average total loss: 0.498275
tensor(-14.0517, device='cuda:0') tensor(1.1397, device='cuda:0') tensor(-2.1236e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.184634
Average KL loss: 0.312334
Average total loss: 0.496968
tensor(-14.0521, device='cuda:0') tensor(1.1400, device='cuda:0') tensor(-9.6600e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.181836
Average KL loss: 0.312316
Average total loss: 0.494152
tensor(-14.0524, device='cuda:0') tensor(1.1404, device='cuda:0') tensor(-3.0185e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.186925
Average KL loss: 0.312301
Average total loss: 0.499226
tensor(-14.0528, device='cuda:0') tensor(1.1407, device='cuda:0') tensor(-1.1008e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.182620
Average KL loss: 0.312286
Average total loss: 0.494905
tensor(-14.0531, device='cuda:0') tensor(1.1410, device='cuda:0') tensor(-2.2063e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.185660
Average KL loss: 0.312264
Average total loss: 0.497924
tensor(-14.0535, device='cuda:0') tensor(1.1414, device='cuda:0') tensor(-7.0954e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.185283
Average KL loss: 0.312245
Average total loss: 0.497528
tensor(-14.0538, device='cuda:0') tensor(1.1418, device='cuda:0') tensor(1.8380e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.183616
Average KL loss: 0.312229
Average total loss: 0.495846
tensor(-14.0542, device='cuda:0') tensor(1.1421, device='cuda:0') tensor(-2.4076e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.184155
Average KL loss: 0.312211
Average total loss: 0.496366
tensor(-14.0546, device='cuda:0') tensor(1.1425, device='cuda:0') tensor(-1.2554e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.182302
Average KL loss: 0.312188
Average total loss: 0.494490
tensor(-14.0549, device='cuda:0') tensor(1.1428, device='cuda:0') tensor(2.1339e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.180459
Average KL loss: 0.312170
Average total loss: 0.492629
tensor(-14.0553, device='cuda:0') tensor(1.1431, device='cuda:0') tensor(-2.1267e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.181607
Average KL loss: 0.312153
Average total loss: 0.493760
tensor(-14.0556, device='cuda:0') tensor(1.1434, device='cuda:0') tensor(-2.0318e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.179834
Average KL loss: 0.312131
Average total loss: 0.491965
tensor(-14.0560, device='cuda:0') tensor(1.1439, device='cuda:0') tensor(-1.4461e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.177597
Average KL loss: 0.312111
Average total loss: 0.489708
tensor(-14.0563, device='cuda:0') tensor(1.1442, device='cuda:0') tensor(-2.3864e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.176959
Average KL loss: 0.312090
Average total loss: 0.489049
tensor(-14.0567, device='cuda:0') tensor(1.1445, device='cuda:0') tensor(-3.6648e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.184828
Average KL loss: 0.312076
Average total loss: 0.496905
tensor(-14.0570, device='cuda:0') tensor(1.1448, device='cuda:0') tensor(-1.0326e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.178456
Average KL loss: 0.312056
Average total loss: 0.490512
tensor(-14.0574, device='cuda:0') tensor(1.1451, device='cuda:0') tensor(-3.2219e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.179827
Average KL loss: 0.312035
Average total loss: 0.491862
tensor(-14.0578, device='cuda:0') tensor(1.1455, device='cuda:0') tensor(-1.6662e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.180687
Average KL loss: 0.312015
Average total loss: 0.492702
tensor(-14.0581, device='cuda:0') tensor(1.1459, device='cuda:0') tensor(-2.6532e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.178921
Average KL loss: 0.311996
Average total loss: 0.490917
tensor(-14.0585, device='cuda:0') tensor(1.1463, device='cuda:0') tensor(-1.9294e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.178128
Average KL loss: 0.311977
Average total loss: 0.490104
tensor(-14.0588, device='cuda:0') tensor(1.1466, device='cuda:0') tensor(-1.1724e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.179658
Average KL loss: 0.311964
Average total loss: 0.491622
tensor(-14.0592, device='cuda:0') tensor(1.1470, device='cuda:0') tensor(-8.8079e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.180162
Average KL loss: 0.311947
Average total loss: 0.492108
tensor(-14.0595, device='cuda:0') tensor(1.1473, device='cuda:0') tensor(-2.7974e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.176702
Average KL loss: 0.311928
Average total loss: 0.488629
tensor(-14.0599, device='cuda:0') tensor(1.1477, device='cuda:0') tensor(-9.9809e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.178824
Average KL loss: 0.311907
Average total loss: 0.490732
tensor(-14.0602, device='cuda:0') tensor(1.1481, device='cuda:0') tensor(7.9566e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.177944
Average KL loss: 0.311891
Average total loss: 0.489834
tensor(-14.0606, device='cuda:0') tensor(1.1484, device='cuda:0') tensor(-4.6407e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.175948
Average KL loss: 0.311870
Average total loss: 0.487819
tensor(-14.0609, device='cuda:0') tensor(1.1488, device='cuda:0') tensor(-4.8993e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.175866
Average KL loss: 0.311858
Average total loss: 0.487724
tensor(-14.0613, device='cuda:0') tensor(1.1492, device='cuda:0') tensor(-4.9694e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.174598
Average KL loss: 0.311845
Average total loss: 0.486443
tensor(-14.0616, device='cuda:0') tensor(1.1495, device='cuda:0') tensor(-2.0243e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.176105
Average KL loss: 0.311831
Average total loss: 0.487936
tensor(-14.0620, device='cuda:0') tensor(1.1498, device='cuda:0') tensor(-3.3920e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.177966
Average KL loss: 0.311819
Average total loss: 0.489785
tensor(-14.0624, device='cuda:0') tensor(1.1502, device='cuda:0') tensor(-2.9300e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.177811
Average KL loss: 0.311805
Average total loss: 0.489616
tensor(-14.0627, device='cuda:0') tensor(1.1506, device='cuda:0') tensor(-7.8429e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.173674
Average KL loss: 0.311793
Average total loss: 0.485467
tensor(-14.0631, device='cuda:0') tensor(1.1509, device='cuda:0') tensor(-1.1245e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.179978
Average KL loss: 0.311783
Average total loss: 0.491761
tensor(-14.0634, device='cuda:0') tensor(1.1514, device='cuda:0') tensor(-1.6085e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.171428
Average KL loss: 0.311771
Average total loss: 0.483199
tensor(-14.0638, device='cuda:0') tensor(1.1517, device='cuda:0') tensor(-2.7524e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.173243
Average KL loss: 0.311756
Average total loss: 0.484999
tensor(-14.0641, device='cuda:0') tensor(1.1520, device='cuda:0') tensor(-6.6645e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.173108
Average KL loss: 0.311738
Average total loss: 0.484846
tensor(-14.0645, device='cuda:0') tensor(1.1524, device='cuda:0') tensor(-1.3144e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.170690
Average KL loss: 0.311722
Average total loss: 0.482412
tensor(-14.0648, device='cuda:0') tensor(1.1527, device='cuda:0') tensor(-1.3712e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.170952
Average KL loss: 0.311706
Average total loss: 0.482657
tensor(-14.0652, device='cuda:0') tensor(1.1531, device='cuda:0') tensor(3.0318e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.172327
Average KL loss: 0.311682
Average total loss: 0.484009
tensor(-14.0655, device='cuda:0') tensor(1.1534, device='cuda:0') tensor(-5.2441e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.172124
Average KL loss: 0.311661
Average total loss: 0.483786
tensor(-14.0659, device='cuda:0') tensor(1.1537, device='cuda:0') tensor(-4.8485e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.173059
Average KL loss: 0.311636
Average total loss: 0.484695
tensor(-14.0662, device='cuda:0') tensor(1.1541, device='cuda:0') tensor(2.0575e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.174213
Average KL loss: 0.311613
Average total loss: 0.485826
tensor(-14.0666, device='cuda:0') tensor(1.1544, device='cuda:0') tensor(-2.8222e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.171373
Average KL loss: 0.311600
Average total loss: 0.482973
tensor(-14.0669, device='cuda:0') tensor(1.1548, device='cuda:0') tensor(-1.6227e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.173634
Average KL loss: 0.311584
Average total loss: 0.485218
tensor(-14.0673, device='cuda:0') tensor(1.1552, device='cuda:0') tensor(-1.8418e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.170934
Average KL loss: 0.311567
Average total loss: 0.482501
tensor(-14.0676, device='cuda:0') tensor(1.1555, device='cuda:0') tensor(-1.6918e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.174054
Average KL loss: 0.311551
Average total loss: 0.485605
tensor(-14.0680, device='cuda:0') tensor(1.1559, device='cuda:0') tensor(-1.2948e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.174204
Average KL loss: 0.311542
Average total loss: 0.485746
tensor(-14.0683, device='cuda:0') tensor(1.1562, device='cuda:0') tensor(-1.9394e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.172754
Average KL loss: 0.311532
Average total loss: 0.484287
tensor(-14.0687, device='cuda:0') tensor(1.1566, device='cuda:0') tensor(-2.5518e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.173061
Average KL loss: 0.311525
Average total loss: 0.484585
tensor(-14.0687, device='cuda:0') tensor(1.1566, device='cuda:0') tensor(4.7330e-11, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.173081
Average KL loss: 0.311523
Average total loss: 0.484604
tensor(-14.0688, device='cuda:0') tensor(1.1567, device='cuda:0') tensor(-1.1966e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.171525
Average KL loss: 0.311521
Average total loss: 0.483046
tensor(-14.0688, device='cuda:0') tensor(1.1567, device='cuda:0') tensor(-4.9310e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.172861
Average KL loss: 0.311520
Average total loss: 0.484381
tensor(-14.0689, device='cuda:0') tensor(1.1567, device='cuda:0') tensor(-2.1144e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.171827
Average KL loss: 0.311519
Average total loss: 0.483346
tensor(-14.0689, device='cuda:0') tensor(1.1568, device='cuda:0') tensor(-2.2202e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.170017
Average KL loss: 0.311518
Average total loss: 0.481535
tensor(-14.0690, device='cuda:0') tensor(1.1568, device='cuda:0') tensor(4.6359e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.167240
Average KL loss: 0.311517
Average total loss: 0.478757
tensor(-14.0690, device='cuda:0') tensor(1.1568, device='cuda:0') tensor(-7.0482e-11, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.168823
Average KL loss: 0.311516
Average total loss: 0.480339
tensor(-14.0691, device='cuda:0') tensor(1.1569, device='cuda:0') tensor(-1.2129e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.172641
Average KL loss: 0.311515
Average total loss: 0.484156
tensor(-14.0691, device='cuda:0') tensor(1.1569, device='cuda:0') tensor(-2.0077e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.171748
Average KL loss: 0.311513
Average total loss: 0.483261
tensor(-14.0692, device='cuda:0') tensor(1.1570, device='cuda:0') tensor(1.6664e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.169012
Average KL loss: 0.311512
Average total loss: 0.480523
tensor(-14.0692, device='cuda:0') tensor(1.1570, device='cuda:0') tensor(-2.1210e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.167369
Average KL loss: 0.311510
Average total loss: 0.478879
tensor(-14.0692, device='cuda:0') tensor(1.1570, device='cuda:0') tensor(-1.2552e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.171291
Average KL loss: 0.311509
Average total loss: 0.482800
tensor(-14.0693, device='cuda:0') tensor(1.1571, device='cuda:0') tensor(-9.0827e-11, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.170274
Average KL loss: 0.311508
Average total loss: 0.481782
tensor(-14.0693, device='cuda:0') tensor(1.1571, device='cuda:0') tensor(1.7191e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.172051
Average KL loss: 0.311507
Average total loss: 0.483558
tensor(-14.0694, device='cuda:0') tensor(1.1571, device='cuda:0') tensor(-1.5778e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.171700
Average KL loss: 0.311506
Average total loss: 0.483206
tensor(-14.0694, device='cuda:0') tensor(1.1572, device='cuda:0') tensor(-3.8515e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.170039
Average KL loss: 0.311505
Average total loss: 0.481544
tensor(-14.0695, device='cuda:0') tensor(1.1572, device='cuda:0') tensor(-1.8933e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.170446
Average KL loss: 0.311504
Average total loss: 0.481949
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-4.5267e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.169393
Average KL loss: 0.311503
Average total loss: 0.480895
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-4.8417e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.169117
Average KL loss: 0.311503
Average total loss: 0.480620
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-1.5185e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.167307
Average KL loss: 0.311503
Average total loss: 0.478810
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(1.1537e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.172709
Average KL loss: 0.311502
Average total loss: 0.484211
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-2.7595e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.170783
Average KL loss: 0.311502
Average total loss: 0.482286
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-1.4871e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.171442
Average KL loss: 0.311502
Average total loss: 0.482944
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-1.5201e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.172947
Average KL loss: 0.311502
Average total loss: 0.484449
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(1.2790e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.167851
Average KL loss: 0.311502
Average total loss: 0.479353
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-1.7584e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.169355
Average KL loss: 0.311502
Average total loss: 0.480857
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-1.4344e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.172808
Average KL loss: 0.311502
Average total loss: 0.484310
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(5.4959e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.169748
Average KL loss: 0.311502
Average total loss: 0.481249
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-1.0106e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.170632
Average KL loss: 0.311502
Average total loss: 0.482133
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-2.9088e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.168834
Average KL loss: 0.311502
Average total loss: 0.480336
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(2.0237e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.169898
Average KL loss: 0.311502
Average total loss: 0.481399
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-4.2902e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.172329
Average KL loss: 0.311502
Average total loss: 0.483831
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-7.0835e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.170662
Average KL loss: 0.311502
Average total loss: 0.482163
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-4.0605e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.168925
Average KL loss: 0.311502
Average total loss: 0.480427
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-1.2178e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.173028
Average KL loss: 0.311502
Average total loss: 0.484530
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-5.8506e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.170972
Average KL loss: 0.311502
Average total loss: 0.482474
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(1.0539e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.172488
Average KL loss: 0.311502
Average total loss: 0.483989
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(-1.3923e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.169665
Average KL loss: 0.311501
Average total loss: 0.481166
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(3.4114e-09, device='cuda:0')
 Percentile value: -13.63050193786621
Non-zero model percentage: 1.8014516830444336%, Non-zero mask percentage: 1.8014516830444336%

--- Pruning Level [18/24]: ---
conv1.weight         | nonzeros =    1113 /    1728             ( 64.41%) | total_pruned =     615 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    4564 /   36864             ( 12.38%) | total_pruned =   32300 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4863 /   36864             ( 13.19%) | total_pruned =   32001 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4174 /   36864             ( 11.32%) | total_pruned =   32690 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4039 /   36864             ( 10.96%) | total_pruned =   32825 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    8166 /   73728             ( 11.08%) | total_pruned =   65562 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   12463 /  147456             (  8.45%) | total_pruned =  134993 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2296 /    8192             ( 28.03%) | total_pruned =    5896 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8836 /  147456             (  5.99%) | total_pruned =  138620 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    8530 /  147456             (  5.78%) | total_pruned =  138926 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   18498 /  294912             (  6.27%) | total_pruned =  276414 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     136 /     256             ( 53.12%) | total_pruned =     120 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   24640 /  589824             (  4.18%) | total_pruned =  565184 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     120 /     256             ( 46.88%) | total_pruned =     136 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4700 /   32768             ( 14.34%) | total_pruned =   28068 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     129 /     256             ( 50.39%) | total_pruned =     127 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   10773 /  589824             (  1.83%) | total_pruned =  579051 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     117 /     256             ( 45.70%) | total_pruned =     139 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   11164 /  589824             (  1.89%) | total_pruned =  578660 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      91 /     256             ( 35.55%) | total_pruned =     165 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   21783 / 1179648             (  1.85%) | total_pruned = 1157865 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     275 /     512             ( 53.71%) | total_pruned =     237 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     155 /     512             ( 30.27%) | total_pruned =     357 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   18792 / 2359296             (  0.80%) | total_pruned = 2340504 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     340 /     512             ( 66.41%) | total_pruned =     172 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     245 /     512             ( 47.85%) | total_pruned =     267 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    4708 /  131072             (  3.59%) | total_pruned =  126364 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     264 /     512             ( 51.56%) | total_pruned =     248 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     247 /     512             ( 48.24%) | total_pruned =     265 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    9040 / 2359296             (  0.38%) | total_pruned = 2350256 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     116 /     512             ( 22.66%) | total_pruned =     396 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   10292 / 2359296             (  0.44%) | total_pruned = 2349004 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     129 /     512             ( 25.20%) | total_pruned =     383 | shape = torch.Size([512])
linear.weight        | nonzeros =    2864 /    5120             ( 55.94%) | total_pruned =    2256 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 201380, pruned : 10977382, total: 11178762, Compression rate :      55.51x  ( 98.20% pruned)
Train Epoch: 23/100 Loss: 0.000020 Accuracy: 86.05 100.00 % Best test Accuracy: 86.28%
tensor(-14.0695, device='cuda:0') tensor(1.1573, device='cuda:0') tensor(1.8449e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.255413
Average KL loss: 0.311232
Average total loss: 0.566644
tensor(-14.0705, device='cuda:0') tensor(1.1341, device='cuda:0') tensor(-8.7289e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.253025
Average KL loss: 0.311002
Average total loss: 0.564026
tensor(-14.0712, device='cuda:0') tensor(1.1216, device='cuda:0') tensor(1.1066e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.251439
Average KL loss: 0.310875
Average total loss: 0.562313
tensor(-14.0717, device='cuda:0') tensor(1.1139, device='cuda:0') tensor(-3.2290e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.246402
Average KL loss: 0.310783
Average total loss: 0.557185
tensor(-14.0722, device='cuda:0') tensor(1.1091, device='cuda:0') tensor(-3.3404e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.243615
Average KL loss: 0.310724
Average total loss: 0.554339
tensor(-14.0727, device='cuda:0') tensor(1.1061, device='cuda:0') tensor(1.3301e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.245771
Average KL loss: 0.310678
Average total loss: 0.556449
tensor(-14.0731, device='cuda:0') tensor(1.1043, device='cuda:0') tensor(-1.3268e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.241940
Average KL loss: 0.310638
Average total loss: 0.552577
tensor(-14.0735, device='cuda:0') tensor(1.1032, device='cuda:0') tensor(-8.1591e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.240844
Average KL loss: 0.310606
Average total loss: 0.551450
tensor(-14.0738, device='cuda:0') tensor(1.1025, device='cuda:0') tensor(-4.5968e-11, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.241749
Average KL loss: 0.310573
Average total loss: 0.552322
tensor(-14.0742, device='cuda:0') tensor(1.1021, device='cuda:0') tensor(-1.5394e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.240176
Average KL loss: 0.310543
Average total loss: 0.550719
tensor(-14.0746, device='cuda:0') tensor(1.1020, device='cuda:0') tensor(-4.3837e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.234008
Average KL loss: 0.310510
Average total loss: 0.544518
tensor(-14.0749, device='cuda:0') tensor(1.1020, device='cuda:0') tensor(-4.9052e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.234409
Average KL loss: 0.310484
Average total loss: 0.544893
tensor(-14.0753, device='cuda:0') tensor(1.1020, device='cuda:0') tensor(-5.1052e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.232291
Average KL loss: 0.310459
Average total loss: 0.542750
tensor(-14.0757, device='cuda:0') tensor(1.1022, device='cuda:0') tensor(3.6571e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.227876
Average KL loss: 0.310430
Average total loss: 0.538306
tensor(-14.0760, device='cuda:0') tensor(1.1023, device='cuda:0') tensor(3.4044e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.229966
Average KL loss: 0.310403
Average total loss: 0.540369
tensor(-14.0764, device='cuda:0') tensor(1.1025, device='cuda:0') tensor(6.7579e-11, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.229554
Average KL loss: 0.310378
Average total loss: 0.539933
tensor(-14.0767, device='cuda:0') tensor(1.1027, device='cuda:0') tensor(-2.9259e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.227575
Average KL loss: 0.310353
Average total loss: 0.537928
tensor(-14.0771, device='cuda:0') tensor(1.1029, device='cuda:0') tensor(-6.1651e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.226093
Average KL loss: 0.310325
Average total loss: 0.536418
tensor(-14.0774, device='cuda:0') tensor(1.1032, device='cuda:0') tensor(-1.0090e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.228161
Average KL loss: 0.310302
Average total loss: 0.538463
tensor(-14.0778, device='cuda:0') tensor(1.1036, device='cuda:0') tensor(-4.2805e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.227612
Average KL loss: 0.310281
Average total loss: 0.537893
tensor(-14.0781, device='cuda:0') tensor(1.1039, device='cuda:0') tensor(-2.8654e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.226939
Average KL loss: 0.310264
Average total loss: 0.537203
tensor(-14.0785, device='cuda:0') tensor(1.1043, device='cuda:0') tensor(-1.1878e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.227486
Average KL loss: 0.310247
Average total loss: 0.537733
tensor(-14.0788, device='cuda:0') tensor(1.1047, device='cuda:0') tensor(-5.7638e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.221216
Average KL loss: 0.310235
Average total loss: 0.531451
tensor(-14.0792, device='cuda:0') tensor(1.1051, device='cuda:0') tensor(-1.1430e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.220297
Average KL loss: 0.310221
Average total loss: 0.530518
tensor(-14.0795, device='cuda:0') tensor(1.1055, device='cuda:0') tensor(-2.4851e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.219147
Average KL loss: 0.310198
Average total loss: 0.529346
tensor(-14.0799, device='cuda:0') tensor(1.1058, device='cuda:0') tensor(-6.5083e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.219612
Average KL loss: 0.310176
Average total loss: 0.529789
tensor(-14.0802, device='cuda:0') tensor(1.1062, device='cuda:0') tensor(-1.6278e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.219606
Average KL loss: 0.310154
Average total loss: 0.529760
tensor(-14.0806, device='cuda:0') tensor(1.1066, device='cuda:0') tensor(-9.5186e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.220259
Average KL loss: 0.310137
Average total loss: 0.530396
tensor(-14.0809, device='cuda:0') tensor(1.1070, device='cuda:0') tensor(-4.3736e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.214096
Average KL loss: 0.310116
Average total loss: 0.524212
tensor(-14.0813, device='cuda:0') tensor(1.1073, device='cuda:0') tensor(-4.3312e-11, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.214936
Average KL loss: 0.310094
Average total loss: 0.525030
tensor(-14.0816, device='cuda:0') tensor(1.1076, device='cuda:0') tensor(-2.4834e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.214307
Average KL loss: 0.310070
Average total loss: 0.524376
tensor(-14.0820, device='cuda:0') tensor(1.1080, device='cuda:0') tensor(-2.7588e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.214808
Average KL loss: 0.310042
Average total loss: 0.524849
tensor(-14.0823, device='cuda:0') tensor(1.1084, device='cuda:0') tensor(7.6742e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.213246
Average KL loss: 0.310012
Average total loss: 0.523258
tensor(-14.0827, device='cuda:0') tensor(1.1087, device='cuda:0') tensor(-9.5529e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.214888
Average KL loss: 0.309987
Average total loss: 0.524875
tensor(-14.0830, device='cuda:0') tensor(1.1091, device='cuda:0') tensor(4.4517e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.212692
Average KL loss: 0.309962
Average total loss: 0.522654
tensor(-14.0834, device='cuda:0') tensor(1.1094, device='cuda:0') tensor(-7.3254e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.210030
Average KL loss: 0.309943
Average total loss: 0.519973
tensor(-14.0837, device='cuda:0') tensor(1.1098, device='cuda:0') tensor(-2.4810e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.211462
Average KL loss: 0.309921
Average total loss: 0.521383
tensor(-14.0841, device='cuda:0') tensor(1.1101, device='cuda:0') tensor(-2.1143e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.214107
Average KL loss: 0.309902
Average total loss: 0.524009
tensor(-14.0844, device='cuda:0') tensor(1.1105, device='cuda:0') tensor(2.3340e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.210077
Average KL loss: 0.309879
Average total loss: 0.519956
tensor(-14.0848, device='cuda:0') tensor(1.1109, device='cuda:0') tensor(-1.1287e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.210019
Average KL loss: 0.309855
Average total loss: 0.519874
tensor(-14.0851, device='cuda:0') tensor(1.1113, device='cuda:0') tensor(-1.7027e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.208541
Average KL loss: 0.309833
Average total loss: 0.518375
tensor(-14.0855, device='cuda:0') tensor(1.1116, device='cuda:0') tensor(2.5007e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.210991
Average KL loss: 0.309816
Average total loss: 0.520807
tensor(-14.0858, device='cuda:0') tensor(1.1120, device='cuda:0') tensor(-4.3553e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.206559
Average KL loss: 0.309787
Average total loss: 0.516346
tensor(-14.0861, device='cuda:0') tensor(1.1124, device='cuda:0') tensor(-2.0775e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.207929
Average KL loss: 0.309769
Average total loss: 0.517698
tensor(-14.0865, device='cuda:0') tensor(1.1128, device='cuda:0') tensor(-7.3891e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.210314
Average KL loss: 0.309749
Average total loss: 0.520064
tensor(-14.0868, device='cuda:0') tensor(1.1132, device='cuda:0') tensor(-2.5317e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.203767
Average KL loss: 0.309730
Average total loss: 0.513498
tensor(-14.0872, device='cuda:0') tensor(1.1136, device='cuda:0') tensor(-1.1756e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.202443
Average KL loss: 0.309710
Average total loss: 0.512153
tensor(-14.0875, device='cuda:0') tensor(1.1140, device='cuda:0') tensor(-8.6893e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.206658
Average KL loss: 0.309685
Average total loss: 0.516343
tensor(-14.0879, device='cuda:0') tensor(1.1144, device='cuda:0') tensor(-4.0915e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.206259
Average KL loss: 0.309667
Average total loss: 0.515926
tensor(-14.0882, device='cuda:0') tensor(1.1148, device='cuda:0') tensor(-1.7093e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.202572
Average KL loss: 0.309647
Average total loss: 0.512219
tensor(-14.0886, device='cuda:0') tensor(1.1151, device='cuda:0') tensor(-8.8241e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.202983
Average KL loss: 0.309623
Average total loss: 0.512607
tensor(-14.0889, device='cuda:0') tensor(1.1155, device='cuda:0') tensor(-1.4478e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.204471
Average KL loss: 0.309607
Average total loss: 0.514078
tensor(-14.0893, device='cuda:0') tensor(1.1159, device='cuda:0') tensor(-5.3907e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.204763
Average KL loss: 0.309591
Average total loss: 0.514353
tensor(-14.0896, device='cuda:0') tensor(1.1163, device='cuda:0') tensor(-3.9805e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.201798
Average KL loss: 0.309570
Average total loss: 0.511367
tensor(-14.0899, device='cuda:0') tensor(1.1166, device='cuda:0') tensor(-2.8467e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.206590
Average KL loss: 0.309548
Average total loss: 0.516137
tensor(-14.0903, device='cuda:0') tensor(1.1170, device='cuda:0') tensor(-1.0838e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.202101
Average KL loss: 0.309526
Average total loss: 0.511627
tensor(-14.0906, device='cuda:0') tensor(1.1173, device='cuda:0') tensor(-6.2632e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.200778
Average KL loss: 0.309500
Average total loss: 0.510279
tensor(-14.0910, device='cuda:0') tensor(1.1177, device='cuda:0') tensor(-2.0314e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.201437
Average KL loss: 0.309478
Average total loss: 0.510914
tensor(-14.0913, device='cuda:0') tensor(1.1181, device='cuda:0') tensor(-1.8173e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.199989
Average KL loss: 0.309462
Average total loss: 0.509451
tensor(-14.0917, device='cuda:0') tensor(1.1185, device='cuda:0') tensor(1.3700e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.197117
Average KL loss: 0.309441
Average total loss: 0.506558
tensor(-14.0920, device='cuda:0') tensor(1.1189, device='cuda:0') tensor(1.5867e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.199498
Average KL loss: 0.309424
Average total loss: 0.508922
tensor(-14.0923, device='cuda:0') tensor(1.1193, device='cuda:0') tensor(-3.5100e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.202789
Average KL loss: 0.309409
Average total loss: 0.512199
tensor(-14.0927, device='cuda:0') tensor(1.1197, device='cuda:0') tensor(1.6606e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.199069
Average KL loss: 0.309393
Average total loss: 0.508462
tensor(-14.0930, device='cuda:0') tensor(1.1201, device='cuda:0') tensor(-2.1800e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.197490
Average KL loss: 0.309375
Average total loss: 0.506864
tensor(-14.0934, device='cuda:0') tensor(1.1205, device='cuda:0') tensor(-1.1107e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.199456
Average KL loss: 0.309348
Average total loss: 0.508804
tensor(-14.0937, device='cuda:0') tensor(1.1209, device='cuda:0') tensor(-2.1583e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.198417
Average KL loss: 0.309325
Average total loss: 0.507742
tensor(-14.0941, device='cuda:0') tensor(1.1212, device='cuda:0') tensor(2.9918e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.195810
Average KL loss: 0.309307
Average total loss: 0.505117
tensor(-14.0944, device='cuda:0') tensor(1.1217, device='cuda:0') tensor(-5.3563e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.195404
Average KL loss: 0.309285
Average total loss: 0.504689
tensor(-14.0947, device='cuda:0') tensor(1.1221, device='cuda:0') tensor(-2.1867e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.194633
Average KL loss: 0.309261
Average total loss: 0.503894
tensor(-14.0951, device='cuda:0') tensor(1.1224, device='cuda:0') tensor(-1.7778e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.195431
Average KL loss: 0.309242
Average total loss: 0.504673
tensor(-14.0954, device='cuda:0') tensor(1.1228, device='cuda:0') tensor(1.1742e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.193488
Average KL loss: 0.309222
Average total loss: 0.502711
tensor(-14.0958, device='cuda:0') tensor(1.1231, device='cuda:0') tensor(-1.7618e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.193535
Average KL loss: 0.309206
Average total loss: 0.502741
tensor(-14.0961, device='cuda:0') tensor(1.1236, device='cuda:0') tensor(1.2986e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.191576
Average KL loss: 0.309191
Average total loss: 0.500768
tensor(-14.0964, device='cuda:0') tensor(1.1240, device='cuda:0') tensor(-1.2595e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.193268
Average KL loss: 0.309177
Average total loss: 0.502445
tensor(-14.0968, device='cuda:0') tensor(1.1244, device='cuda:0') tensor(-1.1227e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.196540
Average KL loss: 0.309165
Average total loss: 0.505704
tensor(-14.0971, device='cuda:0') tensor(1.1248, device='cuda:0') tensor(-2.6772e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.193839
Average KL loss: 0.309154
Average total loss: 0.502993
tensor(-14.0975, device='cuda:0') tensor(1.1252, device='cuda:0') tensor(-1.2824e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.193653
Average KL loss: 0.309135
Average total loss: 0.502789
tensor(-14.0978, device='cuda:0') tensor(1.1256, device='cuda:0') tensor(-8.0570e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.194309
Average KL loss: 0.309115
Average total loss: 0.503424
tensor(-14.0982, device='cuda:0') tensor(1.1259, device='cuda:0') tensor(1.3740e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.189844
Average KL loss: 0.309094
Average total loss: 0.498938
tensor(-14.0985, device='cuda:0') tensor(1.1263, device='cuda:0') tensor(-4.2817e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.192818
Average KL loss: 0.309074
Average total loss: 0.501892
tensor(-14.0988, device='cuda:0') tensor(1.1267, device='cuda:0') tensor(-1.8616e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.190231
Average KL loss: 0.309057
Average total loss: 0.499287
tensor(-14.0992, device='cuda:0') tensor(1.1270, device='cuda:0') tensor(-8.1051e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.190611
Average KL loss: 0.309043
Average total loss: 0.499654
tensor(-14.0995, device='cuda:0') tensor(1.1274, device='cuda:0') tensor(-4.1775e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.191163
Average KL loss: 0.309024
Average total loss: 0.500188
tensor(-14.0999, device='cuda:0') tensor(1.1278, device='cuda:0') tensor(-2.4164e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.190970
Average KL loss: 0.309006
Average total loss: 0.499977
tensor(-14.1002, device='cuda:0') tensor(1.1281, device='cuda:0') tensor(-1.7359e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.190146
Average KL loss: 0.308987
Average total loss: 0.499132
tensor(-14.1005, device='cuda:0') tensor(1.1285, device='cuda:0') tensor(1.8605e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.192404
Average KL loss: 0.308962
Average total loss: 0.501366
tensor(-14.1009, device='cuda:0') tensor(1.1289, device='cuda:0') tensor(-2.2565e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.189256
Average KL loss: 0.308938
Average total loss: 0.498193
tensor(-14.1012, device='cuda:0') tensor(1.1292, device='cuda:0') tensor(-1.3436e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.188819
Average KL loss: 0.308919
Average total loss: 0.497738
tensor(-14.1016, device='cuda:0') tensor(1.1296, device='cuda:0') tensor(-5.2666e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.188369
Average KL loss: 0.308905
Average total loss: 0.497274
tensor(-14.1019, device='cuda:0') tensor(1.1299, device='cuda:0') tensor(-1.0552e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.190002
Average KL loss: 0.308890
Average total loss: 0.498892
tensor(-14.1022, device='cuda:0') tensor(1.1303, device='cuda:0') tensor(-2.5520e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.188632
Average KL loss: 0.308874
Average total loss: 0.497505
tensor(-14.1026, device='cuda:0') tensor(1.1307, device='cuda:0') tensor(3.7784e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.187037
Average KL loss: 0.308849
Average total loss: 0.495886
tensor(-14.1029, device='cuda:0') tensor(1.1310, device='cuda:0') tensor(-4.3438e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.185537
Average KL loss: 0.308838
Average total loss: 0.494375
tensor(-14.1033, device='cuda:0') tensor(1.1314, device='cuda:0') tensor(-1.3473e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.191070
Average KL loss: 0.308823
Average total loss: 0.499893
tensor(-14.1036, device='cuda:0') tensor(1.1318, device='cuda:0') tensor(6.6086e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.186784
Average KL loss: 0.308804
Average total loss: 0.495588
tensor(-14.1040, device='cuda:0') tensor(1.1321, device='cuda:0') tensor(1.0700e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.188580
Average KL loss: 0.308786
Average total loss: 0.497366
tensor(-14.1043, device='cuda:0') tensor(1.1325, device='cuda:0') tensor(-6.4159e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.184472
Average KL loss: 0.308765
Average total loss: 0.493238
tensor(-14.1046, device='cuda:0') tensor(1.1328, device='cuda:0') tensor(-4.7876e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.185546
Average KL loss: 0.308740
Average total loss: 0.494286
tensor(-14.1050, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-4.5501e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.184745
Average KL loss: 0.308719
Average total loss: 0.493464
tensor(-14.1053, device='cuda:0') tensor(1.1336, device='cuda:0') tensor(-4.0172e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.184186
Average KL loss: 0.308708
Average total loss: 0.492894
tensor(-14.1057, device='cuda:0') tensor(1.1339, device='cuda:0') tensor(-1.1306e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.186483
Average KL loss: 0.308694
Average total loss: 0.495177
tensor(-14.1060, device='cuda:0') tensor(1.1343, device='cuda:0') tensor(-1.1871e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.182947
Average KL loss: 0.308678
Average total loss: 0.491625
tensor(-14.1063, device='cuda:0') tensor(1.1346, device='cuda:0') tensor(-2.8389e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.182969
Average KL loss: 0.308663
Average total loss: 0.491631
tensor(-14.1067, device='cuda:0') tensor(1.1350, device='cuda:0') tensor(1.9806e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.187685
Average KL loss: 0.308641
Average total loss: 0.496326
tensor(-14.1070, device='cuda:0') tensor(1.1354, device='cuda:0') tensor(-8.3589e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.184218
Average KL loss: 0.308624
Average total loss: 0.492842
tensor(-14.1074, device='cuda:0') tensor(1.1358, device='cuda:0') tensor(-4.6049e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.182876
Average KL loss: 0.308607
Average total loss: 0.491482
tensor(-14.1077, device='cuda:0') tensor(1.1362, device='cuda:0') tensor(-2.8857e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.183163
Average KL loss: 0.308590
Average total loss: 0.491752
tensor(-14.1080, device='cuda:0') tensor(1.1365, device='cuda:0') tensor(2.2104e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.185045
Average KL loss: 0.308577
Average total loss: 0.493623
tensor(-14.1084, device='cuda:0') tensor(1.1370, device='cuda:0') tensor(-1.5721e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.183162
Average KL loss: 0.308565
Average total loss: 0.491727
tensor(-14.1087, device='cuda:0') tensor(1.1374, device='cuda:0') tensor(-4.9892e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.179382
Average KL loss: 0.308554
Average total loss: 0.487936
tensor(-14.1090, device='cuda:0') tensor(1.1378, device='cuda:0') tensor(-2.0588e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.182408
Average KL loss: 0.308540
Average total loss: 0.490949
tensor(-14.1094, device='cuda:0') tensor(1.1381, device='cuda:0') tensor(-5.0754e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.184371
Average KL loss: 0.308526
Average total loss: 0.492897
tensor(-14.1097, device='cuda:0') tensor(1.1385, device='cuda:0') tensor(-1.3282e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.181339
Average KL loss: 0.308511
Average total loss: 0.489850
tensor(-14.1101, device='cuda:0') tensor(1.1389, device='cuda:0') tensor(-1.5172e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.184897
Average KL loss: 0.308495
Average total loss: 0.493392
tensor(-14.1104, device='cuda:0') tensor(1.1393, device='cuda:0') tensor(-1.3807e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.180164
Average KL loss: 0.308483
Average total loss: 0.488647
tensor(-14.1107, device='cuda:0') tensor(1.1397, device='cuda:0') tensor(-1.5426e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.184092
Average KL loss: 0.308473
Average total loss: 0.492565
tensor(-14.1111, device='cuda:0') tensor(1.1401, device='cuda:0') tensor(-5.8494e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.182145
Average KL loss: 0.308461
Average total loss: 0.490605
tensor(-14.1114, device='cuda:0') tensor(1.1404, device='cuda:0') tensor(-7.9891e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.181115
Average KL loss: 0.308446
Average total loss: 0.489561
tensor(-14.1118, device='cuda:0') tensor(1.1408, device='cuda:0') tensor(-1.5446e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.182896
Average KL loss: 0.308430
Average total loss: 0.491326
tensor(-14.1121, device='cuda:0') tensor(1.1412, device='cuda:0') tensor(-2.7619e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.181903
Average KL loss: 0.308410
Average total loss: 0.490313
tensor(-14.1124, device='cuda:0') tensor(1.1415, device='cuda:0') tensor(-5.5432e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.180016
Average KL loss: 0.308392
Average total loss: 0.488408
tensor(-14.1128, device='cuda:0') tensor(1.1418, device='cuda:0') tensor(1.9459e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.181075
Average KL loss: 0.308379
Average total loss: 0.489455
tensor(-14.1128, device='cuda:0') tensor(1.1419, device='cuda:0') tensor(-7.7424e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.180137
Average KL loss: 0.308378
Average total loss: 0.488515
tensor(-14.1129, device='cuda:0') tensor(1.1419, device='cuda:0') tensor(-6.9518e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.179517
Average KL loss: 0.308377
Average total loss: 0.487893
tensor(-14.1129, device='cuda:0') tensor(1.1420, device='cuda:0') tensor(-2.0680e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.179125
Average KL loss: 0.308375
Average total loss: 0.487501
tensor(-14.1130, device='cuda:0') tensor(1.1420, device='cuda:0') tensor(-4.6357e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.178585
Average KL loss: 0.308374
Average total loss: 0.486960
tensor(-14.1130, device='cuda:0') tensor(1.1420, device='cuda:0') tensor(-8.3583e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.180716
Average KL loss: 0.308372
Average total loss: 0.489089
tensor(-14.1130, device='cuda:0') tensor(1.1421, device='cuda:0') tensor(-1.2075e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.178285
Average KL loss: 0.308370
Average total loss: 0.486655
tensor(-14.1131, device='cuda:0') tensor(1.1421, device='cuda:0') tensor(-1.2360e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.181390
Average KL loss: 0.308369
Average total loss: 0.489759
tensor(-14.1131, device='cuda:0') tensor(1.1421, device='cuda:0') tensor(-8.5913e-12, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.178788
Average KL loss: 0.308368
Average total loss: 0.487155
tensor(-14.1132, device='cuda:0') tensor(1.1422, device='cuda:0') tensor(-2.4422e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.181849
Average KL loss: 0.308366
Average total loss: 0.490214
tensor(-14.1132, device='cuda:0') tensor(1.1422, device='cuda:0') tensor(-3.3961e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.178925
Average KL loss: 0.308364
Average total loss: 0.487289
tensor(-14.1133, device='cuda:0') tensor(1.1422, device='cuda:0') tensor(-2.4403e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.177487
Average KL loss: 0.308362
Average total loss: 0.485849
tensor(-14.1133, device='cuda:0') tensor(1.1423, device='cuda:0') tensor(-2.2812e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.178987
Average KL loss: 0.308361
Average total loss: 0.487347
tensor(-14.1134, device='cuda:0') tensor(1.1423, device='cuda:0') tensor(-1.1740e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.179586
Average KL loss: 0.308359
Average total loss: 0.487945
tensor(-14.1134, device='cuda:0') tensor(1.1424, device='cuda:0') tensor(-1.6259e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.178193
Average KL loss: 0.308357
Average total loss: 0.486550
tensor(-14.1135, device='cuda:0') tensor(1.1424, device='cuda:0') tensor(1.5808e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.180173
Average KL loss: 0.308356
Average total loss: 0.488528
tensor(-14.1135, device='cuda:0') tensor(1.1424, device='cuda:0') tensor(-3.0079e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.181494
Average KL loss: 0.308354
Average total loss: 0.489848
tensor(-14.1136, device='cuda:0') tensor(1.1425, device='cuda:0') tensor(1.3991e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.180785
Average KL loss: 0.308352
Average total loss: 0.489137
tensor(-14.1136, device='cuda:0') tensor(1.1425, device='cuda:0') tensor(-1.1613e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.180409
Average KL loss: 0.308351
Average total loss: 0.488760
tensor(-14.1136, device='cuda:0') tensor(1.1425, device='cuda:0') tensor(-9.4182e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.181245
Average KL loss: 0.308349
Average total loss: 0.489594
tensor(-14.1137, device='cuda:0') tensor(1.1426, device='cuda:0') tensor(-1.0014e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.178348
Average KL loss: 0.308348
Average total loss: 0.486696
tensor(-14.1137, device='cuda:0') tensor(1.1426, device='cuda:0') tensor(-5.5366e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.180176
Average KL loss: 0.308346
Average total loss: 0.488522
tensor(-14.1138, device='cuda:0') tensor(1.1426, device='cuda:0') tensor(-9.1949e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.176927
Average KL loss: 0.308345
Average total loss: 0.485272
tensor(-14.1138, device='cuda:0') tensor(1.1427, device='cuda:0') tensor(-9.7596e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.181664
Average KL loss: 0.308344
Average total loss: 0.490008
tensor(-14.1139, device='cuda:0') tensor(1.1427, device='cuda:0') tensor(-1.6670e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.178180
Average KL loss: 0.308343
Average total loss: 0.486523
tensor(-14.1139, device='cuda:0') tensor(1.1428, device='cuda:0') tensor(-1.7459e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.181310
Average KL loss: 0.308341
Average total loss: 0.489651
tensor(-14.1140, device='cuda:0') tensor(1.1428, device='cuda:0') tensor(-5.9244e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.177954
Average KL loss: 0.308340
Average total loss: 0.486294
tensor(-14.1140, device='cuda:0') tensor(1.1429, device='cuda:0') tensor(-1.0507e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.179868
Average KL loss: 0.308339
Average total loss: 0.488206
tensor(-14.1141, device='cuda:0') tensor(1.1429, device='cuda:0') tensor(-8.6939e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.179285
Average KL loss: 0.308337
Average total loss: 0.487623
tensor(-14.1141, device='cuda:0') tensor(1.1429, device='cuda:0') tensor(-1.2587e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.176789
Average KL loss: 0.308336
Average total loss: 0.485125
tensor(-14.1142, device='cuda:0') tensor(1.1430, device='cuda:0') tensor(4.2297e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.180202
Average KL loss: 0.308335
Average total loss: 0.488536
tensor(-14.1142, device='cuda:0') tensor(1.1430, device='cuda:0') tensor(-2.2645e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.184628
Average KL loss: 0.308334
Average total loss: 0.492961
tensor(-14.1142, device='cuda:0') tensor(1.1430, device='cuda:0') tensor(8.4110e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.176553
Average KL loss: 0.308332
Average total loss: 0.484885
tensor(-14.1143, device='cuda:0') tensor(1.1431, device='cuda:0') tensor(3.4441e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.180820
Average KL loss: 0.308331
Average total loss: 0.489150
tensor(-14.1143, device='cuda:0') tensor(1.1431, device='cuda:0') tensor(-3.9822e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.180805
Average KL loss: 0.308329
Average total loss: 0.489134
tensor(-14.1144, device='cuda:0') tensor(1.1432, device='cuda:0') tensor(-1.8033e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.179699
Average KL loss: 0.308328
Average total loss: 0.488027
tensor(-14.1144, device='cuda:0') tensor(1.1432, device='cuda:0') tensor(9.1494e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.179905
Average KL loss: 0.308327
Average total loss: 0.488232
tensor(-14.1145, device='cuda:0') tensor(1.1432, device='cuda:0') tensor(-1.5654e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.179637
Average KL loss: 0.308325
Average total loss: 0.487962
tensor(-14.1145, device='cuda:0') tensor(1.1433, device='cuda:0') tensor(-2.5603e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.179683
Average KL loss: 0.308324
Average total loss: 0.488007
tensor(-14.1146, device='cuda:0') tensor(1.1433, device='cuda:0') tensor(-2.4281e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.182068
Average KL loss: 0.308322
Average total loss: 0.490390
tensor(-14.1146, device='cuda:0') tensor(1.1434, device='cuda:0') tensor(-8.9554e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.178730
Average KL loss: 0.308321
Average total loss: 0.487050
tensor(-14.1147, device='cuda:0') tensor(1.1434, device='cuda:0') tensor(-2.5425e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.179174
Average KL loss: 0.308320
Average total loss: 0.487494
tensor(-14.1147, device='cuda:0') tensor(1.1434, device='cuda:0') tensor(-1.4739e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.180614
Average KL loss: 0.308320
Average total loss: 0.488933
tensor(-14.1148, device='cuda:0') tensor(1.1435, device='cuda:0') tensor(-1.8070e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.178848
Average KL loss: 0.308318
Average total loss: 0.487166
tensor(-14.1148, device='cuda:0') tensor(1.1435, device='cuda:0') tensor(-2.7487e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.178051
Average KL loss: 0.308318
Average total loss: 0.486369
tensor(-14.1148, device='cuda:0') tensor(1.1435, device='cuda:0') tensor(-2.3072e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.182204
Average KL loss: 0.308317
Average total loss: 0.490522
tensor(-14.1148, device='cuda:0') tensor(1.1435, device='cuda:0') tensor(-3.6285e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.179698
Average KL loss: 0.308317
Average total loss: 0.488016
tensor(-14.1148, device='cuda:0') tensor(1.1435, device='cuda:0') tensor(-1.9713e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.182147
Average KL loss: 0.308317
Average total loss: 0.490464
tensor(-14.1148, device='cuda:0') tensor(1.1435, device='cuda:0') tensor(-1.0265e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.178964
Average KL loss: 0.308317
Average total loss: 0.487281
tensor(-14.1148, device='cuda:0') tensor(1.1435, device='cuda:0') tensor(-5.3102e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.178348
Average KL loss: 0.308317
Average total loss: 0.486666
tensor(-14.1148, device='cuda:0') tensor(1.1435, device='cuda:0') tensor(3.0603e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.179926
Average KL loss: 0.308317
Average total loss: 0.488244
tensor(-14.1148, device='cuda:0') tensor(1.1435, device='cuda:0') tensor(-9.5687e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.179609
Average KL loss: 0.308317
Average total loss: 0.487926
tensor(-14.1148, device='cuda:0') tensor(1.1435, device='cuda:0') tensor(1.9481e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.180386
Average KL loss: 0.308317
Average total loss: 0.488703
tensor(-14.1148, device='cuda:0') tensor(1.1435, device='cuda:0') tensor(-1.7579e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.179637
Average KL loss: 0.308317
Average total loss: 0.487954
tensor(-14.1148, device='cuda:0') tensor(1.1436, device='cuda:0') tensor(-1.1193e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.177432
Average KL loss: 0.308317
Average total loss: 0.485749
tensor(-14.1148, device='cuda:0') tensor(1.1436, device='cuda:0') tensor(-2.6636e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.176702
Average KL loss: 0.308317
Average total loss: 0.485019
tensor(-14.1148, device='cuda:0') tensor(1.1436, device='cuda:0') tensor(2.4644e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.177180
Average KL loss: 0.308317
Average total loss: 0.485496
tensor(-14.1148, device='cuda:0') tensor(1.1436, device='cuda:0') tensor(-1.5280e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.177991
Average KL loss: 0.308317
Average total loss: 0.486308
tensor(-14.1148, device='cuda:0') tensor(1.1436, device='cuda:0') tensor(-8.6224e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.179647
Average KL loss: 0.308316
Average total loss: 0.487964
tensor(-14.1148, device='cuda:0') tensor(1.1436, device='cuda:0') tensor(-6.5687e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.177376
Average KL loss: 0.308316
Average total loss: 0.485693
tensor(-14.1148, device='cuda:0') tensor(1.1436, device='cuda:0') tensor(8.6164e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.179217
Average KL loss: 0.308316
Average total loss: 0.487534
tensor(-14.1148, device='cuda:0') tensor(1.1436, device='cuda:0') tensor(-1.3490e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.177674
Average KL loss: 0.308316
Average total loss: 0.485990
tensor(-14.1148, device='cuda:0') tensor(1.1436, device='cuda:0') tensor(-1.0013e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.178976
Average KL loss: 0.308316
Average total loss: 0.487293
tensor(-14.1148, device='cuda:0') tensor(1.1436, device='cuda:0') tensor(3.8638e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.178557
Average KL loss: 0.308316
Average total loss: 0.486874
tensor(-14.1148, device='cuda:0') tensor(1.1436, device='cuda:0') tensor(-1.4561e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.178550
Average KL loss: 0.308316
Average total loss: 0.486866
tensor(-14.1148, device='cuda:0') tensor(1.1436, device='cuda:0') tensor(-1.8894e-09, device='cuda:0')
 Percentile value: -13.642486953735352
Non-zero model percentage: 1.4411613941192627%, Non-zero mask percentage: 1.4411613941192627%

--- Pruning Level [19/24]: ---
conv1.weight         | nonzeros =    1069 /    1728             ( 61.86%) | total_pruned =     659 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    3739 /   36864             ( 10.14%) | total_pruned =   33125 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4083 /   36864             ( 11.08%) | total_pruned =   32781 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3440 /   36864             (  9.33%) | total_pruned =   33424 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3385 /   36864             (  9.18%) | total_pruned =   33479 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    6756 /   73728             (  9.16%) | total_pruned =   66972 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   10092 /  147456             (  6.84%) | total_pruned =  137364 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2067 /    8192             ( 25.23%) | total_pruned =    6125 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    7078 /  147456             (  4.80%) | total_pruned =  140378 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    6796 /  147456             (  4.61%) | total_pruned =  140660 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   14892 /  294912             (  5.05%) | total_pruned =  280020 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     125 /     256             ( 48.83%) | total_pruned =     131 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   19430 /  589824             (  3.29%) | total_pruned =  570394 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3977 /   32768             ( 12.14%) | total_pruned =   28791 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     224 /     256             ( 87.50%) | total_pruned =      32 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     115 /     256             ( 44.92%) | total_pruned =     141 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    8391 /  589824             (  1.42%) | total_pruned =  581433 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     115 /     256             ( 44.92%) | total_pruned =     141 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      62 /     256             ( 24.22%) | total_pruned =     194 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    8742 /  589824             (  1.48%) | total_pruned =  581082 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     204 /     256             ( 79.69%) | total_pruned =      52 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      79 /     256             ( 30.86%) | total_pruned =     177 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   16842 / 1179648             (  1.43%) | total_pruned = 1162806 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     273 /     512             ( 53.32%) | total_pruned =     239 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     137 /     512             ( 26.76%) | total_pruned =     375 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   14227 / 2359296             (  0.60%) | total_pruned = 2345069 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     339 /     512             ( 66.21%) | total_pruned =     173 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     217 /     512             ( 42.38%) | total_pruned =     295 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3804 /  131072             (  2.90%) | total_pruned =  127268 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     262 /     512             ( 51.17%) | total_pruned =     250 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     216 /     512             ( 42.19%) | total_pruned =     296 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    6913 / 2359296             (  0.29%) | total_pruned = 2352383 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     113 /     512             ( 22.07%) | total_pruned =     399 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      34 /     512             (  6.64%) | total_pruned =     478 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    7878 / 2359296             (  0.33%) | total_pruned = 2351418 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     101 /     512             ( 19.73%) | total_pruned =     411 | shape = torch.Size([512])
linear.weight        | nonzeros =    2658 /    5120             ( 51.91%) | total_pruned =    2462 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 161104, pruned : 11017658, total: 11178762, Compression rate :      69.39x  ( 98.56% pruned)
Train Epoch: 22/100 Loss: 0.016768 Accuracy: 86.11 100.00 % Best test Accuracy: 86.11%
tensor(-14.1148, device='cuda:0') tensor(1.1436, device='cuda:0') tensor(-5.0398e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.258237
Average KL loss: 0.308040
Average total loss: 0.566277
tensor(-14.1157, device='cuda:0') tensor(1.1204, device='cuda:0') tensor(2.4084e-11, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.256715
Average KL loss: 0.307790
Average total loss: 0.564506
tensor(-14.1164, device='cuda:0') tensor(1.1081, device='cuda:0') tensor(2.6551e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.255917
Average KL loss: 0.307662
Average total loss: 0.563580
tensor(-14.1170, device='cuda:0') tensor(1.1007, device='cuda:0') tensor(-1.7670e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.251993
Average KL loss: 0.307570
Average total loss: 0.559563
tensor(-14.1174, device='cuda:0') tensor(1.0961, device='cuda:0') tensor(-3.8411e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.251321
Average KL loss: 0.307499
Average total loss: 0.558820
tensor(-14.1178, device='cuda:0') tensor(1.0934, device='cuda:0') tensor(-2.3103e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.257152
Average KL loss: 0.307450
Average total loss: 0.564602
tensor(-14.1182, device='cuda:0') tensor(1.0917, device='cuda:0') tensor(-1.1241e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.252598
Average KL loss: 0.307410
Average total loss: 0.560008
tensor(-14.1186, device='cuda:0') tensor(1.0908, device='cuda:0') tensor(-7.9134e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.250437
Average KL loss: 0.307374
Average total loss: 0.557810
tensor(-14.1190, device='cuda:0') tensor(1.0903, device='cuda:0') tensor(8.1748e-11, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.247680
Average KL loss: 0.307332
Average total loss: 0.555012
tensor(-14.1193, device='cuda:0') tensor(1.0900, device='cuda:0') tensor(-4.3972e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.245109
Average KL loss: 0.307293
Average total loss: 0.552402
tensor(-14.1197, device='cuda:0') tensor(1.0899, device='cuda:0') tensor(-3.5742e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.246614
Average KL loss: 0.307262
Average total loss: 0.553876
tensor(-14.1200, device='cuda:0') tensor(1.0899, device='cuda:0') tensor(-3.3858e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.243394
Average KL loss: 0.307227
Average total loss: 0.550621
tensor(-14.1204, device='cuda:0') tensor(1.0901, device='cuda:0') tensor(5.4503e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.247800
Average KL loss: 0.307198
Average total loss: 0.554998
tensor(-14.1207, device='cuda:0') tensor(1.0903, device='cuda:0') tensor(6.6021e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.241096
Average KL loss: 0.307174
Average total loss: 0.548270
tensor(-14.1211, device='cuda:0') tensor(1.0907, device='cuda:0') tensor(-3.4908e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.241626
Average KL loss: 0.307147
Average total loss: 0.548772
tensor(-14.1214, device='cuda:0') tensor(1.0909, device='cuda:0') tensor(5.3896e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.239887
Average KL loss: 0.307119
Average total loss: 0.547006
tensor(-14.1217, device='cuda:0') tensor(1.0912, device='cuda:0') tensor(-1.8472e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.240683
Average KL loss: 0.307091
Average total loss: 0.547774
tensor(-14.1221, device='cuda:0') tensor(1.0914, device='cuda:0') tensor(-3.6932e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.238032
Average KL loss: 0.307066
Average total loss: 0.545098
tensor(-14.1224, device='cuda:0') tensor(1.0918, device='cuda:0') tensor(-2.5126e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.236223
Average KL loss: 0.307041
Average total loss: 0.543264
tensor(-14.1228, device='cuda:0') tensor(1.0921, device='cuda:0') tensor(-1.5426e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.235382
Average KL loss: 0.307010
Average total loss: 0.542392
tensor(-14.1231, device='cuda:0') tensor(1.0924, device='cuda:0') tensor(-1.7254e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.231218
Average KL loss: 0.306980
Average total loss: 0.538198
tensor(-14.1235, device='cuda:0') tensor(1.0927, device='cuda:0') tensor(-4.6345e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.233612
Average KL loss: 0.306956
Average total loss: 0.540567
tensor(-14.1238, device='cuda:0') tensor(1.0931, device='cuda:0') tensor(-4.0097e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.232069
Average KL loss: 0.306933
Average total loss: 0.539002
tensor(-14.1241, device='cuda:0') tensor(1.0935, device='cuda:0') tensor(-4.6685e-11, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.231240
Average KL loss: 0.306903
Average total loss: 0.538143
tensor(-14.1245, device='cuda:0') tensor(1.0938, device='cuda:0') tensor(-7.6228e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.228867
Average KL loss: 0.306883
Average total loss: 0.535751
tensor(-14.1248, device='cuda:0') tensor(1.0943, device='cuda:0') tensor(-5.9048e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.234919
Average KL loss: 0.306864
Average total loss: 0.541783
tensor(-14.1251, device='cuda:0') tensor(1.0947, device='cuda:0') tensor(-2.9389e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.228426
Average KL loss: 0.306848
Average total loss: 0.535273
tensor(-14.1255, device='cuda:0') tensor(1.0951, device='cuda:0') tensor(-9.1498e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.229778
Average KL loss: 0.306833
Average total loss: 0.536611
tensor(-14.1258, device='cuda:0') tensor(1.0954, device='cuda:0') tensor(-4.8814e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.228816
Average KL loss: 0.306813
Average total loss: 0.535630
tensor(-14.1262, device='cuda:0') tensor(1.0958, device='cuda:0') tensor(2.7640e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.228715
Average KL loss: 0.306794
Average total loss: 0.535509
tensor(-14.1265, device='cuda:0') tensor(1.0962, device='cuda:0') tensor(3.9249e-11, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.228012
Average KL loss: 0.306773
Average total loss: 0.534785
tensor(-14.1268, device='cuda:0') tensor(1.0965, device='cuda:0') tensor(-5.2586e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.226565
Average KL loss: 0.306747
Average total loss: 0.533312
tensor(-14.1272, device='cuda:0') tensor(1.0970, device='cuda:0') tensor(1.2785e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.229626
Average KL loss: 0.306725
Average total loss: 0.536351
tensor(-14.1275, device='cuda:0') tensor(1.0974, device='cuda:0') tensor(3.3225e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.225129
Average KL loss: 0.306700
Average total loss: 0.531829
tensor(-14.1278, device='cuda:0') tensor(1.0978, device='cuda:0') tensor(-1.7622e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.220911
Average KL loss: 0.306673
Average total loss: 0.527584
tensor(-14.1282, device='cuda:0') tensor(1.0982, device='cuda:0') tensor(-2.2234e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.224285
Average KL loss: 0.306654
Average total loss: 0.530939
tensor(-14.1285, device='cuda:0') tensor(1.0985, device='cuda:0') tensor(-3.3071e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.224582
Average KL loss: 0.306627
Average total loss: 0.531209
tensor(-14.1289, device='cuda:0') tensor(1.0990, device='cuda:0') tensor(-4.1635e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.222695
Average KL loss: 0.306601
Average total loss: 0.529296
tensor(-14.1292, device='cuda:0') tensor(1.0994, device='cuda:0') tensor(-2.7869e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.224301
Average KL loss: 0.306583
Average total loss: 0.530883
tensor(-14.1295, device='cuda:0') tensor(1.0997, device='cuda:0') tensor(-2.9517e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.222368
Average KL loss: 0.306562
Average total loss: 0.528930
tensor(-14.1299, device='cuda:0') tensor(1.1001, device='cuda:0') tensor(-2.3915e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.218528
Average KL loss: 0.306535
Average total loss: 0.525063
tensor(-14.1302, device='cuda:0') tensor(1.1005, device='cuda:0') tensor(-4.3712e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.223677
Average KL loss: 0.306525
Average total loss: 0.530202
tensor(-14.1305, device='cuda:0') tensor(1.1010, device='cuda:0') tensor(5.3956e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.221168
Average KL loss: 0.306504
Average total loss: 0.527672
tensor(-14.1309, device='cuda:0') tensor(1.1014, device='cuda:0') tensor(-2.3566e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.220834
Average KL loss: 0.306490
Average total loss: 0.527324
tensor(-14.1312, device='cuda:0') tensor(1.1018, device='cuda:0') tensor(-1.8833e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.219368
Average KL loss: 0.306472
Average total loss: 0.525840
tensor(-14.1315, device='cuda:0') tensor(1.1023, device='cuda:0') tensor(-2.7515e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.214524
Average KL loss: 0.306449
Average total loss: 0.520972
tensor(-14.1319, device='cuda:0') tensor(1.1026, device='cuda:0') tensor(-6.2011e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.216933
Average KL loss: 0.306430
Average total loss: 0.523363
tensor(-14.1322, device='cuda:0') tensor(1.1030, device='cuda:0') tensor(-3.7365e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.216490
Average KL loss: 0.306406
Average total loss: 0.522896
tensor(-14.1325, device='cuda:0') tensor(1.1034, device='cuda:0') tensor(4.7080e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.216376
Average KL loss: 0.306387
Average total loss: 0.522763
tensor(-14.1329, device='cuda:0') tensor(1.1038, device='cuda:0') tensor(1.2743e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.216652
Average KL loss: 0.306361
Average total loss: 0.523013
tensor(-14.1332, device='cuda:0') tensor(1.1042, device='cuda:0') tensor(-7.4397e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.217908
Average KL loss: 0.306331
Average total loss: 0.524239
tensor(-14.1336, device='cuda:0') tensor(1.1046, device='cuda:0') tensor(-5.6134e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.213952
Average KL loss: 0.306308
Average total loss: 0.520260
tensor(-14.1339, device='cuda:0') tensor(1.1050, device='cuda:0') tensor(1.7334e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.212526
Average KL loss: 0.306288
Average total loss: 0.518814
tensor(-14.1342, device='cuda:0') tensor(1.1054, device='cuda:0') tensor(-4.5919e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.214168
Average KL loss: 0.306276
Average total loss: 0.520443
tensor(-14.1346, device='cuda:0') tensor(1.1057, device='cuda:0') tensor(-3.1358e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.212871
Average KL loss: 0.306261
Average total loss: 0.519132
tensor(-14.1349, device='cuda:0') tensor(1.1061, device='cuda:0') tensor(-8.5807e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.217883
Average KL loss: 0.306245
Average total loss: 0.524128
tensor(-14.1352, device='cuda:0') tensor(1.1064, device='cuda:0') tensor(-7.0067e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.217647
Average KL loss: 0.306227
Average total loss: 0.523874
tensor(-14.1356, device='cuda:0') tensor(1.1068, device='cuda:0') tensor(-2.7744e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.213139
Average KL loss: 0.306209
Average total loss: 0.519348
tensor(-14.1359, device='cuda:0') tensor(1.1072, device='cuda:0') tensor(-1.4871e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.211385
Average KL loss: 0.306187
Average total loss: 0.517572
tensor(-14.1362, device='cuda:0') tensor(1.1075, device='cuda:0') tensor(4.0599e-11, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.210599
Average KL loss: 0.306161
Average total loss: 0.516760
tensor(-14.1366, device='cuda:0') tensor(1.1079, device='cuda:0') tensor(-8.2404e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.208750
Average KL loss: 0.306140
Average total loss: 0.514890
tensor(-14.1369, device='cuda:0') tensor(1.1083, device='cuda:0') tensor(6.9478e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.211407
Average KL loss: 0.306121
Average total loss: 0.517528
tensor(-14.1372, device='cuda:0') tensor(1.1087, device='cuda:0') tensor(-1.2533e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.208479
Average KL loss: 0.306103
Average total loss: 0.514582
tensor(-14.1376, device='cuda:0') tensor(1.1091, device='cuda:0') tensor(1.8076e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.208523
Average KL loss: 0.306085
Average total loss: 0.514608
tensor(-14.1379, device='cuda:0') tensor(1.1094, device='cuda:0') tensor(1.4820e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.208119
Average KL loss: 0.306065
Average total loss: 0.514184
tensor(-14.1382, device='cuda:0') tensor(1.1098, device='cuda:0') tensor(-2.2199e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.212358
Average KL loss: 0.306052
Average total loss: 0.518409
tensor(-14.1386, device='cuda:0') tensor(1.1103, device='cuda:0') tensor(-2.2932e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.208555
Average KL loss: 0.306043
Average total loss: 0.514597
tensor(-14.1389, device='cuda:0') tensor(1.1107, device='cuda:0') tensor(-6.5403e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.209189
Average KL loss: 0.306026
Average total loss: 0.515215
tensor(-14.1393, device='cuda:0') tensor(1.1110, device='cuda:0') tensor(-4.1120e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.211073
Average KL loss: 0.306011
Average total loss: 0.517083
tensor(-14.1396, device='cuda:0') tensor(1.1114, device='cuda:0') tensor(-3.4372e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.206797
Average KL loss: 0.305993
Average total loss: 0.512790
tensor(-14.1399, device='cuda:0') tensor(1.1119, device='cuda:0') tensor(1.1408e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.203853
Average KL loss: 0.305973
Average total loss: 0.509826
tensor(-14.1403, device='cuda:0') tensor(1.1122, device='cuda:0') tensor(-6.5108e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.207677
Average KL loss: 0.305956
Average total loss: 0.513633
tensor(-14.1406, device='cuda:0') tensor(1.1127, device='cuda:0') tensor(-3.8190e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.208412
Average KL loss: 0.305949
Average total loss: 0.514361
tensor(-14.1409, device='cuda:0') tensor(1.1131, device='cuda:0') tensor(-3.0975e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.205151
Average KL loss: 0.305929
Average total loss: 0.511080
tensor(-14.1413, device='cuda:0') tensor(1.1134, device='cuda:0') tensor(-1.5448e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.205929
Average KL loss: 0.305907
Average total loss: 0.511836
tensor(-14.1416, device='cuda:0') tensor(1.1138, device='cuda:0') tensor(-2.3807e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.207239
Average KL loss: 0.305886
Average total loss: 0.513125
tensor(-14.1419, device='cuda:0') tensor(1.1142, device='cuda:0') tensor(-2.2388e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.204818
Average KL loss: 0.305870
Average total loss: 0.510688
tensor(-14.1423, device='cuda:0') tensor(1.1145, device='cuda:0') tensor(-5.2732e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.205731
Average KL loss: 0.305853
Average total loss: 0.511584
tensor(-14.1426, device='cuda:0') tensor(1.1149, device='cuda:0') tensor(-1.2195e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.202104
Average KL loss: 0.305838
Average total loss: 0.507942
tensor(-14.1429, device='cuda:0') tensor(1.1153, device='cuda:0') tensor(-2.7961e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.202970
Average KL loss: 0.305824
Average total loss: 0.508795
tensor(-14.1433, device='cuda:0') tensor(1.1157, device='cuda:0') tensor(2.1660e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.203668
Average KL loss: 0.305807
Average total loss: 0.509475
tensor(-14.1436, device='cuda:0') tensor(1.1160, device='cuda:0') tensor(-1.5706e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.202651
Average KL loss: 0.305789
Average total loss: 0.508441
tensor(-14.1439, device='cuda:0') tensor(1.1164, device='cuda:0') tensor(-7.9084e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.203410
Average KL loss: 0.305771
Average total loss: 0.509181
tensor(-14.1443, device='cuda:0') tensor(1.1168, device='cuda:0') tensor(6.1096e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.203286
Average KL loss: 0.305754
Average total loss: 0.509040
tensor(-14.1446, device='cuda:0') tensor(1.1172, device='cuda:0') tensor(-2.4651e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.203334
Average KL loss: 0.305735
Average total loss: 0.509069
tensor(-14.1449, device='cuda:0') tensor(1.1175, device='cuda:0') tensor(-1.9854e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.202981
Average KL loss: 0.305721
Average total loss: 0.508702
tensor(-14.1453, device='cuda:0') tensor(1.1179, device='cuda:0') tensor(-1.5974e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.200307
Average KL loss: 0.305709
Average total loss: 0.506016
tensor(-14.1456, device='cuda:0') tensor(1.1183, device='cuda:0') tensor(-2.8482e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.202732
Average KL loss: 0.305697
Average total loss: 0.508429
tensor(-14.1459, device='cuda:0') tensor(1.1187, device='cuda:0') tensor(9.4873e-12, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.202153
Average KL loss: 0.305687
Average total loss: 0.507840
tensor(-14.1463, device='cuda:0') tensor(1.1191, device='cuda:0') tensor(-1.0176e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.202776
Average KL loss: 0.305672
Average total loss: 0.508448
tensor(-14.1466, device='cuda:0') tensor(1.1195, device='cuda:0') tensor(-3.3010e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.201897
Average KL loss: 0.305655
Average total loss: 0.507552
tensor(-14.1469, device='cuda:0') tensor(1.1198, device='cuda:0') tensor(-1.8224e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.201599
Average KL loss: 0.305631
Average total loss: 0.507230
tensor(-14.1473, device='cuda:0') tensor(1.1202, device='cuda:0') tensor(-8.4232e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.198793
Average KL loss: 0.305615
Average total loss: 0.504408
tensor(-14.1476, device='cuda:0') tensor(1.1205, device='cuda:0') tensor(-5.3263e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.199843
Average KL loss: 0.305602
Average total loss: 0.505445
tensor(-14.1479, device='cuda:0') tensor(1.1209, device='cuda:0') tensor(8.4465e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.199036
Average KL loss: 0.305582
Average total loss: 0.504618
tensor(-14.1483, device='cuda:0') tensor(1.1212, device='cuda:0') tensor(-4.1338e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.198574
Average KL loss: 0.305565
Average total loss: 0.504139
tensor(-14.1486, device='cuda:0') tensor(1.1216, device='cuda:0') tensor(-2.4535e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.200518
Average KL loss: 0.305551
Average total loss: 0.506069
tensor(-14.1489, device='cuda:0') tensor(1.1220, device='cuda:0') tensor(-2.4617e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.201857
Average KL loss: 0.305535
Average total loss: 0.507392
tensor(-14.1493, device='cuda:0') tensor(1.1224, device='cuda:0') tensor(1.0487e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.199267
Average KL loss: 0.305517
Average total loss: 0.504784
tensor(-14.1496, device='cuda:0') tensor(1.1228, device='cuda:0') tensor(1.9110e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.196297
Average KL loss: 0.305499
Average total loss: 0.501797
tensor(-14.1499, device='cuda:0') tensor(1.1231, device='cuda:0') tensor(4.7365e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.195405
Average KL loss: 0.305484
Average total loss: 0.500889
tensor(-14.1503, device='cuda:0') tensor(1.1235, device='cuda:0') tensor(1.0279e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.201523
Average KL loss: 0.305467
Average total loss: 0.506990
tensor(-14.1506, device='cuda:0') tensor(1.1238, device='cuda:0') tensor(1.0170e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.198187
Average KL loss: 0.305447
Average total loss: 0.503634
tensor(-14.1509, device='cuda:0') tensor(1.1241, device='cuda:0') tensor(4.4765e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.198001
Average KL loss: 0.305433
Average total loss: 0.503434
tensor(-14.1513, device='cuda:0') tensor(1.1245, device='cuda:0') tensor(-3.4574e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.200667
Average KL loss: 0.305418
Average total loss: 0.506085
tensor(-14.1516, device='cuda:0') tensor(1.1249, device='cuda:0') tensor(-1.4661e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.197128
Average KL loss: 0.305401
Average total loss: 0.502529
tensor(-14.1519, device='cuda:0') tensor(1.1253, device='cuda:0') tensor(-8.4689e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.199134
Average KL loss: 0.305388
Average total loss: 0.504522
tensor(-14.1523, device='cuda:0') tensor(1.1257, device='cuda:0') tensor(-2.5115e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.196486
Average KL loss: 0.305373
Average total loss: 0.501859
tensor(-14.1526, device='cuda:0') tensor(1.1261, device='cuda:0') tensor(-7.5986e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.196208
Average KL loss: 0.305359
Average total loss: 0.501567
tensor(-14.1529, device='cuda:0') tensor(1.1265, device='cuda:0') tensor(-4.9501e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.194709
Average KL loss: 0.305349
Average total loss: 0.500058
tensor(-14.1533, device='cuda:0') tensor(1.1268, device='cuda:0') tensor(-4.4924e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.197970
Average KL loss: 0.305339
Average total loss: 0.503308
tensor(-14.1536, device='cuda:0') tensor(1.1272, device='cuda:0') tensor(-5.7622e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.197197
Average KL loss: 0.305325
Average total loss: 0.502522
tensor(-14.1539, device='cuda:0') tensor(1.1276, device='cuda:0') tensor(-1.9888e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.195668
Average KL loss: 0.305308
Average total loss: 0.500976
tensor(-14.1543, device='cuda:0') tensor(1.1280, device='cuda:0') tensor(-7.4199e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.196955
Average KL loss: 0.305289
Average total loss: 0.502243
tensor(-14.1546, device='cuda:0') tensor(1.1283, device='cuda:0') tensor(-2.5737e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.194333
Average KL loss: 0.305279
Average total loss: 0.499612
tensor(-14.1549, device='cuda:0') tensor(1.1286, device='cuda:0') tensor(-1.1836e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.196452
Average KL loss: 0.305267
Average total loss: 0.501719
tensor(-14.1553, device='cuda:0') tensor(1.1290, device='cuda:0') tensor(-8.9233e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.192506
Average KL loss: 0.305251
Average total loss: 0.497757
tensor(-14.1556, device='cuda:0') tensor(1.1294, device='cuda:0') tensor(-2.4061e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.195542
Average KL loss: 0.305238
Average total loss: 0.500780
tensor(-14.1559, device='cuda:0') tensor(1.1297, device='cuda:0') tensor(-7.2395e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.196406
Average KL loss: 0.305224
Average total loss: 0.501629
tensor(-14.1563, device='cuda:0') tensor(1.1301, device='cuda:0') tensor(-2.3955e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.190308
Average KL loss: 0.305205
Average total loss: 0.495513
tensor(-14.1566, device='cuda:0') tensor(1.1304, device='cuda:0') tensor(-9.0482e-11, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.193988
Average KL loss: 0.305192
Average total loss: 0.499180
tensor(-14.1569, device='cuda:0') tensor(1.1308, device='cuda:0') tensor(-2.0006e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.192994
Average KL loss: 0.305181
Average total loss: 0.498175
tensor(-14.1573, device='cuda:0') tensor(1.1312, device='cuda:0') tensor(2.0830e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.191730
Average KL loss: 0.305166
Average total loss: 0.496895
tensor(-14.1576, device='cuda:0') tensor(1.1315, device='cuda:0') tensor(-5.2533e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.191547
Average KL loss: 0.305153
Average total loss: 0.496700
tensor(-14.1579, device='cuda:0') tensor(1.1319, device='cuda:0') tensor(1.5251e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.194179
Average KL loss: 0.305139
Average total loss: 0.499317
tensor(-14.1583, device='cuda:0') tensor(1.1322, device='cuda:0') tensor(-2.3424e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.192119
Average KL loss: 0.305127
Average total loss: 0.497246
tensor(-14.1586, device='cuda:0') tensor(1.1326, device='cuda:0') tensor(-4.5011e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.192679
Average KL loss: 0.305113
Average total loss: 0.497792
tensor(-14.1589, device='cuda:0') tensor(1.1329, device='cuda:0') tensor(1.1790e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.189280
Average KL loss: 0.305097
Average total loss: 0.494377
tensor(-14.1592, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-7.4517e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.192694
Average KL loss: 0.305083
Average total loss: 0.497776
tensor(-14.1596, device='cuda:0') tensor(1.1335, device='cuda:0') tensor(-2.0880e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.188867
Average KL loss: 0.305067
Average total loss: 0.493934
tensor(-14.1599, device='cuda:0') tensor(1.1339, device='cuda:0') tensor(-1.0579e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.191565
Average KL loss: 0.305053
Average total loss: 0.496619
tensor(-14.1602, device='cuda:0') tensor(1.1342, device='cuda:0') tensor(-2.5436e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.192689
Average KL loss: 0.305032
Average total loss: 0.497721
tensor(-14.1606, device='cuda:0') tensor(1.1346, device='cuda:0') tensor(-1.1774e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.189877
Average KL loss: 0.305013
Average total loss: 0.494890
tensor(-14.1609, device='cuda:0') tensor(1.1349, device='cuda:0') tensor(-1.2009e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.188459
Average KL loss: 0.304996
Average total loss: 0.493456
tensor(-14.1612, device='cuda:0') tensor(1.1353, device='cuda:0') tensor(-4.5127e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.191821
Average KL loss: 0.304976
Average total loss: 0.496797
tensor(-14.1615, device='cuda:0') tensor(1.1356, device='cuda:0') tensor(-1.7317e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.189519
Average KL loss: 0.304951
Average total loss: 0.494470
tensor(-14.1619, device='cuda:0') tensor(1.1360, device='cuda:0') tensor(-2.5002e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.187906
Average KL loss: 0.304937
Average total loss: 0.492843
tensor(-14.1622, device='cuda:0') tensor(1.1363, device='cuda:0') tensor(-2.0981e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.189477
Average KL loss: 0.304919
Average total loss: 0.494396
tensor(-14.1625, device='cuda:0') tensor(1.1367, device='cuda:0') tensor(6.1943e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.189853
Average KL loss: 0.304903
Average total loss: 0.494756
tensor(-14.1628, device='cuda:0') tensor(1.1370, device='cuda:0') tensor(-1.1405e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.186133
Average KL loss: 0.304883
Average total loss: 0.491016
tensor(-14.1632, device='cuda:0') tensor(1.1374, device='cuda:0') tensor(-1.0514e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.188684
Average KL loss: 0.304867
Average total loss: 0.493550
tensor(-14.1635, device='cuda:0') tensor(1.1377, device='cuda:0') tensor(1.8551e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.188483
Average KL loss: 0.304847
Average total loss: 0.493331
tensor(-14.1638, device='cuda:0') tensor(1.1380, device='cuda:0') tensor(-1.3441e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.186187
Average KL loss: 0.304831
Average total loss: 0.491018
tensor(-14.1641, device='cuda:0') tensor(1.1384, device='cuda:0') tensor(-1.8170e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.188121
Average KL loss: 0.304816
Average total loss: 0.492937
tensor(-14.1645, device='cuda:0') tensor(1.1387, device='cuda:0') tensor(-1.0997e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.184389
Average KL loss: 0.304806
Average total loss: 0.489195
tensor(-14.1648, device='cuda:0') tensor(1.1390, device='cuda:0') tensor(-2.7295e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.184112
Average KL loss: 0.304794
Average total loss: 0.488906
tensor(-14.1651, device='cuda:0') tensor(1.1393, device='cuda:0') tensor(-2.3419e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.184252
Average KL loss: 0.304777
Average total loss: 0.489029
tensor(-14.1654, device='cuda:0') tensor(1.1396, device='cuda:0') tensor(-1.4849e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.186901
Average KL loss: 0.304759
Average total loss: 0.491659
tensor(-14.1657, device='cuda:0') tensor(1.1400, device='cuda:0') tensor(-1.8780e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.185949
Average KL loss: 0.304746
Average total loss: 0.490694
tensor(-14.1661, device='cuda:0') tensor(1.1404, device='cuda:0') tensor(1.0461e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.185643
Average KL loss: 0.304736
Average total loss: 0.490378
tensor(-14.1664, device='cuda:0') tensor(1.1407, device='cuda:0') tensor(-2.3586e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.185579
Average KL loss: 0.304716
Average total loss: 0.490295
tensor(-14.1667, device='cuda:0') tensor(1.1410, device='cuda:0') tensor(7.4768e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.182289
Average KL loss: 0.304699
Average total loss: 0.486988
tensor(-14.1670, device='cuda:0') tensor(1.1414, device='cuda:0') tensor(-3.3507e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.182991
Average KL loss: 0.304680
Average total loss: 0.487671
tensor(-14.1673, device='cuda:0') tensor(1.1418, device='cuda:0') tensor(-6.3784e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.187338
Average KL loss: 0.304667
Average total loss: 0.492005
tensor(-14.1677, device='cuda:0') tensor(1.1422, device='cuda:0') tensor(-1.4952e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.187282
Average KL loss: 0.304646
Average total loss: 0.491928
tensor(-14.1680, device='cuda:0') tensor(1.1425, device='cuda:0') tensor(-2.6891e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.186882
Average KL loss: 0.304629
Average total loss: 0.491511
tensor(-14.1683, device='cuda:0') tensor(1.1429, device='cuda:0') tensor(-4.0138e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.180714
Average KL loss: 0.304612
Average total loss: 0.485326
tensor(-14.1686, device='cuda:0') tensor(1.1432, device='cuda:0') tensor(-1.5433e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.185622
Average KL loss: 0.304597
Average total loss: 0.490219
tensor(-14.1689, device='cuda:0') tensor(1.1435, device='cuda:0') tensor(-9.8575e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.184547
Average KL loss: 0.304582
Average total loss: 0.489130
tensor(-14.1693, device='cuda:0') tensor(1.1439, device='cuda:0') tensor(1.6182e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.185532
Average KL loss: 0.304565
Average total loss: 0.490097
tensor(-14.1696, device='cuda:0') tensor(1.1443, device='cuda:0') tensor(-2.9857e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.183586
Average KL loss: 0.304545
Average total loss: 0.488131
tensor(-14.1699, device='cuda:0') tensor(1.1446, device='cuda:0') tensor(3.4293e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.182756
Average KL loss: 0.304526
Average total loss: 0.487282
tensor(-14.1702, device='cuda:0') tensor(1.1449, device='cuda:0') tensor(-2.0884e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.183817
Average KL loss: 0.304507
Average total loss: 0.488325
tensor(-14.1705, device='cuda:0') tensor(1.1452, device='cuda:0') tensor(-1.8022e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.184496
Average KL loss: 0.304485
Average total loss: 0.488981
tensor(-14.1708, device='cuda:0') tensor(1.1456, device='cuda:0') tensor(-1.7212e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.184061
Average KL loss: 0.304466
Average total loss: 0.488527
tensor(-14.1712, device='cuda:0') tensor(1.1460, device='cuda:0') tensor(-2.5922e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.183691
Average KL loss: 0.304454
Average total loss: 0.488145
tensor(-14.1715, device='cuda:0') tensor(1.1463, device='cuda:0') tensor(2.6751e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.182036
Average KL loss: 0.304440
Average total loss: 0.486476
tensor(-14.1718, device='cuda:0') tensor(1.1466, device='cuda:0') tensor(-1.5253e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.182488
Average KL loss: 0.304421
Average total loss: 0.486909
tensor(-14.1721, device='cuda:0') tensor(1.1470, device='cuda:0') tensor(-1.7702e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.184156
Average KL loss: 0.304411
Average total loss: 0.488567
tensor(-14.1721, device='cuda:0') tensor(1.1470, device='cuda:0') tensor(-2.0344e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.177951
Average KL loss: 0.304409
Average total loss: 0.482360
tensor(-14.1722, device='cuda:0') tensor(1.1470, device='cuda:0') tensor(-3.9634e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.183675
Average KL loss: 0.304407
Average total loss: 0.488082
tensor(-14.1722, device='cuda:0') tensor(1.1471, device='cuda:0') tensor(7.8277e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.186508
Average KL loss: 0.304406
Average total loss: 0.490914
tensor(-14.1723, device='cuda:0') tensor(1.1471, device='cuda:0') tensor(-7.0989e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.184749
Average KL loss: 0.304405
Average total loss: 0.489154
tensor(-14.1723, device='cuda:0') tensor(1.1471, device='cuda:0') tensor(2.4088e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.182432
Average KL loss: 0.304404
Average total loss: 0.486836
tensor(-14.1724, device='cuda:0') tensor(1.1472, device='cuda:0') tensor(-2.4259e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.182653
Average KL loss: 0.304403
Average total loss: 0.487056
tensor(-14.1724, device='cuda:0') tensor(1.1472, device='cuda:0') tensor(-1.3123e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.181643
Average KL loss: 0.304401
Average total loss: 0.486044
tensor(-14.1725, device='cuda:0') tensor(1.1472, device='cuda:0') tensor(-3.4053e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.182258
Average KL loss: 0.304399
Average total loss: 0.486657
tensor(-14.1725, device='cuda:0') tensor(1.1473, device='cuda:0') tensor(1.7981e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.182810
Average KL loss: 0.304397
Average total loss: 0.487207
tensor(-14.1726, device='cuda:0') tensor(1.1473, device='cuda:0') tensor(-1.8152e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.184202
Average KL loss: 0.304397
Average total loss: 0.488598
tensor(-14.1726, device='cuda:0') tensor(1.1474, device='cuda:0') tensor(-1.2880e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.182969
Average KL loss: 0.304395
Average total loss: 0.487364
tensor(-14.1727, device='cuda:0') tensor(1.1474, device='cuda:0') tensor(-9.9784e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.183558
Average KL loss: 0.304393
Average total loss: 0.487951
tensor(-14.1727, device='cuda:0') tensor(1.1474, device='cuda:0') tensor(-2.4903e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.179501
Average KL loss: 0.304392
Average total loss: 0.483893
tensor(-14.1727, device='cuda:0') tensor(1.1474, device='cuda:0') tensor(-8.9557e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.181894
Average KL loss: 0.304392
Average total loss: 0.486286
tensor(-14.1727, device='cuda:0') tensor(1.1474, device='cuda:0') tensor(-1.1290e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.182922
Average KL loss: 0.304392
Average total loss: 0.487314
tensor(-14.1727, device='cuda:0') tensor(1.1474, device='cuda:0') tensor(-2.1520e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.180788
Average KL loss: 0.304392
Average total loss: 0.485179
tensor(-14.1727, device='cuda:0') tensor(1.1474, device='cuda:0') tensor(-6.2998e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.181108
Average KL loss: 0.304392
Average total loss: 0.485500
tensor(-14.1727, device='cuda:0') tensor(1.1474, device='cuda:0') tensor(-6.0848e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.181926
Average KL loss: 0.304392
Average total loss: 0.486318
tensor(-14.1727, device='cuda:0') tensor(1.1474, device='cuda:0') tensor(-4.2167e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.182286
Average KL loss: 0.304391
Average total loss: 0.486678
tensor(-14.1727, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(-6.6184e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.183044
Average KL loss: 0.304391
Average total loss: 0.487436
tensor(-14.1727, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(9.0716e-11, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.180656
Average KL loss: 0.304391
Average total loss: 0.485047
tensor(-14.1727, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(-4.3399e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.181168
Average KL loss: 0.304391
Average total loss: 0.485559
tensor(-14.1727, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(-1.4364e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.183722
Average KL loss: 0.304391
Average total loss: 0.488113
tensor(-14.1727, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(-1.9992e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.179159
Average KL loss: 0.304391
Average total loss: 0.483550
tensor(-14.1727, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(2.4550e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.181529
Average KL loss: 0.304391
Average total loss: 0.485919
tensor(-14.1727, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(7.4368e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.183109
Average KL loss: 0.304391
Average total loss: 0.487500
tensor(-14.1727, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(-1.6796e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.183025
Average KL loss: 0.304391
Average total loss: 0.487416
tensor(-14.1727, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(-1.2574e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.182837
Average KL loss: 0.304391
Average total loss: 0.487228
tensor(-14.1727, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(-3.5034e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.182598
Average KL loss: 0.304391
Average total loss: 0.486989
tensor(-14.1727, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(-1.3024e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.182651
Average KL loss: 0.304391
Average total loss: 0.487042
tensor(-14.1727, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(-2.3569e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.184022
Average KL loss: 0.304391
Average total loss: 0.488413
 Percentile value: -13.672675132751465
Non-zero model percentage: 1.1529362201690674%, Non-zero mask percentage: 1.1529362201690674%

--- Pruning Level [20/24]: ---
conv1.weight         | nonzeros =    1016 /    1728             ( 58.80%) | total_pruned =     712 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    3086 /   36864             (  8.37%) | total_pruned =   33778 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    3356 /   36864             (  9.10%) | total_pruned =   33508 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2870 /   36864             (  7.79%) | total_pruned =   33994 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2814 /   36864             (  7.63%) | total_pruned =   34050 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    5557 /   73728             (  7.54%) | total_pruned =   68171 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    8113 /  147456             (  5.50%) | total_pruned =  139343 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1865 /    8192             ( 22.77%) | total_pruned =    6327 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    5638 /  147456             (  3.82%) | total_pruned =  141818 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    5451 /  147456             (  3.70%) | total_pruned =  142005 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   11939 /  294912             (  4.05%) | total_pruned =  282973 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     117 /     256             ( 45.70%) | total_pruned =     139 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   15281 /  589824             (  2.59%) | total_pruned =  574543 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      84 /     256             ( 32.81%) | total_pruned =     172 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3406 /   32768             ( 10.39%) | total_pruned =   29362 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     103 /     256             ( 40.23%) | total_pruned =     153 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    6468 /  589824             (  1.10%) | total_pruned =  583356 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     114 /     256             ( 44.53%) | total_pruned =     142 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      52 /     256             ( 20.31%) | total_pruned =     204 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    6646 /  589824             (  1.13%) | total_pruned =  583178 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   12979 / 1179648             (  1.10%) | total_pruned = 1166669 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     273 /     512             ( 53.32%) | total_pruned =     239 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     117 /     512             ( 22.85%) | total_pruned =     395 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   10854 / 2359296             (  0.46%) | total_pruned = 2348442 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     338 /     512             ( 66.02%) | total_pruned =     174 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     181 /     512             ( 35.35%) | total_pruned =     331 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3051 /  131072             (  2.33%) | total_pruned =  128021 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     261 /     512             ( 50.98%) | total_pruned =     251 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     189 /     512             ( 36.91%) | total_pruned =     323 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    5287 / 2359296             (  0.22%) | total_pruned = 2354009 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     113 /     512             ( 22.07%) | total_pruned =     399 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      29 /     512             (  5.66%) | total_pruned =     483 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    6095 / 2359296             (  0.26%) | total_pruned = 2353201 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      78 /     512             ( 15.23%) | total_pruned =     434 | shape = torch.Size([512])
linear.weight        | nonzeros =    2475 /    5120             ( 48.34%) | total_pruned =    2645 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 128884, pruned : 11049878, total: 11178762, Compression rate :      86.74x  ( 98.85% pruned)
Train Epoch: 24/100 Loss: 0.000053 Accuracy: 85.36 100.00 % Best test Accuracy: 85.53%
tensor(-14.1727, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(-1.7355e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.259923
Average KL loss: 0.304141
Average total loss: 0.564064
tensor(-14.1736, device='cuda:0') tensor(1.1247, device='cuda:0') tensor(-2.2990e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.259120
Average KL loss: 0.303914
Average total loss: 0.563034
tensor(-14.1743, device='cuda:0') tensor(1.1121, device='cuda:0') tensor(5.5175e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.253336
Average KL loss: 0.303786
Average total loss: 0.557122
tensor(-14.1748, device='cuda:0') tensor(1.1042, device='cuda:0') tensor(-1.5058e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.253924
Average KL loss: 0.303696
Average total loss: 0.557620
tensor(-14.1752, device='cuda:0') tensor(1.0992, device='cuda:0') tensor(5.1380e-11, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.255329
Average KL loss: 0.303624
Average total loss: 0.558953
tensor(-14.1756, device='cuda:0') tensor(1.0960, device='cuda:0') tensor(2.8864e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.254743
Average KL loss: 0.303571
Average total loss: 0.558313
tensor(-14.1760, device='cuda:0') tensor(1.0940, device='cuda:0') tensor(-4.8151e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.253961
Average KL loss: 0.303528
Average total loss: 0.557489
tensor(-14.1764, device='cuda:0') tensor(1.0928, device='cuda:0') tensor(-2.8265e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.250443
Average KL loss: 0.303482
Average total loss: 0.553925
tensor(-14.1767, device='cuda:0') tensor(1.0919, device='cuda:0') tensor(-3.8752e-12, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.250618
Average KL loss: 0.303442
Average total loss: 0.554060
tensor(-14.1770, device='cuda:0') tensor(1.0915, device='cuda:0') tensor(7.3777e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.249664
Average KL loss: 0.303404
Average total loss: 0.553068
tensor(-14.1774, device='cuda:0') tensor(1.0914, device='cuda:0') tensor(-4.0148e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.250396
Average KL loss: 0.303368
Average total loss: 0.553765
tensor(-14.1777, device='cuda:0') tensor(1.0913, device='cuda:0') tensor(-1.5235e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.248023
Average KL loss: 0.303336
Average total loss: 0.551358
tensor(-14.1780, device='cuda:0') tensor(1.0913, device='cuda:0') tensor(-3.4124e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.245698
Average KL loss: 0.303306
Average total loss: 0.549004
tensor(-14.1783, device='cuda:0') tensor(1.0914, device='cuda:0') tensor(-3.1170e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.246193
Average KL loss: 0.303270
Average total loss: 0.549463
tensor(-14.1787, device='cuda:0') tensor(1.0915, device='cuda:0') tensor(-1.6665e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.240246
Average KL loss: 0.303239
Average total loss: 0.543485
tensor(-14.1790, device='cuda:0') tensor(1.0917, device='cuda:0') tensor(-2.5943e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.245717
Average KL loss: 0.303205
Average total loss: 0.548922
tensor(-14.1793, device='cuda:0') tensor(1.0919, device='cuda:0') tensor(-8.3811e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.239375
Average KL loss: 0.303176
Average total loss: 0.542551
tensor(-14.1796, device='cuda:0') tensor(1.0922, device='cuda:0') tensor(-2.2904e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.241536
Average KL loss: 0.303143
Average total loss: 0.544679
tensor(-14.1799, device='cuda:0') tensor(1.0924, device='cuda:0') tensor(-1.4468e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.239999
Average KL loss: 0.303108
Average total loss: 0.543107
tensor(-14.1802, device='cuda:0') tensor(1.0927, device='cuda:0') tensor(-1.4808e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.236574
Average KL loss: 0.303073
Average total loss: 0.539647
tensor(-14.1805, device='cuda:0') tensor(1.0930, device='cuda:0') tensor(3.9131e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.235965
Average KL loss: 0.303040
Average total loss: 0.539005
tensor(-14.1809, device='cuda:0') tensor(1.0932, device='cuda:0') tensor(-1.3858e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.234071
Average KL loss: 0.303012
Average total loss: 0.537083
tensor(-14.1812, device='cuda:0') tensor(1.0936, device='cuda:0') tensor(-3.4325e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.236080
Average KL loss: 0.302989
Average total loss: 0.539069
tensor(-14.1815, device='cuda:0') tensor(1.0938, device='cuda:0') tensor(8.8726e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.237138
Average KL loss: 0.302956
Average total loss: 0.540095
tensor(-14.1818, device='cuda:0') tensor(1.0941, device='cuda:0') tensor(-1.9410e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.233535
Average KL loss: 0.302932
Average total loss: 0.536467
tensor(-14.1821, device='cuda:0') tensor(1.0945, device='cuda:0') tensor(-2.9374e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.233612
Average KL loss: 0.302907
Average total loss: 0.536519
tensor(-14.1824, device='cuda:0') tensor(1.0948, device='cuda:0') tensor(-1.6365e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.233376
Average KL loss: 0.302886
Average total loss: 0.536263
tensor(-14.1827, device='cuda:0') tensor(1.0951, device='cuda:0') tensor(6.7343e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.234959
Average KL loss: 0.302861
Average total loss: 0.537821
tensor(-14.1830, device='cuda:0') tensor(1.0955, device='cuda:0') tensor(-1.9205e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.229230
Average KL loss: 0.302836
Average total loss: 0.532066
tensor(-14.1834, device='cuda:0') tensor(1.0959, device='cuda:0') tensor(-5.3011e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.233757
Average KL loss: 0.302816
Average total loss: 0.536573
tensor(-14.1837, device='cuda:0') tensor(1.0962, device='cuda:0') tensor(-1.2590e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.232403
Average KL loss: 0.302790
Average total loss: 0.535193
tensor(-14.1840, device='cuda:0') tensor(1.0966, device='cuda:0') tensor(-8.4569e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.230258
Average KL loss: 0.302770
Average total loss: 0.533028
tensor(-14.1843, device='cuda:0') tensor(1.0969, device='cuda:0') tensor(-1.8986e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.230278
Average KL loss: 0.302748
Average total loss: 0.533026
tensor(-14.1846, device='cuda:0') tensor(1.0973, device='cuda:0') tensor(-3.4146e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.225790
Average KL loss: 0.302730
Average total loss: 0.528521
tensor(-14.1849, device='cuda:0') tensor(1.0977, device='cuda:0') tensor(-2.2819e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.230638
Average KL loss: 0.302707
Average total loss: 0.533345
tensor(-14.1852, device='cuda:0') tensor(1.0981, device='cuda:0') tensor(-1.7865e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.227716
Average KL loss: 0.302689
Average total loss: 0.530405
tensor(-14.1855, device='cuda:0') tensor(1.0985, device='cuda:0') tensor(6.9572e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.225372
Average KL loss: 0.302668
Average total loss: 0.528041
tensor(-14.1858, device='cuda:0') tensor(1.0989, device='cuda:0') tensor(-3.6329e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.227226
Average KL loss: 0.302642
Average total loss: 0.529867
tensor(-14.1861, device='cuda:0') tensor(1.0992, device='cuda:0') tensor(1.8344e-11, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.229418
Average KL loss: 0.302613
Average total loss: 0.532032
tensor(-14.1864, device='cuda:0') tensor(1.0996, device='cuda:0') tensor(-1.6003e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.222561
Average KL loss: 0.302592
Average total loss: 0.525154
tensor(-14.1868, device='cuda:0') tensor(1.1000, device='cuda:0') tensor(-1.5721e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.224963
Average KL loss: 0.302567
Average total loss: 0.527530
tensor(-14.1871, device='cuda:0') tensor(1.1003, device='cuda:0') tensor(-1.5394e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.224286
Average KL loss: 0.302541
Average total loss: 0.526827
tensor(-14.1874, device='cuda:0') tensor(1.1007, device='cuda:0') tensor(-2.0660e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.221036
Average KL loss: 0.302516
Average total loss: 0.523552
tensor(-14.1877, device='cuda:0') tensor(1.1010, device='cuda:0') tensor(-2.2427e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.227580
Average KL loss: 0.302492
Average total loss: 0.530072
tensor(-14.1880, device='cuda:0') tensor(1.1014, device='cuda:0') tensor(-5.0081e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.221664
Average KL loss: 0.302471
Average total loss: 0.524135
tensor(-14.1883, device='cuda:0') tensor(1.1018, device='cuda:0') tensor(1.6439e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.222244
Average KL loss: 0.302454
Average total loss: 0.524698
tensor(-14.1886, device='cuda:0') tensor(1.1021, device='cuda:0') tensor(2.2715e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.223705
Average KL loss: 0.302435
Average total loss: 0.526140
tensor(-14.1889, device='cuda:0') tensor(1.1025, device='cuda:0') tensor(-3.4866e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.223709
Average KL loss: 0.302414
Average total loss: 0.526123
tensor(-14.1892, device='cuda:0') tensor(1.1028, device='cuda:0') tensor(1.2196e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.218075
Average KL loss: 0.302392
Average total loss: 0.520466
tensor(-14.1895, device='cuda:0') tensor(1.1032, device='cuda:0') tensor(-1.5162e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.223736
Average KL loss: 0.302369
Average total loss: 0.526105
tensor(-14.1898, device='cuda:0') tensor(1.1036, device='cuda:0') tensor(-2.6162e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.223059
Average KL loss: 0.302352
Average total loss: 0.525410
tensor(-14.1901, device='cuda:0') tensor(1.1040, device='cuda:0') tensor(-2.6781e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.217138
Average KL loss: 0.302337
Average total loss: 0.519475
tensor(-14.1904, device='cuda:0') tensor(1.1044, device='cuda:0') tensor(9.0105e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.221329
Average KL loss: 0.302318
Average total loss: 0.523647
tensor(-14.1908, device='cuda:0') tensor(1.1048, device='cuda:0') tensor(-6.1677e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.217948
Average KL loss: 0.302295
Average total loss: 0.520243
tensor(-14.1911, device='cuda:0') tensor(1.1051, device='cuda:0') tensor(-3.7926e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.216930
Average KL loss: 0.302276
Average total loss: 0.519206
tensor(-14.1914, device='cuda:0') tensor(1.1055, device='cuda:0') tensor(-1.3581e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.218171
Average KL loss: 0.302262
Average total loss: 0.520433
tensor(-14.1917, device='cuda:0') tensor(1.1059, device='cuda:0') tensor(-5.1963e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.215446
Average KL loss: 0.302244
Average total loss: 0.517690
tensor(-14.1920, device='cuda:0') tensor(1.1063, device='cuda:0') tensor(-1.3798e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.216929
Average KL loss: 0.302221
Average total loss: 0.519150
tensor(-14.1923, device='cuda:0') tensor(1.1067, device='cuda:0') tensor(-2.0585e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.214186
Average KL loss: 0.302205
Average total loss: 0.516391
tensor(-14.1926, device='cuda:0') tensor(1.1070, device='cuda:0') tensor(-6.0555e-11, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.214236
Average KL loss: 0.302188
Average total loss: 0.516425
tensor(-14.1929, device='cuda:0') tensor(1.1073, device='cuda:0') tensor(-2.1046e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.214682
Average KL loss: 0.302170
Average total loss: 0.516852
tensor(-14.1932, device='cuda:0') tensor(1.1076, device='cuda:0') tensor(-2.3505e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.213262
Average KL loss: 0.302150
Average total loss: 0.515412
tensor(-14.1935, device='cuda:0') tensor(1.1079, device='cuda:0') tensor(-1.8284e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.215311
Average KL loss: 0.302130
Average total loss: 0.517442
tensor(-14.1938, device='cuda:0') tensor(1.1083, device='cuda:0') tensor(-2.3969e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.215078
Average KL loss: 0.302114
Average total loss: 0.517192
tensor(-14.1941, device='cuda:0') tensor(1.1087, device='cuda:0') tensor(-5.0725e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.212948
Average KL loss: 0.302099
Average total loss: 0.515047
tensor(-14.1944, device='cuda:0') tensor(1.1090, device='cuda:0') tensor(-1.2498e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.214001
Average KL loss: 0.302080
Average total loss: 0.516080
tensor(-14.1947, device='cuda:0') tensor(1.1094, device='cuda:0') tensor(3.8392e-11, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.215505
Average KL loss: 0.302065
Average total loss: 0.517569
tensor(-14.1951, device='cuda:0') tensor(1.1097, device='cuda:0') tensor(8.8659e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.211426
Average KL loss: 0.302048
Average total loss: 0.513474
tensor(-14.1954, device='cuda:0') tensor(1.1100, device='cuda:0') tensor(-3.0363e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.211017
Average KL loss: 0.302030
Average total loss: 0.513046
tensor(-14.1957, device='cuda:0') tensor(1.1104, device='cuda:0') tensor(-8.3912e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.212144
Average KL loss: 0.302014
Average total loss: 0.514157
tensor(-14.1960, device='cuda:0') tensor(1.1107, device='cuda:0') tensor(5.1579e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.209284
Average KL loss: 0.301989
Average total loss: 0.511273
tensor(-14.1963, device='cuda:0') tensor(1.1111, device='cuda:0') tensor(-1.3191e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.211392
Average KL loss: 0.301967
Average total loss: 0.513359
tensor(-14.1966, device='cuda:0') tensor(1.1114, device='cuda:0') tensor(-1.4042e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.210930
Average KL loss: 0.301957
Average total loss: 0.512887
tensor(-14.1969, device='cuda:0') tensor(1.1117, device='cuda:0') tensor(-1.3091e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.209068
Average KL loss: 0.301938
Average total loss: 0.511006
tensor(-14.1972, device='cuda:0') tensor(1.1121, device='cuda:0') tensor(-2.9179e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.209926
Average KL loss: 0.301918
Average total loss: 0.511844
tensor(-14.1975, device='cuda:0') tensor(1.1125, device='cuda:0') tensor(-3.3811e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.206925
Average KL loss: 0.301902
Average total loss: 0.508827
tensor(-14.1978, device='cuda:0') tensor(1.1128, device='cuda:0') tensor(-6.5261e-11, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.211471
Average KL loss: 0.301880
Average total loss: 0.513351
tensor(-14.1981, device='cuda:0') tensor(1.1132, device='cuda:0') tensor(-3.0233e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.210126
Average KL loss: 0.301854
Average total loss: 0.511980
tensor(-14.1984, device='cuda:0') tensor(1.1135, device='cuda:0') tensor(1.0824e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.210292
Average KL loss: 0.301832
Average total loss: 0.512124
tensor(-14.1987, device='cuda:0') tensor(1.1138, device='cuda:0') tensor(-2.9119e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.208105
Average KL loss: 0.301815
Average total loss: 0.509919
tensor(-14.1990, device='cuda:0') tensor(1.1141, device='cuda:0') tensor(-2.0109e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.209173
Average KL loss: 0.301791
Average total loss: 0.510964
tensor(-14.1993, device='cuda:0') tensor(1.1145, device='cuda:0') tensor(9.7054e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.205169
Average KL loss: 0.301771
Average total loss: 0.506940
tensor(-14.1996, device='cuda:0') tensor(1.1148, device='cuda:0') tensor(-1.6609e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.208961
Average KL loss: 0.301749
Average total loss: 0.510710
tensor(-14.2000, device='cuda:0') tensor(1.1151, device='cuda:0') tensor(-1.8748e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.211196
Average KL loss: 0.301723
Average total loss: 0.512920
tensor(-14.2003, device='cuda:0') tensor(1.1154, device='cuda:0') tensor(6.1446e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.204816
Average KL loss: 0.301708
Average total loss: 0.506524
tensor(-14.2006, device='cuda:0') tensor(1.1157, device='cuda:0') tensor(-6.8077e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.208645
Average KL loss: 0.301690
Average total loss: 0.510334
tensor(-14.2009, device='cuda:0') tensor(1.1161, device='cuda:0') tensor(2.1826e-11, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.207247
Average KL loss: 0.301684
Average total loss: 0.508930
tensor(-14.2012, device='cuda:0') tensor(1.1164, device='cuda:0') tensor(-2.7146e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.203520
Average KL loss: 0.301670
Average total loss: 0.505191
tensor(-14.2015, device='cuda:0') tensor(1.1168, device='cuda:0') tensor(-1.7087e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.205308
Average KL loss: 0.301657
Average total loss: 0.506965
tensor(-14.2018, device='cuda:0') tensor(1.1172, device='cuda:0') tensor(-2.1993e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.206053
Average KL loss: 0.301637
Average total loss: 0.507690
tensor(-14.2021, device='cuda:0') tensor(1.1175, device='cuda:0') tensor(-2.0775e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.205913
Average KL loss: 0.301614
Average total loss: 0.507526
tensor(-14.2024, device='cuda:0') tensor(1.1179, device='cuda:0') tensor(-1.5877e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.204361
Average KL loss: 0.301591
Average total loss: 0.505952
tensor(-14.2027, device='cuda:0') tensor(1.1182, device='cuda:0') tensor(-1.4069e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.205065
Average KL loss: 0.301566
Average total loss: 0.506631
tensor(-14.2030, device='cuda:0') tensor(1.1185, device='cuda:0') tensor(6.9705e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.203973
Average KL loss: 0.301542
Average total loss: 0.505515
tensor(-14.2033, device='cuda:0') tensor(1.1188, device='cuda:0') tensor(-2.1099e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.204818
Average KL loss: 0.301519
Average total loss: 0.506336
tensor(-14.2036, device='cuda:0') tensor(1.1191, device='cuda:0') tensor(-1.0432e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.204577
Average KL loss: 0.301498
Average total loss: 0.506074
tensor(-14.2039, device='cuda:0') tensor(1.1194, device='cuda:0') tensor(3.7667e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.199506
Average KL loss: 0.301479
Average total loss: 0.500984
tensor(-14.2042, device='cuda:0') tensor(1.1197, device='cuda:0') tensor(-1.0918e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.201934
Average KL loss: 0.301456
Average total loss: 0.503390
tensor(-14.2045, device='cuda:0') tensor(1.1201, device='cuda:0') tensor(-1.2159e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.205233
Average KL loss: 0.301442
Average total loss: 0.506675
tensor(-14.2048, device='cuda:0') tensor(1.1205, device='cuda:0') tensor(1.6778e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.203431
Average KL loss: 0.301420
Average total loss: 0.504852
tensor(-14.2051, device='cuda:0') tensor(1.1208, device='cuda:0') tensor(-1.1082e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.199631
Average KL loss: 0.301397
Average total loss: 0.501028
tensor(-14.2054, device='cuda:0') tensor(1.1211, device='cuda:0') tensor(1.8714e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.201292
Average KL loss: 0.301377
Average total loss: 0.502669
tensor(-14.2057, device='cuda:0') tensor(1.1215, device='cuda:0') tensor(-1.0848e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.203100
Average KL loss: 0.301358
Average total loss: 0.504458
tensor(-14.2060, device='cuda:0') tensor(1.1218, device='cuda:0') tensor(1.9079e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.201658
Average KL loss: 0.301338
Average total loss: 0.502996
tensor(-14.2063, device='cuda:0') tensor(1.1221, device='cuda:0') tensor(5.9045e-11, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.200400
Average KL loss: 0.301312
Average total loss: 0.501712
tensor(-14.2066, device='cuda:0') tensor(1.1224, device='cuda:0') tensor(-3.6969e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.200061
Average KL loss: 0.301289
Average total loss: 0.501349
tensor(-14.2070, device='cuda:0') tensor(1.1228, device='cuda:0') tensor(1.2129e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.199035
Average KL loss: 0.301270
Average total loss: 0.500305
tensor(-14.2073, device='cuda:0') tensor(1.1231, device='cuda:0') tensor(2.5446e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.198517
Average KL loss: 0.301247
Average total loss: 0.499764
tensor(-14.2076, device='cuda:0') tensor(1.1234, device='cuda:0') tensor(-9.4245e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.201577
Average KL loss: 0.301229
Average total loss: 0.502806
tensor(-14.2079, device='cuda:0') tensor(1.1239, device='cuda:0') tensor(-5.4131e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.200611
Average KL loss: 0.301210
Average total loss: 0.501820
tensor(-14.2082, device='cuda:0') tensor(1.1242, device='cuda:0') tensor(-2.1190e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.200498
Average KL loss: 0.301189
Average total loss: 0.501687
tensor(-14.2085, device='cuda:0') tensor(1.1246, device='cuda:0') tensor(-2.7359e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.198405
Average KL loss: 0.301173
Average total loss: 0.499578
tensor(-14.2088, device='cuda:0') tensor(1.1249, device='cuda:0') tensor(-1.7602e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.195458
Average KL loss: 0.301149
Average total loss: 0.496607
tensor(-14.2091, device='cuda:0') tensor(1.1252, device='cuda:0') tensor(1.2032e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.198659
Average KL loss: 0.301121
Average total loss: 0.499781
tensor(-14.2094, device='cuda:0') tensor(1.1255, device='cuda:0') tensor(6.6375e-11, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.198943
Average KL loss: 0.301107
Average total loss: 0.500049
tensor(-14.2097, device='cuda:0') tensor(1.1259, device='cuda:0') tensor(-2.0390e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.195826
Average KL loss: 0.301085
Average total loss: 0.496911
tensor(-14.2100, device='cuda:0') tensor(1.1262, device='cuda:0') tensor(1.7937e-11, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.198397
Average KL loss: 0.301064
Average total loss: 0.499461
tensor(-14.2103, device='cuda:0') tensor(1.1265, device='cuda:0') tensor(8.3789e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.195764
Average KL loss: 0.301042
Average total loss: 0.496806
tensor(-14.2106, device='cuda:0') tensor(1.1269, device='cuda:0') tensor(-3.8778e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.195841
Average KL loss: 0.301027
Average total loss: 0.496868
tensor(-14.2109, device='cuda:0') tensor(1.1272, device='cuda:0') tensor(-2.5240e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.198696
Average KL loss: 0.301006
Average total loss: 0.499702
tensor(-14.2112, device='cuda:0') tensor(1.1276, device='cuda:0') tensor(1.3009e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.196081
Average KL loss: 0.300989
Average total loss: 0.497070
tensor(-14.2115, device='cuda:0') tensor(1.1279, device='cuda:0') tensor(-9.5981e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.197083
Average KL loss: 0.300968
Average total loss: 0.498050
tensor(-14.2118, device='cuda:0') tensor(1.1283, device='cuda:0') tensor(-1.3213e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.197463
Average KL loss: 0.300949
Average total loss: 0.498412
tensor(-14.2121, device='cuda:0') tensor(1.1286, device='cuda:0') tensor(2.2972e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.193951
Average KL loss: 0.300929
Average total loss: 0.494879
tensor(-14.2124, device='cuda:0') tensor(1.1288, device='cuda:0') tensor(-2.2620e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.196645
Average KL loss: 0.300907
Average total loss: 0.497552
tensor(-14.2127, device='cuda:0') tensor(1.1292, device='cuda:0') tensor(-2.3938e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.194611
Average KL loss: 0.300891
Average total loss: 0.495502
tensor(-14.2130, device='cuda:0') tensor(1.1296, device='cuda:0') tensor(8.3058e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.196044
Average KL loss: 0.300870
Average total loss: 0.496914
tensor(-14.2133, device='cuda:0') tensor(1.1299, device='cuda:0') tensor(-6.2477e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.198450
Average KL loss: 0.300851
Average total loss: 0.499300
tensor(-14.2136, device='cuda:0') tensor(1.1302, device='cuda:0') tensor(-1.6812e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.194703
Average KL loss: 0.300833
Average total loss: 0.495536
tensor(-14.2139, device='cuda:0') tensor(1.1305, device='cuda:0') tensor(-4.9720e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.195019
Average KL loss: 0.300806
Average total loss: 0.495826
tensor(-14.2142, device='cuda:0') tensor(1.1308, device='cuda:0') tensor(-1.0286e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.192980
Average KL loss: 0.300784
Average total loss: 0.493764
tensor(-14.2145, device='cuda:0') tensor(1.1311, device='cuda:0') tensor(-4.0121e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.195328
Average KL loss: 0.300767
Average total loss: 0.496095
tensor(-14.2148, device='cuda:0') tensor(1.1315, device='cuda:0') tensor(1.9526e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.191164
Average KL loss: 0.300741
Average total loss: 0.491906
tensor(-14.2151, device='cuda:0') tensor(1.1318, device='cuda:0') tensor(1.3578e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.196039
Average KL loss: 0.300721
Average total loss: 0.496760
tensor(-14.2154, device='cuda:0') tensor(1.1322, device='cuda:0') tensor(4.5338e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.191298
Average KL loss: 0.300699
Average total loss: 0.491997
tensor(-14.2157, device='cuda:0') tensor(1.1325, device='cuda:0') tensor(1.5050e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.194565
Average KL loss: 0.300681
Average total loss: 0.495247
tensor(-14.2160, device='cuda:0') tensor(1.1328, device='cuda:0') tensor(1.9847e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.192401
Average KL loss: 0.300665
Average total loss: 0.493066
tensor(-14.2163, device='cuda:0') tensor(1.1331, device='cuda:0') tensor(-1.7577e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.190416
Average KL loss: 0.300645
Average total loss: 0.491061
tensor(-14.2166, device='cuda:0') tensor(1.1335, device='cuda:0') tensor(1.1925e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.190981
Average KL loss: 0.300626
Average total loss: 0.491607
tensor(-14.2169, device='cuda:0') tensor(1.1338, device='cuda:0') tensor(2.2022e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.191420
Average KL loss: 0.300606
Average total loss: 0.492026
tensor(-14.2172, device='cuda:0') tensor(1.1341, device='cuda:0') tensor(1.4180e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.191197
Average KL loss: 0.300582
Average total loss: 0.491780
tensor(-14.2175, device='cuda:0') tensor(1.1345, device='cuda:0') tensor(1.3347e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.190146
Average KL loss: 0.300563
Average total loss: 0.490709
tensor(-14.2178, device='cuda:0') tensor(1.1347, device='cuda:0') tensor(7.5939e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.194398
Average KL loss: 0.300541
Average total loss: 0.494939
tensor(-14.2181, device='cuda:0') tensor(1.1351, device='cuda:0') tensor(-6.2522e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.189195
Average KL loss: 0.300521
Average total loss: 0.489715
tensor(-14.2184, device='cuda:0') tensor(1.1354, device='cuda:0') tensor(8.0866e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.194048
Average KL loss: 0.300511
Average total loss: 0.494558
tensor(-14.2187, device='cuda:0') tensor(1.1358, device='cuda:0') tensor(-1.3199e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.191746
Average KL loss: 0.300491
Average total loss: 0.492237
tensor(-14.2190, device='cuda:0') tensor(1.1361, device='cuda:0') tensor(-9.1076e-11, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.189184
Average KL loss: 0.300473
Average total loss: 0.489658
tensor(-14.2193, device='cuda:0') tensor(1.1364, device='cuda:0') tensor(-2.0501e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.188583
Average KL loss: 0.300456
Average total loss: 0.489039
tensor(-14.2196, device='cuda:0') tensor(1.1368, device='cuda:0') tensor(8.5362e-12, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.188844
Average KL loss: 0.300437
Average total loss: 0.489281
tensor(-14.2199, device='cuda:0') tensor(1.1371, device='cuda:0') tensor(-2.6563e-11, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.189445
Average KL loss: 0.300420
Average total loss: 0.489865
tensor(-14.2202, device='cuda:0') tensor(1.1374, device='cuda:0') tensor(-1.2068e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.192341
Average KL loss: 0.300409
Average total loss: 0.492750
tensor(-14.2205, device='cuda:0') tensor(1.1378, device='cuda:0') tensor(-1.3378e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.190896
Average KL loss: 0.300390
Average total loss: 0.491286
tensor(-14.2208, device='cuda:0') tensor(1.1381, device='cuda:0') tensor(-1.3882e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.189159
Average KL loss: 0.300365
Average total loss: 0.489524
tensor(-14.2211, device='cuda:0') tensor(1.1384, device='cuda:0') tensor(-8.1663e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.188751
Average KL loss: 0.300344
Average total loss: 0.489095
tensor(-14.2214, device='cuda:0') tensor(1.1387, device='cuda:0') tensor(-2.6619e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.187983
Average KL loss: 0.300324
Average total loss: 0.488307
tensor(-14.2217, device='cuda:0') tensor(1.1390, device='cuda:0') tensor(-3.3272e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.188085
Average KL loss: 0.300304
Average total loss: 0.488389
tensor(-14.2220, device='cuda:0') tensor(1.1394, device='cuda:0') tensor(-4.1988e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.188443
Average KL loss: 0.300289
Average total loss: 0.488732
tensor(-14.2223, device='cuda:0') tensor(1.1397, device='cuda:0') tensor(-3.2287e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.187769
Average KL loss: 0.300273
Average total loss: 0.488042
tensor(-14.2226, device='cuda:0') tensor(1.1400, device='cuda:0') tensor(-6.9537e-11, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.189982
Average KL loss: 0.300258
Average total loss: 0.490240
tensor(-14.2229, device='cuda:0') tensor(1.1404, device='cuda:0') tensor(-2.0104e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.188640
Average KL loss: 0.300242
Average total loss: 0.488882
tensor(-14.2232, device='cuda:0') tensor(1.1407, device='cuda:0') tensor(-2.3562e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.186423
Average KL loss: 0.300226
Average total loss: 0.486650
tensor(-14.2235, device='cuda:0') tensor(1.1410, device='cuda:0') tensor(5.0680e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.188887
Average KL loss: 0.300204
Average total loss: 0.489091
tensor(-14.2238, device='cuda:0') tensor(1.1413, device='cuda:0') tensor(-2.2762e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.186617
Average KL loss: 0.300183
Average total loss: 0.486800
tensor(-14.2241, device='cuda:0') tensor(1.1417, device='cuda:0') tensor(-1.9446e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.190211
Average KL loss: 0.300166
Average total loss: 0.490377
tensor(-14.2244, device='cuda:0') tensor(1.1421, device='cuda:0') tensor(-4.4007e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.188145
Average KL loss: 0.300152
Average total loss: 0.488297
tensor(-14.2247, device='cuda:0') tensor(1.1425, device='cuda:0') tensor(1.2853e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.185209
Average KL loss: 0.300141
Average total loss: 0.485351
tensor(-14.2250, device='cuda:0') tensor(1.1428, device='cuda:0') tensor(3.9385e-12, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.187458
Average KL loss: 0.300127
Average total loss: 0.487585
tensor(-14.2253, device='cuda:0') tensor(1.1432, device='cuda:0') tensor(-9.9919e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.186843
Average KL loss: 0.300109
Average total loss: 0.486952
tensor(-14.2256, device='cuda:0') tensor(1.1434, device='cuda:0') tensor(9.3668e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.186879
Average KL loss: 0.300090
Average total loss: 0.486969
tensor(-14.2259, device='cuda:0') tensor(1.1437, device='cuda:0') tensor(-3.3144e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.187615
Average KL loss: 0.300070
Average total loss: 0.487685
tensor(-14.2262, device='cuda:0') tensor(1.1441, device='cuda:0') tensor(-2.3405e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.185855
Average KL loss: 0.300054
Average total loss: 0.485908
tensor(-14.2265, device='cuda:0') tensor(1.1444, device='cuda:0') tensor(-1.1220e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.186344
Average KL loss: 0.300035
Average total loss: 0.486379
tensor(-14.2268, device='cuda:0') tensor(1.1447, device='cuda:0') tensor(-4.7606e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.182987
Average KL loss: 0.300018
Average total loss: 0.483005
tensor(-14.2271, device='cuda:0') tensor(1.1450, device='cuda:0') tensor(-2.6731e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.184668
Average KL loss: 0.300005
Average total loss: 0.484673
tensor(-14.2274, device='cuda:0') tensor(1.1453, device='cuda:0') tensor(9.9823e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.184463
Average KL loss: 0.299990
Average total loss: 0.484454
tensor(-14.2277, device='cuda:0') tensor(1.1457, device='cuda:0') tensor(1.9172e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.187772
Average KL loss: 0.299967
Average total loss: 0.487738
tensor(-14.2280, device='cuda:0') tensor(1.1460, device='cuda:0') tensor(-2.1580e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.187143
Average KL loss: 0.299944
Average total loss: 0.487087
tensor(-14.2283, device='cuda:0') tensor(1.1463, device='cuda:0') tensor(1.2110e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.184633
Average KL loss: 0.299925
Average total loss: 0.484558
tensor(-14.2286, device='cuda:0') tensor(1.1467, device='cuda:0') tensor(-1.8521e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.184812
Average KL loss: 0.299914
Average total loss: 0.484726
tensor(-14.2289, device='cuda:0') tensor(1.1469, device='cuda:0') tensor(-2.0106e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.184915
Average KL loss: 0.299900
Average total loss: 0.484814
tensor(-14.2292, device='cuda:0') tensor(1.1472, device='cuda:0') tensor(-3.6941e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.183843
Average KL loss: 0.299883
Average total loss: 0.483726
tensor(-14.2295, device='cuda:0') tensor(1.1475, device='cuda:0') tensor(-1.6334e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.181587
Average KL loss: 0.299873
Average total loss: 0.481461
tensor(-14.2298, device='cuda:0') tensor(1.1479, device='cuda:0') tensor(-1.8102e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.183503
Average KL loss: 0.299862
Average total loss: 0.483365
tensor(-14.2301, device='cuda:0') tensor(1.1481, device='cuda:0') tensor(-1.5018e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.185305
Average KL loss: 0.299846
Average total loss: 0.485151
tensor(-14.2303, device='cuda:0') tensor(1.1484, device='cuda:0') tensor(-2.2669e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.185768
Average KL loss: 0.299827
Average total loss: 0.485595
tensor(-14.2306, device='cuda:0') tensor(1.1487, device='cuda:0') tensor(-2.1325e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.181331
Average KL loss: 0.299818
Average total loss: 0.481148
tensor(-14.2309, device='cuda:0') tensor(1.1490, device='cuda:0') tensor(-2.3262e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.181180
Average KL loss: 0.299806
Average total loss: 0.480986
tensor(-14.2312, device='cuda:0') tensor(1.1493, device='cuda:0') tensor(-2.0208e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.181603
Average KL loss: 0.299791
Average total loss: 0.481394
tensor(-14.2315, device='cuda:0') tensor(1.1497, device='cuda:0') tensor(-7.2215e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.184324
Average KL loss: 0.299779
Average total loss: 0.484103
tensor(-14.2318, device='cuda:0') tensor(1.1500, device='cuda:0') tensor(-8.9166e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.184906
Average KL loss: 0.299768
Average total loss: 0.484673
tensor(-14.2321, device='cuda:0') tensor(1.1504, device='cuda:0') tensor(-5.1608e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.180160
Average KL loss: 0.299749
Average total loss: 0.479909
tensor(-14.2324, device='cuda:0') tensor(1.1507, device='cuda:0') tensor(-1.6389e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.182132
Average KL loss: 0.299728
Average total loss: 0.481860
tensor(-14.2327, device='cuda:0') tensor(1.1510, device='cuda:0') tensor(-1.6027e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.181383
Average KL loss: 0.299713
Average total loss: 0.481095
tensor(-14.2330, device='cuda:0') tensor(1.1514, device='cuda:0') tensor(1.1656e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.184332
Average KL loss: 0.299699
Average total loss: 0.484031
tensor(-14.2333, device='cuda:0') tensor(1.1517, device='cuda:0') tensor(-1.3873e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.180172
Average KL loss: 0.299688
Average total loss: 0.479860
tensor(-14.2336, device='cuda:0') tensor(1.1520, device='cuda:0') tensor(-4.6170e-11, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.180213
Average KL loss: 0.299673
Average total loss: 0.479886
tensor(-14.2339, device='cuda:0') tensor(1.1523, device='cuda:0') tensor(4.9881e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.183148
Average KL loss: 0.299658
Average total loss: 0.482806
tensor(-14.2342, device='cuda:0') tensor(1.1526, device='cuda:0') tensor(-1.0741e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.183674
Average KL loss: 0.299650
Average total loss: 0.483324
tensor(-14.2345, device='cuda:0') tensor(1.1529, device='cuda:0') tensor(-7.0049e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.178596
Average KL loss: 0.299639
Average total loss: 0.478235
tensor(-14.2348, device='cuda:0') tensor(1.1532, device='cuda:0') tensor(-2.6723e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.179406
Average KL loss: 0.299625
Average total loss: 0.479031
 Percentile value: -13.715974617004395
Non-zero model percentage: 0.9223561882972717%, Non-zero mask percentage: 0.9223561882972717%

--- Pruning Level [21/24]: ---
conv1.weight         | nonzeros =     985 /    1728             ( 57.00%) | total_pruned =     743 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2542 /   36864             (  6.90%) | total_pruned =   34322 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2769 /   36864             (  7.51%) | total_pruned =   34095 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2344 /   36864             (  6.36%) | total_pruned =   34520 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2333 /   36864             (  6.33%) | total_pruned =   34531 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4556 /   73728             (  6.18%) | total_pruned =   69172 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    6466 /  147456             (  4.39%) | total_pruned =  140990 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1707 /    8192             ( 20.84%) | total_pruned =    6485 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4492 /  147456             (  3.05%) | total_pruned =  142964 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    4323 /  147456             (  2.93%) | total_pruned =  143133 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    9461 /  294912             (  3.21%) | total_pruned =  285451 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     109 /     256             ( 42.58%) | total_pruned =     147 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   11978 /  589824             (  2.03%) | total_pruned =  577846 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      73 /     256             ( 28.52%) | total_pruned =     183 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2958 /   32768             (  9.03%) | total_pruned =   29810 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      86 /     256             ( 33.59%) | total_pruned =     170 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    4964 /  589824             (  0.84%) | total_pruned =  584860 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     113 /     256             ( 44.14%) | total_pruned =     143 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      49 /     256             ( 19.14%) | total_pruned =     207 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    5066 /  589824             (  0.86%) | total_pruned =  584758 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     201 /     256             ( 78.52%) | total_pruned =      55 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      49 /     256             ( 19.14%) | total_pruned =     207 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   10019 / 1179648             (  0.85%) | total_pruned = 1169629 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     273 /     512             ( 53.32%) | total_pruned =     239 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     102 /     512             ( 19.92%) | total_pruned =     410 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    8212 / 2359296             (  0.35%) | total_pruned = 2351084 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     338 /     512             ( 66.02%) | total_pruned =     174 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     160 /     512             ( 31.25%) | total_pruned =     352 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2425 /  131072             (  1.85%) | total_pruned =  128647 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     260 /     512             ( 50.78%) | total_pruned =     252 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     163 /     512             ( 31.84%) | total_pruned =     349 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    4054 / 2359296             (  0.17%) | total_pruned = 2355242 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     112 /     512             ( 21.88%) | total_pruned =     400 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      27 /     512             (  5.27%) | total_pruned =     485 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    4693 / 2359296             (  0.20%) | total_pruned = 2354603 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      62 /     512             ( 12.11%) | total_pruned =     450 | shape = torch.Size([512])
linear.weight        | nonzeros =    2296 /    5120             ( 44.84%) | total_pruned =    2824 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 103108, pruned : 11075654, total: 11178762, Compression rate :     108.42x  ( 99.08% pruned)
Train Epoch: 25/100 Loss: 0.005530 Accuracy: 85.65 100.00 % Best test Accuracy: 85.69%
tensor(-14.2351, device='cuda:0') tensor(1.1534, device='cuda:0') tensor(-1.6200e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.280883
Average KL loss: 0.299403
Average total loss: 0.580286
tensor(-14.2359, device='cuda:0') tensor(1.1312, device='cuda:0') tensor(8.9749e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.281516
Average KL loss: 0.299206
Average total loss: 0.580722
tensor(-14.2366, device='cuda:0') tensor(1.1179, device='cuda:0') tensor(-7.1281e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.274847
Average KL loss: 0.299089
Average total loss: 0.573937
tensor(-14.2371, device='cuda:0') tensor(1.1092, device='cuda:0') tensor(1.4753e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.276384
Average KL loss: 0.299003
Average total loss: 0.575388
tensor(-14.2375, device='cuda:0') tensor(1.1035, device='cuda:0') tensor(-2.7293e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.270823
Average KL loss: 0.298945
Average total loss: 0.569768
tensor(-14.2379, device='cuda:0') tensor(1.0998, device='cuda:0') tensor(-9.2681e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.271270
Average KL loss: 0.298902
Average total loss: 0.570172
tensor(-14.2383, device='cuda:0') tensor(1.0973, device='cuda:0') tensor(1.6151e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.267398
Average KL loss: 0.298864
Average total loss: 0.566262
tensor(-14.2387, device='cuda:0') tensor(1.0956, device='cuda:0') tensor(-6.2895e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.263873
Average KL loss: 0.298827
Average total loss: 0.562699
tensor(-14.2390, device='cuda:0') tensor(1.0945, device='cuda:0') tensor(-7.7718e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.260539
Average KL loss: 0.298787
Average total loss: 0.559326
tensor(-14.2393, device='cuda:0') tensor(1.0938, device='cuda:0') tensor(-9.8361e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.263073
Average KL loss: 0.298743
Average total loss: 0.561816
tensor(-14.2396, device='cuda:0') tensor(1.0933, device='cuda:0') tensor(-1.8142e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.259080
Average KL loss: 0.298710
Average total loss: 0.557790
tensor(-14.2399, device='cuda:0') tensor(1.0930, device='cuda:0') tensor(-2.4872e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.259710
Average KL loss: 0.298683
Average total loss: 0.558393
tensor(-14.2402, device='cuda:0') tensor(1.0929, device='cuda:0') tensor(4.4139e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.256376
Average KL loss: 0.298661
Average total loss: 0.555037
tensor(-14.2405, device='cuda:0') tensor(1.0929, device='cuda:0') tensor(1.3070e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.251247
Average KL loss: 0.298638
Average total loss: 0.549885
tensor(-14.2408, device='cuda:0') tensor(1.0929, device='cuda:0') tensor(4.1297e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.254243
Average KL loss: 0.298616
Average total loss: 0.552859
tensor(-14.2411, device='cuda:0') tensor(1.0930, device='cuda:0') tensor(-1.1756e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.254829
Average KL loss: 0.298592
Average total loss: 0.553422
tensor(-14.2414, device='cuda:0') tensor(1.0931, device='cuda:0') tensor(-8.4229e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.251083
Average KL loss: 0.298574
Average total loss: 0.549657
tensor(-14.2417, device='cuda:0') tensor(1.0933, device='cuda:0') tensor(1.8968e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.250200
Average KL loss: 0.298551
Average total loss: 0.548751
tensor(-14.2420, device='cuda:0') tensor(1.0934, device='cuda:0') tensor(-2.5349e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.246498
Average KL loss: 0.298530
Average total loss: 0.545027
tensor(-14.2423, device='cuda:0') tensor(1.0936, device='cuda:0') tensor(4.4881e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.252822
Average KL loss: 0.298506
Average total loss: 0.551328
tensor(-14.2426, device='cuda:0') tensor(1.0938, device='cuda:0') tensor(9.9462e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.245250
Average KL loss: 0.298479
Average total loss: 0.543729
tensor(-14.2429, device='cuda:0') tensor(1.0941, device='cuda:0') tensor(-1.4128e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.245358
Average KL loss: 0.298454
Average total loss: 0.543812
tensor(-14.2432, device='cuda:0') tensor(1.0943, device='cuda:0') tensor(-5.6188e-11, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.243660
Average KL loss: 0.298421
Average total loss: 0.542080
tensor(-14.2435, device='cuda:0') tensor(1.0945, device='cuda:0') tensor(-9.8512e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.245804
Average KL loss: 0.298397
Average total loss: 0.544201
tensor(-14.2438, device='cuda:0') tensor(1.0948, device='cuda:0') tensor(-5.2542e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.246512
Average KL loss: 0.298383
Average total loss: 0.544895
tensor(-14.2441, device='cuda:0') tensor(1.0951, device='cuda:0') tensor(3.8108e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.241003
Average KL loss: 0.298361
Average total loss: 0.539364
tensor(-14.2444, device='cuda:0') tensor(1.0953, device='cuda:0') tensor(3.4708e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.242728
Average KL loss: 0.298339
Average total loss: 0.541067
tensor(-14.2447, device='cuda:0') tensor(1.0957, device='cuda:0') tensor(-2.7535e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.240083
Average KL loss: 0.298315
Average total loss: 0.538398
tensor(-14.2450, device='cuda:0') tensor(1.0960, device='cuda:0') tensor(1.5385e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.237640
Average KL loss: 0.298284
Average total loss: 0.535924
tensor(-14.2453, device='cuda:0') tensor(1.0963, device='cuda:0') tensor(-7.8206e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.240990
Average KL loss: 0.298259
Average total loss: 0.539250
tensor(-14.2456, device='cuda:0') tensor(1.0966, device='cuda:0') tensor(-9.3697e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.238711
Average KL loss: 0.298243
Average total loss: 0.536954
tensor(-14.2459, device='cuda:0') tensor(1.0969, device='cuda:0') tensor(-2.1386e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.233753
Average KL loss: 0.298226
Average total loss: 0.531979
tensor(-14.2462, device='cuda:0') tensor(1.0972, device='cuda:0') tensor(-1.5883e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.238017
Average KL loss: 0.298207
Average total loss: 0.536224
tensor(-14.2465, device='cuda:0') tensor(1.0975, device='cuda:0') tensor(-7.9178e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.236849
Average KL loss: 0.298191
Average total loss: 0.535040
tensor(-14.2467, device='cuda:0') tensor(1.0978, device='cuda:0') tensor(-1.9203e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.234220
Average KL loss: 0.298171
Average total loss: 0.532390
tensor(-14.2470, device='cuda:0') tensor(1.0981, device='cuda:0') tensor(-2.8491e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.237461
Average KL loss: 0.298151
Average total loss: 0.535611
tensor(-14.2473, device='cuda:0') tensor(1.0984, device='cuda:0') tensor(-2.6112e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.232331
Average KL loss: 0.298128
Average total loss: 0.530459
tensor(-14.2476, device='cuda:0') tensor(1.0987, device='cuda:0') tensor(-2.0889e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.234443
Average KL loss: 0.298107
Average total loss: 0.532549
tensor(-14.2479, device='cuda:0') tensor(1.0991, device='cuda:0') tensor(-2.0118e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.235640
Average KL loss: 0.298089
Average total loss: 0.533729
tensor(-14.2482, device='cuda:0') tensor(1.0994, device='cuda:0') tensor(-5.7245e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.234197
Average KL loss: 0.298066
Average total loss: 0.532263
tensor(-14.2485, device='cuda:0') tensor(1.0997, device='cuda:0') tensor(-2.8812e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.237684
Average KL loss: 0.298044
Average total loss: 0.535729
tensor(-14.2488, device='cuda:0') tensor(1.1001, device='cuda:0') tensor(-4.1158e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.231895
Average KL loss: 0.298032
Average total loss: 0.529927
tensor(-14.2491, device='cuda:0') tensor(1.1004, device='cuda:0') tensor(1.1935e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.235694
Average KL loss: 0.298015
Average total loss: 0.533709
tensor(-14.2494, device='cuda:0') tensor(1.1007, device='cuda:0') tensor(-7.5283e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.229959
Average KL loss: 0.297999
Average total loss: 0.527958
tensor(-14.2497, device='cuda:0') tensor(1.1010, device='cuda:0') tensor(-2.2700e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.231339
Average KL loss: 0.297980
Average total loss: 0.529319
tensor(-14.2500, device='cuda:0') tensor(1.1013, device='cuda:0') tensor(5.4872e-11, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.232037
Average KL loss: 0.297959
Average total loss: 0.529996
tensor(-14.2502, device='cuda:0') tensor(1.1016, device='cuda:0') tensor(1.2116e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.230439
Average KL loss: 0.297936
Average total loss: 0.528375
tensor(-14.2505, device='cuda:0') tensor(1.1020, device='cuda:0') tensor(1.5738e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.229491
Average KL loss: 0.297911
Average total loss: 0.527403
tensor(-14.2508, device='cuda:0') tensor(1.1023, device='cuda:0') tensor(-2.6976e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.227090
Average KL loss: 0.297892
Average total loss: 0.524982
tensor(-14.2511, device='cuda:0') tensor(1.1027, device='cuda:0') tensor(2.6099e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.228736
Average KL loss: 0.297874
Average total loss: 0.526610
tensor(-14.2514, device='cuda:0') tensor(1.1030, device='cuda:0') tensor(-1.2472e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.228904
Average KL loss: 0.297857
Average total loss: 0.526761
tensor(-14.2517, device='cuda:0') tensor(1.1033, device='cuda:0') tensor(-1.2935e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.228773
Average KL loss: 0.297828
Average total loss: 0.526601
tensor(-14.2520, device='cuda:0') tensor(1.1036, device='cuda:0') tensor(-3.1487e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.231251
Average KL loss: 0.297804
Average total loss: 0.529055
tensor(-14.2523, device='cuda:0') tensor(1.1040, device='cuda:0') tensor(-1.6635e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.224252
Average KL loss: 0.297785
Average total loss: 0.522037
tensor(-14.2526, device='cuda:0') tensor(1.1043, device='cuda:0') tensor(-3.5121e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.227051
Average KL loss: 0.297765
Average total loss: 0.524816
tensor(-14.2529, device='cuda:0') tensor(1.1046, device='cuda:0') tensor(-3.2133e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.225083
Average KL loss: 0.297741
Average total loss: 0.522824
tensor(-14.2532, device='cuda:0') tensor(1.1048, device='cuda:0') tensor(-1.1664e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.229361
Average KL loss: 0.297719
Average total loss: 0.527080
tensor(-14.2535, device='cuda:0') tensor(1.1051, device='cuda:0') tensor(-3.6807e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.228770
Average KL loss: 0.297702
Average total loss: 0.526472
tensor(-14.2537, device='cuda:0') tensor(1.1055, device='cuda:0') tensor(-2.1041e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.220631
Average KL loss: 0.297680
Average total loss: 0.518312
tensor(-14.2540, device='cuda:0') tensor(1.1058, device='cuda:0') tensor(-1.8229e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.225264
Average KL loss: 0.297652
Average total loss: 0.522915
tensor(-14.2543, device='cuda:0') tensor(1.1061, device='cuda:0') tensor(1.0319e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.224071
Average KL loss: 0.297634
Average total loss: 0.521705
tensor(-14.2546, device='cuda:0') tensor(1.1064, device='cuda:0') tensor(-1.2839e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.221361
Average KL loss: 0.297619
Average total loss: 0.518980
tensor(-14.2549, device='cuda:0') tensor(1.1068, device='cuda:0') tensor(-1.0617e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.223603
Average KL loss: 0.297599
Average total loss: 0.521202
tensor(-14.2552, device='cuda:0') tensor(1.1071, device='cuda:0') tensor(-2.2104e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.223601
Average KL loss: 0.297580
Average total loss: 0.521181
tensor(-14.2555, device='cuda:0') tensor(1.1074, device='cuda:0') tensor(1.5799e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.224898
Average KL loss: 0.297556
Average total loss: 0.522454
tensor(-14.2558, device='cuda:0') tensor(1.1077, device='cuda:0') tensor(-7.2226e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.222144
Average KL loss: 0.297529
Average total loss: 0.519674
tensor(-14.2561, device='cuda:0') tensor(1.1080, device='cuda:0') tensor(-2.3480e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.223677
Average KL loss: 0.297504
Average total loss: 0.521181
tensor(-14.2564, device='cuda:0') tensor(1.1084, device='cuda:0') tensor(-2.1355e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.221607
Average KL loss: 0.297475
Average total loss: 0.519083
tensor(-14.2566, device='cuda:0') tensor(1.1086, device='cuda:0') tensor(-1.3023e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.216811
Average KL loss: 0.297447
Average total loss: 0.514258
tensor(-14.2569, device='cuda:0') tensor(1.1089, device='cuda:0') tensor(-3.0931e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.219294
Average KL loss: 0.297425
Average total loss: 0.516719
tensor(-14.2572, device='cuda:0') tensor(1.1092, device='cuda:0') tensor(-1.5712e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.218806
Average KL loss: 0.297405
Average total loss: 0.516211
tensor(-14.2575, device='cuda:0') tensor(1.1096, device='cuda:0') tensor(-2.8105e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.220522
Average KL loss: 0.297380
Average total loss: 0.517902
tensor(-14.2578, device='cuda:0') tensor(1.1099, device='cuda:0') tensor(-2.0116e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.217194
Average KL loss: 0.297362
Average total loss: 0.514556
tensor(-14.2581, device='cuda:0') tensor(1.1102, device='cuda:0') tensor(-5.7306e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.217625
Average KL loss: 0.297343
Average total loss: 0.514968
tensor(-14.2584, device='cuda:0') tensor(1.1105, device='cuda:0') tensor(7.5032e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.218183
Average KL loss: 0.297319
Average total loss: 0.515502
tensor(-14.2587, device='cuda:0') tensor(1.1108, device='cuda:0') tensor(-4.2820e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.215520
Average KL loss: 0.297297
Average total loss: 0.512817
tensor(-14.2590, device='cuda:0') tensor(1.1111, device='cuda:0') tensor(-2.9612e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.218080
Average KL loss: 0.297273
Average total loss: 0.515354
tensor(-14.2593, device='cuda:0') tensor(1.1115, device='cuda:0') tensor(2.1225e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.219858
Average KL loss: 0.297245
Average total loss: 0.517103
tensor(-14.2595, device='cuda:0') tensor(1.1118, device='cuda:0') tensor(2.3818e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.218100
Average KL loss: 0.297226
Average total loss: 0.515326
tensor(-14.2598, device='cuda:0') tensor(1.1122, device='cuda:0') tensor(-4.2575e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.217921
Average KL loss: 0.297205
Average total loss: 0.515126
tensor(-14.2601, device='cuda:0') tensor(1.1125, device='cuda:0') tensor(4.6041e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.216511
Average KL loss: 0.297183
Average total loss: 0.513694
tensor(-14.2604, device='cuda:0') tensor(1.1127, device='cuda:0') tensor(2.5271e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.211467
Average KL loss: 0.297159
Average total loss: 0.508626
tensor(-14.2607, device='cuda:0') tensor(1.1131, device='cuda:0') tensor(-4.1631e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.216362
Average KL loss: 0.297145
Average total loss: 0.513507
tensor(-14.2610, device='cuda:0') tensor(1.1135, device='cuda:0') tensor(3.8007e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.213787
Average KL loss: 0.297128
Average total loss: 0.510915
tensor(-14.2613, device='cuda:0') tensor(1.1138, device='cuda:0') tensor(-1.2790e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.214043
Average KL loss: 0.297103
Average total loss: 0.511146
tensor(-14.2616, device='cuda:0') tensor(1.1141, device='cuda:0') tensor(6.2711e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.215741
Average KL loss: 0.297083
Average total loss: 0.512824
tensor(-14.2619, device='cuda:0') tensor(1.1144, device='cuda:0') tensor(-1.6436e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.212776
Average KL loss: 0.297065
Average total loss: 0.509841
tensor(-14.2622, device='cuda:0') tensor(1.1147, device='cuda:0') tensor(2.6264e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.211584
Average KL loss: 0.297048
Average total loss: 0.508632
tensor(-14.2624, device='cuda:0') tensor(1.1151, device='cuda:0') tensor(-2.0770e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.212576
Average KL loss: 0.297031
Average total loss: 0.509607
tensor(-14.2627, device='cuda:0') tensor(1.1154, device='cuda:0') tensor(-3.2875e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.213743
Average KL loss: 0.297004
Average total loss: 0.510746
tensor(-14.2630, device='cuda:0') tensor(1.1157, device='cuda:0') tensor(-1.9118e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.210013
Average KL loss: 0.296982
Average total loss: 0.506996
tensor(-14.2633, device='cuda:0') tensor(1.1160, device='cuda:0') tensor(-2.7755e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.213190
Average KL loss: 0.296957
Average total loss: 0.510147
tensor(-14.2636, device='cuda:0') tensor(1.1163, device='cuda:0') tensor(-2.8976e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.208816
Average KL loss: 0.296936
Average total loss: 0.505752
tensor(-14.2639, device='cuda:0') tensor(1.1166, device='cuda:0') tensor(-5.7538e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.212753
Average KL loss: 0.296916
Average total loss: 0.509670
tensor(-14.2642, device='cuda:0') tensor(1.1170, device='cuda:0') tensor(-1.3544e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.208387
Average KL loss: 0.296900
Average total loss: 0.505288
tensor(-14.2645, device='cuda:0') tensor(1.1172, device='cuda:0') tensor(6.9633e-11, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.211354
Average KL loss: 0.296881
Average total loss: 0.508235
tensor(-14.2648, device='cuda:0') tensor(1.1176, device='cuda:0') tensor(-2.0337e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.212859
Average KL loss: 0.296859
Average total loss: 0.509718
tensor(-14.2650, device='cuda:0') tensor(1.1179, device='cuda:0') tensor(-1.4201e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.208330
Average KL loss: 0.296844
Average total loss: 0.505174
tensor(-14.2653, device='cuda:0') tensor(1.1182, device='cuda:0') tensor(-3.1753e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.208136
Average KL loss: 0.296828
Average total loss: 0.504963
tensor(-14.2656, device='cuda:0') tensor(1.1185, device='cuda:0') tensor(5.9731e-11, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.209912
Average KL loss: 0.296810
Average total loss: 0.506722
tensor(-14.2659, device='cuda:0') tensor(1.1188, device='cuda:0') tensor(9.1808e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.207826
Average KL loss: 0.296789
Average total loss: 0.504615
tensor(-14.2662, device='cuda:0') tensor(1.1192, device='cuda:0') tensor(-4.8180e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.207935
Average KL loss: 0.296767
Average total loss: 0.504702
tensor(-14.2665, device='cuda:0') tensor(1.1195, device='cuda:0') tensor(1.0171e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.206347
Average KL loss: 0.296746
Average total loss: 0.503093
tensor(-14.2668, device='cuda:0') tensor(1.1198, device='cuda:0') tensor(-2.1000e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.207599
Average KL loss: 0.296724
Average total loss: 0.504323
tensor(-14.2671, device='cuda:0') tensor(1.1202, device='cuda:0') tensor(-6.1105e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.209249
Average KL loss: 0.296703
Average total loss: 0.505951
tensor(-14.2674, device='cuda:0') tensor(1.1205, device='cuda:0') tensor(-1.8731e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.210199
Average KL loss: 0.296685
Average total loss: 0.506883
tensor(-14.2676, device='cuda:0') tensor(1.1209, device='cuda:0') tensor(-7.7551e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.209632
Average KL loss: 0.296663
Average total loss: 0.506295
tensor(-14.2679, device='cuda:0') tensor(1.1212, device='cuda:0') tensor(-2.3212e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.208084
Average KL loss: 0.296638
Average total loss: 0.504723
tensor(-14.2682, device='cuda:0') tensor(1.1215, device='cuda:0') tensor(4.6388e-11, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.205870
Average KL loss: 0.296620
Average total loss: 0.502490
tensor(-14.2685, device='cuda:0') tensor(1.1219, device='cuda:0') tensor(-2.6767e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.207903
Average KL loss: 0.296597
Average total loss: 0.504500
tensor(-14.2688, device='cuda:0') tensor(1.1222, device='cuda:0') tensor(-2.3846e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.208210
Average KL loss: 0.296582
Average total loss: 0.504791
tensor(-14.2691, device='cuda:0') tensor(1.1226, device='cuda:0') tensor(-1.3842e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.207220
Average KL loss: 0.296566
Average total loss: 0.503786
tensor(-14.2694, device='cuda:0') tensor(1.1229, device='cuda:0') tensor(-1.7299e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.205730
Average KL loss: 0.296558
Average total loss: 0.502287
tensor(-14.2697, device='cuda:0') tensor(1.1233, device='cuda:0') tensor(-2.5246e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.205795
Average KL loss: 0.296544
Average total loss: 0.502338
tensor(-14.2699, device='cuda:0') tensor(1.1236, device='cuda:0') tensor(-2.4126e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.203741
Average KL loss: 0.296521
Average total loss: 0.500262
tensor(-14.2702, device='cuda:0') tensor(1.1239, device='cuda:0') tensor(-3.7698e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.207702
Average KL loss: 0.296504
Average total loss: 0.504206
tensor(-14.2705, device='cuda:0') tensor(1.1242, device='cuda:0') tensor(-1.3665e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.204749
Average KL loss: 0.296485
Average total loss: 0.501234
tensor(-14.2708, device='cuda:0') tensor(1.1245, device='cuda:0') tensor(5.0993e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.204785
Average KL loss: 0.296464
Average total loss: 0.501249
tensor(-14.2711, device='cuda:0') tensor(1.1248, device='cuda:0') tensor(-3.2632e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.204758
Average KL loss: 0.296447
Average total loss: 0.501205
tensor(-14.2714, device='cuda:0') tensor(1.1252, device='cuda:0') tensor(-1.0810e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.205892
Average KL loss: 0.296432
Average total loss: 0.502324
tensor(-14.2717, device='cuda:0') tensor(1.1255, device='cuda:0') tensor(-1.8326e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.205463
Average KL loss: 0.296421
Average total loss: 0.501883
tensor(-14.2720, device='cuda:0') tensor(1.1259, device='cuda:0') tensor(1.1488e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.204227
Average KL loss: 0.296411
Average total loss: 0.500638
tensor(-14.2722, device='cuda:0') tensor(1.1262, device='cuda:0') tensor(-5.6471e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.201522
Average KL loss: 0.296395
Average total loss: 0.497916
tensor(-14.2725, device='cuda:0') tensor(1.1265, device='cuda:0') tensor(-5.9750e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.202726
Average KL loss: 0.296375
Average total loss: 0.499101
tensor(-14.2728, device='cuda:0') tensor(1.1268, device='cuda:0') tensor(-8.3547e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.202696
Average KL loss: 0.296356
Average total loss: 0.499052
tensor(-14.2731, device='cuda:0') tensor(1.1272, device='cuda:0') tensor(8.2318e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.204207
Average KL loss: 0.296344
Average total loss: 0.500551
tensor(-14.2734, device='cuda:0') tensor(1.1275, device='cuda:0') tensor(-3.7234e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.201114
Average KL loss: 0.296323
Average total loss: 0.497437
tensor(-14.2737, device='cuda:0') tensor(1.1278, device='cuda:0') tensor(-1.4101e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.202603
Average KL loss: 0.296308
Average total loss: 0.498912
tensor(-14.2740, device='cuda:0') tensor(1.1281, device='cuda:0') tensor(-4.5582e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.202896
Average KL loss: 0.296298
Average total loss: 0.499194
tensor(-14.2743, device='cuda:0') tensor(1.1285, device='cuda:0') tensor(8.5120e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.200524
Average KL loss: 0.296282
Average total loss: 0.496806
tensor(-14.2745, device='cuda:0') tensor(1.1288, device='cuda:0') tensor(7.5761e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.197590
Average KL loss: 0.296268
Average total loss: 0.493858
tensor(-14.2748, device='cuda:0') tensor(1.1291, device='cuda:0') tensor(-5.9205e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.204190
Average KL loss: 0.296251
Average total loss: 0.500441
tensor(-14.2751, device='cuda:0') tensor(1.1294, device='cuda:0') tensor(-5.5327e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.200018
Average KL loss: 0.296227
Average total loss: 0.496245
tensor(-14.2754, device='cuda:0') tensor(1.1297, device='cuda:0') tensor(-1.7310e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.198258
Average KL loss: 0.296209
Average total loss: 0.494467
tensor(-14.2757, device='cuda:0') tensor(1.1300, device='cuda:0') tensor(-2.2931e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.201086
Average KL loss: 0.296191
Average total loss: 0.497276
tensor(-14.2760, device='cuda:0') tensor(1.1304, device='cuda:0') tensor(1.8229e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.201183
Average KL loss: 0.296177
Average total loss: 0.497360
tensor(-14.2763, device='cuda:0') tensor(1.1307, device='cuda:0') tensor(-6.7912e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.198973
Average KL loss: 0.296166
Average total loss: 0.495139
tensor(-14.2766, device='cuda:0') tensor(1.1310, device='cuda:0') tensor(-8.1123e-11, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.198117
Average KL loss: 0.296154
Average total loss: 0.494271
tensor(-14.2768, device='cuda:0') tensor(1.1314, device='cuda:0') tensor(-3.4535e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.200204
Average KL loss: 0.296143
Average total loss: 0.496347
tensor(-14.2771, device='cuda:0') tensor(1.1317, device='cuda:0') tensor(-1.9554e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.199301
Average KL loss: 0.296132
Average total loss: 0.495433
tensor(-14.2774, device='cuda:0') tensor(1.1321, device='cuda:0') tensor(-9.8038e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.199342
Average KL loss: 0.296119
Average total loss: 0.495461
tensor(-14.2777, device='cuda:0') tensor(1.1323, device='cuda:0') tensor(-1.1165e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.202860
Average KL loss: 0.296108
Average total loss: 0.498968
tensor(-14.2780, device='cuda:0') tensor(1.1327, device='cuda:0') tensor(-2.3350e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.201413
Average KL loss: 0.296098
Average total loss: 0.497511
tensor(-14.2780, device='cuda:0') tensor(1.1328, device='cuda:0') tensor(-9.0797e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.196202
Average KL loss: 0.296097
Average total loss: 0.492298
tensor(-14.2781, device='cuda:0') tensor(1.1328, device='cuda:0') tensor(-8.2317e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.197960
Average KL loss: 0.296096
Average total loss: 0.494056
tensor(-14.2781, device='cuda:0') tensor(1.1328, device='cuda:0') tensor(1.1009e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.199188
Average KL loss: 0.296094
Average total loss: 0.495282
tensor(-14.2782, device='cuda:0') tensor(1.1329, device='cuda:0') tensor(-2.9102e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.198870
Average KL loss: 0.296092
Average total loss: 0.494963
tensor(-14.2782, device='cuda:0') tensor(1.1329, device='cuda:0') tensor(-4.2978e-11, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.197029
Average KL loss: 0.296091
Average total loss: 0.493120
tensor(-14.2783, device='cuda:0') tensor(1.1329, device='cuda:0') tensor(5.1648e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.197500
Average KL loss: 0.296089
Average total loss: 0.493589
tensor(-14.2783, device='cuda:0') tensor(1.1330, device='cuda:0') tensor(-1.0821e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.199249
Average KL loss: 0.296088
Average total loss: 0.495336
tensor(-14.2783, device='cuda:0') tensor(1.1330, device='cuda:0') tensor(-1.3833e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.199474
Average KL loss: 0.296087
Average total loss: 0.495561
tensor(-14.2784, device='cuda:0') tensor(1.1330, device='cuda:0') tensor(-2.8303e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.198163
Average KL loss: 0.296085
Average total loss: 0.494249
tensor(-14.2784, device='cuda:0') tensor(1.1331, device='cuda:0') tensor(-5.0138e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.199892
Average KL loss: 0.296084
Average total loss: 0.495976
tensor(-14.2785, device='cuda:0') tensor(1.1331, device='cuda:0') tensor(-1.6803e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.200457
Average KL loss: 0.296084
Average total loss: 0.496541
tensor(-14.2785, device='cuda:0') tensor(1.1331, device='cuda:0') tensor(-3.4213e-11, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.197969
Average KL loss: 0.296083
Average total loss: 0.494051
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-1.5341e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.197347
Average KL loss: 0.296082
Average total loss: 0.493429
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(1.9383e-11, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.195983
Average KL loss: 0.296082
Average total loss: 0.492065
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-1.5121e-11, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.198603
Average KL loss: 0.296082
Average total loss: 0.494684
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-1.0180e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.199197
Average KL loss: 0.296081
Average total loss: 0.495278
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(1.3405e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.197739
Average KL loss: 0.296081
Average total loss: 0.493820
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-3.9594e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.198162
Average KL loss: 0.296081
Average total loss: 0.494243
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-1.1610e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.198728
Average KL loss: 0.296081
Average total loss: 0.494809
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(1.4878e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.199093
Average KL loss: 0.296081
Average total loss: 0.495174
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-8.8476e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.199932
Average KL loss: 0.296081
Average total loss: 0.496013
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-2.1362e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.195908
Average KL loss: 0.296081
Average total loss: 0.491989
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-2.7722e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.198063
Average KL loss: 0.296081
Average total loss: 0.494144
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-1.3528e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.195926
Average KL loss: 0.296080
Average total loss: 0.492006
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(2.5603e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.198206
Average KL loss: 0.296080
Average total loss: 0.494286
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-1.4130e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.199634
Average KL loss: 0.296080
Average total loss: 0.495715
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-4.4169e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.195606
Average KL loss: 0.296080
Average total loss: 0.491686
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-7.0870e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.196462
Average KL loss: 0.296080
Average total loss: 0.492542
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-1.7988e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.197799
Average KL loss: 0.296080
Average total loss: 0.493879
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-1.6694e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.198046
Average KL loss: 0.296080
Average total loss: 0.494126
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-7.7254e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.198180
Average KL loss: 0.296080
Average total loss: 0.494260
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-1.0694e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.197841
Average KL loss: 0.296080
Average total loss: 0.493920
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-3.5188e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.199184
Average KL loss: 0.296080
Average total loss: 0.495264
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-1.5918e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.196765
Average KL loss: 0.296080
Average total loss: 0.492844
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-2.4648e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.199548
Average KL loss: 0.296080
Average total loss: 0.495628
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-7.4739e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.197105
Average KL loss: 0.296079
Average total loss: 0.493184
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-2.1343e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.196777
Average KL loss: 0.296079
Average total loss: 0.492856
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(2.1049e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.196457
Average KL loss: 0.296079
Average total loss: 0.492536
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-2.1051e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.199502
Average KL loss: 0.296079
Average total loss: 0.495581
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-1.0639e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.193582
Average KL loss: 0.296079
Average total loss: 0.489661
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-3.0387e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.197582
Average KL loss: 0.296079
Average total loss: 0.493661
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-2.1748e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.201990
Average KL loss: 0.296079
Average total loss: 0.498070
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(4.0054e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.199465
Average KL loss: 0.296079
Average total loss: 0.495544
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-1.7989e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.197560
Average KL loss: 0.296079
Average total loss: 0.493639
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-1.0522e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.197055
Average KL loss: 0.296079
Average total loss: 0.493134
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-2.3296e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.197536
Average KL loss: 0.296079
Average total loss: 0.493615
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-5.8270e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.199251
Average KL loss: 0.296079
Average total loss: 0.495330
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-1.3969e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.195613
Average KL loss: 0.296079
Average total loss: 0.491692
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(1.8817e-11, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.197210
Average KL loss: 0.296079
Average total loss: 0.493289
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-1.5813e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.196148
Average KL loss: 0.296079
Average total loss: 0.492227
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(3.5144e-10, device='cuda:0')
 Percentile value: -13.71331558227539
Non-zero model percentage: 0.7378903031349182%, Non-zero mask percentage: 0.7378903031349182%

--- Pruning Level [22/24]: ---
conv1.weight         | nonzeros =     942 /    1728             ( 54.51%) | total_pruned =     786 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2107 /   36864             (  5.72%) | total_pruned =   34757 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2298 /   36864             (  6.23%) | total_pruned =   34566 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1938 /   36864             (  5.26%) | total_pruned =   34926 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1940 /   36864             (  5.26%) | total_pruned =   34924 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3687 /   73728             (  5.00%) | total_pruned =   70041 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    5169 /  147456             (  3.51%) | total_pruned =  142287 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1534 /    8192             ( 18.73%) | total_pruned =    6658 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3543 /  147456             (  2.40%) | total_pruned =  143913 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3389 /  147456             (  2.30%) | total_pruned =  144067 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7460 /  294912             (  2.53%) | total_pruned =  287452 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     101 /     256             ( 39.45%) | total_pruned =     155 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    9306 /  589824             (  1.58%) | total_pruned =  580518 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      60 /     256             ( 23.44%) | total_pruned =     196 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2507 /   32768             (  7.65%) | total_pruned =   30261 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      78 /     256             ( 30.47%) | total_pruned =     178 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3833 /  589824             (  0.65%) | total_pruned =  585991 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3864 /  589824             (  0.66%) | total_pruned =  585960 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     199 /     256             ( 77.73%) | total_pruned =      57 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    7710 / 1179648             (  0.65%) | total_pruned = 1171938 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     272 /     512             ( 53.12%) | total_pruned =     240 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      92 /     512             ( 17.97%) | total_pruned =     420 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    6144 / 2359296             (  0.26%) | total_pruned = 2353152 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     337 /     512             ( 65.82%) | total_pruned =     175 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     134 /     512             ( 26.17%) | total_pruned =     378 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1942 /  131072             (  1.48%) | total_pruned =  129130 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     258 /     512             ( 50.39%) | total_pruned =     254 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     132 /     512             ( 25.78%) | total_pruned =     380 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3114 / 2359296             (  0.13%) | total_pruned = 2356182 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     111 /     512             ( 21.68%) | total_pruned =     401 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      25 /     512             (  4.88%) | total_pruned =     487 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    3621 / 2359296             (  0.15%) | total_pruned = 2355675 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      38 /     512             (  7.42%) | total_pruned =     474 | shape = torch.Size([512])
linear.weight        | nonzeros =    2139 /    5120             ( 41.78%) | total_pruned =    2981 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 82487, pruned : 11096275, total: 11178762, Compression rate :     135.52x  ( 99.26% pruned)
Train Epoch: 24/100 Loss: 0.007129 Accuracy: 85.54 100.00 % Best test Accuracy: 85.73%
tensor(-14.2786, device='cuda:0') tensor(1.1332, device='cuda:0') tensor(-2.1616e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.291434
Average KL loss: 0.295851
Average total loss: 0.587285
tensor(-14.2794, device='cuda:0') tensor(1.1112, device='cuda:0') tensor(-8.5233e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.293139
Average KL loss: 0.295641
Average total loss: 0.588780
tensor(-14.2800, device='cuda:0') tensor(1.0987, device='cuda:0') tensor(4.9077e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.291183
Average KL loss: 0.295525
Average total loss: 0.586709
tensor(-14.2805, device='cuda:0') tensor(1.0908, device='cuda:0') tensor(-2.7003e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.283369
Average KL loss: 0.295450
Average total loss: 0.578819
tensor(-14.2810, device='cuda:0') tensor(1.0857, device='cuda:0') tensor(-5.8816e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.287648
Average KL loss: 0.295386
Average total loss: 0.583034
tensor(-14.2814, device='cuda:0') tensor(1.0823, device='cuda:0') tensor(-3.7388e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.286450
Average KL loss: 0.295331
Average total loss: 0.581781
tensor(-14.2817, device='cuda:0') tensor(1.0801, device='cuda:0') tensor(-1.1978e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.281865
Average KL loss: 0.295292
Average total loss: 0.577157
tensor(-14.2820, device='cuda:0') tensor(1.0787, device='cuda:0') tensor(-1.6198e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.275762
Average KL loss: 0.295264
Average total loss: 0.571026
tensor(-14.2824, device='cuda:0') tensor(1.0778, device='cuda:0') tensor(-6.1071e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.275420
Average KL loss: 0.295232
Average total loss: 0.570652
tensor(-14.2827, device='cuda:0') tensor(1.0773, device='cuda:0') tensor(-2.5465e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.273319
Average KL loss: 0.295200
Average total loss: 0.568519
tensor(-14.2830, device='cuda:0') tensor(1.0770, device='cuda:0') tensor(-3.1921e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.272992
Average KL loss: 0.295174
Average total loss: 0.568165
tensor(-14.2833, device='cuda:0') tensor(1.0769, device='cuda:0') tensor(-3.6088e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.268308
Average KL loss: 0.295145
Average total loss: 0.563453
tensor(-14.2836, device='cuda:0') tensor(1.0768, device='cuda:0') tensor(-5.5532e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.273586
Average KL loss: 0.295116
Average total loss: 0.568703
tensor(-14.2839, device='cuda:0') tensor(1.0768, device='cuda:0') tensor(-2.8443e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.267701
Average KL loss: 0.295091
Average total loss: 0.562792
tensor(-14.2842, device='cuda:0') tensor(1.0770, device='cuda:0') tensor(-3.7531e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.268715
Average KL loss: 0.295063
Average total loss: 0.563778
tensor(-14.2844, device='cuda:0') tensor(1.0771, device='cuda:0') tensor(-2.4189e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.269472
Average KL loss: 0.295035
Average total loss: 0.564507
tensor(-14.2847, device='cuda:0') tensor(1.0773, device='cuda:0') tensor(-4.4409e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.267694
Average KL loss: 0.295005
Average total loss: 0.562699
tensor(-14.2850, device='cuda:0') tensor(1.0775, device='cuda:0') tensor(-4.0440e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.262625
Average KL loss: 0.294976
Average total loss: 0.557601
tensor(-14.2853, device='cuda:0') tensor(1.0777, device='cuda:0') tensor(-3.3618e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.260082
Average KL loss: 0.294956
Average total loss: 0.555037
tensor(-14.2856, device='cuda:0') tensor(1.0780, device='cuda:0') tensor(-3.8655e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.259876
Average KL loss: 0.294937
Average total loss: 0.554813
tensor(-14.2859, device='cuda:0') tensor(1.0783, device='cuda:0') tensor(-2.3663e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.263758
Average KL loss: 0.294919
Average total loss: 0.558677
tensor(-14.2862, device='cuda:0') tensor(1.0786, device='cuda:0') tensor(-2.0140e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.259325
Average KL loss: 0.294905
Average total loss: 0.554230
tensor(-14.2865, device='cuda:0') tensor(1.0788, device='cuda:0') tensor(-4.2886e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.258649
Average KL loss: 0.294882
Average total loss: 0.553531
tensor(-14.2868, device='cuda:0') tensor(1.0791, device='cuda:0') tensor(-2.7404e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.257821
Average KL loss: 0.294862
Average total loss: 0.552683
tensor(-14.2870, device='cuda:0') tensor(1.0794, device='cuda:0') tensor(-2.5429e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.258256
Average KL loss: 0.294835
Average total loss: 0.553091
tensor(-14.2873, device='cuda:0') tensor(1.0798, device='cuda:0') tensor(-4.2338e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.259231
Average KL loss: 0.294811
Average total loss: 0.554042
tensor(-14.2876, device='cuda:0') tensor(1.0801, device='cuda:0') tensor(-1.2177e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.256064
Average KL loss: 0.294793
Average total loss: 0.550857
tensor(-14.2879, device='cuda:0') tensor(1.0805, device='cuda:0') tensor(-1.1795e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.254973
Average KL loss: 0.294778
Average total loss: 0.549751
tensor(-14.2882, device='cuda:0') tensor(1.0809, device='cuda:0') tensor(-2.7642e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.253703
Average KL loss: 0.294761
Average total loss: 0.548463
tensor(-14.2885, device='cuda:0') tensor(1.0812, device='cuda:0') tensor(-2.2351e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.251232
Average KL loss: 0.294739
Average total loss: 0.545972
tensor(-14.2888, device='cuda:0') tensor(1.0815, device='cuda:0') tensor(-4.0829e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.250885
Average KL loss: 0.294712
Average total loss: 0.545597
tensor(-14.2890, device='cuda:0') tensor(1.0818, device='cuda:0') tensor(-1.8837e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.249192
Average KL loss: 0.294690
Average total loss: 0.543882
tensor(-14.2893, device='cuda:0') tensor(1.0822, device='cuda:0') tensor(1.4569e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.248707
Average KL loss: 0.294671
Average total loss: 0.543377
tensor(-14.2896, device='cuda:0') tensor(1.0825, device='cuda:0') tensor(-3.4569e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.246908
Average KL loss: 0.294653
Average total loss: 0.541561
tensor(-14.2899, device='cuda:0') tensor(1.0829, device='cuda:0') tensor(6.8357e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.250796
Average KL loss: 0.294631
Average total loss: 0.545427
tensor(-14.2902, device='cuda:0') tensor(1.0832, device='cuda:0') tensor(-2.7164e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.245741
Average KL loss: 0.294611
Average total loss: 0.540353
tensor(-14.2905, device='cuda:0') tensor(1.0835, device='cuda:0') tensor(-9.7952e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.243390
Average KL loss: 0.294593
Average total loss: 0.537983
tensor(-14.2908, device='cuda:0') tensor(1.0839, device='cuda:0') tensor(-5.0750e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.245035
Average KL loss: 0.294575
Average total loss: 0.539610
tensor(-14.2910, device='cuda:0') tensor(1.0843, device='cuda:0') tensor(-7.6711e-11, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.246903
Average KL loss: 0.294558
Average total loss: 0.541461
tensor(-14.2913, device='cuda:0') tensor(1.0847, device='cuda:0') tensor(-7.8951e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.248096
Average KL loss: 0.294538
Average total loss: 0.542634
tensor(-14.2916, device='cuda:0') tensor(1.0850, device='cuda:0') tensor(-5.2727e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.246622
Average KL loss: 0.294522
Average total loss: 0.541144
tensor(-14.2919, device='cuda:0') tensor(1.0854, device='cuda:0') tensor(-4.8978e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.241247
Average KL loss: 0.294510
Average total loss: 0.535757
tensor(-14.2922, device='cuda:0') tensor(1.0858, device='cuda:0') tensor(2.1577e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.244677
Average KL loss: 0.294497
Average total loss: 0.539174
tensor(-14.2925, device='cuda:0') tensor(1.0861, device='cuda:0') tensor(1.9846e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.242657
Average KL loss: 0.294482
Average total loss: 0.537139
tensor(-14.2927, device='cuda:0') tensor(1.0865, device='cuda:0') tensor(-2.3764e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.240827
Average KL loss: 0.294466
Average total loss: 0.535292
tensor(-14.2930, device='cuda:0') tensor(1.0869, device='cuda:0') tensor(-3.8583e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.243926
Average KL loss: 0.294445
Average total loss: 0.538371
tensor(-14.2933, device='cuda:0') tensor(1.0873, device='cuda:0') tensor(-8.3743e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.239186
Average KL loss: 0.294432
Average total loss: 0.533617
tensor(-14.2936, device='cuda:0') tensor(1.0876, device='cuda:0') tensor(-1.4925e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.241977
Average KL loss: 0.294406
Average total loss: 0.536383
tensor(-14.2939, device='cuda:0') tensor(1.0879, device='cuda:0') tensor(1.5758e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.237987
Average KL loss: 0.294378
Average total loss: 0.532365
tensor(-14.2942, device='cuda:0') tensor(1.0882, device='cuda:0') tensor(-1.8546e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.239975
Average KL loss: 0.294353
Average total loss: 0.534328
tensor(-14.2944, device='cuda:0') tensor(1.0886, device='cuda:0') tensor(-9.8979e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.238962
Average KL loss: 0.294332
Average total loss: 0.533294
tensor(-14.2947, device='cuda:0') tensor(1.0889, device='cuda:0') tensor(-3.3613e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.240734
Average KL loss: 0.294309
Average total loss: 0.535043
tensor(-14.2950, device='cuda:0') tensor(1.0892, device='cuda:0') tensor(6.9713e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.237407
Average KL loss: 0.294285
Average total loss: 0.531692
tensor(-14.2953, device='cuda:0') tensor(1.0895, device='cuda:0') tensor(-1.9119e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.231758
Average KL loss: 0.294269
Average total loss: 0.526027
tensor(-14.2956, device='cuda:0') tensor(1.0898, device='cuda:0') tensor(-2.0172e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.236706
Average KL loss: 0.294253
Average total loss: 0.530958
tensor(-14.2959, device='cuda:0') tensor(1.0902, device='cuda:0') tensor(-9.5516e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.238744
Average KL loss: 0.294236
Average total loss: 0.532979
tensor(-14.2962, device='cuda:0') tensor(1.0906, device='cuda:0') tensor(-1.4423e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.233606
Average KL loss: 0.294216
Average total loss: 0.527821
tensor(-14.2964, device='cuda:0') tensor(1.0909, device='cuda:0') tensor(-2.0489e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.233520
Average KL loss: 0.294190
Average total loss: 0.527710
tensor(-14.2967, device='cuda:0') tensor(1.0912, device='cuda:0') tensor(-6.9635e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.232379
Average KL loss: 0.294167
Average total loss: 0.526546
tensor(-14.2970, device='cuda:0') tensor(1.0916, device='cuda:0') tensor(-2.9112e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.232614
Average KL loss: 0.294151
Average total loss: 0.526765
tensor(-14.2973, device='cuda:0') tensor(1.0919, device='cuda:0') tensor(-4.2285e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.234579
Average KL loss: 0.294133
Average total loss: 0.528712
tensor(-14.2976, device='cuda:0') tensor(1.0923, device='cuda:0') tensor(3.4532e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.234077
Average KL loss: 0.294118
Average total loss: 0.528195
tensor(-14.2979, device='cuda:0') tensor(1.0926, device='cuda:0') tensor(-1.3005e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.232549
Average KL loss: 0.294094
Average total loss: 0.526643
tensor(-14.2981, device='cuda:0') tensor(1.0929, device='cuda:0') tensor(-5.2038e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.231331
Average KL loss: 0.294068
Average total loss: 0.525400
tensor(-14.2984, device='cuda:0') tensor(1.0933, device='cuda:0') tensor(-3.7389e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.227930
Average KL loss: 0.294053
Average total loss: 0.521983
tensor(-14.2987, device='cuda:0') tensor(1.0936, device='cuda:0') tensor(-2.8210e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.231519
Average KL loss: 0.294031
Average total loss: 0.525550
tensor(-14.2990, device='cuda:0') tensor(1.0940, device='cuda:0') tensor(-9.0668e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.228638
Average KL loss: 0.294012
Average total loss: 0.522650
tensor(-14.2993, device='cuda:0') tensor(1.0943, device='cuda:0') tensor(2.3721e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.229753
Average KL loss: 0.293992
Average total loss: 0.523745
tensor(-14.2996, device='cuda:0') tensor(1.0946, device='cuda:0') tensor(-3.6225e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.226068
Average KL loss: 0.293968
Average total loss: 0.520036
tensor(-14.2998, device='cuda:0') tensor(1.0949, device='cuda:0') tensor(-1.4421e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.227787
Average KL loss: 0.293950
Average total loss: 0.521737
tensor(-14.3001, device='cuda:0') tensor(1.0952, device='cuda:0') tensor(9.9808e-11, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.229356
Average KL loss: 0.293931
Average total loss: 0.523287
tensor(-14.3004, device='cuda:0') tensor(1.0956, device='cuda:0') tensor(-3.3532e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.229127
Average KL loss: 0.293914
Average total loss: 0.523041
tensor(-14.3007, device='cuda:0') tensor(1.0959, device='cuda:0') tensor(-8.0443e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.224662
Average KL loss: 0.293895
Average total loss: 0.518557
tensor(-14.3010, device='cuda:0') tensor(1.0962, device='cuda:0') tensor(-2.5860e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.228872
Average KL loss: 0.293877
Average total loss: 0.522749
tensor(-14.3013, device='cuda:0') tensor(1.0965, device='cuda:0') tensor(-4.5117e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.222776
Average KL loss: 0.293860
Average total loss: 0.516636
tensor(-14.3015, device='cuda:0') tensor(1.0968, device='cuda:0') tensor(-8.1398e-11, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.228557
Average KL loss: 0.293837
Average total loss: 0.522395
tensor(-14.3018, device='cuda:0') tensor(1.0971, device='cuda:0') tensor(2.3818e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.228212
Average KL loss: 0.293818
Average total loss: 0.522030
tensor(-14.3021, device='cuda:0') tensor(1.0975, device='cuda:0') tensor(-3.7328e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.223547
Average KL loss: 0.293798
Average total loss: 0.517345
tensor(-14.3024, device='cuda:0') tensor(1.0978, device='cuda:0') tensor(6.8437e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.226962
Average KL loss: 0.293777
Average total loss: 0.520738
tensor(-14.3027, device='cuda:0') tensor(1.0981, device='cuda:0') tensor(1.7519e-11, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.225365
Average KL loss: 0.293756
Average total loss: 0.519121
tensor(-14.3030, device='cuda:0') tensor(1.0985, device='cuda:0') tensor(-8.8036e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.222994
Average KL loss: 0.293735
Average total loss: 0.516728
tensor(-14.3032, device='cuda:0') tensor(1.0989, device='cuda:0') tensor(-6.1847e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.221421
Average KL loss: 0.293714
Average total loss: 0.515135
tensor(-14.3035, device='cuda:0') tensor(1.0992, device='cuda:0') tensor(-1.2589e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.221274
Average KL loss: 0.293700
Average total loss: 0.514974
tensor(-14.3038, device='cuda:0') tensor(1.0996, device='cuda:0') tensor(-5.3370e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.222441
Average KL loss: 0.293685
Average total loss: 0.516126
tensor(-14.3041, device='cuda:0') tensor(1.0998, device='cuda:0') tensor(-1.3173e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.222405
Average KL loss: 0.293665
Average total loss: 0.516069
tensor(-14.3044, device='cuda:0') tensor(1.1002, device='cuda:0') tensor(-1.8201e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.224456
Average KL loss: 0.293646
Average total loss: 0.518102
tensor(-14.3046, device='cuda:0') tensor(1.1006, device='cuda:0') tensor(-2.9805e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.225864
Average KL loss: 0.293625
Average total loss: 0.519489
tensor(-14.3049, device='cuda:0') tensor(1.1009, device='cuda:0') tensor(-1.3072e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.220605
Average KL loss: 0.293609
Average total loss: 0.514215
tensor(-14.3052, device='cuda:0') tensor(1.1012, device='cuda:0') tensor(-6.5938e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.227087
Average KL loss: 0.293597
Average total loss: 0.520685
tensor(-14.3055, device='cuda:0') tensor(1.1015, device='cuda:0') tensor(3.0480e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.223581
Average KL loss: 0.293583
Average total loss: 0.517164
tensor(-14.3058, device='cuda:0') tensor(1.1019, device='cuda:0') tensor(-1.3769e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.222859
Average KL loss: 0.293569
Average total loss: 0.516428
tensor(-14.3061, device='cuda:0') tensor(1.1023, device='cuda:0') tensor(-1.6102e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.220858
Average KL loss: 0.293546
Average total loss: 0.514404
tensor(-14.3063, device='cuda:0') tensor(1.1026, device='cuda:0') tensor(1.7409e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.223005
Average KL loss: 0.293526
Average total loss: 0.516531
tensor(-14.3066, device='cuda:0') tensor(1.1030, device='cuda:0') tensor(-3.5952e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.217675
Average KL loss: 0.293511
Average total loss: 0.511185
tensor(-14.3069, device='cuda:0') tensor(1.1032, device='cuda:0') tensor(-4.1839e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.217583
Average KL loss: 0.293494
Average total loss: 0.511077
tensor(-14.3072, device='cuda:0') tensor(1.1036, device='cuda:0') tensor(-4.6092e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.218966
Average KL loss: 0.293479
Average total loss: 0.512446
tensor(-14.3075, device='cuda:0') tensor(1.1039, device='cuda:0') tensor(-7.5485e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.219901
Average KL loss: 0.293462
Average total loss: 0.513364
tensor(-14.3078, device='cuda:0') tensor(1.1042, device='cuda:0') tensor(-7.4095e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.219907
Average KL loss: 0.293450
Average total loss: 0.513358
tensor(-14.3080, device='cuda:0') tensor(1.1046, device='cuda:0') tensor(-3.5989e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.217598
Average KL loss: 0.293434
Average total loss: 0.511032
tensor(-14.3083, device='cuda:0') tensor(1.1050, device='cuda:0') tensor(-3.5170e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.212947
Average KL loss: 0.293422
Average total loss: 0.506369
tensor(-14.3086, device='cuda:0') tensor(1.1052, device='cuda:0') tensor(-1.5498e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.219805
Average KL loss: 0.293403
Average total loss: 0.513208
tensor(-14.3089, device='cuda:0') tensor(1.1056, device='cuda:0') tensor(-1.4659e-11, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.216332
Average KL loss: 0.293380
Average total loss: 0.509712
tensor(-14.3092, device='cuda:0') tensor(1.1059, device='cuda:0') tensor(4.2047e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.218197
Average KL loss: 0.293361
Average total loss: 0.511558
tensor(-14.3094, device='cuda:0') tensor(1.1063, device='cuda:0') tensor(-1.6657e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.215829
Average KL loss: 0.293348
Average total loss: 0.509176
tensor(-14.3097, device='cuda:0') tensor(1.1066, device='cuda:0') tensor(-1.2937e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.217385
Average KL loss: 0.293334
Average total loss: 0.510719
tensor(-14.3100, device='cuda:0') tensor(1.1070, device='cuda:0') tensor(-2.7707e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.217819
Average KL loss: 0.293321
Average total loss: 0.511140
tensor(-14.3103, device='cuda:0') tensor(1.1073, device='cuda:0') tensor(-1.9462e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.219292
Average KL loss: 0.293305
Average total loss: 0.512598
tensor(-14.3106, device='cuda:0') tensor(1.1077, device='cuda:0') tensor(-2.5201e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.216647
Average KL loss: 0.293289
Average total loss: 0.509935
tensor(-14.3109, device='cuda:0') tensor(1.1081, device='cuda:0') tensor(1.6836e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.215184
Average KL loss: 0.293279
Average total loss: 0.508463
tensor(-14.3111, device='cuda:0') tensor(1.1084, device='cuda:0') tensor(-1.3253e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.218788
Average KL loss: 0.293267
Average total loss: 0.512055
tensor(-14.3114, device='cuda:0') tensor(1.1087, device='cuda:0') tensor(-8.3312e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.217770
Average KL loss: 0.293252
Average total loss: 0.511022
tensor(-14.3117, device='cuda:0') tensor(1.1090, device='cuda:0') tensor(7.1431e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.213244
Average KL loss: 0.293239
Average total loss: 0.506484
tensor(-14.3118, device='cuda:0') tensor(1.1090, device='cuda:0') tensor(3.1663e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.213472
Average KL loss: 0.293239
Average total loss: 0.506711
tensor(-14.3118, device='cuda:0') tensor(1.1090, device='cuda:0') tensor(6.5608e-12, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.209477
Average KL loss: 0.293237
Average total loss: 0.502714
tensor(-14.3118, device='cuda:0') tensor(1.1091, device='cuda:0') tensor(-4.8309e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.215362
Average KL loss: 0.293236
Average total loss: 0.508598
tensor(-14.3119, device='cuda:0') tensor(1.1091, device='cuda:0') tensor(-1.6170e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.217991
Average KL loss: 0.293235
Average total loss: 0.511225
tensor(-14.3119, device='cuda:0') tensor(1.1092, device='cuda:0') tensor(-1.0114e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.218695
Average KL loss: 0.293234
Average total loss: 0.511929
tensor(-14.3120, device='cuda:0') tensor(1.1092, device='cuda:0') tensor(-3.7310e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.211977
Average KL loss: 0.293233
Average total loss: 0.505209
tensor(-14.3120, device='cuda:0') tensor(1.1092, device='cuda:0') tensor(-3.0461e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.210043
Average KL loss: 0.293231
Average total loss: 0.503275
tensor(-14.3121, device='cuda:0') tensor(1.1093, device='cuda:0') tensor(-9.6990e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.216346
Average KL loss: 0.293230
Average total loss: 0.509576
tensor(-14.3121, device='cuda:0') tensor(1.1093, device='cuda:0') tensor(-4.7573e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.214832
Average KL loss: 0.293228
Average total loss: 0.508060
tensor(-14.3122, device='cuda:0') tensor(1.1093, device='cuda:0') tensor(-7.6974e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.215287
Average KL loss: 0.293227
Average total loss: 0.508513
tensor(-14.3122, device='cuda:0') tensor(1.1094, device='cuda:0') tensor(-2.3960e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.214523
Average KL loss: 0.293225
Average total loss: 0.507748
tensor(-14.3123, device='cuda:0') tensor(1.1094, device='cuda:0') tensor(1.3403e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.214990
Average KL loss: 0.293224
Average total loss: 0.508213
tensor(-14.3123, device='cuda:0') tensor(1.1094, device='cuda:0') tensor(-1.3150e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.215084
Average KL loss: 0.293223
Average total loss: 0.508307
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(8.1311e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.217470
Average KL loss: 0.293222
Average total loss: 0.510692
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(-3.0557e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.214067
Average KL loss: 0.293222
Average total loss: 0.507289
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(-1.2538e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.216062
Average KL loss: 0.293222
Average total loss: 0.509284
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(-1.6451e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.211684
Average KL loss: 0.293221
Average total loss: 0.504905
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(-3.6426e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.214611
Average KL loss: 0.293221
Average total loss: 0.507833
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(2.7274e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.217594
Average KL loss: 0.293221
Average total loss: 0.510815
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(2.0189e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.213598
Average KL loss: 0.293221
Average total loss: 0.506819
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(4.0460e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.211252
Average KL loss: 0.293221
Average total loss: 0.504472
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(2.4937e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.212501
Average KL loss: 0.293221
Average total loss: 0.505722
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(-1.6114e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.213164
Average KL loss: 0.293221
Average total loss: 0.506384
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(-1.4001e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.216446
Average KL loss: 0.293220
Average total loss: 0.509667
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(1.6798e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.213234
Average KL loss: 0.293220
Average total loss: 0.506454
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(-2.8500e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.216357
Average KL loss: 0.293220
Average total loss: 0.509578
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(-4.4825e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.210780
Average KL loss: 0.293220
Average total loss: 0.504000
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(-2.1473e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.217866
Average KL loss: 0.293220
Average total loss: 0.511087
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(-4.0022e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.213303
Average KL loss: 0.293220
Average total loss: 0.506524
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(-2.1407e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.214748
Average KL loss: 0.293220
Average total loss: 0.507968
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(-4.3058e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.211873
Average KL loss: 0.293220
Average total loss: 0.505093
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(-4.3965e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.212835
Average KL loss: 0.293220
Average total loss: 0.506055
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(-5.3679e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.214837
Average KL loss: 0.293220
Average total loss: 0.508058
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(4.5517e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.212704
Average KL loss: 0.293220
Average total loss: 0.505924
tensor(-14.3123, device='cuda:0') tensor(1.1095, device='cuda:0') tensor(5.5937e-10, device='cuda:0')
 Percentile value: -13.664852142333984
Non-zero model percentage: 0.5903157591819763%, Non-zero mask percentage: 0.5903157591819763%

--- Pruning Level [23/24]: ---
conv1.weight         | nonzeros =     920 /    1728             ( 53.24%) | total_pruned =     808 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1753 /   36864             (  4.76%) | total_pruned =   35111 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1897 /   36864             (  5.15%) | total_pruned =   34967 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1626 /   36864             (  4.41%) | total_pruned =   35238 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1660 /   36864             (  4.50%) | total_pruned =   35204 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2980 /   73728             (  4.04%) | total_pruned =   70748 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4172 /  147456             (  2.83%) | total_pruned =  143284 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1394 /    8192             ( 17.02%) | total_pruned =    6798 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2816 /  147456             (  1.91%) | total_pruned =  144640 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2635 /  147456             (  1.79%) | total_pruned =  144821 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    5884 /  294912             (  2.00%) | total_pruned =  289028 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      95 /     256             ( 37.11%) | total_pruned =     161 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    7103 /  589824             (  1.20%) | total_pruned =  582721 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      55 /     256             ( 21.48%) | total_pruned =     201 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2141 /   32768             (  6.53%) | total_pruned =   30627 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     222 /     256             ( 86.72%) | total_pruned =      34 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2906 /  589824             (  0.49%) | total_pruned =  586918 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      41 /     256             ( 16.02%) | total_pruned =     215 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2945 /  589824             (  0.50%) | total_pruned =  586879 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     199 /     256             ( 77.73%) | total_pruned =      57 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    5893 / 1179648             (  0.50%) | total_pruned = 1173755 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     272 /     512             ( 53.12%) | total_pruned =     240 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      85 /     512             ( 16.60%) | total_pruned =     427 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    4554 / 2359296             (  0.19%) | total_pruned = 2354742 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     334 /     512             ( 65.23%) | total_pruned =     178 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     110 /     512             ( 21.48%) | total_pruned =     402 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1561 /  131072             (  1.19%) | total_pruned =  129511 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     256 /     512             ( 50.00%) | total_pruned =     256 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     107 /     512             ( 20.90%) | total_pruned =     405 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2331 / 2359296             (  0.10%) | total_pruned = 2356965 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     110 /     512             ( 21.48%) | total_pruned =     402 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2694 / 2359296             (  0.11%) | total_pruned = 2356602 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     396 /     512             ( 77.34%) | total_pruned =     116 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
linear.weight        | nonzeros =    1965 /    5120             ( 38.38%) | total_pruned =    3155 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 65990, pruned : 11112772, total: 11178762, Compression rate :     169.40x  ( 99.41% pruned)
Train Epoch: 25/100 Loss: 0.000752 Accuracy: 85.75 100.00 % Best test Accuracy: 85.80%
