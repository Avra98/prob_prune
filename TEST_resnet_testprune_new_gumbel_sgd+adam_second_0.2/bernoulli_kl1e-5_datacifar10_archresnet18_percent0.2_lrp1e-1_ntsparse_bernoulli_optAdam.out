Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/24]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/100 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(2.2858e-06, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.427859
Average KL loss: 24.475323
Average total loss: 25.903181
tensor(-2.6658, device='cuda:0') tensor(1.0850, device='cuda:0') tensor(6.6712e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.975640
Average KL loss: 8.567855
Average total loss: 9.543495
tensor(-3.5107, device='cuda:0') tensor(1.4869, device='cuda:0') tensor(3.9976e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.801338
Average KL loss: 5.844136
Average total loss: 6.645473
tensor(-3.9914, device='cuda:0') tensor(1.6730, device='cuda:0') tensor(2.9207e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.703863
Average KL loss: 4.563307
Average total loss: 5.267170
tensor(-4.3441, device='cuda:0') tensor(1.8088, device='cuda:0') tensor(2.2821e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.644561
Average KL loss: 3.795215
Average total loss: 4.439776
tensor(-4.6254, device='cuda:0') tensor(1.9150, device='cuda:0') tensor(1.8507e-07, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.614952
Average KL loss: 3.279434
Average total loss: 3.894386
tensor(-4.8601, device='cuda:0') tensor(2.0112, device='cuda:0') tensor(1.6363e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.578438
Average KL loss: 2.913968
Average total loss: 3.492406
tensor(-5.0623, device='cuda:0') tensor(2.0927, device='cuda:0') tensor(1.4859e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.566051
Average KL loss: 2.637422
Average total loss: 3.203473
tensor(-5.2404, device='cuda:0') tensor(2.1665, device='cuda:0') tensor(1.2723e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.529497
Average KL loss: 2.418420
Average total loss: 2.947917
tensor(-5.3997, device='cuda:0') tensor(2.2271, device='cuda:0') tensor(1.0465e-07, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.519156
Average KL loss: 2.239531
Average total loss: 2.758687
tensor(-5.5441, device='cuda:0') tensor(2.2836, device='cuda:0') tensor(1.0450e-07, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.496007
Average KL loss: 2.096308
Average total loss: 2.592315
tensor(-5.6761, device='cuda:0') tensor(2.3357, device='cuda:0') tensor(9.6836e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.479302
Average KL loss: 1.969824
Average total loss: 2.449126
tensor(-5.7983, device='cuda:0') tensor(2.3787, device='cuda:0') tensor(8.4402e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.465615
Average KL loss: 1.861752
Average total loss: 2.327366
tensor(-5.9116, device='cuda:0') tensor(2.4195, device='cuda:0') tensor(8.0558e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.450814
Average KL loss: 1.767076
Average total loss: 2.217891
tensor(-6.0176, device='cuda:0') tensor(2.4559, device='cuda:0') tensor(8.3224e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.447322
Average KL loss: 1.685801
Average total loss: 2.133123
tensor(-6.1174, device='cuda:0') tensor(2.4911, device='cuda:0') tensor(7.0562e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.431861
Average KL loss: 1.615296
Average total loss: 2.047156
tensor(-6.2116, device='cuda:0') tensor(2.5246, device='cuda:0') tensor(6.0537e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.420669
Average KL loss: 1.553363
Average total loss: 1.974031
tensor(-6.3007, device='cuda:0') tensor(2.5569, device='cuda:0') tensor(7.0796e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.416689
Average KL loss: 1.498437
Average total loss: 1.915125
tensor(-6.3856, device='cuda:0') tensor(2.5878, device='cuda:0') tensor(6.1953e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.404642
Average KL loss: 1.449803
Average total loss: 1.854445
tensor(-6.4666, device='cuda:0') tensor(2.6149, device='cuda:0') tensor(5.5246e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.394230
Average KL loss: 1.404339
Average total loss: 1.798569
tensor(-6.5439, device='cuda:0') tensor(2.6430, device='cuda:0') tensor(4.9728e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.376904
Average KL loss: 1.363245
Average total loss: 1.740149
tensor(-6.6182, device='cuda:0') tensor(2.6657, device='cuda:0') tensor(4.9316e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.370171
Average KL loss: 1.322524
Average total loss: 1.692696
tensor(-6.6895, device='cuda:0') tensor(2.6877, device='cuda:0') tensor(4.4392e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.363987
Average KL loss: 1.286941
Average total loss: 1.650929
tensor(-6.7579, device='cuda:0') tensor(2.7099, device='cuda:0') tensor(4.7026e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.356287
Average KL loss: 1.255571
Average total loss: 1.611858
tensor(-6.8239, device='cuda:0') tensor(2.7317, device='cuda:0') tensor(4.3283e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.351689
Average KL loss: 1.227037
Average total loss: 1.578726
tensor(-6.8876, device='cuda:0') tensor(2.7542, device='cuda:0') tensor(4.0771e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.341743
Average KL loss: 1.200454
Average total loss: 1.542197
tensor(-6.9495, device='cuda:0') tensor(2.7729, device='cuda:0') tensor(3.7488e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.329618
Average KL loss: 1.173905
Average total loss: 1.503524
tensor(-7.0093, device='cuda:0') tensor(2.7903, device='cuda:0') tensor(3.5093e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.327395
Average KL loss: 1.149217
Average total loss: 1.476612
tensor(-7.0674, device='cuda:0') tensor(2.8080, device='cuda:0') tensor(3.9677e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.318383
Average KL loss: 1.126751
Average total loss: 1.445134
tensor(-7.1237, device='cuda:0') tensor(2.8257, device='cuda:0') tensor(3.3608e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.311867
Average KL loss: 1.107716
Average total loss: 1.419583
tensor(-7.1783, device='cuda:0') tensor(2.8446, device='cuda:0') tensor(3.7653e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.314507
Average KL loss: 1.090124
Average total loss: 1.404631
tensor(-7.2316, device='cuda:0') tensor(2.8628, device='cuda:0') tensor(3.4663e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.301912
Average KL loss: 1.073376
Average total loss: 1.375288
tensor(-7.2835, device='cuda:0') tensor(2.8799, device='cuda:0') tensor(3.3503e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.295801
Average KL loss: 1.056760
Average total loss: 1.352561
tensor(-7.3343, device='cuda:0') tensor(2.8957, device='cuda:0') tensor(2.7143e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.288588
Average KL loss: 1.041291
Average total loss: 1.329879
tensor(-7.3838, device='cuda:0') tensor(2.9110, device='cuda:0') tensor(3.1174e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.279274
Average KL loss: 1.025672
Average total loss: 1.304947
tensor(-7.4323, device='cuda:0') tensor(2.9241, device='cuda:0') tensor(2.8696e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.276624
Average KL loss: 1.010266
Average total loss: 1.286890
tensor(-7.4796, device='cuda:0') tensor(2.9381, device='cuda:0') tensor(2.6649e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.276498
Average KL loss: 0.997071
Average total loss: 1.273569
tensor(-7.5259, device='cuda:0') tensor(2.9525, device='cuda:0') tensor(2.7341e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.264531
Average KL loss: 0.984780
Average total loss: 1.249311
tensor(-7.5713, device='cuda:0') tensor(2.9651, device='cuda:0') tensor(2.4011e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.261839
Average KL loss: 0.972334
Average total loss: 1.234173
tensor(-7.6157, device='cuda:0') tensor(2.9785, device='cuda:0') tensor(2.4761e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.255405
Average KL loss: 0.960781
Average total loss: 1.216186
tensor(-7.6592, device='cuda:0') tensor(2.9913, device='cuda:0') tensor(2.4778e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.250326
Average KL loss: 0.948849
Average total loss: 1.199175
tensor(-7.7019, device='cuda:0') tensor(3.0037, device='cuda:0') tensor(2.2954e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.242255
Average KL loss: 0.937579
Average total loss: 1.179835
tensor(-7.7439, device='cuda:0') tensor(3.0145, device='cuda:0') tensor(2.4111e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.242475
Average KL loss: 0.927196
Average total loss: 1.169671
tensor(-7.7852, device='cuda:0') tensor(3.0271, device='cuda:0') tensor(1.9568e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.237566
Average KL loss: 0.918372
Average total loss: 1.155938
tensor(-7.8257, device='cuda:0') tensor(3.0402, device='cuda:0') tensor(1.8565e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.231139
Average KL loss: 0.909178
Average total loss: 1.140317
tensor(-7.8657, device='cuda:0') tensor(3.0509, device='cuda:0') tensor(2.2341e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.230029
Average KL loss: 0.900959
Average total loss: 1.130988
tensor(-7.9050, device='cuda:0') tensor(3.0637, device='cuda:0') tensor(1.7827e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.222732
Average KL loss: 0.893591
Average total loss: 1.116323
tensor(-7.9436, device='cuda:0') tensor(3.0754, device='cuda:0') tensor(1.8981e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.219608
Average KL loss: 0.885450
Average total loss: 1.105058
tensor(-7.9816, device='cuda:0') tensor(3.0876, device='cuda:0') tensor(1.7393e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.218403
Average KL loss: 0.878401
Average total loss: 1.096804
tensor(-8.0191, device='cuda:0') tensor(3.0993, device='cuda:0') tensor(2.0889e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.214640
Average KL loss: 0.871187
Average total loss: 1.085827
tensor(-8.0560, device='cuda:0') tensor(3.1107, device='cuda:0') tensor(1.6254e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.208348
Average KL loss: 0.864896
Average total loss: 1.073245
tensor(-8.0924, device='cuda:0') tensor(3.1220, device='cuda:0') tensor(1.7457e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.206843
Average KL loss: 0.858217
Average total loss: 1.065060
tensor(-8.1284, device='cuda:0') tensor(3.1326, device='cuda:0') tensor(1.8687e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.203412
Average KL loss: 0.852110
Average total loss: 1.055522
tensor(-8.1639, device='cuda:0') tensor(3.1439, device='cuda:0') tensor(1.4495e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.195823
Average KL loss: 0.846795
Average total loss: 1.042618
tensor(-8.1989, device='cuda:0') tensor(3.1554, device='cuda:0') tensor(1.6222e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.190919
Average KL loss: 0.841551
Average total loss: 1.032471
tensor(-8.2334, device='cuda:0') tensor(3.1658, device='cuda:0') tensor(1.6198e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.191086
Average KL loss: 0.835999
Average total loss: 1.027085
tensor(-8.2675, device='cuda:0') tensor(3.1767, device='cuda:0') tensor(1.7072e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.185522
Average KL loss: 0.829733
Average total loss: 1.015255
tensor(-8.3013, device='cuda:0') tensor(3.1853, device='cuda:0') tensor(1.4239e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.182728
Average KL loss: 0.824259
Average total loss: 1.006987
tensor(-8.3345, device='cuda:0') tensor(3.1961, device='cuda:0') tensor(1.5898e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.176660
Average KL loss: 0.819025
Average total loss: 0.995686
tensor(-8.3674, device='cuda:0') tensor(3.2054, device='cuda:0') tensor(1.6058e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.175863
Average KL loss: 0.814106
Average total loss: 0.989969
tensor(-8.4001, device='cuda:0') tensor(3.2155, device='cuda:0') tensor(1.1990e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.169908
Average KL loss: 0.809097
Average total loss: 0.979004
tensor(-8.4323, device='cuda:0') tensor(3.2246, device='cuda:0') tensor(1.3994e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.167881
Average KL loss: 0.804506
Average total loss: 0.972387
tensor(-8.4641, device='cuda:0') tensor(3.2351, device='cuda:0') tensor(1.1096e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.167963
Average KL loss: 0.800733
Average total loss: 0.968697
tensor(-8.4956, device='cuda:0') tensor(3.2458, device='cuda:0') tensor(1.1753e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.164849
Average KL loss: 0.796947
Average total loss: 0.961797
tensor(-8.5269, device='cuda:0') tensor(3.2558, device='cuda:0') tensor(1.2795e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.164058
Average KL loss: 0.792719
Average total loss: 0.956777
tensor(-8.5577, device='cuda:0') tensor(3.2659, device='cuda:0') tensor(1.3105e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.159488
Average KL loss: 0.789211
Average total loss: 0.948699
tensor(-8.5883, device='cuda:0') tensor(3.2756, device='cuda:0') tensor(1.2144e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.151825
Average KL loss: 0.785248
Average total loss: 0.937074
tensor(-8.6185, device='cuda:0') tensor(3.2841, device='cuda:0') tensor(1.2407e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.154453
Average KL loss: 0.781465
Average total loss: 0.935918
tensor(-8.6486, device='cuda:0') tensor(3.2933, device='cuda:0') tensor(1.2391e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.149175
Average KL loss: 0.778141
Average total loss: 0.927316
tensor(-8.6784, device='cuda:0') tensor(3.3025, device='cuda:0') tensor(1.2600e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.147331
Average KL loss: 0.774754
Average total loss: 0.922085
tensor(-8.7079, device='cuda:0') tensor(3.3115, device='cuda:0') tensor(9.3331e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.142825
Average KL loss: 0.771560
Average total loss: 0.914385
tensor(-8.7371, device='cuda:0') tensor(3.3209, device='cuda:0') tensor(1.0405e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.143828
Average KL loss: 0.768036
Average total loss: 0.911864
tensor(-8.7661, device='cuda:0') tensor(3.3302, device='cuda:0') tensor(9.7146e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.139256
Average KL loss: 0.765119
Average total loss: 0.904375
tensor(-8.7947, device='cuda:0') tensor(3.3399, device='cuda:0') tensor(1.1350e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.138984
Average KL loss: 0.761811
Average total loss: 0.900795
tensor(-8.8233, device='cuda:0') tensor(3.3494, device='cuda:0') tensor(1.0335e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.136708
Average KL loss: 0.758446
Average total loss: 0.895154
tensor(-8.8516, device='cuda:0') tensor(3.3574, device='cuda:0') tensor(1.1472e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.135392
Average KL loss: 0.755418
Average total loss: 0.890810
tensor(-8.8797, device='cuda:0') tensor(3.3664, device='cuda:0') tensor(9.1829e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.131555
Average KL loss: 0.752769
Average total loss: 0.884324
tensor(-8.9076, device='cuda:0') tensor(3.3747, device='cuda:0') tensor(9.8631e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.130298
Average KL loss: 0.749783
Average total loss: 0.880082
tensor(-8.9354, device='cuda:0') tensor(3.3830, device='cuda:0') tensor(1.1978e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.128878
Average KL loss: 0.747109
Average total loss: 0.875987
tensor(-8.9629, device='cuda:0') tensor(3.3916, device='cuda:0') tensor(9.0632e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.128389
Average KL loss: 0.743997
Average total loss: 0.872386
tensor(-8.9903, device='cuda:0') tensor(3.3995, device='cuda:0') tensor(8.4263e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.123650
Average KL loss: 0.741267
Average total loss: 0.864916
tensor(-9.0173, device='cuda:0') tensor(3.4084, device='cuda:0') tensor(9.9939e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.122917
Average KL loss: 0.738660
Average total loss: 0.861578
tensor(-9.0442, device='cuda:0') tensor(3.4167, device='cuda:0') tensor(7.2708e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.121657
Average KL loss: 0.736074
Average total loss: 0.857731
tensor(-9.0709, device='cuda:0') tensor(3.4251, device='cuda:0') tensor(8.8201e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.119503
Average KL loss: 0.733479
Average total loss: 0.852981
tensor(-9.0975, device='cuda:0') tensor(3.4330, device='cuda:0') tensor(8.6908e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.116645
Average KL loss: 0.730243
Average total loss: 0.846888
tensor(-9.1239, device='cuda:0') tensor(3.4400, device='cuda:0') tensor(8.8216e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.115904
Average KL loss: 0.727561
Average total loss: 0.843465
tensor(-9.1502, device='cuda:0') tensor(3.4477, device='cuda:0') tensor(7.5549e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.111937
Average KL loss: 0.725231
Average total loss: 0.837167
tensor(-9.1762, device='cuda:0') tensor(3.4548, device='cuda:0') tensor(8.4730e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.113022
Average KL loss: 0.722908
Average total loss: 0.835929
tensor(-9.2021, device='cuda:0') tensor(3.4624, device='cuda:0') tensor(9.1949e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.107388
Average KL loss: 0.720558
Average total loss: 0.827946
tensor(-9.2279, device='cuda:0') tensor(3.4696, device='cuda:0') tensor(7.9791e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.109031
Average KL loss: 0.718294
Average total loss: 0.827325
tensor(-9.2534, device='cuda:0') tensor(3.4773, device='cuda:0') tensor(6.3037e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.107041
Average KL loss: 0.716130
Average total loss: 0.823171
tensor(-9.2788, device='cuda:0') tensor(3.4848, device='cuda:0') tensor(6.8442e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.104107
Average KL loss: 0.713867
Average total loss: 0.817974
tensor(-9.3040, device='cuda:0') tensor(3.4927, device='cuda:0') tensor(6.1214e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.101475
Average KL loss: 0.711787
Average total loss: 0.813262
tensor(-9.3291, device='cuda:0') tensor(3.5003, device='cuda:0') tensor(6.9876e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.100394
Average KL loss: 0.709635
Average total loss: 0.810029
tensor(-9.3540, device='cuda:0') tensor(3.5080, device='cuda:0') tensor(7.0000e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.098241
Average KL loss: 0.707697
Average total loss: 0.805937
tensor(-9.3788, device='cuda:0') tensor(3.5151, device='cuda:0') tensor(5.7345e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.099468
Average KL loss: 0.705778
Average total loss: 0.805246
tensor(-9.4035, device='cuda:0') tensor(3.5225, device='cuda:0') tensor(8.9757e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.099585
Average KL loss: 0.703904
Average total loss: 0.803488
tensor(-9.4280, device='cuda:0') tensor(3.5292, device='cuda:0') tensor(6.5078e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.096131
Average KL loss: 0.701818
Average total loss: 0.797949
tensor(-9.4525, device='cuda:0') tensor(3.5357, device='cuda:0') tensor(5.5981e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.094523
Average KL loss: 0.699460
Average total loss: 0.793983
tensor(-9.4768, device='cuda:0') tensor(3.5420, device='cuda:0') tensor(6.3383e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.094032
Average KL loss: 0.697608
Average total loss: 0.791640
tensor(-9.5009, device='cuda:0') tensor(3.5492, device='cuda:0') tensor(5.3630e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.093307
Average KL loss: 0.695714
Average total loss: 0.789021
tensor(-9.5249, device='cuda:0') tensor(3.5559, device='cuda:0') tensor(5.5832e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.092910
Average KL loss: 0.694028
Average total loss: 0.786938
tensor(-9.5488, device='cuda:0') tensor(3.5634, device='cuda:0') tensor(5.7115e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.089384
Average KL loss: 0.692420
Average total loss: 0.781804
tensor(-9.5726, device='cuda:0') tensor(3.5700, device='cuda:0') tensor(5.2471e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.087852
Average KL loss: 0.690526
Average total loss: 0.778379
tensor(-9.5963, device='cuda:0') tensor(3.5761, device='cuda:0') tensor(5.9356e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.088251
Average KL loss: 0.688524
Average total loss: 0.776775
tensor(-9.6199, device='cuda:0') tensor(3.5824, device='cuda:0') tensor(5.8424e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.085647
Average KL loss: 0.686745
Average total loss: 0.772392
tensor(-9.6434, device='cuda:0') tensor(3.5884, device='cuda:0') tensor(5.0897e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.086856
Average KL loss: 0.684676
Average total loss: 0.771531
tensor(-9.6667, device='cuda:0') tensor(3.5952, device='cuda:0') tensor(7.5511e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.084987
Average KL loss: 0.683173
Average total loss: 0.768160
tensor(-9.6899, device='cuda:0') tensor(3.6019, device='cuda:0') tensor(6.6901e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.084114
Average KL loss: 0.681413
Average total loss: 0.765527
tensor(-9.7130, device='cuda:0') tensor(3.6081, device='cuda:0') tensor(4.9751e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.085540
Average KL loss: 0.679477
Average total loss: 0.765017
tensor(-9.7360, device='cuda:0') tensor(3.6146, device='cuda:0') tensor(6.0626e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.083101
Average KL loss: 0.677741
Average total loss: 0.760842
tensor(-9.7589, device='cuda:0') tensor(3.6202, device='cuda:0') tensor(4.6878e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.081298
Average KL loss: 0.676115
Average total loss: 0.757414
tensor(-9.7817, device='cuda:0') tensor(3.6262, device='cuda:0') tensor(5.9859e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.080489
Average KL loss: 0.674291
Average total loss: 0.754780
tensor(-9.8044, device='cuda:0') tensor(3.6320, device='cuda:0') tensor(5.5357e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.079414
Average KL loss: 0.672820
Average total loss: 0.752234
tensor(-9.8270, device='cuda:0') tensor(3.6372, device='cuda:0') tensor(4.9812e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.080172
Average KL loss: 0.671324
Average total loss: 0.751495
tensor(-9.8495, device='cuda:0') tensor(3.6431, device='cuda:0') tensor(4.6059e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.079787
Average KL loss: 0.669669
Average total loss: 0.749456
tensor(-9.8719, device='cuda:0') tensor(3.6484, device='cuda:0') tensor(3.7666e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.079310
Average KL loss: 0.667865
Average total loss: 0.747174
tensor(-9.8943, device='cuda:0') tensor(3.6542, device='cuda:0') tensor(4.2543e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.078433
Average KL loss: 0.666438
Average total loss: 0.744871
tensor(-9.9166, device='cuda:0') tensor(3.6589, device='cuda:0') tensor(5.1719e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.076218
Average KL loss: 0.664610
Average total loss: 0.740828
tensor(-9.9388, device='cuda:0') tensor(3.6635, device='cuda:0') tensor(4.1103e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.074962
Average KL loss: 0.662954
Average total loss: 0.737916
tensor(-9.9608, device='cuda:0') tensor(3.6689, device='cuda:0') tensor(3.9024e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.074371
Average KL loss: 0.661423
Average total loss: 0.735795
tensor(-9.9828, device='cuda:0') tensor(3.6739, device='cuda:0') tensor(5.6894e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.073134
Average KL loss: 0.659597
Average total loss: 0.732732
tensor(-10.0046, device='cuda:0') tensor(3.6791, device='cuda:0') tensor(3.0541e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.073931
Average KL loss: 0.658471
Average total loss: 0.732402
tensor(-10.0263, device='cuda:0') tensor(3.6849, device='cuda:0') tensor(4.6222e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.072937
Average KL loss: 0.656972
Average total loss: 0.729910
tensor(-10.0480, device='cuda:0') tensor(3.6888, device='cuda:0') tensor(4.9806e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.071728
Average KL loss: 0.655414
Average total loss: 0.727141
tensor(-10.0696, device='cuda:0') tensor(3.6935, device='cuda:0') tensor(3.8203e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.070955
Average KL loss: 0.653989
Average total loss: 0.724944
tensor(-10.0911, device='cuda:0') tensor(3.6975, device='cuda:0') tensor(4.7765e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.069796
Average KL loss: 0.652417
Average total loss: 0.722213
tensor(-10.1124, device='cuda:0') tensor(3.7022, device='cuda:0') tensor(3.8939e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.070490
Average KL loss: 0.650955
Average total loss: 0.721445
tensor(-10.1336, device='cuda:0') tensor(3.7069, device='cuda:0') tensor(3.7164e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.068646
Average KL loss: 0.649660
Average total loss: 0.718306
tensor(-10.1547, device='cuda:0') tensor(3.7116, device='cuda:0') tensor(4.7299e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.068314
Average KL loss: 0.648208
Average total loss: 0.716522
tensor(-10.1758, device='cuda:0') tensor(3.7160, device='cuda:0') tensor(3.5691e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.067383
Average KL loss: 0.647071
Average total loss: 0.714455
tensor(-10.1968, device='cuda:0') tensor(3.7204, device='cuda:0') tensor(3.8840e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.068792
Average KL loss: 0.645799
Average total loss: 0.714592
tensor(-10.2177, device='cuda:0') tensor(3.7255, device='cuda:0') tensor(3.7164e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.067488
Average KL loss: 0.644724
Average total loss: 0.712212
tensor(-10.2386, device='cuda:0') tensor(3.7302, device='cuda:0') tensor(4.4974e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.066441
Average KL loss: 0.643047
Average total loss: 0.709488
tensor(-10.2594, device='cuda:0') tensor(3.7339, device='cuda:0') tensor(3.4156e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.067509
Average KL loss: 0.641596
Average total loss: 0.709105
tensor(-10.2800, device='cuda:0') tensor(3.7384, device='cuda:0') tensor(4.3881e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.068024
Average KL loss: 0.640653
Average total loss: 0.708676
tensor(-10.3006, device='cuda:0') tensor(3.7430, device='cuda:0') tensor(2.4641e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.066715
Average KL loss: 0.639812
Average total loss: 0.706526
tensor(-10.3212, device='cuda:0') tensor(3.7478, device='cuda:0') tensor(4.0578e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.063916
Average KL loss: 0.638820
Average total loss: 0.702736
tensor(-10.3416, device='cuda:0') tensor(3.7518, device='cuda:0') tensor(3.9978e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.063877
Average KL loss: 0.637564
Average total loss: 0.701441
tensor(-10.3619, device='cuda:0') tensor(3.7551, device='cuda:0') tensor(3.1251e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.064081
Average KL loss: 0.636390
Average total loss: 0.700471
tensor(-10.3822, device='cuda:0') tensor(3.7590, device='cuda:0') tensor(2.8793e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.064074
Average KL loss: 0.635387
Average total loss: 0.699461
tensor(-10.4023, device='cuda:0') tensor(3.7633, device='cuda:0') tensor(3.1435e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.064951
Average KL loss: 0.634385
Average total loss: 0.699336
tensor(-10.4224, device='cuda:0') tensor(3.7674, device='cuda:0') tensor(2.9993e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.063469
Average KL loss: 0.633283
Average total loss: 0.696752
tensor(-10.4424, device='cuda:0') tensor(3.7717, device='cuda:0') tensor(3.1270e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.063294
Average KL loss: 0.632554
Average total loss: 0.695848
tensor(-10.4624, device='cuda:0') tensor(3.7760, device='cuda:0') tensor(3.3336e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.062040
Average KL loss: 0.631745
Average total loss: 0.693785
tensor(-10.4822, device='cuda:0') tensor(3.7798, device='cuda:0') tensor(1.7561e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.060494
Average KL loss: 0.630566
Average total loss: 0.691060
tensor(-10.5020, device='cuda:0') tensor(3.7825, device='cuda:0') tensor(3.1267e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.061363
Average KL loss: 0.629441
Average total loss: 0.690804
tensor(-10.5218, device='cuda:0') tensor(3.7855, device='cuda:0') tensor(3.0090e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.061381
Average KL loss: 0.628633
Average total loss: 0.690014
tensor(-10.5414, device='cuda:0') tensor(3.7897, device='cuda:0') tensor(2.6519e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.060242
Average KL loss: 0.627933
Average total loss: 0.688175
tensor(-10.5610, device='cuda:0') tensor(3.7926, device='cuda:0') tensor(2.8977e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.060606
Average KL loss: 0.626629
Average total loss: 0.687235
tensor(-10.5805, device='cuda:0') tensor(3.7957, device='cuda:0') tensor(2.6826e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.060138
Average KL loss: 0.625696
Average total loss: 0.685834
tensor(-10.5999, device='cuda:0') tensor(3.7987, device='cuda:0') tensor(2.6268e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.060140
Average KL loss: 0.624781
Average total loss: 0.684921
tensor(-10.6192, device='cuda:0') tensor(3.8016, device='cuda:0') tensor(2.8269e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.058969
Average KL loss: 0.624016
Average total loss: 0.682984
tensor(-10.6385, device='cuda:0') tensor(3.8044, device='cuda:0') tensor(2.7015e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.058435
Average KL loss: 0.623122
Average total loss: 0.681557
tensor(-10.6576, device='cuda:0') tensor(3.8074, device='cuda:0') tensor(1.9974e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.058734
Average KL loss: 0.622297
Average total loss: 0.681030
tensor(-10.6767, device='cuda:0') tensor(3.8100, device='cuda:0') tensor(2.5193e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.056751
Average KL loss: 0.621328
Average total loss: 0.678078
tensor(-10.6957, device='cuda:0') tensor(3.8119, device='cuda:0') tensor(2.0492e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.057878
Average KL loss: 0.620432
Average total loss: 0.678310
tensor(-10.7146, device='cuda:0') tensor(3.8148, device='cuda:0') tensor(2.8917e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.056382
Average KL loss: 0.619759
Average total loss: 0.676141
tensor(-10.7334, device='cuda:0') tensor(3.8171, device='cuda:0') tensor(2.5462e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.056544
Average KL loss: 0.618788
Average total loss: 0.675332
tensor(-10.7523, device='cuda:0') tensor(3.8194, device='cuda:0') tensor(2.1878e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.056278
Average KL loss: 0.617916
Average total loss: 0.674194
tensor(-10.7710, device='cuda:0') tensor(3.8216, device='cuda:0') tensor(1.5195e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.056448
Average KL loss: 0.617003
Average total loss: 0.673450
tensor(-10.7896, device='cuda:0') tensor(3.8242, device='cuda:0') tensor(1.9176e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.054865
Average KL loss: 0.616004
Average total loss: 0.670869
tensor(-10.8082, device='cuda:0') tensor(3.8261, device='cuda:0') tensor(2.5714e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.055446
Average KL loss: 0.614899
Average total loss: 0.670344
tensor(-10.8266, device='cuda:0') tensor(3.8277, device='cuda:0') tensor(2.3940e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.054867
Average KL loss: 0.613993
Average total loss: 0.668860
tensor(-10.8451, device='cuda:0') tensor(3.8293, device='cuda:0') tensor(2.4847e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.054687
Average KL loss: 0.612984
Average total loss: 0.667672
tensor(-10.8634, device='cuda:0') tensor(3.8311, device='cuda:0') tensor(2.0288e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.054721
Average KL loss: 0.612128
Average total loss: 0.666849
tensor(-10.8816, device='cuda:0') tensor(3.8330, device='cuda:0') tensor(2.3911e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.055689
Average KL loss: 0.611332
Average total loss: 0.667021
tensor(-10.8998, device='cuda:0') tensor(3.8351, device='cuda:0') tensor(2.0960e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.054203
Average KL loss: 0.610766
Average total loss: 0.664969
tensor(-10.9178, device='cuda:0') tensor(3.8375, device='cuda:0') tensor(2.2535e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.055127
Average KL loss: 0.610043
Average total loss: 0.665170
tensor(-10.9359, device='cuda:0') tensor(3.8395, device='cuda:0') tensor(2.2266e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.053741
Average KL loss: 0.609363
Average total loss: 0.663104
tensor(-10.9538, device='cuda:0') tensor(3.8409, device='cuda:0') tensor(1.7414e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.053889
Average KL loss: 0.608788
Average total loss: 0.662677
tensor(-10.9717, device='cuda:0') tensor(3.8421, device='cuda:0') tensor(1.3238e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.054397
Average KL loss: 0.608170
Average total loss: 0.662567
tensor(-10.9894, device='cuda:0') tensor(3.8441, device='cuda:0') tensor(2.5522e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.053472
Average KL loss: 0.607807
Average total loss: 0.661279
tensor(-11.0072, device='cuda:0') tensor(3.8453, device='cuda:0') tensor(1.2427e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.053296
Average KL loss: 0.607094
Average total loss: 0.660390
tensor(-11.0248, device='cuda:0') tensor(3.8475, device='cuda:0') tensor(2.4546e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.053663
Average KL loss: 0.606518
Average total loss: 0.660181
tensor(-11.0423, device='cuda:0') tensor(3.8491, device='cuda:0') tensor(2.4573e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.052992
Average KL loss: 0.605896
Average total loss: 0.658888
tensor(-11.0599, device='cuda:0') tensor(3.8494, device='cuda:0') tensor(2.0498e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.052148
Average KL loss: 0.605161
Average total loss: 0.657309
tensor(-11.0773, device='cuda:0') tensor(3.8502, device='cuda:0') tensor(2.0731e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.050332
Average KL loss: 0.604346
Average total loss: 0.654678
tensor(-11.0947, device='cuda:0') tensor(3.8503, device='cuda:0') tensor(2.2147e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.050750
Average KL loss: 0.603316
Average total loss: 0.654067
tensor(-11.1120, device='cuda:0') tensor(3.8506, device='cuda:0') tensor(1.9881e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.051738
Average KL loss: 0.602512
Average total loss: 0.654250
tensor(-11.1292, device='cuda:0') tensor(3.8513, device='cuda:0') tensor(1.9192e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.052153
Average KL loss: 0.601699
Average total loss: 0.653852
tensor(-11.1463, device='cuda:0') tensor(3.8519, device='cuda:0') tensor(1.5695e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.051168
Average KL loss: 0.601068
Average total loss: 0.652236
tensor(-11.1634, device='cuda:0') tensor(3.8522, device='cuda:0') tensor(1.4442e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.051038
Average KL loss: 0.600485
Average total loss: 0.651523
tensor(-11.1804, device='cuda:0') tensor(3.8524, device='cuda:0') tensor(1.4501e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.049823
Average KL loss: 0.599672
Average total loss: 0.649495
tensor(-11.1973, device='cuda:0') tensor(3.8529, device='cuda:0') tensor(1.5218e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.049836
Average KL loss: 0.598894
Average total loss: 0.648730
tensor(-11.2142, device='cuda:0') tensor(3.8524, device='cuda:0') tensor(1.4604e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.049819
Average KL loss: 0.597987
Average total loss: 0.647806
tensor(-11.2310, device='cuda:0') tensor(3.8522, device='cuda:0') tensor(1.6903e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.050187
Average KL loss: 0.597276
Average total loss: 0.647463
tensor(-11.2477, device='cuda:0') tensor(3.8524, device='cuda:0') tensor(1.5458e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.049218
Average KL loss: 0.596622
Average total loss: 0.645840
tensor(-11.2643, device='cuda:0') tensor(3.8521, device='cuda:0') tensor(2.5535e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.050404
Average KL loss: 0.596015
Average total loss: 0.646419
tensor(-11.2809, device='cuda:0') tensor(3.8521, device='cuda:0') tensor(1.5688e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.050216
Average KL loss: 0.595344
Average total loss: 0.645561
tensor(-11.2974, device='cuda:0') tensor(3.8516, device='cuda:0') tensor(1.4328e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.049468
Average KL loss: 0.594678
Average total loss: 0.644146
tensor(-11.3138, device='cuda:0') tensor(3.8516, device='cuda:0') tensor(1.1293e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.048860
Average KL loss: 0.594163
Average total loss: 0.643023
tensor(-11.3302, device='cuda:0') tensor(3.8516, device='cuda:0') tensor(1.4296e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.049948
Average KL loss: 0.593515
Average total loss: 0.643463
tensor(-11.3464, device='cuda:0') tensor(3.8510, device='cuda:0') tensor(1.6543e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.049272
Average KL loss: 0.593029
Average total loss: 0.642300
tensor(-11.3627, device='cuda:0') tensor(3.8504, device='cuda:0') tensor(1.2376e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.050145
Average KL loss: 0.592558
Average total loss: 0.642703
tensor(-11.3787, device='cuda:0') tensor(3.8503, device='cuda:0') tensor(1.8667e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.048604
Average KL loss: 0.591985
Average total loss: 0.640589
tensor(-11.3948, device='cuda:0') tensor(3.8494, device='cuda:0') tensor(1.2072e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.048510
Average KL loss: 0.591197
Average total loss: 0.639706
tensor(-11.4107, device='cuda:0') tensor(3.8486, device='cuda:0') tensor(1.1957e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.049269
Average KL loss: 0.590502
Average total loss: 0.639771
tensor(-11.4266, device='cuda:0') tensor(3.8479, device='cuda:0') tensor(1.1664e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.048033
Average KL loss: 0.589971
Average total loss: 0.638005
tensor(-11.4425, device='cuda:0') tensor(3.8470, device='cuda:0') tensor(1.8186e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.048185
Average KL loss: 0.589490
Average total loss: 0.637675
 Percentile value: -12.438299179077148
Non-zero model percentage: 80.0%, Non-zero mask percentage: 80.0%

--- Pruning Level [1/24]: ---
conv1.weight         | nonzeros =    1722 /    1728             ( 99.65%) | total_pruned =       6 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   35764 /   36864             ( 97.02%) | total_pruned =    1100 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   35855 /   36864             ( 97.26%) | total_pruned =    1009 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   35776 /   36864             ( 97.05%) | total_pruned =    1088 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   35500 /   36864             ( 96.30%) | total_pruned =    1364 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   70962 /   73728             ( 96.25%) | total_pruned =    2766 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  139145 /  147456             ( 94.36%) | total_pruned =    8311 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8125 /    8192             ( 99.18%) | total_pruned =      67 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  137856 /  147456             ( 93.49%) | total_pruned =    9600 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  136806 /  147456             ( 92.78%) | total_pruned =   10650 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  276031 /  294912             ( 93.60%) | total_pruned =   18881 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  536626 /  589824             ( 90.98%) | total_pruned =   53198 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   31927 /   32768             ( 97.43%) | total_pruned =     841 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  517360 /  589824             ( 87.71%) | total_pruned =   72464 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  508781 /  589824             ( 86.26%) | total_pruned =   81043 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1059026 / 1179648             ( 89.77%) | total_pruned =  120622 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1895671 / 2359296             ( 80.35%) | total_pruned =  463625 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  124000 /  131072             ( 94.60%) | total_pruned =    7072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1742868 / 2359296             ( 73.87%) | total_pruned =  616428 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1598492 / 2359296             ( 67.75%) | total_pruned =  760804 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    5113 /    5120             ( 99.86%) | total_pruned =       7 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 8943010, pruned : 2235752, total: 11178762, Compression rate :       1.25x  ( 20.00% pruned)
Train Epoch: 31/100 Loss: 0.000085 Accuracy: 87.20 100.00 % Best test Accuracy: 87.27%
tensor(-11.4582, device='cuda:0') tensor(3.8461, device='cuda:0') tensor(2.1123e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.130016
Average KL loss: 0.579541
Average total loss: 0.709557
tensor(-11.5804, device='cuda:0') tensor(3.0835, device='cuda:0') tensor(-1.6218e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.156160
Average KL loss: 0.565859
Average total loss: 0.722019
tensor(-11.6609, device='cuda:0') tensor(2.7308, device='cuda:0') tensor(-8.9292e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.181417
Average KL loss: 0.554375
Average total loss: 0.735792
tensor(-11.7248, device='cuda:0') tensor(2.5308, device='cuda:0') tensor(-3.9264e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.194548
Average KL loss: 0.546633
Average total loss: 0.741181
tensor(-11.7796, device='cuda:0') tensor(2.3996, device='cuda:0') tensor(-3.8264e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.199049
Average KL loss: 0.540937
Average total loss: 0.739986
tensor(-11.8282, device='cuda:0') tensor(2.3070, device='cuda:0') tensor(-3.4539e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.196029
Average KL loss: 0.536792
Average total loss: 0.732821
tensor(-11.8724, device='cuda:0') tensor(2.2374, device='cuda:0') tensor(-2.7199e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.196456
Average KL loss: 0.533132
Average total loss: 0.729588
tensor(-11.9132, device='cuda:0') tensor(2.1839, device='cuda:0') tensor(-3.6612e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.186461
Average KL loss: 0.530309
Average total loss: 0.716770
tensor(-11.9512, device='cuda:0') tensor(2.1422, device='cuda:0') tensor(-5.6305e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.182824
Average KL loss: 0.528265
Average total loss: 0.711088
tensor(-11.9868, device='cuda:0') tensor(2.1095, device='cuda:0') tensor(-1.8378e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.175293
Average KL loss: 0.526481
Average total loss: 0.701774
tensor(-12.0204, device='cuda:0') tensor(2.0822, device='cuda:0') tensor(-4.8193e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.173252
Average KL loss: 0.524630
Average total loss: 0.697882
tensor(-12.0524, device='cuda:0') tensor(2.0595, device='cuda:0') tensor(-1.5900e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.170610
Average KL loss: 0.522955
Average total loss: 0.693565
tensor(-12.0828, device='cuda:0') tensor(2.0408, device='cuda:0') tensor(-2.5417e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.161638
Average KL loss: 0.521358
Average total loss: 0.682997
tensor(-12.1120, device='cuda:0') tensor(2.0246, device='cuda:0') tensor(-1.1451e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.161234
Average KL loss: 0.519876
Average total loss: 0.681110
tensor(-12.1399, device='cuda:0') tensor(2.0115, device='cuda:0') tensor(-1.7093e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.157088
Average KL loss: 0.518430
Average total loss: 0.675518
tensor(-12.1668, device='cuda:0') tensor(2.0002, device='cuda:0') tensor(-3.5561e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.154394
Average KL loss: 0.517117
Average total loss: 0.671511
tensor(-12.1927, device='cuda:0') tensor(1.9915, device='cuda:0') tensor(-2.0122e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.148489
Average KL loss: 0.516035
Average total loss: 0.664524
tensor(-12.2177, device='cuda:0') tensor(1.9840, device='cuda:0') tensor(-9.8983e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.145780
Average KL loss: 0.515063
Average total loss: 0.660842
tensor(-12.2420, device='cuda:0') tensor(1.9779, device='cuda:0') tensor(-1.5546e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.142171
Average KL loss: 0.514160
Average total loss: 0.656331
tensor(-12.2654, device='cuda:0') tensor(1.9728, device='cuda:0') tensor(-5.5686e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.142029
Average KL loss: 0.512864
Average total loss: 0.654893
tensor(-12.2882, device='cuda:0') tensor(1.9682, device='cuda:0') tensor(-3.8112e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.139888
Average KL loss: 0.511695
Average total loss: 0.651583
tensor(-12.3103, device='cuda:0') tensor(1.9648, device='cuda:0') tensor(-9.1022e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.137675
Average KL loss: 0.511054
Average total loss: 0.648729
tensor(-12.3318, device='cuda:0') tensor(1.9626, device='cuda:0') tensor(-3.2724e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.136251
Average KL loss: 0.510229
Average total loss: 0.646480
tensor(-12.3527, device='cuda:0') tensor(1.9609, device='cuda:0') tensor(-6.9036e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.133864
Average KL loss: 0.509357
Average total loss: 0.643221
tensor(-12.3731, device='cuda:0') tensor(1.9600, device='cuda:0') tensor(-1.0410e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.131583
Average KL loss: 0.508567
Average total loss: 0.640150
tensor(-12.3930, device='cuda:0') tensor(1.9597, device='cuda:0') tensor(-2.5728e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.128546
Average KL loss: 0.507965
Average total loss: 0.636511
tensor(-12.4124, device='cuda:0') tensor(1.9599, device='cuda:0') tensor(-1.3749e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.126214
Average KL loss: 0.507189
Average total loss: 0.633403
tensor(-12.4313, device='cuda:0') tensor(1.9604, device='cuda:0') tensor(3.3170e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.122896
Average KL loss: 0.506395
Average total loss: 0.629291
tensor(-12.4498, device='cuda:0') tensor(1.9612, device='cuda:0') tensor(-3.6464e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.120726
Average KL loss: 0.505689
Average total loss: 0.626416
tensor(-12.4680, device='cuda:0') tensor(1.9620, device='cuda:0') tensor(-2.2834e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.118955
Average KL loss: 0.505111
Average total loss: 0.624067
tensor(-12.4857, device='cuda:0') tensor(1.9638, device='cuda:0') tensor(-5.9528e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.115626
Average KL loss: 0.504445
Average total loss: 0.620071
tensor(-12.5031, device='cuda:0') tensor(1.9655, device='cuda:0') tensor(5.0380e-11, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.114047
Average KL loss: 0.503863
Average total loss: 0.617911
tensor(-12.5202, device='cuda:0') tensor(1.9670, device='cuda:0') tensor(4.7563e-12, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.112322
Average KL loss: 0.503214
Average total loss: 0.615535
tensor(-12.5369, device='cuda:0') tensor(1.9681, device='cuda:0') tensor(-1.4293e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.112881
Average KL loss: 0.502437
Average total loss: 0.615318
tensor(-12.5533, device='cuda:0') tensor(1.9697, device='cuda:0') tensor(-7.3731e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.111461
Average KL loss: 0.501726
Average total loss: 0.613187
tensor(-12.5694, device='cuda:0') tensor(1.9722, device='cuda:0') tensor(-1.1719e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.109899
Average KL loss: 0.501099
Average total loss: 0.610998
tensor(-12.5852, device='cuda:0') tensor(1.9746, device='cuda:0') tensor(-8.0946e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.109656
Average KL loss: 0.500476
Average total loss: 0.610132
tensor(-12.6007, device='cuda:0') tensor(1.9770, device='cuda:0') tensor(-2.3829e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.106854
Average KL loss: 0.499903
Average total loss: 0.606756
tensor(-12.6159, device='cuda:0') tensor(1.9798, device='cuda:0') tensor(5.5144e-12, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.107150
Average KL loss: 0.499357
Average total loss: 0.606507
tensor(-12.6309, device='cuda:0') tensor(1.9823, device='cuda:0') tensor(2.3629e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.105778
Average KL loss: 0.498897
Average total loss: 0.604675
tensor(-12.6457, device='cuda:0') tensor(1.9847, device='cuda:0') tensor(-2.4822e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.106718
Average KL loss: 0.498408
Average total loss: 0.605126
tensor(-12.6602, device='cuda:0') tensor(1.9880, device='cuda:0') tensor(8.5044e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.104965
Average KL loss: 0.497909
Average total loss: 0.602873
tensor(-12.6744, device='cuda:0') tensor(1.9912, device='cuda:0') tensor(-1.0999e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.101732
Average KL loss: 0.497557
Average total loss: 0.599288
tensor(-12.6885, device='cuda:0') tensor(1.9942, device='cuda:0') tensor(6.1465e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.101454
Average KL loss: 0.496936
Average total loss: 0.598390
tensor(-12.7023, device='cuda:0') tensor(1.9967, device='cuda:0') tensor(-1.5667e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.102923
Average KL loss: 0.496284
Average total loss: 0.599207
tensor(-12.7159, device='cuda:0') tensor(2.0000, device='cuda:0') tensor(-5.0542e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.099529
Average KL loss: 0.495743
Average total loss: 0.595272
tensor(-12.7293, device='cuda:0') tensor(2.0032, device='cuda:0') tensor(-8.7160e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.098000
Average KL loss: 0.495248
Average total loss: 0.593248
tensor(-12.7425, device='cuda:0') tensor(2.0065, device='cuda:0') tensor(-1.9923e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.097846
Average KL loss: 0.494868
Average total loss: 0.592715
tensor(-12.7555, device='cuda:0') tensor(2.0099, device='cuda:0') tensor(-3.1049e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.098225
Average KL loss: 0.494518
Average total loss: 0.592743
tensor(-12.7684, device='cuda:0') tensor(2.0130, device='cuda:0') tensor(2.3636e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.098347
Average KL loss: 0.494190
Average total loss: 0.592537
tensor(-12.7811, device='cuda:0') tensor(2.0167, device='cuda:0') tensor(5.2737e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.095695
Average KL loss: 0.493800
Average total loss: 0.589495
tensor(-12.7936, device='cuda:0') tensor(2.0197, device='cuda:0') tensor(-1.5601e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.095737
Average KL loss: 0.493320
Average total loss: 0.589057
tensor(-12.8059, device='cuda:0') tensor(2.0233, device='cuda:0') tensor(4.6323e-13, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.094710
Average KL loss: 0.492968
Average total loss: 0.587678
tensor(-12.8181, device='cuda:0') tensor(2.0264, device='cuda:0') tensor(-7.9950e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.091909
Average KL loss: 0.492619
Average total loss: 0.584528
tensor(-12.8301, device='cuda:0') tensor(2.0294, device='cuda:0') tensor(8.1072e-11, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.092803
Average KL loss: 0.492258
Average total loss: 0.585061
tensor(-12.8420, device='cuda:0') tensor(2.0329, device='cuda:0') tensor(-3.9718e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.091269
Average KL loss: 0.491865
Average total loss: 0.583134
tensor(-12.8537, device='cuda:0') tensor(2.0364, device='cuda:0') tensor(6.7846e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.091382
Average KL loss: 0.491488
Average total loss: 0.582870
tensor(-12.8653, device='cuda:0') tensor(2.0398, device='cuda:0') tensor(7.3307e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.087379
Average KL loss: 0.491003
Average total loss: 0.578382
tensor(-12.8767, device='cuda:0') tensor(2.0424, device='cuda:0') tensor(-3.2146e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.090497
Average KL loss: 0.490577
Average total loss: 0.581074
tensor(-12.8880, device='cuda:0') tensor(2.0454, device='cuda:0') tensor(-5.6045e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.089067
Average KL loss: 0.490170
Average total loss: 0.579238
tensor(-12.8992, device='cuda:0') tensor(2.0487, device='cuda:0') tensor(-9.1025e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.088783
Average KL loss: 0.489783
Average total loss: 0.578566
tensor(-12.9102, device='cuda:0') tensor(2.0523, device='cuda:0') tensor(-7.6034e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.087873
Average KL loss: 0.489453
Average total loss: 0.577326
tensor(-12.9211, device='cuda:0') tensor(2.0559, device='cuda:0') tensor(-5.6494e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.088158
Average KL loss: 0.489009
Average total loss: 0.577168
tensor(-12.9319, device='cuda:0') tensor(2.0590, device='cuda:0') tensor(-5.0325e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.087723
Average KL loss: 0.488681
Average total loss: 0.576404
tensor(-12.9425, device='cuda:0') tensor(2.0632, device='cuda:0') tensor(-1.6979e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.085930
Average KL loss: 0.488329
Average total loss: 0.574260
tensor(-12.9530, device='cuda:0') tensor(2.0665, device='cuda:0') tensor(-7.0842e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.084292
Average KL loss: 0.487941
Average total loss: 0.572234
tensor(-12.9634, device='cuda:0') tensor(2.0697, device='cuda:0') tensor(-7.0516e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.085318
Average KL loss: 0.487566
Average total loss: 0.572884
tensor(-12.9737, device='cuda:0') tensor(2.0730, device='cuda:0') tensor(-7.0204e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.085999
Average KL loss: 0.487399
Average total loss: 0.573398
tensor(-12.9839, device='cuda:0') tensor(2.0767, device='cuda:0') tensor(-3.3648e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.085413
Average KL loss: 0.487114
Average total loss: 0.572527
tensor(-12.9940, device='cuda:0') tensor(2.0799, device='cuda:0') tensor(-2.4383e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.083828
Average KL loss: 0.486836
Average total loss: 0.570664
tensor(-13.0039, device='cuda:0') tensor(2.0840, device='cuda:0') tensor(-3.7438e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.082573
Average KL loss: 0.486531
Average total loss: 0.569104
tensor(-13.0138, device='cuda:0') tensor(2.0868, device='cuda:0') tensor(1.7452e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.082147
Average KL loss: 0.486212
Average total loss: 0.568359
tensor(-13.0236, device='cuda:0') tensor(2.0902, device='cuda:0') tensor(2.9684e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.082891
Average KL loss: 0.485942
Average total loss: 0.568833
tensor(-13.0333, device='cuda:0') tensor(2.0935, device='cuda:0') tensor(-1.8545e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.081029
Average KL loss: 0.485693
Average total loss: 0.566722
tensor(-13.0429, device='cuda:0') tensor(2.0966, device='cuda:0') tensor(5.0081e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.081695
Average KL loss: 0.485344
Average total loss: 0.567038
tensor(-13.0523, device='cuda:0') tensor(2.1002, device='cuda:0') tensor(-3.3755e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.081308
Average KL loss: 0.485135
Average total loss: 0.566443
tensor(-13.0617, device='cuda:0') tensor(2.1037, device='cuda:0') tensor(-8.1511e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.079656
Average KL loss: 0.484893
Average total loss: 0.564549
tensor(-13.0710, device='cuda:0') tensor(2.1074, device='cuda:0') tensor(4.1380e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.079768
Average KL loss: 0.484627
Average total loss: 0.564395
tensor(-13.0802, device='cuda:0') tensor(2.1103, device='cuda:0') tensor(3.2518e-12, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.080850
Average KL loss: 0.484264
Average total loss: 0.565113
tensor(-13.0894, device='cuda:0') tensor(2.1133, device='cuda:0') tensor(-2.7936e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.081328
Average KL loss: 0.484013
Average total loss: 0.565341
tensor(-13.0984, device='cuda:0') tensor(2.1168, device='cuda:0') tensor(-1.1087e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.079738
Average KL loss: 0.483684
Average total loss: 0.563422
tensor(-13.1074, device='cuda:0') tensor(2.1203, device='cuda:0') tensor(2.3019e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.078671
Average KL loss: 0.483377
Average total loss: 0.562048
tensor(-13.1162, device='cuda:0') tensor(2.1237, device='cuda:0') tensor(-6.0146e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.078306
Average KL loss: 0.483139
Average total loss: 0.561444
tensor(-13.1250, device='cuda:0') tensor(2.1267, device='cuda:0') tensor(-1.4598e-12, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.078227
Average KL loss: 0.482900
Average total loss: 0.561127
tensor(-13.1338, device='cuda:0') tensor(2.1297, device='cuda:0') tensor(1.4139e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.078285
Average KL loss: 0.482638
Average total loss: 0.560923
tensor(-13.1424, device='cuda:0') tensor(2.1331, device='cuda:0') tensor(5.2910e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.077971
Average KL loss: 0.482476
Average total loss: 0.560447
tensor(-13.1510, device='cuda:0') tensor(2.1363, device='cuda:0') tensor(-2.6932e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.077951
Average KL loss: 0.482226
Average total loss: 0.560178
tensor(-13.1595, device='cuda:0') tensor(2.1393, device='cuda:0') tensor(-4.0554e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.077576
Average KL loss: 0.482001
Average total loss: 0.559576
tensor(-13.1679, device='cuda:0') tensor(2.1425, device='cuda:0') tensor(4.1483e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.077519
Average KL loss: 0.481737
Average total loss: 0.559256
tensor(-13.1762, device='cuda:0') tensor(2.1458, device='cuda:0') tensor(-2.0372e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.075789
Average KL loss: 0.481499
Average total loss: 0.557288
tensor(-13.1845, device='cuda:0') tensor(2.1494, device='cuda:0') tensor(-1.6509e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.075913
Average KL loss: 0.481309
Average total loss: 0.557221
tensor(-13.1927, device='cuda:0') tensor(2.1528, device='cuda:0') tensor(-8.1616e-11, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.075501
Average KL loss: 0.480957
Average total loss: 0.556458
tensor(-13.2008, device='cuda:0') tensor(2.1560, device='cuda:0') tensor(2.7861e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.077227
Average KL loss: 0.480737
Average total loss: 0.557963
tensor(-13.2089, device='cuda:0') tensor(2.1592, device='cuda:0') tensor(1.9057e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.075115
Average KL loss: 0.480546
Average total loss: 0.555662
tensor(-13.2169, device='cuda:0') tensor(2.1622, device='cuda:0') tensor(-2.7645e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.074895
Average KL loss: 0.480290
Average total loss: 0.555184
tensor(-13.2248, device='cuda:0') tensor(2.1651, device='cuda:0') tensor(-3.6329e-11, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.074724
Average KL loss: 0.480063
Average total loss: 0.554787
tensor(-13.2327, device='cuda:0') tensor(2.1682, device='cuda:0') tensor(-7.5963e-11, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.074393
Average KL loss: 0.479992
Average total loss: 0.554385
tensor(-13.2405, device='cuda:0') tensor(2.1711, device='cuda:0') tensor(-4.7565e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.075116
Average KL loss: 0.479781
Average total loss: 0.554897
tensor(-13.2483, device='cuda:0') tensor(2.1741, device='cuda:0') tensor(1.5425e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.074484
Average KL loss: 0.479552
Average total loss: 0.554037
tensor(-13.2560, device='cuda:0') tensor(2.1774, device='cuda:0') tensor(-2.8283e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.074003
Average KL loss: 0.479389
Average total loss: 0.553392
tensor(-13.2636, device='cuda:0') tensor(2.1805, device='cuda:0') tensor(-2.4860e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.073962
Average KL loss: 0.479163
Average total loss: 0.553124
tensor(-13.2712, device='cuda:0') tensor(2.1836, device='cuda:0') tensor(-5.6178e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.073941
Average KL loss: 0.478959
Average total loss: 0.552900
tensor(-13.2787, device='cuda:0') tensor(2.1863, device='cuda:0') tensor(-1.3396e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.074556
Average KL loss: 0.478747
Average total loss: 0.553302
tensor(-13.2862, device='cuda:0') tensor(2.1896, device='cuda:0') tensor(-1.8065e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.073090
Average KL loss: 0.478638
Average total loss: 0.551728
tensor(-13.2936, device='cuda:0') tensor(2.1928, device='cuda:0') tensor(1.7300e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.073590
Average KL loss: 0.478558
Average total loss: 0.552148
tensor(-13.3009, device='cuda:0') tensor(2.1962, device='cuda:0') tensor(-4.8483e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.072871
Average KL loss: 0.478351
Average total loss: 0.551222
tensor(-13.3082, device='cuda:0') tensor(2.1992, device='cuda:0') tensor(-2.6758e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.072373
Average KL loss: 0.478124
Average total loss: 0.550497
tensor(-13.3155, device='cuda:0') tensor(2.2022, device='cuda:0') tensor(1.2945e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.073832
Average KL loss: 0.477927
Average total loss: 0.551759
tensor(-13.3227, device='cuda:0') tensor(2.2051, device='cuda:0') tensor(-3.3416e-11, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.074092
Average KL loss: 0.477739
Average total loss: 0.551830
tensor(-13.3298, device='cuda:0') tensor(2.2082, device='cuda:0') tensor(-9.6367e-11, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.072569
Average KL loss: 0.477568
Average total loss: 0.550136
tensor(-13.3369, device='cuda:0') tensor(2.2114, device='cuda:0') tensor(-3.5006e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.072933
Average KL loss: 0.477429
Average total loss: 0.550361
tensor(-13.3439, device='cuda:0') tensor(2.2146, device='cuda:0') tensor(-1.8523e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.072128
Average KL loss: 0.477291
Average total loss: 0.549418
tensor(-13.3509, device='cuda:0') tensor(2.2173, device='cuda:0') tensor(7.1079e-11, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.073207
Average KL loss: 0.477114
Average total loss: 0.550320
tensor(-13.3579, device='cuda:0') tensor(2.2202, device='cuda:0') tensor(8.8531e-12, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.072134
Average KL loss: 0.476915
Average total loss: 0.549050
tensor(-13.3648, device='cuda:0') tensor(2.2234, device='cuda:0') tensor(2.5702e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.072739
Average KL loss: 0.476758
Average total loss: 0.549497
tensor(-13.3716, device='cuda:0') tensor(2.2259, device='cuda:0') tensor(-4.1806e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.071899
Average KL loss: 0.476558
Average total loss: 0.548457
tensor(-13.3784, device='cuda:0') tensor(2.2292, device='cuda:0') tensor(-2.9278e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.072737
Average KL loss: 0.476320
Average total loss: 0.549057
tensor(-13.3852, device='cuda:0') tensor(2.2314, device='cuda:0') tensor(-3.4010e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.071918
Average KL loss: 0.476146
Average total loss: 0.548063
tensor(-13.3919, device='cuda:0') tensor(2.2341, device='cuda:0') tensor(2.4364e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.072159
Average KL loss: 0.475909
Average total loss: 0.548068
tensor(-13.3985, device='cuda:0') tensor(2.2369, device='cuda:0') tensor(1.3878e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.070862
Average KL loss: 0.475688
Average total loss: 0.546550
tensor(-13.4052, device='cuda:0') tensor(2.2393, device='cuda:0') tensor(7.9395e-12, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.072550
Average KL loss: 0.475471
Average total loss: 0.548020
tensor(-13.4118, device='cuda:0') tensor(2.2420, device='cuda:0') tensor(-6.2890e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.072291
Average KL loss: 0.475290
Average total loss: 0.547580
tensor(-13.4183, device='cuda:0') tensor(2.2442, device='cuda:0') tensor(5.2876e-11, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.072163
Average KL loss: 0.475107
Average total loss: 0.547270
tensor(-13.4248, device='cuda:0') tensor(2.2466, device='cuda:0') tensor(-5.8158e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.071216
Average KL loss: 0.474903
Average total loss: 0.546118
tensor(-13.4313, device='cuda:0') tensor(2.2491, device='cuda:0') tensor(4.2348e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.071408
Average KL loss: 0.474678
Average total loss: 0.546086
tensor(-13.4377, device='cuda:0') tensor(2.2521, device='cuda:0') tensor(-5.9239e-11, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.071973
Average KL loss: 0.474460
Average total loss: 0.546433
tensor(-13.4440, device='cuda:0') tensor(2.2549, device='cuda:0') tensor(5.0098e-11, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.071043
Average KL loss: 0.474325
Average total loss: 0.545368
tensor(-13.4504, device='cuda:0') tensor(2.2578, device='cuda:0') tensor(1.3673e-11, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.070921
Average KL loss: 0.474166
Average total loss: 0.545087
tensor(-13.4567, device='cuda:0') tensor(2.2602, device='cuda:0') tensor(1.1827e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.070931
Average KL loss: 0.473890
Average total loss: 0.544821
tensor(-13.4629, device='cuda:0') tensor(2.2625, device='cuda:0') tensor(-1.9102e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.070980
Average KL loss: 0.473690
Average total loss: 0.544670
tensor(-13.4692, device='cuda:0') tensor(2.2654, device='cuda:0') tensor(-7.6962e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.071364
Average KL loss: 0.473553
Average total loss: 0.544917
tensor(-13.4753, device='cuda:0') tensor(2.2683, device='cuda:0') tensor(-6.1355e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.071869
Average KL loss: 0.473339
Average total loss: 0.545208
tensor(-13.4815, device='cuda:0') tensor(2.2713, device='cuda:0') tensor(2.3852e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.069431
Average KL loss: 0.473283
Average total loss: 0.542713
tensor(-13.4876, device='cuda:0') tensor(2.2743, device='cuda:0') tensor(-3.9742e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.069454
Average KL loss: 0.473195
Average total loss: 0.542648
tensor(-13.4936, device='cuda:0') tensor(2.2765, device='cuda:0') tensor(2.6720e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.070293
Average KL loss: 0.472980
Average total loss: 0.543273
tensor(-13.4997, device='cuda:0') tensor(2.2781, device='cuda:0') tensor(-4.8051e-11, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.070634
Average KL loss: 0.472723
Average total loss: 0.543357
tensor(-13.5057, device='cuda:0') tensor(2.2804, device='cuda:0') tensor(-6.8918e-11, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.070662
Average KL loss: 0.472531
Average total loss: 0.543194
tensor(-13.5117, device='cuda:0') tensor(2.2825, device='cuda:0') tensor(-4.8814e-11, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.070027
Average KL loss: 0.472353
Average total loss: 0.542380
tensor(-13.5176, device='cuda:0') tensor(2.2853, device='cuda:0') tensor(-3.3430e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.070042
Average KL loss: 0.472134
Average total loss: 0.542176
tensor(-13.5235, device='cuda:0') tensor(2.2877, device='cuda:0') tensor(-9.3293e-11, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.069803
Average KL loss: 0.472025
Average total loss: 0.541828
tensor(-13.5294, device='cuda:0') tensor(2.2901, device='cuda:0') tensor(-8.0775e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.070056
Average KL loss: 0.471884
Average total loss: 0.541940
tensor(-13.5352, device='cuda:0') tensor(2.2928, device='cuda:0') tensor(-2.5026e-11, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.069950
Average KL loss: 0.471629
Average total loss: 0.541578
tensor(-13.5410, device='cuda:0') tensor(2.2951, device='cuda:0') tensor(8.8594e-11, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.069768
Average KL loss: 0.471488
Average total loss: 0.541255
tensor(-13.5467, device='cuda:0') tensor(2.2977, device='cuda:0') tensor(1.1142e-11, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.069964
Average KL loss: 0.471289
Average total loss: 0.541253
tensor(-13.5525, device='cuda:0') tensor(2.2997, device='cuda:0') tensor(-3.9274e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.070501
Average KL loss: 0.471111
Average total loss: 0.541611
tensor(-13.5582, device='cuda:0') tensor(2.3022, device='cuda:0') tensor(-5.3296e-11, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.069750
Average KL loss: 0.470969
Average total loss: 0.540719
tensor(-13.5638, device='cuda:0') tensor(2.3039, device='cuda:0') tensor(-4.3570e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.070186
Average KL loss: 0.470796
Average total loss: 0.540983
tensor(-13.5695, device='cuda:0') tensor(2.3063, device='cuda:0') tensor(-4.6638e-11, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.069400
Average KL loss: 0.470672
Average total loss: 0.540071
tensor(-13.5751, device='cuda:0') tensor(2.3089, device='cuda:0') tensor(-2.8346e-11, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.070151
Average KL loss: 0.470609
Average total loss: 0.540761
tensor(-13.5806, device='cuda:0') tensor(2.3114, device='cuda:0') tensor(2.0070e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.069435
Average KL loss: 0.470504
Average total loss: 0.539939
tensor(-13.5862, device='cuda:0') tensor(2.3138, device='cuda:0') tensor(1.6473e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.069806
Average KL loss: 0.470348
Average total loss: 0.540154
tensor(-13.5917, device='cuda:0') tensor(2.3157, device='cuda:0') tensor(9.0182e-11, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.068741
Average KL loss: 0.470164
Average total loss: 0.538905
tensor(-13.5972, device='cuda:0') tensor(2.3178, device='cuda:0') tensor(-3.3479e-12, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.068901
Average KL loss: 0.470024
Average total loss: 0.538925
tensor(-13.6026, device='cuda:0') tensor(2.3203, device='cuda:0') tensor(-2.2379e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.069686
Average KL loss: 0.469943
Average total loss: 0.539628
tensor(-13.6081, device='cuda:0') tensor(2.3227, device='cuda:0') tensor(-4.0420e-11, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.069659
Average KL loss: 0.469820
Average total loss: 0.539479
tensor(-13.6135, device='cuda:0') tensor(2.3251, device='cuda:0') tensor(1.0789e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.069329
Average KL loss: 0.469707
Average total loss: 0.539036
tensor(-13.6188, device='cuda:0') tensor(2.3270, device='cuda:0') tensor(-9.6711e-11, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.068185
Average KL loss: 0.469579
Average total loss: 0.537764
tensor(-13.6242, device='cuda:0') tensor(2.3290, device='cuda:0') tensor(-4.3480e-11, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.069522
Average KL loss: 0.469403
Average total loss: 0.538925
tensor(-13.6295, device='cuda:0') tensor(2.3311, device='cuda:0') tensor(-3.0228e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.069070
Average KL loss: 0.469221
Average total loss: 0.538291
tensor(-13.6348, device='cuda:0') tensor(2.3331, device='cuda:0') tensor(-2.1675e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.069795
Average KL loss: 0.469127
Average total loss: 0.538922
tensor(-13.6401, device='cuda:0') tensor(2.3353, device='cuda:0') tensor(-8.3081e-11, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.068839
Average KL loss: 0.468989
Average total loss: 0.537828
tensor(-13.6453, device='cuda:0') tensor(2.3371, device='cuda:0') tensor(-4.0664e-11, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.070087
Average KL loss: 0.468855
Average total loss: 0.538942
tensor(-13.6505, device='cuda:0') tensor(2.3392, device='cuda:0') tensor(3.1317e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.069646
Average KL loss: 0.468671
Average total loss: 0.538317
tensor(-13.6557, device='cuda:0') tensor(2.3415, device='cuda:0') tensor(-2.7800e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.068814
Average KL loss: 0.468423
Average total loss: 0.537237
tensor(-13.6608, device='cuda:0') tensor(2.3433, device='cuda:0') tensor(1.5500e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.069709
Average KL loss: 0.468223
Average total loss: 0.537932
tensor(-13.6660, device='cuda:0') tensor(2.3454, device='cuda:0') tensor(2.4317e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.069456
Average KL loss: 0.468122
Average total loss: 0.537578
tensor(-13.6711, device='cuda:0') tensor(2.3473, device='cuda:0') tensor(2.0411e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.070173
Average KL loss: 0.467978
Average total loss: 0.538151
tensor(-13.6762, device='cuda:0') tensor(2.3491, device='cuda:0') tensor(-1.7228e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.070729
Average KL loss: 0.467876
Average total loss: 0.538605
tensor(-13.6812, device='cuda:0') tensor(2.3511, device='cuda:0') tensor(-4.0303e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.069178
Average KL loss: 0.467735
Average total loss: 0.536913
tensor(-13.6863, device='cuda:0') tensor(2.3528, device='cuda:0') tensor(-1.4728e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.070134
Average KL loss: 0.467608
Average total loss: 0.537742
tensor(-13.6913, device='cuda:0') tensor(2.3549, device='cuda:0') tensor(-3.1135e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.069262
Average KL loss: 0.467498
Average total loss: 0.536761
tensor(-13.6962, device='cuda:0') tensor(2.3567, device='cuda:0') tensor(1.2889e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.069949
Average KL loss: 0.467291
Average total loss: 0.537240
tensor(-13.7012, device='cuda:0') tensor(2.3587, device='cuda:0') tensor(4.9938e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.069014
Average KL loss: 0.467268
Average total loss: 0.536282
tensor(-13.7061, device='cuda:0') tensor(2.3608, device='cuda:0') tensor(1.4599e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.068713
Average KL loss: 0.467175
Average total loss: 0.535888
tensor(-13.7110, device='cuda:0') tensor(2.3630, device='cuda:0') tensor(-1.2973e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.068591
Average KL loss: 0.467051
Average total loss: 0.535641
tensor(-13.7159, device='cuda:0') tensor(2.3647, device='cuda:0') tensor(-2.9348e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.068626
Average KL loss: 0.466996
Average total loss: 0.535622
tensor(-13.7208, device='cuda:0') tensor(2.3665, device='cuda:0') tensor(-2.4885e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.068627
Average KL loss: 0.466857
Average total loss: 0.535484
tensor(-13.7256, device='cuda:0') tensor(2.3679, device='cuda:0') tensor(6.8283e-12, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.069335
Average KL loss: 0.466673
Average total loss: 0.536008
tensor(-13.7304, device='cuda:0') tensor(2.3697, device='cuda:0') tensor(3.5081e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.070095
Average KL loss: 0.466488
Average total loss: 0.536583
tensor(-13.7352, device='cuda:0') tensor(2.3716, device='cuda:0') tensor(4.3202e-12, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.068769
Average KL loss: 0.466428
Average total loss: 0.535197
tensor(-13.7400, device='cuda:0') tensor(2.3737, device='cuda:0') tensor(2.4981e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.069539
Average KL loss: 0.466303
Average total loss: 0.535842
tensor(-13.7448, device='cuda:0') tensor(2.3751, device='cuda:0') tensor(1.6994e-11, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.068844
Average KL loss: 0.466197
Average total loss: 0.535041
tensor(-13.7495, device='cuda:0') tensor(2.3767, device='cuda:0') tensor(-4.0872e-12, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.069693
Average KL loss: 0.466028
Average total loss: 0.535720
tensor(-13.7542, device='cuda:0') tensor(2.3784, device='cuda:0') tensor(-5.6067e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.069146
Average KL loss: 0.465848
Average total loss: 0.534995
tensor(-13.7589, device='cuda:0') tensor(2.3803, device='cuda:0') tensor(1.2829e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.068725
Average KL loss: 0.465730
Average total loss: 0.534455
tensor(-13.7636, device='cuda:0') tensor(2.3820, device='cuda:0') tensor(-2.5892e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.069198
Average KL loss: 0.465601
Average total loss: 0.534799
tensor(-13.7682, device='cuda:0') tensor(2.3840, device='cuda:0') tensor(-7.3493e-11, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.068807
Average KL loss: 0.465487
Average total loss: 0.534293
tensor(-13.7728, device='cuda:0') tensor(2.3863, device='cuda:0') tensor(-5.1721e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.068451
Average KL loss: 0.465340
Average total loss: 0.533791
tensor(-13.7774, device='cuda:0') tensor(2.3880, device='cuda:0') tensor(5.1042e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.068669
Average KL loss: 0.465159
Average total loss: 0.533828
tensor(-13.7820, device='cuda:0') tensor(2.3899, device='cuda:0') tensor(-5.8282e-11, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.068372
Average KL loss: 0.465064
Average total loss: 0.533436
tensor(-13.7866, device='cuda:0') tensor(2.3916, device='cuda:0') tensor(-1.7962e-11, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.068777
Average KL loss: 0.464896
Average total loss: 0.533673
tensor(-13.7912, device='cuda:0') tensor(2.3925, device='cuda:0') tensor(-2.4885e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.068951
Average KL loss: 0.464735
Average total loss: 0.533685
tensor(-13.7957, device='cuda:0') tensor(2.3941, device='cuda:0') tensor(3.9377e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.068422
Average KL loss: 0.464584
Average total loss: 0.533005
tensor(-13.8002, device='cuda:0') tensor(2.3957, device='cuda:0') tensor(-3.4564e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.069684
Average KL loss: 0.464457
Average total loss: 0.534141
tensor(-13.8047, device='cuda:0') tensor(2.3973, device='cuda:0') tensor(-9.0186e-11, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.069351
Average KL loss: 0.464337
Average total loss: 0.533688
tensor(-13.8092, device='cuda:0') tensor(2.3990, device='cuda:0') tensor(-1.1163e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.068142
Average KL loss: 0.464154
Average total loss: 0.532296
tensor(-13.8136, device='cuda:0') tensor(2.4005, device='cuda:0') tensor(-1.7360e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.069226
Average KL loss: 0.463938
Average total loss: 0.533164
tensor(-13.8180, device='cuda:0') tensor(2.4018, device='cuda:0') tensor(-1.4604e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.069698
Average KL loss: 0.463815
Average total loss: 0.533513
tensor(-13.8224, device='cuda:0') tensor(2.4035, device='cuda:0') tensor(4.3424e-11, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.068699
Average KL loss: 0.463782
Average total loss: 0.532481
tensor(-13.8268, device='cuda:0') tensor(2.4056, device='cuda:0') tensor(-7.5667e-11, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.069033
Average KL loss: 0.463660
Average total loss: 0.532693
 Percentile value: -13.967771530151367
Non-zero model percentage: 64.0%, Non-zero mask percentage: 64.0%

--- Pruning Level [2/24]: ---
conv1.weight         | nonzeros =    1666 /    1728             ( 96.41%) | total_pruned =      62 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   33294 /   36864             ( 90.32%) | total_pruned =    3570 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   33440 /   36864             ( 90.71%) | total_pruned =    3424 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   33519 /   36864             ( 90.93%) | total_pruned =    3345 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   33001 /   36864             ( 89.52%) | total_pruned =    3863 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   65851 /   73728             ( 89.32%) | total_pruned =    7877 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  127151 /  147456             ( 86.23%) | total_pruned =   20305 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    7793 /    8192             ( 95.13%) | total_pruned =     399 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  125451 /  147456             ( 85.08%) | total_pruned =   22005 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  123895 /  147456             ( 84.02%) | total_pruned =   23561 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  250487 /  294912             ( 84.94%) | total_pruned =   44425 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  476793 /  589824             ( 80.84%) | total_pruned =  113031 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   30124 /   32768             ( 91.93%) | total_pruned =    2644 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  441276 /  589824             ( 74.81%) | total_pruned =  148548 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  430602 /  589824             ( 73.01%) | total_pruned =  159222 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  923085 / 1179648             ( 78.25%) | total_pruned =  256563 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1507638 / 2359296             ( 63.90%) | total_pruned =  851658 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  114760 /  131072             ( 87.55%) | total_pruned =   16312 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1254656 / 2359296             ( 53.18%) | total_pruned = 1104640 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1125496 / 2359296             ( 47.70%) | total_pruned = 1233800 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
linear.weight        | nonzeros =    4993 /    5120             ( 97.52%) | total_pruned =     127 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 7154408, pruned : 4024354, total: 11178762, Compression rate :       1.56x  ( 36.00% pruned)
Train Epoch: 37/100 Loss: 0.000017 Accuracy: 86.99 100.00 % Best test Accuracy: 87.03%
tensor(-13.8312, device='cuda:0') tensor(2.4070, device='cuda:0') tensor(2.5650e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.231340
Average KL loss: 0.461884
Average total loss: 0.693224
tensor(-13.8419, device='cuda:0') tensor(2.2270, device='cuda:0') tensor(3.4471e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.226378
Average KL loss: 0.456865
Average total loss: 0.683243
tensor(-13.8508, device='cuda:0') tensor(2.0939, device='cuda:0') tensor(-2.3343e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.236368
Average KL loss: 0.450632
Average total loss: 0.686999
tensor(-13.8582, device='cuda:0') tensor(2.0044, device='cuda:0') tensor(-5.0435e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.243180
Average KL loss: 0.445390
Average total loss: 0.688569
tensor(-13.8648, device='cuda:0') tensor(1.9429, device='cuda:0') tensor(-1.2377e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.243636
Average KL loss: 0.441168
Average total loss: 0.684804
tensor(-13.8708, device='cuda:0') tensor(1.8979, device='cuda:0') tensor(-1.3891e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.245778
Average KL loss: 0.437695
Average total loss: 0.683473
tensor(-13.8765, device='cuda:0') tensor(1.8642, device='cuda:0') tensor(-3.9993e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.245715
Average KL loss: 0.435080
Average total loss: 0.680795
tensor(-13.8819, device='cuda:0') tensor(1.8387, device='cuda:0') tensor(-6.2971e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.244303
Average KL loss: 0.432651
Average total loss: 0.676954
tensor(-13.8871, device='cuda:0') tensor(1.8175, device='cuda:0') tensor(-5.1108e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.238479
Average KL loss: 0.430578
Average total loss: 0.669058
tensor(-13.8921, device='cuda:0') tensor(1.8012, device='cuda:0') tensor(-5.2379e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.242530
Average KL loss: 0.428848
Average total loss: 0.671379
tensor(-13.8971, device='cuda:0') tensor(1.7881, device='cuda:0') tensor(-6.3392e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.241776
Average KL loss: 0.427387
Average total loss: 0.669163
tensor(-13.9019, device='cuda:0') tensor(1.7766, device='cuda:0') tensor(-5.2335e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.234515
Average KL loss: 0.425981
Average total loss: 0.660496
tensor(-13.9066, device='cuda:0') tensor(1.7678, device='cuda:0') tensor(-5.4052e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.229861
Average KL loss: 0.424863
Average total loss: 0.654724
tensor(-13.9112, device='cuda:0') tensor(1.7614, device='cuda:0') tensor(-1.5208e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.227538
Average KL loss: 0.423813
Average total loss: 0.651351
tensor(-13.9158, device='cuda:0') tensor(1.7560, device='cuda:0') tensor(-3.4393e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.225341
Average KL loss: 0.422898
Average total loss: 0.648239
tensor(-13.9203, device='cuda:0') tensor(1.7514, device='cuda:0') tensor(-3.2799e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.219890
Average KL loss: 0.422035
Average total loss: 0.641925
tensor(-13.9248, device='cuda:0') tensor(1.7475, device='cuda:0') tensor(-5.0754e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.219406
Average KL loss: 0.421170
Average total loss: 0.640576
tensor(-13.9292, device='cuda:0') tensor(1.7448, device='cuda:0') tensor(-4.5668e-11, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.215342
Average KL loss: 0.420558
Average total loss: 0.635900
tensor(-13.9336, device='cuda:0') tensor(1.7424, device='cuda:0') tensor(-2.9887e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.214534
Average KL loss: 0.420001
Average total loss: 0.634535
tensor(-13.9379, device='cuda:0') tensor(1.7409, device='cuda:0') tensor(-7.8176e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.210869
Average KL loss: 0.419480
Average total loss: 0.630349
tensor(-13.9422, device='cuda:0') tensor(1.7398, device='cuda:0') tensor(-2.0212e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.210011
Average KL loss: 0.418927
Average total loss: 0.628938
tensor(-13.9464, device='cuda:0') tensor(1.7389, device='cuda:0') tensor(-3.3969e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.205995
Average KL loss: 0.418383
Average total loss: 0.624378
tensor(-13.9506, device='cuda:0') tensor(1.7378, device='cuda:0') tensor(-3.0166e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.205734
Average KL loss: 0.417830
Average total loss: 0.623564
tensor(-13.9548, device='cuda:0') tensor(1.7370, device='cuda:0') tensor(-3.7069e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.202779
Average KL loss: 0.417241
Average total loss: 0.620020
tensor(-13.9590, device='cuda:0') tensor(1.7365, device='cuda:0') tensor(-1.1602e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.200542
Average KL loss: 0.416623
Average total loss: 0.617164
tensor(-13.9631, device='cuda:0') tensor(1.7368, device='cuda:0') tensor(-1.3449e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.196493
Average KL loss: 0.416131
Average total loss: 0.612624
tensor(-13.9672, device='cuda:0') tensor(1.7379, device='cuda:0') tensor(-3.6370e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.196790
Average KL loss: 0.415663
Average total loss: 0.612452
tensor(-13.9713, device='cuda:0') tensor(1.7385, device='cuda:0') tensor(-2.0400e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.195061
Average KL loss: 0.415242
Average total loss: 0.610303
tensor(-13.9753, device='cuda:0') tensor(1.7402, device='cuda:0') tensor(-8.5672e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.194560
Average KL loss: 0.414784
Average total loss: 0.609344
tensor(-13.9793, device='cuda:0') tensor(1.7415, device='cuda:0') tensor(-1.6855e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.190461
Average KL loss: 0.414342
Average total loss: 0.604803
tensor(-13.9833, device='cuda:0') tensor(1.7432, device='cuda:0') tensor(-1.4574e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.189068
Average KL loss: 0.413886
Average total loss: 0.602954
tensor(-13.9873, device='cuda:0') tensor(1.7450, device='cuda:0') tensor(-1.6568e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.188963
Average KL loss: 0.413404
Average total loss: 0.602367
tensor(-13.9912, device='cuda:0') tensor(1.7467, device='cuda:0') tensor(-1.5535e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.184929
Average KL loss: 0.413059
Average total loss: 0.597988
tensor(-13.9951, device='cuda:0') tensor(1.7487, device='cuda:0') tensor(-2.3808e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.183801
Average KL loss: 0.412816
Average total loss: 0.596617
tensor(-13.9990, device='cuda:0') tensor(1.7508, device='cuda:0') tensor(-8.2327e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.180766
Average KL loss: 0.412457
Average total loss: 0.593223
tensor(-14.0029, device='cuda:0') tensor(1.7525, device='cuda:0') tensor(-5.9931e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.182805
Average KL loss: 0.412129
Average total loss: 0.594935
tensor(-14.0068, device='cuda:0') tensor(1.7548, device='cuda:0') tensor(-1.7869e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.179567
Average KL loss: 0.411868
Average total loss: 0.591435
tensor(-14.0106, device='cuda:0') tensor(1.7577, device='cuda:0') tensor(-2.0578e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.177912
Average KL loss: 0.411613
Average total loss: 0.589526
tensor(-14.0144, device='cuda:0') tensor(1.7598, device='cuda:0') tensor(-2.0069e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.174477
Average KL loss: 0.411297
Average total loss: 0.585773
tensor(-14.0182, device='cuda:0') tensor(1.7618, device='cuda:0') tensor(-1.8997e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.175584
Average KL loss: 0.411031
Average total loss: 0.586615
tensor(-14.0220, device='cuda:0') tensor(1.7640, device='cuda:0') tensor(-6.1894e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.174384
Average KL loss: 0.410761
Average total loss: 0.585145
tensor(-14.0258, device='cuda:0') tensor(1.7664, device='cuda:0') tensor(-1.6660e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.176080
Average KL loss: 0.410492
Average total loss: 0.586572
tensor(-14.0295, device='cuda:0') tensor(1.7690, device='cuda:0') tensor(6.4629e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.174269
Average KL loss: 0.410255
Average total loss: 0.584524
tensor(-14.0332, device='cuda:0') tensor(1.7711, device='cuda:0') tensor(-1.7472e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.172124
Average KL loss: 0.409957
Average total loss: 0.582081
tensor(-14.0370, device='cuda:0') tensor(1.7735, device='cuda:0') tensor(-2.8052e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.171673
Average KL loss: 0.409712
Average total loss: 0.581385
tensor(-14.0407, device='cuda:0') tensor(1.7762, device='cuda:0') tensor(-1.0869e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.168960
Average KL loss: 0.409569
Average total loss: 0.578529
tensor(-14.0443, device='cuda:0') tensor(1.7792, device='cuda:0') tensor(-2.4245e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.169265
Average KL loss: 0.409390
Average total loss: 0.578655
tensor(-14.0480, device='cuda:0') tensor(1.7818, device='cuda:0') tensor(1.4858e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.165812
Average KL loss: 0.409118
Average total loss: 0.574929
tensor(-14.0516, device='cuda:0') tensor(1.7840, device='cuda:0') tensor(-1.5312e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.165349
Average KL loss: 0.408883
Average total loss: 0.574232
tensor(-14.0552, device='cuda:0') tensor(1.7873, device='cuda:0') tensor(-1.1425e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.167185
Average KL loss: 0.408694
Average total loss: 0.575879
tensor(-14.0589, device='cuda:0') tensor(1.7900, device='cuda:0') tensor(-1.4557e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.165721
Average KL loss: 0.408635
Average total loss: 0.574356
tensor(-14.0625, device='cuda:0') tensor(1.7927, device='cuda:0') tensor(-5.6819e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.165582
Average KL loss: 0.408375
Average total loss: 0.573957
tensor(-14.0661, device='cuda:0') tensor(1.7948, device='cuda:0') tensor(-1.6873e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.165441
Average KL loss: 0.408146
Average total loss: 0.573588
tensor(-14.0696, device='cuda:0') tensor(1.7973, device='cuda:0') tensor(-5.0782e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.164555
Average KL loss: 0.407931
Average total loss: 0.572486
tensor(-14.0732, device='cuda:0') tensor(1.7995, device='cuda:0') tensor(-7.9584e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.163923
Average KL loss: 0.407628
Average total loss: 0.571551
tensor(-14.0767, device='cuda:0') tensor(1.8021, device='cuda:0') tensor(-4.5212e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.164328
Average KL loss: 0.407347
Average total loss: 0.571675
tensor(-14.0803, device='cuda:0') tensor(1.8040, device='cuda:0') tensor(-3.0329e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.163469
Average KL loss: 0.407114
Average total loss: 0.570582
tensor(-14.0838, device='cuda:0') tensor(1.8067, device='cuda:0') tensor(-1.6413e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.161998
Average KL loss: 0.406940
Average total loss: 0.568937
tensor(-14.0873, device='cuda:0') tensor(1.8098, device='cuda:0') tensor(-1.4946e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.160820
Average KL loss: 0.406752
Average total loss: 0.567572
tensor(-14.0908, device='cuda:0') tensor(1.8120, device='cuda:0') tensor(-2.0304e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.159683
Average KL loss: 0.406544
Average total loss: 0.566228
tensor(-14.0943, device='cuda:0') tensor(1.8144, device='cuda:0') tensor(-8.1393e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.160156
Average KL loss: 0.406328
Average total loss: 0.566484
tensor(-14.0977, device='cuda:0') tensor(1.8169, device='cuda:0') tensor(-3.8628e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.162055
Average KL loss: 0.406130
Average total loss: 0.568185
tensor(-14.1012, device='cuda:0') tensor(1.8197, device='cuda:0') tensor(-1.7002e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.159426
Average KL loss: 0.405980
Average total loss: 0.565405
tensor(-14.1046, device='cuda:0') tensor(1.8225, device='cuda:0') tensor(-9.1430e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.158638
Average KL loss: 0.405822
Average total loss: 0.564460
tensor(-14.1080, device='cuda:0') tensor(1.8252, device='cuda:0') tensor(-1.6028e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.157091
Average KL loss: 0.405624
Average total loss: 0.562716
tensor(-14.1114, device='cuda:0') tensor(1.8282, device='cuda:0') tensor(-1.0506e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.156478
Average KL loss: 0.405535
Average total loss: 0.562013
tensor(-14.1148, device='cuda:0') tensor(1.8310, device='cuda:0') tensor(-1.0243e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.155924
Average KL loss: 0.405417
Average total loss: 0.561341
tensor(-14.1182, device='cuda:0') tensor(1.8337, device='cuda:0') tensor(1.2907e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.155636
Average KL loss: 0.405226
Average total loss: 0.560862
tensor(-14.1216, device='cuda:0') tensor(1.8364, device='cuda:0') tensor(-1.4730e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.155156
Average KL loss: 0.405096
Average total loss: 0.560252
tensor(-14.1249, device='cuda:0') tensor(1.8394, device='cuda:0') tensor(-8.1787e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.153607
Average KL loss: 0.404995
Average total loss: 0.558602
tensor(-14.1283, device='cuda:0') tensor(1.8421, device='cuda:0') tensor(2.2101e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.152396
Average KL loss: 0.404885
Average total loss: 0.557281
tensor(-14.1316, device='cuda:0') tensor(1.8448, device='cuda:0') tensor(-8.5476e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.152462
Average KL loss: 0.404742
Average total loss: 0.557205
tensor(-14.1349, device='cuda:0') tensor(1.8476, device='cuda:0') tensor(-1.9274e-11, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.151536
Average KL loss: 0.404559
Average total loss: 0.556095
tensor(-14.1382, device='cuda:0') tensor(1.8498, device='cuda:0') tensor(-9.1712e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.151377
Average KL loss: 0.404405
Average total loss: 0.555782
tensor(-14.1415, device='cuda:0') tensor(1.8523, device='cuda:0') tensor(-3.4958e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.152566
Average KL loss: 0.404359
Average total loss: 0.556925
tensor(-14.1448, device='cuda:0') tensor(1.8548, device='cuda:0') tensor(-9.7956e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.150700
Average KL loss: 0.404201
Average total loss: 0.554901
tensor(-14.1481, device='cuda:0') tensor(1.8572, device='cuda:0') tensor(-7.3550e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.150322
Average KL loss: 0.404012
Average total loss: 0.554334
tensor(-14.1514, device='cuda:0') tensor(1.8595, device='cuda:0') tensor(-1.3328e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.151209
Average KL loss: 0.403817
Average total loss: 0.555026
tensor(-14.1546, device='cuda:0') tensor(1.8622, device='cuda:0') tensor(-1.1894e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.149674
Average KL loss: 0.403767
Average total loss: 0.553441
tensor(-14.1578, device='cuda:0') tensor(1.8648, device='cuda:0') tensor(-3.0021e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.148472
Average KL loss: 0.403632
Average total loss: 0.552104
tensor(-14.1611, device='cuda:0') tensor(1.8672, device='cuda:0') tensor(-3.7612e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.149436
Average KL loss: 0.403538
Average total loss: 0.552974
tensor(-14.1643, device='cuda:0') tensor(1.8699, device='cuda:0') tensor(8.2589e-11, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.148818
Average KL loss: 0.403405
Average total loss: 0.552223
tensor(-14.1675, device='cuda:0') tensor(1.8729, device='cuda:0') tensor(-8.6595e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.147152
Average KL loss: 0.403307
Average total loss: 0.550459
tensor(-14.1707, device='cuda:0') tensor(1.8759, device='cuda:0') tensor(-2.9637e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.147630
Average KL loss: 0.403226
Average total loss: 0.550856
tensor(-14.1738, device='cuda:0') tensor(1.8787, device='cuda:0') tensor(-3.4357e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.146819
Average KL loss: 0.403047
Average total loss: 0.549866
tensor(-14.1770, device='cuda:0') tensor(1.8811, device='cuda:0') tensor(-5.9051e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.147915
Average KL loss: 0.402900
Average total loss: 0.550815
tensor(-14.1802, device='cuda:0') tensor(1.8836, device='cuda:0') tensor(-6.4297e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.145371
Average KL loss: 0.402831
Average total loss: 0.548202
tensor(-14.1833, device='cuda:0') tensor(1.8865, device='cuda:0') tensor(-1.9194e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.147288
Average KL loss: 0.402704
Average total loss: 0.549991
tensor(-14.1864, device='cuda:0') tensor(1.8892, device='cuda:0') tensor(1.1756e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.146598
Average KL loss: 0.402539
Average total loss: 0.549137
tensor(-14.1896, device='cuda:0') tensor(1.8918, device='cuda:0') tensor(-1.9628e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.145969
Average KL loss: 0.402364
Average total loss: 0.548333
tensor(-14.1927, device='cuda:0') tensor(1.8944, device='cuda:0') tensor(-1.4451e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.146483
Average KL loss: 0.402242
Average total loss: 0.548725
tensor(-14.1958, device='cuda:0') tensor(1.8971, device='cuda:0') tensor(-9.3229e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.145178
Average KL loss: 0.402174
Average total loss: 0.547353
tensor(-14.1989, device='cuda:0') tensor(1.8997, device='cuda:0') tensor(-1.6120e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.144964
Average KL loss: 0.402060
Average total loss: 0.547024
tensor(-14.2020, device='cuda:0') tensor(1.9022, device='cuda:0') tensor(-1.5780e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.145144
Average KL loss: 0.402013
Average total loss: 0.547156
tensor(-14.2051, device='cuda:0') tensor(1.9052, device='cuda:0') tensor(-1.0586e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.144334
Average KL loss: 0.401895
Average total loss: 0.546229
tensor(-14.2081, device='cuda:0') tensor(1.9080, device='cuda:0') tensor(4.8852e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.145111
Average KL loss: 0.401747
Average total loss: 0.546858
tensor(-14.2112, device='cuda:0') tensor(1.9099, device='cuda:0') tensor(2.2746e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.145134
Average KL loss: 0.401582
Average total loss: 0.546716
tensor(-14.2143, device='cuda:0') tensor(1.9124, device='cuda:0') tensor(-6.6761e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.143732
Average KL loss: 0.401509
Average total loss: 0.545241
tensor(-14.2173, device='cuda:0') tensor(1.9150, device='cuda:0') tensor(-5.3313e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.140797
Average KL loss: 0.401372
Average total loss: 0.542169
tensor(-14.2203, device='cuda:0') tensor(1.9171, device='cuda:0') tensor(7.7243e-11, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.144071
Average KL loss: 0.401252
Average total loss: 0.545323
tensor(-14.2234, device='cuda:0') tensor(1.9192, device='cuda:0') tensor(-5.7344e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.142256
Average KL loss: 0.401136
Average total loss: 0.543392
tensor(-14.2264, device='cuda:0') tensor(1.9214, device='cuda:0') tensor(-2.8948e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.143021
Average KL loss: 0.400964
Average total loss: 0.543985
tensor(-14.2294, device='cuda:0') tensor(1.9238, device='cuda:0') tensor(-3.1989e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.140623
Average KL loss: 0.400849
Average total loss: 0.541472
tensor(-14.2324, device='cuda:0') tensor(1.9261, device='cuda:0') tensor(-1.8808e-11, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.141100
Average KL loss: 0.400796
Average total loss: 0.541895
tensor(-14.2353, device='cuda:0') tensor(1.9288, device='cuda:0') tensor(3.7952e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.140408
Average KL loss: 0.400622
Average total loss: 0.541030
tensor(-14.2383, device='cuda:0') tensor(1.9311, device='cuda:0') tensor(-5.6609e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.141330
Average KL loss: 0.400424
Average total loss: 0.541754
tensor(-14.2413, device='cuda:0') tensor(1.9331, device='cuda:0') tensor(3.3724e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.140706
Average KL loss: 0.400320
Average total loss: 0.541025
tensor(-14.2443, device='cuda:0') tensor(1.9352, device='cuda:0') tensor(-1.8950e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.141266
Average KL loss: 0.400240
Average total loss: 0.541506
tensor(-14.2472, device='cuda:0') tensor(1.9382, device='cuda:0') tensor(-1.0435e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.140285
Average KL loss: 0.400113
Average total loss: 0.540398
tensor(-14.2501, device='cuda:0') tensor(1.9405, device='cuda:0') tensor(-8.6106e-11, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.140063
Average KL loss: 0.399932
Average total loss: 0.539995
tensor(-14.2530, device='cuda:0') tensor(1.9430, device='cuda:0') tensor(-2.1169e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.139906
Average KL loss: 0.399791
Average total loss: 0.539698
tensor(-14.2560, device='cuda:0') tensor(1.9454, device='cuda:0') tensor(-3.5210e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.139727
Average KL loss: 0.399767
Average total loss: 0.539494
tensor(-14.2589, device='cuda:0') tensor(1.9481, device='cuda:0') tensor(-3.0773e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.140679
Average KL loss: 0.399684
Average total loss: 0.540363
tensor(-14.2618, device='cuda:0') tensor(1.9508, device='cuda:0') tensor(-9.6270e-11, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.139787
Average KL loss: 0.399596
Average total loss: 0.539383
tensor(-14.2646, device='cuda:0') tensor(1.9536, device='cuda:0') tensor(1.1313e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.139461
Average KL loss: 0.399527
Average total loss: 0.538988
tensor(-14.2675, device='cuda:0') tensor(1.9559, device='cuda:0') tensor(-4.9645e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.139650
Average KL loss: 0.399458
Average total loss: 0.539108
tensor(-14.2704, device='cuda:0') tensor(1.9582, device='cuda:0') tensor(-9.0819e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.139974
Average KL loss: 0.399376
Average total loss: 0.539350
tensor(-14.2733, device='cuda:0') tensor(1.9607, device='cuda:0') tensor(1.7792e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.139040
Average KL loss: 0.399299
Average total loss: 0.538339
tensor(-14.2761, device='cuda:0') tensor(1.9633, device='cuda:0') tensor(-2.4143e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.139386
Average KL loss: 0.399198
Average total loss: 0.538584
tensor(-14.2790, device='cuda:0') tensor(1.9653, device='cuda:0') tensor(-1.8260e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.138595
Average KL loss: 0.399095
Average total loss: 0.537689
tensor(-14.2818, device='cuda:0') tensor(1.9677, device='cuda:0') tensor(-7.8810e-11, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.138220
Average KL loss: 0.399021
Average total loss: 0.537241
tensor(-14.2847, device='cuda:0') tensor(1.9697, device='cuda:0') tensor(-3.4830e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.138187
Average KL loss: 0.398942
Average total loss: 0.537128
tensor(-14.2875, device='cuda:0') tensor(1.9718, device='cuda:0') tensor(-2.8960e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.138470
Average KL loss: 0.398866
Average total loss: 0.537337
tensor(-14.2903, device='cuda:0') tensor(1.9741, device='cuda:0') tensor(-7.2106e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.138626
Average KL loss: 0.398801
Average total loss: 0.537426
tensor(-14.2931, device='cuda:0') tensor(1.9765, device='cuda:0') tensor(-1.9322e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.136970
Average KL loss: 0.398678
Average total loss: 0.535648
tensor(-14.2959, device='cuda:0') tensor(1.9785, device='cuda:0') tensor(-9.4946e-11, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.137007
Average KL loss: 0.398615
Average total loss: 0.535622
tensor(-14.2987, device='cuda:0') tensor(1.9805, device='cuda:0') tensor(2.9439e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.136312
Average KL loss: 0.398524
Average total loss: 0.534836
tensor(-14.3015, device='cuda:0') tensor(1.9825, device='cuda:0') tensor(4.2246e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.136392
Average KL loss: 0.398379
Average total loss: 0.534772
tensor(-14.3043, device='cuda:0') tensor(1.9841, device='cuda:0') tensor(-9.7455e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.136640
Average KL loss: 0.398255
Average total loss: 0.534895
tensor(-14.3070, device='cuda:0') tensor(1.9862, device='cuda:0') tensor(-1.5473e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.135288
Average KL loss: 0.398151
Average total loss: 0.533439
tensor(-14.3098, device='cuda:0') tensor(1.9885, device='cuda:0') tensor(6.9204e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.136274
Average KL loss: 0.398053
Average total loss: 0.534328
tensor(-14.3125, device='cuda:0') tensor(1.9909, device='cuda:0') tensor(-2.2484e-11, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.137120
Average KL loss: 0.397951
Average total loss: 0.535070
tensor(-14.3153, device='cuda:0') tensor(1.9932, device='cuda:0') tensor(-4.6370e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.136929
Average KL loss: 0.397880
Average total loss: 0.534809
tensor(-14.3180, device='cuda:0') tensor(1.9957, device='cuda:0') tensor(-5.7489e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.137111
Average KL loss: 0.397868
Average total loss: 0.534980
tensor(-14.3207, device='cuda:0') tensor(1.9985, device='cuda:0') tensor(-3.6493e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.136134
Average KL loss: 0.397808
Average total loss: 0.533942
tensor(-14.3235, device='cuda:0') tensor(2.0007, device='cuda:0') tensor(7.9052e-11, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.135042
Average KL loss: 0.397672
Average total loss: 0.532714
tensor(-14.3262, device='cuda:0') tensor(2.0026, device='cuda:0') tensor(-2.9639e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.134455
Average KL loss: 0.397610
Average total loss: 0.532065
tensor(-14.3289, device='cuda:0') tensor(2.0048, device='cuda:0') tensor(1.1718e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.135711
Average KL loss: 0.397533
Average total loss: 0.533245
tensor(-14.3316, device='cuda:0') tensor(2.0072, device='cuda:0') tensor(-3.0006e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.134487
Average KL loss: 0.397503
Average total loss: 0.531990
tensor(-14.3343, device='cuda:0') tensor(2.0095, device='cuda:0') tensor(-5.1769e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.134825
Average KL loss: 0.397470
Average total loss: 0.532295
tensor(-14.3370, device='cuda:0') tensor(2.0115, device='cuda:0') tensor(-2.3436e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.135441
Average KL loss: 0.397409
Average total loss: 0.532850
tensor(-14.3396, device='cuda:0') tensor(2.0139, device='cuda:0') tensor(6.7897e-11, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.132948
Average KL loss: 0.397313
Average total loss: 0.530261
tensor(-14.3423, device='cuda:0') tensor(2.0154, device='cuda:0') tensor(-1.9790e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.134867
Average KL loss: 0.397273
Average total loss: 0.532140
tensor(-14.3450, device='cuda:0') tensor(2.0174, device='cuda:0') tensor(-2.6130e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.134249
Average KL loss: 0.397186
Average total loss: 0.531434
tensor(-14.3477, device='cuda:0') tensor(2.0196, device='cuda:0') tensor(-1.6198e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.135021
Average KL loss: 0.397077
Average total loss: 0.532098
tensor(-14.3503, device='cuda:0') tensor(2.0215, device='cuda:0') tensor(2.2848e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.134131
Average KL loss: 0.396957
Average total loss: 0.531088
tensor(-14.3530, device='cuda:0') tensor(2.0231, device='cuda:0') tensor(-9.4214e-11, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.134529
Average KL loss: 0.396860
Average total loss: 0.531389
tensor(-14.3556, device='cuda:0') tensor(2.0251, device='cuda:0') tensor(2.5836e-11, device='cuda:0')
Epoch 148
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 149
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 150
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 151
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 152
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 153
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 154
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 155
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 156
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 157
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 158
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 159
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 160
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 161
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 162
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 163
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 164
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 165
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 166
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 167
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 168
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 169
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 170
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 171
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 172
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 173
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 174
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 175
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 176
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 177
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 178
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 179
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 180
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 181
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 182
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 183
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 184
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 185
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 186
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 187
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 188
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 189
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 190
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 191
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 192
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 193
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 194
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 195
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 196
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 51.200008392333984%, Non-zero mask percentage: 51.200008392333984%

--- Pruning Level [3/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  356231 /  589824             ( 60.40%) | total_pruned =  233593 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  430602 /  589824             ( 73.01%) | total_pruned =  159222 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  923085 / 1179648             ( 78.25%) | total_pruned =  256563 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1507638 / 2359296             ( 63.90%) | total_pruned =  851658 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  114760 /  131072             ( 87.55%) | total_pruned =   16312 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1254656 / 2359296             ( 53.18%) | total_pruned = 1104640 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1125496 / 2359296             ( 47.70%) | total_pruned = 1233800 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
linear.weight        | nonzeros =    4993 /    5120             ( 97.52%) | total_pruned =     127 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 5723527, pruned : 5455235, total: 11178762, Compression rate :       1.95x  ( 48.80% pruned)
Train Epoch: 34/100 Loss: 2.302668 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 40.96000671386719%, Non-zero mask percentage: 40.96000671386719%

--- Pruning Level [4/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  566218 / 1179648             ( 48.00%) | total_pruned =  613430 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1507638 / 2359296             ( 63.90%) | total_pruned =  851658 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  114760 /  131072             ( 87.55%) | total_pruned =   16312 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1254656 / 2359296             ( 53.18%) | total_pruned = 1104640 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1125496 / 2359296             ( 47.70%) | total_pruned = 1233800 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
linear.weight        | nonzeros =    4993 /    5120             ( 97.52%) | total_pruned =     127 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 4578822, pruned : 6599940, total: 11178762, Compression rate :       2.44x  ( 59.04% pruned)
Train Epoch: 34/100 Loss: 2.302554 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 32.76801300048828%, Non-zero mask percentage: 32.76801300048828%

--- Pruning Level [5/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1159106 / 2359296             ( 49.13%) | total_pruned = 1200190 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  114760 /  131072             ( 87.55%) | total_pruned =   16312 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1254656 / 2359296             ( 53.18%) | total_pruned = 1104640 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1125496 / 2359296             ( 47.70%) | total_pruned = 1233800 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
linear.weight        | nonzeros =    4993 /    5120             ( 97.52%) | total_pruned =     127 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 3663058, pruned : 7515704, total: 11178762, Compression rate :       3.05x  ( 67.23% pruned)
Train Epoch: 34/100 Loss: 2.302513 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 26.214414596557617%, Non-zero mask percentage: 26.214414596557617%

--- Pruning Level [6/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  426495 / 2359296             ( 18.08%) | total_pruned = 1932801 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  114760 /  131072             ( 87.55%) | total_pruned =   16312 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1254656 / 2359296             ( 53.18%) | total_pruned = 1104640 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1125496 / 2359296             ( 47.70%) | total_pruned = 1233800 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
linear.weight        | nonzeros =    4993 /    5120             ( 97.52%) | total_pruned =     127 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 2930447, pruned : 8248315, total: 11178762, Compression rate :       3.81x  ( 73.79% pruned)
Train Epoch: 34/100 Loss: 2.302693 Accuracy: 10.00 10.00 % Best test Accuracy: 10.00%
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 1
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 2
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 3
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 4
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 5
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 6
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 7
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 8
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 9
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 10
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 11
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 12
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 13
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 14
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 15
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 16
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 17
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 18
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 19
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 20
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 21
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 22
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 23
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 24
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 25
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 26
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 27
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 28
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 29
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 30
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 31
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 32
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 33
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 34
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 35
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 36
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 37
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 38
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 39
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 40
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 41
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 42
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 43
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 44
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 45
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 46
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 47
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 48
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 49
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 50
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 51
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 52
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 53
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 54
Average batch original loss after noise: nan
Average KL loss: nan
Average total loss: nan
tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
 Percentile value: nan
Non-zero model percentage: 20.971534729003906%, Non-zero mask percentage: 20.971534729003906%

--- Pruning Level [7/24]: ---
conv1.weight         | nonzeros =       0 /    1728             (  0.00%) | total_pruned =    1728 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =       0 /   36864             (  0.00%) | total_pruned =   36864 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =       0 /   73728             (  0.00%) | total_pruned =   73728 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =       0 /    8192             (  0.00%) | total_pruned =    8192 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =       0 /  147456             (  0.00%) | total_pruned =  147456 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =       0 /  294912             (  0.00%) | total_pruned =  294912 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =       0 /   32768             (  0.00%) | total_pruned =   32768 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =       0 /  589824             (  0.00%) | total_pruned =  589824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =       0 / 1179648             (  0.00%) | total_pruned = 1179648 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       0 /  131072             (  0.00%) | total_pruned =  131072 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1211841 / 2359296             ( 51.36%) | total_pruned = 1147455 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1125496 / 2359296             ( 47.70%) | total_pruned = 1233800 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
linear.weight        | nonzeros =    4993 /    5120             ( 97.52%) | total_pruned =     127 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 2344358, pruned : 8834404, total: 11178762, Compression rate :       4.77x  ( 79.03% pruned)
