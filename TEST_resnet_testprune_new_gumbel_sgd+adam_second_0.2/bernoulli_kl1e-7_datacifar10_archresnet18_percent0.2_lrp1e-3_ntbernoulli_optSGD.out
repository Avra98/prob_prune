Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/24]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2560e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302782
Average KL loss: 0.000003
Average total loss: 2.302784
tensor(5.2437e-05, device='cuda:0') tensor(4.9094e-06, device='cuda:0') tensor(-2.4284e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.303061
Average KL loss: 0.000003
Average total loss: 2.303065
tensor(0.0001, device='cuda:0') tensor(1.2362e-05, device='cuda:0') tensor(-2.2978e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.302860
Average KL loss: 0.000005
Average total loss: 2.302864
tensor(0.0002, device='cuda:0') tensor(2.2339e-05, device='cuda:0') tensor(-1.7419e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.302792
Average KL loss: 0.000006
Average total loss: 2.302798
tensor(0.0002, device='cuda:0') tensor(3.5034e-05, device='cuda:0') tensor(-4.1102e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.302996
Average KL loss: 0.000008
Average total loss: 2.303004
tensor(0.0003, device='cuda:0') tensor(5.0899e-05, device='cuda:0') tensor(-4.6270e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.302704
Average KL loss: 0.000011
Average total loss: 2.302715
tensor(0.0004, device='cuda:0') tensor(6.7302e-05, device='cuda:0') tensor(9.6186e-11, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.302292
Average KL loss: 0.000013
Average total loss: 2.302305
tensor(0.0005, device='cuda:0') tensor(8.7845e-05, device='cuda:0') tensor(-1.4988e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.302135
Average KL loss: 0.000016
Average total loss: 2.302152
tensor(0.0006, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-6.0084e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.302095
Average KL loss: 0.000021
Average total loss: 2.302115
tensor(0.0007, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-7.4218e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.301589
Average KL loss: 0.000026
Average total loss: 2.301615
tensor(0.0009, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-5.4725e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.301555
Average KL loss: 0.000032
Average total loss: 2.301587
tensor(0.0010, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-1.9223e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.301023
Average KL loss: 0.000041
Average total loss: 2.301064
tensor(0.0012, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.6775e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.299628
Average KL loss: 0.000052
Average total loss: 2.299680
tensor(0.0015, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-3.4856e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.298697
Average KL loss: 0.000070
Average total loss: 2.298766
tensor(0.0019, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-1.6275e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.297051
Average KL loss: 0.000091
Average total loss: 2.297143
tensor(0.0023, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.3500e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.291838
Average KL loss: 0.000125
Average total loss: 2.291963
tensor(0.0029, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.0342e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.288439
Average KL loss: 0.000173
Average total loss: 2.288612
tensor(0.0036, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.0873e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.278239
Average KL loss: 0.000240
Average total loss: 2.278480
tensor(0.0046, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.8361e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.254708
Average KL loss: 0.000338
Average total loss: 2.255047
tensor(0.0059, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.3192e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.228390
Average KL loss: 0.000477
Average total loss: 2.228867
tensor(0.0077, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.5437e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.189236
Average KL loss: 0.000660
Average total loss: 2.189896
tensor(0.0098, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.7870e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.143879
Average KL loss: 0.000893
Average total loss: 2.144772
tensor(0.0123, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.2959e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.078008
Average KL loss: 0.001164
Average total loss: 2.079172
tensor(0.0152, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-9.1040e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.026992
Average KL loss: 0.001472
Average total loss: 2.028464
tensor(0.0183, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.1278e-07, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.960836
Average KL loss: 0.001808
Average total loss: 1.962645
tensor(0.0215, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.1626e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.876796
Average KL loss: 0.002159
Average total loss: 1.878956
tensor(0.0249, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-1.1560e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.822626
Average KL loss: 0.002507
Average total loss: 1.825132
tensor(0.0282, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-1.1101e-07, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.754981
Average KL loss: 0.002839
Average total loss: 1.757819
tensor(0.0312, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-9.9777e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.688415
Average KL loss: 0.003161
Average total loss: 1.691576
tensor(0.0343, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.1082e-07, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.637122
Average KL loss: 0.003478
Average total loss: 1.640600
tensor(0.0371, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.1028e-07, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.588398
Average KL loss: 0.003772
Average total loss: 1.592170
tensor(0.0397, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-1.2945e-07, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.527881
Average KL loss: 0.004053
Average total loss: 1.531934
tensor(0.0423, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-1.2218e-07, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.488223
Average KL loss: 0.004318
Average total loss: 1.492541
tensor(0.0446, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-1.2844e-07, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.458196
Average KL loss: 0.004576
Average total loss: 1.462772
tensor(0.0469, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.1906e-07, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.407816
Average KL loss: 0.004833
Average total loss: 1.412649
tensor(0.0490, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-1.0690e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.362519
Average KL loss: 0.005071
Average total loss: 1.367590
tensor(0.0511, device='cuda:0') tensor(0.0351, device='cuda:0') tensor(-1.1350e-07, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.314574
Average KL loss: 0.005301
Average total loss: 1.319875
tensor(0.0530, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-1.2047e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.285523
Average KL loss: 0.005519
Average total loss: 1.291042
tensor(0.0549, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-1.1620e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.259207
Average KL loss: 0.005726
Average total loss: 1.264933
tensor(0.0566, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-1.1629e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.223196
Average KL loss: 0.005935
Average total loss: 1.229130
tensor(0.0583, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-1.1046e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.183804
Average KL loss: 0.006133
Average total loss: 1.189937
tensor(0.0599, device='cuda:0') tensor(0.0419, device='cuda:0') tensor(-1.2831e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.174943
Average KL loss: 0.006324
Average total loss: 1.181267
tensor(0.0615, device='cuda:0') tensor(0.0431, device='cuda:0') tensor(-9.9277e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.122505
Average KL loss: 0.006508
Average total loss: 1.129013
tensor(0.0629, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-1.0159e-07, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.109479
Average KL loss: 0.006693
Average total loss: 1.116172
tensor(0.0644, device='cuda:0') tensor(0.0455, device='cuda:0') tensor(-1.0477e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.085231
Average KL loss: 0.006874
Average total loss: 1.092105
tensor(0.0657, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.1195e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.062590
Average KL loss: 0.007042
Average total loss: 1.069633
tensor(0.0670, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-9.0589e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.037532
Average KL loss: 0.007198
Average total loss: 1.044730
tensor(0.0682, device='cuda:0') tensor(0.0487, device='cuda:0') tensor(-1.0433e-07, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.012418
Average KL loss: 0.007344
Average total loss: 1.019762
tensor(0.0693, device='cuda:0') tensor(0.0496, device='cuda:0') tensor(-9.8072e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.010576
Average KL loss: 0.007490
Average total loss: 1.018066
tensor(0.0704, device='cuda:0') tensor(0.0506, device='cuda:0') tensor(-9.8434e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.973405
Average KL loss: 0.007630
Average total loss: 0.981035
tensor(0.0715, device='cuda:0') tensor(0.0515, device='cuda:0') tensor(-9.0496e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.961710
Average KL loss: 0.007768
Average total loss: 0.969478
tensor(0.0726, device='cuda:0') tensor(0.0523, device='cuda:0') tensor(-1.0113e-07, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.951661
Average KL loss: 0.007901
Average total loss: 0.959562
tensor(0.0736, device='cuda:0') tensor(0.0532, device='cuda:0') tensor(-8.9806e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.933103
Average KL loss: 0.008026
Average total loss: 0.941129
tensor(0.0745, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(-8.4506e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.943446
Average KL loss: 0.008146
Average total loss: 0.951592
tensor(0.0754, device='cuda:0') tensor(0.0548, device='cuda:0') tensor(-8.3890e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.900275
Average KL loss: 0.008267
Average total loss: 0.908542
tensor(0.0763, device='cuda:0') tensor(0.0555, device='cuda:0') tensor(-8.3146e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.896883
Average KL loss: 0.008383
Average total loss: 0.905266
tensor(0.0772, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-8.5569e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.881620
Average KL loss: 0.008499
Average total loss: 0.890119
tensor(0.0780, device='cuda:0') tensor(0.0570, device='cuda:0') tensor(-8.7846e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.874644
Average KL loss: 0.008608
Average total loss: 0.883252
tensor(0.0789, device='cuda:0') tensor(0.0577, device='cuda:0') tensor(-8.0874e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.853611
Average KL loss: 0.008712
Average total loss: 0.862323
tensor(0.0796, device='cuda:0') tensor(0.0584, device='cuda:0') tensor(-8.6062e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.861821
Average KL loss: 0.008816
Average total loss: 0.870636
tensor(0.0803, device='cuda:0') tensor(0.0591, device='cuda:0') tensor(-7.6659e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.818016
Average KL loss: 0.008915
Average total loss: 0.826931
tensor(0.0811, device='cuda:0') tensor(0.0597, device='cuda:0') tensor(-7.0246e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.832140
Average KL loss: 0.009007
Average total loss: 0.841148
tensor(0.0818, device='cuda:0') tensor(0.0603, device='cuda:0') tensor(-8.6419e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.800444
Average KL loss: 0.009097
Average total loss: 0.809541
tensor(0.0824, device='cuda:0') tensor(0.0609, device='cuda:0') tensor(-8.0101e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.789272
Average KL loss: 0.009176
Average total loss: 0.798448
tensor(0.0831, device='cuda:0') tensor(0.0614, device='cuda:0') tensor(-6.4742e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.787589
Average KL loss: 0.009258
Average total loss: 0.796847
tensor(0.0837, device='cuda:0') tensor(0.0619, device='cuda:0') tensor(-7.7203e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.788144
Average KL loss: 0.009336
Average total loss: 0.797480
tensor(0.0843, device='cuda:0') tensor(0.0624, device='cuda:0') tensor(-9.0063e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.761168
Average KL loss: 0.009413
Average total loss: 0.770581
tensor(0.0849, device='cuda:0') tensor(0.0629, device='cuda:0') tensor(-6.9066e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.753083
Average KL loss: 0.009483
Average total loss: 0.762566
tensor(0.0854, device='cuda:0') tensor(0.0634, device='cuda:0') tensor(-7.3932e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.749882
Average KL loss: 0.009555
Average total loss: 0.759437
tensor(0.0860, device='cuda:0') tensor(0.0638, device='cuda:0') tensor(-7.3076e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.741518
Average KL loss: 0.009621
Average total loss: 0.751139
tensor(0.0865, device='cuda:0') tensor(0.0643, device='cuda:0') tensor(-7.6260e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.725912
Average KL loss: 0.009689
Average total loss: 0.735601
tensor(0.0871, device='cuda:0') tensor(0.0647, device='cuda:0') tensor(-6.5967e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.737903
Average KL loss: 0.009758
Average total loss: 0.747662
tensor(0.0876, device='cuda:0') tensor(0.0652, device='cuda:0') tensor(-6.8141e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.718367
Average KL loss: 0.009824
Average total loss: 0.728192
tensor(0.0881, device='cuda:0') tensor(0.0656, device='cuda:0') tensor(-6.9938e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.691668
Average KL loss: 0.009885
Average total loss: 0.701554
tensor(0.0886, device='cuda:0') tensor(0.0660, device='cuda:0') tensor(-7.4191e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.702257
Average KL loss: 0.009944
Average total loss: 0.712201
tensor(0.0891, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-6.7506e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.693184
Average KL loss: 0.010003
Average total loss: 0.703186
tensor(0.0896, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-7.8680e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.686039
Average KL loss: 0.010061
Average total loss: 0.696100
tensor(0.0901, device='cuda:0') tensor(0.0672, device='cuda:0') tensor(-6.1984e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.682236
Average KL loss: 0.010113
Average total loss: 0.692349
tensor(0.0905, device='cuda:0') tensor(0.0675, device='cuda:0') tensor(-6.1393e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.663676
Average KL loss: 0.010163
Average total loss: 0.673839
tensor(0.0909, device='cuda:0') tensor(0.0678, device='cuda:0') tensor(-5.4280e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.663035
Average KL loss: 0.010214
Average total loss: 0.673249
tensor(0.0913, device='cuda:0') tensor(0.0682, device='cuda:0') tensor(-6.0707e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.659464
Average KL loss: 0.010263
Average total loss: 0.669728
tensor(0.0917, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-5.5832e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.645958
Average KL loss: 0.010311
Average total loss: 0.656269
tensor(0.0922, device='cuda:0') tensor(0.0688, device='cuda:0') tensor(-6.0368e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.645272
Average KL loss: 0.010359
Average total loss: 0.655630
tensor(0.0925, device='cuda:0') tensor(0.0691, device='cuda:0') tensor(-5.7640e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.643736
Average KL loss: 0.010404
Average total loss: 0.654140
tensor(0.0929, device='cuda:0') tensor(0.0694, device='cuda:0') tensor(-7.4312e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.624841
Average KL loss: 0.010445
Average total loss: 0.635286
tensor(0.0933, device='cuda:0') tensor(0.0697, device='cuda:0') tensor(-6.3581e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.617505
Average KL loss: 0.010485
Average total loss: 0.627991
tensor(0.0936, device='cuda:0') tensor(0.0700, device='cuda:0') tensor(-5.6980e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.624012
Average KL loss: 0.010524
Average total loss: 0.634536
tensor(0.0940, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-7.2060e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.604290
Average KL loss: 0.010561
Average total loss: 0.614851
tensor(0.0943, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-4.9707e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.599831
Average KL loss: 0.010598
Average total loss: 0.610429
tensor(0.0947, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-6.1140e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.595947
Average KL loss: 0.010637
Average total loss: 0.606584
tensor(0.0950, device='cuda:0') tensor(0.0710, device='cuda:0') tensor(-5.8352e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.609867
Average KL loss: 0.010677
Average total loss: 0.620544
tensor(0.0953, device='cuda:0') tensor(0.0713, device='cuda:0') tensor(-6.3204e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.588755
Average KL loss: 0.010714
Average total loss: 0.599469
tensor(0.0957, device='cuda:0') tensor(0.0715, device='cuda:0') tensor(-5.1083e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.577606
Average KL loss: 0.010746
Average total loss: 0.588352
tensor(0.0960, device='cuda:0') tensor(0.0717, device='cuda:0') tensor(-5.3026e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.584604
Average KL loss: 0.010777
Average total loss: 0.595381
tensor(0.0963, device='cuda:0') tensor(0.0720, device='cuda:0') tensor(-5.6447e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.580700
Average KL loss: 0.010809
Average total loss: 0.591509
tensor(0.0966, device='cuda:0') tensor(0.0722, device='cuda:0') tensor(-5.0215e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.563892
Average KL loss: 0.010842
Average total loss: 0.574734
tensor(0.0968, device='cuda:0') tensor(0.0724, device='cuda:0') tensor(-5.6791e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.567755
Average KL loss: 0.010873
Average total loss: 0.578628
tensor(0.0971, device='cuda:0') tensor(0.0726, device='cuda:0') tensor(-5.3471e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.557897
Average KL loss: 0.010905
Average total loss: 0.568801
tensor(0.0974, device='cuda:0') tensor(0.0729, device='cuda:0') tensor(-5.3645e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.554786
Average KL loss: 0.010935
Average total loss: 0.565721
tensor(0.0977, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(-5.3570e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.551956
Average KL loss: 0.010967
Average total loss: 0.562924
tensor(0.0980, device='cuda:0') tensor(0.0733, device='cuda:0') tensor(-4.7583e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.536098
Average KL loss: 0.010996
Average total loss: 0.547095
tensor(0.0982, device='cuda:0') tensor(0.0735, device='cuda:0') tensor(-4.1959e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.537848
Average KL loss: 0.011023
Average total loss: 0.548871
tensor(0.0985, device='cuda:0') tensor(0.0737, device='cuda:0') tensor(-5.3787e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.538108
Average KL loss: 0.011051
Average total loss: 0.549158
tensor(0.0987, device='cuda:0') tensor(0.0739, device='cuda:0') tensor(-5.0942e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.517211
Average KL loss: 0.011080
Average total loss: 0.528291
tensor(0.0990, device='cuda:0') tensor(0.0741, device='cuda:0') tensor(-5.2897e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.514099
Average KL loss: 0.011106
Average total loss: 0.525205
tensor(0.0993, device='cuda:0') tensor(0.0743, device='cuda:0') tensor(-5.5849e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.508278
Average KL loss: 0.011132
Average total loss: 0.519410
tensor(0.0995, device='cuda:0') tensor(0.0745, device='cuda:0') tensor(-4.9687e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.514460
Average KL loss: 0.011155
Average total loss: 0.525614
tensor(0.0997, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(-6.6354e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.511445
Average KL loss: 0.011178
Average total loss: 0.522624
tensor(0.1000, device='cuda:0') tensor(0.0748, device='cuda:0') tensor(-4.1659e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.503200
Average KL loss: 0.011201
Average total loss: 0.514401
tensor(0.1002, device='cuda:0') tensor(0.0750, device='cuda:0') tensor(-6.6064e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.495631
Average KL loss: 0.011223
Average total loss: 0.506854
tensor(0.1004, device='cuda:0') tensor(0.0752, device='cuda:0') tensor(-4.8071e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.494367
Average KL loss: 0.011243
Average total loss: 0.505610
tensor(0.1006, device='cuda:0') tensor(0.0754, device='cuda:0') tensor(-4.2352e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.487318
Average KL loss: 0.011268
Average total loss: 0.498586
tensor(0.1008, device='cuda:0') tensor(0.0755, device='cuda:0') tensor(-3.8899e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.490805
Average KL loss: 0.011289
Average total loss: 0.502094
tensor(0.1010, device='cuda:0') tensor(0.0757, device='cuda:0') tensor(-4.7966e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.480864
Average KL loss: 0.011310
Average total loss: 0.492174
tensor(0.1012, device='cuda:0') tensor(0.0759, device='cuda:0') tensor(-5.8399e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.473734
Average KL loss: 0.011333
Average total loss: 0.485067
tensor(0.1014, device='cuda:0') tensor(0.0760, device='cuda:0') tensor(-4.8343e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.477271
Average KL loss: 0.011353
Average total loss: 0.488623
tensor(0.1016, device='cuda:0') tensor(0.0762, device='cuda:0') tensor(-4.7156e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.463876
Average KL loss: 0.011374
Average total loss: 0.475250
tensor(0.1018, device='cuda:0') tensor(0.0764, device='cuda:0') tensor(-3.8355e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.470197
Average KL loss: 0.011393
Average total loss: 0.481590
tensor(0.1020, device='cuda:0') tensor(0.0765, device='cuda:0') tensor(-3.9773e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.462612
Average KL loss: 0.011415
Average total loss: 0.474027
tensor(0.1022, device='cuda:0') tensor(0.0767, device='cuda:0') tensor(-3.6065e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.454537
Average KL loss: 0.011434
Average total loss: 0.465971
tensor(0.1023, device='cuda:0') tensor(0.0768, device='cuda:0') tensor(-4.3698e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.459499
Average KL loss: 0.011453
Average total loss: 0.470952
tensor(0.1025, device='cuda:0') tensor(0.0770, device='cuda:0') tensor(-3.9264e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.460097
Average KL loss: 0.011475
Average total loss: 0.471572
tensor(0.1027, device='cuda:0') tensor(0.0772, device='cuda:0') tensor(-5.2826e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.455022
Average KL loss: 0.011497
Average total loss: 0.466519
tensor(0.1029, device='cuda:0') tensor(0.0773, device='cuda:0') tensor(-3.9048e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.437226
Average KL loss: 0.011516
Average total loss: 0.448741
tensor(0.1031, device='cuda:0') tensor(0.0775, device='cuda:0') tensor(-3.9626e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.444017
Average KL loss: 0.011537
Average total loss: 0.455554
tensor(0.1033, device='cuda:0') tensor(0.0777, device='cuda:0') tensor(-4.4026e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.430666
Average KL loss: 0.011554
Average total loss: 0.442220
tensor(0.1034, device='cuda:0') tensor(0.0778, device='cuda:0') tensor(-5.5350e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.438680
Average KL loss: 0.011571
Average total loss: 0.450252
tensor(0.1036, device='cuda:0') tensor(0.0780, device='cuda:0') tensor(-3.9296e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.434419
Average KL loss: 0.011588
Average total loss: 0.446007
tensor(0.1037, device='cuda:0') tensor(0.0781, device='cuda:0') tensor(-3.4224e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.429674
Average KL loss: 0.011606
Average total loss: 0.441279
tensor(0.1039, device='cuda:0') tensor(0.0783, device='cuda:0') tensor(-4.4228e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.419661
Average KL loss: 0.011621
Average total loss: 0.431282
tensor(0.1040, device='cuda:0') tensor(0.0784, device='cuda:0') tensor(-4.3947e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.428414
Average KL loss: 0.011635
Average total loss: 0.440049
tensor(0.1041, device='cuda:0') tensor(0.0785, device='cuda:0') tensor(-3.9331e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.415394
Average KL loss: 0.011653
Average total loss: 0.427048
tensor(0.1043, device='cuda:0') tensor(0.0787, device='cuda:0') tensor(-3.4167e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.421289
Average KL loss: 0.011669
Average total loss: 0.432958
tensor(0.1044, device='cuda:0') tensor(0.0788, device='cuda:0') tensor(-3.9095e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.418565
Average KL loss: 0.011687
Average total loss: 0.430252
tensor(0.1046, device='cuda:0') tensor(0.0790, device='cuda:0') tensor(-3.8546e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.403593
Average KL loss: 0.011707
Average total loss: 0.415300
tensor(0.1047, device='cuda:0') tensor(0.0792, device='cuda:0') tensor(-3.2510e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.402057
Average KL loss: 0.011725
Average total loss: 0.413781
tensor(0.1049, device='cuda:0') tensor(0.0793, device='cuda:0') tensor(-4.3433e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.402786
Average KL loss: 0.011741
Average total loss: 0.414527
tensor(0.1050, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-3.6399e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.403517
Average KL loss: 0.011759
Average total loss: 0.415275
tensor(0.1052, device='cuda:0') tensor(0.0796, device='cuda:0') tensor(-3.6841e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.394542
Average KL loss: 0.011778
Average total loss: 0.406320
tensor(0.1053, device='cuda:0') tensor(0.0798, device='cuda:0') tensor(-3.6068e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.388695
Average KL loss: 0.011794
Average total loss: 0.400489
tensor(0.1055, device='cuda:0') tensor(0.0799, device='cuda:0') tensor(-3.9570e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.391904
Average KL loss: 0.011812
Average total loss: 0.403716
tensor(0.1056, device='cuda:0') tensor(0.0801, device='cuda:0') tensor(-3.7694e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.390773
Average KL loss: 0.011831
Average total loss: 0.402605
tensor(0.1057, device='cuda:0') tensor(0.0803, device='cuda:0') tensor(-4.8706e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.383954
Average KL loss: 0.011851
Average total loss: 0.395805
tensor(0.1059, device='cuda:0') tensor(0.0804, device='cuda:0') tensor(-3.5165e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.387443
Average KL loss: 0.011868
Average total loss: 0.399311
tensor(0.1060, device='cuda:0') tensor(0.0806, device='cuda:0') tensor(-3.6974e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.378571
Average KL loss: 0.011886
Average total loss: 0.390458
tensor(0.1062, device='cuda:0') tensor(0.0807, device='cuda:0') tensor(-4.5867e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.375014
Average KL loss: 0.011901
Average total loss: 0.386916
tensor(0.1063, device='cuda:0') tensor(0.0809, device='cuda:0') tensor(-4.1506e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.375922
Average KL loss: 0.011915
Average total loss: 0.387838
tensor(0.1064, device='cuda:0') tensor(0.0810, device='cuda:0') tensor(-2.9509e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.371884
Average KL loss: 0.011931
Average total loss: 0.383814
tensor(0.1065, device='cuda:0') tensor(0.0812, device='cuda:0') tensor(-3.7746e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.358621
Average KL loss: 0.011947
Average total loss: 0.370568
tensor(0.1066, device='cuda:0') tensor(0.0813, device='cuda:0') tensor(-3.5062e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.363627
Average KL loss: 0.011963
Average total loss: 0.375590
tensor(0.1067, device='cuda:0') tensor(0.0815, device='cuda:0') tensor(-3.8647e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.364885
Average KL loss: 0.011978
Average total loss: 0.376863
tensor(0.1068, device='cuda:0') tensor(0.0816, device='cuda:0') tensor(-3.6977e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.361827
Average KL loss: 0.011995
Average total loss: 0.373822
tensor(0.1069, device='cuda:0') tensor(0.0818, device='cuda:0') tensor(-2.9257e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.348775
Average KL loss: 0.012011
Average total loss: 0.360786
tensor(0.1071, device='cuda:0') tensor(0.0819, device='cuda:0') tensor(-4.9586e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.359857
Average KL loss: 0.012026
Average total loss: 0.371883
tensor(0.1072, device='cuda:0') tensor(0.0821, device='cuda:0') tensor(-2.7573e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.360838
Average KL loss: 0.012041
Average total loss: 0.372880
tensor(0.1073, device='cuda:0') tensor(0.0822, device='cuda:0') tensor(-3.1459e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.338734
Average KL loss: 0.012058
Average total loss: 0.350792
tensor(0.1074, device='cuda:0') tensor(0.0824, device='cuda:0') tensor(-3.5937e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.340272
Average KL loss: 0.012073
Average total loss: 0.352345
tensor(0.1075, device='cuda:0') tensor(0.0825, device='cuda:0') tensor(-3.5165e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.344528
Average KL loss: 0.012088
Average total loss: 0.356616
tensor(0.1076, device='cuda:0') tensor(0.0827, device='cuda:0') tensor(-3.7886e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.345659
Average KL loss: 0.012104
Average total loss: 0.357763
tensor(0.1077, device='cuda:0') tensor(0.0828, device='cuda:0') tensor(-3.1108e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.346521
Average KL loss: 0.012122
Average total loss: 0.358643
tensor(0.1078, device='cuda:0') tensor(0.0830, device='cuda:0') tensor(-2.6935e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.334022
Average KL loss: 0.012139
Average total loss: 0.346161
tensor(0.1080, device='cuda:0') tensor(0.0832, device='cuda:0') tensor(-3.2735e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.338651
Average KL loss: 0.012157
Average total loss: 0.350808
tensor(0.1081, device='cuda:0') tensor(0.0833, device='cuda:0') tensor(-2.5171e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.338435
Average KL loss: 0.012176
Average total loss: 0.350612
tensor(0.1082, device='cuda:0') tensor(0.0835, device='cuda:0') tensor(-2.9760e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.329578
Average KL loss: 0.012193
Average total loss: 0.341771
tensor(0.1083, device='cuda:0') tensor(0.0836, device='cuda:0') tensor(-3.0861e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.329269
Average KL loss: 0.012208
Average total loss: 0.341477
tensor(0.1084, device='cuda:0') tensor(0.0838, device='cuda:0') tensor(-3.8242e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.332057
Average KL loss: 0.012225
Average total loss: 0.344282
tensor(0.1085, device='cuda:0') tensor(0.0840, device='cuda:0') tensor(-3.5359e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.323253
Average KL loss: 0.012242
Average total loss: 0.335494
tensor(0.1086, device='cuda:0') tensor(0.0841, device='cuda:0') tensor(-2.6098e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.319390
Average KL loss: 0.012256
Average total loss: 0.331646
tensor(0.1086, device='cuda:0') tensor(0.0843, device='cuda:0') tensor(-2.8035e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.316822
Average KL loss: 0.012269
Average total loss: 0.329091
tensor(0.1087, device='cuda:0') tensor(0.0844, device='cuda:0') tensor(-2.4492e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.314377
Average KL loss: 0.012285
Average total loss: 0.326663
tensor(0.1088, device='cuda:0') tensor(0.0846, device='cuda:0') tensor(-3.3799e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.312484
Average KL loss: 0.012302
Average total loss: 0.324786
tensor(0.1089, device='cuda:0') tensor(0.0848, device='cuda:0') tensor(-3.9625e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.316508
Average KL loss: 0.012319
Average total loss: 0.328827
tensor(0.1090, device='cuda:0') tensor(0.0849, device='cuda:0') tensor(-2.9664e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.306736
Average KL loss: 0.012335
Average total loss: 0.319071
tensor(0.1091, device='cuda:0') tensor(0.0851, device='cuda:0') tensor(-3.1953e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.307770
Average KL loss: 0.012351
Average total loss: 0.320122
tensor(0.1092, device='cuda:0') tensor(0.0852, device='cuda:0') tensor(-3.3919e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.305910
Average KL loss: 0.012367
Average total loss: 0.318277
tensor(0.1093, device='cuda:0') tensor(0.0854, device='cuda:0') tensor(-3.3277e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.305828
Average KL loss: 0.012384
Average total loss: 0.318212
tensor(0.1094, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-3.1915e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.303062
Average KL loss: 0.012398
Average total loss: 0.315461
tensor(0.1095, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-2.6913e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.302358
Average KL loss: 0.012415
Average total loss: 0.314774
tensor(0.1096, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(-3.0135e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.293768
Average KL loss: 0.012432
Average total loss: 0.306200
tensor(0.1097, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(-3.2251e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.296840
Average KL loss: 0.012448
Average total loss: 0.309289
tensor(0.1097, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-2.5867e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.298300
Average KL loss: 0.012462
Average total loss: 0.310763
tensor(0.1098, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(-3.0759e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.291494
Average KL loss: 0.012477
Average total loss: 0.303971
tensor(0.1099, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(-2.3297e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.291590
Average KL loss: 0.012492
Average total loss: 0.304082
tensor(0.1100, device='cuda:0') tensor(0.0867, device='cuda:0') tensor(-2.3931e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.287956
Average KL loss: 0.012509
Average total loss: 0.300465
tensor(0.1101, device='cuda:0') tensor(0.0869, device='cuda:0') tensor(-3.9025e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.290542
Average KL loss: 0.012526
Average total loss: 0.303068
tensor(0.1102, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(-2.7281e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.285326
Average KL loss: 0.012541
Average total loss: 0.297867
tensor(0.1102, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(-2.5779e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.284800
Average KL loss: 0.012556
Average total loss: 0.297356
tensor(0.1103, device='cuda:0') tensor(0.0873, device='cuda:0') tensor(-2.8620e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.286384
Average KL loss: 0.012572
Average total loss: 0.298956
tensor(0.1104, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.6476e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.276331
Average KL loss: 0.012588
Average total loss: 0.288920
tensor(0.1105, device='cuda:0') tensor(0.0877, device='cuda:0') tensor(-2.2992e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.274025
Average KL loss: 0.012604
Average total loss: 0.286629
tensor(0.1106, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(-2.4467e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.273480
Average KL loss: 0.012619
Average total loss: 0.286099
tensor(0.1107, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(-2.3386e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.274319
Average KL loss: 0.012636
Average total loss: 0.286955
tensor(0.1108, device='cuda:0') tensor(0.0881, device='cuda:0') tensor(-2.6445e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.268172
Average KL loss: 0.012651
Average total loss: 0.280824
tensor(0.1108, device='cuda:0') tensor(0.0883, device='cuda:0') tensor(-2.6594e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.272361
Average KL loss: 0.012668
Average total loss: 0.285029
tensor(0.1109, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(-3.2320e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.272756
Average KL loss: 0.012684
Average total loss: 0.285440
tensor(0.1110, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(-3.1632e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.270418
Average KL loss: 0.012700
Average total loss: 0.283118
tensor(0.1111, device='cuda:0') tensor(0.0888, device='cuda:0') tensor(-2.4435e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.263307
Average KL loss: 0.012716
Average total loss: 0.276022
tensor(0.1112, device='cuda:0') tensor(0.0890, device='cuda:0') tensor(-2.2101e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.263601
Average KL loss: 0.012731
Average total loss: 0.276332
tensor(0.1112, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(-2.4796e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.264375
Average KL loss: 0.012746
Average total loss: 0.277122
tensor(0.1113, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-2.3486e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.262295
Average KL loss: 0.012762
Average total loss: 0.275057
 Percentile value: 0.0013393950881436477
Non-zero model percentage: 80.0%, Non-zero mask percentage: 80.0%

--- Pruning Level [1/24]: ---
conv1.weight         | nonzeros =    1581 /    1728             ( 91.49%) | total_pruned =     147 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   32640 /   36864             ( 88.54%) | total_pruned =    4224 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   28514 /   36864             ( 77.35%) | total_pruned =    8350 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   25913 /   36864             ( 70.29%) | total_pruned =   10951 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   27338 /   36864             ( 74.16%) | total_pruned =    9526 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   48487 /   73728             ( 65.76%) | total_pruned =   25241 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   99018 /  147456             ( 67.15%) | total_pruned =   48438 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5840 /    8192             ( 71.29%) | total_pruned =    2352 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  101524 /  147456             ( 68.85%) | total_pruned =   45932 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  106456 /  147456             ( 72.20%) | total_pruned =   41000 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  190276 /  294912             ( 64.52%) | total_pruned =  104636 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  383712 /  589824             ( 65.06%) | total_pruned =  206112 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   22966 /   32768             ( 70.09%) | total_pruned =    9802 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  386310 /  589824             ( 65.50%) | total_pruned =  203514 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  419739 /  589824             ( 71.16%) | total_pruned =  170085 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  782372 / 1179648             ( 66.32%) | total_pruned =  397276 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      77 /     512             ( 15.04%) | total_pruned =     435 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1864161 / 2359296             ( 79.01%) | total_pruned =  495135 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     345 /     512             ( 67.38%) | total_pruned =     167 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  103807 /  131072             ( 79.20%) | total_pruned =   27265 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     345 /     512             ( 67.38%) | total_pruned =     167 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1977148 / 2359296             ( 83.80%) | total_pruned =  382148 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2318863 / 2359296             ( 98.29%) | total_pruned =   40433 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    4988 /    5120             ( 97.42%) | total_pruned =     132 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 8943010, pruned : 2235752, total: 11178762, Compression rate :       1.25x  ( 20.00% pruned)
Train Epoch: 71/100 Loss: 0.011749 Accuracy: 89.41 100.00 % Best test Accuracy: 89.59%
tensor(0.1114, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-9.0632e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.551444
Average KL loss: 0.012559
Average total loss: 0.564003
tensor(0.1122, device='cuda:0') tensor(0.0861, device='cuda:0') tensor(-7.6813e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.529414
Average KL loss: 0.012207
Average total loss: 0.541621
tensor(0.1134, device='cuda:0') tensor(0.0834, device='cuda:0') tensor(-7.9717e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.518733
Average KL loss: 0.011898
Average total loss: 0.530631
tensor(0.1144, device='cuda:0') tensor(0.0809, device='cuda:0') tensor(-7.7100e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.496257
Average KL loss: 0.011622
Average total loss: 0.507878
tensor(0.1153, device='cuda:0') tensor(0.0787, device='cuda:0') tensor(-7.3902e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.468169
Average KL loss: 0.011376
Average total loss: 0.479545
tensor(0.1162, device='cuda:0') tensor(0.0767, device='cuda:0') tensor(-8.1593e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.491676
Average KL loss: 0.011154
Average total loss: 0.502830
tensor(0.1169, device='cuda:0') tensor(0.0749, device='cuda:0') tensor(-6.5963e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.463325
Average KL loss: 0.010955
Average total loss: 0.474280
tensor(0.1176, device='cuda:0') tensor(0.0733, device='cuda:0') tensor(-7.8567e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.460930
Average KL loss: 0.010778
Average total loss: 0.471708
tensor(0.1183, device='cuda:0') tensor(0.0719, device='cuda:0') tensor(-5.8330e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.425728
Average KL loss: 0.010618
Average total loss: 0.436346
tensor(0.1188, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-5.5084e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.437803
Average KL loss: 0.010477
Average total loss: 0.448279
tensor(0.1193, device='cuda:0') tensor(0.0695, device='cuda:0') tensor(-5.3058e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.433125
Average KL loss: 0.010350
Average total loss: 0.443475
tensor(0.1198, device='cuda:0') tensor(0.0686, device='cuda:0') tensor(-5.9000e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.438866
Average KL loss: 0.010238
Average total loss: 0.449104
tensor(0.1202, device='cuda:0') tensor(0.0677, device='cuda:0') tensor(-6.8930e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.408118
Average KL loss: 0.010137
Average total loss: 0.418255
tensor(0.1205, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-4.2800e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.400777
Average KL loss: 0.010048
Average total loss: 0.410826
tensor(0.1208, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-5.6207e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.396705
Average KL loss: 0.009970
Average total loss: 0.406674
tensor(0.1211, device='cuda:0') tensor(0.0656, device='cuda:0') tensor(-5.2422e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.397264
Average KL loss: 0.009901
Average total loss: 0.407165
tensor(0.1213, device='cuda:0') tensor(0.0651, device='cuda:0') tensor(-5.0931e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.405802
Average KL loss: 0.009841
Average total loss: 0.415644
tensor(0.1215, device='cuda:0') tensor(0.0647, device='cuda:0') tensor(-4.4114e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.374742
Average KL loss: 0.009790
Average total loss: 0.384532
tensor(0.1217, device='cuda:0') tensor(0.0643, device='cuda:0') tensor(-5.3675e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.381309
Average KL loss: 0.009743
Average total loss: 0.391052
tensor(0.1218, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-5.2641e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.370593
Average KL loss: 0.009703
Average total loss: 0.380296
tensor(0.1220, device='cuda:0') tensor(0.0637, device='cuda:0') tensor(-4.6118e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.377764
Average KL loss: 0.009668
Average total loss: 0.387432
tensor(0.1220, device='cuda:0') tensor(0.0635, device='cuda:0') tensor(-4.8208e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.349663
Average KL loss: 0.009639
Average total loss: 0.359302
tensor(0.1221, device='cuda:0') tensor(0.0633, device='cuda:0') tensor(-5.0291e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.354284
Average KL loss: 0.009616
Average total loss: 0.363900
tensor(0.1222, device='cuda:0') tensor(0.0632, device='cuda:0') tensor(-5.7136e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.364471
Average KL loss: 0.009596
Average total loss: 0.374067
tensor(0.1222, device='cuda:0') tensor(0.0631, device='cuda:0') tensor(-6.3161e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.345141
Average KL loss: 0.009580
Average total loss: 0.354721
tensor(0.1223, device='cuda:0') tensor(0.0630, device='cuda:0') tensor(-4.9531e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.347413
Average KL loss: 0.009566
Average total loss: 0.356980
tensor(0.1223, device='cuda:0') tensor(0.0630, device='cuda:0') tensor(-4.4591e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.359123
Average KL loss: 0.009556
Average total loss: 0.368680
tensor(0.1223, device='cuda:0') tensor(0.0630, device='cuda:0') tensor(-5.0290e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.341504
Average KL loss: 0.009550
Average total loss: 0.351054
tensor(0.1223, device='cuda:0') tensor(0.0630, device='cuda:0') tensor(-3.7350e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.337488
Average KL loss: 0.009546
Average total loss: 0.347034
tensor(0.1222, device='cuda:0') tensor(0.0630, device='cuda:0') tensor(-3.9558e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.335828
Average KL loss: 0.009542
Average total loss: 0.345370
tensor(0.1222, device='cuda:0') tensor(0.0631, device='cuda:0') tensor(-4.5493e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.322070
Average KL loss: 0.009542
Average total loss: 0.331612
tensor(0.1222, device='cuda:0') tensor(0.0631, device='cuda:0') tensor(-5.2246e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.330101
Average KL loss: 0.009543
Average total loss: 0.339643
tensor(0.1221, device='cuda:0') tensor(0.0632, device='cuda:0') tensor(-3.7603e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.328851
Average KL loss: 0.009546
Average total loss: 0.338397
tensor(0.1221, device='cuda:0') tensor(0.0633, device='cuda:0') tensor(-3.4992e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.332818
Average KL loss: 0.009549
Average total loss: 0.342367
tensor(0.1220, device='cuda:0') tensor(0.0634, device='cuda:0') tensor(-4.1017e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.322280
Average KL loss: 0.009553
Average total loss: 0.331833
tensor(0.1219, device='cuda:0') tensor(0.0635, device='cuda:0') tensor(-3.5194e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.313167
Average KL loss: 0.009559
Average total loss: 0.322726
tensor(0.1219, device='cuda:0') tensor(0.0636, device='cuda:0') tensor(-3.5639e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.316145
Average KL loss: 0.009568
Average total loss: 0.325713
tensor(0.1218, device='cuda:0') tensor(0.0637, device='cuda:0') tensor(-4.1754e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.314203
Average KL loss: 0.009579
Average total loss: 0.323783
tensor(0.1218, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-5.3243e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.310454
Average KL loss: 0.009590
Average total loss: 0.320044
tensor(0.1217, device='cuda:0') tensor(0.0641, device='cuda:0') tensor(-3.9330e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.313558
Average KL loss: 0.009602
Average total loss: 0.323161
tensor(0.1216, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-4.2714e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.298668
Average KL loss: 0.009615
Average total loss: 0.308283
tensor(0.1216, device='cuda:0') tensor(0.0644, device='cuda:0') tensor(-4.6344e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.294380
Average KL loss: 0.009626
Average total loss: 0.304006
tensor(0.1215, device='cuda:0') tensor(0.0645, device='cuda:0') tensor(-5.3545e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.298566
Average KL loss: 0.009639
Average total loss: 0.308205
tensor(0.1214, device='cuda:0') tensor(0.0647, device='cuda:0') tensor(-4.0350e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.277775
Average KL loss: 0.009653
Average total loss: 0.287428
tensor(0.1214, device='cuda:0') tensor(0.0649, device='cuda:0') tensor(-2.9612e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.291920
Average KL loss: 0.009668
Average total loss: 0.301588
tensor(0.1213, device='cuda:0') tensor(0.0651, device='cuda:0') tensor(-6.2398e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.296066
Average KL loss: 0.009683
Average total loss: 0.305750
tensor(0.1213, device='cuda:0') tensor(0.0653, device='cuda:0') tensor(-3.4646e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.278729
Average KL loss: 0.009697
Average total loss: 0.288426
tensor(0.1212, device='cuda:0') tensor(0.0654, device='cuda:0') tensor(-3.7638e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.287454
Average KL loss: 0.009712
Average total loss: 0.297166
tensor(0.1211, device='cuda:0') tensor(0.0656, device='cuda:0') tensor(-3.7958e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.285278
Average KL loss: 0.009728
Average total loss: 0.295005
tensor(0.1211, device='cuda:0') tensor(0.0658, device='cuda:0') tensor(-2.9561e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.269648
Average KL loss: 0.009744
Average total loss: 0.279392
tensor(0.1210, device='cuda:0') tensor(0.0660, device='cuda:0') tensor(-2.1984e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.271224
Average KL loss: 0.009760
Average total loss: 0.280984
tensor(0.1210, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-3.2659e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.267220
Average KL loss: 0.009776
Average total loss: 0.276996
tensor(0.1209, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-2.8863e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.258751
Average KL loss: 0.009793
Average total loss: 0.268544
tensor(0.1209, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-3.0083e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.263192
Average KL loss: 0.009809
Average total loss: 0.273001
tensor(0.1208, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-4.3974e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.264918
Average KL loss: 0.009826
Average total loss: 0.274745
tensor(0.1208, device='cuda:0') tensor(0.0670, device='cuda:0') tensor(-3.3753e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.262538
Average KL loss: 0.009843
Average total loss: 0.272380
tensor(0.1207, device='cuda:0') tensor(0.0672, device='cuda:0') tensor(-3.6549e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.259774
Average KL loss: 0.009861
Average total loss: 0.269635
tensor(0.1207, device='cuda:0') tensor(0.0674, device='cuda:0') tensor(-3.8621e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.252063
Average KL loss: 0.009878
Average total loss: 0.261941
tensor(0.1206, device='cuda:0') tensor(0.0676, device='cuda:0') tensor(-3.3055e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.254121
Average KL loss: 0.009895
Average total loss: 0.264016
tensor(0.1206, device='cuda:0') tensor(0.0678, device='cuda:0') tensor(-5.8381e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.266776
Average KL loss: 0.009913
Average total loss: 0.276689
tensor(0.1206, device='cuda:0') tensor(0.0680, device='cuda:0') tensor(-2.8254e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.255434
Average KL loss: 0.009933
Average total loss: 0.265367
tensor(0.1205, device='cuda:0') tensor(0.0682, device='cuda:0') tensor(-2.5877e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.254558
Average KL loss: 0.009952
Average total loss: 0.264510
tensor(0.1205, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(-3.1937e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.249401
Average KL loss: 0.009969
Average total loss: 0.259370
tensor(0.1205, device='cuda:0') tensor(0.0686, device='cuda:0') tensor(-2.5153e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.255905
Average KL loss: 0.009988
Average total loss: 0.265893
tensor(0.1205, device='cuda:0') tensor(0.0688, device='cuda:0') tensor(-4.0742e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.249554
Average KL loss: 0.010008
Average total loss: 0.259561
tensor(0.1204, device='cuda:0') tensor(0.0690, device='cuda:0') tensor(-2.9957e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.259702
Average KL loss: 0.010026
Average total loss: 0.269728
tensor(0.1204, device='cuda:0') tensor(0.0693, device='cuda:0') tensor(-3.6836e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.252661
Average KL loss: 0.010048
Average total loss: 0.262709
tensor(0.1204, device='cuda:0') tensor(0.0695, device='cuda:0') tensor(-3.3836e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.239356
Average KL loss: 0.010067
Average total loss: 0.249424
tensor(0.1204, device='cuda:0') tensor(0.0697, device='cuda:0') tensor(-2.5937e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.237961
Average KL loss: 0.010086
Average total loss: 0.248047
tensor(0.1203, device='cuda:0') tensor(0.0699, device='cuda:0') tensor(-2.8163e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.249202
Average KL loss: 0.010105
Average total loss: 0.259307
tensor(0.1203, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-3.1387e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.242979
Average KL loss: 0.010125
Average total loss: 0.253104
tensor(0.1203, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-1.9390e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.246675
Average KL loss: 0.010143
Average total loss: 0.256818
tensor(0.1203, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-3.9363e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.240666
Average KL loss: 0.010163
Average total loss: 0.250828
tensor(0.1203, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-2.6783e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.232977
Average KL loss: 0.010182
Average total loss: 0.243159
tensor(0.1203, device='cuda:0') tensor(0.0709, device='cuda:0') tensor(-2.7438e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.224787
Average KL loss: 0.010199
Average total loss: 0.234986
tensor(0.1203, device='cuda:0') tensor(0.0711, device='cuda:0') tensor(-2.0820e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.220149
Average KL loss: 0.010216
Average total loss: 0.230365
tensor(0.1202, device='cuda:0') tensor(0.0713, device='cuda:0') tensor(-3.1100e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.224927
Average KL loss: 0.010234
Average total loss: 0.235161
tensor(0.1202, device='cuda:0') tensor(0.0715, device='cuda:0') tensor(-3.4396e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.221078
Average KL loss: 0.010251
Average total loss: 0.231330
tensor(0.1202, device='cuda:0') tensor(0.0717, device='cuda:0') tensor(-2.1857e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.221820
Average KL loss: 0.010270
Average total loss: 0.232090
tensor(0.1202, device='cuda:0') tensor(0.0719, device='cuda:0') tensor(-2.4591e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.226955
Average KL loss: 0.010288
Average total loss: 0.237242
tensor(0.1202, device='cuda:0') tensor(0.0721, device='cuda:0') tensor(-2.4597e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.210106
Average KL loss: 0.010304
Average total loss: 0.220411
tensor(0.1202, device='cuda:0') tensor(0.0723, device='cuda:0') tensor(-4.7786e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.222614
Average KL loss: 0.010322
Average total loss: 0.232936
tensor(0.1202, device='cuda:0') tensor(0.0725, device='cuda:0') tensor(-2.5602e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.214450
Average KL loss: 0.010340
Average total loss: 0.224790
tensor(0.1202, device='cuda:0') tensor(0.0727, device='cuda:0') tensor(-3.7740e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.219085
Average KL loss: 0.010358
Average total loss: 0.229443
tensor(0.1202, device='cuda:0') tensor(0.0729, device='cuda:0') tensor(-3.2771e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.206763
Average KL loss: 0.010376
Average total loss: 0.217139
tensor(0.1202, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(-2.4215e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.206563
Average KL loss: 0.010393
Average total loss: 0.216955
tensor(0.1202, device='cuda:0') tensor(0.0733, device='cuda:0') tensor(-2.6457e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.209209
Average KL loss: 0.010410
Average total loss: 0.219619
tensor(0.1202, device='cuda:0') tensor(0.0735, device='cuda:0') tensor(-2.2398e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.210956
Average KL loss: 0.010427
Average total loss: 0.221383
tensor(0.1202, device='cuda:0') tensor(0.0737, device='cuda:0') tensor(-3.2575e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.209719
Average KL loss: 0.010445
Average total loss: 0.220164
tensor(0.1202, device='cuda:0') tensor(0.0739, device='cuda:0') tensor(-3.4130e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.213993
Average KL loss: 0.010463
Average total loss: 0.224456
tensor(0.1202, device='cuda:0') tensor(0.0741, device='cuda:0') tensor(-1.8100e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.205618
Average KL loss: 0.010482
Average total loss: 0.216099
tensor(0.1202, device='cuda:0') tensor(0.0743, device='cuda:0') tensor(-2.3610e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.198069
Average KL loss: 0.010499
Average total loss: 0.208567
tensor(0.1202, device='cuda:0') tensor(0.0745, device='cuda:0') tensor(-2.5096e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.201554
Average KL loss: 0.010515
Average total loss: 0.212069
tensor(0.1202, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(-2.5766e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.204173
Average KL loss: 0.010531
Average total loss: 0.214704
tensor(0.1202, device='cuda:0') tensor(0.0748, device='cuda:0') tensor(-2.3943e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.202198
Average KL loss: 0.010548
Average total loss: 0.212746
tensor(0.1202, device='cuda:0') tensor(0.0750, device='cuda:0') tensor(-3.3409e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.204730
Average KL loss: 0.010565
Average total loss: 0.215295
tensor(0.1202, device='cuda:0') tensor(0.0752, device='cuda:0') tensor(-2.2718e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.204311
Average KL loss: 0.010581
Average total loss: 0.214892
tensor(0.1202, device='cuda:0') tensor(0.0754, device='cuda:0') tensor(-2.5063e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.191814
Average KL loss: 0.010598
Average total loss: 0.202412
tensor(0.1202, device='cuda:0') tensor(0.0756, device='cuda:0') tensor(-2.8246e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.192209
Average KL loss: 0.010613
Average total loss: 0.202821
tensor(0.1202, device='cuda:0') tensor(0.0758, device='cuda:0') tensor(-2.3521e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.193442
Average KL loss: 0.010630
Average total loss: 0.204072
tensor(0.1202, device='cuda:0') tensor(0.0760, device='cuda:0') tensor(-2.0929e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.194844
Average KL loss: 0.010646
Average total loss: 0.205490
tensor(0.1202, device='cuda:0') tensor(0.0762, device='cuda:0') tensor(-2.0360e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.188474
Average KL loss: 0.010662
Average total loss: 0.199136
tensor(0.1202, device='cuda:0') tensor(0.0763, device='cuda:0') tensor(-2.7748e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.189775
Average KL loss: 0.010677
Average total loss: 0.200452
tensor(0.1202, device='cuda:0') tensor(0.0765, device='cuda:0') tensor(-2.1039e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.195351
Average KL loss: 0.010693
Average total loss: 0.206044
tensor(0.1202, device='cuda:0') tensor(0.0767, device='cuda:0') tensor(-1.9010e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.191401
Average KL loss: 0.010711
Average total loss: 0.202112
tensor(0.1202, device='cuda:0') tensor(0.0769, device='cuda:0') tensor(-2.4338e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.182200
Average KL loss: 0.010727
Average total loss: 0.192926
tensor(0.1202, device='cuda:0') tensor(0.0771, device='cuda:0') tensor(-1.6579e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.179270
Average KL loss: 0.010741
Average total loss: 0.190011
tensor(0.1202, device='cuda:0') tensor(0.0773, device='cuda:0') tensor(-2.2540e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.177212
Average KL loss: 0.010757
Average total loss: 0.187968
tensor(0.1203, device='cuda:0') tensor(0.0774, device='cuda:0') tensor(-3.0572e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.187176
Average KL loss: 0.010773
Average total loss: 0.197949
tensor(0.1203, device='cuda:0') tensor(0.0776, device='cuda:0') tensor(-2.7681e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.183292
Average KL loss: 0.010788
Average total loss: 0.194081
tensor(0.1203, device='cuda:0') tensor(0.0778, device='cuda:0') tensor(-1.6096e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.172929
Average KL loss: 0.010803
Average total loss: 0.183733
tensor(0.1203, device='cuda:0') tensor(0.0780, device='cuda:0') tensor(-1.9696e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.176157
Average KL loss: 0.010818
Average total loss: 0.186975
tensor(0.1203, device='cuda:0') tensor(0.0781, device='cuda:0') tensor(-2.7729e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.184021
Average KL loss: 0.010834
Average total loss: 0.194855
tensor(0.1203, device='cuda:0') tensor(0.0783, device='cuda:0') tensor(-3.1625e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.172466
Average KL loss: 0.010850
Average total loss: 0.183316
tensor(0.1203, device='cuda:0') tensor(0.0785, device='cuda:0') tensor(-2.4094e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.179151
Average KL loss: 0.010865
Average total loss: 0.190016
tensor(0.1203, device='cuda:0') tensor(0.0787, device='cuda:0') tensor(-1.9021e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.179837
Average KL loss: 0.010881
Average total loss: 0.190718
tensor(0.1203, device='cuda:0') tensor(0.0789, device='cuda:0') tensor(-2.8559e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.174592
Average KL loss: 0.010900
Average total loss: 0.185491
tensor(0.1203, device='cuda:0') tensor(0.0791, device='cuda:0') tensor(-2.0290e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.171340
Average KL loss: 0.010915
Average total loss: 0.182255
tensor(0.1203, device='cuda:0') tensor(0.0793, device='cuda:0') tensor(-2.0077e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.169490
Average KL loss: 0.010930
Average total loss: 0.180419
tensor(0.1203, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-2.3466e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.171349
Average KL loss: 0.010944
Average total loss: 0.182293
tensor(0.1204, device='cuda:0') tensor(0.0796, device='cuda:0') tensor(-1.8664e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.169449
Average KL loss: 0.010959
Average total loss: 0.180408
tensor(0.1204, device='cuda:0') tensor(0.0798, device='cuda:0') tensor(-1.8300e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.167657
Average KL loss: 0.010974
Average total loss: 0.178631
tensor(0.1204, device='cuda:0') tensor(0.0800, device='cuda:0') tensor(-2.1515e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.167197
Average KL loss: 0.010989
Average total loss: 0.178185
tensor(0.1204, device='cuda:0') tensor(0.0801, device='cuda:0') tensor(-2.2443e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.160202
Average KL loss: 0.011003
Average total loss: 0.171205
tensor(0.1204, device='cuda:0') tensor(0.0803, device='cuda:0') tensor(-2.2433e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.162583
Average KL loss: 0.011016
Average total loss: 0.173598
tensor(0.1204, device='cuda:0') tensor(0.0805, device='cuda:0') tensor(-2.3607e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.164747
Average KL loss: 0.011030
Average total loss: 0.175777
tensor(0.1204, device='cuda:0') tensor(0.0807, device='cuda:0') tensor(-1.6697e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.159412
Average KL loss: 0.011045
Average total loss: 0.170456
tensor(0.1204, device='cuda:0') tensor(0.0808, device='cuda:0') tensor(-2.3170e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.166015
Average KL loss: 0.011059
Average total loss: 0.177075
tensor(0.1204, device='cuda:0') tensor(0.0810, device='cuda:0') tensor(-1.3579e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.158600
Average KL loss: 0.011073
Average total loss: 0.169672
tensor(0.1204, device='cuda:0') tensor(0.0812, device='cuda:0') tensor(-2.2851e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.156666
Average KL loss: 0.011087
Average total loss: 0.167753
tensor(0.1204, device='cuda:0') tensor(0.0813, device='cuda:0') tensor(-1.3384e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.158549
Average KL loss: 0.011101
Average total loss: 0.169650
tensor(0.1204, device='cuda:0') tensor(0.0815, device='cuda:0') tensor(-2.8814e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.156557
Average KL loss: 0.011116
Average total loss: 0.167673
tensor(0.1204, device='cuda:0') tensor(0.0817, device='cuda:0') tensor(-1.9456e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.159363
Average KL loss: 0.011131
Average total loss: 0.170493
tensor(0.1204, device='cuda:0') tensor(0.0819, device='cuda:0') tensor(-1.6445e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.149721
Average KL loss: 0.011145
Average total loss: 0.160865
tensor(0.1204, device='cuda:0') tensor(0.0820, device='cuda:0') tensor(-2.0633e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.154493
Average KL loss: 0.011159
Average total loss: 0.165651
tensor(0.1204, device='cuda:0') tensor(0.0822, device='cuda:0') tensor(-1.8206e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.158083
Average KL loss: 0.011173
Average total loss: 0.169255
tensor(0.1204, device='cuda:0') tensor(0.0824, device='cuda:0') tensor(-2.4661e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.153351
Average KL loss: 0.011187
Average total loss: 0.164538
tensor(0.1204, device='cuda:0') tensor(0.0826, device='cuda:0') tensor(-1.6144e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.149845
Average KL loss: 0.011201
Average total loss: 0.161046
tensor(0.1204, device='cuda:0') tensor(0.0827, device='cuda:0') tensor(-1.6876e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.156712
Average KL loss: 0.011215
Average total loss: 0.167927
tensor(0.1204, device='cuda:0') tensor(0.0829, device='cuda:0') tensor(-1.9378e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.147030
Average KL loss: 0.011230
Average total loss: 0.158260
tensor(0.1204, device='cuda:0') tensor(0.0831, device='cuda:0') tensor(-1.5381e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.149405
Average KL loss: 0.011242
Average total loss: 0.160648
tensor(0.1205, device='cuda:0') tensor(0.0832, device='cuda:0') tensor(-2.7505e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.145211
Average KL loss: 0.011256
Average total loss: 0.156467
tensor(0.1205, device='cuda:0') tensor(0.0834, device='cuda:0') tensor(-1.5758e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.149708
Average KL loss: 0.011269
Average total loss: 0.160977
tensor(0.1205, device='cuda:0') tensor(0.0836, device='cuda:0') tensor(-1.5699e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.145847
Average KL loss: 0.011282
Average total loss: 0.157129
tensor(0.1205, device='cuda:0') tensor(0.0837, device='cuda:0') tensor(-2.1487e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.148164
Average KL loss: 0.011295
Average total loss: 0.159459
tensor(0.1204, device='cuda:0') tensor(0.0839, device='cuda:0') tensor(-1.8175e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.142472
Average KL loss: 0.011307
Average total loss: 0.153779
tensor(0.1204, device='cuda:0') tensor(0.0841, device='cuda:0') tensor(-2.1256e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.143827
Average KL loss: 0.011319
Average total loss: 0.155146
tensor(0.1204, device='cuda:0') tensor(0.0842, device='cuda:0') tensor(-1.7672e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.143427
Average KL loss: 0.011330
Average total loss: 0.154757
tensor(0.1204, device='cuda:0') tensor(0.0844, device='cuda:0') tensor(-2.3493e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.144483
Average KL loss: 0.011343
Average total loss: 0.155826
tensor(0.1204, device='cuda:0') tensor(0.0845, device='cuda:0') tensor(-1.8264e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.140311
Average KL loss: 0.011356
Average total loss: 0.151667
tensor(0.1204, device='cuda:0') tensor(0.0847, device='cuda:0') tensor(-1.9171e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.142701
Average KL loss: 0.011369
Average total loss: 0.154069
tensor(0.1204, device='cuda:0') tensor(0.0849, device='cuda:0') tensor(-1.4030e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.140408
Average KL loss: 0.011381
Average total loss: 0.151789
tensor(0.1204, device='cuda:0') tensor(0.0850, device='cuda:0') tensor(-1.3079e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.137044
Average KL loss: 0.011395
Average total loss: 0.148439
tensor(0.1204, device='cuda:0') tensor(0.0852, device='cuda:0') tensor(-1.7642e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.140659
Average KL loss: 0.011407
Average total loss: 0.152066
tensor(0.1204, device='cuda:0') tensor(0.0854, device='cuda:0') tensor(-1.4995e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.138211
Average KL loss: 0.011420
Average total loss: 0.149631
tensor(0.1204, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-2.0249e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.141304
Average KL loss: 0.011433
Average total loss: 0.152737
tensor(0.1204, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-1.7093e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.133978
Average KL loss: 0.011445
Average total loss: 0.145423
tensor(0.1204, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(-1.8802e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.128541
Average KL loss: 0.011457
Average total loss: 0.139998
tensor(0.1204, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(-1.2225e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.128450
Average KL loss: 0.011468
Average total loss: 0.139918
tensor(0.1204, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-1.4369e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.139752
Average KL loss: 0.011480
Average total loss: 0.151232
tensor(0.1204, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(-1.3815e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.130342
Average KL loss: 0.011492
Average total loss: 0.141834
tensor(0.1204, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(-1.2628e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.131004
Average KL loss: 0.011503
Average total loss: 0.142507
tensor(0.1204, device='cuda:0') tensor(0.0866, device='cuda:0') tensor(-1.7684e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.132194
Average KL loss: 0.011517
Average total loss: 0.143711
tensor(0.1204, device='cuda:0') tensor(0.0868, device='cuda:0') tensor(-1.6997e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.129475
Average KL loss: 0.011530
Average total loss: 0.141006
tensor(0.1204, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(-1.7300e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.126879
Average KL loss: 0.011542
Average total loss: 0.138421
tensor(0.1204, device='cuda:0') tensor(0.0871, device='cuda:0') tensor(-1.4811e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.127821
Average KL loss: 0.011554
Average total loss: 0.139375
tensor(0.1204, device='cuda:0') tensor(0.0873, device='cuda:0') tensor(-1.6805e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.129067
Average KL loss: 0.011565
Average total loss: 0.140632
tensor(0.1204, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-1.5814e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.125992
Average KL loss: 0.011578
Average total loss: 0.137569
tensor(0.1204, device='cuda:0') tensor(0.0876, device='cuda:0') tensor(-1.2580e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.123249
Average KL loss: 0.011589
Average total loss: 0.134838
tensor(0.1204, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(-1.7500e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.127778
Average KL loss: 0.011601
Average total loss: 0.139379
tensor(0.1204, device='cuda:0') tensor(0.0879, device='cuda:0') tensor(-1.6842e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.128364
Average KL loss: 0.011614
Average total loss: 0.139979
tensor(0.1204, device='cuda:0') tensor(0.0881, device='cuda:0') tensor(-1.1931e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.126188
Average KL loss: 0.011627
Average total loss: 0.137815
tensor(0.1204, device='cuda:0') tensor(0.0882, device='cuda:0') tensor(-1.3021e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.123772
Average KL loss: 0.011638
Average total loss: 0.135410
tensor(0.1204, device='cuda:0') tensor(0.0884, device='cuda:0') tensor(-1.6268e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.124307
Average KL loss: 0.011650
Average total loss: 0.135956
tensor(0.1204, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(-1.3622e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.126223
Average KL loss: 0.011660
Average total loss: 0.137882
tensor(0.1204, device='cuda:0') tensor(0.0887, device='cuda:0') tensor(-1.3106e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.118502
Average KL loss: 0.011672
Average total loss: 0.130174
tensor(0.1204, device='cuda:0') tensor(0.0889, device='cuda:0') tensor(-1.5161e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.123647
Average KL loss: 0.011683
Average total loss: 0.135330
tensor(0.1204, device='cuda:0') tensor(0.0890, device='cuda:0') tensor(-1.7815e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.121239
Average KL loss: 0.011695
Average total loss: 0.132935
tensor(0.1204, device='cuda:0') tensor(0.0892, device='cuda:0') tensor(-1.7247e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.125451
Average KL loss: 0.011706
Average total loss: 0.137157
tensor(0.1204, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.5300e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.119308
Average KL loss: 0.011716
Average total loss: 0.131024
tensor(0.1204, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-1.2410e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.119209
Average KL loss: 0.011726
Average total loss: 0.130936
tensor(0.1204, device='cuda:0') tensor(0.0896, device='cuda:0') tensor(-1.3950e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.118347
Average KL loss: 0.011736
Average total loss: 0.130083
tensor(0.1204, device='cuda:0') tensor(0.0898, device='cuda:0') tensor(-1.0870e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.116599
Average KL loss: 0.011748
Average total loss: 0.128347
tensor(0.1204, device='cuda:0') tensor(0.0899, device='cuda:0') tensor(-9.8913e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.114735
Average KL loss: 0.011759
Average total loss: 0.126494
tensor(0.1204, device='cuda:0') tensor(0.0901, device='cuda:0') tensor(-1.3025e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.113454
Average KL loss: 0.011768
Average total loss: 0.125222
tensor(0.1204, device='cuda:0') tensor(0.0902, device='cuda:0') tensor(-1.5169e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.118179
Average KL loss: 0.011778
Average total loss: 0.129958
tensor(0.1204, device='cuda:0') tensor(0.0904, device='cuda:0') tensor(-1.9399e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.114483
Average KL loss: 0.011790
Average total loss: 0.126273
tensor(0.1204, device='cuda:0') tensor(0.0905, device='cuda:0') tensor(-1.6015e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.113596
Average KL loss: 0.011800
Average total loss: 0.125396
tensor(0.1203, device='cuda:0') tensor(0.0907, device='cuda:0') tensor(-8.1355e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.113338
Average KL loss: 0.011811
Average total loss: 0.125149
tensor(0.1203, device='cuda:0') tensor(0.0908, device='cuda:0') tensor(-1.2869e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.111992
Average KL loss: 0.011820
Average total loss: 0.123812
tensor(0.1203, device='cuda:0') tensor(0.0909, device='cuda:0') tensor(-1.5974e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.111455
Average KL loss: 0.011830
Average total loss: 0.123285
tensor(0.1203, device='cuda:0') tensor(0.0911, device='cuda:0') tensor(-1.3743e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.109351
Average KL loss: 0.011840
Average total loss: 0.121191
tensor(0.1203, device='cuda:0') tensor(0.0912, device='cuda:0') tensor(-2.1649e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.108574
Average KL loss: 0.011848
Average total loss: 0.120422
tensor(0.1203, device='cuda:0') tensor(0.0914, device='cuda:0') tensor(-1.2698e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.112612
Average KL loss: 0.011858
Average total loss: 0.124470
tensor(0.1203, device='cuda:0') tensor(0.0915, device='cuda:0') tensor(-1.0136e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.108683
Average KL loss: 0.011869
Average total loss: 0.120551
tensor(0.1203, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-1.1276e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.107804
Average KL loss: 0.011878
Average total loss: 0.119682
tensor(0.1203, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(-1.5270e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.110753
Average KL loss: 0.011886
Average total loss: 0.122640
tensor(0.1202, device='cuda:0') tensor(0.0919, device='cuda:0') tensor(-1.2254e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.109549
Average KL loss: 0.011897
Average total loss: 0.121446
tensor(0.1202, device='cuda:0') tensor(0.0921, device='cuda:0') tensor(-9.9609e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.108267
Average KL loss: 0.011908
Average total loss: 0.120175
tensor(0.1202, device='cuda:0') tensor(0.0922, device='cuda:0') tensor(-1.2854e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.106470
Average KL loss: 0.011919
Average total loss: 0.118389
 Percentile value: 3.260853409301491e-05
Non-zero model percentage: 64.0%, Non-zero mask percentage: 64.0%

--- Pruning Level [2/24]: ---
conv1.weight         | nonzeros =    1544 /    1728             ( 89.35%) | total_pruned =     184 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   31897 /   36864             ( 86.53%) | total_pruned =    4967 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   26237 /   36864             ( 71.17%) | total_pruned =   10627 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   23060 /   36864             ( 62.55%) | total_pruned =   13804 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   23580 /   36864             ( 63.96%) | total_pruned =   13284 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   40831 /   73728             ( 55.38%) | total_pruned =   32897 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   82217 /  147456             ( 55.76%) | total_pruned =   65239 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5057 /    8192             ( 61.73%) | total_pruned =    3135 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   81984 /  147456             ( 55.60%) | total_pruned =   65472 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   86373 /  147456             ( 58.58%) | total_pruned =   61083 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  155067 /  294912             ( 52.58%) | total_pruned =  139845 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  304947 /  589824             ( 51.70%) | total_pruned =  284877 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   19097 /   32768             ( 58.28%) | total_pruned =   13671 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  297727 /  589824             ( 50.48%) | total_pruned =  292097 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  304384 /  589824             ( 51.61%) | total_pruned =  285440 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  602214 / 1179648             ( 51.05%) | total_pruned =  577434 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      77 /     512             ( 15.04%) | total_pruned =     435 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1348418 / 2359296             ( 57.15%) | total_pruned = 1010878 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     330 /     512             ( 64.45%) | total_pruned =     182 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   76386 /  131072             ( 58.28%) | total_pruned =   54686 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     328 /     512             ( 64.06%) | total_pruned =     184 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1520154 / 2359296             ( 64.43%) | total_pruned =  839142 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      36 /     512             (  7.03%) | total_pruned =     476 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2106975 / 2359296             ( 89.31%) | total_pruned =  252321 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
linear.weight        | nonzeros =    4971 /    5120             ( 97.09%) | total_pruned =     149 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 7154408, pruned : 4024354, total: 11178762, Compression rate :       1.56x  ( 36.00% pruned)
Train Epoch: 42/100 Loss: 0.011850 Accuracy: 89.15 100.00 % Best test Accuracy: 89.18%
tensor(0.1202, device='cuda:0') tensor(0.0924, device='cuda:0') tensor(-2.1463e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.168354
Average KL loss: 0.011855
Average total loss: 0.180210
tensor(0.1204, device='cuda:0') tensor(0.0914, device='cuda:0') tensor(-3.0458e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.158030
Average KL loss: 0.011774
Average total loss: 0.169803
tensor(0.1209, device='cuda:0') tensor(0.0908, device='cuda:0') tensor(-2.1313e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.164436
Average KL loss: 0.011708
Average total loss: 0.176144
tensor(0.1213, device='cuda:0') tensor(0.0902, device='cuda:0') tensor(-1.9431e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.155240
Average KL loss: 0.011652
Average total loss: 0.166891
tensor(0.1216, device='cuda:0') tensor(0.0898, device='cuda:0') tensor(-1.9122e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.153171
Average KL loss: 0.011601
Average total loss: 0.164772
tensor(0.1219, device='cuda:0') tensor(0.0894, device='cuda:0') tensor(-2.6712e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.164112
Average KL loss: 0.011557
Average total loss: 0.175669
tensor(0.1222, device='cuda:0') tensor(0.0890, device='cuda:0') tensor(-2.7490e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.147770
Average KL loss: 0.011518
Average total loss: 0.159287
tensor(0.1225, device='cuda:0') tensor(0.0887, device='cuda:0') tensor(-2.0984e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.146376
Average KL loss: 0.011481
Average total loss: 0.157857
tensor(0.1227, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(-1.9664e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.145705
Average KL loss: 0.011450
Average total loss: 0.157155
tensor(0.1228, device='cuda:0') tensor(0.0882, device='cuda:0') tensor(-2.1405e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.138427
Average KL loss: 0.011422
Average total loss: 0.149849
tensor(0.1230, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(-3.5119e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.150444
Average KL loss: 0.011397
Average total loss: 0.161841
tensor(0.1231, device='cuda:0') tensor(0.0879, device='cuda:0') tensor(-2.3736e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.147789
Average KL loss: 0.011376
Average total loss: 0.159166
tensor(0.1233, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(-2.4189e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.135506
Average KL loss: 0.011357
Average total loss: 0.146864
tensor(0.1233, device='cuda:0') tensor(0.0876, device='cuda:0') tensor(-2.5260e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.135605
Average KL loss: 0.011339
Average total loss: 0.146944
tensor(0.1234, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.5531e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.138345
Average KL loss: 0.011324
Average total loss: 0.149670
tensor(0.1235, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-1.8251e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.134882
Average KL loss: 0.011312
Average total loss: 0.146194
tensor(0.1235, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-1.2288e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.136355
Average KL loss: 0.011300
Average total loss: 0.147655
tensor(0.1236, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-1.9262e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.142006
Average KL loss: 0.011290
Average total loss: 0.153296
tensor(0.1236, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-1.7896e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.130681
Average KL loss: 0.011282
Average total loss: 0.141963
tensor(0.1236, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-3.8195e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.140954
Average KL loss: 0.011275
Average total loss: 0.152228
tensor(0.1236, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-2.4803e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.129893
Average KL loss: 0.011271
Average total loss: 0.141163
tensor(0.1236, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-1.8223e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.134078
Average KL loss: 0.011267
Average total loss: 0.145345
tensor(0.1236, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-1.8260e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.138564
Average KL loss: 0.011264
Average total loss: 0.149827
tensor(0.1236, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.0676e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.130343
Average KL loss: 0.011263
Average total loss: 0.141606
tensor(0.1236, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-1.3417e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.131093
Average KL loss: 0.011262
Average total loss: 0.142354
tensor(0.1235, device='cuda:0') tensor(0.0876, device='cuda:0') tensor(-1.3425e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.124655
Average KL loss: 0.011260
Average total loss: 0.135915
tensor(0.1235, device='cuda:0') tensor(0.0877, device='cuda:0') tensor(-1.7439e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.119766
Average KL loss: 0.011260
Average total loss: 0.131026
tensor(0.1235, device='cuda:0') tensor(0.0877, device='cuda:0') tensor(-1.3573e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.121880
Average KL loss: 0.011260
Average total loss: 0.133140
tensor(0.1234, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(-1.2827e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.124044
Average KL loss: 0.011259
Average total loss: 0.135304
tensor(0.1234, device='cuda:0') tensor(0.0879, device='cuda:0') tensor(-1.5991e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.122625
Average KL loss: 0.011261
Average total loss: 0.133886
tensor(0.1233, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(-2.0381e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.122870
Average KL loss: 0.011263
Average total loss: 0.134133
tensor(0.1233, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(-2.2802e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.123860
Average KL loss: 0.011265
Average total loss: 0.135126
tensor(0.1232, device='cuda:0') tensor(0.0881, device='cuda:0') tensor(-1.7375e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.123911
Average KL loss: 0.011269
Average total loss: 0.135179
tensor(0.1232, device='cuda:0') tensor(0.0882, device='cuda:0') tensor(-1.2348e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.118908
Average KL loss: 0.011273
Average total loss: 0.130181
tensor(0.1231, device='cuda:0') tensor(0.0884, device='cuda:0') tensor(-1.3649e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.115584
Average KL loss: 0.011277
Average total loss: 0.126861
tensor(0.1231, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(-1.4164e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.123093
Average KL loss: 0.011280
Average total loss: 0.134373
tensor(0.1230, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(-1.4791e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.114121
Average KL loss: 0.011285
Average total loss: 0.125406
tensor(0.1230, device='cuda:0') tensor(0.0887, device='cuda:0') tensor(-1.2103e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.114576
Average KL loss: 0.011289
Average total loss: 0.125865
tensor(0.1229, device='cuda:0') tensor(0.0888, device='cuda:0') tensor(-1.4143e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.121506
Average KL loss: 0.011294
Average total loss: 0.132800
tensor(0.1229, device='cuda:0') tensor(0.0889, device='cuda:0') tensor(-2.1321e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.115507
Average KL loss: 0.011299
Average total loss: 0.126806
tensor(0.1228, device='cuda:0') tensor(0.0890, device='cuda:0') tensor(-1.4362e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.115333
Average KL loss: 0.011305
Average total loss: 0.126638
tensor(0.1228, device='cuda:0') tensor(0.0891, device='cuda:0') tensor(-1.3587e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.111693
Average KL loss: 0.011311
Average total loss: 0.123004
tensor(0.1227, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-1.5334e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.113904
Average KL loss: 0.011317
Average total loss: 0.125220
tensor(0.1227, device='cuda:0') tensor(0.0894, device='cuda:0') tensor(-1.3710e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.110967
Average KL loss: 0.011323
Average total loss: 0.122290
tensor(0.1226, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-1.2612e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.108541
Average KL loss: 0.011329
Average total loss: 0.119870
tensor(0.1226, device='cuda:0') tensor(0.0896, device='cuda:0') tensor(-1.3102e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.112638
Average KL loss: 0.011335
Average total loss: 0.123972
tensor(0.1226, device='cuda:0') tensor(0.0898, device='cuda:0') tensor(-1.4253e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.110927
Average KL loss: 0.011341
Average total loss: 0.122268
tensor(0.1225, device='cuda:0') tensor(0.0899, device='cuda:0') tensor(-9.1209e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.110819
Average KL loss: 0.011348
Average total loss: 0.122167
tensor(0.1225, device='cuda:0') tensor(0.0900, device='cuda:0') tensor(-1.2632e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.110652
Average KL loss: 0.011354
Average total loss: 0.122006
tensor(0.1224, device='cuda:0') tensor(0.0901, device='cuda:0') tensor(-1.4125e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.108935
Average KL loss: 0.011363
Average total loss: 0.120298
tensor(0.1224, device='cuda:0') tensor(0.0903, device='cuda:0') tensor(-1.5946e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.105602
Average KL loss: 0.011371
Average total loss: 0.116973
tensor(0.1223, device='cuda:0') tensor(0.0904, device='cuda:0') tensor(-1.7508e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.107626
Average KL loss: 0.011378
Average total loss: 0.119005
tensor(0.1223, device='cuda:0') tensor(0.0906, device='cuda:0') tensor(-1.8148e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.106223
Average KL loss: 0.011386
Average total loss: 0.117608
tensor(0.1223, device='cuda:0') tensor(0.0907, device='cuda:0') tensor(-1.0911e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.106478
Average KL loss: 0.011393
Average total loss: 0.117871
tensor(0.1222, device='cuda:0') tensor(0.0908, device='cuda:0') tensor(-1.2414e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.106066
Average KL loss: 0.011401
Average total loss: 0.117467
tensor(0.1222, device='cuda:0') tensor(0.0910, device='cuda:0') tensor(-1.5137e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.109552
Average KL loss: 0.011409
Average total loss: 0.120961
tensor(0.1221, device='cuda:0') tensor(0.0911, device='cuda:0') tensor(-1.4510e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.105758
Average KL loss: 0.011417
Average total loss: 0.117175
tensor(0.1221, device='cuda:0') tensor(0.0912, device='cuda:0') tensor(-1.0655e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.102340
Average KL loss: 0.011425
Average total loss: 0.113764
tensor(0.1221, device='cuda:0') tensor(0.0914, device='cuda:0') tensor(-2.4261e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.104752
Average KL loss: 0.011433
Average total loss: 0.116185
tensor(0.1220, device='cuda:0') tensor(0.0915, device='cuda:0') tensor(-1.1328e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.102552
Average KL loss: 0.011441
Average total loss: 0.113993
tensor(0.1220, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-2.0212e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.103639
Average KL loss: 0.011449
Average total loss: 0.115088
tensor(0.1220, device='cuda:0') tensor(0.0918, device='cuda:0') tensor(-1.1718e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.100259
Average KL loss: 0.011457
Average total loss: 0.111716
tensor(0.1219, device='cuda:0') tensor(0.0919, device='cuda:0') tensor(-1.2058e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.105615
Average KL loss: 0.011464
Average total loss: 0.117080
tensor(0.1219, device='cuda:0') tensor(0.0921, device='cuda:0') tensor(-1.1407e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.103068
Average KL loss: 0.011473
Average total loss: 0.114540
tensor(0.1218, device='cuda:0') tensor(0.0922, device='cuda:0') tensor(-9.1096e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.099896
Average KL loss: 0.011481
Average total loss: 0.111377
tensor(0.1218, device='cuda:0') tensor(0.0924, device='cuda:0') tensor(-1.5982e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.097528
Average KL loss: 0.011489
Average total loss: 0.109017
tensor(0.1218, device='cuda:0') tensor(0.0925, device='cuda:0') tensor(-9.6758e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.096065
Average KL loss: 0.011497
Average total loss: 0.107562
tensor(0.1217, device='cuda:0') tensor(0.0926, device='cuda:0') tensor(-1.7227e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.096804
Average KL loss: 0.011505
Average total loss: 0.108309
tensor(0.1217, device='cuda:0') tensor(0.0928, device='cuda:0') tensor(-1.0142e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.097054
Average KL loss: 0.011513
Average total loss: 0.108567
tensor(0.1217, device='cuda:0') tensor(0.0929, device='cuda:0') tensor(-9.8372e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.094863
Average KL loss: 0.011521
Average total loss: 0.106385
tensor(0.1217, device='cuda:0') tensor(0.0930, device='cuda:0') tensor(-1.1460e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.096863
Average KL loss: 0.011530
Average total loss: 0.108392
tensor(0.1216, device='cuda:0') tensor(0.0932, device='cuda:0') tensor(-1.1640e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.097072
Average KL loss: 0.011538
Average total loss: 0.108610
tensor(0.1216, device='cuda:0') tensor(0.0933, device='cuda:0') tensor(-1.2353e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.093438
Average KL loss: 0.011547
Average total loss: 0.104984
tensor(0.1216, device='cuda:0') tensor(0.0935, device='cuda:0') tensor(-1.1871e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.095248
Average KL loss: 0.011554
Average total loss: 0.106802
tensor(0.1215, device='cuda:0') tensor(0.0936, device='cuda:0') tensor(-1.0906e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.096839
Average KL loss: 0.011562
Average total loss: 0.108401
tensor(0.1215, device='cuda:0') tensor(0.0937, device='cuda:0') tensor(-9.6855e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.095942
Average KL loss: 0.011571
Average total loss: 0.107513
tensor(0.1215, device='cuda:0') tensor(0.0939, device='cuda:0') tensor(-1.1417e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.100073
Average KL loss: 0.011579
Average total loss: 0.111652
tensor(0.1215, device='cuda:0') tensor(0.0940, device='cuda:0') tensor(-1.2660e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.095850
Average KL loss: 0.011588
Average total loss: 0.107438
tensor(0.1214, device='cuda:0') tensor(0.0942, device='cuda:0') tensor(-1.0768e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.092977
Average KL loss: 0.011596
Average total loss: 0.104573
tensor(0.1214, device='cuda:0') tensor(0.0943, device='cuda:0') tensor(-1.8163e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.090058
Average KL loss: 0.011605
Average total loss: 0.101663
tensor(0.1214, device='cuda:0') tensor(0.0944, device='cuda:0') tensor(-1.3379e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.088701
Average KL loss: 0.011612
Average total loss: 0.100312
tensor(0.1213, device='cuda:0') tensor(0.0946, device='cuda:0') tensor(-9.8216e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.094577
Average KL loss: 0.011619
Average total loss: 0.106196
tensor(0.1213, device='cuda:0') tensor(0.0947, device='cuda:0') tensor(-1.0677e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.086607
Average KL loss: 0.011626
Average total loss: 0.098233
tensor(0.1213, device='cuda:0') tensor(0.0948, device='cuda:0') tensor(-1.5671e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.089778
Average KL loss: 0.011633
Average total loss: 0.101411
tensor(0.1212, device='cuda:0') tensor(0.0949, device='cuda:0') tensor(-1.1545e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.086794
Average KL loss: 0.011640
Average total loss: 0.098434
tensor(0.1212, device='cuda:0') tensor(0.0951, device='cuda:0') tensor(-1.1089e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.093223
Average KL loss: 0.011649
Average total loss: 0.104872
tensor(0.1212, device='cuda:0') tensor(0.0952, device='cuda:0') tensor(-1.2081e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.089203
Average KL loss: 0.011657
Average total loss: 0.100861
tensor(0.1211, device='cuda:0') tensor(0.0954, device='cuda:0') tensor(-9.6767e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.091560
Average KL loss: 0.011664
Average total loss: 0.103224
tensor(0.1211, device='cuda:0') tensor(0.0955, device='cuda:0') tensor(-1.0706e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.088217
Average KL loss: 0.011672
Average total loss: 0.099889
tensor(0.1211, device='cuda:0') tensor(0.0956, device='cuda:0') tensor(-1.1287e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.085579
Average KL loss: 0.011681
Average total loss: 0.097260
tensor(0.1211, device='cuda:0') tensor(0.0958, device='cuda:0') tensor(-1.0656e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.081299
Average KL loss: 0.011688
Average total loss: 0.092987
tensor(0.1210, device='cuda:0') tensor(0.0959, device='cuda:0') tensor(-6.9741e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.088237
Average KL loss: 0.011694
Average total loss: 0.099931
tensor(0.1210, device='cuda:0') tensor(0.0960, device='cuda:0') tensor(-1.5548e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.085317
Average KL loss: 0.011702
Average total loss: 0.097019
tensor(0.1210, device='cuda:0') tensor(0.0961, device='cuda:0') tensor(-9.8885e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.091137
Average KL loss: 0.011711
Average total loss: 0.102848
tensor(0.1209, device='cuda:0') tensor(0.0963, device='cuda:0') tensor(-1.2395e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.088393
Average KL loss: 0.011719
Average total loss: 0.100112
tensor(0.1209, device='cuda:0') tensor(0.0964, device='cuda:0') tensor(-1.0463e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.081449
Average KL loss: 0.011727
Average total loss: 0.093177
tensor(0.1209, device='cuda:0') tensor(0.0966, device='cuda:0') tensor(-1.0319e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.083803
Average KL loss: 0.011735
Average total loss: 0.095538
tensor(0.1209, device='cuda:0') tensor(0.0967, device='cuda:0') tensor(-1.3482e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.084809
Average KL loss: 0.011741
Average total loss: 0.096550
tensor(0.1208, device='cuda:0') tensor(0.0968, device='cuda:0') tensor(-7.1722e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.083299
Average KL loss: 0.011749
Average total loss: 0.095047
tensor(0.1208, device='cuda:0') tensor(0.0969, device='cuda:0') tensor(-1.1446e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.087497
Average KL loss: 0.011757
Average total loss: 0.099254
tensor(0.1208, device='cuda:0') tensor(0.0971, device='cuda:0') tensor(-9.5884e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.082492
Average KL loss: 0.011764
Average total loss: 0.094256
tensor(0.1208, device='cuda:0') tensor(0.0972, device='cuda:0') tensor(-1.0551e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.080485
Average KL loss: 0.011772
Average total loss: 0.092257
tensor(0.1207, device='cuda:0') tensor(0.0973, device='cuda:0') tensor(-9.3285e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.077405
Average KL loss: 0.011779
Average total loss: 0.089184
tensor(0.1207, device='cuda:0') tensor(0.0975, device='cuda:0') tensor(-1.0825e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.080811
Average KL loss: 0.011786
Average total loss: 0.092597
tensor(0.1207, device='cuda:0') tensor(0.0976, device='cuda:0') tensor(-9.8985e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.078222
Average KL loss: 0.011793
Average total loss: 0.090014
tensor(0.1206, device='cuda:0') tensor(0.0977, device='cuda:0') tensor(-9.1668e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.079066
Average KL loss: 0.011799
Average total loss: 0.090865
tensor(0.1206, device='cuda:0') tensor(0.0978, device='cuda:0') tensor(-6.2842e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.075364
Average KL loss: 0.011804
Average total loss: 0.087167
tensor(0.1206, device='cuda:0') tensor(0.0979, device='cuda:0') tensor(-1.3476e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.082770
Average KL loss: 0.011810
Average total loss: 0.094580
tensor(0.1205, device='cuda:0') tensor(0.0981, device='cuda:0') tensor(-9.2280e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.081887
Average KL loss: 0.011818
Average total loss: 0.093705
tensor(0.1205, device='cuda:0') tensor(0.0982, device='cuda:0') tensor(-8.9742e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.078543
Average KL loss: 0.011826
Average total loss: 0.090369
tensor(0.1205, device='cuda:0') tensor(0.0983, device='cuda:0') tensor(-8.4089e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.078221
Average KL loss: 0.011832
Average total loss: 0.090053
tensor(0.1205, device='cuda:0') tensor(0.0985, device='cuda:0') tensor(-9.0148e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.079424
Average KL loss: 0.011840
Average total loss: 0.091264
tensor(0.1204, device='cuda:0') tensor(0.0986, device='cuda:0') tensor(-9.2198e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.074782
Average KL loss: 0.011846
Average total loss: 0.086628
tensor(0.1204, device='cuda:0') tensor(0.0987, device='cuda:0') tensor(-9.8604e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.075761
Average KL loss: 0.011852
Average total loss: 0.087613
tensor(0.1204, device='cuda:0') tensor(0.0988, device='cuda:0') tensor(-6.5186e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.080373
Average KL loss: 0.011859
Average total loss: 0.092231
tensor(0.1203, device='cuda:0') tensor(0.0990, device='cuda:0') tensor(-8.0494e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.078755
Average KL loss: 0.011865
Average total loss: 0.090620
tensor(0.1203, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-9.4709e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.072471
Average KL loss: 0.011872
Average total loss: 0.084343
tensor(0.1203, device='cuda:0') tensor(0.0992, device='cuda:0') tensor(-8.0671e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.074442
Average KL loss: 0.011878
Average total loss: 0.086320
tensor(0.1202, device='cuda:0') tensor(0.0993, device='cuda:0') tensor(-9.2131e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.076527
Average KL loss: 0.011885
Average total loss: 0.088412
tensor(0.1202, device='cuda:0') tensor(0.0995, device='cuda:0') tensor(-8.4802e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.075852
Average KL loss: 0.011891
Average total loss: 0.087744
tensor(0.1202, device='cuda:0') tensor(0.0996, device='cuda:0') tensor(-1.0138e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.075680
Average KL loss: 0.011898
Average total loss: 0.087578
tensor(0.1201, device='cuda:0') tensor(0.0997, device='cuda:0') tensor(-1.5068e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.079255
Average KL loss: 0.011905
Average total loss: 0.091159
tensor(0.1201, device='cuda:0') tensor(0.0998, device='cuda:0') tensor(-5.3512e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.076836
Average KL loss: 0.011911
Average total loss: 0.088747
tensor(0.1201, device='cuda:0') tensor(0.1000, device='cuda:0') tensor(-9.5887e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.073473
Average KL loss: 0.011918
Average total loss: 0.085390
tensor(0.1201, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-8.2312e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.070118
Average KL loss: 0.011924
Average total loss: 0.082042
tensor(0.1200, device='cuda:0') tensor(0.1002, device='cuda:0') tensor(-8.2800e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.072124
Average KL loss: 0.011929
Average total loss: 0.084053
tensor(0.1200, device='cuda:0') tensor(0.1003, device='cuda:0') tensor(-8.8530e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.071206
Average KL loss: 0.011935
Average total loss: 0.083140
tensor(0.1200, device='cuda:0') tensor(0.1004, device='cuda:0') tensor(-5.1496e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.073068
Average KL loss: 0.011941
Average total loss: 0.085009
tensor(0.1199, device='cuda:0') tensor(0.1005, device='cuda:0') tensor(-6.5443e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.069517
Average KL loss: 0.011946
Average total loss: 0.081462
tensor(0.1199, device='cuda:0') tensor(0.1007, device='cuda:0') tensor(-1.0254e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.073138
Average KL loss: 0.011952
Average total loss: 0.085090
tensor(0.1199, device='cuda:0') tensor(0.1008, device='cuda:0') tensor(-1.0745e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.070629
Average KL loss: 0.011958
Average total loss: 0.082587
tensor(0.1198, device='cuda:0') tensor(0.1009, device='cuda:0') tensor(-8.3272e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.072894
Average KL loss: 0.011965
Average total loss: 0.084859
tensor(0.1198, device='cuda:0') tensor(0.1010, device='cuda:0') tensor(-9.5740e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.074676
Average KL loss: 0.011972
Average total loss: 0.086648
tensor(0.1198, device='cuda:0') tensor(0.1012, device='cuda:0') tensor(-6.3270e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.071322
Average KL loss: 0.011978
Average total loss: 0.083300
tensor(0.1198, device='cuda:0') tensor(0.1013, device='cuda:0') tensor(-6.8755e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.070273
Average KL loss: 0.011985
Average total loss: 0.082259
tensor(0.1197, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-9.6758e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.069170
Average KL loss: 0.011991
Average total loss: 0.081161
tensor(0.1197, device='cuda:0') tensor(0.1015, device='cuda:0') tensor(-6.6783e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.070394
Average KL loss: 0.011996
Average total loss: 0.082391
tensor(0.1196, device='cuda:0') tensor(0.1016, device='cuda:0') tensor(-6.8299e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.069005
Average KL loss: 0.012002
Average total loss: 0.081008
tensor(0.1196, device='cuda:0') tensor(0.1018, device='cuda:0') tensor(-8.1145e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.068429
Average KL loss: 0.012008
Average total loss: 0.080438
tensor(0.1196, device='cuda:0') tensor(0.1019, device='cuda:0') tensor(-8.4744e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.074075
Average KL loss: 0.012014
Average total loss: 0.086089
tensor(0.1196, device='cuda:0') tensor(0.1020, device='cuda:0') tensor(-7.3131e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.068505
Average KL loss: 0.012020
Average total loss: 0.080525
tensor(0.1195, device='cuda:0') tensor(0.1021, device='cuda:0') tensor(-7.7683e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.066277
Average KL loss: 0.012025
Average total loss: 0.078302
tensor(0.1195, device='cuda:0') tensor(0.1022, device='cuda:0') tensor(-6.8417e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.070807
Average KL loss: 0.012031
Average total loss: 0.082838
tensor(0.1195, device='cuda:0') tensor(0.1023, device='cuda:0') tensor(-7.3252e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.067728
Average KL loss: 0.012037
Average total loss: 0.079766
tensor(0.1194, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-1.1173e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.068613
Average KL loss: 0.012044
Average total loss: 0.080656
tensor(0.1194, device='cuda:0') tensor(0.1026, device='cuda:0') tensor(-7.7550e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.066220
Average KL loss: 0.012048
Average total loss: 0.078268
tensor(0.1194, device='cuda:0') tensor(0.1027, device='cuda:0') tensor(-6.8228e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.064450
Average KL loss: 0.012052
Average total loss: 0.076503
tensor(0.1193, device='cuda:0') tensor(0.1028, device='cuda:0') tensor(-9.7063e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.069987
Average KL loss: 0.012058
Average total loss: 0.082045
tensor(0.1193, device='cuda:0') tensor(0.1029, device='cuda:0') tensor(-1.0805e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.065979
Average KL loss: 0.012064
Average total loss: 0.078042
tensor(0.1193, device='cuda:0') tensor(0.1030, device='cuda:0') tensor(-5.8463e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.063669
Average KL loss: 0.012069
Average total loss: 0.075738
tensor(0.1192, device='cuda:0') tensor(0.1031, device='cuda:0') tensor(-7.0234e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.065594
Average KL loss: 0.012073
Average total loss: 0.077667
tensor(0.1192, device='cuda:0') tensor(0.1032, device='cuda:0') tensor(-6.5106e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.067334
Average KL loss: 0.012079
Average total loss: 0.079413
tensor(0.1192, device='cuda:0') tensor(0.1033, device='cuda:0') tensor(-6.9881e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.064459
Average KL loss: 0.012084
Average total loss: 0.076543
tensor(0.1191, device='cuda:0') tensor(0.1034, device='cuda:0') tensor(-6.3538e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.065783
Average KL loss: 0.012089
Average total loss: 0.077872
tensor(0.1191, device='cuda:0') tensor(0.1036, device='cuda:0') tensor(-9.1019e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.065077
Average KL loss: 0.012094
Average total loss: 0.077172
tensor(0.1191, device='cuda:0') tensor(0.1037, device='cuda:0') tensor(-8.4037e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.063186
Average KL loss: 0.012098
Average total loss: 0.075284
tensor(0.1190, device='cuda:0') tensor(0.1038, device='cuda:0') tensor(-7.6725e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.065500
Average KL loss: 0.012104
Average total loss: 0.077604
tensor(0.1190, device='cuda:0') tensor(0.1039, device='cuda:0') tensor(-7.3707e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.066604
Average KL loss: 0.012110
Average total loss: 0.078714
tensor(0.1190, device='cuda:0') tensor(0.1040, device='cuda:0') tensor(-7.3882e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.062890
Average KL loss: 0.012116
Average total loss: 0.075006
tensor(0.1189, device='cuda:0') tensor(0.1041, device='cuda:0') tensor(-1.0269e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.061803
Average KL loss: 0.012121
Average total loss: 0.073925
tensor(0.1189, device='cuda:0') tensor(0.1042, device='cuda:0') tensor(-6.6168e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.062641
Average KL loss: 0.012127
Average total loss: 0.074767
tensor(0.1189, device='cuda:0') tensor(0.1043, device='cuda:0') tensor(-6.6762e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.060499
Average KL loss: 0.012132
Average total loss: 0.072631
tensor(0.1188, device='cuda:0') tensor(0.1045, device='cuda:0') tensor(-7.7376e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.060293
Average KL loss: 0.012135
Average total loss: 0.072429
tensor(0.1188, device='cuda:0') tensor(0.1045, device='cuda:0') tensor(-5.2193e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.061686
Average KL loss: 0.012139
Average total loss: 0.073826
tensor(0.1188, device='cuda:0') tensor(0.1047, device='cuda:0') tensor(-7.7280e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.063232
Average KL loss: 0.012144
Average total loss: 0.075376
tensor(0.1187, device='cuda:0') tensor(0.1048, device='cuda:0') tensor(-5.1801e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.063786
Average KL loss: 0.012149
Average total loss: 0.075935
tensor(0.1187, device='cuda:0') tensor(0.1049, device='cuda:0') tensor(-8.1989e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.061564
Average KL loss: 0.012154
Average total loss: 0.073718
tensor(0.1187, device='cuda:0') tensor(0.1050, device='cuda:0') tensor(-6.2145e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.062030
Average KL loss: 0.012158
Average total loss: 0.074189
tensor(0.1186, device='cuda:0') tensor(0.1051, device='cuda:0') tensor(-4.3615e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.061504
Average KL loss: 0.012163
Average total loss: 0.073667
tensor(0.1186, device='cuda:0') tensor(0.1052, device='cuda:0') tensor(-6.3219e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.060646
Average KL loss: 0.012168
Average total loss: 0.072814
tensor(0.1186, device='cuda:0') tensor(0.1053, device='cuda:0') tensor(-1.7136e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.062314
Average KL loss: 0.012172
Average total loss: 0.074485
tensor(0.1185, device='cuda:0') tensor(0.1054, device='cuda:0') tensor(-6.4554e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.058986
Average KL loss: 0.012176
Average total loss: 0.071162
tensor(0.1185, device='cuda:0') tensor(0.1055, device='cuda:0') tensor(-4.8405e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.057953
Average KL loss: 0.012179
Average total loss: 0.070132
tensor(0.1184, device='cuda:0') tensor(0.1056, device='cuda:0') tensor(-6.9566e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.060771
Average KL loss: 0.012182
Average total loss: 0.072953
tensor(0.1184, device='cuda:0') tensor(0.1057, device='cuda:0') tensor(-9.0231e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.059599
Average KL loss: 0.012187
Average total loss: 0.071786
tensor(0.1184, device='cuda:0') tensor(0.1058, device='cuda:0') tensor(-6.3603e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.058069
Average KL loss: 0.012191
Average total loss: 0.070260
tensor(0.1183, device='cuda:0') tensor(0.1059, device='cuda:0') tensor(-6.3007e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.061812
Average KL loss: 0.012195
Average total loss: 0.074006
tensor(0.1183, device='cuda:0') tensor(0.1060, device='cuda:0') tensor(-9.0963e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.058661
Average KL loss: 0.012200
Average total loss: 0.070861
tensor(0.1183, device='cuda:0') tensor(0.1061, device='cuda:0') tensor(-5.9442e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.058122
Average KL loss: 0.012204
Average total loss: 0.070325
tensor(0.1182, device='cuda:0') tensor(0.1062, device='cuda:0') tensor(-6.7456e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.056676
Average KL loss: 0.012208
Average total loss: 0.068884
tensor(0.1182, device='cuda:0') tensor(0.1063, device='cuda:0') tensor(-6.0136e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.057630
Average KL loss: 0.012211
Average total loss: 0.069841
tensor(0.1181, device='cuda:0') tensor(0.1064, device='cuda:0') tensor(-6.2306e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.057108
Average KL loss: 0.012214
Average total loss: 0.069322
tensor(0.1181, device='cuda:0') tensor(0.1065, device='cuda:0') tensor(-8.2980e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.058682
Average KL loss: 0.012219
Average total loss: 0.070900
tensor(0.1181, device='cuda:0') tensor(0.1066, device='cuda:0') tensor(-6.3303e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.058539
Average KL loss: 0.012223
Average total loss: 0.070762
tensor(0.1180, device='cuda:0') tensor(0.1067, device='cuda:0') tensor(-6.8773e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.054688
Average KL loss: 0.012227
Average total loss: 0.066915
tensor(0.1180, device='cuda:0') tensor(0.1068, device='cuda:0') tensor(-1.0073e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.056071
Average KL loss: 0.012230
Average total loss: 0.068301
tensor(0.1179, device='cuda:0') tensor(0.1069, device='cuda:0') tensor(-4.3993e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.055796
Average KL loss: 0.012233
Average total loss: 0.068029
tensor(0.1179, device='cuda:0') tensor(0.1070, device='cuda:0') tensor(-5.5921e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.056305
Average KL loss: 0.012236
Average total loss: 0.068541
tensor(0.1178, device='cuda:0') tensor(0.1071, device='cuda:0') tensor(-7.3832e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.056164
Average KL loss: 0.012240
Average total loss: 0.068404
tensor(0.1178, device='cuda:0') tensor(0.1072, device='cuda:0') tensor(-5.4841e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.054493
Average KL loss: 0.012244
Average total loss: 0.066737
tensor(0.1178, device='cuda:0') tensor(0.1073, device='cuda:0') tensor(-6.4077e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.053383
Average KL loss: 0.012246
Average total loss: 0.065629
tensor(0.1177, device='cuda:0') tensor(0.1074, device='cuda:0') tensor(-4.0015e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.056639
Average KL loss: 0.012249
Average total loss: 0.068888
tensor(0.1177, device='cuda:0') tensor(0.1075, device='cuda:0') tensor(-7.7875e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.057902
Average KL loss: 0.012253
Average total loss: 0.070155
tensor(0.1176, device='cuda:0') tensor(0.1076, device='cuda:0') tensor(-8.2724e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.059903
Average KL loss: 0.012258
Average total loss: 0.072161
tensor(0.1176, device='cuda:0') tensor(0.1077, device='cuda:0') tensor(-3.6219e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.055699
Average KL loss: 0.012262
Average total loss: 0.067961
tensor(0.1176, device='cuda:0') tensor(0.1078, device='cuda:0') tensor(-5.1920e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.054423
Average KL loss: 0.012265
Average total loss: 0.066688
tensor(0.1175, device='cuda:0') tensor(0.1079, device='cuda:0') tensor(-4.0826e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.053229
Average KL loss: 0.012268
Average total loss: 0.065498
tensor(0.1175, device='cuda:0') tensor(0.1080, device='cuda:0') tensor(-6.2273e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.053633
Average KL loss: 0.012271
Average total loss: 0.065903
tensor(0.1175, device='cuda:0') tensor(0.1080, device='cuda:0') tensor(-1.3512e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.055558
Average KL loss: 0.012274
Average total loss: 0.067832
tensor(0.1174, device='cuda:0') tensor(0.1081, device='cuda:0') tensor(-6.6794e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.054232
Average KL loss: 0.012278
Average total loss: 0.066511
 Percentile value: 5.530129874387057e-06
Non-zero model percentage: 51.200008392333984%, Non-zero mask percentage: 51.200008392333984%

--- Pruning Level [3/24]: ---
conv1.weight         | nonzeros =    1118 /    1728             ( 64.70%) | total_pruned =     610 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
bn1.weight           | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
bn1.bias             | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   26837 /   36864             ( 72.80%) | total_pruned =   10027 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   19130 /   36864             ( 51.89%) | total_pruned =   17734 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   17614 /   36864             ( 47.78%) | total_pruned =   19250 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   17848 /   36864             ( 48.42%) | total_pruned =   19016 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   34412 /   73728             ( 46.67%) | total_pruned =   39316 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   68915 /  147456             ( 46.74%) | total_pruned =   78541 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4297 /    8192             ( 52.45%) | total_pruned =    3895 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   64358 /  147456             ( 43.65%) | total_pruned =   83098 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   66964 /  147456             ( 45.41%) | total_pruned =   80492 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  135069 /  294912             ( 45.80%) | total_pruned =  159843 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     185 /     256             ( 72.27%) | total_pruned =      71 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  260208 /  589824             ( 44.12%) | total_pruned =  329616 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     181 /     256             ( 70.70%) | total_pruned =      75 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      39 /     256             ( 15.23%) | total_pruned =     217 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   16380 /   32768             ( 49.99%) | total_pruned =   16388 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      34 /     256             ( 13.28%) | total_pruned =     222 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  237771 /  589824             ( 40.31%) | total_pruned =  352053 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  226399 /  589824             ( 38.38%) | total_pruned =  363425 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     185 /     256             ( 72.27%) | total_pruned =      71 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  497317 / 1179648             ( 42.16%) | total_pruned =  682331 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     388 /     512             ( 75.78%) | total_pruned =     124 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      67 /     512             ( 13.09%) | total_pruned =     445 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1014392 / 2359296             ( 43.00%) | total_pruned = 1344904 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     501 /     512             ( 97.85%) | total_pruned =      11 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     311 /     512             ( 60.74%) | total_pruned =     201 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   54692 /  131072             ( 41.73%) | total_pruned =   76380 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     384 /     512             ( 75.00%) | total_pruned =     128 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     486 /     512             ( 94.92%) | total_pruned =      26 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     305 /     512             ( 59.57%) | total_pruned =     207 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1128101 / 2359296             ( 47.82%) | total_pruned = 1231195 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     378 /     512             ( 73.83%) | total_pruned =     134 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      25 /     512             (  4.88%) | total_pruned =     487 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1817024 / 2359296             ( 77.02%) | total_pruned =  542272 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     389 /     512             ( 75.98%) | total_pruned =     123 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
linear.weight        | nonzeros =    4900 /    5120             ( 95.70%) | total_pruned =     220 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 5723527, pruned : 5455235, total: 11178762, Compression rate :       1.95x  ( 48.80% pruned)
Train Epoch: 40/100 Loss: 0.020593 Accuracy: 87.89 100.00 % Best test Accuracy: 87.89%
tensor(0.1174, device='cuda:0') tensor(0.1082, device='cuda:0') tensor(-4.1671e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.202570
Average KL loss: 0.012218
Average total loss: 0.214788
tensor(0.1172, device='cuda:0') tensor(0.1072, device='cuda:0') tensor(-2.7034e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.199318
Average KL loss: 0.012140
Average total loss: 0.211458
tensor(0.1172, device='cuda:0') tensor(0.1066, device='cuda:0') tensor(-3.0562e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.202971
Average KL loss: 0.012074
Average total loss: 0.215046
tensor(0.1172, device='cuda:0') tensor(0.1061, device='cuda:0') tensor(-2.6085e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.185885
Average KL loss: 0.012015
Average total loss: 0.197900
tensor(0.1172, device='cuda:0') tensor(0.1056, device='cuda:0') tensor(-2.3487e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.184367
Average KL loss: 0.011961
Average total loss: 0.196327
tensor(0.1172, device='cuda:0') tensor(0.1051, device='cuda:0') tensor(-2.1919e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.183177
Average KL loss: 0.011911
Average total loss: 0.195088
tensor(0.1172, device='cuda:0') tensor(0.1047, device='cuda:0') tensor(-2.3443e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.178296
Average KL loss: 0.011865
Average total loss: 0.190162
tensor(0.1172, device='cuda:0') tensor(0.1043, device='cuda:0') tensor(-2.7533e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.180845
Average KL loss: 0.011824
Average total loss: 0.192669
tensor(0.1171, device='cuda:0') tensor(0.1040, device='cuda:0') tensor(-2.3947e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.171666
Average KL loss: 0.011785
Average total loss: 0.183451
tensor(0.1170, device='cuda:0') tensor(0.1037, device='cuda:0') tensor(-2.0942e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.177963
Average KL loss: 0.011750
Average total loss: 0.189713
tensor(0.1170, device='cuda:0') tensor(0.1034, device='cuda:0') tensor(-2.1593e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.174958
Average KL loss: 0.011718
Average total loss: 0.186676
tensor(0.1169, device='cuda:0') tensor(0.1032, device='cuda:0') tensor(-2.6752e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.177431
Average KL loss: 0.011688
Average total loss: 0.189118
tensor(0.1168, device='cuda:0') tensor(0.1030, device='cuda:0') tensor(-3.2984e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.176871
Average KL loss: 0.011660
Average total loss: 0.188531
tensor(0.1168, device='cuda:0') tensor(0.1027, device='cuda:0') tensor(-2.1779e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.171709
Average KL loss: 0.011635
Average total loss: 0.183344
tensor(0.1167, device='cuda:0') tensor(0.1026, device='cuda:0') tensor(-1.8300e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.166780
Average KL loss: 0.011611
Average total loss: 0.178391
tensor(0.1166, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-2.1594e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.164593
Average KL loss: 0.011589
Average total loss: 0.176182
tensor(0.1165, device='cuda:0') tensor(0.1022, device='cuda:0') tensor(-2.4111e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.155441
Average KL loss: 0.011569
Average total loss: 0.167010
tensor(0.1164, device='cuda:0') tensor(0.1021, device='cuda:0') tensor(-2.2272e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.155207
Average KL loss: 0.011550
Average total loss: 0.166757
tensor(0.1163, device='cuda:0') tensor(0.1020, device='cuda:0') tensor(-2.5224e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.167873
Average KL loss: 0.011533
Average total loss: 0.179406
tensor(0.1162, device='cuda:0') tensor(0.1019, device='cuda:0') tensor(-2.8043e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.152320
Average KL loss: 0.011517
Average total loss: 0.163837
tensor(0.1161, device='cuda:0') tensor(0.1018, device='cuda:0') tensor(-1.9976e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.155943
Average KL loss: 0.011502
Average total loss: 0.167446
tensor(0.1160, device='cuda:0') tensor(0.1017, device='cuda:0') tensor(-2.6924e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.153351
Average KL loss: 0.011489
Average total loss: 0.164840
tensor(0.1159, device='cuda:0') tensor(0.1016, device='cuda:0') tensor(-1.9034e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.153701
Average KL loss: 0.011477
Average total loss: 0.165179
tensor(0.1158, device='cuda:0') tensor(0.1015, device='cuda:0') tensor(-1.9422e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.149877
Average KL loss: 0.011466
Average total loss: 0.161343
tensor(0.1157, device='cuda:0') tensor(0.1015, device='cuda:0') tensor(-2.1130e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.152197
Average KL loss: 0.011457
Average total loss: 0.163654
tensor(0.1156, device='cuda:0') tensor(0.1015, device='cuda:0') tensor(-1.9664e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.152575
Average KL loss: 0.011448
Average total loss: 0.164024
tensor(0.1155, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-1.8206e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.150190
Average KL loss: 0.011440
Average total loss: 0.161630
tensor(0.1154, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-1.8797e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.153854
Average KL loss: 0.011433
Average total loss: 0.165287
tensor(0.1153, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-1.5540e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.149026
Average KL loss: 0.011427
Average total loss: 0.160454
tensor(0.1153, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-1.7841e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.146850
Average KL loss: 0.011422
Average total loss: 0.158272
tensor(0.1152, device='cuda:0') tensor(0.1013, device='cuda:0') tensor(-1.8254e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.148638
Average KL loss: 0.011417
Average total loss: 0.160055
tensor(0.1151, device='cuda:0') tensor(0.1013, device='cuda:0') tensor(-1.9821e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.141049
Average KL loss: 0.011413
Average total loss: 0.152462
tensor(0.1150, device='cuda:0') tensor(0.1013, device='cuda:0') tensor(-1.5281e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.145790
Average KL loss: 0.011408
Average total loss: 0.157198
tensor(0.1149, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-1.7599e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.142858
Average KL loss: 0.011404
Average total loss: 0.154263
tensor(0.1149, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-1.4169e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.142904
Average KL loss: 0.011402
Average total loss: 0.154305
tensor(0.1148, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-1.6853e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.147223
Average KL loss: 0.011400
Average total loss: 0.158622
tensor(0.1147, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-2.4178e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.136452
Average KL loss: 0.011398
Average total loss: 0.147850
tensor(0.1146, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-2.0979e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.143862
Average KL loss: 0.011396
Average total loss: 0.155258
tensor(0.1146, device='cuda:0') tensor(0.1015, device='cuda:0') tensor(-1.4752e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.135387
Average KL loss: 0.011395
Average total loss: 0.146781
tensor(0.1145, device='cuda:0') tensor(0.1015, device='cuda:0') tensor(-1.7499e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.139846
Average KL loss: 0.011394
Average total loss: 0.151240
tensor(0.1144, device='cuda:0') tensor(0.1015, device='cuda:0') tensor(-1.6560e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.137248
Average KL loss: 0.011394
Average total loss: 0.148642
tensor(0.1144, device='cuda:0') tensor(0.1016, device='cuda:0') tensor(-1.4510e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.136999
Average KL loss: 0.011395
Average total loss: 0.148394
tensor(0.1143, device='cuda:0') tensor(0.1016, device='cuda:0') tensor(-1.6502e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.131387
Average KL loss: 0.011396
Average total loss: 0.142784
tensor(0.1143, device='cuda:0') tensor(0.1017, device='cuda:0') tensor(-1.7816e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.132725
Average KL loss: 0.011398
Average total loss: 0.144123
tensor(0.1142, device='cuda:0') tensor(0.1017, device='cuda:0') tensor(-1.6663e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.135035
Average KL loss: 0.011399
Average total loss: 0.146435
tensor(0.1142, device='cuda:0') tensor(0.1018, device='cuda:0') tensor(-1.7152e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.128136
Average KL loss: 0.011401
Average total loss: 0.139537
tensor(0.1141, device='cuda:0') tensor(0.1018, device='cuda:0') tensor(-1.6291e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.125728
Average KL loss: 0.011402
Average total loss: 0.137130
tensor(0.1141, device='cuda:0') tensor(0.1019, device='cuda:0') tensor(-1.3279e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.130125
Average KL loss: 0.011402
Average total loss: 0.141527
tensor(0.1140, device='cuda:0') tensor(0.1019, device='cuda:0') tensor(-1.4440e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.128712
Average KL loss: 0.011404
Average total loss: 0.140116
tensor(0.1140, device='cuda:0') tensor(0.1020, device='cuda:0') tensor(-1.7940e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.132755
Average KL loss: 0.011407
Average total loss: 0.144161
tensor(0.1139, device='cuda:0') tensor(0.1021, device='cuda:0') tensor(-2.6026e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.129817
Average KL loss: 0.011411
Average total loss: 0.141228
tensor(0.1139, device='cuda:0') tensor(0.1021, device='cuda:0') tensor(-9.1538e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.128587
Average KL loss: 0.011413
Average total loss: 0.140000
tensor(0.1138, device='cuda:0') tensor(0.1022, device='cuda:0') tensor(-1.8605e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.130529
Average KL loss: 0.011417
Average total loss: 0.141946
tensor(0.1138, device='cuda:0') tensor(0.1023, device='cuda:0') tensor(-1.5126e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.128010
Average KL loss: 0.011420
Average total loss: 0.139430
tensor(0.1138, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-1.3175e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.124136
Average KL loss: 0.011424
Average total loss: 0.135560
tensor(0.1137, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-1.8526e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.123902
Average KL loss: 0.011428
Average total loss: 0.135330
tensor(0.1137, device='cuda:0') tensor(0.1025, device='cuda:0') tensor(-1.5698e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.131107
Average KL loss: 0.011433
Average total loss: 0.142540
tensor(0.1137, device='cuda:0') tensor(0.1026, device='cuda:0') tensor(-1.6342e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.122321
Average KL loss: 0.011437
Average total loss: 0.133758
tensor(0.1136, device='cuda:0') tensor(0.1027, device='cuda:0') tensor(-1.4389e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.121954
Average KL loss: 0.011441
Average total loss: 0.133395
tensor(0.1136, device='cuda:0') tensor(0.1027, device='cuda:0') tensor(-1.7753e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.124341
Average KL loss: 0.011445
Average total loss: 0.135785
tensor(0.1136, device='cuda:0') tensor(0.1028, device='cuda:0') tensor(-1.6155e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.116843
Average KL loss: 0.011450
Average total loss: 0.128293
tensor(0.1135, device='cuda:0') tensor(0.1029, device='cuda:0') tensor(-1.7732e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.117487
Average KL loss: 0.011454
Average total loss: 0.128941
tensor(0.1135, device='cuda:0') tensor(0.1030, device='cuda:0') tensor(-1.4607e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.119666
Average KL loss: 0.011459
Average total loss: 0.131125
tensor(0.1135, device='cuda:0') tensor(0.1031, device='cuda:0') tensor(-1.3539e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.115332
Average KL loss: 0.011464
Average total loss: 0.126796
tensor(0.1135, device='cuda:0') tensor(0.1032, device='cuda:0') tensor(-1.3095e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.118059
Average KL loss: 0.011469
Average total loss: 0.129528
tensor(0.1134, device='cuda:0') tensor(0.1033, device='cuda:0') tensor(-1.8239e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.116947
Average KL loss: 0.011474
Average total loss: 0.128422
tensor(0.1134, device='cuda:0') tensor(0.1033, device='cuda:0') tensor(-1.4859e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.116174
Average KL loss: 0.011480
Average total loss: 0.127653
tensor(0.1134, device='cuda:0') tensor(0.1034, device='cuda:0') tensor(-1.4453e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.114537
Average KL loss: 0.011485
Average total loss: 0.126022
tensor(0.1134, device='cuda:0') tensor(0.1035, device='cuda:0') tensor(-1.2193e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.114377
Average KL loss: 0.011490
Average total loss: 0.125867
tensor(0.1133, device='cuda:0') tensor(0.1036, device='cuda:0') tensor(-1.0380e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.111231
Average KL loss: 0.011496
Average total loss: 0.122727
tensor(0.1133, device='cuda:0') tensor(0.1037, device='cuda:0') tensor(-1.4604e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.117688
Average KL loss: 0.011501
Average total loss: 0.129189
tensor(0.1133, device='cuda:0') tensor(0.1038, device='cuda:0') tensor(-1.3782e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.114440
Average KL loss: 0.011507
Average total loss: 0.125947
tensor(0.1133, device='cuda:0') tensor(0.1039, device='cuda:0') tensor(-1.4168e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.109770
Average KL loss: 0.011512
Average total loss: 0.121282
tensor(0.1133, device='cuda:0') tensor(0.1040, device='cuda:0') tensor(-1.6042e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.117981
Average KL loss: 0.011518
Average total loss: 0.129499
tensor(0.1133, device='cuda:0') tensor(0.1041, device='cuda:0') tensor(-1.3212e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.111632
Average KL loss: 0.011525
Average total loss: 0.123157
tensor(0.1133, device='cuda:0') tensor(0.1042, device='cuda:0') tensor(-1.5819e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.112418
Average KL loss: 0.011531
Average total loss: 0.123949
tensor(0.1132, device='cuda:0') tensor(0.1043, device='cuda:0') tensor(-1.5914e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.116608
Average KL loss: 0.011537
Average total loss: 0.128145
tensor(0.1132, device='cuda:0') tensor(0.1044, device='cuda:0') tensor(-1.0505e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.112921
Average KL loss: 0.011543
Average total loss: 0.124463
tensor(0.1132, device='cuda:0') tensor(0.1045, device='cuda:0') tensor(-1.5392e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.110862
Average KL loss: 0.011549
Average total loss: 0.122411
tensor(0.1132, device='cuda:0') tensor(0.1046, device='cuda:0') tensor(-1.6118e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.108694
Average KL loss: 0.011556
Average total loss: 0.120251
tensor(0.1132, device='cuda:0') tensor(0.1047, device='cuda:0') tensor(-1.2570e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.109135
Average KL loss: 0.011563
Average total loss: 0.120698
tensor(0.1132, device='cuda:0') tensor(0.1048, device='cuda:0') tensor(-1.9426e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.110183
Average KL loss: 0.011571
Average total loss: 0.121754
tensor(0.1132, device='cuda:0') tensor(0.1049, device='cuda:0') tensor(-1.4895e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.108769
Average KL loss: 0.011578
Average total loss: 0.120347
tensor(0.1132, device='cuda:0') tensor(0.1050, device='cuda:0') tensor(-1.4950e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.113774
Average KL loss: 0.011584
Average total loss: 0.125358
tensor(0.1132, device='cuda:0') tensor(0.1051, device='cuda:0') tensor(-1.6109e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.106289
Average KL loss: 0.011591
Average total loss: 0.117880
tensor(0.1132, device='cuda:0') tensor(0.1052, device='cuda:0') tensor(-9.1902e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.110606
Average KL loss: 0.011597
Average total loss: 0.122203
tensor(0.1131, device='cuda:0') tensor(0.1053, device='cuda:0') tensor(-1.5622e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.109751
Average KL loss: 0.011604
Average total loss: 0.121355
tensor(0.1131, device='cuda:0') tensor(0.1054, device='cuda:0') tensor(-1.5039e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.106799
Average KL loss: 0.011610
Average total loss: 0.118408
tensor(0.1131, device='cuda:0') tensor(0.1055, device='cuda:0') tensor(-1.6023e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.102947
Average KL loss: 0.011616
Average total loss: 0.114563
tensor(0.1131, device='cuda:0') tensor(0.1056, device='cuda:0') tensor(-1.0927e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.103593
Average KL loss: 0.011622
Average total loss: 0.115215
tensor(0.1131, device='cuda:0') tensor(0.1057, device='cuda:0') tensor(-1.1097e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.105983
Average KL loss: 0.011628
Average total loss: 0.117611
tensor(0.1131, device='cuda:0') tensor(0.1058, device='cuda:0') tensor(-1.2416e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.105141
Average KL loss: 0.011635
Average total loss: 0.116776
tensor(0.1131, device='cuda:0') tensor(0.1059, device='cuda:0') tensor(-1.2536e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.099962
Average KL loss: 0.011642
Average total loss: 0.111604
tensor(0.1131, device='cuda:0') tensor(0.1060, device='cuda:0') tensor(-1.0831e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.102595
Average KL loss: 0.011648
Average total loss: 0.114242
tensor(0.1131, device='cuda:0') tensor(0.1061, device='cuda:0') tensor(-1.2473e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.103129
Average KL loss: 0.011655
Average total loss: 0.114784
tensor(0.1131, device='cuda:0') tensor(0.1062, device='cuda:0') tensor(-1.0872e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.105090
Average KL loss: 0.011661
Average total loss: 0.116751
tensor(0.1130, device='cuda:0') tensor(0.1063, device='cuda:0') tensor(-1.6055e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.099240
Average KL loss: 0.011668
Average total loss: 0.110907
tensor(0.1130, device='cuda:0') tensor(0.1064, device='cuda:0') tensor(-6.8312e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.099692
Average KL loss: 0.011673
Average total loss: 0.111365
tensor(0.1130, device='cuda:0') tensor(0.1065, device='cuda:0') tensor(-9.2221e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.099521
Average KL loss: 0.011680
Average total loss: 0.111200
tensor(0.1130, device='cuda:0') tensor(0.1066, device='cuda:0') tensor(-1.0262e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.097561
Average KL loss: 0.011686
Average total loss: 0.109247
tensor(0.1130, device='cuda:0') tensor(0.1067, device='cuda:0') tensor(-1.4525e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.100478
Average KL loss: 0.011693
Average total loss: 0.112170
tensor(0.1130, device='cuda:0') tensor(0.1068, device='cuda:0') tensor(-1.4780e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.102563
Average KL loss: 0.011699
Average total loss: 0.114262
tensor(0.1130, device='cuda:0') tensor(0.1069, device='cuda:0') tensor(-1.0155e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.095623
Average KL loss: 0.011706
Average total loss: 0.107330
tensor(0.1130, device='cuda:0') tensor(0.1070, device='cuda:0') tensor(-1.0761e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.096631
Average KL loss: 0.011713
Average total loss: 0.108344
tensor(0.1130, device='cuda:0') tensor(0.1071, device='cuda:0') tensor(-1.2283e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.093773
Average KL loss: 0.011719
Average total loss: 0.105492
tensor(0.1130, device='cuda:0') tensor(0.1072, device='cuda:0') tensor(-9.0694e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.095756
Average KL loss: 0.011725
Average total loss: 0.107481
tensor(0.1130, device='cuda:0') tensor(0.1073, device='cuda:0') tensor(-1.2948e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.102362
Average KL loss: 0.011731
Average total loss: 0.114094
tensor(0.1129, device='cuda:0') tensor(0.1074, device='cuda:0') tensor(-1.0433e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.098984
Average KL loss: 0.011739
Average total loss: 0.110723
tensor(0.1129, device='cuda:0') tensor(0.1075, device='cuda:0') tensor(-1.3623e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.094396
Average KL loss: 0.011745
Average total loss: 0.106142
tensor(0.1129, device='cuda:0') tensor(0.1076, device='cuda:0') tensor(-1.2698e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.094869
Average KL loss: 0.011752
Average total loss: 0.106621
tensor(0.1129, device='cuda:0') tensor(0.1077, device='cuda:0') tensor(-1.3748e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.099448
Average KL loss: 0.011758
Average total loss: 0.111206
tensor(0.1129, device='cuda:0') tensor(0.1078, device='cuda:0') tensor(-9.1297e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.090645
Average KL loss: 0.011765
Average total loss: 0.102410
tensor(0.1129, device='cuda:0') tensor(0.1079, device='cuda:0') tensor(-1.2306e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.094155
Average KL loss: 0.011772
Average total loss: 0.105927
tensor(0.1129, device='cuda:0') tensor(0.1080, device='cuda:0') tensor(-9.2035e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.098193
Average KL loss: 0.011780
Average total loss: 0.109973
tensor(0.1129, device='cuda:0') tensor(0.1082, device='cuda:0') tensor(-1.2692e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.095158
Average KL loss: 0.011787
Average total loss: 0.106945
tensor(0.1129, device='cuda:0') tensor(0.1083, device='cuda:0') tensor(-1.0075e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.092434
Average KL loss: 0.011794
Average total loss: 0.104228
tensor(0.1129, device='cuda:0') tensor(0.1084, device='cuda:0') tensor(-7.6530e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.090123
Average KL loss: 0.011801
Average total loss: 0.101923
tensor(0.1129, device='cuda:0') tensor(0.1085, device='cuda:0') tensor(-1.1464e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.094562
Average KL loss: 0.011806
Average total loss: 0.106368
tensor(0.1129, device='cuda:0') tensor(0.1086, device='cuda:0') tensor(-1.0048e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.090840
Average KL loss: 0.011812
Average total loss: 0.102652
tensor(0.1129, device='cuda:0') tensor(0.1087, device='cuda:0') tensor(-1.0176e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.090117
Average KL loss: 0.011819
Average total loss: 0.101937
tensor(0.1129, device='cuda:0') tensor(0.1088, device='cuda:0') tensor(-9.0471e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.094114
Average KL loss: 0.011824
Average total loss: 0.105939
tensor(0.1129, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-1.0217e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.089315
Average KL loss: 0.011831
Average total loss: 0.101146
tensor(0.1128, device='cuda:0') tensor(0.1090, device='cuda:0') tensor(-1.0979e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.089948
Average KL loss: 0.011836
Average total loss: 0.101784
tensor(0.1128, device='cuda:0') tensor(0.1091, device='cuda:0') tensor(-1.0021e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.087390
Average KL loss: 0.011842
Average total loss: 0.099232
tensor(0.1128, device='cuda:0') tensor(0.1092, device='cuda:0') tensor(-1.2354e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.087275
Average KL loss: 0.011848
Average total loss: 0.099123
tensor(0.1128, device='cuda:0') tensor(0.1093, device='cuda:0') tensor(-9.3356e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.089953
Average KL loss: 0.011855
Average total loss: 0.101808
tensor(0.1128, device='cuda:0') tensor(0.1094, device='cuda:0') tensor(-8.6281e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.090018
Average KL loss: 0.011862
Average total loss: 0.101880
tensor(0.1128, device='cuda:0') tensor(0.1095, device='cuda:0') tensor(-1.1307e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.086672
Average KL loss: 0.011869
Average total loss: 0.098540
tensor(0.1128, device='cuda:0') tensor(0.1096, device='cuda:0') tensor(-1.2339e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.088195
Average KL loss: 0.011875
Average total loss: 0.100070
tensor(0.1128, device='cuda:0') tensor(0.1097, device='cuda:0') tensor(-1.0460e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.085739
Average KL loss: 0.011881
Average total loss: 0.097620
tensor(0.1128, device='cuda:0') tensor(0.1098, device='cuda:0') tensor(-6.7801e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.085673
Average KL loss: 0.011887
Average total loss: 0.097560
tensor(0.1128, device='cuda:0') tensor(0.1099, device='cuda:0') tensor(-1.2200e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.082083
Average KL loss: 0.011893
Average total loss: 0.093976
tensor(0.1128, device='cuda:0') tensor(0.1100, device='cuda:0') tensor(-1.3374e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.085299
Average KL loss: 0.011899
Average total loss: 0.097198
tensor(0.1128, device='cuda:0') tensor(0.1101, device='cuda:0') tensor(-1.1487e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.085545
Average KL loss: 0.011904
Average total loss: 0.097450
tensor(0.1128, device='cuda:0') tensor(0.1102, device='cuda:0') tensor(-1.0778e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.087999
Average KL loss: 0.011911
Average total loss: 0.099909
tensor(0.1127, device='cuda:0') tensor(0.1103, device='cuda:0') tensor(-7.5278e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.084244
Average KL loss: 0.011917
Average total loss: 0.096160
tensor(0.1127, device='cuda:0') tensor(0.1104, device='cuda:0') tensor(-1.0633e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.082350
Average KL loss: 0.011923
Average total loss: 0.094272
tensor(0.1127, device='cuda:0') tensor(0.1105, device='cuda:0') tensor(-9.0664e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.081571
Average KL loss: 0.011928
Average total loss: 0.093500
tensor(0.1127, device='cuda:0') tensor(0.1106, device='cuda:0') tensor(-9.4760e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.085244
Average KL loss: 0.011934
Average total loss: 0.097178
tensor(0.1127, device='cuda:0') tensor(0.1107, device='cuda:0') tensor(-1.3993e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.083357
Average KL loss: 0.011941
Average total loss: 0.095297
tensor(0.1127, device='cuda:0') tensor(0.1108, device='cuda:0') tensor(-9.6622e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.081409
Average KL loss: 0.011947
Average total loss: 0.093356
tensor(0.1127, device='cuda:0') tensor(0.1109, device='cuda:0') tensor(-1.0039e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.085533
Average KL loss: 0.011953
Average total loss: 0.097486
tensor(0.1127, device='cuda:0') tensor(0.1110, device='cuda:0') tensor(-8.7167e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.085233
Average KL loss: 0.011960
Average total loss: 0.097193
tensor(0.1127, device='cuda:0') tensor(0.1111, device='cuda:0') tensor(-9.8770e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.080281
Average KL loss: 0.011966
Average total loss: 0.092247
tensor(0.1127, device='cuda:0') tensor(0.1112, device='cuda:0') tensor(-9.7611e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.082992
Average KL loss: 0.011972
Average total loss: 0.094964
tensor(0.1127, device='cuda:0') tensor(0.1113, device='cuda:0') tensor(-7.8815e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.083649
Average KL loss: 0.011978
Average total loss: 0.095626
tensor(0.1127, device='cuda:0') tensor(0.1114, device='cuda:0') tensor(-8.6160e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.085900
Average KL loss: 0.011984
Average total loss: 0.097883
tensor(0.1126, device='cuda:0') tensor(0.1115, device='cuda:0') tensor(-8.8462e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.082613
Average KL loss: 0.011991
Average total loss: 0.094604
tensor(0.1126, device='cuda:0') tensor(0.1116, device='cuda:0') tensor(-6.3170e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.079916
Average KL loss: 0.011997
Average total loss: 0.091913
tensor(0.1126, device='cuda:0') tensor(0.1117, device='cuda:0') tensor(-9.0912e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.078646
Average KL loss: 0.012003
Average total loss: 0.090649
tensor(0.1126, device='cuda:0') tensor(0.1118, device='cuda:0') tensor(-7.7933e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.082831
Average KL loss: 0.012009
Average total loss: 0.094840
tensor(0.1126, device='cuda:0') tensor(0.1119, device='cuda:0') tensor(-9.4304e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.079393
Average KL loss: 0.012015
Average total loss: 0.091407
tensor(0.1126, device='cuda:0') tensor(0.1120, device='cuda:0') tensor(-1.0492e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.079638
Average KL loss: 0.012021
Average total loss: 0.091659
tensor(0.1126, device='cuda:0') tensor(0.1121, device='cuda:0') tensor(-1.1787e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.079615
Average KL loss: 0.012027
Average total loss: 0.091642
tensor(0.1126, device='cuda:0') tensor(0.1122, device='cuda:0') tensor(-6.5402e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.078879
Average KL loss: 0.012033
Average total loss: 0.090912
tensor(0.1126, device='cuda:0') tensor(0.1123, device='cuda:0') tensor(-5.8437e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.076532
Average KL loss: 0.012038
Average total loss: 0.088571
tensor(0.1126, device='cuda:0') tensor(0.1124, device='cuda:0') tensor(-9.8504e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.079433
Average KL loss: 0.012044
Average total loss: 0.091478
tensor(0.1126, device='cuda:0') tensor(0.1125, device='cuda:0') tensor(-9.4486e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.077572
Average KL loss: 0.012050
Average total loss: 0.089622
tensor(0.1126, device='cuda:0') tensor(0.1126, device='cuda:0') tensor(-7.4276e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.081008
Average KL loss: 0.012055
Average total loss: 0.093063
tensor(0.1126, device='cuda:0') tensor(0.1127, device='cuda:0') tensor(-7.9598e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.076689
Average KL loss: 0.012062
Average total loss: 0.088750
tensor(0.1125, device='cuda:0') tensor(0.1129, device='cuda:0') tensor(-7.9886e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.080118
Average KL loss: 0.012067
Average total loss: 0.092185
tensor(0.1125, device='cuda:0') tensor(0.1130, device='cuda:0') tensor(-8.8038e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.077243
Average KL loss: 0.012074
Average total loss: 0.089317
tensor(0.1125, device='cuda:0') tensor(0.1131, device='cuda:0') tensor(-1.0383e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.077652
Average KL loss: 0.012080
Average total loss: 0.089733
tensor(0.1125, device='cuda:0') tensor(0.1132, device='cuda:0') tensor(-9.1305e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.079530
Average KL loss: 0.012086
Average total loss: 0.091616
tensor(0.1125, device='cuda:0') tensor(0.1133, device='cuda:0') tensor(-1.0718e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.080591
Average KL loss: 0.012093
Average total loss: 0.092684
tensor(0.1125, device='cuda:0') tensor(0.1134, device='cuda:0') tensor(-8.4771e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.076900
Average KL loss: 0.012099
Average total loss: 0.088999
tensor(0.1125, device='cuda:0') tensor(0.1135, device='cuda:0') tensor(-1.1653e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.076772
Average KL loss: 0.012105
Average total loss: 0.088877
tensor(0.1125, device='cuda:0') tensor(0.1136, device='cuda:0') tensor(-8.7904e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.080079
Average KL loss: 0.012109
Average total loss: 0.092188
tensor(0.1125, device='cuda:0') tensor(0.1136, device='cuda:0') tensor(-9.8101e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.074737
Average KL loss: 0.012109
Average total loss: 0.086846
tensor(0.1125, device='cuda:0') tensor(0.1136, device='cuda:0') tensor(-7.3295e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.074519
Average KL loss: 0.012110
Average total loss: 0.086629
tensor(0.1125, device='cuda:0') tensor(0.1136, device='cuda:0') tensor(-8.3847e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.077325
Average KL loss: 0.012110
Average total loss: 0.089435
tensor(0.1125, device='cuda:0') tensor(0.1136, device='cuda:0') tensor(-6.5721e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.076128
Average KL loss: 0.012111
Average total loss: 0.088238
tensor(0.1125, device='cuda:0') tensor(0.1136, device='cuda:0') tensor(-8.1267e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.077362
Average KL loss: 0.012111
Average total loss: 0.089474
tensor(0.1125, device='cuda:0') tensor(0.1136, device='cuda:0') tensor(-1.0724e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.077309
Average KL loss: 0.012112
Average total loss: 0.089421
tensor(0.1125, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-7.0659e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.075281
Average KL loss: 0.012112
Average total loss: 0.087394
tensor(0.1125, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-7.4397e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.075104
Average KL loss: 0.012113
Average total loss: 0.087217
tensor(0.1125, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-7.3665e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.075548
Average KL loss: 0.012113
Average total loss: 0.087662
tensor(0.1125, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-8.9205e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.076330
Average KL loss: 0.012114
Average total loss: 0.088443
tensor(0.1125, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-7.1303e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.073663
Average KL loss: 0.012114
Average total loss: 0.085777
tensor(0.1125, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-6.5381e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.073612
Average KL loss: 0.012114
Average total loss: 0.085727
tensor(0.1125, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-9.7810e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.076557
Average KL loss: 0.012115
Average total loss: 0.088672
tensor(0.1125, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-9.3856e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.075928
Average KL loss: 0.012116
Average total loss: 0.088043
tensor(0.1125, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-8.6967e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.076547
Average KL loss: 0.012116
Average total loss: 0.088663
tensor(0.1125, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-8.6743e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.075135
Average KL loss: 0.012117
Average total loss: 0.087252
tensor(0.1125, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-7.0085e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.073630
Average KL loss: 0.012117
Average total loss: 0.085747
tensor(0.1125, device='cuda:0') tensor(0.1138, device='cuda:0') tensor(-9.9997e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.075723
Average KL loss: 0.012118
Average total loss: 0.087840
tensor(0.1125, device='cuda:0') tensor(0.1138, device='cuda:0') tensor(-8.0232e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.075062
Average KL loss: 0.012118
Average total loss: 0.087180
tensor(0.1125, device='cuda:0') tensor(0.1138, device='cuda:0') tensor(-9.3840e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.075013
Average KL loss: 0.012118
Average total loss: 0.087131
tensor(0.1125, device='cuda:0') tensor(0.1138, device='cuda:0') tensor(-1.1225e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.075092
Average KL loss: 0.012119
Average total loss: 0.087211
tensor(0.1125, device='cuda:0') tensor(0.1138, device='cuda:0') tensor(-6.6606e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.073260
Average KL loss: 0.012119
Average total loss: 0.085379
tensor(0.1125, device='cuda:0') tensor(0.1138, device='cuda:0') tensor(-6.8538e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.073400
Average KL loss: 0.012120
Average total loss: 0.085520
tensor(0.1125, device='cuda:0') tensor(0.1138, device='cuda:0') tensor(-8.6975e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.073750
Average KL loss: 0.012120
Average total loss: 0.085870
tensor(0.1125, device='cuda:0') tensor(0.1138, device='cuda:0') tensor(-9.8668e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.076403
Average KL loss: 0.012121
Average total loss: 0.088524
tensor(0.1125, device='cuda:0') tensor(0.1138, device='cuda:0') tensor(-4.6274e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.075324
Average KL loss: 0.012121
Average total loss: 0.087445
tensor(0.1125, device='cuda:0') tensor(0.1138, device='cuda:0') tensor(-9.8162e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.075354
Average KL loss: 0.012122
Average total loss: 0.087476
tensor(0.1125, device='cuda:0') tensor(0.1139, device='cuda:0') tensor(-7.8210e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.073819
Average KL loss: 0.012122
Average total loss: 0.085941
tensor(0.1125, device='cuda:0') tensor(0.1139, device='cuda:0') tensor(-9.6550e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.072247
Average KL loss: 0.012123
Average total loss: 0.084369
tensor(0.1125, device='cuda:0') tensor(0.1139, device='cuda:0') tensor(-8.6873e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.073553
Average KL loss: 0.012123
Average total loss: 0.085676
tensor(0.1125, device='cuda:0') tensor(0.1139, device='cuda:0') tensor(-6.5953e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.071418
Average KL loss: 0.012124
Average total loss: 0.083542
tensor(0.1125, device='cuda:0') tensor(0.1139, device='cuda:0') tensor(-6.0374e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.076038
Average KL loss: 0.012124
Average total loss: 0.088162
 Percentile value: 4.188542334304708e-06
Non-zero model percentage: 40.96000671386719%, Non-zero mask percentage: 40.96000671386719%

--- Pruning Level [4/24]: ---
conv1.weight         | nonzeros =     770 /    1728             ( 44.56%) | total_pruned =     958 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
bn1.weight           | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
bn1.bias             | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   11591 /   36864             ( 31.44%) | total_pruned =   25273 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   13011 /   36864             ( 35.29%) | total_pruned =   23853 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   12013 /   36864             ( 32.59%) | total_pruned =   24851 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   12892 /   36864             ( 34.97%) | total_pruned =   23972 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   28381 /   73728             ( 38.49%) | total_pruned =   45347 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   57236 /  147456             ( 38.82%) | total_pruned =   90220 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3661 /    8192             ( 44.69%) | total_pruned =    4531 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   50305 /  147456             ( 34.12%) | total_pruned =   97151 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   50450 /  147456             ( 34.21%) | total_pruned =   97006 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  119862 /  294912             ( 40.64%) | total_pruned =  175050 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  228679 /  589824             ( 38.77%) | total_pruned =  361145 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     124 /     256             ( 48.44%) | total_pruned =     132 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      39 /     256             ( 15.23%) | total_pruned =     217 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   14386 /   32768             ( 43.90%) | total_pruned =   18382 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      34 /     256             ( 13.28%) | total_pruned =     222 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  194477 /  589824             ( 32.97%) | total_pruned =  395347 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     148 /     256             ( 57.81%) | total_pruned =     108 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     246 /     256             ( 96.09%) | total_pruned =      10 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  173445 /  589824             ( 29.41%) | total_pruned =  416379 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  423730 / 1179648             ( 35.92%) | total_pruned =  755918 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     291 /     512             ( 56.84%) | total_pruned =     221 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  771366 / 2359296             ( 32.69%) | total_pruned = 1587930 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     282 /     512             ( 55.08%) | total_pruned =     230 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     290 /     512             ( 56.64%) | total_pruned =     222 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   40737 /  131072             ( 31.08%) | total_pruned =   90335 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     278 /     512             ( 54.30%) | total_pruned =     234 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     454 /     512             ( 88.67%) | total_pruned =      58 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     284 /     512             ( 55.47%) | total_pruned =     228 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  832474 / 2359296             ( 35.28%) | total_pruned = 1526822 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     247 /     512             ( 48.24%) | total_pruned =     265 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     467 /     512             ( 91.21%) | total_pruned =      45 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1526119 / 2359296             ( 64.69%) | total_pruned =  833177 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     281 /     512             ( 54.88%) | total_pruned =     231 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     501 /     512             ( 97.85%) | total_pruned =      11 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     490 /     512             ( 95.70%) | total_pruned =      22 | shape = torch.Size([512])
linear.weight        | nonzeros =    4812 /    5120             ( 93.98%) | total_pruned =     308 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 4578822, pruned : 6599940, total: 11178762, Compression rate :       2.44x  ( 59.04% pruned)
Train Epoch: 38/100 Loss: 0.042460 Accuracy: 88.65 100.00 % Best test Accuracy: 88.65%
tensor(0.1125, device='cuda:0') tensor(0.1139, device='cuda:0') tensor(-1.2515e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.122769
Average KL loss: 0.012066
Average total loss: 0.134834
tensor(0.1121, device='cuda:0') tensor(0.1130, device='cuda:0') tensor(-1.1649e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.116346
Average KL loss: 0.011994
Average total loss: 0.128341
tensor(0.1120, device='cuda:0') tensor(0.1124, device='cuda:0') tensor(-1.3858e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.117955
Average KL loss: 0.011935
Average total loss: 0.129890
tensor(0.1118, device='cuda:0') tensor(0.1120, device='cuda:0') tensor(-1.5496e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.116115
Average KL loss: 0.011881
Average total loss: 0.127996
tensor(0.1117, device='cuda:0') tensor(0.1116, device='cuda:0') tensor(-1.6989e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.116191
Average KL loss: 0.011830
Average total loss: 0.128022
tensor(0.1116, device='cuda:0') tensor(0.1112, device='cuda:0') tensor(-1.3317e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.114200
Average KL loss: 0.011784
Average total loss: 0.125985
tensor(0.1114, device='cuda:0') tensor(0.1109, device='cuda:0') tensor(-1.7775e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.112603
Average KL loss: 0.011742
Average total loss: 0.124345
tensor(0.1113, device='cuda:0') tensor(0.1106, device='cuda:0') tensor(-1.7441e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.110907
Average KL loss: 0.011703
Average total loss: 0.122610
tensor(0.1111, device='cuda:0') tensor(0.1103, device='cuda:0') tensor(-1.4760e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.109247
Average KL loss: 0.011666
Average total loss: 0.120913
tensor(0.1110, device='cuda:0') tensor(0.1101, device='cuda:0') tensor(-1.3932e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.109054
Average KL loss: 0.011633
Average total loss: 0.120687
tensor(0.1108, device='cuda:0') tensor(0.1098, device='cuda:0') tensor(-1.5302e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.108560
Average KL loss: 0.011602
Average total loss: 0.120162
tensor(0.1107, device='cuda:0') tensor(0.1096, device='cuda:0') tensor(-1.0851e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.111545
Average KL loss: 0.011572
Average total loss: 0.123118
tensor(0.1105, device='cuda:0') tensor(0.1094, device='cuda:0') tensor(-1.1141e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.106829
Average KL loss: 0.011545
Average total loss: 0.118374
tensor(0.1104, device='cuda:0') tensor(0.1093, device='cuda:0') tensor(-1.1717e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.105152
Average KL loss: 0.011520
Average total loss: 0.116672
tensor(0.1102, device='cuda:0') tensor(0.1091, device='cuda:0') tensor(-1.4171e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.106115
Average KL loss: 0.011496
Average total loss: 0.117611
tensor(0.1101, device='cuda:0') tensor(0.1090, device='cuda:0') tensor(-1.2318e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.105112
Average KL loss: 0.011474
Average total loss: 0.116586
tensor(0.1099, device='cuda:0') tensor(0.1088, device='cuda:0') tensor(-1.1954e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.107375
Average KL loss: 0.011453
Average total loss: 0.118828
tensor(0.1098, device='cuda:0') tensor(0.1087, device='cuda:0') tensor(-1.2140e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.103293
Average KL loss: 0.011434
Average total loss: 0.114727
tensor(0.1096, device='cuda:0') tensor(0.1086, device='cuda:0') tensor(-1.1269e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.105311
Average KL loss: 0.011417
Average total loss: 0.116728
tensor(0.1095, device='cuda:0') tensor(0.1085, device='cuda:0') tensor(-1.1303e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.103451
Average KL loss: 0.011401
Average total loss: 0.114852
tensor(0.1094, device='cuda:0') tensor(0.1084, device='cuda:0') tensor(-1.4532e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.100987
Average KL loss: 0.011386
Average total loss: 0.112373
tensor(0.1092, device='cuda:0') tensor(0.1084, device='cuda:0') tensor(-1.2902e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.101520
Average KL loss: 0.011372
Average total loss: 0.112892
tensor(0.1091, device='cuda:0') tensor(0.1083, device='cuda:0') tensor(-8.3317e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.102543
Average KL loss: 0.011359
Average total loss: 0.113902
tensor(0.1090, device='cuda:0') tensor(0.1083, device='cuda:0') tensor(-9.8245e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.102248
Average KL loss: 0.011347
Average total loss: 0.113595
tensor(0.1088, device='cuda:0') tensor(0.1082, device='cuda:0') tensor(-1.3313e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.101870
Average KL loss: 0.011336
Average total loss: 0.113206
tensor(0.1087, device='cuda:0') tensor(0.1082, device='cuda:0') tensor(-7.8305e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.101053
Average KL loss: 0.011327
Average total loss: 0.112380
tensor(0.1086, device='cuda:0') tensor(0.1082, device='cuda:0') tensor(-1.1857e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.102381
Average KL loss: 0.011317
Average total loss: 0.113699
tensor(0.1085, device='cuda:0') tensor(0.1081, device='cuda:0') tensor(-1.1752e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.098318
Average KL loss: 0.011310
Average total loss: 0.109628
tensor(0.1084, device='cuda:0') tensor(0.1081, device='cuda:0') tensor(-7.4674e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.100318
Average KL loss: 0.011302
Average total loss: 0.111620
tensor(0.1083, device='cuda:0') tensor(0.1081, device='cuda:0') tensor(-1.0615e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.099298
Average KL loss: 0.011295
Average total loss: 0.110593
tensor(0.1082, device='cuda:0') tensor(0.1081, device='cuda:0') tensor(-8.9859e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.096741
Average KL loss: 0.011289
Average total loss: 0.108030
tensor(0.1081, device='cuda:0') tensor(0.1081, device='cuda:0') tensor(-1.0145e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.096384
Average KL loss: 0.011283
Average total loss: 0.107667
tensor(0.1080, device='cuda:0') tensor(0.1081, device='cuda:0') tensor(-1.0961e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.096261
Average KL loss: 0.011279
Average total loss: 0.107541
tensor(0.1079, device='cuda:0') tensor(0.1081, device='cuda:0') tensor(-8.2461e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.096147
Average KL loss: 0.011275
Average total loss: 0.107421
tensor(0.1078, device='cuda:0') tensor(0.1081, device='cuda:0') tensor(-1.0349e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.096303
Average KL loss: 0.011271
Average total loss: 0.107574
tensor(0.1077, device='cuda:0') tensor(0.1082, device='cuda:0') tensor(-1.0385e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.093904
Average KL loss: 0.011267
Average total loss: 0.105172
tensor(0.1076, device='cuda:0') tensor(0.1082, device='cuda:0') tensor(-1.0385e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.094266
Average KL loss: 0.011264
Average total loss: 0.105530
tensor(0.1075, device='cuda:0') tensor(0.1082, device='cuda:0') tensor(-1.4276e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.093175
Average KL loss: 0.011261
Average total loss: 0.104436
tensor(0.1074, device='cuda:0') tensor(0.1082, device='cuda:0') tensor(-8.2037e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.097031
Average KL loss: 0.011259
Average total loss: 0.108290
tensor(0.1074, device='cuda:0') tensor(0.1083, device='cuda:0') tensor(-8.6399e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.092843
Average KL loss: 0.011258
Average total loss: 0.104101
tensor(0.1073, device='cuda:0') tensor(0.1083, device='cuda:0') tensor(-1.1188e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.093194
Average KL loss: 0.011257
Average total loss: 0.104451
tensor(0.1072, device='cuda:0') tensor(0.1083, device='cuda:0') tensor(-1.1548e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.094044
Average KL loss: 0.011255
Average total loss: 0.105300
tensor(0.1072, device='cuda:0') tensor(0.1084, device='cuda:0') tensor(-1.0420e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.090621
Average KL loss: 0.011255
Average total loss: 0.101877
tensor(0.1071, device='cuda:0') tensor(0.1084, device='cuda:0') tensor(-1.0222e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.091396
Average KL loss: 0.011255
Average total loss: 0.102651
tensor(0.1070, device='cuda:0') tensor(0.1085, device='cuda:0') tensor(-1.3557e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.088979
Average KL loss: 0.011254
Average total loss: 0.100233
tensor(0.1070, device='cuda:0') tensor(0.1085, device='cuda:0') tensor(-1.3139e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.090536
Average KL loss: 0.011254
Average total loss: 0.101789
tensor(0.1069, device='cuda:0') tensor(0.1085, device='cuda:0') tensor(-1.1956e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.090315
Average KL loss: 0.011254
Average total loss: 0.101568
tensor(0.1068, device='cuda:0') tensor(0.1086, device='cuda:0') tensor(-1.2991e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.090862
Average KL loss: 0.011255
Average total loss: 0.102117
tensor(0.1068, device='cuda:0') tensor(0.1086, device='cuda:0') tensor(-9.4551e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.087696
Average KL loss: 0.011255
Average total loss: 0.098951
tensor(0.1067, device='cuda:0') tensor(0.1087, device='cuda:0') tensor(-8.6438e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.087461
Average KL loss: 0.011256
Average total loss: 0.098717
tensor(0.1067, device='cuda:0') tensor(0.1087, device='cuda:0') tensor(-1.1128e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.087891
Average KL loss: 0.011257
Average total loss: 0.099148
tensor(0.1066, device='cuda:0') tensor(0.1088, device='cuda:0') tensor(-9.4454e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.084781
Average KL loss: 0.011259
Average total loss: 0.096040
tensor(0.1066, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-8.6980e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.087179
Average KL loss: 0.011260
Average total loss: 0.098439
tensor(0.1065, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-8.2750e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.084993
Average KL loss: 0.011260
Average total loss: 0.096253
tensor(0.1065, device='cuda:0') tensor(0.1090, device='cuda:0') tensor(-1.1783e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.085985
Average KL loss: 0.011262
Average total loss: 0.097247
tensor(0.1064, device='cuda:0') tensor(0.1090, device='cuda:0') tensor(-5.8698e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.087649
Average KL loss: 0.011264
Average total loss: 0.098913
tensor(0.1064, device='cuda:0') tensor(0.1091, device='cuda:0') tensor(-9.4774e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.086704
Average KL loss: 0.011267
Average total loss: 0.097971
tensor(0.1063, device='cuda:0') tensor(0.1092, device='cuda:0') tensor(-6.5063e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.086616
Average KL loss: 0.011270
Average total loss: 0.097886
tensor(0.1063, device='cuda:0') tensor(0.1092, device='cuda:0') tensor(-8.5042e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.083281
Average KL loss: 0.011272
Average total loss: 0.094553
tensor(0.1063, device='cuda:0') tensor(0.1093, device='cuda:0') tensor(-8.9763e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.088553
Average KL loss: 0.011274
Average total loss: 0.099827
tensor(0.1062, device='cuda:0') tensor(0.1093, device='cuda:0') tensor(-9.6646e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.083851
Average KL loss: 0.011277
Average total loss: 0.095128
tensor(0.1062, device='cuda:0') tensor(0.1094, device='cuda:0') tensor(-8.8579e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.084307
Average KL loss: 0.011280
Average total loss: 0.095587
tensor(0.1061, device='cuda:0') tensor(0.1095, device='cuda:0') tensor(-8.9734e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.082390
Average KL loss: 0.011283
Average total loss: 0.093673
tensor(0.1061, device='cuda:0') tensor(0.1096, device='cuda:0') tensor(-1.0097e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.084963
Average KL loss: 0.011285
Average total loss: 0.096248
tensor(0.1061, device='cuda:0') tensor(0.1096, device='cuda:0') tensor(-8.8546e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.084107
Average KL loss: 0.011288
Average total loss: 0.095395
tensor(0.1060, device='cuda:0') tensor(0.1097, device='cuda:0') tensor(-9.7663e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.083797
Average KL loss: 0.011292
Average total loss: 0.095089
tensor(0.1060, device='cuda:0') tensor(0.1098, device='cuda:0') tensor(-7.5699e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.080256
Average KL loss: 0.011295
Average total loss: 0.091551
tensor(0.1060, device='cuda:0') tensor(0.1098, device='cuda:0') tensor(-1.0107e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.082264
Average KL loss: 0.011297
Average total loss: 0.093561
tensor(0.1059, device='cuda:0') tensor(0.1099, device='cuda:0') tensor(-9.4423e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.082146
Average KL loss: 0.011300
Average total loss: 0.093446
tensor(0.1059, device='cuda:0') tensor(0.1100, device='cuda:0') tensor(-9.0700e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.080390
Average KL loss: 0.011304
Average total loss: 0.091694
tensor(0.1059, device='cuda:0') tensor(0.1100, device='cuda:0') tensor(-8.5415e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.083034
Average KL loss: 0.011307
Average total loss: 0.094341
tensor(0.1059, device='cuda:0') tensor(0.1101, device='cuda:0') tensor(-7.3015e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.080043
Average KL loss: 0.011311
Average total loss: 0.091354
tensor(0.1058, device='cuda:0') tensor(0.1102, device='cuda:0') tensor(-8.5211e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.081561
Average KL loss: 0.011315
Average total loss: 0.092876
tensor(0.1058, device='cuda:0') tensor(0.1103, device='cuda:0') tensor(-8.2552e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.079445
Average KL loss: 0.011319
Average total loss: 0.090764
tensor(0.1058, device='cuda:0') tensor(0.1104, device='cuda:0') tensor(-6.9440e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.077415
Average KL loss: 0.011322
Average total loss: 0.088737
tensor(0.1058, device='cuda:0') tensor(0.1104, device='cuda:0') tensor(-7.9522e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.081933
Average KL loss: 0.011325
Average total loss: 0.093258
tensor(0.1057, device='cuda:0') tensor(0.1105, device='cuda:0') tensor(-7.5589e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.081014
Average KL loss: 0.011329
Average total loss: 0.092344
tensor(0.1057, device='cuda:0') tensor(0.1106, device='cuda:0') tensor(-7.9726e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.082662
Average KL loss: 0.011333
Average total loss: 0.093995
tensor(0.1057, device='cuda:0') tensor(0.1107, device='cuda:0') tensor(-7.2486e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.078230
Average KL loss: 0.011337
Average total loss: 0.089568
tensor(0.1057, device='cuda:0') tensor(0.1107, device='cuda:0') tensor(-1.0717e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.077287
Average KL loss: 0.011341
Average total loss: 0.088628
tensor(0.1056, device='cuda:0') tensor(0.1108, device='cuda:0') tensor(-7.7323e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.076874
Average KL loss: 0.011345
Average total loss: 0.088220
tensor(0.1056, device='cuda:0') tensor(0.1109, device='cuda:0') tensor(-6.9075e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.077960
Average KL loss: 0.011350
Average total loss: 0.089310
tensor(0.1056, device='cuda:0') tensor(0.1110, device='cuda:0') tensor(-7.3710e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.076806
Average KL loss: 0.011353
Average total loss: 0.088160
tensor(0.1056, device='cuda:0') tensor(0.1111, device='cuda:0') tensor(-5.8562e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.076823
Average KL loss: 0.011357
Average total loss: 0.088180
tensor(0.1055, device='cuda:0') tensor(0.1111, device='cuda:0') tensor(-8.0526e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.075917
Average KL loss: 0.011360
Average total loss: 0.087278
tensor(0.1055, device='cuda:0') tensor(0.1112, device='cuda:0') tensor(-8.4611e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.077978
Average KL loss: 0.011365
Average total loss: 0.089343
tensor(0.1055, device='cuda:0') tensor(0.1113, device='cuda:0') tensor(-8.2642e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.077725
Average KL loss: 0.011369
Average total loss: 0.089094
tensor(0.1055, device='cuda:0') tensor(0.1114, device='cuda:0') tensor(-5.4216e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.077316
Average KL loss: 0.011373
Average total loss: 0.088689
tensor(0.1055, device='cuda:0') tensor(0.1114, device='cuda:0') tensor(-7.9081e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.074436
Average KL loss: 0.011377
Average total loss: 0.085813
tensor(0.1054, device='cuda:0') tensor(0.1115, device='cuda:0') tensor(-8.8207e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.076553
Average KL loss: 0.011381
Average total loss: 0.087935
tensor(0.1054, device='cuda:0') tensor(0.1116, device='cuda:0') tensor(-9.7055e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.076904
Average KL loss: 0.011386
Average total loss: 0.088290
tensor(0.1054, device='cuda:0') tensor(0.1117, device='cuda:0') tensor(-6.9884e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.074734
Average KL loss: 0.011389
Average total loss: 0.086124
tensor(0.1054, device='cuda:0') tensor(0.1118, device='cuda:0') tensor(-1.0609e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.073298
Average KL loss: 0.011393
Average total loss: 0.084691
tensor(0.1053, device='cuda:0') tensor(0.1118, device='cuda:0') tensor(-8.2089e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.073867
Average KL loss: 0.011397
Average total loss: 0.085263
tensor(0.1053, device='cuda:0') tensor(0.1119, device='cuda:0') tensor(-6.6363e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.078980
Average KL loss: 0.011401
Average total loss: 0.090381
tensor(0.1053, device='cuda:0') tensor(0.1120, device='cuda:0') tensor(-8.0672e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.074524
Average KL loss: 0.011406
Average total loss: 0.085929
tensor(0.1053, device='cuda:0') tensor(0.1121, device='cuda:0') tensor(-6.0880e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.075054
Average KL loss: 0.011409
Average total loss: 0.086463
tensor(0.1053, device='cuda:0') tensor(0.1122, device='cuda:0') tensor(-6.0138e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.074641
Average KL loss: 0.011414
Average total loss: 0.086055
tensor(0.1052, device='cuda:0') tensor(0.1122, device='cuda:0') tensor(-5.6388e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.073987
Average KL loss: 0.011418
Average total loss: 0.085405
tensor(0.1052, device='cuda:0') tensor(0.1123, device='cuda:0') tensor(-6.7850e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.072584
Average KL loss: 0.011422
Average total loss: 0.084006
tensor(0.1052, device='cuda:0') tensor(0.1124, device='cuda:0') tensor(-8.3027e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.071565
Average KL loss: 0.011426
Average total loss: 0.082991
tensor(0.1052, device='cuda:0') tensor(0.1125, device='cuda:0') tensor(-7.6717e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.072191
Average KL loss: 0.011430
Average total loss: 0.083621
tensor(0.1052, device='cuda:0') tensor(0.1126, device='cuda:0') tensor(-6.3055e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.072145
Average KL loss: 0.011435
Average total loss: 0.083580
tensor(0.1052, device='cuda:0') tensor(0.1127, device='cuda:0') tensor(-5.8737e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.073084
Average KL loss: 0.011439
Average total loss: 0.084523
tensor(0.1051, device='cuda:0') tensor(0.1127, device='cuda:0') tensor(-5.6932e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.072824
Average KL loss: 0.011443
Average total loss: 0.084267
tensor(0.1051, device='cuda:0') tensor(0.1128, device='cuda:0') tensor(-9.1178e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.069162
Average KL loss: 0.011448
Average total loss: 0.080610
tensor(0.1051, device='cuda:0') tensor(0.1129, device='cuda:0') tensor(-5.4120e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.074205
Average KL loss: 0.011451
Average total loss: 0.085656
tensor(0.1051, device='cuda:0') tensor(0.1130, device='cuda:0') tensor(-5.5002e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.070699
Average KL loss: 0.011455
Average total loss: 0.082154
tensor(0.1051, device='cuda:0') tensor(0.1131, device='cuda:0') tensor(-7.6695e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.071126
Average KL loss: 0.011459
Average total loss: 0.082586
tensor(0.1050, device='cuda:0') tensor(0.1131, device='cuda:0') tensor(-4.9312e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.071032
Average KL loss: 0.011463
Average total loss: 0.082495
tensor(0.1050, device='cuda:0') tensor(0.1132, device='cuda:0') tensor(-4.9376e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.072660
Average KL loss: 0.011468
Average total loss: 0.084129
tensor(0.1050, device='cuda:0') tensor(0.1133, device='cuda:0') tensor(-5.8995e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.068545
Average KL loss: 0.011473
Average total loss: 0.080017
tensor(0.1050, device='cuda:0') tensor(0.1134, device='cuda:0') tensor(-7.8204e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.070770
Average KL loss: 0.011476
Average total loss: 0.082246
tensor(0.1050, device='cuda:0') tensor(0.1135, device='cuda:0') tensor(-6.8285e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.071074
Average KL loss: 0.011481
Average total loss: 0.082555
tensor(0.1050, device='cuda:0') tensor(0.1136, device='cuda:0') tensor(-4.5347e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.067410
Average KL loss: 0.011485
Average total loss: 0.078895
tensor(0.1049, device='cuda:0') tensor(0.1136, device='cuda:0') tensor(-6.1412e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.070554
Average KL loss: 0.011489
Average total loss: 0.082043
tensor(0.1049, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-7.2115e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.068490
Average KL loss: 0.011493
Average total loss: 0.079983
tensor(0.1049, device='cuda:0') tensor(0.1138, device='cuda:0') tensor(-8.6931e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.071351
Average KL loss: 0.011498
Average total loss: 0.082848
tensor(0.1049, device='cuda:0') tensor(0.1139, device='cuda:0') tensor(-6.8507e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.066971
Average KL loss: 0.011502
Average total loss: 0.078473
tensor(0.1049, device='cuda:0') tensor(0.1140, device='cuda:0') tensor(-7.8077e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.067231
Average KL loss: 0.011506
Average total loss: 0.078737
tensor(0.1049, device='cuda:0') tensor(0.1141, device='cuda:0') tensor(-7.1871e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.069020
Average KL loss: 0.011511
Average total loss: 0.080531
tensor(0.1049, device='cuda:0') tensor(0.1141, device='cuda:0') tensor(-8.3355e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.069876
Average KL loss: 0.011516
Average total loss: 0.081392
tensor(0.1048, device='cuda:0') tensor(0.1142, device='cuda:0') tensor(-5.6843e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.070272
Average KL loss: 0.011520
Average total loss: 0.081792
tensor(0.1048, device='cuda:0') tensor(0.1143, device='cuda:0') tensor(-6.6769e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.067856
Average KL loss: 0.011525
Average total loss: 0.079381
tensor(0.1048, device='cuda:0') tensor(0.1144, device='cuda:0') tensor(-7.5061e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.066258
Average KL loss: 0.011529
Average total loss: 0.077787
tensor(0.1048, device='cuda:0') tensor(0.1145, device='cuda:0') tensor(-5.9851e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.066681
Average KL loss: 0.011533
Average total loss: 0.078214
tensor(0.1048, device='cuda:0') tensor(0.1146, device='cuda:0') tensor(-6.7121e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.067616
Average KL loss: 0.011538
Average total loss: 0.079154
tensor(0.1048, device='cuda:0') tensor(0.1147, device='cuda:0') tensor(-5.1560e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.064947
Average KL loss: 0.011543
Average total loss: 0.076490
tensor(0.1048, device='cuda:0') tensor(0.1147, device='cuda:0') tensor(-5.3465e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.065279
Average KL loss: 0.011547
Average total loss: 0.076826
tensor(0.1047, device='cuda:0') tensor(0.1148, device='cuda:0') tensor(-3.8551e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.064765
Average KL loss: 0.011551
Average total loss: 0.076317
tensor(0.1047, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-7.8765e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.064853
Average KL loss: 0.011555
Average total loss: 0.076409
tensor(0.1047, device='cuda:0') tensor(0.1150, device='cuda:0') tensor(-4.7574e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.063356
Average KL loss: 0.011560
Average total loss: 0.074916
tensor(0.1047, device='cuda:0') tensor(0.1151, device='cuda:0') tensor(-6.6279e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.066088
Average KL loss: 0.011564
Average total loss: 0.077652
tensor(0.1047, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-5.3927e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.065824
Average KL loss: 0.011568
Average total loss: 0.077392
tensor(0.1047, device='cuda:0') tensor(0.1153, device='cuda:0') tensor(-6.4231e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.067831
Average KL loss: 0.011573
Average total loss: 0.079404
tensor(0.1046, device='cuda:0') tensor(0.1153, device='cuda:0') tensor(-8.4534e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.063833
Average KL loss: 0.011579
Average total loss: 0.075411
tensor(0.1046, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-6.9071e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.065858
Average KL loss: 0.011583
Average total loss: 0.077441
tensor(0.1046, device='cuda:0') tensor(0.1155, device='cuda:0') tensor(-6.7255e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.066248
Average KL loss: 0.011587
Average total loss: 0.077836
tensor(0.1046, device='cuda:0') tensor(0.1156, device='cuda:0') tensor(-6.9098e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.064383
Average KL loss: 0.011592
Average total loss: 0.075975
tensor(0.1046, device='cuda:0') tensor(0.1157, device='cuda:0') tensor(-3.3784e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.064918
Average KL loss: 0.011596
Average total loss: 0.076514
tensor(0.1046, device='cuda:0') tensor(0.1158, device='cuda:0') tensor(-8.0208e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.066836
Average KL loss: 0.011600
Average total loss: 0.078436
tensor(0.1046, device='cuda:0') tensor(0.1159, device='cuda:0') tensor(-5.1327e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.062766
Average KL loss: 0.011604
Average total loss: 0.074370
tensor(0.1045, device='cuda:0') tensor(0.1159, device='cuda:0') tensor(-7.2202e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.066430
Average KL loss: 0.011608
Average total loss: 0.078038
tensor(0.1045, device='cuda:0') tensor(0.1160, device='cuda:0') tensor(-5.0022e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.064149
Average KL loss: 0.011613
Average total loss: 0.075763
tensor(0.1045, device='cuda:0') tensor(0.1161, device='cuda:0') tensor(-6.3969e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.063228
Average KL loss: 0.011618
Average total loss: 0.074846
tensor(0.1045, device='cuda:0') tensor(0.1162, device='cuda:0') tensor(-5.9000e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.062329
Average KL loss: 0.011622
Average total loss: 0.073951
tensor(0.1045, device='cuda:0') tensor(0.1163, device='cuda:0') tensor(-6.0076e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.062771
Average KL loss: 0.011626
Average total loss: 0.074397
tensor(0.1045, device='cuda:0') tensor(0.1164, device='cuda:0') tensor(-4.4332e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.062350
Average KL loss: 0.011630
Average total loss: 0.073980
tensor(0.1044, device='cuda:0') tensor(0.1164, device='cuda:0') tensor(-5.3983e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.062062
Average KL loss: 0.011634
Average total loss: 0.073696
tensor(0.1044, device='cuda:0') tensor(0.1165, device='cuda:0') tensor(-9.1709e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.061419
Average KL loss: 0.011638
Average total loss: 0.073057
tensor(0.1044, device='cuda:0') tensor(0.1166, device='cuda:0') tensor(-6.2093e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.060972
Average KL loss: 0.011642
Average total loss: 0.072614
tensor(0.1044, device='cuda:0') tensor(0.1167, device='cuda:0') tensor(-6.6930e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.061515
Average KL loss: 0.011646
Average total loss: 0.073161
tensor(0.1044, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-3.8889e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.062249
Average KL loss: 0.011650
Average total loss: 0.073900
tensor(0.1044, device='cuda:0') tensor(0.1169, device='cuda:0') tensor(-4.1663e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.062080
Average KL loss: 0.011654
Average total loss: 0.073735
tensor(0.1044, device='cuda:0') tensor(0.1169, device='cuda:0') tensor(-6.7752e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.062342
Average KL loss: 0.011659
Average total loss: 0.074002
tensor(0.1043, device='cuda:0') tensor(0.1170, device='cuda:0') tensor(-6.3923e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.061608
Average KL loss: 0.011663
Average total loss: 0.073272
tensor(0.1043, device='cuda:0') tensor(0.1171, device='cuda:0') tensor(-7.6068e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.064096
Average KL loss: 0.011668
Average total loss: 0.075764
tensor(0.1043, device='cuda:0') tensor(0.1172, device='cuda:0') tensor(-3.5437e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.059790
Average KL loss: 0.011672
Average total loss: 0.071462
tensor(0.1043, device='cuda:0') tensor(0.1173, device='cuda:0') tensor(-4.3944e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.060064
Average KL loss: 0.011677
Average total loss: 0.071741
tensor(0.1043, device='cuda:0') tensor(0.1174, device='cuda:0') tensor(-6.5925e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.060273
Average KL loss: 0.011681
Average total loss: 0.071954
tensor(0.1043, device='cuda:0') tensor(0.1175, device='cuda:0') tensor(-7.2223e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.063095
Average KL loss: 0.011685
Average total loss: 0.074780
tensor(0.1042, device='cuda:0') tensor(0.1176, device='cuda:0') tensor(-3.7806e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.059756
Average KL loss: 0.011690
Average total loss: 0.071446
tensor(0.1042, device='cuda:0') tensor(0.1176, device='cuda:0') tensor(-6.6975e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.059729
Average KL loss: 0.011694
Average total loss: 0.071423
tensor(0.1042, device='cuda:0') tensor(0.1177, device='cuda:0') tensor(-6.1467e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.060986
Average KL loss: 0.011698
Average total loss: 0.072684
tensor(0.1042, device='cuda:0') tensor(0.1178, device='cuda:0') tensor(-5.8689e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.060517
Average KL loss: 0.011702
Average total loss: 0.072219
tensor(0.1042, device='cuda:0') tensor(0.1179, device='cuda:0') tensor(-4.7961e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.061992
Average KL loss: 0.011706
Average total loss: 0.073698
tensor(0.1042, device='cuda:0') tensor(0.1180, device='cuda:0') tensor(-5.7439e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.062213
Average KL loss: 0.011711
Average total loss: 0.073924
tensor(0.1042, device='cuda:0') tensor(0.1181, device='cuda:0') tensor(-4.1482e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.059559
Average KL loss: 0.011715
Average total loss: 0.071274
tensor(0.1042, device='cuda:0') tensor(0.1181, device='cuda:0') tensor(-1.3578e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.058372
Average KL loss: 0.011719
Average total loss: 0.070091
tensor(0.1041, device='cuda:0') tensor(0.1182, device='cuda:0') tensor(-6.6590e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.057926
Average KL loss: 0.011723
Average total loss: 0.069649
tensor(0.1041, device='cuda:0') tensor(0.1183, device='cuda:0') tensor(-5.1528e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.058409
Average KL loss: 0.011726
Average total loss: 0.070136
tensor(0.1041, device='cuda:0') tensor(0.1184, device='cuda:0') tensor(-4.8837e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.059835
Average KL loss: 0.011730
Average total loss: 0.071565
tensor(0.1041, device='cuda:0') tensor(0.1185, device='cuda:0') tensor(-3.4488e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.057538
Average KL loss: 0.011734
Average total loss: 0.069272
tensor(0.1041, device='cuda:0') tensor(0.1185, device='cuda:0') tensor(-6.4967e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.058256
Average KL loss: 0.011739
Average total loss: 0.069994
tensor(0.1041, device='cuda:0') tensor(0.1186, device='cuda:0') tensor(-4.8962e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.057473
Average KL loss: 0.011743
Average total loss: 0.069215
tensor(0.1040, device='cuda:0') tensor(0.1187, device='cuda:0') tensor(-6.1386e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.057992
Average KL loss: 0.011746
Average total loss: 0.069737
tensor(0.1040, device='cuda:0') tensor(0.1188, device='cuda:0') tensor(-8.0619e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.059110
Average KL loss: 0.011750
Average total loss: 0.070860
tensor(0.1040, device='cuda:0') tensor(0.1189, device='cuda:0') tensor(-3.6646e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.057123
Average KL loss: 0.011754
Average total loss: 0.068877
tensor(0.1040, device='cuda:0') tensor(0.1190, device='cuda:0') tensor(-5.0181e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.057742
Average KL loss: 0.011758
Average total loss: 0.069500
tensor(0.1040, device='cuda:0') tensor(0.1190, device='cuda:0') tensor(-5.6563e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.057017
Average KL loss: 0.011762
Average total loss: 0.068779
tensor(0.1040, device='cuda:0') tensor(0.1191, device='cuda:0') tensor(-5.6620e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.057401
Average KL loss: 0.011766
Average total loss: 0.069167
tensor(0.1039, device='cuda:0') tensor(0.1192, device='cuda:0') tensor(-5.4602e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.058077
Average KL loss: 0.011770
Average total loss: 0.069846
tensor(0.1039, device='cuda:0') tensor(0.1193, device='cuda:0') tensor(-5.7092e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.058703
Average KL loss: 0.011774
Average total loss: 0.070477
tensor(0.1039, device='cuda:0') tensor(0.1194, device='cuda:0') tensor(-4.7387e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.060294
Average KL loss: 0.011778
Average total loss: 0.072072
tensor(0.1039, device='cuda:0') tensor(0.1195, device='cuda:0') tensor(-6.3747e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.057679
Average KL loss: 0.011783
Average total loss: 0.069462
tensor(0.1039, device='cuda:0') tensor(0.1195, device='cuda:0') tensor(-6.9593e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.056913
Average KL loss: 0.011787
Average total loss: 0.068700
tensor(0.1039, device='cuda:0') tensor(0.1196, device='cuda:0') tensor(-3.8930e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.058007
Average KL loss: 0.011791
Average total loss: 0.069798
tensor(0.1039, device='cuda:0') tensor(0.1197, device='cuda:0') tensor(-4.5551e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.055400
Average KL loss: 0.011795
Average total loss: 0.067195
tensor(0.1038, device='cuda:0') tensor(0.1198, device='cuda:0') tensor(-4.5302e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.055963
Average KL loss: 0.011798
Average total loss: 0.067761
tensor(0.1038, device='cuda:0') tensor(0.1199, device='cuda:0') tensor(-4.2240e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.055973
Average KL loss: 0.011802
Average total loss: 0.067775
tensor(0.1038, device='cuda:0') tensor(0.1200, device='cuda:0') tensor(-5.5030e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.056190
Average KL loss: 0.011806
Average total loss: 0.067996
tensor(0.1038, device='cuda:0') tensor(0.1200, device='cuda:0') tensor(-5.3021e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.054221
Average KL loss: 0.011810
Average total loss: 0.066031
tensor(0.1038, device='cuda:0') tensor(0.1201, device='cuda:0') tensor(-4.4362e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.056227
Average KL loss: 0.011813
Average total loss: 0.068041
tensor(0.1038, device='cuda:0') tensor(0.1202, device='cuda:0') tensor(-5.2799e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.054576
Average KL loss: 0.011817
Average total loss: 0.066394
tensor(0.1037, device='cuda:0') tensor(0.1203, device='cuda:0') tensor(-3.4188e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.055269
Average KL loss: 0.011821
Average total loss: 0.067090
tensor(0.1037, device='cuda:0') tensor(0.1204, device='cuda:0') tensor(-4.4664e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.054004
Average KL loss: 0.011825
Average total loss: 0.065829
tensor(0.1037, device='cuda:0') tensor(0.1204, device='cuda:0') tensor(-5.9495e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.054068
Average KL loss: 0.011829
Average total loss: 0.065897
tensor(0.1037, device='cuda:0') tensor(0.1205, device='cuda:0') tensor(-5.4484e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.053973
Average KL loss: 0.011832
Average total loss: 0.065805
tensor(0.1037, device='cuda:0') tensor(0.1206, device='cuda:0') tensor(-3.8774e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.057295
Average KL loss: 0.011835
Average total loss: 0.069130
tensor(0.1037, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-4.1548e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.056106
Average KL loss: 0.011838
Average total loss: 0.067945
 Percentile value: 1.5253617675625736e-05
Non-zero model percentage: 32.76801300048828%, Non-zero mask percentage: 32.76801300048828%

--- Pruning Level [5/24]: ---
conv1.weight         | nonzeros =     559 /    1728             ( 32.35%) | total_pruned =    1169 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
bn1.weight           | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
bn1.bias             | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    7826 /   36864             ( 21.23%) | total_pruned =   29038 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    8753 /   36864             ( 23.74%) | total_pruned =   28111 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    8246 /   36864             ( 22.37%) | total_pruned =   28618 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    9267 /   36864             ( 25.14%) | total_pruned =   27597 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   23254 /   73728             ( 31.54%) | total_pruned =   50474 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   47459 /  147456             ( 32.19%) | total_pruned =   99997 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3141 /    8192             ( 38.34%) | total_pruned =    5051 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   39693 /  147456             ( 26.92%) | total_pruned =  107763 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   38567 /  147456             ( 26.15%) | total_pruned =  108889 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  106411 /  294912             ( 36.08%) | total_pruned =  188501 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     105 /     256             ( 41.02%) | total_pruned =     151 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  197714 /  589824             ( 33.52%) | total_pruned =  392110 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      90 /     256             ( 35.16%) | total_pruned =     166 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   12767 /   32768             ( 38.96%) | total_pruned =   20001 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      88 /     256             ( 34.38%) | total_pruned =     168 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      32 /     256             ( 12.50%) | total_pruned =     224 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  153689 /  589824             ( 26.06%) | total_pruned =  436135 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     238 /     256             ( 92.97%) | total_pruned =      18 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  129219 /  589824             ( 21.91%) | total_pruned =  460605 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  357347 / 1179648             ( 30.29%) | total_pruned =  822301 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     200 /     512             ( 39.06%) | total_pruned =     312 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      57 /     512             ( 11.13%) | total_pruned =     455 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  592270 / 2359296             ( 25.10%) | total_pruned = 1767026 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     200 /     512             ( 39.06%) | total_pruned =     312 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     485 /     512             ( 94.73%) | total_pruned =      27 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     276 /     512             ( 53.91%) | total_pruned =     236 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   30052 /  131072             ( 22.93%) | total_pruned =  101020 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     182 /     512             ( 35.55%) | total_pruned =     330 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     422 /     512             ( 82.42%) | total_pruned =      90 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     272 /     512             ( 53.12%) | total_pruned =     240 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  606806 / 2359296             ( 25.72%) | total_pruned = 1752490 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     177 /     512             ( 34.57%) | total_pruned =     335 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     424 /     512             ( 82.81%) | total_pruned =      88 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1277965 / 2359296             ( 54.17%) | total_pruned = 1081331 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     194 /     512             ( 37.89%) | total_pruned =     318 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     482 /     512             ( 94.14%) | total_pruned =      30 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     479 /     512             ( 93.55%) | total_pruned =      33 | shape = torch.Size([512])
linear.weight        | nonzeros =    4698 /    5120             ( 91.76%) | total_pruned =     422 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 3663058, pruned : 7515704, total: 11178762, Compression rate :       3.05x  ( 67.23% pruned)
Train Epoch: 41/100 Loss: 0.021508 Accuracy: 88.36 100.00 % Best test Accuracy: 88.43%
tensor(0.1036, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-2.5137e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.123526
Average KL loss: 0.011793
Average total loss: 0.135320
tensor(0.1034, device='cuda:0') tensor(0.1199, device='cuda:0') tensor(-1.3593e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.127105
Average KL loss: 0.011739
Average total loss: 0.138844
tensor(0.1033, device='cuda:0') tensor(0.1195, device='cuda:0') tensor(-1.6364e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.121097
Average KL loss: 0.011694
Average total loss: 0.132791
tensor(0.1032, device='cuda:0') tensor(0.1191, device='cuda:0') tensor(-1.2135e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.124425
Average KL loss: 0.011653
Average total loss: 0.136077
tensor(0.1031, device='cuda:0') tensor(0.1187, device='cuda:0') tensor(-1.3746e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.116635
Average KL loss: 0.011614
Average total loss: 0.128249
tensor(0.1030, device='cuda:0') tensor(0.1184, device='cuda:0') tensor(-2.2173e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.115675
Average KL loss: 0.011579
Average total loss: 0.127254
tensor(0.1029, device='cuda:0') tensor(0.1181, device='cuda:0') tensor(-1.6359e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.114020
Average KL loss: 0.011545
Average total loss: 0.125565
tensor(0.1028, device='cuda:0') tensor(0.1178, device='cuda:0') tensor(-1.4109e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.116091
Average KL loss: 0.011514
Average total loss: 0.127606
tensor(0.1027, device='cuda:0') tensor(0.1176, device='cuda:0') tensor(-2.1366e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.111421
Average KL loss: 0.011486
Average total loss: 0.122908
tensor(0.1026, device='cuda:0') tensor(0.1173, device='cuda:0') tensor(-1.3904e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.111515
Average KL loss: 0.011459
Average total loss: 0.122974
tensor(0.1024, device='cuda:0') tensor(0.1171, device='cuda:0') tensor(-1.5462e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.112314
Average KL loss: 0.011434
Average total loss: 0.123749
tensor(0.1023, device='cuda:0') tensor(0.1169, device='cuda:0') tensor(-1.0443e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.108131
Average KL loss: 0.011411
Average total loss: 0.119543
tensor(0.1022, device='cuda:0') tensor(0.1167, device='cuda:0') tensor(-1.2512e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.110214
Average KL loss: 0.011389
Average total loss: 0.121603
tensor(0.1021, device='cuda:0') tensor(0.1166, device='cuda:0') tensor(-1.4655e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.110126
Average KL loss: 0.011369
Average total loss: 0.121495
tensor(0.1020, device='cuda:0') tensor(0.1164, device='cuda:0') tensor(-1.5151e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.105973
Average KL loss: 0.011351
Average total loss: 0.117324
tensor(0.1019, device='cuda:0') tensor(0.1163, device='cuda:0') tensor(-1.5267e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.101954
Average KL loss: 0.011333
Average total loss: 0.113287
tensor(0.1018, device='cuda:0') tensor(0.1162, device='cuda:0') tensor(-1.1699e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.101688
Average KL loss: 0.011316
Average total loss: 0.113004
tensor(0.1017, device='cuda:0') tensor(0.1160, device='cuda:0') tensor(-1.3833e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.099523
Average KL loss: 0.011300
Average total loss: 0.110823
tensor(0.1016, device='cuda:0') tensor(0.1159, device='cuda:0') tensor(-1.4423e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.098007
Average KL loss: 0.011285
Average total loss: 0.109292
tensor(0.1015, device='cuda:0') tensor(0.1158, device='cuda:0') tensor(-1.1923e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.099867
Average KL loss: 0.011271
Average total loss: 0.111138
tensor(0.1014, device='cuda:0') tensor(0.1157, device='cuda:0') tensor(-1.7807e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.100215
Average KL loss: 0.011259
Average total loss: 0.111473
tensor(0.1013, device='cuda:0') tensor(0.1156, device='cuda:0') tensor(-1.4057e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.099798
Average KL loss: 0.011247
Average total loss: 0.111044
tensor(0.1012, device='cuda:0') tensor(0.1156, device='cuda:0') tensor(-1.0759e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.097143
Average KL loss: 0.011236
Average total loss: 0.108379
tensor(0.1011, device='cuda:0') tensor(0.1155, device='cuda:0') tensor(-1.3078e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.095000
Average KL loss: 0.011225
Average total loss: 0.106225
tensor(0.1010, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-1.1251e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.097588
Average KL loss: 0.011215
Average total loss: 0.108803
tensor(0.1009, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-1.3060e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.097751
Average KL loss: 0.011206
Average total loss: 0.108957
tensor(0.1008, device='cuda:0') tensor(0.1153, device='cuda:0') tensor(-1.2642e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.102340
Average KL loss: 0.011198
Average total loss: 0.113539
tensor(0.1007, device='cuda:0') tensor(0.1153, device='cuda:0') tensor(-1.0932e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.094871
Average KL loss: 0.011192
Average total loss: 0.106063
tensor(0.1006, device='cuda:0') tensor(0.1153, device='cuda:0') tensor(-1.8035e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.095063
Average KL loss: 0.011184
Average total loss: 0.106248
tensor(0.1005, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-1.1985e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.095251
Average KL loss: 0.011177
Average total loss: 0.106428
tensor(0.1005, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-1.0304e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.092493
Average KL loss: 0.011171
Average total loss: 0.103664
tensor(0.1004, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-1.2212e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.090415
Average KL loss: 0.011165
Average total loss: 0.101580
tensor(0.1003, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-1.3785e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.092336
Average KL loss: 0.011160
Average total loss: 0.103496
tensor(0.1002, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-1.0177e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.092105
Average KL loss: 0.011155
Average total loss: 0.103259
tensor(0.1001, device='cuda:0') tensor(0.1151, device='cuda:0') tensor(-1.1199e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.089951
Average KL loss: 0.011150
Average total loss: 0.101101
tensor(0.1001, device='cuda:0') tensor(0.1151, device='cuda:0') tensor(-1.1662e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.091037
Average KL loss: 0.011146
Average total loss: 0.102183
tensor(0.1000, device='cuda:0') tensor(0.1151, device='cuda:0') tensor(-1.2426e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.087790
Average KL loss: 0.011143
Average total loss: 0.098933
tensor(0.0999, device='cuda:0') tensor(0.1151, device='cuda:0') tensor(-1.1552e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.089235
Average KL loss: 0.011140
Average total loss: 0.100375
tensor(0.0999, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-1.1978e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.090878
Average KL loss: 0.011138
Average total loss: 0.102016
tensor(0.0998, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-1.9220e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.086192
Average KL loss: 0.011136
Average total loss: 0.097328
tensor(0.0998, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-1.1323e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.092129
Average KL loss: 0.011135
Average total loss: 0.103264
tensor(0.0997, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-1.2823e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.085670
Average KL loss: 0.011134
Average total loss: 0.096804
tensor(0.0997, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-1.1204e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.084309
Average KL loss: 0.011132
Average total loss: 0.095442
tensor(0.0996, device='cuda:0') tensor(0.1153, device='cuda:0') tensor(-1.1990e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.087694
Average KL loss: 0.011131
Average total loss: 0.098825
tensor(0.0995, device='cuda:0') tensor(0.1153, device='cuda:0') tensor(-1.0227e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.086610
Average KL loss: 0.011132
Average total loss: 0.097742
tensor(0.0995, device='cuda:0') tensor(0.1153, device='cuda:0') tensor(-8.6331e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.087803
Average KL loss: 0.011132
Average total loss: 0.098934
tensor(0.0995, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-1.1951e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.086142
Average KL loss: 0.011132
Average total loss: 0.097274
tensor(0.0994, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-1.0208e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.084446
Average KL loss: 0.011132
Average total loss: 0.095578
tensor(0.0994, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-8.1685e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.084999
Average KL loss: 0.011132
Average total loss: 0.096131
tensor(0.0993, device='cuda:0') tensor(0.1155, device='cuda:0') tensor(-1.0561e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.084479
Average KL loss: 0.011132
Average total loss: 0.095611
tensor(0.0993, device='cuda:0') tensor(0.1155, device='cuda:0') tensor(-9.8106e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.086846
Average KL loss: 0.011133
Average total loss: 0.097979
tensor(0.0993, device='cuda:0') tensor(0.1155, device='cuda:0') tensor(-1.0128e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.085472
Average KL loss: 0.011135
Average total loss: 0.096607
tensor(0.0992, device='cuda:0') tensor(0.1156, device='cuda:0') tensor(-1.0146e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.080918
Average KL loss: 0.011136
Average total loss: 0.092053
tensor(0.0992, device='cuda:0') tensor(0.1156, device='cuda:0') tensor(-1.0445e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.082420
Average KL loss: 0.011137
Average total loss: 0.093557
tensor(0.0991, device='cuda:0') tensor(0.1157, device='cuda:0') tensor(-8.3099e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.083700
Average KL loss: 0.011138
Average total loss: 0.094839
tensor(0.0991, device='cuda:0') tensor(0.1157, device='cuda:0') tensor(-6.8571e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.081281
Average KL loss: 0.011140
Average total loss: 0.092421
tensor(0.0991, device='cuda:0') tensor(0.1158, device='cuda:0') tensor(-9.5956e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.081141
Average KL loss: 0.011142
Average total loss: 0.092283
tensor(0.0990, device='cuda:0') tensor(0.1158, device='cuda:0') tensor(-1.2553e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.081300
Average KL loss: 0.011143
Average total loss: 0.092443
tensor(0.0990, device='cuda:0') tensor(0.1159, device='cuda:0') tensor(-8.3558e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.082466
Average KL loss: 0.011145
Average total loss: 0.093611
tensor(0.0990, device='cuda:0') tensor(0.1159, device='cuda:0') tensor(-5.7610e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.077431
Average KL loss: 0.011148
Average total loss: 0.088578
tensor(0.0990, device='cuda:0') tensor(0.1160, device='cuda:0') tensor(-1.2269e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.079946
Average KL loss: 0.011149
Average total loss: 0.091095
tensor(0.0989, device='cuda:0') tensor(0.1160, device='cuda:0') tensor(-8.6174e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.081834
Average KL loss: 0.011152
Average total loss: 0.092986
tensor(0.0989, device='cuda:0') tensor(0.1161, device='cuda:0') tensor(-7.1938e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.079361
Average KL loss: 0.011155
Average total loss: 0.090516
tensor(0.0989, device='cuda:0') tensor(0.1162, device='cuda:0') tensor(-1.1125e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.078971
Average KL loss: 0.011158
Average total loss: 0.090129
tensor(0.0989, device='cuda:0') tensor(0.1162, device='cuda:0') tensor(-8.5304e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.078175
Average KL loss: 0.011161
Average total loss: 0.089336
tensor(0.0988, device='cuda:0') tensor(0.1163, device='cuda:0') tensor(-7.4728e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.076177
Average KL loss: 0.011164
Average total loss: 0.087341
tensor(0.0988, device='cuda:0') tensor(0.1164, device='cuda:0') tensor(-8.5401e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.078696
Average KL loss: 0.011167
Average total loss: 0.089863
tensor(0.0988, device='cuda:0') tensor(0.1164, device='cuda:0') tensor(-9.3002e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.077868
Average KL loss: 0.011170
Average total loss: 0.089037
tensor(0.0988, device='cuda:0') tensor(0.1165, device='cuda:0') tensor(-1.0371e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.076467
Average KL loss: 0.011172
Average total loss: 0.087639
tensor(0.0988, device='cuda:0') tensor(0.1165, device='cuda:0') tensor(-1.0055e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.076803
Average KL loss: 0.011175
Average total loss: 0.087977
tensor(0.0987, device='cuda:0') tensor(0.1166, device='cuda:0') tensor(-7.8379e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.074927
Average KL loss: 0.011177
Average total loss: 0.086105
tensor(0.0987, device='cuda:0') tensor(0.1167, device='cuda:0') tensor(-9.6526e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.077166
Average KL loss: 0.011180
Average total loss: 0.088346
tensor(0.0987, device='cuda:0') tensor(0.1167, device='cuda:0') tensor(-9.8892e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.076780
Average KL loss: 0.011183
Average total loss: 0.087964
tensor(0.0987, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-7.8200e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.075494
Average KL loss: 0.011187
Average total loss: 0.086681
tensor(0.0987, device='cuda:0') tensor(0.1169, device='cuda:0') tensor(-7.8069e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.074914
Average KL loss: 0.011191
Average total loss: 0.086104
tensor(0.0986, device='cuda:0') tensor(0.1169, device='cuda:0') tensor(-7.8619e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.072064
Average KL loss: 0.011194
Average total loss: 0.083258
tensor(0.0986, device='cuda:0') tensor(0.1170, device='cuda:0') tensor(-8.8075e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.072770
Average KL loss: 0.011197
Average total loss: 0.083967
tensor(0.0986, device='cuda:0') tensor(0.1171, device='cuda:0') tensor(-9.5337e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.074225
Average KL loss: 0.011201
Average total loss: 0.085425
tensor(0.0986, device='cuda:0') tensor(0.1171, device='cuda:0') tensor(-7.9985e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.074788
Average KL loss: 0.011204
Average total loss: 0.085992
tensor(0.0986, device='cuda:0') tensor(0.1172, device='cuda:0') tensor(-8.8850e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.071562
Average KL loss: 0.011207
Average total loss: 0.082769
tensor(0.0986, device='cuda:0') tensor(0.1173, device='cuda:0') tensor(-7.4478e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.074672
Average KL loss: 0.011211
Average total loss: 0.085883
tensor(0.0985, device='cuda:0') tensor(0.1173, device='cuda:0') tensor(-6.1616e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.072901
Average KL loss: 0.011214
Average total loss: 0.084115
tensor(0.0985, device='cuda:0') tensor(0.1174, device='cuda:0') tensor(-6.9506e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.072797
Average KL loss: 0.011217
Average total loss: 0.084014
tensor(0.0985, device='cuda:0') tensor(0.1175, device='cuda:0') tensor(-6.9934e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.071538
Average KL loss: 0.011221
Average total loss: 0.082759
tensor(0.0985, device='cuda:0') tensor(0.1176, device='cuda:0') tensor(-7.5073e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.072341
Average KL loss: 0.011225
Average total loss: 0.083566
tensor(0.0985, device='cuda:0') tensor(0.1176, device='cuda:0') tensor(-7.9439e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.071136
Average KL loss: 0.011229
Average total loss: 0.082365
tensor(0.0985, device='cuda:0') tensor(0.1177, device='cuda:0') tensor(-5.8055e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.072031
Average KL loss: 0.011233
Average total loss: 0.083263
tensor(0.0985, device='cuda:0') tensor(0.1178, device='cuda:0') tensor(-9.3733e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.071098
Average KL loss: 0.011237
Average total loss: 0.082335
tensor(0.0985, device='cuda:0') tensor(0.1179, device='cuda:0') tensor(-8.9107e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.070544
Average KL loss: 0.011241
Average total loss: 0.081785
tensor(0.0985, device='cuda:0') tensor(0.1179, device='cuda:0') tensor(-5.4173e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.069708
Average KL loss: 0.011245
Average total loss: 0.080953
tensor(0.0985, device='cuda:0') tensor(0.1180, device='cuda:0') tensor(-5.9851e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.070964
Average KL loss: 0.011248
Average total loss: 0.082212
tensor(0.0984, device='cuda:0') tensor(0.1181, device='cuda:0') tensor(-8.2616e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.069444
Average KL loss: 0.011252
Average total loss: 0.080697
tensor(0.0984, device='cuda:0') tensor(0.1182, device='cuda:0') tensor(-8.7683e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.069173
Average KL loss: 0.011256
Average total loss: 0.080430
tensor(0.0984, device='cuda:0') tensor(0.1182, device='cuda:0') tensor(-5.4107e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.067738
Average KL loss: 0.011260
Average total loss: 0.078998
tensor(0.0984, device='cuda:0') tensor(0.1183, device='cuda:0') tensor(-7.9003e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.070590
Average KL loss: 0.011264
Average total loss: 0.081853
tensor(0.0984, device='cuda:0') tensor(0.1184, device='cuda:0') tensor(-6.3889e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.068987
Average KL loss: 0.011268
Average total loss: 0.080255
tensor(0.0984, device='cuda:0') tensor(0.1185, device='cuda:0') tensor(-8.7445e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.067102
Average KL loss: 0.011272
Average total loss: 0.078374
tensor(0.0984, device='cuda:0') tensor(0.1185, device='cuda:0') tensor(-7.1239e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.067628
Average KL loss: 0.011276
Average total loss: 0.078904
tensor(0.0984, device='cuda:0') tensor(0.1186, device='cuda:0') tensor(-1.0145e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.067709
Average KL loss: 0.011279
Average total loss: 0.078988
tensor(0.0984, device='cuda:0') tensor(0.1187, device='cuda:0') tensor(-6.6769e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.069289
Average KL loss: 0.011283
Average total loss: 0.080572
tensor(0.0983, device='cuda:0') tensor(0.1188, device='cuda:0') tensor(-8.5573e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.064439
Average KL loss: 0.011287
Average total loss: 0.075726
tensor(0.0983, device='cuda:0') tensor(0.1188, device='cuda:0') tensor(-6.5218e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.067701
Average KL loss: 0.011290
Average total loss: 0.078992
tensor(0.0983, device='cuda:0') tensor(0.1189, device='cuda:0') tensor(-9.1813e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.066666
Average KL loss: 0.011295
Average total loss: 0.077961
tensor(0.0983, device='cuda:0') tensor(0.1190, device='cuda:0') tensor(-7.8568e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.065116
Average KL loss: 0.011299
Average total loss: 0.076416
tensor(0.0983, device='cuda:0') tensor(0.1191, device='cuda:0') tensor(-9.8458e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.065955
Average KL loss: 0.011303
Average total loss: 0.077257
tensor(0.0983, device='cuda:0') tensor(0.1191, device='cuda:0') tensor(-6.4237e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.064775
Average KL loss: 0.011307
Average total loss: 0.076082
tensor(0.0983, device='cuda:0') tensor(0.1192, device='cuda:0') tensor(-6.3974e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.065499
Average KL loss: 0.011311
Average total loss: 0.076810
tensor(0.0983, device='cuda:0') tensor(0.1193, device='cuda:0') tensor(-7.8681e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.064625
Average KL loss: 0.011314
Average total loss: 0.075939
tensor(0.0983, device='cuda:0') tensor(0.1194, device='cuda:0') tensor(-5.3655e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.067533
Average KL loss: 0.011318
Average total loss: 0.078851
tensor(0.0983, device='cuda:0') tensor(0.1195, device='cuda:0') tensor(-7.6231e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.063959
Average KL loss: 0.011322
Average total loss: 0.075280
tensor(0.0982, device='cuda:0') tensor(0.1195, device='cuda:0') tensor(-6.7743e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.065156
Average KL loss: 0.011325
Average total loss: 0.076481
tensor(0.0982, device='cuda:0') tensor(0.1196, device='cuda:0') tensor(-8.9443e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.063480
Average KL loss: 0.011329
Average total loss: 0.074810
tensor(0.0982, device='cuda:0') tensor(0.1197, device='cuda:0') tensor(-8.7331e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.062823
Average KL loss: 0.011333
Average total loss: 0.074156
tensor(0.0982, device='cuda:0') tensor(0.1198, device='cuda:0') tensor(-7.3771e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.065221
Average KL loss: 0.011337
Average total loss: 0.076558
tensor(0.0982, device='cuda:0') tensor(0.1198, device='cuda:0') tensor(-7.5243e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.063633
Average KL loss: 0.011341
Average total loss: 0.074974
tensor(0.0982, device='cuda:0') tensor(0.1199, device='cuda:0') tensor(-9.6087e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.065492
Average KL loss: 0.011345
Average total loss: 0.076837
tensor(0.0982, device='cuda:0') tensor(0.1200, device='cuda:0') tensor(-9.4064e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.064369
Average KL loss: 0.011349
Average total loss: 0.075718
tensor(0.0982, device='cuda:0') tensor(0.1201, device='cuda:0') tensor(-8.3484e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.066235
Average KL loss: 0.011354
Average total loss: 0.077589
tensor(0.0982, device='cuda:0') tensor(0.1202, device='cuda:0') tensor(-6.4563e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.065037
Average KL loss: 0.011358
Average total loss: 0.076395
tensor(0.0982, device='cuda:0') tensor(0.1202, device='cuda:0') tensor(-1.3859e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.062781
Average KL loss: 0.011362
Average total loss: 0.074143
tensor(0.0982, device='cuda:0') tensor(0.1203, device='cuda:0') tensor(-5.7184e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.062203
Average KL loss: 0.011366
Average total loss: 0.073569
tensor(0.0982, device='cuda:0') tensor(0.1204, device='cuda:0') tensor(-6.9467e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.061551
Average KL loss: 0.011370
Average total loss: 0.072921
tensor(0.0982, device='cuda:0') tensor(0.1205, device='cuda:0') tensor(-7.7402e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.061974
Average KL loss: 0.011374
Average total loss: 0.073348
tensor(0.0981, device='cuda:0') tensor(0.1206, device='cuda:0') tensor(-5.7921e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.060009
Average KL loss: 0.011378
Average total loss: 0.071387
tensor(0.0981, device='cuda:0') tensor(0.1206, device='cuda:0') tensor(-4.3995e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.060761
Average KL loss: 0.011382
Average total loss: 0.072143
tensor(0.0981, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-4.9637e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.061002
Average KL loss: 0.011386
Average total loss: 0.072388
tensor(0.0981, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-5.7669e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.059515
Average KL loss: 0.011389
Average total loss: 0.070904
tensor(0.0981, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-7.1960e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.061407
Average KL loss: 0.011394
Average total loss: 0.072801
tensor(0.0981, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-5.5111e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.059108
Average KL loss: 0.011398
Average total loss: 0.070506
tensor(0.0981, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-8.0067e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.060089
Average KL loss: 0.011401
Average total loss: 0.071491
tensor(0.0981, device='cuda:0') tensor(0.1211, device='cuda:0') tensor(-6.7210e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.058726
Average KL loss: 0.011405
Average total loss: 0.070131
tensor(0.0981, device='cuda:0') tensor(0.1212, device='cuda:0') tensor(-5.9955e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.058100
Average KL loss: 0.011408
Average total loss: 0.069508
tensor(0.0981, device='cuda:0') tensor(0.1212, device='cuda:0') tensor(-1.2056e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.061255
Average KL loss: 0.011412
Average total loss: 0.072667
tensor(0.0981, device='cuda:0') tensor(0.1213, device='cuda:0') tensor(-4.7226e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.059756
Average KL loss: 0.011416
Average total loss: 0.071172
tensor(0.0981, device='cuda:0') tensor(0.1214, device='cuda:0') tensor(-4.7892e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.060158
Average KL loss: 0.011420
Average total loss: 0.071578
tensor(0.0981, device='cuda:0') tensor(0.1215, device='cuda:0') tensor(-5.5563e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.059095
Average KL loss: 0.011424
Average total loss: 0.070519
tensor(0.0980, device='cuda:0') tensor(0.1216, device='cuda:0') tensor(-5.4315e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.057644
Average KL loss: 0.011428
Average total loss: 0.069072
tensor(0.0980, device='cuda:0') tensor(0.1216, device='cuda:0') tensor(-5.0218e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.060235
Average KL loss: 0.011432
Average total loss: 0.071667
tensor(0.0980, device='cuda:0') tensor(0.1217, device='cuda:0') tensor(-7.6836e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.061429
Average KL loss: 0.011436
Average total loss: 0.072865
tensor(0.0980, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-5.4355e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.059767
Average KL loss: 0.011441
Average total loss: 0.071208
tensor(0.0980, device='cuda:0') tensor(0.1219, device='cuda:0') tensor(-5.3161e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.059072
Average KL loss: 0.011444
Average total loss: 0.070516
tensor(0.0980, device='cuda:0') tensor(0.1220, device='cuda:0') tensor(-5.3479e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.057721
Average KL loss: 0.011448
Average total loss: 0.069169
tensor(0.0980, device='cuda:0') tensor(0.1220, device='cuda:0') tensor(-4.5782e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.055959
Average KL loss: 0.011452
Average total loss: 0.067410
tensor(0.0980, device='cuda:0') tensor(0.1221, device='cuda:0') tensor(-7.3675e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.056003
Average KL loss: 0.011455
Average total loss: 0.067458
tensor(0.0980, device='cuda:0') tensor(0.1222, device='cuda:0') tensor(-7.2475e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.057001
Average KL loss: 0.011458
Average total loss: 0.068459
tensor(0.0980, device='cuda:0') tensor(0.1223, device='cuda:0') tensor(-5.8170e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.057206
Average KL loss: 0.011462
Average total loss: 0.068669
tensor(0.0980, device='cuda:0') tensor(0.1223, device='cuda:0') tensor(-6.1912e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.057777
Average KL loss: 0.011466
Average total loss: 0.069243
tensor(0.0980, device='cuda:0') tensor(0.1224, device='cuda:0') tensor(-3.9206e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.057527
Average KL loss: 0.011469
Average total loss: 0.068997
tensor(0.0979, device='cuda:0') tensor(0.1225, device='cuda:0') tensor(-3.6513e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.055331
Average KL loss: 0.011473
Average total loss: 0.066804
tensor(0.0979, device='cuda:0') tensor(0.1226, device='cuda:0') tensor(-4.4768e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.054512
Average KL loss: 0.011476
Average total loss: 0.065988
tensor(0.0979, device='cuda:0') tensor(0.1226, device='cuda:0') tensor(-5.8241e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.055683
Average KL loss: 0.011479
Average total loss: 0.067162
tensor(0.0979, device='cuda:0') tensor(0.1227, device='cuda:0') tensor(-3.7509e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.057243
Average KL loss: 0.011483
Average total loss: 0.068726
tensor(0.0979, device='cuda:0') tensor(0.1228, device='cuda:0') tensor(-4.1810e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.057524
Average KL loss: 0.011487
Average total loss: 0.069011
tensor(0.0979, device='cuda:0') tensor(0.1229, device='cuda:0') tensor(-6.4271e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.055154
Average KL loss: 0.011491
Average total loss: 0.066645
tensor(0.0979, device='cuda:0') tensor(0.1230, device='cuda:0') tensor(-7.9664e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.054744
Average KL loss: 0.011494
Average total loss: 0.066238
tensor(0.0979, device='cuda:0') tensor(0.1230, device='cuda:0') tensor(-4.4791e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.054086
Average KL loss: 0.011498
Average total loss: 0.065584
tensor(0.0979, device='cuda:0') tensor(0.1231, device='cuda:0') tensor(-7.7281e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.052820
Average KL loss: 0.011501
Average total loss: 0.064322
tensor(0.0979, device='cuda:0') tensor(0.1232, device='cuda:0') tensor(-5.1474e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.053979
Average KL loss: 0.011504
Average total loss: 0.065483
tensor(0.0978, device='cuda:0') tensor(0.1232, device='cuda:0') tensor(-4.8203e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.054693
Average KL loss: 0.011507
Average total loss: 0.066200
tensor(0.0978, device='cuda:0') tensor(0.1233, device='cuda:0') tensor(-5.0403e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.056723
Average KL loss: 0.011511
Average total loss: 0.068234
tensor(0.0978, device='cuda:0') tensor(0.1234, device='cuda:0') tensor(-5.4678e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.054233
Average KL loss: 0.011514
Average total loss: 0.065747
tensor(0.0978, device='cuda:0') tensor(0.1235, device='cuda:0') tensor(-5.3396e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.053784
Average KL loss: 0.011518
Average total loss: 0.065302
tensor(0.0978, device='cuda:0') tensor(0.1235, device='cuda:0') tensor(-4.8084e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.055026
Average KL loss: 0.011521
Average total loss: 0.066547
tensor(0.0978, device='cuda:0') tensor(0.1236, device='cuda:0') tensor(-3.0543e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.054566
Average KL loss: 0.011525
Average total loss: 0.066092
tensor(0.0978, device='cuda:0') tensor(0.1237, device='cuda:0') tensor(-6.8256e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.055795
Average KL loss: 0.011529
Average total loss: 0.067325
tensor(0.0978, device='cuda:0') tensor(0.1238, device='cuda:0') tensor(-4.8481e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.053991
Average KL loss: 0.011533
Average total loss: 0.065524
tensor(0.0978, device='cuda:0') tensor(0.1239, device='cuda:0') tensor(-5.1830e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.053272
Average KL loss: 0.011537
Average total loss: 0.064808
tensor(0.0978, device='cuda:0') tensor(0.1239, device='cuda:0') tensor(-4.8180e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.055654
Average KL loss: 0.011540
Average total loss: 0.067194
tensor(0.0978, device='cuda:0') tensor(0.1240, device='cuda:0') tensor(-5.6801e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.054372
Average KL loss: 0.011542
Average total loss: 0.065915
tensor(0.0978, device='cuda:0') tensor(0.1240, device='cuda:0') tensor(-4.0032e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.053821
Average KL loss: 0.011543
Average total loss: 0.065364
tensor(0.0978, device='cuda:0') tensor(0.1240, device='cuda:0') tensor(-4.9959e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.055638
Average KL loss: 0.011543
Average total loss: 0.067181
tensor(0.0978, device='cuda:0') tensor(0.1240, device='cuda:0') tensor(-5.6001e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.053000
Average KL loss: 0.011543
Average total loss: 0.064543
tensor(0.0978, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-6.4499e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.052863
Average KL loss: 0.011544
Average total loss: 0.064407
tensor(0.0978, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-3.9311e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.053575
Average KL loss: 0.011544
Average total loss: 0.065119
tensor(0.0978, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-5.3008e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.052483
Average KL loss: 0.011544
Average total loss: 0.064027
tensor(0.0978, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-5.5323e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.051297
Average KL loss: 0.011545
Average total loss: 0.062841
tensor(0.0978, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-5.5685e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.051557
Average KL loss: 0.011545
Average total loss: 0.063102
tensor(0.0978, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-5.7020e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.054735
Average KL loss: 0.011545
Average total loss: 0.066280
tensor(0.0978, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-4.4787e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.052372
Average KL loss: 0.011545
Average total loss: 0.063917
tensor(0.0978, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-5.7252e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.053239
Average KL loss: 0.011546
Average total loss: 0.064785
tensor(0.0978, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-6.5114e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.053892
Average KL loss: 0.011546
Average total loss: 0.065438
tensor(0.0978, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-3.6893e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.051958
Average KL loss: 0.011546
Average total loss: 0.063505
tensor(0.0978, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-6.5397e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.053278
Average KL loss: 0.011547
Average total loss: 0.064824
tensor(0.0978, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-4.7476e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.051443
Average KL loss: 0.011547
Average total loss: 0.062990
tensor(0.0978, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-5.3829e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.051605
Average KL loss: 0.011547
Average total loss: 0.063152
tensor(0.0978, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-4.6974e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.056588
Average KL loss: 0.011547
Average total loss: 0.068135
tensor(0.0978, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-6.0732e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.053518
Average KL loss: 0.011548
Average total loss: 0.065066
tensor(0.0978, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-4.6303e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.052907
Average KL loss: 0.011548
Average total loss: 0.064455
tensor(0.0978, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-6.0719e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.053084
Average KL loss: 0.011548
Average total loss: 0.064632
tensor(0.0978, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-3.6567e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.054283
Average KL loss: 0.011548
Average total loss: 0.065831
tensor(0.0978, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-4.9721e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.052446
Average KL loss: 0.011548
Average total loss: 0.063994
tensor(0.0978, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-6.0715e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.055117
Average KL loss: 0.011548
Average total loss: 0.066665
tensor(0.0978, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-4.0655e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.053897
Average KL loss: 0.011548
Average total loss: 0.065446
tensor(0.0978, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-4.8545e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.052586
Average KL loss: 0.011548
Average total loss: 0.064134
tensor(0.0978, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-5.4553e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.054245
Average KL loss: 0.011548
Average total loss: 0.065793
tensor(0.0978, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-6.2411e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.052703
Average KL loss: 0.011548
Average total loss: 0.064251
tensor(0.0978, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-5.1701e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.052635
Average KL loss: 0.011548
Average total loss: 0.064183
tensor(0.0978, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-5.3310e-09, device='cuda:0')
 Percentile value: 0.0001840359152993192
Non-zero model percentage: 26.214414596557617%, Non-zero mask percentage: 26.214414596557617%

--- Pruning Level [6/24]: ---
conv1.weight         | nonzeros =     400 /    1728             ( 23.15%) | total_pruned =    1328 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.weight           | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
bn1.bias             | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    4557 /   36864             ( 12.36%) | total_pruned =   32307 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    5386 /   36864             ( 14.61%) | total_pruned =   31478 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    5298 /   36864             ( 14.37%) | total_pruned =   31566 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    6400 /   36864             ( 17.36%) | total_pruned =   30464 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   19087 /   73728             ( 25.89%) | total_pruned =   54641 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   39328 /  147456             ( 26.67%) | total_pruned =  108128 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2706 /    8192             ( 33.03%) | total_pruned =    5486 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   31071 /  147456             ( 21.07%) | total_pruned =  116385 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   29211 /  147456             ( 19.81%) | total_pruned =  118245 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   96378 /  294912             ( 32.68%) | total_pruned =  198534 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      50 /     256             ( 19.53%) | total_pruned =     206 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  174521 /  589824             ( 29.59%) | total_pruned =  415303 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      31 /     256             ( 12.11%) | total_pruned =     225 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   11582 /   32768             ( 35.35%) | total_pruned =   21186 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      28 /     256             ( 10.94%) | total_pruned =     228 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  122722 /  589824             ( 20.81%) | total_pruned =  467102 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      54 /     256             ( 21.09%) | total_pruned =     202 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   96949 /  589824             ( 16.44%) | total_pruned =  492875 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      39 /     256             ( 15.23%) | total_pruned =     217 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     236 /     256             ( 92.19%) | total_pruned =      20 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  305945 / 1179648             ( 25.94%) | total_pruned =  873703 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      82 /     512             ( 16.02%) | total_pruned =     430 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     475 /     512             ( 92.77%) | total_pruned =      37 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      50 /     512             (  9.77%) | total_pruned =     462 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  459067 / 2359296             ( 19.46%) | total_pruned = 1900229 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     100 /     512             ( 19.53%) | total_pruned =     412 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     470 /     512             ( 91.80%) | total_pruned =      42 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     269 /     512             ( 52.54%) | total_pruned =     243 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   21923 /  131072             ( 16.73%) | total_pruned =  109149 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     100 /     512             ( 19.53%) | total_pruned =     412 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     362 /     512             ( 70.70%) | total_pruned =     150 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     268 /     512             ( 52.34%) | total_pruned =     244 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  434175 / 2359296             ( 18.40%) | total_pruned = 1925121 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      88 /     512             ( 17.19%) | total_pruned =     424 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     385 /     512             ( 75.20%) | total_pruned =     127 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1053036 / 2359296             ( 44.63%) | total_pruned = 1306260 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     102 /     512             ( 19.92%) | total_pruned =     410 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     476 /     512             ( 92.97%) | total_pruned =      36 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     461 /     512             ( 90.04%) | total_pruned =      51 | shape = torch.Size([512])
linear.weight        | nonzeros =    4533 /    5120             ( 88.54%) | total_pruned =     587 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 2930447, pruned : 8248315, total: 11178762, Compression rate :       3.81x  ( 73.79% pruned)
Train Epoch: 35/100 Loss: 0.018705 Accuracy: 88.46 100.00 % Best test Accuracy: 88.46%
tensor(0.0978, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-1.5505e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.123953
Average KL loss: 0.011498
Average total loss: 0.135452
tensor(0.0974, device='cuda:0') tensor(0.1232, device='cuda:0') tensor(-1.1793e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.122938
Average KL loss: 0.011435
Average total loss: 0.134373
tensor(0.0972, device='cuda:0') tensor(0.1226, device='cuda:0') tensor(-1.2422e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.120020
Average KL loss: 0.011381
Average total loss: 0.131401
tensor(0.0970, device='cuda:0') tensor(0.1221, device='cuda:0') tensor(-1.4626e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.120123
Average KL loss: 0.011330
Average total loss: 0.131453
tensor(0.0969, device='cuda:0') tensor(0.1217, device='cuda:0') tensor(-1.1906e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.122137
Average KL loss: 0.011283
Average total loss: 0.133420
tensor(0.0967, device='cuda:0') tensor(0.1212, device='cuda:0') tensor(-1.0161e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.117705
Average KL loss: 0.011238
Average total loss: 0.128943
tensor(0.0965, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-1.1285e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.115283
Average KL loss: 0.011197
Average total loss: 0.126479
tensor(0.0963, device='cuda:0') tensor(0.1204, device='cuda:0') tensor(-1.7224e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.118170
Average KL loss: 0.011157
Average total loss: 0.129328
tensor(0.0962, device='cuda:0') tensor(0.1201, device='cuda:0') tensor(-1.2958e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.116339
Average KL loss: 0.011120
Average total loss: 0.127459
tensor(0.0960, device='cuda:0') tensor(0.1197, device='cuda:0') tensor(-1.2773e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.113512
Average KL loss: 0.011085
Average total loss: 0.124597
tensor(0.0958, device='cuda:0') tensor(0.1194, device='cuda:0') tensor(-1.1109e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.109237
Average KL loss: 0.011052
Average total loss: 0.120289
tensor(0.0957, device='cuda:0') tensor(0.1191, device='cuda:0') tensor(-1.2097e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.109630
Average KL loss: 0.011020
Average total loss: 0.120650
tensor(0.0955, device='cuda:0') tensor(0.1188, device='cuda:0') tensor(-1.2611e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.112318
Average KL loss: 0.010990
Average total loss: 0.123309
tensor(0.0953, device='cuda:0') tensor(0.1185, device='cuda:0') tensor(-1.2681e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.112550
Average KL loss: 0.010962
Average total loss: 0.123513
tensor(0.0952, device='cuda:0') tensor(0.1183, device='cuda:0') tensor(-1.0899e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.109405
Average KL loss: 0.010935
Average total loss: 0.120340
tensor(0.0950, device='cuda:0') tensor(0.1181, device='cuda:0') tensor(-9.7843e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.108348
Average KL loss: 0.010910
Average total loss: 0.119258
tensor(0.0948, device='cuda:0') tensor(0.1178, device='cuda:0') tensor(-1.2023e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.105490
Average KL loss: 0.010886
Average total loss: 0.116375
tensor(0.0947, device='cuda:0') tensor(0.1176, device='cuda:0') tensor(-1.4071e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.106121
Average KL loss: 0.010863
Average total loss: 0.116984
tensor(0.0945, device='cuda:0') tensor(0.1174, device='cuda:0') tensor(-2.0390e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.107000
Average KL loss: 0.010841
Average total loss: 0.117840
tensor(0.0944, device='cuda:0') tensor(0.1172, device='cuda:0') tensor(-1.0866e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.104496
Average KL loss: 0.010820
Average total loss: 0.115316
tensor(0.0942, device='cuda:0') tensor(0.1170, device='cuda:0') tensor(-1.2733e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.109392
Average KL loss: 0.010801
Average total loss: 0.120193
tensor(0.0941, device='cuda:0') tensor(0.1169, device='cuda:0') tensor(-1.2299e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.102188
Average KL loss: 0.010782
Average total loss: 0.112970
tensor(0.0940, device='cuda:0') tensor(0.1167, device='cuda:0') tensor(-1.0222e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.101883
Average KL loss: 0.010764
Average total loss: 0.112648
tensor(0.0938, device='cuda:0') tensor(0.1166, device='cuda:0') tensor(-8.5360e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.103983
Average KL loss: 0.010748
Average total loss: 0.114731
tensor(0.0937, device='cuda:0') tensor(0.1164, device='cuda:0') tensor(-7.2609e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.100437
Average KL loss: 0.010732
Average total loss: 0.111169
tensor(0.0936, device='cuda:0') tensor(0.1163, device='cuda:0') tensor(-1.0314e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.102881
Average KL loss: 0.010717
Average total loss: 0.113598
tensor(0.0934, device='cuda:0') tensor(0.1162, device='cuda:0') tensor(-9.4407e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.100699
Average KL loss: 0.010703
Average total loss: 0.111402
tensor(0.0933, device='cuda:0') tensor(0.1161, device='cuda:0') tensor(-1.7969e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.099458
Average KL loss: 0.010690
Average total loss: 0.110148
tensor(0.0932, device='cuda:0') tensor(0.1160, device='cuda:0') tensor(-1.2223e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.106064
Average KL loss: 0.010677
Average total loss: 0.116741
tensor(0.0931, device='cuda:0') tensor(0.1159, device='cuda:0') tensor(-1.0599e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.101303
Average KL loss: 0.010666
Average total loss: 0.111969
tensor(0.0930, device='cuda:0') tensor(0.1158, device='cuda:0') tensor(-9.0136e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.099108
Average KL loss: 0.010655
Average total loss: 0.109763
tensor(0.0929, device='cuda:0') tensor(0.1157, device='cuda:0') tensor(-1.0605e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.098375
Average KL loss: 0.010644
Average total loss: 0.109020
tensor(0.0928, device='cuda:0') tensor(0.1156, device='cuda:0') tensor(-8.9101e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.097661
Average KL loss: 0.010634
Average total loss: 0.108295
tensor(0.0927, device='cuda:0') tensor(0.1155, device='cuda:0') tensor(-1.2933e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.099051
Average KL loss: 0.010624
Average total loss: 0.109675
tensor(0.0926, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-1.3494e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.097168
Average KL loss: 0.010616
Average total loss: 0.107783
tensor(0.0925, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-1.2640e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.096699
Average KL loss: 0.010608
Average total loss: 0.107307
tensor(0.0924, device='cuda:0') tensor(0.1153, device='cuda:0') tensor(-9.2381e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.095225
Average KL loss: 0.010600
Average total loss: 0.105825
tensor(0.0923, device='cuda:0') tensor(0.1153, device='cuda:0') tensor(-1.1466e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.097406
Average KL loss: 0.010592
Average total loss: 0.107997
tensor(0.0922, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-1.0686e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.099551
Average KL loss: 0.010585
Average total loss: 0.110137
tensor(0.0921, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-1.1249e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.100202
Average KL loss: 0.010580
Average total loss: 0.110782
tensor(0.0921, device='cuda:0') tensor(0.1151, device='cuda:0') tensor(-7.4158e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.094401
Average KL loss: 0.010574
Average total loss: 0.104975
tensor(0.0920, device='cuda:0') tensor(0.1151, device='cuda:0') tensor(-8.2318e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.096374
Average KL loss: 0.010569
Average total loss: 0.106943
tensor(0.0919, device='cuda:0') tensor(0.1151, device='cuda:0') tensor(-1.1598e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.097633
Average KL loss: 0.010564
Average total loss: 0.108196
tensor(0.0918, device='cuda:0') tensor(0.1150, device='cuda:0') tensor(-9.2465e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.094182
Average KL loss: 0.010559
Average total loss: 0.104741
tensor(0.0918, device='cuda:0') tensor(0.1150, device='cuda:0') tensor(-8.2290e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.093676
Average KL loss: 0.010554
Average total loss: 0.104230
tensor(0.0917, device='cuda:0') tensor(0.1150, device='cuda:0') tensor(-8.5969e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.097610
Average KL loss: 0.010550
Average total loss: 0.108160
tensor(0.0916, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-1.1886e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.094846
Average KL loss: 0.010547
Average total loss: 0.105393
tensor(0.0916, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-1.1128e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.093383
Average KL loss: 0.010543
Average total loss: 0.103927
tensor(0.0915, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-7.1306e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.093341
Average KL loss: 0.010540
Average total loss: 0.103881
tensor(0.0915, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-8.5258e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.090843
Average KL loss: 0.010537
Average total loss: 0.101380
tensor(0.0914, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-1.1595e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.089766
Average KL loss: 0.010534
Average total loss: 0.100300
tensor(0.0913, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-9.1831e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.091040
Average KL loss: 0.010532
Average total loss: 0.101572
tensor(0.0913, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-6.3351e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.091299
Average KL loss: 0.010530
Average total loss: 0.101829
tensor(0.0912, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-8.9930e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.090629
Average KL loss: 0.010528
Average total loss: 0.101157
tensor(0.0912, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-1.0416e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.091529
Average KL loss: 0.010526
Average total loss: 0.102055
tensor(0.0911, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-1.1078e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.089810
Average KL loss: 0.010525
Average total loss: 0.100334
tensor(0.0911, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-8.5560e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.090726
Average KL loss: 0.010524
Average total loss: 0.101250
tensor(0.0911, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-1.0163e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.087767
Average KL loss: 0.010523
Average total loss: 0.098290
tensor(0.0910, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-9.0381e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.089172
Average KL loss: 0.010522
Average total loss: 0.099694
tensor(0.0910, device='cuda:0') tensor(0.1149, device='cuda:0') tensor(-8.1415e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.088076
Average KL loss: 0.010522
Average total loss: 0.098598
tensor(0.0909, device='cuda:0') tensor(0.1150, device='cuda:0') tensor(-7.4645e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.089280
Average KL loss: 0.010521
Average total loss: 0.099801
tensor(0.0909, device='cuda:0') tensor(0.1150, device='cuda:0') tensor(-8.3453e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.087771
Average KL loss: 0.010521
Average total loss: 0.098292
tensor(0.0909, device='cuda:0') tensor(0.1150, device='cuda:0') tensor(-1.1626e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.087377
Average KL loss: 0.010521
Average total loss: 0.097898
tensor(0.0908, device='cuda:0') tensor(0.1150, device='cuda:0') tensor(-7.6209e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.088149
Average KL loss: 0.010521
Average total loss: 0.098670
tensor(0.0908, device='cuda:0') tensor(0.1150, device='cuda:0') tensor(-9.9772e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.089132
Average KL loss: 0.010521
Average total loss: 0.099653
tensor(0.0908, device='cuda:0') tensor(0.1151, device='cuda:0') tensor(-9.6590e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.089792
Average KL loss: 0.010522
Average total loss: 0.100313
tensor(0.0907, device='cuda:0') tensor(0.1151, device='cuda:0') tensor(-1.1598e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.085763
Average KL loss: 0.010522
Average total loss: 0.096285
tensor(0.0907, device='cuda:0') tensor(0.1151, device='cuda:0') tensor(-9.9277e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.085971
Average KL loss: 0.010523
Average total loss: 0.096494
tensor(0.0907, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-8.1981e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.084668
Average KL loss: 0.010524
Average total loss: 0.095192
tensor(0.0906, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-9.1671e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.085766
Average KL loss: 0.010524
Average total loss: 0.096289
tensor(0.0906, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-7.0484e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.084313
Average KL loss: 0.010524
Average total loss: 0.094837
tensor(0.0906, device='cuda:0') tensor(0.1152, device='cuda:0') tensor(-1.0307e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.086570
Average KL loss: 0.010525
Average total loss: 0.097096
tensor(0.0906, device='cuda:0') tensor(0.1153, device='cuda:0') tensor(-6.6879e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.084920
Average KL loss: 0.010527
Average total loss: 0.095448
tensor(0.0905, device='cuda:0') tensor(0.1153, device='cuda:0') tensor(-9.2751e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.086290
Average KL loss: 0.010529
Average total loss: 0.096818
tensor(0.0905, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-1.1000e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.086016
Average KL loss: 0.010530
Average total loss: 0.096546
tensor(0.0905, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-6.5666e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.084361
Average KL loss: 0.010532
Average total loss: 0.094893
tensor(0.0905, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-7.4831e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.084826
Average KL loss: 0.010534
Average total loss: 0.095360
tensor(0.0905, device='cuda:0') tensor(0.1155, device='cuda:0') tensor(-8.8037e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.083058
Average KL loss: 0.010536
Average total loss: 0.093594
tensor(0.0904, device='cuda:0') tensor(0.1155, device='cuda:0') tensor(-6.6796e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.086114
Average KL loss: 0.010538
Average total loss: 0.096652
tensor(0.0904, device='cuda:0') tensor(0.1156, device='cuda:0') tensor(-8.2345e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.083080
Average KL loss: 0.010540
Average total loss: 0.093620
tensor(0.0904, device='cuda:0') tensor(0.1156, device='cuda:0') tensor(-6.9916e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.082216
Average KL loss: 0.010542
Average total loss: 0.092758
tensor(0.0904, device='cuda:0') tensor(0.1157, device='cuda:0') tensor(-5.9892e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.082816
Average KL loss: 0.010544
Average total loss: 0.093359
tensor(0.0904, device='cuda:0') tensor(0.1157, device='cuda:0') tensor(-8.5121e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.083693
Average KL loss: 0.010545
Average total loss: 0.094238
tensor(0.0903, device='cuda:0') tensor(0.1158, device='cuda:0') tensor(-7.2116e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.083681
Average KL loss: 0.010547
Average total loss: 0.094228
tensor(0.0903, device='cuda:0') tensor(0.1158, device='cuda:0') tensor(-6.7875e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.084164
Average KL loss: 0.010550
Average total loss: 0.094714
tensor(0.0903, device='cuda:0') tensor(0.1159, device='cuda:0') tensor(-9.2192e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.083490
Average KL loss: 0.010553
Average total loss: 0.094043
tensor(0.0903, device='cuda:0') tensor(0.1159, device='cuda:0') tensor(-7.8357e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.081430
Average KL loss: 0.010555
Average total loss: 0.091986
tensor(0.0903, device='cuda:0') tensor(0.1160, device='cuda:0') tensor(-9.4349e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.080304
Average KL loss: 0.010558
Average total loss: 0.090862
tensor(0.0903, device='cuda:0') tensor(0.1160, device='cuda:0') tensor(-7.7646e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.081018
Average KL loss: 0.010561
Average total loss: 0.091579
tensor(0.0903, device='cuda:0') tensor(0.1161, device='cuda:0') tensor(-6.0283e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.080094
Average KL loss: 0.010563
Average total loss: 0.090657
tensor(0.0902, device='cuda:0') tensor(0.1161, device='cuda:0') tensor(-6.8075e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.084397
Average KL loss: 0.010565
Average total loss: 0.094963
tensor(0.0902, device='cuda:0') tensor(0.1162, device='cuda:0') tensor(-8.7376e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.080277
Average KL loss: 0.010568
Average total loss: 0.090845
tensor(0.0902, device='cuda:0') tensor(0.1162, device='cuda:0') tensor(-8.0149e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.081429
Average KL loss: 0.010571
Average total loss: 0.092000
tensor(0.0902, device='cuda:0') tensor(0.1163, device='cuda:0') tensor(-9.6640e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.080507
Average KL loss: 0.010573
Average total loss: 0.091080
tensor(0.0902, device='cuda:0') tensor(0.1163, device='cuda:0') tensor(-8.4916e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.081393
Average KL loss: 0.010576
Average total loss: 0.091969
tensor(0.0902, device='cuda:0') tensor(0.1164, device='cuda:0') tensor(-8.4783e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.080638
Average KL loss: 0.010579
Average total loss: 0.091217
tensor(0.0902, device='cuda:0') tensor(0.1165, device='cuda:0') tensor(-9.8112e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.080251
Average KL loss: 0.010582
Average total loss: 0.090833
tensor(0.0902, device='cuda:0') tensor(0.1165, device='cuda:0') tensor(-5.9154e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.078879
Average KL loss: 0.010585
Average total loss: 0.089464
tensor(0.0902, device='cuda:0') tensor(0.1166, device='cuda:0') tensor(-8.0151e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.079056
Average KL loss: 0.010588
Average total loss: 0.089644
tensor(0.0902, device='cuda:0') tensor(0.1166, device='cuda:0') tensor(-9.7792e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.082292
Average KL loss: 0.010592
Average total loss: 0.092884
tensor(0.0902, device='cuda:0') tensor(0.1167, device='cuda:0') tensor(-8.7964e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.078740
Average KL loss: 0.010596
Average total loss: 0.089335
tensor(0.0901, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-7.0220e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.077693
Average KL loss: 0.010599
Average total loss: 0.088292
tensor(0.0901, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-7.1499e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.079511
Average KL loss: 0.010601
Average total loss: 0.090113
tensor(0.0901, device='cuda:0') tensor(0.1169, device='cuda:0') tensor(-6.5877e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.078375
Average KL loss: 0.010605
Average total loss: 0.088980
tensor(0.0901, device='cuda:0') tensor(0.1169, device='cuda:0') tensor(-6.3781e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.078055
Average KL loss: 0.010608
Average total loss: 0.088663
tensor(0.0901, device='cuda:0') tensor(0.1170, device='cuda:0') tensor(-6.9051e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.078686
Average KL loss: 0.010612
Average total loss: 0.089297
tensor(0.0901, device='cuda:0') tensor(0.1171, device='cuda:0') tensor(-5.0915e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.074553
Average KL loss: 0.010615
Average total loss: 0.085168
tensor(0.0901, device='cuda:0') tensor(0.1171, device='cuda:0') tensor(-6.8757e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.075753
Average KL loss: 0.010618
Average total loss: 0.086371
tensor(0.0901, device='cuda:0') tensor(0.1172, device='cuda:0') tensor(-6.8395e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.075393
Average KL loss: 0.010621
Average total loss: 0.086014
tensor(0.0901, device='cuda:0') tensor(0.1172, device='cuda:0') tensor(-6.9011e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.074812
Average KL loss: 0.010624
Average total loss: 0.085436
tensor(0.0901, device='cuda:0') tensor(0.1173, device='cuda:0') tensor(-7.1427e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.080255
Average KL loss: 0.010627
Average total loss: 0.090881
tensor(0.0901, device='cuda:0') tensor(0.1174, device='cuda:0') tensor(-8.2371e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.074164
Average KL loss: 0.010631
Average total loss: 0.084794
tensor(0.0901, device='cuda:0') tensor(0.1174, device='cuda:0') tensor(-5.2056e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.076116
Average KL loss: 0.010633
Average total loss: 0.086750
tensor(0.0901, device='cuda:0') tensor(0.1175, device='cuda:0') tensor(-9.0077e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.077517
Average KL loss: 0.010637
Average total loss: 0.088154
tensor(0.0900, device='cuda:0') tensor(0.1176, device='cuda:0') tensor(-5.3023e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.074919
Average KL loss: 0.010640
Average total loss: 0.085559
tensor(0.0900, device='cuda:0') tensor(0.1176, device='cuda:0') tensor(-6.4512e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.075017
Average KL loss: 0.010643
Average total loss: 0.085661
tensor(0.0900, device='cuda:0') tensor(0.1177, device='cuda:0') tensor(-7.7994e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.074922
Average KL loss: 0.010647
Average total loss: 0.085569
tensor(0.0900, device='cuda:0') tensor(0.1178, device='cuda:0') tensor(-9.7762e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.075298
Average KL loss: 0.010650
Average total loss: 0.085949
tensor(0.0900, device='cuda:0') tensor(0.1178, device='cuda:0') tensor(-9.9107e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.073956
Average KL loss: 0.010653
Average total loss: 0.084610
tensor(0.0900, device='cuda:0') tensor(0.1179, device='cuda:0') tensor(-7.1591e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.074125
Average KL loss: 0.010657
Average total loss: 0.084782
tensor(0.0900, device='cuda:0') tensor(0.1180, device='cuda:0') tensor(-6.9175e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.074932
Average KL loss: 0.010661
Average total loss: 0.085593
tensor(0.0900, device='cuda:0') tensor(0.1180, device='cuda:0') tensor(-8.0311e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.076081
Average KL loss: 0.010665
Average total loss: 0.086746
tensor(0.0900, device='cuda:0') tensor(0.1181, device='cuda:0') tensor(-7.4293e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.073666
Average KL loss: 0.010668
Average total loss: 0.084334
tensor(0.0900, device='cuda:0') tensor(0.1182, device='cuda:0') tensor(-4.4457e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.072053
Average KL loss: 0.010672
Average total loss: 0.082725
tensor(0.0900, device='cuda:0') tensor(0.1182, device='cuda:0') tensor(-5.6316e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.073110
Average KL loss: 0.010676
Average total loss: 0.083786
tensor(0.0900, device='cuda:0') tensor(0.1183, device='cuda:0') tensor(-6.0062e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.072227
Average KL loss: 0.010679
Average total loss: 0.082907
tensor(0.0900, device='cuda:0') tensor(0.1184, device='cuda:0') tensor(-8.7248e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.073214
Average KL loss: 0.010683
Average total loss: 0.083897
tensor(0.0900, device='cuda:0') tensor(0.1184, device='cuda:0') tensor(-6.4510e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.072559
Average KL loss: 0.010687
Average total loss: 0.083246
tensor(0.0900, device='cuda:0') tensor(0.1185, device='cuda:0') tensor(-6.6598e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.073797
Average KL loss: 0.010692
Average total loss: 0.084489
tensor(0.0900, device='cuda:0') tensor(0.1186, device='cuda:0') tensor(-6.1820e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.071414
Average KL loss: 0.010696
Average total loss: 0.082110
tensor(0.0900, device='cuda:0') tensor(0.1187, device='cuda:0') tensor(-7.5522e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.073590
Average KL loss: 0.010699
Average total loss: 0.084289
tensor(0.0900, device='cuda:0') tensor(0.1187, device='cuda:0') tensor(-6.1578e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.071512
Average KL loss: 0.010702
Average total loss: 0.082215
tensor(0.0900, device='cuda:0') tensor(0.1188, device='cuda:0') tensor(-5.8804e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.071215
Average KL loss: 0.010706
Average total loss: 0.081920
tensor(0.0900, device='cuda:0') tensor(0.1189, device='cuda:0') tensor(-8.5386e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.071817
Average KL loss: 0.010709
Average total loss: 0.082526
tensor(0.0900, device='cuda:0') tensor(0.1189, device='cuda:0') tensor(-5.0254e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.071055
Average KL loss: 0.010713
Average total loss: 0.081767
tensor(0.0900, device='cuda:0') tensor(0.1190, device='cuda:0') tensor(-4.4036e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.074690
Average KL loss: 0.010717
Average total loss: 0.085407
tensor(0.0900, device='cuda:0') tensor(0.1191, device='cuda:0') tensor(-7.6454e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.072453
Average KL loss: 0.010722
Average total loss: 0.083175
tensor(0.0900, device='cuda:0') tensor(0.1191, device='cuda:0') tensor(-4.4736e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.070132
Average KL loss: 0.010725
Average total loss: 0.080857
tensor(0.0900, device='cuda:0') tensor(0.1192, device='cuda:0') tensor(-5.7034e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.072932
Average KL loss: 0.010729
Average total loss: 0.083661
tensor(0.0900, device='cuda:0') tensor(0.1193, device='cuda:0') tensor(-7.5216e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.070408
Average KL loss: 0.010733
Average total loss: 0.081141
tensor(0.0900, device='cuda:0') tensor(0.1194, device='cuda:0') tensor(-7.3582e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.069638
Average KL loss: 0.010737
Average total loss: 0.080374
tensor(0.0900, device='cuda:0') tensor(0.1194, device='cuda:0') tensor(-5.7771e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.072093
Average KL loss: 0.010741
Average total loss: 0.082834
tensor(0.0900, device='cuda:0') tensor(0.1195, device='cuda:0') tensor(-5.5160e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.069914
Average KL loss: 0.010745
Average total loss: 0.080659
tensor(0.0900, device='cuda:0') tensor(0.1196, device='cuda:0') tensor(-5.4431e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.069252
Average KL loss: 0.010748
Average total loss: 0.080001
tensor(0.0900, device='cuda:0') tensor(0.1196, device='cuda:0') tensor(-5.6983e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.073383
Average KL loss: 0.010752
Average total loss: 0.084135
tensor(0.0900, device='cuda:0') tensor(0.1197, device='cuda:0') tensor(-5.3462e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.069187
Average KL loss: 0.010756
Average total loss: 0.079943
tensor(0.0900, device='cuda:0') tensor(0.1198, device='cuda:0') tensor(-6.2649e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.068768
Average KL loss: 0.010760
Average total loss: 0.079528
tensor(0.0900, device='cuda:0') tensor(0.1199, device='cuda:0') tensor(-7.7591e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.068094
Average KL loss: 0.010763
Average total loss: 0.078857
tensor(0.0900, device='cuda:0') tensor(0.1199, device='cuda:0') tensor(-7.8612e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.071546
Average KL loss: 0.010767
Average total loss: 0.082313
tensor(0.0900, device='cuda:0') tensor(0.1200, device='cuda:0') tensor(-5.3654e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.068050
Average KL loss: 0.010771
Average total loss: 0.078821
tensor(0.0900, device='cuda:0') tensor(0.1201, device='cuda:0') tensor(-6.2771e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.069683
Average KL loss: 0.010775
Average total loss: 0.080458
tensor(0.0900, device='cuda:0') tensor(0.1202, device='cuda:0') tensor(-9.0252e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.068939
Average KL loss: 0.010780
Average total loss: 0.079718
tensor(0.0900, device='cuda:0') tensor(0.1202, device='cuda:0') tensor(-6.2370e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.069087
Average KL loss: 0.010784
Average total loss: 0.079870
tensor(0.0900, device='cuda:0') tensor(0.1203, device='cuda:0') tensor(-5.3955e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.067486
Average KL loss: 0.010788
Average total loss: 0.078274
tensor(0.0900, device='cuda:0') tensor(0.1204, device='cuda:0') tensor(-7.1865e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.070738
Average KL loss: 0.010791
Average total loss: 0.081529
tensor(0.0900, device='cuda:0') tensor(0.1204, device='cuda:0') tensor(-5.2126e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.068457
Average KL loss: 0.010795
Average total loss: 0.079252
tensor(0.0900, device='cuda:0') tensor(0.1205, device='cuda:0') tensor(-7.8152e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.067742
Average KL loss: 0.010799
Average total loss: 0.078541
tensor(0.0900, device='cuda:0') tensor(0.1206, device='cuda:0') tensor(-6.0951e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.069620
Average KL loss: 0.010803
Average total loss: 0.080423
tensor(0.0900, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-7.1234e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.068906
Average KL loss: 0.010807
Average total loss: 0.079714
tensor(0.0900, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-4.4626e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.066532
Average KL loss: 0.010812
Average total loss: 0.077344
tensor(0.0900, device='cuda:0') tensor(0.1208, device='cuda:0') tensor(-4.2549e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.068286
Average KL loss: 0.010815
Average total loss: 0.079101
tensor(0.0900, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-8.1697e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.069235
Average KL loss: 0.010819
Average total loss: 0.080054
tensor(0.0900, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-6.5795e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.066426
Average KL loss: 0.010823
Average total loss: 0.077250
tensor(0.0900, device='cuda:0') tensor(0.1210, device='cuda:0') tensor(-5.9137e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.066103
Average KL loss: 0.010827
Average total loss: 0.076930
tensor(0.0900, device='cuda:0') tensor(0.1211, device='cuda:0') tensor(-6.2312e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.066352
Average KL loss: 0.010831
Average total loss: 0.077183
tensor(0.0900, device='cuda:0') tensor(0.1212, device='cuda:0') tensor(-4.9371e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.065043
Average KL loss: 0.010835
Average total loss: 0.075877
tensor(0.0900, device='cuda:0') tensor(0.1213, device='cuda:0') tensor(-5.8706e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.066214
Average KL loss: 0.010838
Average total loss: 0.077052
tensor(0.0900, device='cuda:0') tensor(0.1213, device='cuda:0') tensor(-4.2910e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.065180
Average KL loss: 0.010842
Average total loss: 0.076022
tensor(0.0900, device='cuda:0') tensor(0.1214, device='cuda:0') tensor(-6.5125e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.065295
Average KL loss: 0.010846
Average total loss: 0.076140
tensor(0.0900, device='cuda:0') tensor(0.1215, device='cuda:0') tensor(-5.4431e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.065261
Average KL loss: 0.010849
Average total loss: 0.076110
tensor(0.0900, device='cuda:0') tensor(0.1215, device='cuda:0') tensor(-6.8404e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.064713
Average KL loss: 0.010852
Average total loss: 0.075565
tensor(0.0900, device='cuda:0') tensor(0.1216, device='cuda:0') tensor(-5.7503e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.065091
Average KL loss: 0.010856
Average total loss: 0.075947
tensor(0.0900, device='cuda:0') tensor(0.1217, device='cuda:0') tensor(-6.7345e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.066861
Average KL loss: 0.010861
Average total loss: 0.077721
tensor(0.0900, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-4.4895e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.066338
Average KL loss: 0.010865
Average total loss: 0.077203
tensor(0.0900, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-5.8814e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.064402
Average KL loss: 0.010868
Average total loss: 0.075270
tensor(0.0900, device='cuda:0') tensor(0.1219, device='cuda:0') tensor(-5.6086e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.064778
Average KL loss: 0.010872
Average total loss: 0.075650
tensor(0.0900, device='cuda:0') tensor(0.1220, device='cuda:0') tensor(-7.1137e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.065148
Average KL loss: 0.010876
Average total loss: 0.076024
tensor(0.0900, device='cuda:0') tensor(0.1221, device='cuda:0') tensor(-6.6359e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.063764
Average KL loss: 0.010879
Average total loss: 0.074644
tensor(0.0900, device='cuda:0') tensor(0.1221, device='cuda:0') tensor(-5.7697e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.064977
Average KL loss: 0.010884
Average total loss: 0.075861
tensor(0.0900, device='cuda:0') tensor(0.1222, device='cuda:0') tensor(-3.8380e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.065526
Average KL loss: 0.010888
Average total loss: 0.076414
tensor(0.0900, device='cuda:0') tensor(0.1223, device='cuda:0') tensor(-3.7848e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.062859
Average KL loss: 0.010892
Average total loss: 0.073751
tensor(0.0900, device='cuda:0') tensor(0.1224, device='cuda:0') tensor(-5.0208e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.064594
Average KL loss: 0.010895
Average total loss: 0.075489
tensor(0.0900, device='cuda:0') tensor(0.1224, device='cuda:0') tensor(-6.4718e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.064487
Average KL loss: 0.010899
Average total loss: 0.075386
tensor(0.0900, device='cuda:0') tensor(0.1225, device='cuda:0') tensor(-6.6968e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.063207
Average KL loss: 0.010903
Average total loss: 0.074110
tensor(0.0900, device='cuda:0') tensor(0.1226, device='cuda:0') tensor(-4.0637e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.064401
Average KL loss: 0.010907
Average total loss: 0.075308
tensor(0.0900, device='cuda:0') tensor(0.1227, device='cuda:0') tensor(-6.7182e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.063720
Average KL loss: 0.010911
Average total loss: 0.074631
tensor(0.0900, device='cuda:0') tensor(0.1227, device='cuda:0') tensor(-5.2337e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.062296
Average KL loss: 0.010915
Average total loss: 0.073211
tensor(0.0900, device='cuda:0') tensor(0.1228, device='cuda:0') tensor(-6.0882e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.063246
Average KL loss: 0.010918
Average total loss: 0.074165
tensor(0.0900, device='cuda:0') tensor(0.1229, device='cuda:0') tensor(-6.8500e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.062211
Average KL loss: 0.010922
Average total loss: 0.073132
tensor(0.0900, device='cuda:0') tensor(0.1229, device='cuda:0') tensor(-5.7917e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.063080
Average KL loss: 0.010925
Average total loss: 0.074005
tensor(0.0900, device='cuda:0') tensor(0.1230, device='cuda:0') tensor(-7.8296e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.062104
Average KL loss: 0.010929
Average total loss: 0.073033
tensor(0.0900, device='cuda:0') tensor(0.1231, device='cuda:0') tensor(-4.4882e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.063641
Average KL loss: 0.010933
Average total loss: 0.074574
tensor(0.0900, device='cuda:0') tensor(0.1232, device='cuda:0') tensor(-6.1792e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.062799
Average KL loss: 0.010937
Average total loss: 0.073735
tensor(0.0900, device='cuda:0') tensor(0.1232, device='cuda:0') tensor(-4.7443e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.062765
Average KL loss: 0.010940
Average total loss: 0.073705
tensor(0.0900, device='cuda:0') tensor(0.1233, device='cuda:0') tensor(-6.5522e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.062939
Average KL loss: 0.010945
Average total loss: 0.073884
tensor(0.0900, device='cuda:0') tensor(0.1234, device='cuda:0') tensor(-4.3600e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.060967
Average KL loss: 0.010948
Average total loss: 0.071915
tensor(0.0900, device='cuda:0') tensor(0.1235, device='cuda:0') tensor(-4.6961e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.060602
Average KL loss: 0.010952
Average total loss: 0.071554
tensor(0.0900, device='cuda:0') tensor(0.1235, device='cuda:0') tensor(-3.5920e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.062976
Average KL loss: 0.010956
Average total loss: 0.073931
tensor(0.0900, device='cuda:0') tensor(0.1236, device='cuda:0') tensor(-5.8122e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.061720
Average KL loss: 0.010960
Average total loss: 0.072680
tensor(0.0900, device='cuda:0') tensor(0.1237, device='cuda:0') tensor(-5.8383e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.061606
Average KL loss: 0.010963
Average total loss: 0.072570
 Percentile value: 0.0017441382864490204
Non-zero model percentage: 20.971534729003906%, Non-zero mask percentage: 20.971534729003906%

--- Pruning Level [7/24]: ---
conv1.weight         | nonzeros =     258 /    1728             ( 14.93%) | total_pruned =    1470 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
bn1.weight           | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
bn1.bias             | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1734 /   36864             (  4.70%) | total_pruned =   35130 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2533 /   36864             (  6.87%) | total_pruned =   34331 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2817 /   36864             (  7.64%) | total_pruned =   34047 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3857 /   36864             ( 10.46%) | total_pruned =   33007 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   15579 /   73728             ( 21.13%) | total_pruned =   58149 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   33296 /  147456             ( 22.58%) | total_pruned =  114160 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2375 /    8192             ( 28.99%) | total_pruned =    5817 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   24142 /  147456             ( 16.37%) | total_pruned =  123314 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   21076 /  147456             ( 14.29%) | total_pruned =  126380 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   87611 /  294912             ( 29.71%) | total_pruned =  207301 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      43 /     256             ( 16.80%) | total_pruned =     213 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  152998 /  589824             ( 25.94%) | total_pruned =  436826 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   10496 /   32768             ( 32.03%) | total_pruned =   22272 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   99188 /  589824             ( 16.82%) | total_pruned =  490636 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      39 /     256             ( 15.23%) | total_pruned =     217 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     217 /     256             ( 84.77%) | total_pruned =      39 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   73353 /  589824             ( 12.44%) | total_pruned =  516471 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      31 /     256             ( 12.11%) | total_pruned =     225 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     218 /     256             ( 85.16%) | total_pruned =      38 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  259574 / 1179648             ( 22.00%) | total_pruned =  920074 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      70 /     512             ( 13.67%) | total_pruned =     442 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     462 /     512             ( 90.23%) | total_pruned =      50 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  357361 / 2359296             ( 15.15%) | total_pruned = 2001935 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      74 /     512             ( 14.45%) | total_pruned =     438 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     457 /     512             ( 89.26%) | total_pruned =      55 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     262 /     512             ( 51.17%) | total_pruned =     250 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   16303 /  131072             ( 12.44%) | total_pruned =  114769 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      61 /     512             ( 11.91%) | total_pruned =     451 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     334 /     512             ( 65.23%) | total_pruned =     178 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     262 /     512             ( 51.17%) | total_pruned =     250 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  301430 / 2359296             ( 12.78%) | total_pruned = 2057866 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      63 /     512             ( 12.30%) | total_pruned =     449 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     359 /     512             ( 70.12%) | total_pruned =     153 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  868233 / 2359296             ( 36.80%) | total_pruned = 1491063 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      77 /     512             ( 15.04%) | total_pruned =     435 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     467 /     512             ( 91.21%) | total_pruned =      45 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     450 /     512             ( 87.89%) | total_pruned =      62 | shape = torch.Size([512])
linear.weight        | nonzeros =    4427 /    5120             ( 86.46%) | total_pruned =     693 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 2344358, pruned : 8834404, total: 11178762, Compression rate :       4.77x  ( 79.03% pruned)
Train Epoch: 35/100 Loss: 0.017026 Accuracy: 88.61 100.00 % Best test Accuracy: 88.87%
tensor(0.0900, device='cuda:0') tensor(0.1238, device='cuda:0') tensor(-7.5781e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.076473
Average KL loss: 0.010933
Average total loss: 0.087406
tensor(0.0898, device='cuda:0') tensor(0.1232, device='cuda:0') tensor(-7.0227e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.076706
Average KL loss: 0.010906
Average total loss: 0.087612
tensor(0.0898, device='cuda:0') tensor(0.1230, device='cuda:0') tensor(-1.1579e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.076954
Average KL loss: 0.010886
Average total loss: 0.087840
tensor(0.0897, device='cuda:0') tensor(0.1228, device='cuda:0') tensor(-4.9970e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.075624
Average KL loss: 0.010868
Average total loss: 0.086492
tensor(0.0897, device='cuda:0') tensor(0.1226, device='cuda:0') tensor(-7.9407e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.077478
Average KL loss: 0.010852
Average total loss: 0.088331
tensor(0.0897, device='cuda:0') tensor(0.1225, device='cuda:0') tensor(-7.5313e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.078565
Average KL loss: 0.010838
Average total loss: 0.089403
tensor(0.0897, device='cuda:0') tensor(0.1224, device='cuda:0') tensor(-7.7269e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.073435
Average KL loss: 0.010825
Average total loss: 0.084260
tensor(0.0897, device='cuda:0') tensor(0.1223, device='cuda:0') tensor(-9.6780e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.071547
Average KL loss: 0.010813
Average total loss: 0.082361
tensor(0.0896, device='cuda:0') tensor(0.1222, device='cuda:0') tensor(-6.3092e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.072233
Average KL loss: 0.010802
Average total loss: 0.083034
tensor(0.0896, device='cuda:0') tensor(0.1222, device='cuda:0') tensor(-5.5397e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.071730
Average KL loss: 0.010791
Average total loss: 0.082521
tensor(0.0896, device='cuda:0') tensor(0.1221, device='cuda:0') tensor(-6.2407e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.073012
Average KL loss: 0.010782
Average total loss: 0.083794
tensor(0.0896, device='cuda:0') tensor(0.1220, device='cuda:0') tensor(-6.6059e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.073444
Average KL loss: 0.010773
Average total loss: 0.084218
tensor(0.0895, device='cuda:0') tensor(0.1220, device='cuda:0') tensor(-6.2961e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.071448
Average KL loss: 0.010765
Average total loss: 0.082214
tensor(0.0895, device='cuda:0') tensor(0.1219, device='cuda:0') tensor(-8.0870e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.070190
Average KL loss: 0.010758
Average total loss: 0.080948
tensor(0.0895, device='cuda:0') tensor(0.1219, device='cuda:0') tensor(-5.5284e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.068959
Average KL loss: 0.010751
Average total loss: 0.079711
tensor(0.0894, device='cuda:0') tensor(0.1219, device='cuda:0') tensor(-7.4041e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.071093
Average KL loss: 0.010745
Average total loss: 0.081838
tensor(0.0894, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-6.7788e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.070791
Average KL loss: 0.010739
Average total loss: 0.081530
tensor(0.0894, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-5.5130e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.070545
Average KL loss: 0.010734
Average total loss: 0.081278
tensor(0.0894, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-7.5940e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.069384
Average KL loss: 0.010729
Average total loss: 0.080114
tensor(0.0893, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-5.2204e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.068904
Average KL loss: 0.010725
Average total loss: 0.079629
tensor(0.0893, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-6.6271e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.067648
Average KL loss: 0.010721
Average total loss: 0.078369
tensor(0.0893, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-5.7698e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.071078
Average KL loss: 0.010718
Average total loss: 0.081795
tensor(0.0892, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-6.9162e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.070493
Average KL loss: 0.010715
Average total loss: 0.081207
tensor(0.0892, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-6.0325e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.069344
Average KL loss: 0.010712
Average total loss: 0.080056
tensor(0.0892, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-9.3190e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.068922
Average KL loss: 0.010709
Average total loss: 0.079631
tensor(0.0892, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-6.0530e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.069130
Average KL loss: 0.010706
Average total loss: 0.079836
tensor(0.0891, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-6.8536e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.067451
Average KL loss: 0.010705
Average total loss: 0.078156
tensor(0.0891, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-6.6696e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.066297
Average KL loss: 0.010703
Average total loss: 0.077000
tensor(0.0891, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-6.0282e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.067508
Average KL loss: 0.010701
Average total loss: 0.078209
tensor(0.0890, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-6.8164e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.067834
Average KL loss: 0.010699
Average total loss: 0.078533
tensor(0.0890, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-4.9979e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.066932
Average KL loss: 0.010698
Average total loss: 0.077630
tensor(0.0890, device='cuda:0') tensor(0.1219, device='cuda:0') tensor(-5.1784e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.065006
Average KL loss: 0.010698
Average total loss: 0.075704
tensor(0.0890, device='cuda:0') tensor(0.1219, device='cuda:0') tensor(-6.5704e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.066369
Average KL loss: 0.010697
Average total loss: 0.077066
tensor(0.0889, device='cuda:0') tensor(0.1219, device='cuda:0') tensor(-3.6727e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.066063
Average KL loss: 0.010696
Average total loss: 0.076759
tensor(0.0889, device='cuda:0') tensor(0.1219, device='cuda:0') tensor(-7.5125e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.065631
Average KL loss: 0.010696
Average total loss: 0.076327
tensor(0.0889, device='cuda:0') tensor(0.1220, device='cuda:0') tensor(-5.8661e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.066739
Average KL loss: 0.010696
Average total loss: 0.077435
tensor(0.0889, device='cuda:0') tensor(0.1220, device='cuda:0') tensor(-6.3110e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.065679
Average KL loss: 0.010697
Average total loss: 0.076376
tensor(0.0889, device='cuda:0') tensor(0.1220, device='cuda:0') tensor(-5.3208e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.065785
Average KL loss: 0.010696
Average total loss: 0.076481
tensor(0.0888, device='cuda:0') tensor(0.1221, device='cuda:0') tensor(-4.7839e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.066257
Average KL loss: 0.010697
Average total loss: 0.076953
tensor(0.0888, device='cuda:0') tensor(0.1221, device='cuda:0') tensor(-5.3183e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.064610
Average KL loss: 0.010697
Average total loss: 0.075307
tensor(0.0888, device='cuda:0') tensor(0.1221, device='cuda:0') tensor(-6.3622e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.064864
Average KL loss: 0.010698
Average total loss: 0.075562
tensor(0.0888, device='cuda:0') tensor(0.1222, device='cuda:0') tensor(-4.8844e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.065024
Average KL loss: 0.010699
Average total loss: 0.075724
tensor(0.0888, device='cuda:0') tensor(0.1222, device='cuda:0') tensor(-5.2056e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.064093
Average KL loss: 0.010700
Average total loss: 0.074793
tensor(0.0888, device='cuda:0') tensor(0.1222, device='cuda:0') tensor(-4.4954e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.064463
Average KL loss: 0.010701
Average total loss: 0.075165
tensor(0.0887, device='cuda:0') tensor(0.1223, device='cuda:0') tensor(-6.7745e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.065580
Average KL loss: 0.010703
Average total loss: 0.076282
tensor(0.0887, device='cuda:0') tensor(0.1223, device='cuda:0') tensor(-6.2904e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.066849
Average KL loss: 0.010704
Average total loss: 0.077553
tensor(0.0887, device='cuda:0') tensor(0.1224, device='cuda:0') tensor(-4.8725e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.065680
Average KL loss: 0.010705
Average total loss: 0.076385
tensor(0.0887, device='cuda:0') tensor(0.1224, device='cuda:0') tensor(-6.1076e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.062986
Average KL loss: 0.010706
Average total loss: 0.073692
tensor(0.0887, device='cuda:0') tensor(0.1224, device='cuda:0') tensor(-6.1014e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.063695
Average KL loss: 0.010707
Average total loss: 0.074402
tensor(0.0887, device='cuda:0') tensor(0.1225, device='cuda:0') tensor(-5.7533e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.064542
Average KL loss: 0.010708
Average total loss: 0.075250
tensor(0.0886, device='cuda:0') tensor(0.1225, device='cuda:0') tensor(-6.5790e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.062575
Average KL loss: 0.010710
Average total loss: 0.073285
tensor(0.0886, device='cuda:0') tensor(0.1226, device='cuda:0') tensor(-6.1292e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.063196
Average KL loss: 0.010711
Average total loss: 0.073907
tensor(0.0886, device='cuda:0') tensor(0.1226, device='cuda:0') tensor(-5.8741e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.062497
Average KL loss: 0.010712
Average total loss: 0.073209
tensor(0.0886, device='cuda:0') tensor(0.1226, device='cuda:0') tensor(-4.8096e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.061623
Average KL loss: 0.010713
Average total loss: 0.072337
tensor(0.0886, device='cuda:0') tensor(0.1227, device='cuda:0') tensor(-5.5982e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.062881
Average KL loss: 0.010715
Average total loss: 0.073596
tensor(0.0886, device='cuda:0') tensor(0.1227, device='cuda:0') tensor(-5.8106e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.062713
Average KL loss: 0.010717
Average total loss: 0.073430
tensor(0.0886, device='cuda:0') tensor(0.1228, device='cuda:0') tensor(-5.8459e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.061003
Average KL loss: 0.010719
Average total loss: 0.071722
tensor(0.0885, device='cuda:0') tensor(0.1228, device='cuda:0') tensor(-4.9451e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.063205
Average KL loss: 0.010720
Average total loss: 0.073925
tensor(0.0885, device='cuda:0') tensor(0.1229, device='cuda:0') tensor(-5.8630e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.062512
Average KL loss: 0.010722
Average total loss: 0.073233
tensor(0.0885, device='cuda:0') tensor(0.1229, device='cuda:0') tensor(-4.4439e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.060789
Average KL loss: 0.010724
Average total loss: 0.071513
tensor(0.0885, device='cuda:0') tensor(0.1230, device='cuda:0') tensor(-5.3738e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.061534
Average KL loss: 0.010726
Average total loss: 0.072260
tensor(0.0885, device='cuda:0') tensor(0.1230, device='cuda:0') tensor(-4.2490e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.061149
Average KL loss: 0.010728
Average total loss: 0.071877
tensor(0.0885, device='cuda:0') tensor(0.1231, device='cuda:0') tensor(-3.8831e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.061058
Average KL loss: 0.010730
Average total loss: 0.071788
tensor(0.0885, device='cuda:0') tensor(0.1231, device='cuda:0') tensor(-5.1836e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.060829
Average KL loss: 0.010732
Average total loss: 0.071560
tensor(0.0885, device='cuda:0') tensor(0.1232, device='cuda:0') tensor(-5.4621e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.063149
Average KL loss: 0.010733
Average total loss: 0.073882
tensor(0.0885, device='cuda:0') tensor(0.1232, device='cuda:0') tensor(-5.6475e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.061277
Average KL loss: 0.010736
Average total loss: 0.072013
tensor(0.0884, device='cuda:0') tensor(0.1233, device='cuda:0') tensor(-4.1668e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.059844
Average KL loss: 0.010739
Average total loss: 0.070583
tensor(0.0884, device='cuda:0') tensor(0.1233, device='cuda:0') tensor(-3.2512e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.060128
Average KL loss: 0.010741
Average total loss: 0.070868
tensor(0.0884, device='cuda:0') tensor(0.1234, device='cuda:0') tensor(-5.1062e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.060755
Average KL loss: 0.010743
Average total loss: 0.071498
tensor(0.0884, device='cuda:0') tensor(0.1234, device='cuda:0') tensor(-1.2258e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.060610
Average KL loss: 0.010746
Average total loss: 0.071355
tensor(0.0884, device='cuda:0') tensor(0.1235, device='cuda:0') tensor(-4.8757e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.058754
Average KL loss: 0.010748
Average total loss: 0.069503
tensor(0.0884, device='cuda:0') tensor(0.1235, device='cuda:0') tensor(-3.1632e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.060535
Average KL loss: 0.010750
Average total loss: 0.071285
tensor(0.0884, device='cuda:0') tensor(0.1236, device='cuda:0') tensor(-4.6762e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.058590
Average KL loss: 0.010752
Average total loss: 0.069342
tensor(0.0884, device='cuda:0') tensor(0.1236, device='cuda:0') tensor(-3.0881e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.059198
Average KL loss: 0.010754
Average total loss: 0.069952
tensor(0.0884, device='cuda:0') tensor(0.1237, device='cuda:0') tensor(-6.2430e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.060272
Average KL loss: 0.010757
Average total loss: 0.071029
tensor(0.0884, device='cuda:0') tensor(0.1237, device='cuda:0') tensor(-4.1675e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.059762
Average KL loss: 0.010760
Average total loss: 0.070522
tensor(0.0884, device='cuda:0') tensor(0.1238, device='cuda:0') tensor(-5.2288e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.059504
Average KL loss: 0.010763
Average total loss: 0.070267
tensor(0.0884, device='cuda:0') tensor(0.1239, device='cuda:0') tensor(-4.5938e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.058930
Average KL loss: 0.010766
Average total loss: 0.069696
tensor(0.0884, device='cuda:0') tensor(0.1239, device='cuda:0') tensor(-5.4444e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.059608
Average KL loss: 0.010768
Average total loss: 0.070376
tensor(0.0884, device='cuda:0') tensor(0.1240, device='cuda:0') tensor(-4.0073e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.061488
Average KL loss: 0.010771
Average total loss: 0.072259
tensor(0.0883, device='cuda:0') tensor(0.1240, device='cuda:0') tensor(-6.1698e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.057398
Average KL loss: 0.010773
Average total loss: 0.068172
tensor(0.0883, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-4.8209e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.059431
Average KL loss: 0.010776
Average total loss: 0.070206
tensor(0.0883, device='cuda:0') tensor(0.1241, device='cuda:0') tensor(-4.0820e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.059188
Average KL loss: 0.010778
Average total loss: 0.069966
tensor(0.0883, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-3.7762e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.058803
Average KL loss: 0.010781
Average total loss: 0.069584
tensor(0.0883, device='cuda:0') tensor(0.1242, device='cuda:0') tensor(-4.1463e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.058121
Average KL loss: 0.010783
Average total loss: 0.068905
tensor(0.0883, device='cuda:0') tensor(0.1243, device='cuda:0') tensor(-5.8905e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.058502
Average KL loss: 0.010786
Average total loss: 0.069287
tensor(0.0883, device='cuda:0') tensor(0.1244, device='cuda:0') tensor(-5.2801e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.058206
Average KL loss: 0.010788
Average total loss: 0.068994
tensor(0.0883, device='cuda:0') tensor(0.1244, device='cuda:0') tensor(-7.9801e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.058409
Average KL loss: 0.010791
Average total loss: 0.069200
tensor(0.0883, device='cuda:0') tensor(0.1245, device='cuda:0') tensor(-4.1252e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.056520
Average KL loss: 0.010793
Average total loss: 0.067313
tensor(0.0883, device='cuda:0') tensor(0.1245, device='cuda:0') tensor(-4.7389e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.056753
Average KL loss: 0.010796
Average total loss: 0.067549
tensor(0.0883, device='cuda:0') tensor(0.1246, device='cuda:0') tensor(-4.4842e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.056558
Average KL loss: 0.010798
Average total loss: 0.067357
tensor(0.0883, device='cuda:0') tensor(0.1246, device='cuda:0') tensor(-4.2298e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.057282
Average KL loss: 0.010801
Average total loss: 0.068083
tensor(0.0883, device='cuda:0') tensor(0.1247, device='cuda:0') tensor(-6.5280e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.057181
Average KL loss: 0.010803
Average total loss: 0.067984
tensor(0.0883, device='cuda:0') tensor(0.1247, device='cuda:0') tensor(-5.0437e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.055515
Average KL loss: 0.010805
Average total loss: 0.066320
tensor(0.0882, device='cuda:0') tensor(0.1248, device='cuda:0') tensor(-4.1566e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.056030
Average KL loss: 0.010807
Average total loss: 0.066838
tensor(0.0882, device='cuda:0') tensor(0.1248, device='cuda:0') tensor(-4.1419e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.055945
Average KL loss: 0.010810
Average total loss: 0.066755
tensor(0.0882, device='cuda:0') tensor(0.1249, device='cuda:0') tensor(-3.3506e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.056339
Average KL loss: 0.010812
Average total loss: 0.067152
tensor(0.0882, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-4.1357e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.055683
Average KL loss: 0.010815
Average total loss: 0.066498
tensor(0.0882, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.6006e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.055162
Average KL loss: 0.010817
Average total loss: 0.065979
tensor(0.0882, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-4.6659e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.055401
Average KL loss: 0.010820
Average total loss: 0.066221
tensor(0.0882, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-3.6849e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.055673
Average KL loss: 0.010822
Average total loss: 0.066495
tensor(0.0882, device='cuda:0') tensor(0.1252, device='cuda:0') tensor(-4.7057e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.055334
Average KL loss: 0.010826
Average total loss: 0.066159
tensor(0.0882, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-3.3366e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.056053
Average KL loss: 0.010828
Average total loss: 0.066881
tensor(0.0882, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-3.6995e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.055572
Average KL loss: 0.010831
Average total loss: 0.066402
tensor(0.0882, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-4.6887e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.054459
Average KL loss: 0.010833
Average total loss: 0.065292
tensor(0.0882, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.4857e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.055472
Average KL loss: 0.010835
Average total loss: 0.066307
tensor(0.0882, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-5.7199e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.054697
Average KL loss: 0.010838
Average total loss: 0.065534
tensor(0.0882, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-2.9547e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.054620
Average KL loss: 0.010840
Average total loss: 0.065460
tensor(0.0882, device='cuda:0') tensor(0.1256, device='cuda:0') tensor(-3.7386e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.054911
Average KL loss: 0.010842
Average total loss: 0.065753
tensor(0.0882, device='cuda:0') tensor(0.1257, device='cuda:0') tensor(-3.3241e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.054598
Average KL loss: 0.010845
Average total loss: 0.065443
tensor(0.0881, device='cuda:0') tensor(0.1257, device='cuda:0') tensor(-4.9981e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.054892
Average KL loss: 0.010848
Average total loss: 0.065740
tensor(0.0881, device='cuda:0') tensor(0.1258, device='cuda:0') tensor(-4.3977e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.056676
Average KL loss: 0.010851
Average total loss: 0.067527
tensor(0.0881, device='cuda:0') tensor(0.1258, device='cuda:0') tensor(-4.1513e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.054356
Average KL loss: 0.010854
Average total loss: 0.065210
tensor(0.0881, device='cuda:0') tensor(0.1259, device='cuda:0') tensor(-5.5695e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.054083
Average KL loss: 0.010857
Average total loss: 0.064940
tensor(0.0881, device='cuda:0') tensor(0.1260, device='cuda:0') tensor(-4.9293e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.054440
Average KL loss: 0.010860
Average total loss: 0.065300
tensor(0.0881, device='cuda:0') tensor(0.1260, device='cuda:0') tensor(-2.7408e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.053752
Average KL loss: 0.010863
Average total loss: 0.064615
tensor(0.0881, device='cuda:0') tensor(0.1261, device='cuda:0') tensor(-4.7744e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.054382
Average KL loss: 0.010866
Average total loss: 0.065248
tensor(0.0881, device='cuda:0') tensor(0.1262, device='cuda:0') tensor(-4.2050e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.053102
Average KL loss: 0.010869
Average total loss: 0.063971
tensor(0.0881, device='cuda:0') tensor(0.1262, device='cuda:0') tensor(-3.7380e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.054389
Average KL loss: 0.010871
Average total loss: 0.065260
tensor(0.0881, device='cuda:0') tensor(0.1263, device='cuda:0') tensor(-3.8815e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.054080
Average KL loss: 0.010874
Average total loss: 0.064954
tensor(0.0881, device='cuda:0') tensor(0.1263, device='cuda:0') tensor(-4.6100e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.052198
Average KL loss: 0.010877
Average total loss: 0.063075
tensor(0.0881, device='cuda:0') tensor(0.1264, device='cuda:0') tensor(-3.2487e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.053503
Average KL loss: 0.010879
Average total loss: 0.064383
tensor(0.0881, device='cuda:0') tensor(0.1264, device='cuda:0') tensor(-5.3130e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.053272
Average KL loss: 0.010882
Average total loss: 0.064154
tensor(0.0881, device='cuda:0') tensor(0.1265, device='cuda:0') tensor(-3.5857e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.052518
Average KL loss: 0.010885
Average total loss: 0.063402
tensor(0.0881, device='cuda:0') tensor(0.1266, device='cuda:0') tensor(-4.2103e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.055815
Average KL loss: 0.010887
Average total loss: 0.066702
tensor(0.0881, device='cuda:0') tensor(0.1266, device='cuda:0') tensor(-3.5718e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.054411
Average KL loss: 0.010890
Average total loss: 0.065301
tensor(0.0881, device='cuda:0') tensor(0.1267, device='cuda:0') tensor(-3.6992e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.052829
Average KL loss: 0.010894
Average total loss: 0.063723
tensor(0.0881, device='cuda:0') tensor(0.1268, device='cuda:0') tensor(-3.2745e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.052919
Average KL loss: 0.010896
Average total loss: 0.063814
tensor(0.0881, device='cuda:0') tensor(0.1268, device='cuda:0') tensor(-3.5530e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.052771
Average KL loss: 0.010899
Average total loss: 0.063670
tensor(0.0881, device='cuda:0') tensor(0.1269, device='cuda:0') tensor(-4.6180e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.053653
Average KL loss: 0.010901
Average total loss: 0.064555
tensor(0.0881, device='cuda:0') tensor(0.1269, device='cuda:0') tensor(-3.2640e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.052670
Average KL loss: 0.010904
Average total loss: 0.063574
tensor(0.0881, device='cuda:0') tensor(0.1270, device='cuda:0') tensor(-3.7578e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.051360
Average KL loss: 0.010907
Average total loss: 0.062267
tensor(0.0881, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-3.7099e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.052436
Average KL loss: 0.010909
Average total loss: 0.063345
tensor(0.0881, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-3.5947e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.055341
Average KL loss: 0.010913
Average total loss: 0.066254
tensor(0.0881, device='cuda:0') tensor(0.1272, device='cuda:0') tensor(-3.7801e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.051749
Average KL loss: 0.010916
Average total loss: 0.062665
tensor(0.0880, device='cuda:0') tensor(0.1272, device='cuda:0') tensor(-2.5781e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.051048
Average KL loss: 0.010918
Average total loss: 0.061966
tensor(0.0880, device='cuda:0') tensor(0.1273, device='cuda:0') tensor(-3.4382e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.051631
Average KL loss: 0.010921
Average total loss: 0.062552
tensor(0.0880, device='cuda:0') tensor(0.1274, device='cuda:0') tensor(-4.9650e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.052168
Average KL loss: 0.010923
Average total loss: 0.063091
tensor(0.0880, device='cuda:0') tensor(0.1274, device='cuda:0') tensor(-4.2927e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.051318
Average KL loss: 0.010926
Average total loss: 0.062244
tensor(0.0880, device='cuda:0') tensor(0.1275, device='cuda:0') tensor(-4.3378e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.051717
Average KL loss: 0.010928
Average total loss: 0.062645
tensor(0.0880, device='cuda:0') tensor(0.1275, device='cuda:0') tensor(-3.2292e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.051960
Average KL loss: 0.010931
Average total loss: 0.062891
tensor(0.0880, device='cuda:0') tensor(0.1276, device='cuda:0') tensor(-3.0792e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.050708
Average KL loss: 0.010933
Average total loss: 0.061641
tensor(0.0880, device='cuda:0') tensor(0.1277, device='cuda:0') tensor(-4.3343e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.050787
Average KL loss: 0.010936
Average total loss: 0.061723
tensor(0.0880, device='cuda:0') tensor(0.1277, device='cuda:0') tensor(-3.2706e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.051098
Average KL loss: 0.010938
Average total loss: 0.062036
tensor(0.0880, device='cuda:0') tensor(0.1278, device='cuda:0') tensor(-4.0304e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.050619
Average KL loss: 0.010940
Average total loss: 0.061559
tensor(0.0880, device='cuda:0') tensor(0.1278, device='cuda:0') tensor(-4.6764e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.050297
Average KL loss: 0.010942
Average total loss: 0.061239
tensor(0.0880, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-2.3579e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.050655
Average KL loss: 0.010945
Average total loss: 0.061600
tensor(0.0880, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-6.5290e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.050482
Average KL loss: 0.010947
Average total loss: 0.061430
tensor(0.0880, device='cuda:0') tensor(0.1280, device='cuda:0') tensor(-3.4091e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.050084
Average KL loss: 0.010950
Average total loss: 0.061033
tensor(0.0880, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(-3.6229e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.050514
Average KL loss: 0.010953
Average total loss: 0.061467
tensor(0.0880, device='cuda:0') tensor(0.1281, device='cuda:0') tensor(-3.0781e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.050041
Average KL loss: 0.010956
Average total loss: 0.060997
tensor(0.0880, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-8.3416e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.048905
Average KL loss: 0.010958
Average total loss: 0.059863
tensor(0.0879, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-5.8498e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.051263
Average KL loss: 0.010960
Average total loss: 0.062224
tensor(0.0879, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(-3.6956e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.051062
Average KL loss: 0.010963
Average total loss: 0.062025
tensor(0.0879, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-3.9481e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.051218
Average KL loss: 0.010966
Average total loss: 0.062184
tensor(0.0879, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-2.8803e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.049468
Average KL loss: 0.010969
Average total loss: 0.060438
tensor(0.0879, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-2.9703e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.048566
Average KL loss: 0.010972
Average total loss: 0.059538
tensor(0.0879, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-3.8802e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.048810
Average KL loss: 0.010974
Average total loss: 0.059784
tensor(0.0879, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-3.7168e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.049873
Average KL loss: 0.010976
Average total loss: 0.060850
tensor(0.0879, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-2.5688e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.048472
Average KL loss: 0.010979
Average total loss: 0.059451
tensor(0.0879, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-3.2743e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.048644
Average KL loss: 0.010981
Average total loss: 0.059625
tensor(0.0879, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-4.3341e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.049230
Average KL loss: 0.010984
Average total loss: 0.060214
tensor(0.0879, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-2.7674e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.049445
Average KL loss: 0.010986
Average total loss: 0.060432
tensor(0.0879, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-3.8714e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.049511
Average KL loss: 0.010990
Average total loss: 0.060501
tensor(0.0879, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-2.3847e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.047930
Average KL loss: 0.010992
Average total loss: 0.058922
tensor(0.0879, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-3.2589e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.048293
Average KL loss: 0.010995
Average total loss: 0.059287
tensor(0.0879, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-4.2487e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.048910
Average KL loss: 0.010997
Average total loss: 0.059907
tensor(0.0879, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-3.3135e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.048923
Average KL loss: 0.010999
Average total loss: 0.059922
tensor(0.0879, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-3.4443e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.048277
Average KL loss: 0.011002
Average total loss: 0.059279
tensor(0.0879, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-4.3764e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.048121
Average KL loss: 0.011005
Average total loss: 0.059125
tensor(0.0879, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-2.3866e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.047872
Average KL loss: 0.011007
Average total loss: 0.058879
tensor(0.0879, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-3.7455e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.047710
Average KL loss: 0.011010
Average total loss: 0.058720
tensor(0.0879, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-4.8010e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.048110
Average KL loss: 0.011012
Average total loss: 0.059122
tensor(0.0879, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-4.0484e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.048988
Average KL loss: 0.011015
Average total loss: 0.060002
tensor(0.0878, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-3.5010e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.048931
Average KL loss: 0.011017
Average total loss: 0.059948
tensor(0.0878, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-2.9843e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.047984
Average KL loss: 0.011020
Average total loss: 0.059004
tensor(0.0878, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-3.5463e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.048130
Average KL loss: 0.011023
Average total loss: 0.059153
tensor(0.0878, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.8029e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.048625
Average KL loss: 0.011025
Average total loss: 0.059650
tensor(0.0878, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.2452e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.046869
Average KL loss: 0.011027
Average total loss: 0.057897
tensor(0.0878, device='cuda:0') tensor(0.1299, device='cuda:0') tensor(-5.2126e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.047571
Average KL loss: 0.011029
Average total loss: 0.058600
tensor(0.0878, device='cuda:0') tensor(0.1299, device='cuda:0') tensor(-2.3677e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.047546
Average KL loss: 0.011032
Average total loss: 0.058578
tensor(0.0878, device='cuda:0') tensor(0.1300, device='cuda:0') tensor(-2.6323e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.048050
Average KL loss: 0.011034
Average total loss: 0.059084
tensor(0.0878, device='cuda:0') tensor(0.1300, device='cuda:0') tensor(-2.8757e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.048087
Average KL loss: 0.011037
Average total loss: 0.059124
tensor(0.0878, device='cuda:0') tensor(0.1301, device='cuda:0') tensor(-4.4355e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.048193
Average KL loss: 0.011040
Average total loss: 0.059232
tensor(0.0878, device='cuda:0') tensor(0.1302, device='cuda:0') tensor(-3.7507e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.046752
Average KL loss: 0.011042
Average total loss: 0.057794
tensor(0.0878, device='cuda:0') tensor(0.1302, device='cuda:0') tensor(-3.3467e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.046973
Average KL loss: 0.011045
Average total loss: 0.058017
tensor(0.0878, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-2.9704e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.047274
Average KL loss: 0.011047
Average total loss: 0.058320
tensor(0.0878, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-2.7978e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.047657
Average KL loss: 0.011049
Average total loss: 0.058706
tensor(0.0878, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.1904e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.046513
Average KL loss: 0.011051
Average total loss: 0.057564
tensor(0.0878, device='cuda:0') tensor(0.1305, device='cuda:0') tensor(-2.3511e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.045823
Average KL loss: 0.011054
Average total loss: 0.056876
tensor(0.0878, device='cuda:0') tensor(0.1305, device='cuda:0') tensor(-3.0787e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.047453
Average KL loss: 0.011056
Average total loss: 0.058509
tensor(0.0878, device='cuda:0') tensor(0.1306, device='cuda:0') tensor(-2.7245e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.046620
Average KL loss: 0.011059
Average total loss: 0.057678
tensor(0.0877, device='cuda:0') tensor(0.1306, device='cuda:0') tensor(-3.6061e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.046021
Average KL loss: 0.011061
Average total loss: 0.057082
tensor(0.0877, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.9574e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.046218
Average KL loss: 0.011063
Average total loss: 0.057281
tensor(0.0877, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-3.3545e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.046108
Average KL loss: 0.011065
Average total loss: 0.057173
tensor(0.0877, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-3.9174e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.046116
Average KL loss: 0.011068
Average total loss: 0.057183
tensor(0.0877, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(-3.8204e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.046386
Average KL loss: 0.011070
Average total loss: 0.057456
tensor(0.0877, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(-2.2465e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.046696
Average KL loss: 0.011073
Average total loss: 0.057769
tensor(0.0877, device='cuda:0') tensor(0.1310, device='cuda:0') tensor(-3.6333e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.046652
Average KL loss: 0.011076
Average total loss: 0.057728
tensor(0.0877, device='cuda:0') tensor(0.1311, device='cuda:0') tensor(-2.4363e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.044909
Average KL loss: 0.011078
Average total loss: 0.055988
 Percentile value: 0.0154304850846529
Non-zero model percentage: 16.777233123779297%, Non-zero mask percentage: 16.777233123779297%

--- Pruning Level [8/24]: ---
conv1.weight         | nonzeros =     202 /    1728             ( 11.69%) | total_pruned =    1526 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
bn1.weight           | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     396 /   36864             (  1.07%) | total_pruned =   36468 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1217 /   36864             (  3.30%) | total_pruned =   35647 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1692 /   36864             (  4.59%) | total_pruned =   35172 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2735 /   36864             (  7.42%) | total_pruned =   34129 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   13221 /   73728             ( 17.93%) | total_pruned =   60507 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   28596 /  147456             ( 19.39%) | total_pruned =  118860 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2142 /    8192             ( 26.15%) | total_pruned =    6050 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   19991 /  147456             ( 13.56%) | total_pruned =  127465 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   16695 /  147456             ( 11.32%) | total_pruned =  130761 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   80145 /  294912             ( 27.18%) | total_pruned =  214767 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     241 /     256             ( 94.14%) | total_pruned =      15 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  133732 /  589824             ( 22.67%) | total_pruned =  456092 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    9647 /   32768             ( 29.44%) | total_pruned =   23121 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     219 /     256             ( 85.55%) | total_pruned =      37 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   80708 /  589824             ( 13.68%) | total_pruned =  509116 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   56168 /  589824             (  9.52%) | total_pruned =  533656 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     196 /     256             ( 76.56%) | total_pruned =      60 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  218670 / 1179648             ( 18.54%) | total_pruned =  960978 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     435 /     512             ( 84.96%) | total_pruned =      77 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  272712 / 2359296             ( 11.56%) | total_pruned = 2086584 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      26 /     512             (  5.08%) | total_pruned =     486 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     421 /     512             ( 82.23%) | total_pruned =      91 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     244 /     512             ( 47.66%) | total_pruned =     268 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   12045 /  131072             (  9.19%) | total_pruned =  119027 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     286 /     512             ( 55.86%) | total_pruned =     226 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     241 /     512             ( 47.07%) | total_pruned =     271 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  209915 / 2359296             (  8.90%) | total_pruned = 2149381 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     323 /     512             ( 63.09%) | total_pruned =     189 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  705749 / 2359296             ( 29.91%) | total_pruned = 1653547 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     449 /     512             ( 87.70%) | total_pruned =      63 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     432 /     512             ( 84.38%) | total_pruned =      80 | shape = torch.Size([512])
linear.weight        | nonzeros =    4232 /    5120             ( 82.66%) | total_pruned =     888 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1875487, pruned : 9303275, total: 11178762, Compression rate :       5.96x  ( 83.22% pruned)
Train Epoch: 35/100 Loss: 0.026632 Accuracy: 88.82 100.00 % Best test Accuracy: 88.92%
tensor(0.0877, device='cuda:0') tensor(0.1311, device='cuda:0') tensor(-5.0984e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.061827
Average KL loss: 0.011049
Average total loss: 0.072876
tensor(0.0875, device='cuda:0') tensor(0.1305, device='cuda:0') tensor(-6.4998e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.060509
Average KL loss: 0.011024
Average total loss: 0.071534
tensor(0.0875, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-5.5991e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.061722
Average KL loss: 0.011006
Average total loss: 0.072729
tensor(0.0875, device='cuda:0') tensor(0.1301, device='cuda:0') tensor(-5.1912e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.058628
Average KL loss: 0.010990
Average total loss: 0.069619
tensor(0.0874, device='cuda:0') tensor(0.1300, device='cuda:0') tensor(-4.5020e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.059251
Average KL loss: 0.010976
Average total loss: 0.070227
tensor(0.0874, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-3.8930e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.058621
Average KL loss: 0.010962
Average total loss: 0.069583
tensor(0.0874, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-8.1319e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.062006
Average KL loss: 0.010950
Average total loss: 0.072956
tensor(0.0873, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-4.4740e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.058533
Average KL loss: 0.010938
Average total loss: 0.069471
tensor(0.0873, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-6.2529e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.057396
Average KL loss: 0.010928
Average total loss: 0.068324
tensor(0.0873, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-4.7051e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.058446
Average KL loss: 0.010918
Average total loss: 0.069364
tensor(0.0872, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-4.6664e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.058469
Average KL loss: 0.010909
Average total loss: 0.069377
tensor(0.0872, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-5.1039e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.058044
Average KL loss: 0.010900
Average total loss: 0.068944
tensor(0.0872, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-4.6532e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.057949
Average KL loss: 0.010892
Average total loss: 0.068842
tensor(0.0871, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-3.1828e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.057741
Average KL loss: 0.010885
Average total loss: 0.068626
tensor(0.0871, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-4.6494e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.057477
Average KL loss: 0.010877
Average total loss: 0.068355
tensor(0.0871, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-3.8875e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.056661
Average KL loss: 0.010871
Average total loss: 0.067531
tensor(0.0870, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-3.8105e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.057833
Average KL loss: 0.010864
Average total loss: 0.068697
tensor(0.0870, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-4.4585e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.056192
Average KL loss: 0.010858
Average total loss: 0.067050
tensor(0.0870, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-3.8250e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.056244
Average KL loss: 0.010852
Average total loss: 0.067096
tensor(0.0869, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-4.8349e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.056037
Average KL loss: 0.010846
Average total loss: 0.066884
tensor(0.0869, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-4.4438e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.054712
Average KL loss: 0.010842
Average total loss: 0.065554
tensor(0.0869, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-4.5465e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.055886
Average KL loss: 0.010837
Average total loss: 0.066722
tensor(0.0868, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-4.1203e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.056229
Average KL loss: 0.010832
Average total loss: 0.067061
tensor(0.0868, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-6.0351e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.054991
Average KL loss: 0.010828
Average total loss: 0.065819
tensor(0.0868, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-5.1965e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.055755
Average KL loss: 0.010824
Average total loss: 0.066579
tensor(0.0867, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-2.8041e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.054347
Average KL loss: 0.010820
Average total loss: 0.065168
tensor(0.0867, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-3.9901e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.057926
Average KL loss: 0.010817
Average total loss: 0.068743
tensor(0.0867, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-4.4494e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.054237
Average KL loss: 0.010814
Average total loss: 0.065051
tensor(0.0866, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-3.8679e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.055508
Average KL loss: 0.010811
Average total loss: 0.066319
tensor(0.0866, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-5.6243e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.054981
Average KL loss: 0.010808
Average total loss: 0.065789
tensor(0.0866, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-4.8990e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.054787
Average KL loss: 0.010805
Average total loss: 0.065592
tensor(0.0865, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-5.9685e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.054189
Average KL loss: 0.010802
Average total loss: 0.064991
tensor(0.0865, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-3.8019e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.055233
Average KL loss: 0.010800
Average total loss: 0.066033
tensor(0.0865, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-3.2598e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.054208
Average KL loss: 0.010798
Average total loss: 0.065006
tensor(0.0864, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-4.3142e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.052782
Average KL loss: 0.010796
Average total loss: 0.063578
tensor(0.0864, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-4.1609e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.054543
Average KL loss: 0.010794
Average total loss: 0.065337
tensor(0.0864, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-3.9497e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.052678
Average KL loss: 0.010792
Average total loss: 0.063470
tensor(0.0863, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-4.4890e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.051989
Average KL loss: 0.010790
Average total loss: 0.062779
tensor(0.0863, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-4.0722e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.055461
Average KL loss: 0.010789
Average total loss: 0.066250
tensor(0.0863, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-2.8942e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.051991
Average KL loss: 0.010788
Average total loss: 0.062779
tensor(0.0863, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-3.8873e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.053496
Average KL loss: 0.010787
Average total loss: 0.064282
tensor(0.0862, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-4.7024e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.054456
Average KL loss: 0.010786
Average total loss: 0.065243
tensor(0.0862, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-5.0948e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.053773
Average KL loss: 0.010786
Average total loss: 0.064559
tensor(0.0862, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-2.9637e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.053251
Average KL loss: 0.010785
Average total loss: 0.064036
tensor(0.0862, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-4.5145e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.052823
Average KL loss: 0.010784
Average total loss: 0.063607
tensor(0.0861, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-4.4142e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.052653
Average KL loss: 0.010783
Average total loss: 0.063437
tensor(0.0861, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-3.1671e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.051744
Average KL loss: 0.010783
Average total loss: 0.062527
tensor(0.0861, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-1.9856e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.051970
Average KL loss: 0.010782
Average total loss: 0.062752
tensor(0.0861, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-4.0270e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.054853
Average KL loss: 0.010782
Average total loss: 0.065635
tensor(0.0861, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-2.4138e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.050939
Average KL loss: 0.010782
Average total loss: 0.061721
tensor(0.0860, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-3.9817e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.050821
Average KL loss: 0.010781
Average total loss: 0.061602
tensor(0.0860, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-4.5103e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.051223
Average KL loss: 0.010780
Average total loss: 0.062003
tensor(0.0860, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-4.1924e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.052565
Average KL loss: 0.010780
Average total loss: 0.063345
tensor(0.0860, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-5.0500e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.051513
Average KL loss: 0.010781
Average total loss: 0.062294
tensor(0.0859, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-4.2373e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.051039
Average KL loss: 0.010781
Average total loss: 0.061821
tensor(0.0859, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-3.1423e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.050929
Average KL loss: 0.010782
Average total loss: 0.061711
tensor(0.0859, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-5.4432e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.051473
Average KL loss: 0.010782
Average total loss: 0.062255
tensor(0.0859, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-5.2791e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.050276
Average KL loss: 0.010783
Average total loss: 0.061058
tensor(0.0859, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-3.8771e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.050694
Average KL loss: 0.010783
Average total loss: 0.061477
tensor(0.0859, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-3.7559e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.050802
Average KL loss: 0.010784
Average total loss: 0.061586
tensor(0.0858, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-3.1805e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.051223
Average KL loss: 0.010785
Average total loss: 0.062008
tensor(0.0858, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-3.7837e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.049754
Average KL loss: 0.010785
Average total loss: 0.060539
tensor(0.0858, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.0725e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.050900
Average KL loss: 0.010786
Average total loss: 0.061686
tensor(0.0858, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.5336e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.050493
Average KL loss: 0.010787
Average total loss: 0.061279
tensor(0.0858, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.7206e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.051263
Average KL loss: 0.010787
Average total loss: 0.062050
tensor(0.0858, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-4.1834e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.049557
Average KL loss: 0.010788
Average total loss: 0.060345
tensor(0.0857, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-3.0856e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.049613
Average KL loss: 0.010788
Average total loss: 0.060401
tensor(0.0857, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-4.5098e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.049415
Average KL loss: 0.010789
Average total loss: 0.060204
tensor(0.0857, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-4.8613e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.049674
Average KL loss: 0.010790
Average total loss: 0.060465
tensor(0.0857, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-4.8454e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.049750
Average KL loss: 0.010791
Average total loss: 0.060541
tensor(0.0857, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-3.6493e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.049016
Average KL loss: 0.010792
Average total loss: 0.059809
tensor(0.0857, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-3.7049e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.049750
Average KL loss: 0.010793
Average total loss: 0.060544
tensor(0.0857, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-3.5215e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.049360
Average KL loss: 0.010794
Average total loss: 0.060155
tensor(0.0856, device='cuda:0') tensor(0.1299, device='cuda:0') tensor(-3.2059e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.048933
Average KL loss: 0.010796
Average total loss: 0.059728
tensor(0.0856, device='cuda:0') tensor(0.1299, device='cuda:0') tensor(-3.7326e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.049174
Average KL loss: 0.010797
Average total loss: 0.059971
tensor(0.0856, device='cuda:0') tensor(0.1300, device='cuda:0') tensor(-3.3321e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.048235
Average KL loss: 0.010797
Average total loss: 0.059033
tensor(0.0856, device='cuda:0') tensor(0.1300, device='cuda:0') tensor(-2.8627e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.050695
Average KL loss: 0.010798
Average total loss: 0.061493
tensor(0.0856, device='cuda:0') tensor(0.1300, device='cuda:0') tensor(-5.0315e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.048689
Average KL loss: 0.010799
Average total loss: 0.059489
tensor(0.0856, device='cuda:0') tensor(0.1301, device='cuda:0') tensor(-4.9856e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.049120
Average KL loss: 0.010800
Average total loss: 0.059921
tensor(0.0856, device='cuda:0') tensor(0.1301, device='cuda:0') tensor(-2.7829e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.048447
Average KL loss: 0.010802
Average total loss: 0.059249
tensor(0.0856, device='cuda:0') tensor(0.1301, device='cuda:0') tensor(-3.6437e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.047234
Average KL loss: 0.010803
Average total loss: 0.058037
tensor(0.0855, device='cuda:0') tensor(0.1302, device='cuda:0') tensor(-2.5390e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.047529
Average KL loss: 0.010804
Average total loss: 0.058333
tensor(0.0855, device='cuda:0') tensor(0.1302, device='cuda:0') tensor(-2.3623e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.048478
Average KL loss: 0.010805
Average total loss: 0.059283
tensor(0.0855, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-3.7432e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.047504
Average KL loss: 0.010806
Average total loss: 0.058310
tensor(0.0855, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-4.1307e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.048274
Average KL loss: 0.010807
Average total loss: 0.059081
tensor(0.0855, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-2.4541e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.048459
Average KL loss: 0.010809
Average total loss: 0.059268
tensor(0.0855, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-4.2804e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.048346
Average KL loss: 0.010810
Average total loss: 0.059156
tensor(0.0855, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-4.3471e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.047889
Average KL loss: 0.010812
Average total loss: 0.058700
tensor(0.0855, device='cuda:0') tensor(0.1305, device='cuda:0') tensor(-3.8408e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.047636
Average KL loss: 0.010813
Average total loss: 0.058449
tensor(0.0854, device='cuda:0') tensor(0.1305, device='cuda:0') tensor(-3.3666e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.050004
Average KL loss: 0.010814
Average total loss: 0.060819
tensor(0.0854, device='cuda:0') tensor(0.1306, device='cuda:0') tensor(-3.2973e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.047455
Average KL loss: 0.010816
Average total loss: 0.058272
tensor(0.0854, device='cuda:0') tensor(0.1306, device='cuda:0') tensor(-3.8457e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.047705
Average KL loss: 0.010817
Average total loss: 0.058523
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.4064e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.046746
Average KL loss: 0.010818
Average total loss: 0.057564
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-4.2600e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.047621
Average KL loss: 0.010818
Average total loss: 0.058439
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.0855e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.047105
Average KL loss: 0.010818
Average total loss: 0.057923
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.3367e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.048737
Average KL loss: 0.010818
Average total loss: 0.059556
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.1032e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.047684
Average KL loss: 0.010819
Average total loss: 0.058503
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.0094e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.046954
Average KL loss: 0.010819
Average total loss: 0.057773
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-4.0204e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.047501
Average KL loss: 0.010819
Average total loss: 0.058320
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.4626e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.049301
Average KL loss: 0.010819
Average total loss: 0.060120
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.4343e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.047293
Average KL loss: 0.010819
Average total loss: 0.058112
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-4.4273e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.046362
Average KL loss: 0.010819
Average total loss: 0.057181
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.2617e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.047307
Average KL loss: 0.010819
Average total loss: 0.058127
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.0046e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.047792
Average KL loss: 0.010819
Average total loss: 0.058612
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.7054e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.047112
Average KL loss: 0.010819
Average total loss: 0.057931
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-4.4066e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.047064
Average KL loss: 0.010820
Average total loss: 0.057884
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.5706e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.046463
Average KL loss: 0.010820
Average total loss: 0.057283
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.0691e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.048418
Average KL loss: 0.010820
Average total loss: 0.059237
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-5.5521e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.046884
Average KL loss: 0.010820
Average total loss: 0.057704
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.2334e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.046834
Average KL loss: 0.010820
Average total loss: 0.057655
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.9354e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.047940
Average KL loss: 0.010820
Average total loss: 0.058761
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.3127e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.047662
Average KL loss: 0.010820
Average total loss: 0.058482
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.9120e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.046463
Average KL loss: 0.010821
Average total loss: 0.057284
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.3923e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.047176
Average KL loss: 0.010821
Average total loss: 0.057997
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.3417e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.046470
Average KL loss: 0.010821
Average total loss: 0.057291
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.4933e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.046748
Average KL loss: 0.010821
Average total loss: 0.057569
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.7147e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.047482
Average KL loss: 0.010821
Average total loss: 0.058302
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.9685e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.047463
Average KL loss: 0.010821
Average total loss: 0.058284
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.8630e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.046180
Average KL loss: 0.010821
Average total loss: 0.057001
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.2377e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.046619
Average KL loss: 0.010821
Average total loss: 0.057440
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.9182e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.047181
Average KL loss: 0.010821
Average total loss: 0.058002
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-4.7688e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.046484
Average KL loss: 0.010821
Average total loss: 0.057304
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.8368e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.047706
Average KL loss: 0.010821
Average total loss: 0.058526
tensor(0.0854, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.0930e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.047854
Average KL loss: 0.010821
Average total loss: 0.058674
tensor(0.0854, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-3.1573e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.046800
Average KL loss: 0.010821
Average total loss: 0.057621
tensor(0.0854, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-2.5087e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.047107
Average KL loss: 0.010821
Average total loss: 0.057928
tensor(0.0854, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-2.4828e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.046266
Average KL loss: 0.010821
Average total loss: 0.057087
tensor(0.0854, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-3.0995e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.046511
Average KL loss: 0.010821
Average total loss: 0.057332
tensor(0.0854, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-3.2028e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.047643
Average KL loss: 0.010821
Average total loss: 0.058464
tensor(0.0854, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-3.1985e-09, device='cuda:0')
 Percentile value: 0.08036723583936692
Non-zero model percentage: 13.42179012298584%, Non-zero mask percentage: 13.42179012298584%

--- Pruning Level [9/24]: ---
conv1.weight         | nonzeros =     191 /    1728             ( 11.05%) | total_pruned =    1537 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     308 /   36864             (  0.84%) | total_pruned =   36556 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     925 /   36864             (  2.51%) | total_pruned =   35939 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1461 /   36864             (  3.96%) | total_pruned =   35403 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2594 /   36864             (  7.04%) | total_pruned =   34270 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   12239 /   73728             ( 16.60%) | total_pruned =   61489 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   26581 /  147456             ( 18.03%) | total_pruned =  120875 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1995 /    8192             ( 24.35%) | total_pruned =    6197 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   18011 /  147456             ( 12.21%) | total_pruned =  129445 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   14632 /  147456             (  9.92%) | total_pruned =  132824 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   76266 /  294912             ( 25.86%) | total_pruned =  218646 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  121543 /  589824             ( 20.61%) | total_pruned =  468281 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    9227 /   32768             ( 28.16%) | total_pruned =   23541 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     214 /     256             ( 83.59%) | total_pruned =      42 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   69854 /  589824             ( 11.84%) | total_pruned =  519970 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     180 /     256             ( 70.31%) | total_pruned =      76 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   46946 /  589824             (  7.96%) | total_pruned =  542878 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     174 /     256             ( 67.97%) | total_pruned =      82 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  194874 / 1179648             ( 16.52%) | total_pruned =  984774 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     416 /     512             ( 81.25%) | total_pruned =      96 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  221115 / 2359296             (  9.37%) | total_pruned = 2138181 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     396 /     512             ( 77.34%) | total_pruned =     116 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     228 /     512             ( 44.53%) | total_pruned =     284 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    9658 /  131072             (  7.37%) | total_pruned =  121414 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     235 /     512             ( 45.90%) | total_pruned =     277 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     227 /     512             ( 44.34%) | total_pruned =     285 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  157469 / 2359296             (  6.67%) | total_pruned = 2201827 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     296 /     512             ( 57.81%) | total_pruned =     216 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  506101 / 2359296             ( 21.45%) | total_pruned = 1853195 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     426 /     512             ( 83.20%) | total_pruned =      86 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     408 /     512             ( 79.69%) | total_pruned =     104 | shape = torch.Size([512])
linear.weight        | nonzeros =    4003 /    5120             ( 78.18%) | total_pruned =    1117 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1500390, pruned : 9678372, total: 11178762, Compression rate :       7.45x  ( 86.58% pruned)
Train Epoch: 35/100 Loss: 0.029833 Accuracy: 88.66 100.00 % Best test Accuracy: 88.79%
tensor(0.0854, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-4.6718e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.059671
Average KL loss: 0.010794
Average total loss: 0.070465
tensor(0.0852, device='cuda:0') tensor(0.1302, device='cuda:0') tensor(-4.9272e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.057745
Average KL loss: 0.010775
Average total loss: 0.068520
tensor(0.0851, device='cuda:0') tensor(0.1300, device='cuda:0') tensor(-5.8000e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.058811
Average KL loss: 0.010762
Average total loss: 0.069572
tensor(0.0851, device='cuda:0') tensor(0.1299, device='cuda:0') tensor(-5.1173e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.057678
Average KL loss: 0.010751
Average total loss: 0.068429
tensor(0.0850, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-6.6403e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.058477
Average KL loss: 0.010740
Average total loss: 0.069218
tensor(0.0850, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-4.3648e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.057678
Average KL loss: 0.010731
Average total loss: 0.068409
tensor(0.0849, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-3.5873e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.056511
Average KL loss: 0.010722
Average total loss: 0.067233
tensor(0.0849, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-3.5547e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.057244
Average KL loss: 0.010714
Average total loss: 0.067958
tensor(0.0849, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-6.5680e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.055059
Average KL loss: 0.010707
Average total loss: 0.065766
tensor(0.0848, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-3.7531e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.056000
Average KL loss: 0.010699
Average total loss: 0.066699
tensor(0.0848, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-3.8729e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.055969
Average KL loss: 0.010692
Average total loss: 0.066662
tensor(0.0847, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-4.1061e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.055125
Average KL loss: 0.010685
Average total loss: 0.065811
tensor(0.0847, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-7.6489e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.053821
Average KL loss: 0.010679
Average total loss: 0.064500
tensor(0.0846, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-4.4511e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.057528
Average KL loss: 0.010673
Average total loss: 0.068201
tensor(0.0846, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-3.7693e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.054800
Average KL loss: 0.010668
Average total loss: 0.065468
tensor(0.0846, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-4.5262e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.053806
Average KL loss: 0.010663
Average total loss: 0.064469
tensor(0.0845, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-3.9481e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.054719
Average KL loss: 0.010658
Average total loss: 0.065377
tensor(0.0845, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-3.7620e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.053685
Average KL loss: 0.010653
Average total loss: 0.064338
tensor(0.0844, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-4.1255e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.054654
Average KL loss: 0.010649
Average total loss: 0.065303
tensor(0.0844, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-4.8010e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.052538
Average KL loss: 0.010645
Average total loss: 0.063183
tensor(0.0844, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-4.8061e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.053528
Average KL loss: 0.010641
Average total loss: 0.064168
tensor(0.0843, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-3.6232e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.053824
Average KL loss: 0.010637
Average total loss: 0.064461
tensor(0.0843, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-3.5527e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.052134
Average KL loss: 0.010633
Average total loss: 0.062767
tensor(0.0843, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-3.9009e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.053333
Average KL loss: 0.010629
Average total loss: 0.063962
tensor(0.0842, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-4.9914e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.053452
Average KL loss: 0.010626
Average total loss: 0.064079
tensor(0.0842, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-3.4453e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.053565
Average KL loss: 0.010623
Average total loss: 0.064188
tensor(0.0842, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-5.4829e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.054075
Average KL loss: 0.010620
Average total loss: 0.064696
tensor(0.0841, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-4.8198e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.052896
Average KL loss: 0.010618
Average total loss: 0.063514
tensor(0.0841, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-4.8644e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.052391
Average KL loss: 0.010616
Average total loss: 0.063006
tensor(0.0841, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-3.4776e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.052822
Average KL loss: 0.010613
Average total loss: 0.063435
tensor(0.0840, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-3.5991e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.052547
Average KL loss: 0.010612
Average total loss: 0.063159
tensor(0.0840, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-3.8394e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.051680
Average KL loss: 0.010610
Average total loss: 0.062290
tensor(0.0840, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-4.3521e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.052004
Average KL loss: 0.010607
Average total loss: 0.062612
tensor(0.0840, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-3.7015e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.052161
Average KL loss: 0.010606
Average total loss: 0.062767
tensor(0.0839, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-3.5375e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.052212
Average KL loss: 0.010604
Average total loss: 0.062816
tensor(0.0839, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-3.6422e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.050610
Average KL loss: 0.010602
Average total loss: 0.061213
tensor(0.0839, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-4.9647e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.051670
Average KL loss: 0.010601
Average total loss: 0.062271
tensor(0.0839, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-4.7188e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.051967
Average KL loss: 0.010600
Average total loss: 0.062567
tensor(0.0838, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-5.7548e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.050705
Average KL loss: 0.010599
Average total loss: 0.061304
tensor(0.0838, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-3.5237e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.049468
Average KL loss: 0.010598
Average total loss: 0.060066
tensor(0.0838, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-4.1832e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.054349
Average KL loss: 0.010597
Average total loss: 0.064946
tensor(0.0838, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-4.3712e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.052865
Average KL loss: 0.010597
Average total loss: 0.063462
tensor(0.0837, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-4.2153e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.049606
Average KL loss: 0.010596
Average total loss: 0.060203
tensor(0.0837, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-3.1217e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.048358
Average KL loss: 0.010595
Average total loss: 0.058953
tensor(0.0837, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-4.2654e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.054156
Average KL loss: 0.010595
Average total loss: 0.064751
tensor(0.0837, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-4.5060e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.052749
Average KL loss: 0.010594
Average total loss: 0.063344
tensor(0.0837, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-4.4128e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.050295
Average KL loss: 0.010594
Average total loss: 0.060889
tensor(0.0836, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-4.2688e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.051427
Average KL loss: 0.010594
Average total loss: 0.062021
tensor(0.0836, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-3.5284e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.050008
Average KL loss: 0.010594
Average total loss: 0.060602
tensor(0.0836, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-4.4309e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.049966
Average KL loss: 0.010594
Average total loss: 0.060560
tensor(0.0836, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-3.9211e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.052397
Average KL loss: 0.010594
Average total loss: 0.062991
tensor(0.0836, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-1.9271e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.049718
Average KL loss: 0.010594
Average total loss: 0.060312
tensor(0.0835, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-2.9237e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.051532
Average KL loss: 0.010595
Average total loss: 0.062127
tensor(0.0835, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-3.7729e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.049090
Average KL loss: 0.010595
Average total loss: 0.059685
tensor(0.0835, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-3.7128e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.049038
Average KL loss: 0.010595
Average total loss: 0.059633
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-2.7831e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.049971
Average KL loss: 0.010596
Average total loss: 0.060567
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.6643e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.049178
Average KL loss: 0.010596
Average total loss: 0.059773
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.7784e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.048884
Average KL loss: 0.010595
Average total loss: 0.059479
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.6551e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.049098
Average KL loss: 0.010595
Average total loss: 0.059693
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.9689e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.049618
Average KL loss: 0.010595
Average total loss: 0.060214
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-2.6008e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.049249
Average KL loss: 0.010595
Average total loss: 0.059845
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-2.0736e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.050067
Average KL loss: 0.010595
Average total loss: 0.060662
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.8623e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.049291
Average KL loss: 0.010596
Average total loss: 0.059887
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-4.3542e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.049941
Average KL loss: 0.010596
Average total loss: 0.060536
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.9069e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.049156
Average KL loss: 0.010596
Average total loss: 0.059752
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-4.1079e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.049150
Average KL loss: 0.010595
Average total loss: 0.059746
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.2137e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.049560
Average KL loss: 0.010596
Average total loss: 0.060155
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-1.0112e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.049003
Average KL loss: 0.010596
Average total loss: 0.059599
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.3131e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.052967
Average KL loss: 0.010596
Average total loss: 0.063562
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.8166e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.049723
Average KL loss: 0.010596
Average total loss: 0.060319
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-4.4414e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.048698
Average KL loss: 0.010596
Average total loss: 0.059293
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-4.0561e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.048657
Average KL loss: 0.010596
Average total loss: 0.059252
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.0570e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.048583
Average KL loss: 0.010596
Average total loss: 0.059179
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.3065e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.048094
Average KL loss: 0.010596
Average total loss: 0.058689
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.7721e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.049265
Average KL loss: 0.010596
Average total loss: 0.059861
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-2.8537e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.048412
Average KL loss: 0.010595
Average total loss: 0.059007
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-4.5990e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.049986
Average KL loss: 0.010596
Average total loss: 0.060581
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.7283e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.048959
Average KL loss: 0.010596
Average total loss: 0.059555
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-2.9451e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.049391
Average KL loss: 0.010596
Average total loss: 0.059987
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.4355e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.048288
Average KL loss: 0.010596
Average total loss: 0.058883
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-6.2585e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.049253
Average KL loss: 0.010596
Average total loss: 0.059849
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.1495e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.049178
Average KL loss: 0.010596
Average total loss: 0.059773
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.2769e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.049403
Average KL loss: 0.010596
Average total loss: 0.059999
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.4673e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.048371
Average KL loss: 0.010596
Average total loss: 0.058966
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-2.7176e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.047870
Average KL loss: 0.010596
Average total loss: 0.058466
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.1908e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.050060
Average KL loss: 0.010596
Average total loss: 0.060655
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-2.8974e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.051301
Average KL loss: 0.010596
Average total loss: 0.061897
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-4.4222e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.048655
Average KL loss: 0.010596
Average total loss: 0.059250
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.2772e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.048994
Average KL loss: 0.010596
Average total loss: 0.059589
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-2.6295e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.049371
Average KL loss: 0.010596
Average total loss: 0.059966
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-2.9216e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.049504
Average KL loss: 0.010596
Average total loss: 0.060100
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.2774e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.048870
Average KL loss: 0.010596
Average total loss: 0.059466
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.1454e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.049804
Average KL loss: 0.010596
Average total loss: 0.060399
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.1648e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.050090
Average KL loss: 0.010596
Average total loss: 0.060685
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.4522e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.048548
Average KL loss: 0.010596
Average total loss: 0.059143
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.9292e-09, device='cuda:0')
 Percentile value: 0.20405726730823517
Non-zero model percentage: 10.737431526184082%, Non-zero mask percentage: 10.737431526184082%

--- Pruning Level [10/24]: ---
conv1.weight         | nonzeros =     190 /    1728             ( 11.00%) | total_pruned =    1538 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     281 /   36864             (  0.76%) | total_pruned =   36583 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     816 /   36864             (  2.21%) | total_pruned =   36048 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1324 /   36864             (  3.59%) | total_pruned =   35540 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2493 /   36864             (  6.76%) | total_pruned =   34371 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   11545 /   73728             ( 15.66%) | total_pruned =   62183 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   24984 /  147456             ( 16.94%) | total_pruned =  122472 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1944 /    8192             ( 23.73%) | total_pruned =    6248 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   16974 /  147456             ( 11.51%) | total_pruned =  130482 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   13514 /  147456             (  9.16%) | total_pruned =  133942 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   71227 /  294912             ( 24.15%) | total_pruned =  223685 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  109888 /  589824             ( 18.63%) | total_pruned =  479936 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     222 /     256             ( 86.72%) | total_pruned =      34 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    8812 /   32768             ( 26.89%) | total_pruned =   23956 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   63583 /  589824             ( 10.78%) | total_pruned =  526241 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     173 /     256             ( 67.58%) | total_pruned =      83 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   42826 /  589824             (  7.26%) | total_pruned =  546998 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     169 /     256             ( 66.02%) | total_pruned =      87 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  174925 / 1179648             ( 14.83%) | total_pruned = 1004723 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     411 /     512             ( 80.27%) | total_pruned =     101 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  188573 / 2359296             (  7.99%) | total_pruned = 2170723 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     388 /     512             ( 75.78%) | total_pruned =     124 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     227 /     512             ( 44.34%) | total_pruned =     285 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    8258 /  131072             (  6.30%) | total_pruned =  122814 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     220 /     512             ( 42.97%) | total_pruned =     292 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     226 /     512             ( 44.14%) | total_pruned =     286 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  123408 / 2359296             (  5.23%) | total_pruned = 2235888 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     292 /     512             ( 57.03%) | total_pruned =     220 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  326570 / 2359296             ( 13.84%) | total_pruned = 2032726 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     422 /     512             ( 82.42%) | total_pruned =      90 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
linear.weight        | nonzeros =    3849 /    5120             ( 75.18%) | total_pruned =    1271 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1200312, pruned : 9978450, total: 11178762, Compression rate :       9.31x  ( 89.26% pruned)
Train Epoch: 34/100 Loss: 0.018482 Accuracy: 89.00 100.00 % Best test Accuracy: 89.12%
tensor(0.0835, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-5.6451e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.060020
Average KL loss: 0.010572
Average total loss: 0.070592
tensor(0.0832, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-4.1358e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.056404
Average KL loss: 0.010557
Average total loss: 0.066961
tensor(0.0831, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-5.1120e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.057068
Average KL loss: 0.010547
Average total loss: 0.067616
tensor(0.0830, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-4.2677e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.056677
Average KL loss: 0.010539
Average total loss: 0.067216
tensor(0.0830, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-4.4839e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.055264
Average KL loss: 0.010532
Average total loss: 0.065797
tensor(0.0829, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-5.9485e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.055725
Average KL loss: 0.010526
Average total loss: 0.066251
tensor(0.0828, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-4.0110e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.054295
Average KL loss: 0.010520
Average total loss: 0.064815
tensor(0.0828, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-3.5268e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.056938
Average KL loss: 0.010514
Average total loss: 0.067453
tensor(0.0827, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-5.2523e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.055031
Average KL loss: 0.010510
Average total loss: 0.065540
tensor(0.0826, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-6.4010e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.054320
Average KL loss: 0.010505
Average total loss: 0.064825
tensor(0.0826, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-5.3384e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.054077
Average KL loss: 0.010502
Average total loss: 0.064578
tensor(0.0825, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-3.7654e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.056576
Average KL loss: 0.010498
Average total loss: 0.067074
tensor(0.0825, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(-4.1896e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.054505
Average KL loss: 0.010494
Average total loss: 0.065000
tensor(0.0824, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(-4.3568e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.054464
Average KL loss: 0.010491
Average total loss: 0.064954
tensor(0.0824, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(-3.8630e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.052589
Average KL loss: 0.010488
Average total loss: 0.063077
tensor(0.0823, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(-3.3853e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.053314
Average KL loss: 0.010485
Average total loss: 0.063798
tensor(0.0823, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-4.8675e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.052771
Average KL loss: 0.010482
Average total loss: 0.063253
tensor(0.0823, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-3.7930e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.053606
Average KL loss: 0.010479
Average total loss: 0.064085
tensor(0.0822, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-5.0183e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.052644
Average KL loss: 0.010477
Average total loss: 0.063121
tensor(0.0822, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-4.1295e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.052919
Average KL loss: 0.010475
Average total loss: 0.063394
tensor(0.0822, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-4.0318e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.051914
Average KL loss: 0.010473
Average total loss: 0.062388
tensor(0.0821, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-3.6704e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.051346
Average KL loss: 0.010471
Average total loss: 0.061817
tensor(0.0821, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-3.9472e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.051586
Average KL loss: 0.010469
Average total loss: 0.062055
tensor(0.0821, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-5.0619e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.052678
Average KL loss: 0.010468
Average total loss: 0.063147
tensor(0.0820, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-3.1300e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.052888
Average KL loss: 0.010468
Average total loss: 0.063356
tensor(0.0820, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-3.6543e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.050585
Average KL loss: 0.010467
Average total loss: 0.061052
tensor(0.0820, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-3.6010e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.051353
Average KL loss: 0.010465
Average total loss: 0.061818
tensor(0.0820, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-2.9440e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.051739
Average KL loss: 0.010465
Average total loss: 0.062203
tensor(0.0819, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-5.2033e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.052214
Average KL loss: 0.010464
Average total loss: 0.062678
tensor(0.0819, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-5.0987e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.050450
Average KL loss: 0.010464
Average total loss: 0.060914
tensor(0.0819, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-3.8679e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.052505
Average KL loss: 0.010464
Average total loss: 0.062968
tensor(0.0819, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-4.0877e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.051757
Average KL loss: 0.010463
Average total loss: 0.062220
tensor(0.0818, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-4.0196e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.050446
Average KL loss: 0.010463
Average total loss: 0.060909
tensor(0.0818, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-3.8466e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.051281
Average KL loss: 0.010463
Average total loss: 0.061744
tensor(0.0818, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-3.4786e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.050746
Average KL loss: 0.010463
Average total loss: 0.061209
tensor(0.0818, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(-3.7439e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.050250
Average KL loss: 0.010463
Average total loss: 0.060714
tensor(0.0818, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(-3.6852e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.050642
Average KL loss: 0.010464
Average total loss: 0.061106
tensor(0.0818, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(-3.9134e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.049196
Average KL loss: 0.010464
Average total loss: 0.059660
tensor(0.0817, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(-2.6529e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.049988
Average KL loss: 0.010463
Average total loss: 0.060451
tensor(0.0817, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(-3.8231e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.049306
Average KL loss: 0.010464
Average total loss: 0.059770
tensor(0.0817, device='cuda:0') tensor(0.1283, device='cuda:0') tensor(-6.1731e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.049334
Average KL loss: 0.010464
Average total loss: 0.059798
tensor(0.0817, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-2.9437e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.049010
Average KL loss: 0.010465
Average total loss: 0.059474
tensor(0.0817, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-4.4863e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.049373
Average KL loss: 0.010465
Average total loss: 0.059838
tensor(0.0817, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-3.3409e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.048474
Average KL loss: 0.010466
Average total loss: 0.058940
tensor(0.0816, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-3.9375e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.049681
Average KL loss: 0.010467
Average total loss: 0.060148
tensor(0.0816, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-3.2885e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.048656
Average KL loss: 0.010468
Average total loss: 0.059124
tensor(0.0816, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-3.0474e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.048390
Average KL loss: 0.010468
Average total loss: 0.058858
tensor(0.0816, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-2.4855e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.048973
Average KL loss: 0.010469
Average total loss: 0.059442
tensor(0.0816, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-3.3845e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.049093
Average KL loss: 0.010470
Average total loss: 0.059564
tensor(0.0816, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-4.3347e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.048677
Average KL loss: 0.010471
Average total loss: 0.059149
tensor(0.0816, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-2.6399e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.047972
Average KL loss: 0.010472
Average total loss: 0.058444
tensor(0.0815, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-3.9593e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.048060
Average KL loss: 0.010473
Average total loss: 0.058533
tensor(0.0815, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-2.4993e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.048873
Average KL loss: 0.010474
Average total loss: 0.059347
tensor(0.0815, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-3.8304e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.048467
Average KL loss: 0.010475
Average total loss: 0.058942
tensor(0.0815, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-2.1658e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.047385
Average KL loss: 0.010476
Average total loss: 0.057861
tensor(0.0815, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-3.8743e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.047762
Average KL loss: 0.010478
Average total loss: 0.058240
tensor(0.0815, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-2.9896e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.047055
Average KL loss: 0.010479
Average total loss: 0.057534
tensor(0.0815, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-3.5217e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.047735
Average KL loss: 0.010481
Average total loss: 0.058216
tensor(0.0815, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-2.9332e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.048258
Average KL loss: 0.010482
Average total loss: 0.058741
tensor(0.0815, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-3.4367e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.047252
Average KL loss: 0.010484
Average total loss: 0.057736
tensor(0.0815, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-4.3977e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.047758
Average KL loss: 0.010485
Average total loss: 0.058244
tensor(0.0815, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-2.7840e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.047455
Average KL loss: 0.010487
Average total loss: 0.057942
tensor(0.0814, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-4.6895e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.047598
Average KL loss: 0.010489
Average total loss: 0.058087
tensor(0.0814, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-2.5192e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.047020
Average KL loss: 0.010490
Average total loss: 0.057511
tensor(0.0814, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-3.3161e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.046292
Average KL loss: 0.010492
Average total loss: 0.056784
tensor(0.0814, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-2.7769e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.046684
Average KL loss: 0.010493
Average total loss: 0.057177
tensor(0.0814, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-1.9966e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.045801
Average KL loss: 0.010495
Average total loss: 0.056296
tensor(0.0814, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-3.7696e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.046323
Average KL loss: 0.010497
Average total loss: 0.056819
tensor(0.0814, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-4.0326e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.046230
Average KL loss: 0.010498
Average total loss: 0.056729
tensor(0.0814, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-3.9769e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.046863
Average KL loss: 0.010500
Average total loss: 0.057363
tensor(0.0814, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-3.4147e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.046914
Average KL loss: 0.010501
Average total loss: 0.057415
tensor(0.0814, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-3.4189e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.046037
Average KL loss: 0.010503
Average total loss: 0.056540
tensor(0.0814, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-2.9360e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.046541
Average KL loss: 0.010504
Average total loss: 0.057046
tensor(0.0813, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-1.7105e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.046145
Average KL loss: 0.010506
Average total loss: 0.056652
tensor(0.0813, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.6806e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.045695
Average KL loss: 0.010509
Average total loss: 0.056203
tensor(0.0813, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-1.9743e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.046875
Average KL loss: 0.010511
Average total loss: 0.057386
tensor(0.0813, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.3986e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.045973
Average KL loss: 0.010513
Average total loss: 0.056486
tensor(0.0813, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-3.8596e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.046130
Average KL loss: 0.010515
Average total loss: 0.056644
tensor(0.0813, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-2.5022e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.045062
Average KL loss: 0.010517
Average total loss: 0.055579
tensor(0.0813, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-2.9958e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.045495
Average KL loss: 0.010519
Average total loss: 0.056014
tensor(0.0813, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-3.2029e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.046037
Average KL loss: 0.010521
Average total loss: 0.056558
tensor(0.0813, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.5158e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.043665
Average KL loss: 0.010523
Average total loss: 0.054188
tensor(0.0813, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.3871e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.045522
Average KL loss: 0.010524
Average total loss: 0.056046
tensor(0.0813, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-4.1589e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.045743
Average KL loss: 0.010526
Average total loss: 0.056270
tensor(0.0813, device='cuda:0') tensor(0.1299, device='cuda:0') tensor(-2.6077e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.044047
Average KL loss: 0.010528
Average total loss: 0.054576
tensor(0.0813, device='cuda:0') tensor(0.1299, device='cuda:0') tensor(-3.3572e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.044710
Average KL loss: 0.010530
Average total loss: 0.055240
tensor(0.0813, device='cuda:0') tensor(0.1300, device='cuda:0') tensor(-2.9351e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.044512
Average KL loss: 0.010533
Average total loss: 0.055045
tensor(0.0813, device='cuda:0') tensor(0.1300, device='cuda:0') tensor(-3.4172e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.045503
Average KL loss: 0.010535
Average total loss: 0.056038
tensor(0.0813, device='cuda:0') tensor(0.1301, device='cuda:0') tensor(-3.0712e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.044791
Average KL loss: 0.010537
Average total loss: 0.055327
tensor(0.0813, device='cuda:0') tensor(0.1301, device='cuda:0') tensor(-3.0491e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.045233
Average KL loss: 0.010539
Average total loss: 0.055772
tensor(0.0813, device='cuda:0') tensor(0.1302, device='cuda:0') tensor(-3.6065e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.044715
Average KL loss: 0.010541
Average total loss: 0.055256
tensor(0.0812, device='cuda:0') tensor(0.1302, device='cuda:0') tensor(-2.9795e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.044725
Average KL loss: 0.010543
Average total loss: 0.055268
tensor(0.0812, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-3.6550e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.048215
Average KL loss: 0.010545
Average total loss: 0.058760
tensor(0.0812, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-3.3221e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.044118
Average KL loss: 0.010547
Average total loss: 0.054665
tensor(0.0812, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-3.3585e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.044319
Average KL loss: 0.010547
Average total loss: 0.054866
tensor(0.0812, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-2.9729e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.044138
Average KL loss: 0.010547
Average total loss: 0.054685
tensor(0.0812, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-2.2854e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.044549
Average KL loss: 0.010547
Average total loss: 0.055096
tensor(0.0812, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-4.3648e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.044165
Average KL loss: 0.010548
Average total loss: 0.054713
tensor(0.0812, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-4.3091e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.047018
Average KL loss: 0.010548
Average total loss: 0.057565
tensor(0.0812, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-2.2148e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.044017
Average KL loss: 0.010548
Average total loss: 0.054565
tensor(0.0812, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-2.5776e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.043873
Average KL loss: 0.010548
Average total loss: 0.054421
tensor(0.0812, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-2.0889e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.044021
Average KL loss: 0.010548
Average total loss: 0.054570
tensor(0.0812, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-2.5479e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.044444
Average KL loss: 0.010549
Average total loss: 0.054993
tensor(0.0812, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-3.3197e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.044314
Average KL loss: 0.010549
Average total loss: 0.054862
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.6057e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.043467
Average KL loss: 0.010549
Average total loss: 0.054016
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-2.8277e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.043898
Average KL loss: 0.010549
Average total loss: 0.054447
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-2.2648e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.045461
Average KL loss: 0.010549
Average total loss: 0.056010
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.5329e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.045186
Average KL loss: 0.010549
Average total loss: 0.055735
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-2.9093e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.044458
Average KL loss: 0.010549
Average total loss: 0.055007
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.6967e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.043947
Average KL loss: 0.010549
Average total loss: 0.054496
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.5676e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.043747
Average KL loss: 0.010549
Average total loss: 0.054296
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.1301e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.043447
Average KL loss: 0.010549
Average total loss: 0.053996
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.6085e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.043259
Average KL loss: 0.010549
Average total loss: 0.053808
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-2.2248e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.045688
Average KL loss: 0.010549
Average total loss: 0.056237
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-2.8555e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.043380
Average KL loss: 0.010549
Average total loss: 0.053929
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.5933e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.044069
Average KL loss: 0.010549
Average total loss: 0.054619
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.3472e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.045034
Average KL loss: 0.010549
Average total loss: 0.055583
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-4.6368e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.045103
Average KL loss: 0.010549
Average total loss: 0.055652
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.4582e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.044620
Average KL loss: 0.010549
Average total loss: 0.055169
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-2.7552e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.044731
Average KL loss: 0.010549
Average total loss: 0.055280
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-2.3646e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.044748
Average KL loss: 0.010549
Average total loss: 0.055298
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-2.2380e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.044410
Average KL loss: 0.010549
Average total loss: 0.054959
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-4.2450e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.044120
Average KL loss: 0.010549
Average total loss: 0.054670
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.4874e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.043174
Average KL loss: 0.010549
Average total loss: 0.053723
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-2.9888e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.045195
Average KL loss: 0.010549
Average total loss: 0.055744
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.2468e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.045734
Average KL loss: 0.010549
Average total loss: 0.056283
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.8626e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.044290
Average KL loss: 0.010549
Average total loss: 0.054839
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.3817e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.045040
Average KL loss: 0.010549
Average total loss: 0.055590
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-2.7349e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.044571
Average KL loss: 0.010549
Average total loss: 0.055120
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-2.7689e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.043886
Average KL loss: 0.010549
Average total loss: 0.054436
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-2.2778e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.044346
Average KL loss: 0.010549
Average total loss: 0.054895
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-2.8489e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.044572
Average KL loss: 0.010549
Average total loss: 0.055121
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-2.0082e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.043633
Average KL loss: 0.010549
Average total loss: 0.054183
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-2.4113e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.044082
Average KL loss: 0.010549
Average total loss: 0.054631
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.8478e-09, device='cuda:0')
 Percentile value: 0.3412479877471924
Non-zero model percentage: 8.589949607849121%, Non-zero mask percentage: 8.589949607849121%

--- Pruning Level [11/24]: ---
conv1.weight         | nonzeros =     189 /    1728             ( 10.94%) | total_pruned =    1539 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     267 /   36864             (  0.72%) | total_pruned =   36597 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     600 /   36864             (  1.63%) | total_pruned =   36264 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     969 /   36864             (  2.63%) | total_pruned =   35895 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2274 /   36864             (  6.17%) | total_pruned =   34590 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   10292 /   73728             ( 13.96%) | total_pruned =   63436 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   22441 /  147456             ( 15.22%) | total_pruned =  125015 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1798 /    8192             ( 21.95%) | total_pruned =    6394 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   14885 /  147456             ( 10.09%) | total_pruned =  132571 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   11722 /  147456             (  7.95%) | total_pruned =  135734 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   63219 /  294912             ( 21.44%) | total_pruned =  231693 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     238 /     256             ( 92.97%) | total_pruned =      18 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   95126 /  589824             ( 16.13%) | total_pruned =  494698 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    8106 /   32768             ( 24.74%) | total_pruned =   24662 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   53798 /  589824             (  9.12%) | total_pruned =  536026 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     170 /     256             ( 66.41%) | total_pruned =      86 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   36699 /  589824             (  6.22%) | total_pruned =  553125 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     165 /     256             ( 64.45%) | total_pruned =      91 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  147628 / 1179648             ( 12.51%) | total_pruned = 1032020 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     406 /     512             ( 79.30%) | total_pruned =     106 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  151325 / 2359296             (  6.41%) | total_pruned = 2207971 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     383 /     512             ( 74.80%) | total_pruned =     129 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     222 /     512             ( 43.36%) | total_pruned =     290 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    6375 /  131072             (  4.86%) | total_pruned =  124697 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     208 /     512             ( 40.62%) | total_pruned =     304 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     222 /     512             ( 43.36%) | total_pruned =     290 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   94758 / 2359296             (  4.02%) | total_pruned = 2264538 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     287 /     512             ( 56.05%) | total_pruned =     225 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  229829 / 2359296             (  9.74%) | total_pruned = 2129467 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     417 /     512             ( 81.45%) | total_pruned =      95 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     388 /     512             ( 75.78%) | total_pruned =     124 | shape = torch.Size([512])
linear.weight        | nonzeros =    3701 /    5120             ( 72.29%) | total_pruned =    1419 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 960250, pruned : 10218512, total: 11178762, Compression rate :      11.64x  ( 91.41% pruned)
Train Epoch: 34/100 Loss: 0.017094 Accuracy: 89.18 100.00 % Best test Accuracy: 89.18%
tensor(0.0812, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.1792e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.051470
Average KL loss: 0.010522
Average total loss: 0.061992
tensor(0.0809, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-4.0417e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.054868
Average KL loss: 0.010501
Average total loss: 0.065369
tensor(0.0807, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-4.0806e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.049918
Average KL loss: 0.010485
Average total loss: 0.060403
tensor(0.0805, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-5.8904e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.049459
Average KL loss: 0.010472
Average total loss: 0.059931
tensor(0.0803, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-5.0994e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.049867
Average KL loss: 0.010459
Average total loss: 0.060326
tensor(0.0802, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-4.5210e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.050424
Average KL loss: 0.010448
Average total loss: 0.060872
tensor(0.0800, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-5.6918e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.049595
Average KL loss: 0.010438
Average total loss: 0.060033
tensor(0.0799, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-5.5871e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.048591
Average KL loss: 0.010428
Average total loss: 0.059019
tensor(0.0797, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-4.4304e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.047883
Average KL loss: 0.010419
Average total loss: 0.058302
tensor(0.0796, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-2.3003e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.049258
Average KL loss: 0.010411
Average total loss: 0.059669
tensor(0.0795, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-4.1968e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.049123
Average KL loss: 0.010403
Average total loss: 0.059526
tensor(0.0794, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-4.1258e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.048152
Average KL loss: 0.010396
Average total loss: 0.058548
tensor(0.0793, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-4.1342e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.050465
Average KL loss: 0.010390
Average total loss: 0.060855
tensor(0.0792, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-3.4010e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.048040
Average KL loss: 0.010383
Average total loss: 0.058423
tensor(0.0791, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-4.4958e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.048918
Average KL loss: 0.010378
Average total loss: 0.059296
tensor(0.0790, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-4.7061e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.047773
Average KL loss: 0.010372
Average total loss: 0.058145
tensor(0.0789, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-4.3051e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.047388
Average KL loss: 0.010368
Average total loss: 0.057756
tensor(0.0789, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-3.8607e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.047843
Average KL loss: 0.010363
Average total loss: 0.058206
tensor(0.0788, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-5.5120e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.047665
Average KL loss: 0.010358
Average total loss: 0.058023
tensor(0.0787, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-3.6477e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.047164
Average KL loss: 0.010354
Average total loss: 0.057518
tensor(0.0787, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-4.8347e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.048731
Average KL loss: 0.010350
Average total loss: 0.059081
tensor(0.0786, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-3.2180e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.048352
Average KL loss: 0.010346
Average total loss: 0.058697
tensor(0.0785, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-3.4240e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.047944
Average KL loss: 0.010342
Average total loss: 0.058287
tensor(0.0785, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-4.8107e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.046602
Average KL loss: 0.010339
Average total loss: 0.056942
tensor(0.0784, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-3.9349e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.047228
Average KL loss: 0.010337
Average total loss: 0.057564
tensor(0.0784, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-3.5297e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.045912
Average KL loss: 0.010333
Average total loss: 0.056246
tensor(0.0783, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-5.0738e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.047119
Average KL loss: 0.010330
Average total loss: 0.057449
tensor(0.0783, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-2.9526e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.047519
Average KL loss: 0.010328
Average total loss: 0.057847
tensor(0.0782, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-4.1704e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.047077
Average KL loss: 0.010326
Average total loss: 0.057403
tensor(0.0782, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-2.7799e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.045705
Average KL loss: 0.010324
Average total loss: 0.056030
tensor(0.0782, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-3.4385e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.045977
Average KL loss: 0.010322
Average total loss: 0.056299
tensor(0.0781, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-2.5940e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.045559
Average KL loss: 0.010320
Average total loss: 0.055879
tensor(0.0781, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-2.9429e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.045807
Average KL loss: 0.010318
Average total loss: 0.056125
tensor(0.0780, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-2.3992e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.045355
Average KL loss: 0.010316
Average total loss: 0.055671
tensor(0.0780, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-4.1901e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.045299
Average KL loss: 0.010315
Average total loss: 0.055614
tensor(0.0780, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-3.8585e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.046097
Average KL loss: 0.010313
Average total loss: 0.056411
tensor(0.0779, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-3.0111e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.046327
Average KL loss: 0.010312
Average total loss: 0.056639
tensor(0.0779, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-3.1793e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.045021
Average KL loss: 0.010311
Average total loss: 0.055332
tensor(0.0779, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-2.8414e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.044522
Average KL loss: 0.010310
Average total loss: 0.054831
tensor(0.0779, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-3.3179e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.046604
Average KL loss: 0.010309
Average total loss: 0.056913
tensor(0.0778, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-3.7771e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.045028
Average KL loss: 0.010309
Average total loss: 0.055337
tensor(0.0778, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-3.1396e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.045182
Average KL loss: 0.010308
Average total loss: 0.055490
tensor(0.0778, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-3.4846e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.044528
Average KL loss: 0.010308
Average total loss: 0.054836
tensor(0.0778, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-3.5375e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.044704
Average KL loss: 0.010307
Average total loss: 0.055011
tensor(0.0777, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-3.2029e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.044129
Average KL loss: 0.010307
Average total loss: 0.054436
tensor(0.0777, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-3.5815e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.044599
Average KL loss: 0.010307
Average total loss: 0.054905
tensor(0.0777, device='cuda:0') tensor(0.1285, device='cuda:0') tensor(-1.7587e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.045175
Average KL loss: 0.010306
Average total loss: 0.055481
tensor(0.0777, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-2.3305e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.044311
Average KL loss: 0.010307
Average total loss: 0.054618
tensor(0.0776, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-2.1379e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.046996
Average KL loss: 0.010307
Average total loss: 0.057302
tensor(0.0776, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-3.3417e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.044497
Average KL loss: 0.010307
Average total loss: 0.054804
tensor(0.0776, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-2.5474e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.045318
Average KL loss: 0.010308
Average total loss: 0.055625
tensor(0.0776, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-3.2622e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.043383
Average KL loss: 0.010308
Average total loss: 0.053691
tensor(0.0776, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-4.4605e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.044641
Average KL loss: 0.010308
Average total loss: 0.054949
tensor(0.0776, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-3.5200e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.044111
Average KL loss: 0.010308
Average total loss: 0.054419
tensor(0.0775, device='cuda:0') tensor(0.1287, device='cuda:0') tensor(-3.3135e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.044070
Average KL loss: 0.010309
Average total loss: 0.054379
tensor(0.0775, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-2.8063e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.043425
Average KL loss: 0.010310
Average total loss: 0.053735
tensor(0.0775, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-2.5989e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.043898
Average KL loss: 0.010310
Average total loss: 0.054208
tensor(0.0775, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-1.9938e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.044094
Average KL loss: 0.010311
Average total loss: 0.054404
tensor(0.0775, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-2.5612e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.042852
Average KL loss: 0.010311
Average total loss: 0.053163
tensor(0.0775, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-4.1568e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.043124
Average KL loss: 0.010312
Average total loss: 0.053436
tensor(0.0775, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-3.1148e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.043449
Average KL loss: 0.010313
Average total loss: 0.053762
tensor(0.0774, device='cuda:0') tensor(0.1289, device='cuda:0') tensor(-3.3734e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.044455
Average KL loss: 0.010313
Average total loss: 0.054769
tensor(0.0774, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-1.7217e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.043290
Average KL loss: 0.010314
Average total loss: 0.053604
tensor(0.0774, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-2.7103e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.043225
Average KL loss: 0.010315
Average total loss: 0.053540
tensor(0.0774, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-2.3089e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.042445
Average KL loss: 0.010316
Average total loss: 0.052761
tensor(0.0774, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-2.9702e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.042388
Average KL loss: 0.010317
Average total loss: 0.052705
tensor(0.0774, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-4.0321e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.042896
Average KL loss: 0.010318
Average total loss: 0.053214
tensor(0.0774, device='cuda:0') tensor(0.1291, device='cuda:0') tensor(-4.5048e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.044197
Average KL loss: 0.010319
Average total loss: 0.054516
tensor(0.0774, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-2.2779e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.042105
Average KL loss: 0.010320
Average total loss: 0.052426
tensor(0.0773, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-2.0257e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.043169
Average KL loss: 0.010322
Average total loss: 0.053491
tensor(0.0773, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-2.5918e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.041244
Average KL loss: 0.010323
Average total loss: 0.051566
tensor(0.0773, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-2.6187e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.042718
Average KL loss: 0.010324
Average total loss: 0.053041
tensor(0.0773, device='cuda:0') tensor(0.1293, device='cuda:0') tensor(-2.9405e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.042261
Average KL loss: 0.010325
Average total loss: 0.052586
tensor(0.0773, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-3.2380e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.041650
Average KL loss: 0.010326
Average total loss: 0.051975
tensor(0.0773, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-2.9498e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.042025
Average KL loss: 0.010327
Average total loss: 0.052352
tensor(0.0773, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-1.9030e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.042413
Average KL loss: 0.010328
Average total loss: 0.052741
tensor(0.0773, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-2.4910e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.047567
Average KL loss: 0.010330
Average total loss: 0.057897
tensor(0.0773, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.3296e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.042427
Average KL loss: 0.010331
Average total loss: 0.052758
tensor(0.0773, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.6027e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.043420
Average KL loss: 0.010333
Average total loss: 0.053753
tensor(0.0772, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-2.7435e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.042613
Average KL loss: 0.010334
Average total loss: 0.052947
tensor(0.0772, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-3.3964e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.041726
Average KL loss: 0.010336
Average total loss: 0.052062
tensor(0.0772, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-2.5659e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.041543
Average KL loss: 0.010337
Average total loss: 0.051880
tensor(0.0772, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-3.3084e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.042596
Average KL loss: 0.010338
Average total loss: 0.052934
tensor(0.0772, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-3.3457e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.041887
Average KL loss: 0.010338
Average total loss: 0.052225
tensor(0.0772, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-3.2025e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.044078
Average KL loss: 0.010339
Average total loss: 0.054417
tensor(0.0772, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-3.1714e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.041601
Average KL loss: 0.010339
Average total loss: 0.051939
tensor(0.0772, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-1.4103e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.042049
Average KL loss: 0.010339
Average total loss: 0.052388
tensor(0.0772, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-3.2309e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.041625
Average KL loss: 0.010339
Average total loss: 0.051964
tensor(0.0772, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-2.2600e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.040934
Average KL loss: 0.010339
Average total loss: 0.051273
tensor(0.0772, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-3.4291e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.041576
Average KL loss: 0.010339
Average total loss: 0.051915
tensor(0.0772, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-3.0549e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.042463
Average KL loss: 0.010339
Average total loss: 0.052802
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.1744e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.041630
Average KL loss: 0.010340
Average total loss: 0.051969
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.6336e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.041529
Average KL loss: 0.010340
Average total loss: 0.051869
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.0432e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.040700
Average KL loss: 0.010340
Average total loss: 0.051040
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.2235e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.041485
Average KL loss: 0.010340
Average total loss: 0.051825
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-3.1382e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.042028
Average KL loss: 0.010340
Average total loss: 0.052368
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.2237e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.042143
Average KL loss: 0.010340
Average total loss: 0.052483
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-1.9558e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.040039
Average KL loss: 0.010340
Average total loss: 0.050379
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.4528e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.042600
Average KL loss: 0.010340
Average total loss: 0.052941
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.7218e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.041824
Average KL loss: 0.010341
Average total loss: 0.052165
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-3.2319e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.041506
Average KL loss: 0.010341
Average total loss: 0.051847
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.0958e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.041523
Average KL loss: 0.010341
Average total loss: 0.051864
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.8453e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.042043
Average KL loss: 0.010341
Average total loss: 0.052384
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-3.3068e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.041656
Average KL loss: 0.010341
Average total loss: 0.051997
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.8094e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.041589
Average KL loss: 0.010341
Average total loss: 0.051930
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.7254e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.041446
Average KL loss: 0.010342
Average total loss: 0.051788
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.5111e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.041520
Average KL loss: 0.010342
Average total loss: 0.051862
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.4389e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.041019
Average KL loss: 0.010342
Average total loss: 0.051361
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.2154e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.042448
Average KL loss: 0.010342
Average total loss: 0.052790
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.3017e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.041501
Average KL loss: 0.010342
Average total loss: 0.051843
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-3.4941e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.041104
Average KL loss: 0.010342
Average total loss: 0.051446
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.4599e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.042158
Average KL loss: 0.010342
Average total loss: 0.052500
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.9271e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.041942
Average KL loss: 0.010342
Average total loss: 0.052284
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.7451e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.041764
Average KL loss: 0.010342
Average total loss: 0.052107
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-3.0572e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.041723
Average KL loss: 0.010342
Average total loss: 0.052065
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-3.7309e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.041501
Average KL loss: 0.010342
Average total loss: 0.051844
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-4.0343e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.041444
Average KL loss: 0.010342
Average total loss: 0.051786
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.3045e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.041366
Average KL loss: 0.010342
Average total loss: 0.051708
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-2.6450e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.041413
Average KL loss: 0.010342
Average total loss: 0.051755
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-4.0669e-09, device='cuda:0')
 Percentile value: 0.4715509593486786
Non-zero model percentage: 6.871959686279297%, Non-zero mask percentage: 6.871959686279297%

--- Pruning Level [12/24]: ---
conv1.weight         | nonzeros =     189 /    1728             ( 10.94%) | total_pruned =    1539 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     242 /   36864             (  0.66%) | total_pruned =   36622 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     493 /   36864             (  1.34%) | total_pruned =   36371 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     891 /   36864             (  2.42%) | total_pruned =   35973 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2203 /   36864             (  5.98%) | total_pruned =   34661 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    9453 /   73728             ( 12.82%) | total_pruned =   64275 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   19967 /  147456             ( 13.54%) | total_pruned =  127489 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1707 /    8192             ( 20.84%) | total_pruned =    6485 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   12872 /  147456             (  8.73%) | total_pruned =  134584 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   10255 /  147456             (  6.95%) | total_pruned =  137201 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   54979 /  294912             ( 18.64%) | total_pruned =  239933 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     238 /     256             ( 92.97%) | total_pruned =      18 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   81513 /  589824             ( 13.82%) | total_pruned =  508311 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     217 /     256             ( 84.77%) | total_pruned =      39 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    7281 /   32768             ( 22.22%) | total_pruned =   25487 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     205 /     256             ( 80.08%) | total_pruned =      51 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   43817 /  589824             (  7.43%) | total_pruned =  546007 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     167 /     256             ( 65.23%) | total_pruned =      89 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   30700 /  589824             (  5.20%) | total_pruned =  559124 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     158 /     256             ( 61.72%) | total_pruned =      98 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  120839 / 1179648             ( 10.24%) | total_pruned = 1058809 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     402 /     512             ( 78.52%) | total_pruned =     110 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  121365 / 2359296             (  5.14%) | total_pruned = 2237931 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     380 /     512             ( 74.22%) | total_pruned =     132 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     214 /     512             ( 41.80%) | total_pruned =     298 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    4930 /  131072             (  3.76%) | total_pruned =  126142 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     194 /     512             ( 37.89%) | total_pruned =     318 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     215 /     512             ( 41.99%) | total_pruned =     297 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   72857 / 2359296             (  3.09%) | total_pruned = 2286439 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     283 /     512             ( 55.27%) | total_pruned =     229 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  163934 / 2359296             (  6.95%) | total_pruned = 2195362 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     409 /     512             ( 79.88%) | total_pruned =     103 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     378 /     512             ( 73.83%) | total_pruned =     134 | shape = torch.Size([512])
linear.weight        | nonzeros =    3550 /    5120             ( 69.34%) | total_pruned =    1570 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 768200, pruned : 10410562, total: 11178762, Compression rate :      14.55x  ( 93.13% pruned)
Train Epoch: 34/100 Loss: 0.025011 Accuracy: 88.76 100.00 % Best test Accuracy: 88.85%
tensor(0.0772, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-6.6776e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.055154
Average KL loss: 0.010320
Average total loss: 0.065474
tensor(0.0769, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-4.8598e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.054087
Average KL loss: 0.010305
Average total loss: 0.064393
tensor(0.0767, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-4.6866e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.054130
Average KL loss: 0.010296
Average total loss: 0.064426
tensor(0.0765, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-5.6043e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.055444
Average KL loss: 0.010288
Average total loss: 0.065732
tensor(0.0763, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-4.4904e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.052370
Average KL loss: 0.010282
Average total loss: 0.062652
tensor(0.0761, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-4.4541e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.051338
Average KL loss: 0.010278
Average total loss: 0.061615
tensor(0.0760, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-4.2475e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.050609
Average KL loss: 0.010273
Average total loss: 0.060882
tensor(0.0758, device='cuda:0') tensor(0.1294, device='cuda:0') tensor(-6.0037e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.050855
Average KL loss: 0.010269
Average total loss: 0.061124
tensor(0.0757, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-4.5048e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.050010
Average KL loss: 0.010267
Average total loss: 0.060277
tensor(0.0756, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-5.5018e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.049140
Average KL loss: 0.010265
Average total loss: 0.059405
tensor(0.0755, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-4.9239e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.050573
Average KL loss: 0.010263
Average total loss: 0.060835
tensor(0.0754, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-4.2388e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.048571
Average KL loss: 0.010261
Average total loss: 0.058832
tensor(0.0753, device='cuda:0') tensor(0.1296, device='cuda:0') tensor(-4.7522e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.049113
Average KL loss: 0.010260
Average total loss: 0.059372
tensor(0.0752, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-3.5975e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.048589
Average KL loss: 0.010259
Average total loss: 0.058848
tensor(0.0751, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-3.6561e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.048686
Average KL loss: 0.010259
Average total loss: 0.058945
tensor(0.0750, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-4.2733e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.048506
Average KL loss: 0.010259
Average total loss: 0.058765
tensor(0.0749, device='cuda:0') tensor(0.1298, device='cuda:0') tensor(-5.2336e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.048207
Average KL loss: 0.010259
Average total loss: 0.058466
tensor(0.0749, device='cuda:0') tensor(0.1299, device='cuda:0') tensor(-5.4317e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.047782
Average KL loss: 0.010259
Average total loss: 0.058041
tensor(0.0748, device='cuda:0') tensor(0.1299, device='cuda:0') tensor(-5.4355e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.048040
Average KL loss: 0.010260
Average total loss: 0.058300
tensor(0.0748, device='cuda:0') tensor(0.1300, device='cuda:0') tensor(-3.1875e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.046999
Average KL loss: 0.010261
Average total loss: 0.057260
tensor(0.0747, device='cuda:0') tensor(0.1300, device='cuda:0') tensor(-4.8988e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.046968
Average KL loss: 0.010262
Average total loss: 0.057230
tensor(0.0747, device='cuda:0') tensor(0.1301, device='cuda:0') tensor(-3.8080e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.047274
Average KL loss: 0.010264
Average total loss: 0.057537
tensor(0.0746, device='cuda:0') tensor(0.1302, device='cuda:0') tensor(-5.5765e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.047665
Average KL loss: 0.010265
Average total loss: 0.057930
tensor(0.0746, device='cuda:0') tensor(0.1302, device='cuda:0') tensor(-4.4675e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.047347
Average KL loss: 0.010267
Average total loss: 0.057614
tensor(0.0745, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-4.2425e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.046985
Average KL loss: 0.010268
Average total loss: 0.057254
tensor(0.0745, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-4.1711e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.047016
Average KL loss: 0.010271
Average total loss: 0.057287
tensor(0.0745, device='cuda:0') tensor(0.1304, device='cuda:0') tensor(-3.9639e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.047010
Average KL loss: 0.010273
Average total loss: 0.057282
tensor(0.0745, device='cuda:0') tensor(0.1305, device='cuda:0') tensor(-3.2455e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.045435
Average KL loss: 0.010275
Average total loss: 0.055710
tensor(0.0744, device='cuda:0') tensor(0.1306, device='cuda:0') tensor(-3.4969e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.046052
Average KL loss: 0.010277
Average total loss: 0.056328
tensor(0.0744, device='cuda:0') tensor(0.1306, device='cuda:0') tensor(-5.3302e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.049981
Average KL loss: 0.010279
Average total loss: 0.060259
tensor(0.0744, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-4.5827e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.047482
Average KL loss: 0.010282
Average total loss: 0.057764
tensor(0.0744, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-3.6439e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.045693
Average KL loss: 0.010284
Average total loss: 0.055978
tensor(0.0744, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-2.8725e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.044929
Average KL loss: 0.010287
Average total loss: 0.055216
tensor(0.0743, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(-3.5392e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.044826
Average KL loss: 0.010289
Average total loss: 0.055115
tensor(0.0743, device='cuda:0') tensor(0.1310, device='cuda:0') tensor(-4.4635e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.044804
Average KL loss: 0.010292
Average total loss: 0.055096
tensor(0.0743, device='cuda:0') tensor(0.1310, device='cuda:0') tensor(-3.2754e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.048473
Average KL loss: 0.010294
Average total loss: 0.058767
tensor(0.0743, device='cuda:0') tensor(0.1311, device='cuda:0') tensor(-4.0885e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.045173
Average KL loss: 0.010298
Average total loss: 0.055470
tensor(0.0743, device='cuda:0') tensor(0.1312, device='cuda:0') tensor(-3.9835e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.044404
Average KL loss: 0.010300
Average total loss: 0.054704
tensor(0.0743, device='cuda:0') tensor(0.1312, device='cuda:0') tensor(-4.3264e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.045046
Average KL loss: 0.010302
Average total loss: 0.055348
tensor(0.0743, device='cuda:0') tensor(0.1313, device='cuda:0') tensor(-4.2768e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.044626
Average KL loss: 0.010305
Average total loss: 0.054931
tensor(0.0743, device='cuda:0') tensor(0.1314, device='cuda:0') tensor(-2.9809e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.044846
Average KL loss: 0.010308
Average total loss: 0.055154
tensor(0.0743, device='cuda:0') tensor(0.1314, device='cuda:0') tensor(-4.1320e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.045594
Average KL loss: 0.010311
Average total loss: 0.055904
tensor(0.0743, device='cuda:0') tensor(0.1315, device='cuda:0') tensor(-3.3460e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.044198
Average KL loss: 0.010313
Average total loss: 0.054511
tensor(0.0743, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-3.9093e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.044782
Average KL loss: 0.010316
Average total loss: 0.055098
tensor(0.0743, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-3.9033e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.043060
Average KL loss: 0.010320
Average total loss: 0.053379
tensor(0.0742, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-2.5666e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.044502
Average KL loss: 0.010323
Average total loss: 0.054825
tensor(0.0742, device='cuda:0') tensor(0.1318, device='cuda:0') tensor(-4.2719e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.043483
Average KL loss: 0.010326
Average total loss: 0.053809
tensor(0.0742, device='cuda:0') tensor(0.1319, device='cuda:0') tensor(-4.3539e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.043856
Average KL loss: 0.010329
Average total loss: 0.054185
tensor(0.0742, device='cuda:0') tensor(0.1319, device='cuda:0') tensor(-3.6646e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.044026
Average KL loss: 0.010332
Average total loss: 0.054357
tensor(0.0742, device='cuda:0') tensor(0.1320, device='cuda:0') tensor(-3.4021e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.043526
Average KL loss: 0.010335
Average total loss: 0.053860
tensor(0.0742, device='cuda:0') tensor(0.1321, device='cuda:0') tensor(-3.0102e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.042926
Average KL loss: 0.010337
Average total loss: 0.053263
tensor(0.0742, device='cuda:0') tensor(0.1322, device='cuda:0') tensor(-3.4099e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.044353
Average KL loss: 0.010341
Average total loss: 0.054694
tensor(0.0742, device='cuda:0') tensor(0.1322, device='cuda:0') tensor(-3.0185e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.042066
Average KL loss: 0.010344
Average total loss: 0.052410
tensor(0.0742, device='cuda:0') tensor(0.1323, device='cuda:0') tensor(-3.4028e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.041837
Average KL loss: 0.010347
Average total loss: 0.052184
tensor(0.0742, device='cuda:0') tensor(0.1324, device='cuda:0') tensor(-2.7922e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.043397
Average KL loss: 0.010350
Average total loss: 0.053747
tensor(0.0742, device='cuda:0') tensor(0.1325, device='cuda:0') tensor(-2.8024e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.043408
Average KL loss: 0.010353
Average total loss: 0.053761
tensor(0.0743, device='cuda:0') tensor(0.1325, device='cuda:0') tensor(-4.1616e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.043221
Average KL loss: 0.010356
Average total loss: 0.053577
tensor(0.0743, device='cuda:0') tensor(0.1326, device='cuda:0') tensor(-4.2481e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.042546
Average KL loss: 0.010359
Average total loss: 0.052905
tensor(0.0743, device='cuda:0') tensor(0.1327, device='cuda:0') tensor(-3.4306e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.043278
Average KL loss: 0.010363
Average total loss: 0.053641
tensor(0.0743, device='cuda:0') tensor(0.1328, device='cuda:0') tensor(-3.6684e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.042520
Average KL loss: 0.010366
Average total loss: 0.052886
tensor(0.0743, device='cuda:0') tensor(0.1328, device='cuda:0') tensor(-2.1261e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.044336
Average KL loss: 0.010369
Average total loss: 0.054704
tensor(0.0743, device='cuda:0') tensor(0.1329, device='cuda:0') tensor(-2.1397e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.042010
Average KL loss: 0.010372
Average total loss: 0.052382
tensor(0.0743, device='cuda:0') tensor(0.1330, device='cuda:0') tensor(-2.5276e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.041409
Average KL loss: 0.010375
Average total loss: 0.051784
tensor(0.0743, device='cuda:0') tensor(0.1330, device='cuda:0') tensor(-2.7988e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.042724
Average KL loss: 0.010378
Average total loss: 0.053102
tensor(0.0743, device='cuda:0') tensor(0.1331, device='cuda:0') tensor(-4.0005e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.042257
Average KL loss: 0.010381
Average total loss: 0.052638
tensor(0.0743, device='cuda:0') tensor(0.1332, device='cuda:0') tensor(-3.1454e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.041578
Average KL loss: 0.010384
Average total loss: 0.051962
tensor(0.0743, device='cuda:0') tensor(0.1333, device='cuda:0') tensor(-3.1445e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.041707
Average KL loss: 0.010387
Average total loss: 0.052094
tensor(0.0743, device='cuda:0') tensor(0.1333, device='cuda:0') tensor(-2.5407e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.041870
Average KL loss: 0.010390
Average total loss: 0.052261
tensor(0.0743, device='cuda:0') tensor(0.1334, device='cuda:0') tensor(-3.6074e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.041999
Average KL loss: 0.010394
Average total loss: 0.052393
tensor(0.0743, device='cuda:0') tensor(0.1335, device='cuda:0') tensor(-2.2211e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.041036
Average KL loss: 0.010397
Average total loss: 0.051433
tensor(0.0743, device='cuda:0') tensor(0.1336, device='cuda:0') tensor(-2.8121e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.041786
Average KL loss: 0.010401
Average total loss: 0.052186
tensor(0.0743, device='cuda:0') tensor(0.1336, device='cuda:0') tensor(-3.7198e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.042457
Average KL loss: 0.010404
Average total loss: 0.052861
tensor(0.0743, device='cuda:0') tensor(0.1337, device='cuda:0') tensor(-3.6061e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.041125
Average KL loss: 0.010407
Average total loss: 0.051532
tensor(0.0743, device='cuda:0') tensor(0.1338, device='cuda:0') tensor(-3.3510e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.040298
Average KL loss: 0.010410
Average total loss: 0.050708
tensor(0.0743, device='cuda:0') tensor(0.1338, device='cuda:0') tensor(-3.3684e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.041117
Average KL loss: 0.010413
Average total loss: 0.051529
tensor(0.0743, device='cuda:0') tensor(0.1339, device='cuda:0') tensor(-3.8497e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.041638
Average KL loss: 0.010416
Average total loss: 0.052054
tensor(0.0743, device='cuda:0') tensor(0.1340, device='cuda:0') tensor(-3.4077e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.040529
Average KL loss: 0.010419
Average total loss: 0.050948
tensor(0.0743, device='cuda:0') tensor(0.1341, device='cuda:0') tensor(-3.2359e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.042442
Average KL loss: 0.010423
Average total loss: 0.052865
tensor(0.0743, device='cuda:0') tensor(0.1341, device='cuda:0') tensor(-2.7743e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.041274
Average KL loss: 0.010426
Average total loss: 0.051700
tensor(0.0743, device='cuda:0') tensor(0.1342, device='cuda:0') tensor(-3.5300e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.042232
Average KL loss: 0.010430
Average total loss: 0.052662
tensor(0.0743, device='cuda:0') tensor(0.1343, device='cuda:0') tensor(-3.1762e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.040215
Average KL loss: 0.010433
Average total loss: 0.050648
tensor(0.0743, device='cuda:0') tensor(0.1344, device='cuda:0') tensor(-2.7824e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.040995
Average KL loss: 0.010436
Average total loss: 0.051431
tensor(0.0743, device='cuda:0') tensor(0.1344, device='cuda:0') tensor(-2.3434e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.040691
Average KL loss: 0.010439
Average total loss: 0.051131
tensor(0.0744, device='cuda:0') tensor(0.1345, device='cuda:0') tensor(-2.6086e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.039791
Average KL loss: 0.010443
Average total loss: 0.050235
tensor(0.0744, device='cuda:0') tensor(0.1346, device='cuda:0') tensor(-4.0566e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.040528
Average KL loss: 0.010447
Average total loss: 0.050974
tensor(0.0744, device='cuda:0') tensor(0.1347, device='cuda:0') tensor(-3.8234e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.040356
Average KL loss: 0.010450
Average total loss: 0.050807
tensor(0.0744, device='cuda:0') tensor(0.1348, device='cuda:0') tensor(-2.9543e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.040168
Average KL loss: 0.010453
Average total loss: 0.050621
tensor(0.0744, device='cuda:0') tensor(0.1348, device='cuda:0') tensor(-2.6088e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.040487
Average KL loss: 0.010457
Average total loss: 0.050944
tensor(0.0744, device='cuda:0') tensor(0.1349, device='cuda:0') tensor(-5.1804e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.039789
Average KL loss: 0.010460
Average total loss: 0.050249
tensor(0.0744, device='cuda:0') tensor(0.1350, device='cuda:0') tensor(-4.1894e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.039508
Average KL loss: 0.010463
Average total loss: 0.049972
tensor(0.0744, device='cuda:0') tensor(0.1351, device='cuda:0') tensor(-2.9854e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.040069
Average KL loss: 0.010467
Average total loss: 0.050535
tensor(0.0744, device='cuda:0') tensor(0.1351, device='cuda:0') tensor(-2.7769e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.040109
Average KL loss: 0.010470
Average total loss: 0.050579
tensor(0.0744, device='cuda:0') tensor(0.1352, device='cuda:0') tensor(-2.8950e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.040089
Average KL loss: 0.010473
Average total loss: 0.050563
tensor(0.0744, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.6324e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.039784
Average KL loss: 0.010477
Average total loss: 0.050261
tensor(0.0744, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(-3.2030e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.039577
Average KL loss: 0.010481
Average total loss: 0.050058
tensor(0.0744, device='cuda:0') tensor(0.1355, device='cuda:0') tensor(-2.8606e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.039738
Average KL loss: 0.010484
Average total loss: 0.050222
tensor(0.0744, device='cuda:0') tensor(0.1355, device='cuda:0') tensor(-2.5056e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.038697
Average KL loss: 0.010487
Average total loss: 0.049184
tensor(0.0744, device='cuda:0') tensor(0.1356, device='cuda:0') tensor(-2.5520e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.040644
Average KL loss: 0.010490
Average total loss: 0.051134
tensor(0.0745, device='cuda:0') tensor(0.1357, device='cuda:0') tensor(-2.3839e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.038848
Average KL loss: 0.010494
Average total loss: 0.049342
tensor(0.0745, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-2.1709e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.039386
Average KL loss: 0.010497
Average total loss: 0.049883
tensor(0.0745, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-3.3997e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.040240
Average KL loss: 0.010500
Average total loss: 0.050741
tensor(0.0745, device='cuda:0') tensor(0.1359, device='cuda:0') tensor(-2.9773e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.039471
Average KL loss: 0.010504
Average total loss: 0.049975
tensor(0.0745, device='cuda:0') tensor(0.1360, device='cuda:0') tensor(-3.2305e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.038580
Average KL loss: 0.010507
Average total loss: 0.049087
tensor(0.0745, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(-2.6379e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.040481
Average KL loss: 0.010510
Average total loss: 0.050991
tensor(0.0745, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(-2.9494e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.038322
Average KL loss: 0.010513
Average total loss: 0.048836
tensor(0.0745, device='cuda:0') tensor(0.1362, device='cuda:0') tensor(-2.4765e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.039318
Average KL loss: 0.010517
Average total loss: 0.049834
tensor(0.0745, device='cuda:0') tensor(0.1363, device='cuda:0') tensor(-3.0536e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.039381
Average KL loss: 0.010520
Average total loss: 0.049901
tensor(0.0745, device='cuda:0') tensor(0.1364, device='cuda:0') tensor(-1.8134e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.037884
Average KL loss: 0.010523
Average total loss: 0.048407
tensor(0.0745, device='cuda:0') tensor(0.1364, device='cuda:0') tensor(-2.3906e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.037477
Average KL loss: 0.010526
Average total loss: 0.048004
tensor(0.0745, device='cuda:0') tensor(0.1365, device='cuda:0') tensor(-2.0585e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.037980
Average KL loss: 0.010529
Average total loss: 0.048509
tensor(0.0745, device='cuda:0') tensor(0.1366, device='cuda:0') tensor(-2.6509e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.037910
Average KL loss: 0.010532
Average total loss: 0.048442
tensor(0.0745, device='cuda:0') tensor(0.1367, device='cuda:0') tensor(-2.1664e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.038105
Average KL loss: 0.010534
Average total loss: 0.048640
tensor(0.0745, device='cuda:0') tensor(0.1367, device='cuda:0') tensor(-2.2609e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.039629
Average KL loss: 0.010538
Average total loss: 0.050167
tensor(0.0745, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-3.5682e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.038121
Average KL loss: 0.010541
Average total loss: 0.048662
tensor(0.0745, device='cuda:0') tensor(0.1369, device='cuda:0') tensor(-2.6407e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.037551
Average KL loss: 0.010544
Average total loss: 0.048094
tensor(0.0745, device='cuda:0') tensor(0.1369, device='cuda:0') tensor(-2.2451e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.037909
Average KL loss: 0.010547
Average total loss: 0.048456
tensor(0.0745, device='cuda:0') tensor(0.1370, device='cuda:0') tensor(-3.0275e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.038625
Average KL loss: 0.010550
Average total loss: 0.049175
tensor(0.0746, device='cuda:0') tensor(0.1371, device='cuda:0') tensor(-2.1290e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.037626
Average KL loss: 0.010553
Average total loss: 0.048179
tensor(0.0746, device='cuda:0') tensor(0.1372, device='cuda:0') tensor(-2.4406e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.038603
Average KL loss: 0.010556
Average total loss: 0.049159
tensor(0.0746, device='cuda:0') tensor(0.1372, device='cuda:0') tensor(-2.3724e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.037217
Average KL loss: 0.010559
Average total loss: 0.047776
tensor(0.0746, device='cuda:0') tensor(0.1373, device='cuda:0') tensor(-2.3647e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.037660
Average KL loss: 0.010562
Average total loss: 0.048221
tensor(0.0746, device='cuda:0') tensor(0.1374, device='cuda:0') tensor(-2.0342e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.037070
Average KL loss: 0.010565
Average total loss: 0.047635
tensor(0.0746, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(-2.0537e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.036730
Average KL loss: 0.010568
Average total loss: 0.047298
tensor(0.0746, device='cuda:0') tensor(0.1375, device='cuda:0') tensor(-1.9229e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.037754
Average KL loss: 0.010570
Average total loss: 0.048324
tensor(0.0746, device='cuda:0') tensor(0.1376, device='cuda:0') tensor(-3.8135e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.038033
Average KL loss: 0.010574
Average total loss: 0.048607
tensor(0.0746, device='cuda:0') tensor(0.1377, device='cuda:0') tensor(-2.1255e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.037390
Average KL loss: 0.010577
Average total loss: 0.047967
tensor(0.0746, device='cuda:0') tensor(0.1378, device='cuda:0') tensor(-1.7744e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.036987
Average KL loss: 0.010580
Average total loss: 0.047566
tensor(0.0746, device='cuda:0') tensor(0.1378, device='cuda:0') tensor(-2.3014e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.038024
Average KL loss: 0.010583
Average total loss: 0.048606
tensor(0.0746, device='cuda:0') tensor(0.1379, device='cuda:0') tensor(-1.9826e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.036427
Average KL loss: 0.010585
Average total loss: 0.047013
tensor(0.0746, device='cuda:0') tensor(0.1380, device='cuda:0') tensor(-2.4167e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.036896
Average KL loss: 0.010588
Average total loss: 0.047484
tensor(0.0746, device='cuda:0') tensor(0.1380, device='cuda:0') tensor(-3.5872e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.037059
Average KL loss: 0.010591
Average total loss: 0.047649
tensor(0.0746, device='cuda:0') tensor(0.1381, device='cuda:0') tensor(-2.7989e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.039195
Average KL loss: 0.010594
Average total loss: 0.049789
tensor(0.0746, device='cuda:0') tensor(0.1382, device='cuda:0') tensor(-3.5074e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.037624
Average KL loss: 0.010597
Average total loss: 0.048221
tensor(0.0746, device='cuda:0') tensor(0.1383, device='cuda:0') tensor(-1.4405e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.037101
Average KL loss: 0.010600
Average total loss: 0.047701
tensor(0.0746, device='cuda:0') tensor(0.1383, device='cuda:0') tensor(-3.5394e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.037375
Average KL loss: 0.010603
Average total loss: 0.047978
tensor(0.0746, device='cuda:0') tensor(0.1384, device='cuda:0') tensor(-3.2764e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.036089
Average KL loss: 0.010606
Average total loss: 0.046695
tensor(0.0747, device='cuda:0') tensor(0.1385, device='cuda:0') tensor(-2.4029e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.037832
Average KL loss: 0.010608
Average total loss: 0.048440
tensor(0.0747, device='cuda:0') tensor(0.1386, device='cuda:0') tensor(-2.4521e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.036610
Average KL loss: 0.010611
Average total loss: 0.047221
tensor(0.0747, device='cuda:0') tensor(0.1386, device='cuda:0') tensor(-2.7340e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.036621
Average KL loss: 0.010614
Average total loss: 0.047235
tensor(0.0747, device='cuda:0') tensor(0.1387, device='cuda:0') tensor(-2.4910e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.036671
Average KL loss: 0.010617
Average total loss: 0.047288
tensor(0.0747, device='cuda:0') tensor(0.1388, device='cuda:0') tensor(-2.0729e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.036990
Average KL loss: 0.010619
Average total loss: 0.047610
tensor(0.0747, device='cuda:0') tensor(0.1388, device='cuda:0') tensor(-2.5211e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.037373
Average KL loss: 0.010623
Average total loss: 0.047996
tensor(0.0747, device='cuda:0') tensor(0.1389, device='cuda:0') tensor(-2.0185e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.036081
Average KL loss: 0.010626
Average total loss: 0.046707
tensor(0.0747, device='cuda:0') tensor(0.1390, device='cuda:0') tensor(-3.7344e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.036510
Average KL loss: 0.010629
Average total loss: 0.047138
tensor(0.0747, device='cuda:0') tensor(0.1391, device='cuda:0') tensor(-2.9750e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.036585
Average KL loss: 0.010632
Average total loss: 0.047217
tensor(0.0747, device='cuda:0') tensor(0.1391, device='cuda:0') tensor(-2.1638e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.036271
Average KL loss: 0.010635
Average total loss: 0.046906
tensor(0.0747, device='cuda:0') tensor(0.1392, device='cuda:0') tensor(-2.5530e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.035345
Average KL loss: 0.010637
Average total loss: 0.045982
tensor(0.0747, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(-2.8825e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.035734
Average KL loss: 0.010640
Average total loss: 0.046375
tensor(0.0747, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(-8.3807e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.036498
Average KL loss: 0.010643
Average total loss: 0.047141
tensor(0.0747, device='cuda:0') tensor(0.1394, device='cuda:0') tensor(-2.1800e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.035326
Average KL loss: 0.010645
Average total loss: 0.045971
tensor(0.0747, device='cuda:0') tensor(0.1395, device='cuda:0') tensor(-4.8129e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.035933
Average KL loss: 0.010648
Average total loss: 0.046581
tensor(0.0747, device='cuda:0') tensor(0.1396, device='cuda:0') tensor(-2.9245e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.036030
Average KL loss: 0.010651
Average total loss: 0.046681
tensor(0.0747, device='cuda:0') tensor(0.1396, device='cuda:0') tensor(-2.2992e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.035327
Average KL loss: 0.010653
Average total loss: 0.045980
tensor(0.0747, device='cuda:0') tensor(0.1397, device='cuda:0') tensor(-1.8754e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.035817
Average KL loss: 0.010656
Average total loss: 0.046473
tensor(0.0747, device='cuda:0') tensor(0.1398, device='cuda:0') tensor(-2.1443e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.036036
Average KL loss: 0.010659
Average total loss: 0.046695
tensor(0.0747, device='cuda:0') tensor(0.1398, device='cuda:0') tensor(-2.5804e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.035890
Average KL loss: 0.010662
Average total loss: 0.046552
tensor(0.0748, device='cuda:0') tensor(0.1399, device='cuda:0') tensor(-2.1487e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.035306
Average KL loss: 0.010665
Average total loss: 0.045971
tensor(0.0748, device='cuda:0') tensor(0.1400, device='cuda:0') tensor(-1.0620e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.035361
Average KL loss: 0.010668
Average total loss: 0.046029
tensor(0.0748, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(-2.2410e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.036134
Average KL loss: 0.010670
Average total loss: 0.046805
tensor(0.0748, device='cuda:0') tensor(0.1401, device='cuda:0') tensor(-2.1682e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.037485
Average KL loss: 0.010673
Average total loss: 0.048157
tensor(0.0748, device='cuda:0') tensor(0.1402, device='cuda:0') tensor(-2.1461e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.035183
Average KL loss: 0.010676
Average total loss: 0.045859
tensor(0.0748, device='cuda:0') tensor(0.1403, device='cuda:0') tensor(-2.0308e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.035360
Average KL loss: 0.010678
Average total loss: 0.046038
tensor(0.0748, device='cuda:0') tensor(0.1403, device='cuda:0') tensor(-1.5201e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.035516
Average KL loss: 0.010681
Average total loss: 0.046197
tensor(0.0748, device='cuda:0') tensor(0.1404, device='cuda:0') tensor(-3.2301e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.035519
Average KL loss: 0.010683
Average total loss: 0.046202
tensor(0.0748, device='cuda:0') tensor(0.1405, device='cuda:0') tensor(-2.2756e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.035118
Average KL loss: 0.010686
Average total loss: 0.045804
tensor(0.0748, device='cuda:0') tensor(0.1406, device='cuda:0') tensor(-2.1499e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.034517
Average KL loss: 0.010689
Average total loss: 0.045206
tensor(0.0748, device='cuda:0') tensor(0.1406, device='cuda:0') tensor(-2.6050e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.035404
Average KL loss: 0.010691
Average total loss: 0.046096
tensor(0.0748, device='cuda:0') tensor(0.1407, device='cuda:0') tensor(-1.8910e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.035080
Average KL loss: 0.010694
Average total loss: 0.045774
tensor(0.0748, device='cuda:0') tensor(0.1408, device='cuda:0') tensor(-1.9568e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.035120
Average KL loss: 0.010696
Average total loss: 0.045817
tensor(0.0748, device='cuda:0') tensor(0.1408, device='cuda:0') tensor(-2.4814e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.035474
Average KL loss: 0.010699
Average total loss: 0.046174
tensor(0.0748, device='cuda:0') tensor(0.1409, device='cuda:0') tensor(-2.4606e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.034681
Average KL loss: 0.010702
Average total loss: 0.045383
tensor(0.0748, device='cuda:0') tensor(0.1410, device='cuda:0') tensor(-1.6160e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.034292
Average KL loss: 0.010704
Average total loss: 0.044996
tensor(0.0748, device='cuda:0') tensor(0.1410, device='cuda:0') tensor(-2.2577e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.034582
Average KL loss: 0.010706
Average total loss: 0.045288
tensor(0.0748, device='cuda:0') tensor(0.1411, device='cuda:0') tensor(-2.1107e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.034379
Average KL loss: 0.010708
Average total loss: 0.045087
tensor(0.0748, device='cuda:0') tensor(0.1412, device='cuda:0') tensor(-2.4421e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.034429
Average KL loss: 0.010710
Average total loss: 0.045139
tensor(0.0748, device='cuda:0') tensor(0.1412, device='cuda:0') tensor(-1.6714e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.034104
Average KL loss: 0.010712
Average total loss: 0.044817
tensor(0.0748, device='cuda:0') tensor(0.1413, device='cuda:0') tensor(-2.3091e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.034833
Average KL loss: 0.010715
Average total loss: 0.045548
tensor(0.0748, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-2.9148e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.034400
Average KL loss: 0.010717
Average total loss: 0.045118
tensor(0.0748, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-1.7443e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.034121
Average KL loss: 0.010720
Average total loss: 0.044841
tensor(0.0748, device='cuda:0') tensor(0.1415, device='cuda:0') tensor(-1.4503e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.033813
Average KL loss: 0.010722
Average total loss: 0.044535
tensor(0.0748, device='cuda:0') tensor(0.1416, device='cuda:0') tensor(-1.5065e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.033887
Average KL loss: 0.010725
Average total loss: 0.044612
tensor(0.0749, device='cuda:0') tensor(0.1416, device='cuda:0') tensor(-2.4006e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.034095
Average KL loss: 0.010727
Average total loss: 0.044822
tensor(0.0749, device='cuda:0') tensor(0.1417, device='cuda:0') tensor(-1.9473e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.033563
Average KL loss: 0.010729
Average total loss: 0.044292
tensor(0.0749, device='cuda:0') tensor(0.1418, device='cuda:0') tensor(-2.0312e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.034130
Average KL loss: 0.010732
Average total loss: 0.044862
tensor(0.0749, device='cuda:0') tensor(0.1418, device='cuda:0') tensor(-1.2606e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.033709
Average KL loss: 0.010734
Average total loss: 0.044443
tensor(0.0749, device='cuda:0') tensor(0.1419, device='cuda:0') tensor(-1.7282e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.034846
Average KL loss: 0.010737
Average total loss: 0.045583
tensor(0.0749, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(-2.6346e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.034444
Average KL loss: 0.010739
Average total loss: 0.045183
tensor(0.0749, device='cuda:0') tensor(0.1420, device='cuda:0') tensor(-2.6702e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.033521
Average KL loss: 0.010742
Average total loss: 0.044263
tensor(0.0749, device='cuda:0') tensor(0.1421, device='cuda:0') tensor(-2.3903e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.034716
Average KL loss: 0.010745
Average total loss: 0.045460
tensor(0.0749, device='cuda:0') tensor(0.1422, device='cuda:0') tensor(-2.1848e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.033942
Average KL loss: 0.010747
Average total loss: 0.044689
tensor(0.0749, device='cuda:0') tensor(0.1422, device='cuda:0') tensor(-2.1123e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.034009
Average KL loss: 0.010750
Average total loss: 0.044759
tensor(0.0749, device='cuda:0') tensor(0.1423, device='cuda:0') tensor(-1.5983e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.034538
Average KL loss: 0.010752
Average total loss: 0.045290
tensor(0.0749, device='cuda:0') tensor(0.1424, device='cuda:0') tensor(-1.8186e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.033120
Average KL loss: 0.010755
Average total loss: 0.043875
tensor(0.0749, device='cuda:0') tensor(0.1425, device='cuda:0') tensor(-2.6084e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.033418
Average KL loss: 0.010757
Average total loss: 0.044175
tensor(0.0749, device='cuda:0') tensor(0.1425, device='cuda:0') tensor(-1.5265e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.033212
Average KL loss: 0.010759
Average total loss: 0.043972
tensor(0.0749, device='cuda:0') tensor(0.1426, device='cuda:0') tensor(-2.8141e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.034425
Average KL loss: 0.010761
Average total loss: 0.045187
tensor(0.0749, device='cuda:0') tensor(0.1427, device='cuda:0') tensor(-2.8145e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.033631
Average KL loss: 0.010764
Average total loss: 0.044395
tensor(0.0749, device='cuda:0') tensor(0.1427, device='cuda:0') tensor(-1.6708e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.033059
Average KL loss: 0.010765
Average total loss: 0.043825
tensor(0.0749, device='cuda:0') tensor(0.1428, device='cuda:0') tensor(-1.2988e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.033685
Average KL loss: 0.010768
Average total loss: 0.044453
tensor(0.0749, device='cuda:0') tensor(0.1429, device='cuda:0') tensor(-2.3765e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.032950
Average KL loss: 0.010770
Average total loss: 0.043720
 Percentile value: 0.6169268965721131
Non-zero model percentage: 5.497567176818848%, Non-zero mask percentage: 5.497567176818848%

--- Pruning Level [13/24]: ---
conv1.weight         | nonzeros =     188 /    1728             ( 10.88%) | total_pruned =    1540 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     210 /   36864             (  0.57%) | total_pruned =   36654 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     361 /   36864             (  0.98%) | total_pruned =   36503 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     822 /   36864             (  2.23%) | total_pruned =   36042 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1971 /   36864             (  5.35%) | total_pruned =   34893 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    7897 /   73728             ( 10.71%) | total_pruned =   65831 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   17142 /  147456             ( 11.63%) | total_pruned =  130314 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1548 /    8192             ( 18.90%) | total_pruned =    6644 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   10795 /  147456             (  7.32%) | total_pruned =  136661 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    8750 /  147456             (  5.93%) | total_pruned =  138706 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   46707 /  294912             ( 15.84%) | total_pruned =  248205 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     236 /     256             ( 92.19%) | total_pruned =      20 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   68826 /  589824             ( 11.67%) | total_pruned =  520998 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6267 /   32768             ( 19.13%) | total_pruned =   26501 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     202 /     256             ( 78.91%) | total_pruned =      54 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   36186 /  589824             (  6.14%) | total_pruned =  553638 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     161 /     256             ( 62.89%) | total_pruned =      95 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   25623 /  589824             (  4.34%) | total_pruned =  564201 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   95653 / 1179648             (  8.11%) | total_pruned = 1083995 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     385 /     512             ( 75.20%) | total_pruned =     127 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   94435 / 2359296             (  4.00%) | total_pruned = 2264861 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     361 /     512             ( 70.51%) | total_pruned =     151 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     205 /     512             ( 40.04%) | total_pruned =     307 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3501 /  131072             (  2.67%) | total_pruned =  127571 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     183 /     512             ( 35.74%) | total_pruned =     329 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     205 /     512             ( 40.04%) | total_pruned =     307 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   57449 / 2359296             (  2.44%) | total_pruned = 2301847 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     267 /     512             ( 52.15%) | total_pruned =     245 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  123034 / 2359296             (  5.21%) | total_pruned = 2236262 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     394 /     512             ( 76.95%) | total_pruned =     118 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     341 /     512             ( 66.60%) | total_pruned =     171 | shape = torch.Size([512])
linear.weight        | nonzeros =    3225 /    5120             ( 62.99%) | total_pruned =    1895 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 614560, pruned : 10564202, total: 11178762, Compression rate :      18.19x  ( 94.50% pruned)
Train Epoch: 35/100 Loss: 0.016423 Accuracy: 88.36 100.00 % Best test Accuracy: 88.49%
tensor(0.0749, device='cuda:0') tensor(0.1429, device='cuda:0') tensor(-3.9866e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.046385
Average KL loss: 0.010737
Average total loss: 0.057122
tensor(0.0745, device='cuda:0') tensor(0.1422, device='cuda:0') tensor(-4.6973e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.046073
Average KL loss: 0.010695
Average total loss: 0.056768
tensor(0.0742, device='cuda:0') tensor(0.1417, device='cuda:0') tensor(-2.9966e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.045649
Average KL loss: 0.010660
Average total loss: 0.056309
tensor(0.0739, device='cuda:0') tensor(0.1414, device='cuda:0') tensor(-2.9370e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.045235
Average KL loss: 0.010627
Average total loss: 0.055861
tensor(0.0736, device='cuda:0') tensor(0.1411, device='cuda:0') tensor(-2.8363e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.044275
Average KL loss: 0.010596
Average total loss: 0.054870
tensor(0.0734, device='cuda:0') tensor(0.1408, device='cuda:0') tensor(-4.2417e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.044400
Average KL loss: 0.010567
Average total loss: 0.054966
tensor(0.0731, device='cuda:0') tensor(0.1405, device='cuda:0') tensor(-4.1903e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.044088
Average KL loss: 0.010539
Average total loss: 0.054627
tensor(0.0729, device='cuda:0') tensor(0.1402, device='cuda:0') tensor(-4.3122e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.044726
Average KL loss: 0.010513
Average total loss: 0.055239
tensor(0.0727, device='cuda:0') tensor(0.1400, device='cuda:0') tensor(-3.4779e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.043647
Average KL loss: 0.010488
Average total loss: 0.054135
tensor(0.0724, device='cuda:0') tensor(0.1397, device='cuda:0') tensor(-4.6672e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.043693
Average KL loss: 0.010464
Average total loss: 0.054157
tensor(0.0722, device='cuda:0') tensor(0.1395, device='cuda:0') tensor(-2.7372e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.043687
Average KL loss: 0.010442
Average total loss: 0.054129
tensor(0.0720, device='cuda:0') tensor(0.1393, device='cuda:0') tensor(-2.4797e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.043111
Average KL loss: 0.010420
Average total loss: 0.053531
tensor(0.0718, device='cuda:0') tensor(0.1391, device='cuda:0') tensor(-3.1575e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.043129
Average KL loss: 0.010399
Average total loss: 0.053528
tensor(0.0716, device='cuda:0') tensor(0.1389, device='cuda:0') tensor(-3.4098e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.043373
Average KL loss: 0.010379
Average total loss: 0.053753
tensor(0.0715, device='cuda:0') tensor(0.1387, device='cuda:0') tensor(-3.9521e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.043286
Average KL loss: 0.010361
Average total loss: 0.053647
tensor(0.0713, device='cuda:0') tensor(0.1385, device='cuda:0') tensor(-3.2176e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.043542
Average KL loss: 0.010343
Average total loss: 0.053885
tensor(0.0711, device='cuda:0') tensor(0.1383, device='cuda:0') tensor(-2.4907e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.044013
Average KL loss: 0.010325
Average total loss: 0.054338
tensor(0.0710, device='cuda:0') tensor(0.1382, device='cuda:0') tensor(-2.8487e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.041869
Average KL loss: 0.010309
Average total loss: 0.052177
tensor(0.0708, device='cuda:0') tensor(0.1380, device='cuda:0') tensor(-3.1279e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.041997
Average KL loss: 0.010293
Average total loss: 0.052289
tensor(0.0707, device='cuda:0') tensor(0.1379, device='cuda:0') tensor(-3.2464e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.041327
Average KL loss: 0.010277
Average total loss: 0.051604
tensor(0.0705, device='cuda:0') tensor(0.1377, device='cuda:0') tensor(-3.8789e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.042838
Average KL loss: 0.010262
Average total loss: 0.053100
tensor(0.0704, device='cuda:0') tensor(0.1376, device='cuda:0') tensor(-3.1831e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.041211
Average KL loss: 0.010248
Average total loss: 0.051459
tensor(0.0703, device='cuda:0') tensor(0.1374, device='cuda:0') tensor(-3.1700e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.042346
Average KL loss: 0.010234
Average total loss: 0.052579
tensor(0.0701, device='cuda:0') tensor(0.1373, device='cuda:0') tensor(-4.7887e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.042381
Average KL loss: 0.010221
Average total loss: 0.052602
tensor(0.0700, device='cuda:0') tensor(0.1372, device='cuda:0') tensor(-4.0677e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.041685
Average KL loss: 0.010208
Average total loss: 0.051893
tensor(0.0699, device='cuda:0') tensor(0.1371, device='cuda:0') tensor(-4.1375e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.041604
Average KL loss: 0.010195
Average total loss: 0.051799
tensor(0.0698, device='cuda:0') tensor(0.1370, device='cuda:0') tensor(-3.3493e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.043919
Average KL loss: 0.010183
Average total loss: 0.054102
tensor(0.0697, device='cuda:0') tensor(0.1368, device='cuda:0') tensor(-2.6253e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.041207
Average KL loss: 0.010172
Average total loss: 0.051379
tensor(0.0696, device='cuda:0') tensor(0.1367, device='cuda:0') tensor(-3.4324e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.041271
Average KL loss: 0.010161
Average total loss: 0.051432
tensor(0.0695, device='cuda:0') tensor(0.1367, device='cuda:0') tensor(-2.4799e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.042168
Average KL loss: 0.010150
Average total loss: 0.052318
tensor(0.0694, device='cuda:0') tensor(0.1366, device='cuda:0') tensor(-2.2951e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.043618
Average KL loss: 0.010140
Average total loss: 0.053758
tensor(0.0693, device='cuda:0') tensor(0.1365, device='cuda:0') tensor(-3.3006e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.040770
Average KL loss: 0.010130
Average total loss: 0.050900
tensor(0.0692, device='cuda:0') tensor(0.1364, device='cuda:0') tensor(-3.2397e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.041377
Average KL loss: 0.010121
Average total loss: 0.051498
tensor(0.0691, device='cuda:0') tensor(0.1363, device='cuda:0') tensor(-3.7237e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.040641
Average KL loss: 0.010111
Average total loss: 0.050753
tensor(0.0691, device='cuda:0') tensor(0.1362, device='cuda:0') tensor(-4.3333e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.041082
Average KL loss: 0.010102
Average total loss: 0.051185
tensor(0.0690, device='cuda:0') tensor(0.1362, device='cuda:0') tensor(-2.4158e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.040635
Average KL loss: 0.010094
Average total loss: 0.050729
tensor(0.0689, device='cuda:0') tensor(0.1361, device='cuda:0') tensor(-2.0824e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.039516
Average KL loss: 0.010086
Average total loss: 0.049602
tensor(0.0688, device='cuda:0') tensor(0.1360, device='cuda:0') tensor(-4.6519e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.040476
Average KL loss: 0.010078
Average total loss: 0.050553
tensor(0.0688, device='cuda:0') tensor(0.1360, device='cuda:0') tensor(-2.2026e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.039956
Average KL loss: 0.010070
Average total loss: 0.050025
tensor(0.0687, device='cuda:0') tensor(0.1359, device='cuda:0') tensor(-3.0966e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.039706
Average KL loss: 0.010062
Average total loss: 0.049769
tensor(0.0686, device='cuda:0') tensor(0.1359, device='cuda:0') tensor(-2.9019e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.040091
Average KL loss: 0.010055
Average total loss: 0.050147
tensor(0.0686, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-2.0724e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.039282
Average KL loss: 0.010048
Average total loss: 0.049330
tensor(0.0685, device='cuda:0') tensor(0.1358, device='cuda:0') tensor(-3.0182e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.040073
Average KL loss: 0.010042
Average total loss: 0.050114
tensor(0.0684, device='cuda:0') tensor(0.1357, device='cuda:0') tensor(-2.5887e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.040094
Average KL loss: 0.010035
Average total loss: 0.050129
tensor(0.0684, device='cuda:0') tensor(0.1357, device='cuda:0') tensor(-2.5060e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.039866
Average KL loss: 0.010029
Average total loss: 0.049895
tensor(0.0683, device='cuda:0') tensor(0.1356, device='cuda:0') tensor(-1.9861e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.039674
Average KL loss: 0.010023
Average total loss: 0.049697
tensor(0.0683, device='cuda:0') tensor(0.1356, device='cuda:0') tensor(-3.1782e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.038318
Average KL loss: 0.010017
Average total loss: 0.048335
tensor(0.0682, device='cuda:0') tensor(0.1356, device='cuda:0') tensor(-3.4177e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.039233
Average KL loss: 0.010011
Average total loss: 0.049244
tensor(0.0682, device='cuda:0') tensor(0.1355, device='cuda:0') tensor(-3.1964e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.039195
Average KL loss: 0.010006
Average total loss: 0.049201
tensor(0.0681, device='cuda:0') tensor(0.1355, device='cuda:0') tensor(-3.4877e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.039296
Average KL loss: 0.010001
Average total loss: 0.049297
tensor(0.0681, device='cuda:0') tensor(0.1355, device='cuda:0') tensor(-3.2728e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.038617
Average KL loss: 0.009996
Average total loss: 0.048613
tensor(0.0680, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(-1.5098e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.039054
Average KL loss: 0.009992
Average total loss: 0.049046
tensor(0.0680, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(-2.0445e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.039457
Average KL loss: 0.009987
Average total loss: 0.049444
tensor(0.0679, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(-2.5521e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.042076
Average KL loss: 0.009983
Average total loss: 0.052059
tensor(0.0679, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(-3.6553e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.038366
Average KL loss: 0.009980
Average total loss: 0.048345
tensor(0.0678, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(-2.8826e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.038862
Average KL loss: 0.009976
Average total loss: 0.048837
tensor(0.0678, device='cuda:0') tensor(0.1354, device='cuda:0') tensor(-2.8979e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.038911
Average KL loss: 0.009972
Average total loss: 0.048883
tensor(0.0678, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.8886e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.038754
Average KL loss: 0.009969
Average total loss: 0.048722
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.9534e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.039554
Average KL loss: 0.009967
Average total loss: 0.049521
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.3553e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.038844
Average KL loss: 0.009966
Average total loss: 0.048810
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.9445e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.038055
Average KL loss: 0.009966
Average total loss: 0.048021
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.3770e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.038382
Average KL loss: 0.009966
Average total loss: 0.048348
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.5520e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.038582
Average KL loss: 0.009965
Average total loss: 0.048547
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.3657e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.038054
Average KL loss: 0.009965
Average total loss: 0.048019
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.6429e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.038923
Average KL loss: 0.009965
Average total loss: 0.048888
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.9913e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.038200
Average KL loss: 0.009964
Average total loss: 0.048165
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.8763e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.038129
Average KL loss: 0.009964
Average total loss: 0.048092
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.3541e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.038787
Average KL loss: 0.009964
Average total loss: 0.048751
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.1314e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.037740
Average KL loss: 0.009963
Average total loss: 0.047703
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.3832e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.037982
Average KL loss: 0.009963
Average total loss: 0.047945
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.0782e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.037487
Average KL loss: 0.009963
Average total loss: 0.047450
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-4.3627e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.038685
Average KL loss: 0.009962
Average total loss: 0.048647
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.8165e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.039018
Average KL loss: 0.009962
Average total loss: 0.048980
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.4451e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.038567
Average KL loss: 0.009962
Average total loss: 0.048529
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.5113e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.038295
Average KL loss: 0.009961
Average total loss: 0.048256
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.2758e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.038188
Average KL loss: 0.009961
Average total loss: 0.048149
tensor(0.0677, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.3936e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.037164
Average KL loss: 0.009961
Average total loss: 0.047125
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.6019e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.041566
Average KL loss: 0.009961
Average total loss: 0.051526
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.7656e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.038423
Average KL loss: 0.009960
Average total loss: 0.048383
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.8939e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.038151
Average KL loss: 0.009960
Average total loss: 0.048111
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.2933e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.038379
Average KL loss: 0.009960
Average total loss: 0.048338
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.2935e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.037150
Average KL loss: 0.009959
Average total loss: 0.047109
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.0490e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.040498
Average KL loss: 0.009959
Average total loss: 0.050457
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.1207e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.039561
Average KL loss: 0.009959
Average total loss: 0.049519
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-1.2404e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.037461
Average KL loss: 0.009958
Average total loss: 0.047420
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.9139e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.037655
Average KL loss: 0.009958
Average total loss: 0.047613
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.3024e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.038628
Average KL loss: 0.009958
Average total loss: 0.048586
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.7358e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.038667
Average KL loss: 0.009958
Average total loss: 0.048624
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.9700e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.038355
Average KL loss: 0.009957
Average total loss: 0.048312
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.4317e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.038145
Average KL loss: 0.009957
Average total loss: 0.048102
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.0871e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.037756
Average KL loss: 0.009957
Average total loss: 0.047713
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.6280e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.038145
Average KL loss: 0.009956
Average total loss: 0.048101
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.9188e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.038999
Average KL loss: 0.009956
Average total loss: 0.048955
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.2589e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.038181
Average KL loss: 0.009956
Average total loss: 0.048137
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.4599e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.038832
Average KL loss: 0.009956
Average total loss: 0.048788
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.1140e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.038058
Average KL loss: 0.009956
Average total loss: 0.048014
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.6502e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.037147
Average KL loss: 0.009956
Average total loss: 0.047103
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.0343e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.038315
Average KL loss: 0.009956
Average total loss: 0.048271
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.7299e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.038496
Average KL loss: 0.009956
Average total loss: 0.048452
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.5797e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.038564
Average KL loss: 0.009956
Average total loss: 0.048520
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.2540e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.038416
Average KL loss: 0.009956
Average total loss: 0.048372
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-1.8114e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.037352
Average KL loss: 0.009956
Average total loss: 0.047307
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.4907e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.038454
Average KL loss: 0.009956
Average total loss: 0.048409
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.7819e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.038246
Average KL loss: 0.009956
Average total loss: 0.048201
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.5622e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.038861
Average KL loss: 0.009956
Average total loss: 0.048816
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.0930e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.038765
Average KL loss: 0.009956
Average total loss: 0.048721
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.5591e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.038323
Average KL loss: 0.009956
Average total loss: 0.048278
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.8420e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.036900
Average KL loss: 0.009956
Average total loss: 0.046856
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.1795e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.038959
Average KL loss: 0.009956
Average total loss: 0.048914
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.1675e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.038826
Average KL loss: 0.009955
Average total loss: 0.048782
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.2813e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.038754
Average KL loss: 0.009955
Average total loss: 0.048710
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.2518e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.038756
Average KL loss: 0.009955
Average total loss: 0.048711
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.3866e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.038250
Average KL loss: 0.009955
Average total loss: 0.048205
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.3274e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.041279
Average KL loss: 0.009955
Average total loss: 0.051234
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.6694e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.038395
Average KL loss: 0.009955
Average total loss: 0.048350
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.1441e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.037751
Average KL loss: 0.009955
Average total loss: 0.047706
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.4216e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.038857
Average KL loss: 0.009955
Average total loss: 0.048812
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-3.1321e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.038152
Average KL loss: 0.009955
Average total loss: 0.048108
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-2.6347e-09, device='cuda:0')
 Percentile value: 0.7480961680412292
Non-zero model percentage: 4.398054122924805%, Non-zero mask percentage: 4.398054122924805%

--- Pruning Level [14/24]: ---
conv1.weight         | nonzeros =     186 /    1728             ( 10.76%) | total_pruned =    1542 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     201 /   36864             (  0.55%) | total_pruned =   36663 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     339 /   36864             (  0.92%) | total_pruned =   36525 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     754 /   36864             (  2.05%) | total_pruned =   36110 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1848 /   36864             (  5.01%) | total_pruned =   35016 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    6991 /   73728             (  9.48%) | total_pruned =   66737 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   14764 /  147456             ( 10.01%) | total_pruned =  132692 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1467 /    8192             ( 17.91%) | total_pruned =    6725 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8963 /  147456             (  6.08%) | total_pruned =  138493 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    7402 /  147456             (  5.02%) | total_pruned =  140054 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   39256 /  294912             ( 13.31%) | total_pruned =  255656 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     236 /     256             ( 92.19%) | total_pruned =      20 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   55529 /  589824             (  9.41%) | total_pruned =  534295 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    5435 /   32768             ( 16.59%) | total_pruned =   27333 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     199 /     256             ( 77.73%) | total_pruned =      57 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   28201 /  589824             (  4.78%) | total_pruned =  561623 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     160 /     256             ( 62.50%) | total_pruned =      96 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   20592 /  589824             (  3.49%) | total_pruned =  569232 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   75605 / 1179648             (  6.41%) | total_pruned = 1104043 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     384 /     512             ( 75.00%) | total_pruned =     128 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   75520 / 2359296             (  3.20%) | total_pruned = 2283776 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     359 /     512             ( 70.12%) | total_pruned =     153 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     203 /     512             ( 39.65%) | total_pruned =     309 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2724 /  131072             (  2.08%) | total_pruned =  128348 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     176 /     512             ( 34.38%) | total_pruned =     336 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     202 /     512             ( 39.45%) | total_pruned =     310 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   45668 / 2359296             (  1.94%) | total_pruned = 2313628 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     260 /     512             ( 50.78%) | total_pruned =     252 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   93144 / 2359296             (  3.95%) | total_pruned = 2266152 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     389 /     512             ( 75.98%) | total_pruned =     123 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     328 /     512             ( 64.06%) | total_pruned =     184 | shape = torch.Size([512])
linear.weight        | nonzeros =    3140 /    5120             ( 61.33%) | total_pruned =    1980 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 491648, pruned : 10687114, total: 11178762, Compression rate :      22.74x  ( 95.60% pruned)
Train Epoch: 35/100 Loss: 0.021519 Accuracy: 88.22 100.00 % Best test Accuracy: 88.71%
tensor(0.0676, device='cuda:0') tensor(0.1353, device='cuda:0') tensor(-4.1337e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.044116
Average KL loss: 0.009925
Average total loss: 0.054041
tensor(0.0672, device='cuda:0') tensor(0.1347, device='cuda:0') tensor(-3.9599e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.043064
Average KL loss: 0.009889
Average total loss: 0.052953
tensor(0.0670, device='cuda:0') tensor(0.1344, device='cuda:0') tensor(-4.0361e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.042920
Average KL loss: 0.009859
Average total loss: 0.052779
tensor(0.0667, device='cuda:0') tensor(0.1341, device='cuda:0') tensor(-5.3203e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.044543
Average KL loss: 0.009831
Average total loss: 0.054374
tensor(0.0665, device='cuda:0') tensor(0.1338, device='cuda:0') tensor(-4.8554e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.042807
Average KL loss: 0.009805
Average total loss: 0.052611
tensor(0.0663, device='cuda:0') tensor(0.1336, device='cuda:0') tensor(-4.1051e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.042112
Average KL loss: 0.009781
Average total loss: 0.051893
tensor(0.0660, device='cuda:0') tensor(0.1334, device='cuda:0') tensor(-3.1648e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.042799
Average KL loss: 0.009758
Average total loss: 0.052557
tensor(0.0658, device='cuda:0') tensor(0.1332, device='cuda:0') tensor(-2.6126e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.042286
Average KL loss: 0.009736
Average total loss: 0.052022
tensor(0.0656, device='cuda:0') tensor(0.1330, device='cuda:0') tensor(-5.2797e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.041948
Average KL loss: 0.009716
Average total loss: 0.051664
tensor(0.0655, device='cuda:0') tensor(0.1329, device='cuda:0') tensor(-4.6977e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.043088
Average KL loss: 0.009697
Average total loss: 0.052785
tensor(0.0653, device='cuda:0') tensor(0.1327, device='cuda:0') tensor(-4.3610e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.042183
Average KL loss: 0.009680
Average total loss: 0.051863
tensor(0.0651, device='cuda:0') tensor(0.1326, device='cuda:0') tensor(-3.1732e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.041826
Average KL loss: 0.009663
Average total loss: 0.051489
tensor(0.0649, device='cuda:0') tensor(0.1324, device='cuda:0') tensor(-3.4235e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.041633
Average KL loss: 0.009648
Average total loss: 0.051281
tensor(0.0648, device='cuda:0') tensor(0.1323, device='cuda:0') tensor(-3.4186e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.042109
Average KL loss: 0.009633
Average total loss: 0.051742
tensor(0.0646, device='cuda:0') tensor(0.1322, device='cuda:0') tensor(-2.9510e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.041805
Average KL loss: 0.009619
Average total loss: 0.051424
tensor(0.0645, device='cuda:0') tensor(0.1321, device='cuda:0') tensor(-4.2124e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.041076
Average KL loss: 0.009606
Average total loss: 0.050682
tensor(0.0643, device='cuda:0') tensor(0.1320, device='cuda:0') tensor(-3.1312e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.040926
Average KL loss: 0.009594
Average total loss: 0.050520
tensor(0.0642, device='cuda:0') tensor(0.1319, device='cuda:0') tensor(-2.8843e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.040124
Average KL loss: 0.009582
Average total loss: 0.049706
tensor(0.0641, device='cuda:0') tensor(0.1318, device='cuda:0') tensor(-3.0809e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.041423
Average KL loss: 0.009571
Average total loss: 0.050994
tensor(0.0640, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-4.3580e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.041240
Average KL loss: 0.009560
Average total loss: 0.050801
tensor(0.0638, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-2.9991e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.039768
Average KL loss: 0.009550
Average total loss: 0.049319
tensor(0.0637, device='cuda:0') tensor(0.1315, device='cuda:0') tensor(-2.8012e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.042255
Average KL loss: 0.009541
Average total loss: 0.051796
tensor(0.0636, device='cuda:0') tensor(0.1314, device='cuda:0') tensor(-3.6932e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.041906
Average KL loss: 0.009532
Average total loss: 0.051438
tensor(0.0635, device='cuda:0') tensor(0.1314, device='cuda:0') tensor(-2.5964e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.040799
Average KL loss: 0.009524
Average total loss: 0.050323
tensor(0.0634, device='cuda:0') tensor(0.1313, device='cuda:0') tensor(-2.7611e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.041035
Average KL loss: 0.009516
Average total loss: 0.050551
tensor(0.0633, device='cuda:0') tensor(0.1313, device='cuda:0') tensor(-2.6253e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.039308
Average KL loss: 0.009508
Average total loss: 0.048816
tensor(0.0632, device='cuda:0') tensor(0.1312, device='cuda:0') tensor(-2.6877e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.039575
Average KL loss: 0.009501
Average total loss: 0.049075
tensor(0.0632, device='cuda:0') tensor(0.1311, device='cuda:0') tensor(-4.7902e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.040040
Average KL loss: 0.009493
Average total loss: 0.049533
tensor(0.0631, device='cuda:0') tensor(0.1311, device='cuda:0') tensor(-3.0649e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.039464
Average KL loss: 0.009487
Average total loss: 0.048951
tensor(0.0630, device='cuda:0') tensor(0.1310, device='cuda:0') tensor(-3.4404e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.039742
Average KL loss: 0.009480
Average total loss: 0.049222
tensor(0.0629, device='cuda:0') tensor(0.1310, device='cuda:0') tensor(-2.0753e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.040190
Average KL loss: 0.009474
Average total loss: 0.049664
tensor(0.0629, device='cuda:0') tensor(0.1310, device='cuda:0') tensor(-2.8762e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.039459
Average KL loss: 0.009468
Average total loss: 0.048927
tensor(0.0628, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(-2.4787e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.040199
Average KL loss: 0.009463
Average total loss: 0.049662
tensor(0.0627, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(-3.9673e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.039833
Average KL loss: 0.009457
Average total loss: 0.049291
tensor(0.0627, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(-2.1704e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.038641
Average KL loss: 0.009452
Average total loss: 0.048093
tensor(0.0626, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-3.2986e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.039185
Average KL loss: 0.009447
Average total loss: 0.048632
tensor(0.0625, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-3.0940e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.039725
Average KL loss: 0.009442
Average total loss: 0.049167
tensor(0.0625, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-5.1344e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.039211
Average KL loss: 0.009438
Average total loss: 0.048649
tensor(0.0624, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.8352e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.039657
Average KL loss: 0.009434
Average total loss: 0.049091
tensor(0.0624, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-4.1491e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.039587
Average KL loss: 0.009430
Average total loss: 0.049016
tensor(0.0623, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.4915e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.038417
Average KL loss: 0.009425
Average total loss: 0.047842
tensor(0.0623, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.8440e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.038623
Average KL loss: 0.009421
Average total loss: 0.048045
tensor(0.0623, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.8472e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.039843
Average KL loss: 0.009418
Average total loss: 0.049261
tensor(0.0622, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.9777e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.039860
Average KL loss: 0.009415
Average total loss: 0.049274
tensor(0.0622, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.8145e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.041602
Average KL loss: 0.009412
Average total loss: 0.051014
tensor(0.0621, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.5760e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.038272
Average KL loss: 0.009409
Average total loss: 0.047681
tensor(0.0621, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.5246e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.038384
Average KL loss: 0.009406
Average total loss: 0.047790
tensor(0.0621, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.0369e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.038580
Average KL loss: 0.009403
Average total loss: 0.047983
tensor(0.0620, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.6487e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.037945
Average KL loss: 0.009401
Average total loss: 0.047345
tensor(0.0620, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.0084e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.038629
Average KL loss: 0.009398
Average total loss: 0.048027
tensor(0.0620, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.5281e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.036951
Average KL loss: 0.009396
Average total loss: 0.046347
tensor(0.0619, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.1178e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.037765
Average KL loss: 0.009393
Average total loss: 0.047158
tensor(0.0619, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.3271e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.036934
Average KL loss: 0.009391
Average total loss: 0.046325
tensor(0.0619, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.9687e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.037734
Average KL loss: 0.009389
Average total loss: 0.047123
tensor(0.0619, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.5793e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.038598
Average KL loss: 0.009387
Average total loss: 0.047985
tensor(0.0618, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.9324e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.036833
Average KL loss: 0.009385
Average total loss: 0.046218
tensor(0.0618, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.5603e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.036988
Average KL loss: 0.009383
Average total loss: 0.046371
tensor(0.0618, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.1899e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.037821
Average KL loss: 0.009382
Average total loss: 0.047203
tensor(0.0618, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-3.5772e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.037716
Average KL loss: 0.009380
Average total loss: 0.047097
tensor(0.0617, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.3641e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.037531
Average KL loss: 0.009379
Average total loss: 0.046910
tensor(0.0617, device='cuda:0') tensor(0.1307, device='cuda:0') tensor(-2.6236e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.037338
Average KL loss: 0.009378
Average total loss: 0.046716
tensor(0.0617, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-3.3138e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.036545
Average KL loss: 0.009377
Average total loss: 0.045922
tensor(0.0617, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-2.5360e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.036016
Average KL loss: 0.009375
Average total loss: 0.045391
tensor(0.0617, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-2.0456e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.037161
Average KL loss: 0.009374
Average total loss: 0.046535
tensor(0.0616, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-1.7494e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.036620
Average KL loss: 0.009374
Average total loss: 0.045993
tensor(0.0616, device='cuda:0') tensor(0.1308, device='cuda:0') tensor(-3.8485e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.036948
Average KL loss: 0.009373
Average total loss: 0.046320
tensor(0.0616, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(-3.1847e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.036987
Average KL loss: 0.009372
Average total loss: 0.046359
tensor(0.0616, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(-2.6229e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.037419
Average KL loss: 0.009372
Average total loss: 0.046791
tensor(0.0616, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(-3.2799e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.036478
Average KL loss: 0.009372
Average total loss: 0.045849
tensor(0.0616, device='cuda:0') tensor(0.1309, device='cuda:0') tensor(-2.8451e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.037998
Average KL loss: 0.009371
Average total loss: 0.047369
tensor(0.0616, device='cuda:0') tensor(0.1310, device='cuda:0') tensor(-2.6827e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.035898
Average KL loss: 0.009371
Average total loss: 0.045269
tensor(0.0615, device='cuda:0') tensor(0.1310, device='cuda:0') tensor(-2.0242e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.036257
Average KL loss: 0.009371
Average total loss: 0.045628
tensor(0.0615, device='cuda:0') tensor(0.1310, device='cuda:0') tensor(-2.7849e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.037433
Average KL loss: 0.009371
Average total loss: 0.046803
tensor(0.0615, device='cuda:0') tensor(0.1311, device='cuda:0') tensor(-2.5567e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.036260
Average KL loss: 0.009371
Average total loss: 0.045631
tensor(0.0615, device='cuda:0') tensor(0.1311, device='cuda:0') tensor(-2.4646e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.036026
Average KL loss: 0.009370
Average total loss: 0.045396
tensor(0.0615, device='cuda:0') tensor(0.1311, device='cuda:0') tensor(-3.3111e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.036031
Average KL loss: 0.009370
Average total loss: 0.045401
tensor(0.0615, device='cuda:0') tensor(0.1312, device='cuda:0') tensor(-2.9497e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.034821
Average KL loss: 0.009370
Average total loss: 0.044191
tensor(0.0615, device='cuda:0') tensor(0.1312, device='cuda:0') tensor(-2.6448e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.036246
Average KL loss: 0.009370
Average total loss: 0.045616
tensor(0.0615, device='cuda:0') tensor(0.1312, device='cuda:0') tensor(-2.1964e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.036043
Average KL loss: 0.009370
Average total loss: 0.045413
tensor(0.0615, device='cuda:0') tensor(0.1313, device='cuda:0') tensor(-1.5436e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.035190
Average KL loss: 0.009371
Average total loss: 0.044560
tensor(0.0615, device='cuda:0') tensor(0.1313, device='cuda:0') tensor(-2.9518e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.035336
Average KL loss: 0.009371
Average total loss: 0.044706
tensor(0.0614, device='cuda:0') tensor(0.1313, device='cuda:0') tensor(-3.8171e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.036424
Average KL loss: 0.009371
Average total loss: 0.045795
tensor(0.0614, device='cuda:0') tensor(0.1314, device='cuda:0') tensor(-2.2725e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.035790
Average KL loss: 0.009372
Average total loss: 0.045161
tensor(0.0614, device='cuda:0') tensor(0.1314, device='cuda:0') tensor(-3.3708e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.036035
Average KL loss: 0.009372
Average total loss: 0.045407
tensor(0.0614, device='cuda:0') tensor(0.1314, device='cuda:0') tensor(-2.8066e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.035923
Average KL loss: 0.009372
Average total loss: 0.045296
tensor(0.0614, device='cuda:0') tensor(0.1315, device='cuda:0') tensor(-2.7683e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.035244
Average KL loss: 0.009373
Average total loss: 0.044616
tensor(0.0614, device='cuda:0') tensor(0.1315, device='cuda:0') tensor(-2.4861e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.035796
Average KL loss: 0.009373
Average total loss: 0.045170
tensor(0.0614, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-2.1932e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.035654
Average KL loss: 0.009374
Average total loss: 0.045028
tensor(0.0614, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-2.6855e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.035750
Average KL loss: 0.009375
Average total loss: 0.045124
tensor(0.0614, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-2.4130e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.034796
Average KL loss: 0.009375
Average total loss: 0.044171
tensor(0.0614, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-1.8264e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.035517
Average KL loss: 0.009375
Average total loss: 0.044891
tensor(0.0614, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-3.1938e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.035459
Average KL loss: 0.009375
Average total loss: 0.044834
tensor(0.0614, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-3.9438e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.034993
Average KL loss: 0.009375
Average total loss: 0.044368
tensor(0.0614, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-2.7742e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.035523
Average KL loss: 0.009375
Average total loss: 0.044898
tensor(0.0614, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-1.8350e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.036321
Average KL loss: 0.009375
Average total loss: 0.045696
tensor(0.0614, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-2.6341e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.034834
Average KL loss: 0.009375
Average total loss: 0.044209
tensor(0.0614, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-2.5674e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.035999
Average KL loss: 0.009375
Average total loss: 0.045374
tensor(0.0614, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-1.7460e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.034950
Average KL loss: 0.009375
Average total loss: 0.044326
tensor(0.0614, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-2.8758e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.034991
Average KL loss: 0.009375
Average total loss: 0.044367
tensor(0.0614, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-2.1393e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.035415
Average KL loss: 0.009375
Average total loss: 0.044791
tensor(0.0614, device='cuda:0') tensor(0.1316, device='cuda:0') tensor(-1.9437e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.036070
Average KL loss: 0.009375
Average total loss: 0.045446
tensor(0.0614, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-3.3576e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.034231
Average KL loss: 0.009375
Average total loss: 0.043607
tensor(0.0614, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-1.7189e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.035179
Average KL loss: 0.009375
Average total loss: 0.044554
tensor(0.0614, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-3.1208e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.035436
Average KL loss: 0.009375
Average total loss: 0.044811
tensor(0.0614, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-2.3423e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.034997
Average KL loss: 0.009375
Average total loss: 0.044373
tensor(0.0614, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-2.7280e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.035529
Average KL loss: 0.009375
Average total loss: 0.044904
tensor(0.0614, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-2.7047e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.035474
Average KL loss: 0.009375
Average total loss: 0.044849
tensor(0.0614, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-1.9699e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.035092
Average KL loss: 0.009375
Average total loss: 0.044468
tensor(0.0614, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-2.1852e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.034764
Average KL loss: 0.009376
Average total loss: 0.044140
tensor(0.0614, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-3.5656e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.036176
Average KL loss: 0.009376
Average total loss: 0.045552
tensor(0.0614, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-2.6184e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.034950
Average KL loss: 0.009376
Average total loss: 0.044326
tensor(0.0614, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-3.6631e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.038822
Average KL loss: 0.009376
Average total loss: 0.048198
tensor(0.0614, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-2.7788e-09, device='cuda:0')
 Percentile value: 0.9017011642456055
Non-zero model percentage: 3.5184483528137207%, Non-zero mask percentage: 3.5184483528137207%

--- Pruning Level [15/24]: ---
conv1.weight         | nonzeros =     186 /    1728             ( 10.76%) | total_pruned =    1542 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     194 /   36864             (  0.53%) | total_pruned =   36670 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     319 /   36864             (  0.87%) | total_pruned =   36545 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     668 /   36864             (  1.81%) | total_pruned =   36196 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1564 /   36864             (  4.24%) | total_pruned =   35300 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    5901 /   73728             (  8.00%) | total_pruned =   67827 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   12657 /  147456             (  8.58%) | total_pruned =  134799 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1332 /    8192             ( 16.26%) | total_pruned =    6860 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    7561 /  147456             (  5.13%) | total_pruned =  139895 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    6447 /  147456             (  4.37%) | total_pruned =  141009 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   32706 /  294912             ( 11.09%) | total_pruned =  262206 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   45358 /  589824             (  7.69%) | total_pruned =  544466 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     205 /     256             ( 80.08%) | total_pruned =      51 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4673 /   32768             ( 14.26%) | total_pruned =   28095 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   22549 /  589824             (  3.82%) | total_pruned =  567275 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     160 /     256             ( 62.50%) | total_pruned =      96 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   16947 /  589824             (  2.87%) | total_pruned =  572877 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     147 /     256             ( 57.42%) | total_pruned =     109 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   60005 / 1179648             (  5.09%) | total_pruned = 1119643 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     381 /     512             ( 74.41%) | total_pruned =     131 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   59559 / 2359296             (  2.52%) | total_pruned = 2299737 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     356 /     512             ( 69.53%) | total_pruned =     156 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     200 /     512             ( 39.06%) | total_pruned =     312 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2135 /  131072             (  1.63%) | total_pruned =  128937 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     159 /     512             ( 31.05%) | total_pruned =     353 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     198 /     512             ( 38.67%) | total_pruned =     314 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   35247 / 2359296             (  1.49%) | total_pruned = 2324049 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     249 /     512             ( 48.63%) | total_pruned =     263 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   70513 / 2359296             (  2.99%) | total_pruned = 2288783 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     374 /     512             ( 73.05%) | total_pruned =     138 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     316 /     512             ( 61.72%) | total_pruned =     196 | shape = torch.Size([512])
linear.weight        | nonzeros =    2989 /    5120             ( 58.38%) | total_pruned =    2131 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 393319, pruned : 10785443, total: 11178762, Compression rate :      28.42x  ( 96.48% pruned)
Train Epoch: 38/100 Loss: 0.020662 Accuracy: 88.36 100.00 % Best test Accuracy: 88.36%
tensor(0.0614, device='cuda:0') tensor(0.1317, device='cuda:0') tensor(-4.7370e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.049367
Average KL loss: 0.009346
Average total loss: 0.058713
tensor(0.0611, device='cuda:0') tensor(0.1310, device='cuda:0') tensor(-6.2698e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.049078
Average KL loss: 0.009308
Average total loss: 0.058386
tensor(0.0608, device='cuda:0') tensor(0.1306, device='cuda:0') tensor(-4.1127e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.048567
Average KL loss: 0.009275
Average total loss: 0.057841
tensor(0.0606, device='cuda:0') tensor(0.1303, device='cuda:0') tensor(-5.2680e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.048204
Average KL loss: 0.009244
Average total loss: 0.057447
tensor(0.0604, device='cuda:0') tensor(0.1300, device='cuda:0') tensor(-4.4651e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.046612
Average KL loss: 0.009214
Average total loss: 0.055826
tensor(0.0602, device='cuda:0') tensor(0.1297, device='cuda:0') tensor(-4.3037e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.049036
Average KL loss: 0.009186
Average total loss: 0.058222
tensor(0.0600, device='cuda:0') tensor(0.1295, device='cuda:0') tensor(-3.7322e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.047243
Average KL loss: 0.009160
Average total loss: 0.056403
tensor(0.0598, device='cuda:0') tensor(0.1292, device='cuda:0') tensor(-3.9411e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.047440
Average KL loss: 0.009135
Average total loss: 0.056575
tensor(0.0596, device='cuda:0') tensor(0.1290, device='cuda:0') tensor(-3.3959e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.051037
Average KL loss: 0.009112
Average total loss: 0.060149
tensor(0.0594, device='cuda:0') tensor(0.1288, device='cuda:0') tensor(-4.9191e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.046641
Average KL loss: 0.009090
Average total loss: 0.055731
tensor(0.0592, device='cuda:0') tensor(0.1286, device='cuda:0') tensor(-4.0879e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.045378
Average KL loss: 0.009069
Average total loss: 0.054448
tensor(0.0591, device='cuda:0') tensor(0.1284, device='cuda:0') tensor(-3.8968e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.047140
Average KL loss: 0.009049
Average total loss: 0.056190
tensor(0.0589, device='cuda:0') tensor(0.1282, device='cuda:0') tensor(-4.6084e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.046992
Average KL loss: 0.009031
Average total loss: 0.056023
tensor(0.0587, device='cuda:0') tensor(0.1280, device='cuda:0') tensor(-3.3853e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.045434
Average KL loss: 0.009013
Average total loss: 0.054448
tensor(0.0586, device='cuda:0') tensor(0.1279, device='cuda:0') tensor(-3.9324e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.046707
Average KL loss: 0.008996
Average total loss: 0.055703
tensor(0.0584, device='cuda:0') tensor(0.1277, device='cuda:0') tensor(-3.7783e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.045925
Average KL loss: 0.008980
Average total loss: 0.054905
tensor(0.0583, device='cuda:0') tensor(0.1276, device='cuda:0') tensor(-5.5429e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.047656
Average KL loss: 0.008966
Average total loss: 0.056621
tensor(0.0581, device='cuda:0') tensor(0.1274, device='cuda:0') tensor(-4.4388e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.045101
Average KL loss: 0.008951
Average total loss: 0.054053
tensor(0.0580, device='cuda:0') tensor(0.1273, device='cuda:0') tensor(-4.6922e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.046464
Average KL loss: 0.008938
Average total loss: 0.055402
tensor(0.0579, device='cuda:0') tensor(0.1272, device='cuda:0') tensor(-3.1618e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.044193
Average KL loss: 0.008925
Average total loss: 0.053118
tensor(0.0578, device='cuda:0') tensor(0.1271, device='cuda:0') tensor(-3.3170e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.046188
Average KL loss: 0.008912
Average total loss: 0.055100
tensor(0.0576, device='cuda:0') tensor(0.1269, device='cuda:0') tensor(-3.8741e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.045280
Average KL loss: 0.008900
Average total loss: 0.054180
tensor(0.0575, device='cuda:0') tensor(0.1268, device='cuda:0') tensor(-5.5664e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.045848
Average KL loss: 0.008889
Average total loss: 0.054737
tensor(0.0574, device='cuda:0') tensor(0.1267, device='cuda:0') tensor(-3.1785e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.046214
Average KL loss: 0.008879
Average total loss: 0.055093
tensor(0.0573, device='cuda:0') tensor(0.1266, device='cuda:0') tensor(-5.4103e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.043277
Average KL loss: 0.008869
Average total loss: 0.052146
tensor(0.0572, device='cuda:0') tensor(0.1265, device='cuda:0') tensor(-4.8113e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.045048
Average KL loss: 0.008859
Average total loss: 0.053907
tensor(0.0571, device='cuda:0') tensor(0.1264, device='cuda:0') tensor(-3.1787e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.044655
Average KL loss: 0.008850
Average total loss: 0.053505
tensor(0.0570, device='cuda:0') tensor(0.1264, device='cuda:0') tensor(-1.9793e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.042841
Average KL loss: 0.008841
Average total loss: 0.051681
tensor(0.0569, device='cuda:0') tensor(0.1263, device='cuda:0') tensor(-3.7445e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.043466
Average KL loss: 0.008832
Average total loss: 0.052298
tensor(0.0568, device='cuda:0') tensor(0.1262, device='cuda:0') tensor(-4.4406e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.043704
Average KL loss: 0.008824
Average total loss: 0.052528
tensor(0.0568, device='cuda:0') tensor(0.1261, device='cuda:0') tensor(-3.9460e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.042909
Average KL loss: 0.008816
Average total loss: 0.051725
tensor(0.0567, device='cuda:0') tensor(0.1260, device='cuda:0') tensor(-4.1160e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.043295
Average KL loss: 0.008808
Average total loss: 0.052103
tensor(0.0566, device='cuda:0') tensor(0.1260, device='cuda:0') tensor(-3.5060e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.045158
Average KL loss: 0.008801
Average total loss: 0.053959
tensor(0.0565, device='cuda:0') tensor(0.1259, device='cuda:0') tensor(-3.3986e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.043536
Average KL loss: 0.008794
Average total loss: 0.052329
tensor(0.0565, device='cuda:0') tensor(0.1259, device='cuda:0') tensor(-3.1418e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.044547
Average KL loss: 0.008787
Average total loss: 0.053334
tensor(0.0564, device='cuda:0') tensor(0.1258, device='cuda:0') tensor(-4.0040e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.045465
Average KL loss: 0.008781
Average total loss: 0.054246
tensor(0.0563, device='cuda:0') tensor(0.1257, device='cuda:0') tensor(-3.7367e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.044602
Average KL loss: 0.008775
Average total loss: 0.053377
tensor(0.0563, device='cuda:0') tensor(0.1257, device='cuda:0') tensor(-4.1875e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.042805
Average KL loss: 0.008769
Average total loss: 0.051574
tensor(0.0562, device='cuda:0') tensor(0.1256, device='cuda:0') tensor(-3.5648e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.042495
Average KL loss: 0.008763
Average total loss: 0.051258
tensor(0.0561, device='cuda:0') tensor(0.1256, device='cuda:0') tensor(-3.2504e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.043905
Average KL loss: 0.008757
Average total loss: 0.052662
tensor(0.0561, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-2.2305e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.042199
Average KL loss: 0.008752
Average total loss: 0.050951
tensor(0.0560, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-4.0926e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.042632
Average KL loss: 0.008747
Average total loss: 0.051378
tensor(0.0560, device='cuda:0') tensor(0.1255, device='cuda:0') tensor(-4.3547e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.043164
Average KL loss: 0.008742
Average total loss: 0.051905
tensor(0.0559, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-3.3927e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.043912
Average KL loss: 0.008737
Average total loss: 0.052649
tensor(0.0559, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-4.6118e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.041847
Average KL loss: 0.008732
Average total loss: 0.050579
tensor(0.0558, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-3.6899e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.041921
Average KL loss: 0.008728
Average total loss: 0.050648
tensor(0.0558, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-4.3092e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.042153
Average KL loss: 0.008723
Average total loss: 0.050876
tensor(0.0558, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-3.7796e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.041562
Average KL loss: 0.008719
Average total loss: 0.050281
tensor(0.0557, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-3.3941e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.042393
Average KL loss: 0.008715
Average total loss: 0.051108
tensor(0.0557, device='cuda:0') tensor(0.1252, device='cuda:0') tensor(-5.5282e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.042942
Average KL loss: 0.008712
Average total loss: 0.051653
tensor(0.0556, device='cuda:0') tensor(0.1252, device='cuda:0') tensor(-3.5431e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.041409
Average KL loss: 0.008708
Average total loss: 0.050117
tensor(0.0556, device='cuda:0') tensor(0.1252, device='cuda:0') tensor(-4.0107e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.041484
Average KL loss: 0.008704
Average total loss: 0.050188
tensor(0.0556, device='cuda:0') tensor(0.1252, device='cuda:0') tensor(-2.1702e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.045038
Average KL loss: 0.008701
Average total loss: 0.053739
tensor(0.0555, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-3.5562e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.041418
Average KL loss: 0.008698
Average total loss: 0.050116
tensor(0.0555, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-4.0241e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.041233
Average KL loss: 0.008694
Average total loss: 0.049927
tensor(0.0555, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-3.3702e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.041327
Average KL loss: 0.008691
Average total loss: 0.050018
tensor(0.0554, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-3.2345e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.039795
Average KL loss: 0.008688
Average total loss: 0.048483
tensor(0.0554, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-2.6885e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.039973
Average KL loss: 0.008685
Average total loss: 0.048658
tensor(0.0554, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-4.4068e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.042142
Average KL loss: 0.008682
Average total loss: 0.050825
tensor(0.0553, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.9642e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.041649
Average KL loss: 0.008680
Average total loss: 0.050329
tensor(0.0553, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-2.2156e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.041188
Average KL loss: 0.008677
Average total loss: 0.049865
tensor(0.0553, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.0506e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.039007
Average KL loss: 0.008675
Average total loss: 0.047682
tensor(0.0553, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.7417e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.042458
Average KL loss: 0.008672
Average total loss: 0.051130
tensor(0.0552, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.7743e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.041065
Average KL loss: 0.008670
Average total loss: 0.049735
tensor(0.0552, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.3412e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.039730
Average KL loss: 0.008668
Average total loss: 0.048398
tensor(0.0552, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.0521e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.039005
Average KL loss: 0.008666
Average total loss: 0.047671
tensor(0.0552, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.5525e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.039924
Average KL loss: 0.008664
Average total loss: 0.048588
tensor(0.0552, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.0093e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.040185
Average KL loss: 0.008662
Average total loss: 0.048847
tensor(0.0551, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.7197e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.038796
Average KL loss: 0.008660
Average total loss: 0.047456
tensor(0.0551, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-2.1473e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.042190
Average KL loss: 0.008659
Average total loss: 0.050849
tensor(0.0551, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.5993e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.039982
Average KL loss: 0.008657
Average total loss: 0.048639
tensor(0.0551, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-5.8416e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.039651
Average KL loss: 0.008655
Average total loss: 0.048306
tensor(0.0551, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.7990e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.039677
Average KL loss: 0.008654
Average total loss: 0.048331
tensor(0.0550, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.9105e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.039880
Average KL loss: 0.008653
Average total loss: 0.048532
tensor(0.0550, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.4244e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.038785
Average KL loss: 0.008651
Average total loss: 0.047436
tensor(0.0550, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-2.2940e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.038919
Average KL loss: 0.008650
Average total loss: 0.047569
tensor(0.0550, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.4048e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.040332
Average KL loss: 0.008648
Average total loss: 0.048980
tensor(0.0550, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-2.5897e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.038658
Average KL loss: 0.008647
Average total loss: 0.047305
tensor(0.0550, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-4.7234e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.038630
Average KL loss: 0.008646
Average total loss: 0.047276
tensor(0.0550, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-2.9080e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.040754
Average KL loss: 0.008645
Average total loss: 0.049399
tensor(0.0549, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-2.7806e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.038265
Average KL loss: 0.008644
Average total loss: 0.046909
tensor(0.0549, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-2.0049e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.038071
Average KL loss: 0.008643
Average total loss: 0.046714
tensor(0.0549, device='cuda:0') tensor(0.1250, device='cuda:0') tensor(-3.1259e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.038003
Average KL loss: 0.008642
Average total loss: 0.046645
tensor(0.0549, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-3.1197e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.038244
Average KL loss: 0.008641
Average total loss: 0.046885
tensor(0.0549, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-3.6855e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.038116
Average KL loss: 0.008640
Average total loss: 0.046757
tensor(0.0549, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-2.0105e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.038595
Average KL loss: 0.008640
Average total loss: 0.047235
tensor(0.0549, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-2.4708e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.038826
Average KL loss: 0.008639
Average total loss: 0.047465
tensor(0.0549, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-2.1539e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.038033
Average KL loss: 0.008638
Average total loss: 0.046671
tensor(0.0548, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-3.4869e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.037045
Average KL loss: 0.008638
Average total loss: 0.045683
tensor(0.0548, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-3.0187e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.037287
Average KL loss: 0.008637
Average total loss: 0.045924
tensor(0.0548, device='cuda:0') tensor(0.1251, device='cuda:0') tensor(-1.9214e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.037133
Average KL loss: 0.008636
Average total loss: 0.045770
tensor(0.0548, device='cuda:0') tensor(0.1252, device='cuda:0') tensor(-2.6177e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.036714
Average KL loss: 0.008636
Average total loss: 0.045350
tensor(0.0548, device='cuda:0') tensor(0.1252, device='cuda:0') tensor(-2.0063e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.036174
Average KL loss: 0.008635
Average total loss: 0.044809
tensor(0.0548, device='cuda:0') tensor(0.1252, device='cuda:0') tensor(-3.1949e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.038270
Average KL loss: 0.008634
Average total loss: 0.046904
tensor(0.0548, device='cuda:0') tensor(0.1252, device='cuda:0') tensor(-2.6475e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.038094
Average KL loss: 0.008634
Average total loss: 0.046728
tensor(0.0548, device='cuda:0') tensor(0.1252, device='cuda:0') tensor(-3.8514e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.036851
Average KL loss: 0.008634
Average total loss: 0.045485
tensor(0.0548, device='cuda:0') tensor(0.1252, device='cuda:0') tensor(-2.6826e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.037214
Average KL loss: 0.008633
Average total loss: 0.045847
tensor(0.0548, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-3.1570e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.038519
Average KL loss: 0.008633
Average total loss: 0.047153
tensor(0.0548, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-3.4732e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.036861
Average KL loss: 0.008633
Average total loss: 0.045494
tensor(0.0547, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-2.4328e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.036627
Average KL loss: 0.008633
Average total loss: 0.045259
tensor(0.0547, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-2.9800e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.037289
Average KL loss: 0.008632
Average total loss: 0.045922
tensor(0.0547, device='cuda:0') tensor(0.1253, device='cuda:0') tensor(-4.4737e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.036745
Average KL loss: 0.008632
Average total loss: 0.045377
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.4611e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.039317
Average KL loss: 0.008632
Average total loss: 0.047950
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-3.0670e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.036187
Average KL loss: 0.008632
Average total loss: 0.044819
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-3.0411e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.036577
Average KL loss: 0.008632
Average total loss: 0.045210
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-3.6222e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.036282
Average KL loss: 0.008632
Average total loss: 0.044915
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.9394e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.035819
Average KL loss: 0.008632
Average total loss: 0.044451
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.0027e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.037023
Average KL loss: 0.008632
Average total loss: 0.045655
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.2269e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.037440
Average KL loss: 0.008632
Average total loss: 0.046073
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.8267e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.036309
Average KL loss: 0.008632
Average total loss: 0.044942
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.7210e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.036504
Average KL loss: 0.008632
Average total loss: 0.045136
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.1317e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.035910
Average KL loss: 0.008632
Average total loss: 0.044542
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.9279e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.036932
Average KL loss: 0.008632
Average total loss: 0.045564
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.7370e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.036573
Average KL loss: 0.008632
Average total loss: 0.045205
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.7807e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.038568
Average KL loss: 0.008632
Average total loss: 0.047200
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.9147e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.037015
Average KL loss: 0.008632
Average total loss: 0.045648
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.2321e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.036820
Average KL loss: 0.008632
Average total loss: 0.045453
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.0291e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.036434
Average KL loss: 0.008632
Average total loss: 0.045066
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-3.8068e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.037154
Average KL loss: 0.008632
Average total loss: 0.045787
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.3024e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.035335
Average KL loss: 0.008632
Average total loss: 0.043968
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.2463e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.036254
Average KL loss: 0.008632
Average total loss: 0.044887
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-3.3401e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.037813
Average KL loss: 0.008632
Average total loss: 0.046445
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-3.9243e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.036557
Average KL loss: 0.008632
Average total loss: 0.045189
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.2154e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.041827
Average KL loss: 0.008632
Average total loss: 0.050459
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-3.7540e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.037996
Average KL loss: 0.008632
Average total loss: 0.046629
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.9209e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.038135
Average KL loss: 0.008632
Average total loss: 0.046767
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-2.7594e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.036116
Average KL loss: 0.008632
Average total loss: 0.044749
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-3.2989e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.037801
Average KL loss: 0.008632
Average total loss: 0.046434
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-1.6725e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.036057
Average KL loss: 0.008632
Average total loss: 0.044689
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-1.9864e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.036706
Average KL loss: 0.008632
Average total loss: 0.045339
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-3.6500e-09, device='cuda:0')
 Percentile value: 1.059539794921875
Non-zero model percentage: 2.8147659301757812%, Non-zero mask percentage: 2.8147659301757812%

--- Pruning Level [16/24]: ---
conv1.weight         | nonzeros =     184 /    1728             ( 10.65%) | total_pruned =    1544 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      99 /   36864             (  0.27%) | total_pruned =   36765 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     169 /   36864             (  0.46%) | total_pruned =   36695 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     554 /   36864             (  1.50%) | total_pruned =   36310 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1383 /   36864             (  3.75%) | total_pruned =   35481 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    5131 /   73728             (  6.96%) | total_pruned =   68597 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   10765 /  147456             (  7.30%) | total_pruned =  136691 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1196 /    8192             ( 14.60%) | total_pruned =    6996 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    6255 /  147456             (  4.24%) | total_pruned =  141201 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    5555 /  147456             (  3.77%) | total_pruned =  141901 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   26439 /  294912             (  8.97%) | total_pruned =  268473 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   36921 /  589824             (  6.26%) | total_pruned =  552903 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3957 /   32768             ( 12.08%) | total_pruned =   28811 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     172 /     256             ( 67.19%) | total_pruned =      84 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   17593 /  589824             (  2.98%) | total_pruned =  572231 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     159 /     256             ( 62.11%) | total_pruned =      97 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   13402 /  589824             (  2.27%) | total_pruned =  576422 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     145 /     256             ( 56.64%) | total_pruned =     111 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   48270 / 1179648             (  4.09%) | total_pruned = 1131378 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     378 /     512             ( 73.83%) | total_pruned =     134 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   48347 / 2359296             (  2.05%) | total_pruned = 2310949 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     351 /     512             ( 68.55%) | total_pruned =     161 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     191 /     512             ( 37.30%) | total_pruned =     321 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1723 /  131072             (  1.31%) | total_pruned =  129349 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     139 /     512             ( 27.15%) | total_pruned =     373 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     194 /     512             ( 37.89%) | total_pruned =     318 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   28253 / 2359296             (  1.20%) | total_pruned = 2331043 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     237 /     512             ( 46.29%) | total_pruned =     275 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   51974 / 2359296             (  2.20%) | total_pruned = 2307322 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     357 /     512             ( 69.73%) | total_pruned =     155 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     306 /     512             ( 59.77%) | total_pruned =     206 | shape = torch.Size([512])
linear.weight        | nonzeros =    2807 /    5120             ( 54.82%) | total_pruned =    2313 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 314656, pruned : 10864106, total: 11178762, Compression rate :      35.53x  ( 97.19% pruned)
Train Epoch: 39/100 Loss: 0.015990 Accuracy: 87.68 100.00 % Best test Accuracy: 87.83%
tensor(0.0547, device='cuda:0') tensor(0.1254, device='cuda:0') tensor(-3.6767e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.047069
Average KL loss: 0.008605
Average total loss: 0.055674
tensor(0.0544, device='cuda:0') tensor(0.1248, device='cuda:0') tensor(-4.8349e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.048558
Average KL loss: 0.008567
Average total loss: 0.057125
tensor(0.0542, device='cuda:0') tensor(0.1243, device='cuda:0') tensor(-6.8870e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.047943
Average KL loss: 0.008532
Average total loss: 0.056476
tensor(0.0540, device='cuda:0') tensor(0.1240, device='cuda:0') tensor(-4.5618e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.047120
Average KL loss: 0.008500
Average total loss: 0.055619
tensor(0.0538, device='cuda:0') tensor(0.1236, device='cuda:0') tensor(-4.3738e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.047834
Average KL loss: 0.008468
Average total loss: 0.056303
tensor(0.0536, device='cuda:0') tensor(0.1233, device='cuda:0') tensor(-4.7039e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.048252
Average KL loss: 0.008438
Average total loss: 0.056690
tensor(0.0534, device='cuda:0') tensor(0.1230, device='cuda:0') tensor(-4.0459e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.046034
Average KL loss: 0.008410
Average total loss: 0.054443
tensor(0.0532, device='cuda:0') tensor(0.1227, device='cuda:0') tensor(-4.3217e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.047109
Average KL loss: 0.008382
Average total loss: 0.055491
tensor(0.0531, device='cuda:0') tensor(0.1224, device='cuda:0') tensor(-4.6987e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.045950
Average KL loss: 0.008356
Average total loss: 0.054306
tensor(0.0529, device='cuda:0') tensor(0.1221, device='cuda:0') tensor(-5.4380e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.046325
Average KL loss: 0.008331
Average total loss: 0.054655
tensor(0.0527, device='cuda:0') tensor(0.1218, device='cuda:0') tensor(-4.8600e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.047892
Average KL loss: 0.008307
Average total loss: 0.056198
tensor(0.0525, device='cuda:0') tensor(0.1216, device='cuda:0') tensor(-4.5832e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.045716
Average KL loss: 0.008284
Average total loss: 0.054000
tensor(0.0524, device='cuda:0') tensor(0.1214, device='cuda:0') tensor(-4.3228e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.045132
Average KL loss: 0.008262
Average total loss: 0.053393
tensor(0.0522, device='cuda:0') tensor(0.1211, device='cuda:0') tensor(-5.4372e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.045072
Average KL loss: 0.008241
Average total loss: 0.053312
tensor(0.0521, device='cuda:0') tensor(0.1209, device='cuda:0') tensor(-4.8388e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.048199
Average KL loss: 0.008220
Average total loss: 0.056419
tensor(0.0519, device='cuda:0') tensor(0.1207, device='cuda:0') tensor(-3.8182e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.045760
Average KL loss: 0.008201
Average total loss: 0.053961
tensor(0.0518, device='cuda:0') tensor(0.1205, device='cuda:0') tensor(-4.1828e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.044531
Average KL loss: 0.008183
Average total loss: 0.052713
tensor(0.0516, device='cuda:0') tensor(0.1203, device='cuda:0') tensor(-3.0976e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.045092
Average KL loss: 0.008165
Average total loss: 0.053257
tensor(0.0515, device='cuda:0') tensor(0.1201, device='cuda:0') tensor(-5.1371e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.046044
Average KL loss: 0.008148
Average total loss: 0.054192
tensor(0.0514, device='cuda:0') tensor(0.1199, device='cuda:0') tensor(-3.6540e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.044484
Average KL loss: 0.008132
Average total loss: 0.052616
tensor(0.0512, device='cuda:0') tensor(0.1198, device='cuda:0') tensor(-4.4826e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.045909
Average KL loss: 0.008116
Average total loss: 0.054025
tensor(0.0511, device='cuda:0') tensor(0.1196, device='cuda:0') tensor(-4.2322e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.044140
Average KL loss: 0.008101
Average total loss: 0.052241
tensor(0.0510, device='cuda:0') tensor(0.1195, device='cuda:0') tensor(-4.3754e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.044394
Average KL loss: 0.008087
Average total loss: 0.052480
tensor(0.0509, device='cuda:0') tensor(0.1193, device='cuda:0') tensor(-3.5668e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.044132
Average KL loss: 0.008073
Average total loss: 0.052205
tensor(0.0508, device='cuda:0') tensor(0.1192, device='cuda:0') tensor(-4.2782e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.044665
Average KL loss: 0.008060
Average total loss: 0.052725
tensor(0.0507, device='cuda:0') tensor(0.1190, device='cuda:0') tensor(-3.6267e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.044763
Average KL loss: 0.008047
Average total loss: 0.052809
tensor(0.0506, device='cuda:0') tensor(0.1189, device='cuda:0') tensor(-3.1814e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.043891
Average KL loss: 0.008035
Average total loss: 0.051926
tensor(0.0504, device='cuda:0') tensor(0.1188, device='cuda:0') tensor(-3.7513e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.044257
Average KL loss: 0.008023
Average total loss: 0.052280
tensor(0.0504, device='cuda:0') tensor(0.1186, device='cuda:0') tensor(-3.7413e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.042559
Average KL loss: 0.008012
Average total loss: 0.050571
tensor(0.0503, device='cuda:0') tensor(0.1185, device='cuda:0') tensor(-2.9807e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.046526
Average KL loss: 0.008001
Average total loss: 0.054527
tensor(0.0502, device='cuda:0') tensor(0.1184, device='cuda:0') tensor(-2.9946e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.043664
Average KL loss: 0.007990
Average total loss: 0.051654
tensor(0.0501, device='cuda:0') tensor(0.1183, device='cuda:0') tensor(-3.1922e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.042975
Average KL loss: 0.007980
Average total loss: 0.050955
tensor(0.0500, device='cuda:0') tensor(0.1182, device='cuda:0') tensor(-3.8115e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.043672
Average KL loss: 0.007970
Average total loss: 0.051642
tensor(0.0499, device='cuda:0') tensor(0.1181, device='cuda:0') tensor(-4.1543e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.043223
Average KL loss: 0.007961
Average total loss: 0.051184
tensor(0.0498, device='cuda:0') tensor(0.1180, device='cuda:0') tensor(-3.4133e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.041761
Average KL loss: 0.007952
Average total loss: 0.049713
tensor(0.0497, device='cuda:0') tensor(0.1179, device='cuda:0') tensor(-3.5456e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.043491
Average KL loss: 0.007943
Average total loss: 0.051434
tensor(0.0497, device='cuda:0') tensor(0.1178, device='cuda:0') tensor(-6.0546e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.042459
Average KL loss: 0.007934
Average total loss: 0.050393
tensor(0.0496, device='cuda:0') tensor(0.1177, device='cuda:0') tensor(-4.0486e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.041495
Average KL loss: 0.007926
Average total loss: 0.049421
tensor(0.0495, device='cuda:0') tensor(0.1177, device='cuda:0') tensor(-3.6881e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.044123
Average KL loss: 0.007918
Average total loss: 0.052041
tensor(0.0495, device='cuda:0') tensor(0.1176, device='cuda:0') tensor(-4.3587e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.043373
Average KL loss: 0.007910
Average total loss: 0.051283
tensor(0.0494, device='cuda:0') tensor(0.1175, device='cuda:0') tensor(-3.5047e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.041127
Average KL loss: 0.007903
Average total loss: 0.049030
tensor(0.0493, device='cuda:0') tensor(0.1174, device='cuda:0') tensor(-2.4616e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.041723
Average KL loss: 0.007896
Average total loss: 0.049618
tensor(0.0493, device='cuda:0') tensor(0.1174, device='cuda:0') tensor(-4.0610e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.041161
Average KL loss: 0.007889
Average total loss: 0.049049
tensor(0.0492, device='cuda:0') tensor(0.1173, device='cuda:0') tensor(-3.7029e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.043956
Average KL loss: 0.007882
Average total loss: 0.051838
tensor(0.0491, device='cuda:0') tensor(0.1172, device='cuda:0') tensor(-3.7396e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.042226
Average KL loss: 0.007876
Average total loss: 0.050102
tensor(0.0491, device='cuda:0') tensor(0.1172, device='cuda:0') tensor(-3.5973e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.042578
Average KL loss: 0.007869
Average total loss: 0.050448
tensor(0.0490, device='cuda:0') tensor(0.1171, device='cuda:0') tensor(-4.0920e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.041894
Average KL loss: 0.007863
Average total loss: 0.049758
tensor(0.0490, device='cuda:0') tensor(0.1171, device='cuda:0') tensor(-3.6754e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.042095
Average KL loss: 0.007858
Average total loss: 0.049952
tensor(0.0489, device='cuda:0') tensor(0.1170, device='cuda:0') tensor(-3.0201e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.041520
Average KL loss: 0.007852
Average total loss: 0.049372
tensor(0.0489, device='cuda:0') tensor(0.1170, device='cuda:0') tensor(-3.8973e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.042824
Average KL loss: 0.007846
Average total loss: 0.050670
tensor(0.0488, device='cuda:0') tensor(0.1169, device='cuda:0') tensor(-3.5417e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.041674
Average KL loss: 0.007841
Average total loss: 0.049515
tensor(0.0488, device='cuda:0') tensor(0.1169, device='cuda:0') tensor(-4.4467e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.041971
Average KL loss: 0.007836
Average total loss: 0.049807
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-3.0487e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.039525
Average KL loss: 0.007833
Average total loss: 0.047358
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-3.8251e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.040935
Average KL loss: 0.007833
Average total loss: 0.048768
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-3.6601e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.040840
Average KL loss: 0.007832
Average total loss: 0.048672
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-3.8176e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.039998
Average KL loss: 0.007832
Average total loss: 0.047829
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-5.7150e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.040922
Average KL loss: 0.007831
Average total loss: 0.048754
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-3.5721e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.041498
Average KL loss: 0.007831
Average total loss: 0.049329
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-2.6522e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.042071
Average KL loss: 0.007830
Average total loss: 0.049902
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-3.3823e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.041003
Average KL loss: 0.007830
Average total loss: 0.048833
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-4.5214e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.041552
Average KL loss: 0.007829
Average total loss: 0.049382
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-3.7892e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.041512
Average KL loss: 0.007829
Average total loss: 0.049341
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-2.3587e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.041778
Average KL loss: 0.007829
Average total loss: 0.049606
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-2.9282e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.041950
Average KL loss: 0.007828
Average total loss: 0.049778
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-4.0367e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.041215
Average KL loss: 0.007828
Average total loss: 0.049043
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-3.8639e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.041900
Average KL loss: 0.007828
Average total loss: 0.049728
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-4.8575e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.043300
Average KL loss: 0.007828
Average total loss: 0.051128
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-3.7016e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.042246
Average KL loss: 0.007828
Average total loss: 0.050073
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-3.5414e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.040762
Average KL loss: 0.007828
Average total loss: 0.048590
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-7.5004e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.042002
Average KL loss: 0.007828
Average total loss: 0.049829
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-3.7771e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.040797
Average KL loss: 0.007828
Average total loss: 0.048625
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-3.2922e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.040488
Average KL loss: 0.007827
Average total loss: 0.048315
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-3.6655e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.041485
Average KL loss: 0.007827
Average total loss: 0.049312
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-2.9474e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.040088
Average KL loss: 0.007827
Average total loss: 0.047915
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-3.6464e-09, device='cuda:0')
 Percentile value: 1.216138195991516
Non-zero model percentage: 2.251814603805542%, Non-zero mask percentage: 2.251814603805542%

--- Pruning Level [17/24]: ---
conv1.weight         | nonzeros =     181 /    1728             ( 10.47%) | total_pruned =    1547 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      71 /   36864             (  0.19%) | total_pruned =   36793 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     118 /   36864             (  0.32%) | total_pruned =   36746 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     490 /   36864             (  1.33%) | total_pruned =   36374 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1142 /   36864             (  3.10%) | total_pruned =   35722 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4164 /   73728             (  5.65%) | total_pruned =   69564 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    9198 /  147456             (  6.24%) | total_pruned =  138258 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1059 /    8192             ( 12.93%) | total_pruned =    7133 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    5003 /  147456             (  3.39%) | total_pruned =  142453 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    4665 /  147456             (  3.16%) | total_pruned =  142791 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   21223 /  294912             (  7.20%) | total_pruned =  273689 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   29526 /  589824             (  5.01%) | total_pruned =  560298 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     201 /     256             ( 78.52%) | total_pruned =      55 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3308 /   32768             ( 10.10%) | total_pruned =   29460 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     169 /     256             ( 66.02%) | total_pruned =      87 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   13776 /  589824             (  2.34%) | total_pruned =  576048 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     154 /     256             ( 60.16%) | total_pruned =     102 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   10801 /  589824             (  1.83%) | total_pruned =  579023 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     141 /     256             ( 55.08%) | total_pruned =     115 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   38124 / 1179648             (  3.23%) | total_pruned = 1141524 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     371 /     512             ( 72.46%) | total_pruned =     141 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   37605 / 2359296             (  1.59%) | total_pruned = 2321691 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     348 /     512             ( 67.97%) | total_pruned =     164 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     182 /     512             ( 35.55%) | total_pruned =     330 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1323 /  131072             (  1.01%) | total_pruned =  129749 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     131 /     512             ( 25.59%) | total_pruned =     381 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     184 /     512             ( 35.94%) | total_pruned =     328 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   22751 / 2359296             (  0.96%) | total_pruned = 2336545 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     234 /     512             ( 45.70%) | total_pruned =     278 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   40907 / 2359296             (  1.73%) | total_pruned = 2318389 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     346 /     512             ( 67.58%) | total_pruned =     166 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     295 /     512             ( 57.62%) | total_pruned =     217 | shape = torch.Size([512])
linear.weight        | nonzeros =    2704 /    5120             ( 52.81%) | total_pruned =    2416 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 251725, pruned : 10927037, total: 11178762, Compression rate :      44.41x  ( 97.75% pruned)
Train Epoch: 47/100 Loss: 0.013078 Accuracy: 87.79 100.00 % Best test Accuracy: 87.86%
tensor(0.0487, device='cuda:0') tensor(0.1168, device='cuda:0') tensor(-9.0761e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.045367
Average KL loss: 0.007803
Average total loss: 0.053170
tensor(0.0484, device='cuda:0') tensor(0.1162, device='cuda:0') tensor(-4.6233e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.044467
Average KL loss: 0.007767
Average total loss: 0.052234
tensor(0.0482, device='cuda:0') tensor(0.1158, device='cuda:0') tensor(-5.0466e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.044555
Average KL loss: 0.007734
Average total loss: 0.052289
tensor(0.0481, device='cuda:0') tensor(0.1154, device='cuda:0') tensor(-3.6525e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.044981
Average KL loss: 0.007703
Average total loss: 0.052684
tensor(0.0479, device='cuda:0') tensor(0.1151, device='cuda:0') tensor(-4.5257e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.043775
Average KL loss: 0.007673
Average total loss: 0.051448
tensor(0.0477, device='cuda:0') tensor(0.1148, device='cuda:0') tensor(-4.0527e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.043662
Average KL loss: 0.007645
Average total loss: 0.051306
tensor(0.0475, device='cuda:0') tensor(0.1145, device='cuda:0') tensor(-3.0475e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.043112
Average KL loss: 0.007617
Average total loss: 0.050729
tensor(0.0473, device='cuda:0') tensor(0.1143, device='cuda:0') tensor(-2.9790e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.042006
Average KL loss: 0.007591
Average total loss: 0.049597
tensor(0.0472, device='cuda:0') tensor(0.1140, device='cuda:0') tensor(-4.3791e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.042176
Average KL loss: 0.007566
Average total loss: 0.049741
tensor(0.0470, device='cuda:0') tensor(0.1137, device='cuda:0') tensor(-5.0552e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.043331
Average KL loss: 0.007541
Average total loss: 0.050872
tensor(0.0469, device='cuda:0') tensor(0.1135, device='cuda:0') tensor(-3.2848e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.044641
Average KL loss: 0.007518
Average total loss: 0.052159
tensor(0.0467, device='cuda:0') tensor(0.1133, device='cuda:0') tensor(-3.4726e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.045397
Average KL loss: 0.007497
Average total loss: 0.052893
tensor(0.0466, device='cuda:0') tensor(0.1131, device='cuda:0') tensor(-3.0994e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.043314
Average KL loss: 0.007475
Average total loss: 0.050789
tensor(0.0464, device='cuda:0') tensor(0.1129, device='cuda:0') tensor(-3.1276e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.041225
Average KL loss: 0.007455
Average total loss: 0.048681
tensor(0.0463, device='cuda:0') tensor(0.1127, device='cuda:0') tensor(-4.3180e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.042333
Average KL loss: 0.007436
Average total loss: 0.049769
tensor(0.0461, device='cuda:0') tensor(0.1125, device='cuda:0') tensor(-4.6386e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.040654
Average KL loss: 0.007418
Average total loss: 0.048072
tensor(0.0460, device='cuda:0') tensor(0.1123, device='cuda:0') tensor(-3.2867e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.041616
Average KL loss: 0.007400
Average total loss: 0.049017
tensor(0.0459, device='cuda:0') tensor(0.1121, device='cuda:0') tensor(-4.8462e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.040818
Average KL loss: 0.007384
Average total loss: 0.048202
tensor(0.0458, device='cuda:0') tensor(0.1120, device='cuda:0') tensor(-3.5616e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.043917
Average KL loss: 0.007368
Average total loss: 0.051285
tensor(0.0456, device='cuda:0') tensor(0.1118, device='cuda:0') tensor(-3.8759e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.041200
Average KL loss: 0.007353
Average total loss: 0.048554
tensor(0.0455, device='cuda:0') tensor(0.1117, device='cuda:0') tensor(-4.1528e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.041335
Average KL loss: 0.007339
Average total loss: 0.048674
tensor(0.0454, device='cuda:0') tensor(0.1115, device='cuda:0') tensor(-3.3156e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.040741
Average KL loss: 0.007325
Average total loss: 0.048066
tensor(0.0453, device='cuda:0') tensor(0.1114, device='cuda:0') tensor(-5.1780e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.041465
Average KL loss: 0.007312
Average total loss: 0.048777
tensor(0.0452, device='cuda:0') tensor(0.1112, device='cuda:0') tensor(-3.4202e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.041711
Average KL loss: 0.007300
Average total loss: 0.049011
tensor(0.0451, device='cuda:0') tensor(0.1111, device='cuda:0') tensor(-3.3699e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.041523
Average KL loss: 0.007288
Average total loss: 0.048811
tensor(0.0450, device='cuda:0') tensor(0.1110, device='cuda:0') tensor(-3.8825e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.041021
Average KL loss: 0.007277
Average total loss: 0.048299
tensor(0.0449, device='cuda:0') tensor(0.1109, device='cuda:0') tensor(-3.4970e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.040838
Average KL loss: 0.007267
Average total loss: 0.048104
tensor(0.0448, device='cuda:0') tensor(0.1108, device='cuda:0') tensor(-3.0743e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.041512
Average KL loss: 0.007257
Average total loss: 0.048769
tensor(0.0447, device='cuda:0') tensor(0.1107, device='cuda:0') tensor(-3.9815e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.039944
Average KL loss: 0.007247
Average total loss: 0.047191
tensor(0.0446, device='cuda:0') tensor(0.1106, device='cuda:0') tensor(-5.1768e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.039711
Average KL loss: 0.007238
Average total loss: 0.046949
tensor(0.0445, device='cuda:0') tensor(0.1105, device='cuda:0') tensor(-3.8587e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.039858
Average KL loss: 0.007229
Average total loss: 0.047087
tensor(0.0444, device='cuda:0') tensor(0.1104, device='cuda:0') tensor(-4.7630e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.039834
Average KL loss: 0.007221
Average total loss: 0.047054
tensor(0.0444, device='cuda:0') tensor(0.1103, device='cuda:0') tensor(-3.2851e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.040367
Average KL loss: 0.007213
Average total loss: 0.047580
tensor(0.0443, device='cuda:0') tensor(0.1102, device='cuda:0') tensor(-4.0514e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.041146
Average KL loss: 0.007205
Average total loss: 0.048351
tensor(0.0442, device='cuda:0') tensor(0.1102, device='cuda:0') tensor(-4.5097e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.039727
Average KL loss: 0.007198
Average total loss: 0.046925
tensor(0.0441, device='cuda:0') tensor(0.1101, device='cuda:0') tensor(-4.6144e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.040106
Average KL loss: 0.007191
Average total loss: 0.047297
tensor(0.0441, device='cuda:0') tensor(0.1100, device='cuda:0') tensor(-3.9473e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.039414
Average KL loss: 0.007185
Average total loss: 0.046598
tensor(0.0440, device='cuda:0') tensor(0.1099, device='cuda:0') tensor(-3.7547e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.038528
Average KL loss: 0.007178
Average total loss: 0.045706
tensor(0.0439, device='cuda:0') tensor(0.1099, device='cuda:0') tensor(-3.2443e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.038861
Average KL loss: 0.007172
Average total loss: 0.046032
tensor(0.0439, device='cuda:0') tensor(0.1098, device='cuda:0') tensor(-4.0959e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.038954
Average KL loss: 0.007166
Average total loss: 0.046120
tensor(0.0438, device='cuda:0') tensor(0.1098, device='cuda:0') tensor(-3.6833e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.038377
Average KL loss: 0.007160
Average total loss: 0.045537
tensor(0.0438, device='cuda:0') tensor(0.1097, device='cuda:0') tensor(-3.1012e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.039124
Average KL loss: 0.007155
Average total loss: 0.046279
tensor(0.0437, device='cuda:0') tensor(0.1096, device='cuda:0') tensor(-4.4155e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.039914
Average KL loss: 0.007150
Average total loss: 0.047064
tensor(0.0436, device='cuda:0') tensor(0.1096, device='cuda:0') tensor(-4.5352e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.038382
Average KL loss: 0.007145
Average total loss: 0.045527
tensor(0.0436, device='cuda:0') tensor(0.1095, device='cuda:0') tensor(-4.2341e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.037789
Average KL loss: 0.007140
Average total loss: 0.044929
tensor(0.0435, device='cuda:0') tensor(0.1095, device='cuda:0') tensor(-2.4964e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.038397
Average KL loss: 0.007135
Average total loss: 0.045532
tensor(0.0435, device='cuda:0') tensor(0.1094, device='cuda:0') tensor(-3.0664e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.037335
Average KL loss: 0.007130
Average total loss: 0.044465
tensor(0.0435, device='cuda:0') tensor(0.1094, device='cuda:0') tensor(-4.2441e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.038687
Average KL loss: 0.007126
Average total loss: 0.045814
tensor(0.0434, device='cuda:0') tensor(0.1094, device='cuda:0') tensor(-4.3038e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.038551
Average KL loss: 0.007122
Average total loss: 0.045673
tensor(0.0434, device='cuda:0') tensor(0.1093, device='cuda:0') tensor(-3.7499e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.038683
Average KL loss: 0.007118
Average total loss: 0.045801
tensor(0.0433, device='cuda:0') tensor(0.1093, device='cuda:0') tensor(-2.1809e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.036744
Average KL loss: 0.007114
Average total loss: 0.043859
tensor(0.0433, device='cuda:0') tensor(0.1092, device='cuda:0') tensor(-4.1433e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.037716
Average KL loss: 0.007110
Average total loss: 0.044827
tensor(0.0433, device='cuda:0') tensor(0.1092, device='cuda:0') tensor(-3.8340e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.036888
Average KL loss: 0.007107
Average total loss: 0.043995
tensor(0.0432, device='cuda:0') tensor(0.1092, device='cuda:0') tensor(-2.8885e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.036770
Average KL loss: 0.007103
Average total loss: 0.043873
tensor(0.0432, device='cuda:0') tensor(0.1091, device='cuda:0') tensor(-2.9905e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.037966
Average KL loss: 0.007100
Average total loss: 0.045066
tensor(0.0431, device='cuda:0') tensor(0.1091, device='cuda:0') tensor(-5.2658e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.039430
Average KL loss: 0.007097
Average total loss: 0.046526
tensor(0.0431, device='cuda:0') tensor(0.1091, device='cuda:0') tensor(-3.6623e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.038496
Average KL loss: 0.007094
Average total loss: 0.045590
tensor(0.0431, device='cuda:0') tensor(0.1091, device='cuda:0') tensor(-2.2927e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.037028
Average KL loss: 0.007091
Average total loss: 0.044119
tensor(0.0431, device='cuda:0') tensor(0.1090, device='cuda:0') tensor(-4.1772e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.037004
Average KL loss: 0.007088
Average total loss: 0.044091
tensor(0.0430, device='cuda:0') tensor(0.1090, device='cuda:0') tensor(-4.9776e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.037437
Average KL loss: 0.007085
Average total loss: 0.044521
tensor(0.0430, device='cuda:0') tensor(0.1090, device='cuda:0') tensor(-2.7281e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.038735
Average KL loss: 0.007082
Average total loss: 0.045817
tensor(0.0430, device='cuda:0') tensor(0.1090, device='cuda:0') tensor(-2.7813e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.038599
Average KL loss: 0.007079
Average total loss: 0.045678
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-2.1103e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.038110
Average KL loss: 0.007078
Average total loss: 0.045188
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.2042e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.036878
Average KL loss: 0.007078
Average total loss: 0.043956
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-6.4950e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.037385
Average KL loss: 0.007077
Average total loss: 0.044463
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-2.6931e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.036338
Average KL loss: 0.007077
Average total loss: 0.043415
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-5.4517e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.036564
Average KL loss: 0.007077
Average total loss: 0.043641
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.1302e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.036703
Average KL loss: 0.007077
Average total loss: 0.043780
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-2.0378e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.037537
Average KL loss: 0.007076
Average total loss: 0.044613
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-2.8197e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.036430
Average KL loss: 0.007076
Average total loss: 0.043506
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-4.3276e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.036257
Average KL loss: 0.007076
Average total loss: 0.043333
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.1373e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.037332
Average KL loss: 0.007076
Average total loss: 0.044408
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.0907e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.035718
Average KL loss: 0.007075
Average total loss: 0.042793
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-7.1963e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.036214
Average KL loss: 0.007075
Average total loss: 0.043289
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-4.3080e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.037400
Average KL loss: 0.007075
Average total loss: 0.044475
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-4.7016e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.037808
Average KL loss: 0.007075
Average total loss: 0.044883
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.0968e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.037223
Average KL loss: 0.007074
Average total loss: 0.044297
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.1653e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.038036
Average KL loss: 0.007074
Average total loss: 0.045110
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.6083e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.038165
Average KL loss: 0.007074
Average total loss: 0.045239
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-1.8986e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.037026
Average KL loss: 0.007074
Average total loss: 0.044100
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.4932e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.036638
Average KL loss: 0.007073
Average total loss: 0.043712
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.9170e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.037109
Average KL loss: 0.007073
Average total loss: 0.044183
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-4.1252e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.036210
Average KL loss: 0.007073
Average total loss: 0.043283
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-4.6783e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.037358
Average KL loss: 0.007073
Average total loss: 0.044431
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.7020e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.039049
Average KL loss: 0.007073
Average total loss: 0.046122
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.7413e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.036227
Average KL loss: 0.007073
Average total loss: 0.043300
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-2.9564e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.037574
Average KL loss: 0.007073
Average total loss: 0.044646
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-2.4644e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.035943
Average KL loss: 0.007073
Average total loss: 0.043015
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.1007e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.036518
Average KL loss: 0.007073
Average total loss: 0.043590
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.3834e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.036311
Average KL loss: 0.007073
Average total loss: 0.043383
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-6.5800e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.035922
Average KL loss: 0.007073
Average total loss: 0.042995
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.8835e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.035544
Average KL loss: 0.007072
Average total loss: 0.042617
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.9716e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.036864
Average KL loss: 0.007072
Average total loss: 0.043936
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-4.8462e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.036661
Average KL loss: 0.007072
Average total loss: 0.043734
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-2.7418e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.036953
Average KL loss: 0.007072
Average total loss: 0.044025
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.7762e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.036609
Average KL loss: 0.007072
Average total loss: 0.043682
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-2.0825e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.036722
Average KL loss: 0.007072
Average total loss: 0.043795
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.7096e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.036694
Average KL loss: 0.007072
Average total loss: 0.043766
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-2.6348e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.035936
Average KL loss: 0.007072
Average total loss: 0.043009
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.3795e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.038353
Average KL loss: 0.007072
Average total loss: 0.045426
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-3.5067e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.035819
Average KL loss: 0.007072
Average total loss: 0.042892
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-2.3998e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.037433
Average KL loss: 0.007072
Average total loss: 0.044505
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-2.9052e-09, device='cuda:0')
 Percentile value: 1.3963130474090577
Non-zero model percentage: 1.8014516830444336%, Non-zero mask percentage: 1.8014516830444336%

--- Pruning Level [18/24]: ---
conv1.weight         | nonzeros =     169 /    1728             (  9.78%) | total_pruned =    1559 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      59 /   36864             (  0.16%) | total_pruned =   36805 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      86 /   36864             (  0.23%) | total_pruned =   36778 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     381 /   36864             (  1.03%) | total_pruned =   36483 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     924 /   36864             (  2.51%) | total_pruned =   35940 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3344 /   73728             (  4.54%) | total_pruned =   70384 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    7794 /  147456             (  5.29%) | total_pruned =  139662 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     920 /    8192             ( 11.23%) | total_pruned =    7272 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4099 /  147456             (  2.78%) | total_pruned =  143357 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3940 /  147456             (  2.67%) | total_pruned =  143516 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   16910 /  294912             (  5.73%) | total_pruned =  278002 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     227 /     256             ( 88.67%) | total_pruned =      29 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   23601 /  589824             (  4.00%) | total_pruned =  566223 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     194 /     256             ( 75.78%) | total_pruned =      62 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2770 /   32768             (  8.45%) | total_pruned =   29998 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     164 /     256             ( 64.06%) | total_pruned =      92 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   10999 /  589824             (  1.86%) | total_pruned =  578825 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     148 /     256             ( 57.81%) | total_pruned =     108 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    8813 /  589824             (  1.49%) | total_pruned =  581011 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     140 /     256             ( 54.69%) | total_pruned =     116 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   30565 / 1179648             (  2.59%) | total_pruned = 1149083 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     361 /     512             ( 70.51%) | total_pruned =     151 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   30447 / 2359296             (  1.29%) | total_pruned = 2328849 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     336 /     512             ( 65.62%) | total_pruned =     176 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     175 /     512             ( 34.18%) | total_pruned =     337 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1099 /  131072             (  0.84%) | total_pruned =  129973 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     122 /     512             ( 23.83%) | total_pruned =     390 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     176 /     512             ( 34.38%) | total_pruned =     336 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   17794 / 2359296             (  0.75%) | total_pruned = 2341502 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     229 /     512             ( 44.73%) | total_pruned =     283 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   30632 / 2359296             (  1.30%) | total_pruned = 2328664 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     340 /     512             ( 66.41%) | total_pruned =     172 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     279 /     512             ( 54.49%) | total_pruned =     233 | shape = torch.Size([512])
linear.weight        | nonzeros =    2560 /    5120             ( 50.00%) | total_pruned =    2560 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 201380, pruned : 10977382, total: 11178762, Compression rate :      55.51x  ( 98.20% pruned)
Train Epoch: 45/100 Loss: 0.023884 Accuracy: 87.54 100.00 % Best test Accuracy: 87.54%
tensor(0.0429, device='cuda:0') tensor(0.1089, device='cuda:0') tensor(-4.5104e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.049584
Average KL loss: 0.007050
Average total loss: 0.056634
tensor(0.0427, device='cuda:0') tensor(0.1083, device='cuda:0') tensor(-6.5704e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.047744
Average KL loss: 0.007017
Average total loss: 0.054761
tensor(0.0425, device='cuda:0') tensor(0.1079, device='cuda:0') tensor(-6.9392e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.051571
Average KL loss: 0.006986
Average total loss: 0.058557
tensor(0.0423, device='cuda:0') tensor(0.1075, device='cuda:0') tensor(-4.3085e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.047724
Average KL loss: 0.006956
Average total loss: 0.054680
tensor(0.0422, device='cuda:0') tensor(0.1072, device='cuda:0') tensor(-5.4862e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.047252
Average KL loss: 0.006927
Average total loss: 0.054179
tensor(0.0420, device='cuda:0') tensor(0.1069, device='cuda:0') tensor(-5.4455e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.049269
Average KL loss: 0.006899
Average total loss: 0.056168
tensor(0.0419, device='cuda:0') tensor(0.1065, device='cuda:0') tensor(-4.4838e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.050285
Average KL loss: 0.006871
Average total loss: 0.057157
tensor(0.0417, device='cuda:0') tensor(0.1062, device='cuda:0') tensor(-5.5587e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.047387
Average KL loss: 0.006845
Average total loss: 0.054232
tensor(0.0416, device='cuda:0') tensor(0.1059, device='cuda:0') tensor(-3.3244e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.048815
Average KL loss: 0.006819
Average total loss: 0.055635
tensor(0.0414, device='cuda:0') tensor(0.1057, device='cuda:0') tensor(-5.5926e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.045882
Average KL loss: 0.006794
Average total loss: 0.052676
tensor(0.0413, device='cuda:0') tensor(0.1054, device='cuda:0') tensor(-4.6849e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.047233
Average KL loss: 0.006770
Average total loss: 0.054003
tensor(0.0412, device='cuda:0') tensor(0.1051, device='cuda:0') tensor(-7.6689e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.048133
Average KL loss: 0.006747
Average total loss: 0.054880
tensor(0.0410, device='cuda:0') tensor(0.1049, device='cuda:0') tensor(-3.1616e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.050315
Average KL loss: 0.006725
Average total loss: 0.057040
tensor(0.0409, device='cuda:0') tensor(0.1046, device='cuda:0') tensor(-4.9877e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.049774
Average KL loss: 0.006703
Average total loss: 0.056477
tensor(0.0408, device='cuda:0') tensor(0.1044, device='cuda:0') tensor(-4.2578e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.044352
Average KL loss: 0.006683
Average total loss: 0.051035
tensor(0.0406, device='cuda:0') tensor(0.1042, device='cuda:0') tensor(-3.7869e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.046470
Average KL loss: 0.006663
Average total loss: 0.053133
tensor(0.0405, device='cuda:0') tensor(0.1040, device='cuda:0') tensor(-4.1285e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.045203
Average KL loss: 0.006643
Average total loss: 0.051846
tensor(0.0404, device='cuda:0') tensor(0.1038, device='cuda:0') tensor(-5.2532e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.048170
Average KL loss: 0.006625
Average total loss: 0.054795
tensor(0.0403, device='cuda:0') tensor(0.1036, device='cuda:0') tensor(-3.7778e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.044602
Average KL loss: 0.006607
Average total loss: 0.051209
tensor(0.0401, device='cuda:0') tensor(0.1034, device='cuda:0') tensor(-3.3450e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.046407
Average KL loss: 0.006590
Average total loss: 0.052997
tensor(0.0400, device='cuda:0') tensor(0.1032, device='cuda:0') tensor(-4.3071e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.045908
Average KL loss: 0.006574
Average total loss: 0.052482
tensor(0.0399, device='cuda:0') tensor(0.1030, device='cuda:0') tensor(-4.1049e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.043718
Average KL loss: 0.006558
Average total loss: 0.050276
tensor(0.0398, device='cuda:0') tensor(0.1028, device='cuda:0') tensor(-4.6064e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.046668
Average KL loss: 0.006543
Average total loss: 0.053211
tensor(0.0397, device='cuda:0') tensor(0.1027, device='cuda:0') tensor(-4.4954e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.047547
Average KL loss: 0.006529
Average total loss: 0.054076
tensor(0.0396, device='cuda:0') tensor(0.1025, device='cuda:0') tensor(-4.0792e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.044485
Average KL loss: 0.006515
Average total loss: 0.051000
tensor(0.0395, device='cuda:0') tensor(0.1024, device='cuda:0') tensor(-4.8098e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.045409
Average KL loss: 0.006502
Average total loss: 0.051911
tensor(0.0394, device='cuda:0') tensor(0.1022, device='cuda:0') tensor(-2.9932e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.043757
Average KL loss: 0.006489
Average total loss: 0.050246
tensor(0.0393, device='cuda:0') tensor(0.1021, device='cuda:0') tensor(-5.8358e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.044053
Average KL loss: 0.006477
Average total loss: 0.050530
tensor(0.0392, device='cuda:0') tensor(0.1019, device='cuda:0') tensor(-4.8875e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.043131
Average KL loss: 0.006465
Average total loss: 0.049596
tensor(0.0391, device='cuda:0') tensor(0.1018, device='cuda:0') tensor(-6.3524e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.043699
Average KL loss: 0.006454
Average total loss: 0.050153
tensor(0.0390, device='cuda:0') tensor(0.1017, device='cuda:0') tensor(-4.8713e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.043766
Average KL loss: 0.006443
Average total loss: 0.050209
tensor(0.0390, device='cuda:0') tensor(0.1016, device='cuda:0') tensor(-3.7219e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.045707
Average KL loss: 0.006433
Average total loss: 0.052140
tensor(0.0389, device='cuda:0') tensor(0.1015, device='cuda:0') tensor(-5.3304e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.044086
Average KL loss: 0.006423
Average total loss: 0.050509
tensor(0.0388, device='cuda:0') tensor(0.1014, device='cuda:0') tensor(-4.5430e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.041962
Average KL loss: 0.006414
Average total loss: 0.048375
tensor(0.0387, device='cuda:0') tensor(0.1012, device='cuda:0') tensor(-3.9993e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.043100
Average KL loss: 0.006405
Average total loss: 0.049504
tensor(0.0386, device='cuda:0') tensor(0.1011, device='cuda:0') tensor(-3.7531e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.044294
Average KL loss: 0.006396
Average total loss: 0.050690
tensor(0.0386, device='cuda:0') tensor(0.1011, device='cuda:0') tensor(-4.1943e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.044491
Average KL loss: 0.006388
Average total loss: 0.050878
tensor(0.0385, device='cuda:0') tensor(0.1010, device='cuda:0') tensor(-4.3402e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.041150
Average KL loss: 0.006380
Average total loss: 0.047529
tensor(0.0384, device='cuda:0') tensor(0.1009, device='cuda:0') tensor(-1.9766e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.042719
Average KL loss: 0.006372
Average total loss: 0.049091
tensor(0.0383, device='cuda:0') tensor(0.1008, device='cuda:0') tensor(-4.6015e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.042512
Average KL loss: 0.006364
Average total loss: 0.048876
tensor(0.0383, device='cuda:0') tensor(0.1007, device='cuda:0') tensor(-4.1118e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.045769
Average KL loss: 0.006357
Average total loss: 0.052126
tensor(0.0382, device='cuda:0') tensor(0.1006, device='cuda:0') tensor(-4.3194e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.042633
Average KL loss: 0.006350
Average total loss: 0.048983
tensor(0.0382, device='cuda:0') tensor(0.1005, device='cuda:0') tensor(-4.6249e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.042254
Average KL loss: 0.006344
Average total loss: 0.048598
tensor(0.0381, device='cuda:0') tensor(0.1005, device='cuda:0') tensor(-3.1375e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.043444
Average KL loss: 0.006337
Average total loss: 0.049781
tensor(0.0380, device='cuda:0') tensor(0.1004, device='cuda:0') tensor(-4.0535e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.044297
Average KL loss: 0.006331
Average total loss: 0.050628
tensor(0.0380, device='cuda:0') tensor(0.1003, device='cuda:0') tensor(-3.5672e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.043015
Average KL loss: 0.006325
Average total loss: 0.049340
tensor(0.0379, device='cuda:0') tensor(0.1003, device='cuda:0') tensor(-3.6231e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.041182
Average KL loss: 0.006320
Average total loss: 0.047502
tensor(0.0379, device='cuda:0') tensor(0.1002, device='cuda:0') tensor(-2.8673e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.042272
Average KL loss: 0.006314
Average total loss: 0.048586
tensor(0.0378, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-4.3853e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.043786
Average KL loss: 0.006309
Average total loss: 0.050094
tensor(0.0378, device='cuda:0') tensor(0.1001, device='cuda:0') tensor(-5.2095e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.043742
Average KL loss: 0.006304
Average total loss: 0.050046
tensor(0.0377, device='cuda:0') tensor(0.1000, device='cuda:0') tensor(-4.1432e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.042735
Average KL loss: 0.006299
Average total loss: 0.049034
tensor(0.0377, device='cuda:0') tensor(0.1000, device='cuda:0') tensor(-3.4161e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.040501
Average KL loss: 0.006294
Average total loss: 0.046796
tensor(0.0376, device='cuda:0') tensor(0.0999, device='cuda:0') tensor(-7.4948e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.042229
Average KL loss: 0.006289
Average total loss: 0.048518
tensor(0.0376, device='cuda:0') tensor(0.0999, device='cuda:0') tensor(-4.1913e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.041083
Average KL loss: 0.006285
Average total loss: 0.047368
tensor(0.0376, device='cuda:0') tensor(0.0998, device='cuda:0') tensor(-3.4864e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.041694
Average KL loss: 0.006281
Average total loss: 0.047974
tensor(0.0375, device='cuda:0') tensor(0.0998, device='cuda:0') tensor(-6.4109e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.042141
Average KL loss: 0.006276
Average total loss: 0.048417
tensor(0.0375, device='cuda:0') tensor(0.0997, device='cuda:0') tensor(-4.3620e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.040888
Average KL loss: 0.006272
Average total loss: 0.047160
tensor(0.0374, device='cuda:0') tensor(0.0997, device='cuda:0') tensor(-5.2797e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.040766
Average KL loss: 0.006268
Average total loss: 0.047034
tensor(0.0374, device='cuda:0') tensor(0.0996, device='cuda:0') tensor(-4.5132e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.040837
Average KL loss: 0.006264
Average total loss: 0.047101
tensor(0.0374, device='cuda:0') tensor(0.0996, device='cuda:0') tensor(-4.9809e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.041563
Average KL loss: 0.006261
Average total loss: 0.047824
tensor(0.0373, device='cuda:0') tensor(0.0996, device='cuda:0') tensor(-3.8560e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.042690
Average KL loss: 0.006257
Average total loss: 0.048947
tensor(0.0373, device='cuda:0') tensor(0.0995, device='cuda:0') tensor(-4.5098e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.040148
Average KL loss: 0.006254
Average total loss: 0.046402
tensor(0.0373, device='cuda:0') tensor(0.0995, device='cuda:0') tensor(-4.6064e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.040718
Average KL loss: 0.006250
Average total loss: 0.046969
tensor(0.0372, device='cuda:0') tensor(0.0995, device='cuda:0') tensor(-3.3680e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.040755
Average KL loss: 0.006247
Average total loss: 0.047002
tensor(0.0372, device='cuda:0') tensor(0.0994, device='cuda:0') tensor(-4.4952e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.041301
Average KL loss: 0.006244
Average total loss: 0.047545
tensor(0.0372, device='cuda:0') tensor(0.0994, device='cuda:0') tensor(-5.0733e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.040053
Average KL loss: 0.006241
Average total loss: 0.046294
tensor(0.0372, device='cuda:0') tensor(0.0994, device='cuda:0') tensor(-6.7147e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.041869
Average KL loss: 0.006238
Average total loss: 0.048107
tensor(0.0371, device='cuda:0') tensor(0.0994, device='cuda:0') tensor(-3.2660e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.037633
Average KL loss: 0.006235
Average total loss: 0.043868
tensor(0.0371, device='cuda:0') tensor(0.0993, device='cuda:0') tensor(-4.8634e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.042081
Average KL loss: 0.006232
Average total loss: 0.048313
tensor(0.0371, device='cuda:0') tensor(0.0993, device='cuda:0') tensor(-4.0351e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.040452
Average KL loss: 0.006230
Average total loss: 0.046681
tensor(0.0371, device='cuda:0') tensor(0.0993, device='cuda:0') tensor(-4.1785e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.039763
Average KL loss: 0.006227
Average total loss: 0.045991
tensor(0.0370, device='cuda:0') tensor(0.0993, device='cuda:0') tensor(-2.7977e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.040645
Average KL loss: 0.006225
Average total loss: 0.046870
tensor(0.0370, device='cuda:0') tensor(0.0992, device='cuda:0') tensor(-3.3871e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.039034
Average KL loss: 0.006222
Average total loss: 0.045256
tensor(0.0370, device='cuda:0') tensor(0.0992, device='cuda:0') tensor(-2.3003e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.039039
Average KL loss: 0.006220
Average total loss: 0.045259
tensor(0.0370, device='cuda:0') tensor(0.0992, device='cuda:0') tensor(-2.8065e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.039183
Average KL loss: 0.006218
Average total loss: 0.045401
tensor(0.0370, device='cuda:0') tensor(0.0992, device='cuda:0') tensor(-2.7427e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.037909
Average KL loss: 0.006216
Average total loss: 0.044125
tensor(0.0369, device='cuda:0') tensor(0.0992, device='cuda:0') tensor(-2.0170e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.037798
Average KL loss: 0.006214
Average total loss: 0.044012
tensor(0.0369, device='cuda:0') tensor(0.0992, device='cuda:0') tensor(-3.7328e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.038984
Average KL loss: 0.006212
Average total loss: 0.045196
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-2.6180e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.038594
Average KL loss: 0.006210
Average total loss: 0.044803
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-2.1639e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.037494
Average KL loss: 0.006208
Average total loss: 0.043703
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-5.9857e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.038428
Average KL loss: 0.006208
Average total loss: 0.044637
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-5.0594e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.039415
Average KL loss: 0.006208
Average total loss: 0.045623
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-2.8152e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.039431
Average KL loss: 0.006208
Average total loss: 0.045639
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-4.6239e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.038074
Average KL loss: 0.006208
Average total loss: 0.044282
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-2.8388e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.038400
Average KL loss: 0.006208
Average total loss: 0.044607
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-2.5816e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.040762
Average KL loss: 0.006207
Average total loss: 0.046969
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-3.6103e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.038187
Average KL loss: 0.006207
Average total loss: 0.044394
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-3.6344e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.039022
Average KL loss: 0.006207
Average total loss: 0.045229
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-2.6453e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.037771
Average KL loss: 0.006207
Average total loss: 0.043978
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-3.2904e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.040483
Average KL loss: 0.006207
Average total loss: 0.046689
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-3.9597e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.038279
Average KL loss: 0.006207
Average total loss: 0.044486
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-4.4815e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.039968
Average KL loss: 0.006206
Average total loss: 0.046174
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-3.4036e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.039121
Average KL loss: 0.006206
Average total loss: 0.045327
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-3.7412e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.037353
Average KL loss: 0.006206
Average total loss: 0.043560
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-3.0073e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.039559
Average KL loss: 0.006206
Average total loss: 0.045766
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-4.1954e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.038121
Average KL loss: 0.006206
Average total loss: 0.044327
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-5.5466e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.038249
Average KL loss: 0.006206
Average total loss: 0.044455
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-3.7605e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.038721
Average KL loss: 0.006206
Average total loss: 0.044927
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-3.0465e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.038483
Average KL loss: 0.006206
Average total loss: 0.044689
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-4.8499e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.039674
Average KL loss: 0.006206
Average total loss: 0.045880
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-5.0296e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.037902
Average KL loss: 0.006206
Average total loss: 0.044109
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-3.5750e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.039287
Average KL loss: 0.006206
Average total loss: 0.045493
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-4.6259e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.038855
Average KL loss: 0.006206
Average total loss: 0.045061
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-4.3722e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.039031
Average KL loss: 0.006206
Average total loss: 0.045237
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-3.9347e-09, device='cuda:0')
 Percentile value: 1.5688411235809325
Non-zero model percentage: 1.4411613941192627%, Non-zero mask percentage: 1.4411613941192627%

--- Pruning Level [19/24]: ---
conv1.weight         | nonzeros =     160 /    1728             (  9.26%) | total_pruned =    1568 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      57 /   36864             (  0.15%) | total_pruned =   36807 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      75 /   36864             (  0.20%) | total_pruned =   36789 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     349 /   36864             (  0.95%) | total_pruned =   36515 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     830 /   36864             (  2.25%) | total_pruned =   36034 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2834 /   73728             (  3.84%) | total_pruned =   70894 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    6685 /  147456             (  4.53%) | total_pruned =  140771 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     812 /    8192             (  9.91%) | total_pruned =    7380 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3465 /  147456             (  2.35%) | total_pruned =  143991 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3451 /  147456             (  2.34%) | total_pruned =  144005 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   13953 /  294912             (  4.73%) | total_pruned =  280959 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     224 /     256             ( 87.50%) | total_pruned =      32 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   19820 /  589824             (  3.36%) | total_pruned =  570004 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     189 /     256             ( 73.83%) | total_pruned =      67 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2384 /   32768             (  7.28%) | total_pruned =   30384 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     154 /     256             ( 60.16%) | total_pruned =     102 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    8955 /  589824             (  1.52%) | total_pruned =  580869 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     144 /     256             ( 56.25%) | total_pruned =     112 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    7240 /  589824             (  1.23%) | total_pruned =  582584 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   25278 / 1179648             (  2.14%) | total_pruned = 1154370 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     358 /     512             ( 69.92%) | total_pruned =     154 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   23916 / 2359296             (  1.01%) | total_pruned = 2335380 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     327 /     512             ( 63.87%) | total_pruned =     185 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     170 /     512             ( 33.20%) | total_pruned =     342 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     865 /  131072             (  0.66%) | total_pruned =  130207 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     110 /     512             ( 21.48%) | total_pruned =     402 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     172 /     512             ( 33.59%) | total_pruned =     340 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   13502 / 2359296             (  0.57%) | total_pruned = 2345794 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     223 /     512             ( 43.55%) | total_pruned =     289 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   20752 / 2359296             (  0.88%) | total_pruned = 2338544 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     332 /     512             ( 64.84%) | total_pruned =     180 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     264 /     512             ( 51.56%) | total_pruned =     248 | shape = torch.Size([512])
linear.weight        | nonzeros =    2367 /    5120             ( 46.23%) | total_pruned =    2753 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 161104, pruned : 11017658, total: 11178762, Compression rate :      69.39x  ( 98.56% pruned)
Train Epoch: 51/100 Loss: 0.045195 Accuracy: 84.25 99.99 % Best test Accuracy: 84.71%
tensor(0.0369, device='cuda:0') tensor(0.0991, device='cuda:0') tensor(-2.2860e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.226489
Average KL loss: 0.006188
Average total loss: 0.232676
tensor(0.0367, device='cuda:0') tensor(0.0986, device='cuda:0') tensor(-2.8303e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.235741
Average KL loss: 0.006158
Average total loss: 0.241898
tensor(0.0365, device='cuda:0') tensor(0.0981, device='cuda:0') tensor(-2.7480e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.231062
Average KL loss: 0.006128
Average total loss: 0.237190
tensor(0.0364, device='cuda:0') tensor(0.0977, device='cuda:0') tensor(-2.9756e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.235286
Average KL loss: 0.006100
Average total loss: 0.241385
tensor(0.0362, device='cuda:0') tensor(0.0973, device='cuda:0') tensor(-3.3349e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.233005
Average KL loss: 0.006071
Average total loss: 0.239076
tensor(0.0361, device='cuda:0') tensor(0.0969, device='cuda:0') tensor(-3.4684e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.230985
Average KL loss: 0.006043
Average total loss: 0.237029
tensor(0.0360, device='cuda:0') tensor(0.0965, device='cuda:0') tensor(-3.2708e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.222133
Average KL loss: 0.006016
Average total loss: 0.228149
tensor(0.0358, device='cuda:0') tensor(0.0962, device='cuda:0') tensor(-2.4402e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.218871
Average KL loss: 0.005989
Average total loss: 0.224860
tensor(0.0357, device='cuda:0') tensor(0.0958, device='cuda:0') tensor(-1.8118e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.220632
Average KL loss: 0.005963
Average total loss: 0.226595
tensor(0.0355, device='cuda:0') tensor(0.0954, device='cuda:0') tensor(-2.4598e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.224409
Average KL loss: 0.005937
Average total loss: 0.230346
tensor(0.0354, device='cuda:0') tensor(0.0951, device='cuda:0') tensor(-2.2636e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.211857
Average KL loss: 0.005912
Average total loss: 0.217768
tensor(0.0353, device='cuda:0') tensor(0.0948, device='cuda:0') tensor(-3.9888e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.220441
Average KL loss: 0.005887
Average total loss: 0.226328
tensor(0.0352, device='cuda:0') tensor(0.0945, device='cuda:0') tensor(-2.3733e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.215943
Average KL loss: 0.005863
Average total loss: 0.221805
tensor(0.0350, device='cuda:0') tensor(0.0941, device='cuda:0') tensor(-2.5090e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.214528
Average KL loss: 0.005839
Average total loss: 0.220367
tensor(0.0349, device='cuda:0') tensor(0.0938, device='cuda:0') tensor(-2.1876e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.209152
Average KL loss: 0.005816
Average total loss: 0.214968
tensor(0.0348, device='cuda:0') tensor(0.0935, device='cuda:0') tensor(-2.2139e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.214851
Average KL loss: 0.005793
Average total loss: 0.220644
tensor(0.0346, device='cuda:0') tensor(0.0933, device='cuda:0') tensor(-2.5437e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.210899
Average KL loss: 0.005771
Average total loss: 0.216670
tensor(0.0345, device='cuda:0') tensor(0.0930, device='cuda:0') tensor(-1.8422e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.212771
Average KL loss: 0.005749
Average total loss: 0.218520
tensor(0.0344, device='cuda:0') tensor(0.0927, device='cuda:0') tensor(-2.7831e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.205594
Average KL loss: 0.005728
Average total loss: 0.211323
tensor(0.0343, device='cuda:0') tensor(0.0924, device='cuda:0') tensor(-2.3894e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.207566
Average KL loss: 0.005708
Average total loss: 0.213274
tensor(0.0342, device='cuda:0') tensor(0.0922, device='cuda:0') tensor(-2.6609e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.204127
Average KL loss: 0.005688
Average total loss: 0.209816
tensor(0.0341, device='cuda:0') tensor(0.0919, device='cuda:0') tensor(-2.4879e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.212175
Average KL loss: 0.005669
Average total loss: 0.217844
tensor(0.0339, device='cuda:0') tensor(0.0917, device='cuda:0') tensor(-2.1143e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.201767
Average KL loss: 0.005650
Average total loss: 0.207417
tensor(0.0338, device='cuda:0') tensor(0.0915, device='cuda:0') tensor(-2.1420e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.200467
Average KL loss: 0.005632
Average total loss: 0.206100
tensor(0.0337, device='cuda:0') tensor(0.0912, device='cuda:0') tensor(-2.2206e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.202473
Average KL loss: 0.005615
Average total loss: 0.208087
tensor(0.0336, device='cuda:0') tensor(0.0910, device='cuda:0') tensor(-2.4286e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.198375
Average KL loss: 0.005598
Average total loss: 0.203972
tensor(0.0335, device='cuda:0') tensor(0.0908, device='cuda:0') tensor(-2.1352e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.203527
Average KL loss: 0.005581
Average total loss: 0.209109
tensor(0.0334, device='cuda:0') tensor(0.0906, device='cuda:0') tensor(-2.5180e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.201111
Average KL loss: 0.005565
Average total loss: 0.206676
tensor(0.0333, device='cuda:0') tensor(0.0904, device='cuda:0') tensor(-1.7097e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.196508
Average KL loss: 0.005550
Average total loss: 0.202058
tensor(0.0332, device='cuda:0') tensor(0.0902, device='cuda:0') tensor(-1.9890e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.191346
Average KL loss: 0.005535
Average total loss: 0.196881
tensor(0.0331, device='cuda:0') tensor(0.0900, device='cuda:0') tensor(-2.0210e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.199650
Average KL loss: 0.005520
Average total loss: 0.205171
tensor(0.0330, device='cuda:0') tensor(0.0898, device='cuda:0') tensor(-1.8781e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.197857
Average KL loss: 0.005506
Average total loss: 0.203363
tensor(0.0329, device='cuda:0') tensor(0.0897, device='cuda:0') tensor(-2.0815e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.197054
Average KL loss: 0.005493
Average total loss: 0.202547
tensor(0.0328, device='cuda:0') tensor(0.0895, device='cuda:0') tensor(-2.1620e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.198799
Average KL loss: 0.005480
Average total loss: 0.204279
tensor(0.0328, device='cuda:0') tensor(0.0893, device='cuda:0') tensor(-2.0587e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.193634
Average KL loss: 0.005467
Average total loss: 0.199101
tensor(0.0327, device='cuda:0') tensor(0.0892, device='cuda:0') tensor(-2.3904e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.195259
Average KL loss: 0.005454
Average total loss: 0.200713
tensor(0.0326, device='cuda:0') tensor(0.0890, device='cuda:0') tensor(-2.2649e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.186511
Average KL loss: 0.005443
Average total loss: 0.191954
tensor(0.0325, device='cuda:0') tensor(0.0889, device='cuda:0') tensor(-2.3237e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.188589
Average KL loss: 0.005431
Average total loss: 0.194020
tensor(0.0324, device='cuda:0') tensor(0.0887, device='cuda:0') tensor(-1.8436e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.186348
Average KL loss: 0.005420
Average total loss: 0.191768
tensor(0.0323, device='cuda:0') tensor(0.0886, device='cuda:0') tensor(-1.8820e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.189146
Average KL loss: 0.005409
Average total loss: 0.194555
tensor(0.0323, device='cuda:0') tensor(0.0885, device='cuda:0') tensor(-3.1471e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.183224
Average KL loss: 0.005399
Average total loss: 0.188623
tensor(0.0322, device='cuda:0') tensor(0.0883, device='cuda:0') tensor(-1.6146e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.185373
Average KL loss: 0.005389
Average total loss: 0.190761
tensor(0.0321, device='cuda:0') tensor(0.0882, device='cuda:0') tensor(-2.3851e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.186593
Average KL loss: 0.005379
Average total loss: 0.191972
tensor(0.0320, device='cuda:0') tensor(0.0881, device='cuda:0') tensor(-1.9744e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.181596
Average KL loss: 0.005369
Average total loss: 0.186965
tensor(0.0320, device='cuda:0') tensor(0.0880, device='cuda:0') tensor(-2.0788e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.184379
Average KL loss: 0.005360
Average total loss: 0.189739
tensor(0.0319, device='cuda:0') tensor(0.0879, device='cuda:0') tensor(-1.8699e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.176275
Average KL loss: 0.005351
Average total loss: 0.181626
tensor(0.0318, device='cuda:0') tensor(0.0878, device='cuda:0') tensor(-1.8088e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.176718
Average KL loss: 0.005343
Average total loss: 0.182061
tensor(0.0318, device='cuda:0') tensor(0.0877, device='cuda:0') tensor(-2.3128e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.178309
Average KL loss: 0.005335
Average total loss: 0.183644
tensor(0.0317, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-2.5211e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.177989
Average KL loss: 0.005327
Average total loss: 0.183316
tensor(0.0316, device='cuda:0') tensor(0.0875, device='cuda:0') tensor(-1.9633e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.171602
Average KL loss: 0.005319
Average total loss: 0.176921
tensor(0.0316, device='cuda:0') tensor(0.0874, device='cuda:0') tensor(-3.5149e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.179772
Average KL loss: 0.005311
Average total loss: 0.185083
tensor(0.0315, device='cuda:0') tensor(0.0873, device='cuda:0') tensor(-1.8071e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.186868
Average KL loss: 0.005304
Average total loss: 0.192173
tensor(0.0315, device='cuda:0') tensor(0.0872, device='cuda:0') tensor(-1.4815e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.182323
Average KL loss: 0.005297
Average total loss: 0.187620
tensor(0.0314, device='cuda:0') tensor(0.0871, device='cuda:0') tensor(-1.7551e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.169842
Average KL loss: 0.005290
Average total loss: 0.175133
tensor(0.0314, device='cuda:0') tensor(0.0870, device='cuda:0') tensor(-2.5189e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.177259
Average KL loss: 0.005284
Average total loss: 0.182543
tensor(0.0313, device='cuda:0') tensor(0.0869, device='cuda:0') tensor(-4.8836e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.170168
Average KL loss: 0.005278
Average total loss: 0.175446
tensor(0.0313, device='cuda:0') tensor(0.0869, device='cuda:0') tensor(-1.9831e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.173085
Average KL loss: 0.005272
Average total loss: 0.178357
tensor(0.0312, device='cuda:0') tensor(0.0868, device='cuda:0') tensor(-1.9304e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.163720
Average KL loss: 0.005266
Average total loss: 0.168986
tensor(0.0312, device='cuda:0') tensor(0.0867, device='cuda:0') tensor(-1.6041e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.169595
Average KL loss: 0.005260
Average total loss: 0.174855
tensor(0.0311, device='cuda:0') tensor(0.0866, device='cuda:0') tensor(-1.7515e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.168236
Average KL loss: 0.005255
Average total loss: 0.173491
tensor(0.0311, device='cuda:0') tensor(0.0866, device='cuda:0') tensor(-2.4605e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.165255
Average KL loss: 0.005249
Average total loss: 0.170504
tensor(0.0310, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(-1.8345e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.165850
Average KL loss: 0.005244
Average total loss: 0.171095
tensor(0.0310, device='cuda:0') tensor(0.0865, device='cuda:0') tensor(-2.4217e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.165640
Average KL loss: 0.005239
Average total loss: 0.170879
tensor(0.0309, device='cuda:0') tensor(0.0864, device='cuda:0') tensor(-2.1879e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.173488
Average KL loss: 0.005235
Average total loss: 0.178723
tensor(0.0309, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(-2.0247e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.164338
Average KL loss: 0.005230
Average total loss: 0.169568
tensor(0.0309, device='cuda:0') tensor(0.0863, device='cuda:0') tensor(-1.5340e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.161359
Average KL loss: 0.005226
Average total loss: 0.166584
tensor(0.0308, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-1.8396e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.164597
Average KL loss: 0.005221
Average total loss: 0.169818
tensor(0.0308, device='cuda:0') tensor(0.0862, device='cuda:0') tensor(-1.6037e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.166782
Average KL loss: 0.005217
Average total loss: 0.171999
tensor(0.0307, device='cuda:0') tensor(0.0861, device='cuda:0') tensor(-1.7543e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.163390
Average KL loss: 0.005213
Average total loss: 0.168604
tensor(0.0307, device='cuda:0') tensor(0.0861, device='cuda:0') tensor(-1.6082e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.162023
Average KL loss: 0.005209
Average total loss: 0.167232
tensor(0.0307, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(-1.8743e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.163747
Average KL loss: 0.005205
Average total loss: 0.168952
tensor(0.0306, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(-1.5745e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.166764
Average KL loss: 0.005202
Average total loss: 0.171965
tensor(0.0306, device='cuda:0') tensor(0.0860, device='cuda:0') tensor(-1.7817e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.166495
Average KL loss: 0.005198
Average total loss: 0.171693
tensor(0.0306, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(-1.5318e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.168466
Average KL loss: 0.005195
Average total loss: 0.173662
tensor(0.0306, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(-1.5013e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.153659
Average KL loss: 0.005192
Average total loss: 0.158851
tensor(0.0305, device='cuda:0') tensor(0.0859, device='cuda:0') tensor(-1.4827e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.160007
Average KL loss: 0.005189
Average total loss: 0.165195
tensor(0.0305, device='cuda:0') tensor(0.0858, device='cuda:0') tensor(-1.5405e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.160107
Average KL loss: 0.005186
Average total loss: 0.165293
tensor(0.0305, device='cuda:0') tensor(0.0858, device='cuda:0') tensor(-1.7505e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.156133
Average KL loss: 0.005183
Average total loss: 0.161316
tensor(0.0304, device='cuda:0') tensor(0.0858, device='cuda:0') tensor(-2.0580e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.156470
Average KL loss: 0.005180
Average total loss: 0.161649
tensor(0.0304, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-1.6367e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.156331
Average KL loss: 0.005177
Average total loss: 0.161509
tensor(0.0304, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-1.6936e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.158779
Average KL loss: 0.005175
Average total loss: 0.163954
tensor(0.0304, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-2.1747e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.154017
Average KL loss: 0.005172
Average total loss: 0.159190
tensor(0.0304, device='cuda:0') tensor(0.0857, device='cuda:0') tensor(-1.4550e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.156885
Average KL loss: 0.005170
Average total loss: 0.162055
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.7065e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.155607
Average KL loss: 0.005168
Average total loss: 0.160774
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.9622e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.154364
Average KL loss: 0.005166
Average total loss: 0.159529
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.8764e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.157085
Average KL loss: 0.005163
Average total loss: 0.162249
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.5800e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.152307
Average KL loss: 0.005162
Average total loss: 0.157469
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.8893e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.150826
Average KL loss: 0.005162
Average total loss: 0.155988
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.5564e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.157606
Average KL loss: 0.005162
Average total loss: 0.162768
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.5323e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.153443
Average KL loss: 0.005162
Average total loss: 0.158605
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.5810e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.151058
Average KL loss: 0.005162
Average total loss: 0.156219
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.3411e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.151465
Average KL loss: 0.005161
Average total loss: 0.156626
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-2.1962e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.157164
Average KL loss: 0.005161
Average total loss: 0.162325
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-2.3531e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.154729
Average KL loss: 0.005161
Average total loss: 0.159890
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.5139e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.151747
Average KL loss: 0.005161
Average total loss: 0.156908
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.8095e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.155188
Average KL loss: 0.005161
Average total loss: 0.160348
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.6483e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.153738
Average KL loss: 0.005161
Average total loss: 0.158898
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-2.0232e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.157626
Average KL loss: 0.005160
Average total loss: 0.162786
tensor(0.0303, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.4132e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.151123
Average KL loss: 0.005160
Average total loss: 0.156283
tensor(0.0302, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.5178e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.155756
Average KL loss: 0.005160
Average total loss: 0.160916
tensor(0.0302, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.9613e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.151944
Average KL loss: 0.005160
Average total loss: 0.157104
tensor(0.0302, device='cuda:0') tensor(0.0856, device='cuda:0') tensor(-1.4104e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.154683
Average KL loss: 0.005160
Average total loss: 0.159843
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.6347e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.150329
Average KL loss: 0.005160
Average total loss: 0.155489
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-2.2889e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.156010
Average KL loss: 0.005160
Average total loss: 0.161170
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.5248e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.150739
Average KL loss: 0.005160
Average total loss: 0.155899
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.8691e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.160654
Average KL loss: 0.005160
Average total loss: 0.165814
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.8047e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.155829
Average KL loss: 0.005160
Average total loss: 0.160989
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.7917e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.162641
Average KL loss: 0.005160
Average total loss: 0.167801
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.7691e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.154370
Average KL loss: 0.005160
Average total loss: 0.159529
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.5425e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.152439
Average KL loss: 0.005160
Average total loss: 0.157599
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.8240e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.154154
Average KL loss: 0.005160
Average total loss: 0.159314
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.7293e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.151562
Average KL loss: 0.005160
Average total loss: 0.156722
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.5352e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.147426
Average KL loss: 0.005160
Average total loss: 0.152585
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.6348e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.153221
Average KL loss: 0.005160
Average total loss: 0.158380
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.4275e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.156025
Average KL loss: 0.005160
Average total loss: 0.161185
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.7074e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.150640
Average KL loss: 0.005160
Average total loss: 0.155799
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.6658e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.149429
Average KL loss: 0.005160
Average total loss: 0.154589
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.8422e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.152679
Average KL loss: 0.005160
Average total loss: 0.157839
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.6299e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.160253
Average KL loss: 0.005160
Average total loss: 0.165413
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.7405e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.154788
Average KL loss: 0.005160
Average total loss: 0.159948
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.6040e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.153405
Average KL loss: 0.005160
Average total loss: 0.158565
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.6049e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.154781
Average KL loss: 0.005160
Average total loss: 0.159940
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.3267e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.152288
Average KL loss: 0.005160
Average total loss: 0.157448
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-2.2960e-08, device='cuda:0')
 Percentile value: 1.71578369140625
Non-zero model percentage: 1.1529362201690674%, Non-zero mask percentage: 1.1529362201690674%

--- Pruning Level [20/24]: ---
conv1.weight         | nonzeros =     158 /    1728             (  9.14%) | total_pruned =    1570 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      51 /   36864             (  0.14%) | total_pruned =   36813 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      69 /   36864             (  0.19%) | total_pruned =   36795 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     305 /   36864             (  0.83%) | total_pruned =   36559 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     741 /   36864             (  2.01%) | total_pruned =   36123 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2607 /   73728             (  3.54%) | total_pruned =   71121 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    5992 /  147456             (  4.06%) | total_pruned =  141464 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     729 /    8192             (  8.90%) | total_pruned =    7463 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3133 /  147456             (  2.12%) | total_pruned =  144323 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3145 /  147456             (  2.13%) | total_pruned =  144311 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   12335 /  294912             (  4.18%) | total_pruned =  282577 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     219 /     256             ( 85.55%) | total_pruned =      37 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   17622 /  589824             (  2.99%) | total_pruned =  572202 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     187 /     256             ( 73.05%) | total_pruned =      69 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2065 /   32768             (  6.30%) | total_pruned =   30703 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     147 /     256             ( 57.42%) | total_pruned =     109 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    7831 /  589824             (  1.33%) | total_pruned =  581993 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    6261 /  589824             (  1.06%) | total_pruned =  583563 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     130 /     256             ( 50.78%) | total_pruned =     126 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   21568 / 1179648             (  1.83%) | total_pruned = 1158080 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     351 /     512             ( 68.55%) | total_pruned =     161 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   17007 / 2359296             (  0.72%) | total_pruned = 2342289 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     308 /     512             ( 60.16%) | total_pruned =     204 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     159 /     512             ( 31.05%) | total_pruned =     353 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     603 /  131072             (  0.46%) | total_pruned =  130469 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     100 /     512             ( 19.53%) | total_pruned =     412 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     162 /     512             ( 31.64%) | total_pruned =     350 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    8815 / 2359296             (  0.37%) | total_pruned = 2350481 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     214 /     512             ( 41.80%) | total_pruned =     298 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   12466 / 2359296             (  0.53%) | total_pruned = 2346830 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     318 /     512             ( 62.11%) | total_pruned =     194 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     237 /     512             ( 46.29%) | total_pruned =     275 | shape = torch.Size([512])
linear.weight        | nonzeros =    2185 /    5120             ( 42.68%) | total_pruned =    2935 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 128884, pruned : 11049878, total: 11178762, Compression rate :      86.74x  ( 98.85% pruned)
Train Epoch: 54/100 Loss: 0.027209 Accuracy: 85.55 100.00 % Best test Accuracy: 85.78%
tensor(0.0302, device='cuda:0') tensor(0.0855, device='cuda:0') tensor(-1.3794e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.139416
Average KL loss: 0.005149
Average total loss: 0.144565
tensor(0.0301, device='cuda:0') tensor(0.0852, device='cuda:0') tensor(-1.3266e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.135760
Average KL loss: 0.005133
Average total loss: 0.140893
tensor(0.0301, device='cuda:0') tensor(0.0850, device='cuda:0') tensor(-1.2912e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.139012
Average KL loss: 0.005118
Average total loss: 0.144130
tensor(0.0300, device='cuda:0') tensor(0.0847, device='cuda:0') tensor(-1.3601e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.134498
Average KL loss: 0.005104
Average total loss: 0.139601
tensor(0.0299, device='cuda:0') tensor(0.0845, device='cuda:0') tensor(-1.7573e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.131490
Average KL loss: 0.005089
Average total loss: 0.136579
tensor(0.0298, device='cuda:0') tensor(0.0843, device='cuda:0') tensor(-1.3540e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.137800
Average KL loss: 0.005075
Average total loss: 0.142875
tensor(0.0297, device='cuda:0') tensor(0.0841, device='cuda:0') tensor(-1.5910e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.133152
Average KL loss: 0.005061
Average total loss: 0.138214
tensor(0.0297, device='cuda:0') tensor(0.0839, device='cuda:0') tensor(-1.9376e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.133045
Average KL loss: 0.005047
Average total loss: 0.138093
tensor(0.0296, device='cuda:0') tensor(0.0837, device='cuda:0') tensor(-1.3037e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.130485
Average KL loss: 0.005034
Average total loss: 0.135519
tensor(0.0295, device='cuda:0') tensor(0.0836, device='cuda:0') tensor(-1.7522e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.138001
Average KL loss: 0.005021
Average total loss: 0.143022
tensor(0.0294, device='cuda:0') tensor(0.0834, device='cuda:0') tensor(-1.6585e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.129080
Average KL loss: 0.005008
Average total loss: 0.134088
tensor(0.0294, device='cuda:0') tensor(0.0832, device='cuda:0') tensor(-1.4218e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.132766
Average KL loss: 0.004995
Average total loss: 0.137762
tensor(0.0293, device='cuda:0') tensor(0.0830, device='cuda:0') tensor(-1.7507e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.129165
Average KL loss: 0.004983
Average total loss: 0.134148
tensor(0.0292, device='cuda:0') tensor(0.0829, device='cuda:0') tensor(-1.3928e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.133460
Average KL loss: 0.004971
Average total loss: 0.138431
tensor(0.0292, device='cuda:0') tensor(0.0827, device='cuda:0') tensor(-1.7132e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.131913
Average KL loss: 0.004959
Average total loss: 0.136872
tensor(0.0291, device='cuda:0') tensor(0.0826, device='cuda:0') tensor(-1.7139e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.125591
Average KL loss: 0.004948
Average total loss: 0.130539
tensor(0.0290, device='cuda:0') tensor(0.0824, device='cuda:0') tensor(-2.2925e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.130562
Average KL loss: 0.004936
Average total loss: 0.135498
tensor(0.0290, device='cuda:0') tensor(0.0823, device='cuda:0') tensor(-1.0464e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.127600
Average KL loss: 0.004925
Average total loss: 0.132526
tensor(0.0289, device='cuda:0') tensor(0.0821, device='cuda:0') tensor(-1.1571e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.124891
Average KL loss: 0.004914
Average total loss: 0.129806
tensor(0.0289, device='cuda:0') tensor(0.0820, device='cuda:0') tensor(-1.2553e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.124893
Average KL loss: 0.004904
Average total loss: 0.129797
tensor(0.0288, device='cuda:0') tensor(0.0819, device='cuda:0') tensor(-1.3244e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.127482
Average KL loss: 0.004894
Average total loss: 0.132375
tensor(0.0287, device='cuda:0') tensor(0.0817, device='cuda:0') tensor(-1.7095e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.122606
Average KL loss: 0.004884
Average total loss: 0.127490
tensor(0.0287, device='cuda:0') tensor(0.0816, device='cuda:0') tensor(-1.2330e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.124112
Average KL loss: 0.004874
Average total loss: 0.128986
tensor(0.0286, device='cuda:0') tensor(0.0815, device='cuda:0') tensor(-1.2476e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.124835
Average KL loss: 0.004865
Average total loss: 0.129700
tensor(0.0286, device='cuda:0') tensor(0.0814, device='cuda:0') tensor(-1.5553e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.126753
Average KL loss: 0.004856
Average total loss: 0.131609
tensor(0.0285, device='cuda:0') tensor(0.0813, device='cuda:0') tensor(-1.3675e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.121229
Average KL loss: 0.004847
Average total loss: 0.126076
tensor(0.0285, device='cuda:0') tensor(0.0812, device='cuda:0') tensor(-1.4121e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.118782
Average KL loss: 0.004839
Average total loss: 0.123620
tensor(0.0284, device='cuda:0') tensor(0.0810, device='cuda:0') tensor(-1.2787e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.121555
Average KL loss: 0.004830
Average total loss: 0.126385
tensor(0.0283, device='cuda:0') tensor(0.0809, device='cuda:0') tensor(-1.1321e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.122688
Average KL loss: 0.004822
Average total loss: 0.127510
tensor(0.0283, device='cuda:0') tensor(0.0808, device='cuda:0') tensor(-1.2096e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.122038
Average KL loss: 0.004814
Average total loss: 0.126853
tensor(0.0282, device='cuda:0') tensor(0.0807, device='cuda:0') tensor(-1.1551e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.117592
Average KL loss: 0.004807
Average total loss: 0.122399
tensor(0.0282, device='cuda:0') tensor(0.0807, device='cuda:0') tensor(-1.4404e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.118624
Average KL loss: 0.004800
Average total loss: 0.123424
tensor(0.0281, device='cuda:0') tensor(0.0806, device='cuda:0') tensor(-9.8926e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.124507
Average KL loss: 0.004793
Average total loss: 0.129299
tensor(0.0281, device='cuda:0') tensor(0.0805, device='cuda:0') tensor(-1.1564e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.118845
Average KL loss: 0.004786
Average total loss: 0.123631
tensor(0.0281, device='cuda:0') tensor(0.0804, device='cuda:0') tensor(-1.2095e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.120291
Average KL loss: 0.004779
Average total loss: 0.125070
tensor(0.0280, device='cuda:0') tensor(0.0803, device='cuda:0') tensor(-1.5969e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.116420
Average KL loss: 0.004773
Average total loss: 0.121193
tensor(0.0280, device='cuda:0') tensor(0.0802, device='cuda:0') tensor(-1.1658e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.110134
Average KL loss: 0.004767
Average total loss: 0.114901
tensor(0.0279, device='cuda:0') tensor(0.0802, device='cuda:0') tensor(-1.2619e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.118106
Average KL loss: 0.004761
Average total loss: 0.122867
tensor(0.0279, device='cuda:0') tensor(0.0801, device='cuda:0') tensor(-1.0070e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.122632
Average KL loss: 0.004755
Average total loss: 0.127387
tensor(0.0278, device='cuda:0') tensor(0.0800, device='cuda:0') tensor(-1.5774e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.115554
Average KL loss: 0.004750
Average total loss: 0.120304
tensor(0.0278, device='cuda:0') tensor(0.0800, device='cuda:0') tensor(-1.1973e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.115669
Average KL loss: 0.004744
Average total loss: 0.120413
tensor(0.0278, device='cuda:0') tensor(0.0799, device='cuda:0') tensor(-1.7483e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.114695
Average KL loss: 0.004739
Average total loss: 0.119434
tensor(0.0277, device='cuda:0') tensor(0.0798, device='cuda:0') tensor(-1.3891e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.114874
Average KL loss: 0.004734
Average total loss: 0.119608
tensor(0.0277, device='cuda:0') tensor(0.0798, device='cuda:0') tensor(-9.2487e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.112870
Average KL loss: 0.004729
Average total loss: 0.117599
tensor(0.0277, device='cuda:0') tensor(0.0797, device='cuda:0') tensor(-1.0225e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.115892
Average KL loss: 0.004725
Average total loss: 0.120617
tensor(0.0276, device='cuda:0') tensor(0.0797, device='cuda:0') tensor(-1.1689e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.113858
Average KL loss: 0.004720
Average total loss: 0.118579
tensor(0.0276, device='cuda:0') tensor(0.0796, device='cuda:0') tensor(-1.1219e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.110967
Average KL loss: 0.004716
Average total loss: 0.115683
tensor(0.0275, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(-1.1795e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.111736
Average KL loss: 0.004712
Average total loss: 0.116448
tensor(0.0275, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(-9.0548e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.111056
Average KL loss: 0.004710
Average total loss: 0.115766
tensor(0.0275, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(-1.4041e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.111550
Average KL loss: 0.004709
Average total loss: 0.116259
tensor(0.0275, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(-1.0091e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.109711
Average KL loss: 0.004709
Average total loss: 0.114420
tensor(0.0275, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(-1.1638e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.110010
Average KL loss: 0.004708
Average total loss: 0.114718
tensor(0.0275, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(-1.3300e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.113185
Average KL loss: 0.004708
Average total loss: 0.117893
tensor(0.0275, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(-1.1352e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.111438
Average KL loss: 0.004708
Average total loss: 0.116146
tensor(0.0275, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(-1.1641e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.113711
Average KL loss: 0.004707
Average total loss: 0.118419
tensor(0.0275, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(-9.4582e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.111153
Average KL loss: 0.004707
Average total loss: 0.115860
tensor(0.0275, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(-1.6536e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.109947
Average KL loss: 0.004707
Average total loss: 0.114653
tensor(0.0275, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(-1.3622e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.111375
Average KL loss: 0.004706
Average total loss: 0.116081
tensor(0.0275, device='cuda:0') tensor(0.0795, device='cuda:0') tensor(-9.2445e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.112860
Average KL loss: 0.004706
Average total loss: 0.117566
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.5853e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.111522
Average KL loss: 0.004705
Average total loss: 0.116227
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.2056e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.111194
Average KL loss: 0.004705
Average total loss: 0.115899
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-8.7360e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.114078
Average KL loss: 0.004705
Average total loss: 0.118782
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.2555e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.110710
Average KL loss: 0.004704
Average total loss: 0.115414
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.3331e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.111417
Average KL loss: 0.004704
Average total loss: 0.116122
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.2334e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.110893
Average KL loss: 0.004704
Average total loss: 0.115598
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.3059e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.114304
Average KL loss: 0.004704
Average total loss: 0.119008
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-7.5751e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.110400
Average KL loss: 0.004704
Average total loss: 0.115104
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.2107e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.108352
Average KL loss: 0.004704
Average total loss: 0.113057
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.2148e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.109034
Average KL loss: 0.004704
Average total loss: 0.113738
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.4923e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.107146
Average KL loss: 0.004704
Average total loss: 0.111850
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.1700e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.108630
Average KL loss: 0.004704
Average total loss: 0.113334
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-8.6945e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.108586
Average KL loss: 0.004704
Average total loss: 0.113290
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.5082e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.107179
Average KL loss: 0.004704
Average total loss: 0.111883
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.4936e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.108273
Average KL loss: 0.004704
Average total loss: 0.112977
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.1661e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.112247
Average KL loss: 0.004704
Average total loss: 0.116950
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.0777e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.110532
Average KL loss: 0.004704
Average total loss: 0.115235
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-8.7406e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.110700
Average KL loss: 0.004704
Average total loss: 0.115404
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.2079e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.111263
Average KL loss: 0.004704
Average total loss: 0.115967
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.5450e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.116631
Average KL loss: 0.004704
Average total loss: 0.121335
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.0993e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.110908
Average KL loss: 0.004704
Average total loss: 0.115612
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.3450e-08, device='cuda:0')
 Percentile value: 1.8998366832733156
Non-zero model percentage: 0.9223561882972717%, Non-zero mask percentage: 0.9223561882972717%

--- Pruning Level [21/24]: ---
conv1.weight         | nonzeros =     156 /    1728             (  9.03%) | total_pruned =    1572 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      38 /   36864             (  0.10%) | total_pruned =   36826 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      56 /   36864             (  0.15%) | total_pruned =   36808 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     290 /   36864             (  0.79%) | total_pruned =   36574 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     685 /   36864             (  1.86%) | total_pruned =   36179 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2250 /   73728             (  3.05%) | total_pruned =   71478 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    5009 /  147456             (  3.40%) | total_pruned =  142447 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     666 /    8192             (  8.13%) | total_pruned =    7526 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2664 /  147456             (  1.81%) | total_pruned =  144792 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2702 /  147456             (  1.83%) | total_pruned =  144754 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   10190 /  294912             (  3.46%) | total_pruned =  284722 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   14720 /  589824             (  2.50%) | total_pruned =  575104 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1790 /   32768             (  5.46%) | total_pruned =   30978 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     143 /     256             ( 55.86%) | total_pruned =     113 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    6497 /  589824             (  1.10%) | total_pruned =  583327 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     132 /     256             ( 51.56%) | total_pruned =     124 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    5180 /  589824             (  0.88%) | total_pruned =  584644 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   17233 / 1179648             (  1.46%) | total_pruned = 1162415 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     344 /     512             ( 67.19%) | total_pruned =     168 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   12072 / 2359296             (  0.51%) | total_pruned = 2347224 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     299 /     512             ( 58.40%) | total_pruned =     213 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     149 /     512             ( 29.10%) | total_pruned =     363 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     442 /  131072             (  0.34%) | total_pruned =  130630 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      85 /     512             ( 16.60%) | total_pruned =     427 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     154 /     512             ( 30.08%) | total_pruned =     358 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    6503 / 2359296             (  0.28%) | total_pruned = 2352793 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     203 /     512             ( 39.65%) | total_pruned =     309 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    8813 / 2359296             (  0.37%) | total_pruned = 2350483 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     315 /     512             ( 61.52%) | total_pruned =     197 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     224 /     512             ( 43.75%) | total_pruned =     288 | shape = torch.Size([512])
linear.weight        | nonzeros =    2065 /    5120             ( 40.33%) | total_pruned =    3055 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 103108, pruned : 11075654, total: 11178762, Compression rate :     108.42x  ( 99.08% pruned)
Train Epoch: 73/100 Loss: 0.028685 Accuracy: 86.33 99.99 % Best test Accuracy: 86.59%
tensor(0.0275, device='cuda:0') tensor(0.0794, device='cuda:0') tensor(-1.3009e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.103293
Average KL loss: 0.004691
Average total loss: 0.107984
tensor(0.0273, device='cuda:0') tensor(0.0790, device='cuda:0') tensor(-1.1234e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.107713
Average KL loss: 0.004671
Average total loss: 0.112384
tensor(0.0272, device='cuda:0') tensor(0.0787, device='cuda:0') tensor(-1.0518e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.099876
Average KL loss: 0.004651
Average total loss: 0.104526
tensor(0.0271, device='cuda:0') tensor(0.0784, device='cuda:0') tensor(-1.1981e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.103186
Average KL loss: 0.004631
Average total loss: 0.107817
tensor(0.0270, device='cuda:0') tensor(0.0782, device='cuda:0') tensor(-1.1639e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.098432
Average KL loss: 0.004611
Average total loss: 0.103043
tensor(0.0269, device='cuda:0') tensor(0.0779, device='cuda:0') tensor(-1.2629e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.098467
Average KL loss: 0.004592
Average total loss: 0.103059
tensor(0.0268, device='cuda:0') tensor(0.0776, device='cuda:0') tensor(-1.1385e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.102211
Average KL loss: 0.004573
Average total loss: 0.106784
tensor(0.0267, device='cuda:0') tensor(0.0773, device='cuda:0') tensor(-1.0555e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.095940
Average KL loss: 0.004554
Average total loss: 0.100494
tensor(0.0266, device='cuda:0') tensor(0.0771, device='cuda:0') tensor(-1.1542e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.098807
Average KL loss: 0.004536
Average total loss: 0.103343
tensor(0.0265, device='cuda:0') tensor(0.0768, device='cuda:0') tensor(-7.9424e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.108412
Average KL loss: 0.004517
Average total loss: 0.112929
tensor(0.0264, device='cuda:0') tensor(0.0766, device='cuda:0') tensor(-8.0988e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.100706
Average KL loss: 0.004499
Average total loss: 0.105205
tensor(0.0263, device='cuda:0') tensor(0.0764, device='cuda:0') tensor(-1.0106e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.095528
Average KL loss: 0.004481
Average total loss: 0.100009
tensor(0.0263, device='cuda:0') tensor(0.0761, device='cuda:0') tensor(-9.2381e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.093543
Average KL loss: 0.004464
Average total loss: 0.098007
tensor(0.0262, device='cuda:0') tensor(0.0759, device='cuda:0') tensor(-1.2502e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.097000
Average KL loss: 0.004446
Average total loss: 0.101446
tensor(0.0261, device='cuda:0') tensor(0.0757, device='cuda:0') tensor(-1.2121e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.094433
Average KL loss: 0.004429
Average total loss: 0.098863
tensor(0.0260, device='cuda:0') tensor(0.0755, device='cuda:0') tensor(-1.0626e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.095498
Average KL loss: 0.004413
Average total loss: 0.099911
tensor(0.0259, device='cuda:0') tensor(0.0753, device='cuda:0') tensor(-1.0420e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.093668
Average KL loss: 0.004397
Average total loss: 0.098064
tensor(0.0258, device='cuda:0') tensor(0.0751, device='cuda:0') tensor(-7.9574e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.090350
Average KL loss: 0.004381
Average total loss: 0.094731
tensor(0.0257, device='cuda:0') tensor(0.0749, device='cuda:0') tensor(-9.1095e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.089952
Average KL loss: 0.004365
Average total loss: 0.094317
tensor(0.0256, device='cuda:0') tensor(0.0747, device='cuda:0') tensor(-1.1666e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.095783
Average KL loss: 0.004350
Average total loss: 0.100133
tensor(0.0256, device='cuda:0') tensor(0.0745, device='cuda:0') tensor(-1.0100e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.091797
Average KL loss: 0.004335
Average total loss: 0.096132
tensor(0.0255, device='cuda:0') tensor(0.0743, device='cuda:0') tensor(-7.8464e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.090629
Average KL loss: 0.004321
Average total loss: 0.094950
tensor(0.0254, device='cuda:0') tensor(0.0742, device='cuda:0') tensor(-1.0117e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.091832
Average KL loss: 0.004306
Average total loss: 0.096139
tensor(0.0253, device='cuda:0') tensor(0.0740, device='cuda:0') tensor(-1.2271e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.097773
Average KL loss: 0.004293
Average total loss: 0.102065
tensor(0.0253, device='cuda:0') tensor(0.0738, device='cuda:0') tensor(-1.0586e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.092839
Average KL loss: 0.004279
Average total loss: 0.097119
tensor(0.0252, device='cuda:0') tensor(0.0737, device='cuda:0') tensor(-1.0980e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.088679
Average KL loss: 0.004267
Average total loss: 0.092946
tensor(0.0251, device='cuda:0') tensor(0.0735, device='cuda:0') tensor(-1.0559e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.089713
Average KL loss: 0.004254
Average total loss: 0.093967
tensor(0.0250, device='cuda:0') tensor(0.0734, device='cuda:0') tensor(-1.1915e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.089706
Average KL loss: 0.004242
Average total loss: 0.093947
tensor(0.0250, device='cuda:0') tensor(0.0732, device='cuda:0') tensor(-7.2171e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.089519
Average KL loss: 0.004230
Average total loss: 0.093749
tensor(0.0249, device='cuda:0') tensor(0.0731, device='cuda:0') tensor(-9.8361e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.098107
Average KL loss: 0.004219
Average total loss: 0.102326
tensor(0.0248, device='cuda:0') tensor(0.0730, device='cuda:0') tensor(-7.7600e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.090555
Average KL loss: 0.004208
Average total loss: 0.094763
tensor(0.0248, device='cuda:0') tensor(0.0729, device='cuda:0') tensor(-9.9902e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.088739
Average KL loss: 0.004197
Average total loss: 0.092936
tensor(0.0247, device='cuda:0') tensor(0.0727, device='cuda:0') tensor(-9.3103e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.093233
Average KL loss: 0.004187
Average total loss: 0.097420
tensor(0.0246, device='cuda:0') tensor(0.0726, device='cuda:0') tensor(-9.8158e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.090084
Average KL loss: 0.004177
Average total loss: 0.094261
tensor(0.0246, device='cuda:0') tensor(0.0725, device='cuda:0') tensor(-1.0985e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.092614
Average KL loss: 0.004167
Average total loss: 0.096782
tensor(0.0245, device='cuda:0') tensor(0.0724, device='cuda:0') tensor(-1.1552e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.092781
Average KL loss: 0.004158
Average total loss: 0.096939
tensor(0.0244, device='cuda:0') tensor(0.0723, device='cuda:0') tensor(-8.7130e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.087306
Average KL loss: 0.004149
Average total loss: 0.091456
tensor(0.0244, device='cuda:0') tensor(0.0722, device='cuda:0') tensor(-1.0363e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.091074
Average KL loss: 0.004141
Average total loss: 0.095215
tensor(0.0243, device='cuda:0') tensor(0.0721, device='cuda:0') tensor(-6.9388e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.091210
Average KL loss: 0.004133
Average total loss: 0.095343
tensor(0.0243, device='cuda:0') tensor(0.0720, device='cuda:0') tensor(-9.0006e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.085790
Average KL loss: 0.004125
Average total loss: 0.089915
tensor(0.0242, device='cuda:0') tensor(0.0719, device='cuda:0') tensor(-7.7713e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.085178
Average KL loss: 0.004117
Average total loss: 0.089295
tensor(0.0242, device='cuda:0') tensor(0.0718, device='cuda:0') tensor(-1.0804e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.082261
Average KL loss: 0.004110
Average total loss: 0.086371
tensor(0.0241, device='cuda:0') tensor(0.0717, device='cuda:0') tensor(-1.0378e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.085996
Average KL loss: 0.004103
Average total loss: 0.090099
tensor(0.0241, device='cuda:0') tensor(0.0717, device='cuda:0') tensor(-7.7056e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.085780
Average KL loss: 0.004096
Average total loss: 0.089876
tensor(0.0240, device='cuda:0') tensor(0.0716, device='cuda:0') tensor(-9.5751e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.085942
Average KL loss: 0.004090
Average total loss: 0.090032
tensor(0.0240, device='cuda:0') tensor(0.0715, device='cuda:0') tensor(-7.7411e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.088435
Average KL loss: 0.004084
Average total loss: 0.092518
tensor(0.0239, device='cuda:0') tensor(0.0714, device='cuda:0') tensor(-7.5551e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.084864
Average KL loss: 0.004078
Average total loss: 0.088942
tensor(0.0239, device='cuda:0') tensor(0.0714, device='cuda:0') tensor(-7.5982e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.082274
Average KL loss: 0.004072
Average total loss: 0.086346
tensor(0.0238, device='cuda:0') tensor(0.0713, device='cuda:0') tensor(-8.0977e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.083856
Average KL loss: 0.004067
Average total loss: 0.087923
tensor(0.0238, device='cuda:0') tensor(0.0712, device='cuda:0') tensor(-1.0900e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.084316
Average KL loss: 0.004062
Average total loss: 0.088378
tensor(0.0237, device='cuda:0') tensor(0.0712, device='cuda:0') tensor(-9.8202e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.084060
Average KL loss: 0.004057
Average total loss: 0.088117
tensor(0.0237, device='cuda:0') tensor(0.0711, device='cuda:0') tensor(-1.0926e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.082122
Average KL loss: 0.004052
Average total loss: 0.086174
tensor(0.0237, device='cuda:0') tensor(0.0711, device='cuda:0') tensor(-8.6422e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.082475
Average KL loss: 0.004047
Average total loss: 0.086522
tensor(0.0236, device='cuda:0') tensor(0.0710, device='cuda:0') tensor(-9.6466e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.081986
Average KL loss: 0.004043
Average total loss: 0.086028
tensor(0.0236, device='cuda:0') tensor(0.0710, device='cuda:0') tensor(-9.0764e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.086888
Average KL loss: 0.004039
Average total loss: 0.090927
tensor(0.0235, device='cuda:0') tensor(0.0709, device='cuda:0') tensor(-8.0184e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.083717
Average KL loss: 0.004035
Average total loss: 0.087752
tensor(0.0235, device='cuda:0') tensor(0.0709, device='cuda:0') tensor(-9.8147e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.093900
Average KL loss: 0.004031
Average total loss: 0.097930
tensor(0.0235, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-7.2544e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.078422
Average KL loss: 0.004027
Average total loss: 0.082449
tensor(0.0234, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-9.8455e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.081845
Average KL loss: 0.004024
Average total loss: 0.085869
tensor(0.0234, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-7.8969e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.084419
Average KL loss: 0.004020
Average total loss: 0.088439
tensor(0.0234, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-8.8514e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.082975
Average KL loss: 0.004017
Average total loss: 0.086992
tensor(0.0233, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-1.0472e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.077829
Average KL loss: 0.004014
Average total loss: 0.081843
tensor(0.0233, device='cuda:0') tensor(0.0706, device='cuda:0') tensor(-8.5300e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.078574
Average KL loss: 0.004011
Average total loss: 0.082585
tensor(0.0233, device='cuda:0') tensor(0.0706, device='cuda:0') tensor(-8.0933e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.078194
Average KL loss: 0.004008
Average total loss: 0.082202
tensor(0.0233, device='cuda:0') tensor(0.0706, device='cuda:0') tensor(-8.3862e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.082109
Average KL loss: 0.004005
Average total loss: 0.086114
tensor(0.0232, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-9.5141e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.083538
Average KL loss: 0.004003
Average total loss: 0.087541
tensor(0.0232, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-9.2802e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.080433
Average KL loss: 0.004000
Average total loss: 0.084433
tensor(0.0232, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-9.6140e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.076571
Average KL loss: 0.003998
Average total loss: 0.080569
tensor(0.0232, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-9.5048e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.089929
Average KL loss: 0.003995
Average total loss: 0.093924
tensor(0.0231, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-6.3033e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.085181
Average KL loss: 0.003993
Average total loss: 0.089174
tensor(0.0231, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-7.0862e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.079778
Average KL loss: 0.003991
Average total loss: 0.083769
tensor(0.0231, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-6.9356e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.083029
Average KL loss: 0.003989
Average total loss: 0.087018
tensor(0.0231, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-6.9407e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.077664
Average KL loss: 0.003987
Average total loss: 0.081651
tensor(0.0230, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-7.5716e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.081955
Average KL loss: 0.003985
Average total loss: 0.085940
tensor(0.0230, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-7.7256e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.076712
Average KL loss: 0.003983
Average total loss: 0.080696
tensor(0.0230, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-8.9771e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.075858
Average KL loss: 0.003981
Average total loss: 0.079839
tensor(0.0230, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-8.8058e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.077766
Average KL loss: 0.003980
Average total loss: 0.081746
tensor(0.0230, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-7.8469e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.078359
Average KL loss: 0.003978
Average total loss: 0.082337
tensor(0.0230, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-7.5541e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.077961
Average KL loss: 0.003977
Average total loss: 0.081938
tensor(0.0229, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-7.6049e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.078604
Average KL loss: 0.003975
Average total loss: 0.082580
tensor(0.0229, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-6.8834e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.075838
Average KL loss: 0.003974
Average total loss: 0.079812
tensor(0.0229, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-5.5250e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.075092
Average KL loss: 0.003972
Average total loss: 0.079065
tensor(0.0229, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-7.0110e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.075464
Average KL loss: 0.003971
Average total loss: 0.079436
tensor(0.0229, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-6.5787e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.077262
Average KL loss: 0.003970
Average total loss: 0.081232
tensor(0.0229, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-8.6259e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.076513
Average KL loss: 0.003969
Average total loss: 0.080482
tensor(0.0229, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-6.1133e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.082786
Average KL loss: 0.003968
Average total loss: 0.086754
tensor(0.0228, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-6.5412e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.074432
Average KL loss: 0.003967
Average total loss: 0.078399
tensor(0.0228, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-6.4052e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.080359
Average KL loss: 0.003966
Average total loss: 0.084325
tensor(0.0228, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-7.7088e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.074831
Average KL loss: 0.003965
Average total loss: 0.078796
tensor(0.0228, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-8.4576e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.075691
Average KL loss: 0.003964
Average total loss: 0.079655
tensor(0.0228, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-7.0928e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.073627
Average KL loss: 0.003963
Average total loss: 0.077590
tensor(0.0228, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-8.4955e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.074955
Average KL loss: 0.003962
Average total loss: 0.078917
tensor(0.0228, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-8.0702e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.074239
Average KL loss: 0.003962
Average total loss: 0.078200
tensor(0.0228, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-7.6585e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.073869
Average KL loss: 0.003961
Average total loss: 0.077830
tensor(0.0228, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-7.0870e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.070578
Average KL loss: 0.003960
Average total loss: 0.074538
tensor(0.0228, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-9.3906e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.077118
Average KL loss: 0.003960
Average total loss: 0.081078
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-5.7351e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.072303
Average KL loss: 0.003959
Average total loss: 0.076262
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-1.4329e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.070437
Average KL loss: 0.003959
Average total loss: 0.074396
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-1.0553e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.074624
Average KL loss: 0.003958
Average total loss: 0.078582
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-5.8025e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.071299
Average KL loss: 0.003958
Average total loss: 0.075256
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-7.9318e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.076417
Average KL loss: 0.003957
Average total loss: 0.080375
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-6.8913e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.072220
Average KL loss: 0.003957
Average total loss: 0.076176
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-7.7521e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.071545
Average KL loss: 0.003956
Average total loss: 0.075501
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-1.2076e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.072446
Average KL loss: 0.003956
Average total loss: 0.076402
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-7.7988e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.068427
Average KL loss: 0.003955
Average total loss: 0.072382
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-1.2017e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.069247
Average KL loss: 0.003955
Average total loss: 0.073202
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-6.9305e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.073113
Average KL loss: 0.003955
Average total loss: 0.077068
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-6.9406e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.072000
Average KL loss: 0.003954
Average total loss: 0.075954
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-5.3769e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.069997
Average KL loss: 0.003954
Average total loss: 0.073951
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-9.6007e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.078481
Average KL loss: 0.003954
Average total loss: 0.082435
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-5.1359e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.068280
Average KL loss: 0.003954
Average total loss: 0.072234
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-6.3185e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.069006
Average KL loss: 0.003953
Average total loss: 0.072959
tensor(0.0227, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-7.4690e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.071987
Average KL loss: 0.003953
Average total loss: 0.075940
tensor(0.0226, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-7.5848e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.068424
Average KL loss: 0.003953
Average total loss: 0.072377
tensor(0.0226, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-9.0947e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.072392
Average KL loss: 0.003953
Average total loss: 0.076346
tensor(0.0226, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-7.2056e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.069395
Average KL loss: 0.003953
Average total loss: 0.073348
tensor(0.0226, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-5.7594e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.067350
Average KL loss: 0.003953
Average total loss: 0.071303
tensor(0.0226, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-8.4454e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.069924
Average KL loss: 0.003953
Average total loss: 0.073877
tensor(0.0226, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-9.4824e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.070292
Average KL loss: 0.003953
Average total loss: 0.074245
tensor(0.0226, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-7.9072e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.068889
Average KL loss: 0.003953
Average total loss: 0.072842
tensor(0.0226, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-5.7286e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.074162
Average KL loss: 0.003953
Average total loss: 0.078115
tensor(0.0226, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-5.9508e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.068719
Average KL loss: 0.003953
Average total loss: 0.072672
tensor(0.0226, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-7.3381e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.067256
Average KL loss: 0.003953
Average total loss: 0.071208
tensor(0.0226, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-7.0116e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.071286
Average KL loss: 0.003953
Average total loss: 0.075239
tensor(0.0226, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-9.2429e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.068169
Average KL loss: 0.003953
Average total loss: 0.072122
tensor(0.0226, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-6.2393e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.064585
Average KL loss: 0.003953
Average total loss: 0.068538
tensor(0.0226, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-5.6081e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.064853
Average KL loss: 0.003953
Average total loss: 0.068806
tensor(0.0226, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-7.1753e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.063937
Average KL loss: 0.003953
Average total loss: 0.067890
tensor(0.0226, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-6.3366e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.065595
Average KL loss: 0.003953
Average total loss: 0.069548
tensor(0.0226, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-4.3090e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.065501
Average KL loss: 0.003953
Average total loss: 0.069455
tensor(0.0226, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-4.7609e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.064490
Average KL loss: 0.003953
Average total loss: 0.068443
tensor(0.0226, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-6.5261e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.066850
Average KL loss: 0.003953
Average total loss: 0.070804
tensor(0.0226, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-6.5544e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.066746
Average KL loss: 0.003954
Average total loss: 0.070700
tensor(0.0226, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-6.2374e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.066497
Average KL loss: 0.003954
Average total loss: 0.070451
tensor(0.0226, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-5.9685e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.072540
Average KL loss: 0.003954
Average total loss: 0.076494
tensor(0.0226, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-7.3465e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.063493
Average KL loss: 0.003954
Average total loss: 0.067447
tensor(0.0226, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-4.1250e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.066950
Average KL loss: 0.003954
Average total loss: 0.070904
tensor(0.0226, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-5.9376e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.065197
Average KL loss: 0.003955
Average total loss: 0.069152
tensor(0.0226, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-8.4636e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.065726
Average KL loss: 0.003955
Average total loss: 0.069681
tensor(0.0226, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-5.3803e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.065865
Average KL loss: 0.003955
Average total loss: 0.069820
tensor(0.0226, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-5.8940e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.067543
Average KL loss: 0.003955
Average total loss: 0.071498
tensor(0.0226, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-6.4324e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.063849
Average KL loss: 0.003956
Average total loss: 0.067805
tensor(0.0226, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-6.4739e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.066089
Average KL loss: 0.003956
Average total loss: 0.070044
tensor(0.0226, device='cuda:0') tensor(0.0703, device='cuda:0') tensor(-6.4280e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.066574
Average KL loss: 0.003956
Average total loss: 0.070531
tensor(0.0226, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-5.5870e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.066385
Average KL loss: 0.003956
Average total loss: 0.070342
tensor(0.0226, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-6.4086e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.067263
Average KL loss: 0.003957
Average total loss: 0.071220
tensor(0.0226, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-4.5833e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.063314
Average KL loss: 0.003957
Average total loss: 0.067271
tensor(0.0226, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-5.5143e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.062615
Average KL loss: 0.003957
Average total loss: 0.066572
tensor(0.0226, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-1.8170e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.066990
Average KL loss: 0.003958
Average total loss: 0.070947
tensor(0.0226, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-6.0904e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.062812
Average KL loss: 0.003958
Average total loss: 0.066770
tensor(0.0226, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-5.0877e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.067985
Average KL loss: 0.003958
Average total loss: 0.071943
tensor(0.0226, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-6.2648e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.060928
Average KL loss: 0.003959
Average total loss: 0.064886
tensor(0.0226, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-5.0493e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.065441
Average KL loss: 0.003959
Average total loss: 0.069400
tensor(0.0226, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-5.8680e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.062215
Average KL loss: 0.003959
Average total loss: 0.066174
tensor(0.0226, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-5.8487e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.065202
Average KL loss: 0.003960
Average total loss: 0.069162
tensor(0.0226, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-6.0430e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.062643
Average KL loss: 0.003960
Average total loss: 0.066603
tensor(0.0226, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-5.7626e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.064259
Average KL loss: 0.003960
Average total loss: 0.068219
tensor(0.0226, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-5.4556e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.065882
Average KL loss: 0.003961
Average total loss: 0.069843
tensor(0.0226, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-5.5037e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.062045
Average KL loss: 0.003961
Average total loss: 0.066005
tensor(0.0226, device='cuda:0') tensor(0.0706, device='cuda:0') tensor(-4.5602e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.065746
Average KL loss: 0.003961
Average total loss: 0.069707
tensor(0.0226, device='cuda:0') tensor(0.0706, device='cuda:0') tensor(-7.2353e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.059487
Average KL loss: 0.003962
Average total loss: 0.063449
tensor(0.0226, device='cuda:0') tensor(0.0706, device='cuda:0') tensor(-6.5327e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.060145
Average KL loss: 0.003962
Average total loss: 0.064107
tensor(0.0226, device='cuda:0') tensor(0.0706, device='cuda:0') tensor(-6.7209e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.060971
Average KL loss: 0.003962
Average total loss: 0.064933
tensor(0.0226, device='cuda:0') tensor(0.0706, device='cuda:0') tensor(-8.5164e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.060626
Average KL loss: 0.003963
Average total loss: 0.064589
tensor(0.0226, device='cuda:0') tensor(0.0706, device='cuda:0') tensor(-5.0698e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.061487
Average KL loss: 0.003963
Average total loss: 0.065450
tensor(0.0226, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-8.5223e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.061901
Average KL loss: 0.003963
Average total loss: 0.065865
tensor(0.0226, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-6.3463e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.062179
Average KL loss: 0.003964
Average total loss: 0.066143
tensor(0.0226, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-7.3569e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.060686
Average KL loss: 0.003964
Average total loss: 0.064650
tensor(0.0226, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-6.8689e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.062626
Average KL loss: 0.003965
Average total loss: 0.066591
tensor(0.0226, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-6.3813e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.059827
Average KL loss: 0.003965
Average total loss: 0.063792
tensor(0.0226, device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-4.4387e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.062025
Average KL loss: 0.003966
Average total loss: 0.065990
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-5.9132e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.060253
Average KL loss: 0.003966
Average total loss: 0.064220
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-4.8117e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.058172
Average KL loss: 0.003966
Average total loss: 0.062138
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-6.5784e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.061010
Average KL loss: 0.003966
Average total loss: 0.064976
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-4.4448e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.058621
Average KL loss: 0.003966
Average total loss: 0.062587
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-1.5424e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.059739
Average KL loss: 0.003966
Average total loss: 0.063706
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-3.0230e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.060971
Average KL loss: 0.003966
Average total loss: 0.064937
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-7.2540e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.060078
Average KL loss: 0.003967
Average total loss: 0.064045
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-7.2130e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.059938
Average KL loss: 0.003967
Average total loss: 0.063905
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-5.6436e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.064797
Average KL loss: 0.003967
Average total loss: 0.068764
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-6.1030e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.062338
Average KL loss: 0.003967
Average total loss: 0.066304
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-5.5478e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.061706
Average KL loss: 0.003967
Average total loss: 0.065673
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-4.5938e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.059533
Average KL loss: 0.003967
Average total loss: 0.063500
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-8.0692e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.066501
Average KL loss: 0.003967
Average total loss: 0.070468
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-7.5760e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.063007
Average KL loss: 0.003967
Average total loss: 0.066974
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-6.8164e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.059753
Average KL loss: 0.003967
Average total loss: 0.063720
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-8.3385e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.058585
Average KL loss: 0.003967
Average total loss: 0.062552
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-4.7658e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.061067
Average KL loss: 0.003967
Average total loss: 0.065033
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-4.4766e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.058538
Average KL loss: 0.003967
Average total loss: 0.062505
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-8.3075e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.058479
Average KL loss: 0.003967
Average total loss: 0.062446
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-8.2546e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.061068
Average KL loss: 0.003967
Average total loss: 0.065035
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-6.3600e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.068302
Average KL loss: 0.003967
Average total loss: 0.072269
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-6.9465e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.060108
Average KL loss: 0.003967
Average total loss: 0.064075
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-5.5802e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.058983
Average KL loss: 0.003967
Average total loss: 0.062950
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-8.5911e-09, device='cuda:0')
 Percentile value: 2.1501104831695557
Non-zero model percentage: 0.7378903031349182%, Non-zero mask percentage: 0.7378903031349182%

--- Pruning Level [22/24]: ---
conv1.weight         | nonzeros =     154 /    1728             (  8.91%) | total_pruned =    1574 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      27 /   36864             (  0.07%) | total_pruned =   36837 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      43 /   36864             (  0.12%) | total_pruned =   36821 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     246 /   36864             (  0.67%) | total_pruned =   36618 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     515 /   36864             (  1.40%) | total_pruned =   36349 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1952 /   73728             (  2.65%) | total_pruned =   71776 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4355 /  147456             (  2.95%) | total_pruned =  143101 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     599 /    8192             (  7.31%) | total_pruned =    7593 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2402 /  147456             (  1.63%) | total_pruned =  145054 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2463 /  147456             (  1.67%) | total_pruned =  144993 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    9013 /  294912             (  3.06%) | total_pruned =  285899 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     193 /     256             ( 75.39%) | total_pruned =      63 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   13042 /  589824             (  2.21%) | total_pruned =  576782 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     175 /     256             ( 68.36%) | total_pruned =      81 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1584 /   32768             (  4.83%) | total_pruned =   31184 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     126 /     256             ( 49.22%) | total_pruned =     130 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    5785 /  589824             (  0.98%) | total_pruned =  584039 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     120 /     256             ( 46.88%) | total_pruned =     136 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    4574 /  589824             (  0.78%) | total_pruned =  585250 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     116 /     256             ( 45.31%) | total_pruned =     140 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   14508 / 1179648             (  1.23%) | total_pruned = 1165140 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     313 /     512             ( 61.13%) | total_pruned =     199 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    8509 / 2359296             (  0.36%) | total_pruned = 2350787 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     246 /     512             ( 48.05%) | total_pruned =     266 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     104 /     512             ( 20.31%) | total_pruned =     408 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     300 /  131072             (  0.23%) | total_pruned =  130772 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      47 /     512             (  9.18%) | total_pruned =     465 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     110 /     512             ( 21.48%) | total_pruned =     402 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    4314 / 2359296             (  0.18%) | total_pruned = 2354982 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     173 /     512             ( 33.79%) | total_pruned =     339 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    3741 / 2359296             (  0.16%) | total_pruned = 2355555 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     294 /     512             ( 57.42%) | total_pruned =     218 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     159 /     512             ( 31.05%) | total_pruned =     353 | shape = torch.Size([512])
linear.weight        | nonzeros =    1714 /    5120             ( 33.48%) | total_pruned =    3406 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 82487, pruned : 11096275, total: 11178762, Compression rate :     135.52x  ( 99.26% pruned)
Train Epoch: 52/100 Loss: 0.025360 Accuracy: 84.67 99.98 % Best test Accuracy: 85.24%
tensor(0.0226, device='cuda:0') tensor(0.0708, device='cuda:0') tensor(-1.1832e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.138163
Average KL loss: 0.003960
Average total loss: 0.142123
tensor(0.0226, device='cuda:0') tensor(0.0705, device='cuda:0') tensor(-1.7802e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.141063
Average KL loss: 0.003950
Average total loss: 0.145014
tensor(0.0225, device='cuda:0') tensor(0.0704, device='cuda:0') tensor(-1.5256e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.142540
Average KL loss: 0.003941
Average total loss: 0.146481
tensor(0.0225, device='cuda:0') tensor(0.0702, device='cuda:0') tensor(-1.7386e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.144834
Average KL loss: 0.003932
Average total loss: 0.148766
tensor(0.0225, device='cuda:0') tensor(0.0701, device='cuda:0') tensor(-1.2696e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.137314
Average KL loss: 0.003922
Average total loss: 0.141236
tensor(0.0224, device='cuda:0') tensor(0.0699, device='cuda:0') tensor(-1.5886e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.142262
Average KL loss: 0.003913
Average total loss: 0.146174
tensor(0.0224, device='cuda:0') tensor(0.0698, device='cuda:0') tensor(-1.6956e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.137425
Average KL loss: 0.003904
Average total loss: 0.141328
tensor(0.0223, device='cuda:0') tensor(0.0697, device='cuda:0') tensor(-1.5532e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.141009
Average KL loss: 0.003894
Average total loss: 0.144903
tensor(0.0223, device='cuda:0') tensor(0.0695, device='cuda:0') tensor(-1.5115e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.136011
Average KL loss: 0.003885
Average total loss: 0.139896
tensor(0.0222, device='cuda:0') tensor(0.0694, device='cuda:0') tensor(-1.5201e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.134307
Average KL loss: 0.003876
Average total loss: 0.138183
tensor(0.0222, device='cuda:0') tensor(0.0693, device='cuda:0') tensor(-1.5266e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.134723
Average KL loss: 0.003866
Average total loss: 0.138589
tensor(0.0222, device='cuda:0') tensor(0.0691, device='cuda:0') tensor(-1.1325e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.132012
Average KL loss: 0.003857
Average total loss: 0.135869
tensor(0.0221, device='cuda:0') tensor(0.0690, device='cuda:0') tensor(-1.7942e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.134142
Average KL loss: 0.003848
Average total loss: 0.137990
tensor(0.0221, device='cuda:0') tensor(0.0689, device='cuda:0') tensor(-1.2080e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.147663
Average KL loss: 0.003839
Average total loss: 0.151502
tensor(0.0220, device='cuda:0') tensor(0.0688, device='cuda:0') tensor(-1.4237e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.133097
Average KL loss: 0.003830
Average total loss: 0.136927
tensor(0.0220, device='cuda:0') tensor(0.0687, device='cuda:0') tensor(-9.1776e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.131874
Average KL loss: 0.003821
Average total loss: 0.135695
tensor(0.0220, device='cuda:0') tensor(0.0686, device='cuda:0') tensor(-1.2047e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.141125
Average KL loss: 0.003812
Average total loss: 0.144937
tensor(0.0219, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-1.2229e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.131350
Average KL loss: 0.003803
Average total loss: 0.135153
tensor(0.0219, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(-5.2213e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.134605
Average KL loss: 0.003795
Average total loss: 0.138400
tensor(0.0218, device='cuda:0') tensor(0.0683, device='cuda:0') tensor(-1.4123e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.131864
Average KL loss: 0.003786
Average total loss: 0.135650
tensor(0.0218, device='cuda:0') tensor(0.0682, device='cuda:0') tensor(-1.1432e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.131402
Average KL loss: 0.003778
Average total loss: 0.135180
tensor(0.0218, device='cuda:0') tensor(0.0681, device='cuda:0') tensor(-1.5146e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.133654
Average KL loss: 0.003770
Average total loss: 0.137423
tensor(0.0217, device='cuda:0') tensor(0.0680, device='cuda:0') tensor(-1.3593e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.136515
Average KL loss: 0.003762
Average total loss: 0.140277
tensor(0.0217, device='cuda:0') tensor(0.0679, device='cuda:0') tensor(-1.2758e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.139110
Average KL loss: 0.003754
Average total loss: 0.142864
tensor(0.0216, device='cuda:0') tensor(0.0678, device='cuda:0') tensor(-1.1719e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.130453
Average KL loss: 0.003746
Average total loss: 0.134199
tensor(0.0216, device='cuda:0') tensor(0.0677, device='cuda:0') tensor(-1.0442e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.124184
Average KL loss: 0.003739
Average total loss: 0.127923
tensor(0.0216, device='cuda:0') tensor(0.0676, device='cuda:0') tensor(-1.0981e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.131171
Average KL loss: 0.003731
Average total loss: 0.134902
tensor(0.0215, device='cuda:0') tensor(0.0675, device='cuda:0') tensor(-1.1927e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.128744
Average KL loss: 0.003724
Average total loss: 0.132468
tensor(0.0215, device='cuda:0') tensor(0.0675, device='cuda:0') tensor(-1.3643e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.127316
Average KL loss: 0.003717
Average total loss: 0.131033
tensor(0.0215, device='cuda:0') tensor(0.0674, device='cuda:0') tensor(-1.3309e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.126747
Average KL loss: 0.003710
Average total loss: 0.130458
tensor(0.0214, device='cuda:0') tensor(0.0673, device='cuda:0') tensor(-1.0473e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.127029
Average KL loss: 0.003704
Average total loss: 0.130732
tensor(0.0214, device='cuda:0') tensor(0.0673, device='cuda:0') tensor(-1.1784e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.122496
Average KL loss: 0.003697
Average total loss: 0.126193
tensor(0.0214, device='cuda:0') tensor(0.0672, device='cuda:0') tensor(-7.8717e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.125555
Average KL loss: 0.003691
Average total loss: 0.129246
tensor(0.0213, device='cuda:0') tensor(0.0671, device='cuda:0') tensor(-9.9028e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.136590
Average KL loss: 0.003685
Average total loss: 0.140275
tensor(0.0213, device='cuda:0') tensor(0.0671, device='cuda:0') tensor(-1.5944e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.126552
Average KL loss: 0.003679
Average total loss: 0.130232
tensor(0.0213, device='cuda:0') tensor(0.0670, device='cuda:0') tensor(-9.9348e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.124354
Average KL loss: 0.003674
Average total loss: 0.128028
tensor(0.0212, device='cuda:0') tensor(0.0670, device='cuda:0') tensor(-9.5380e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.122092
Average KL loss: 0.003668
Average total loss: 0.125761
tensor(0.0212, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-1.3895e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.123376
Average KL loss: 0.003663
Average total loss: 0.127039
tensor(0.0212, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-1.0084e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.125051
Average KL loss: 0.003658
Average total loss: 0.128709
tensor(0.0211, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-1.1188e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.124039
Average KL loss: 0.003653
Average total loss: 0.127693
tensor(0.0211, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-1.3159e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.128655
Average KL loss: 0.003649
Average total loss: 0.132303
tensor(0.0211, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-1.6222e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.122368
Average KL loss: 0.003644
Average total loss: 0.126012
tensor(0.0210, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-7.1541e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.123594
Average KL loss: 0.003640
Average total loss: 0.127234
tensor(0.0210, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-1.0150e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.122163
Average KL loss: 0.003636
Average total loss: 0.125799
tensor(0.0210, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-1.2672e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.120374
Average KL loss: 0.003632
Average total loss: 0.124006
tensor(0.0210, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-1.2332e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.126892
Average KL loss: 0.003628
Average total loss: 0.130520
tensor(0.0209, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-1.2868e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.117857
Average KL loss: 0.003624
Average total loss: 0.121481
tensor(0.0209, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-1.2762e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.120776
Average KL loss: 0.003621
Average total loss: 0.124397
tensor(0.0209, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-1.1453e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.124572
Average KL loss: 0.003617
Average total loss: 0.128190
tensor(0.0209, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-9.9583e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.120378
Average KL loss: 0.003614
Average total loss: 0.123992
tensor(0.0208, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-1.0791e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.115844
Average KL loss: 0.003611
Average total loss: 0.119455
tensor(0.0208, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-1.3610e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.118777
Average KL loss: 0.003608
Average total loss: 0.122385
tensor(0.0208, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-1.4202e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.122776
Average KL loss: 0.003606
Average total loss: 0.126381
tensor(0.0208, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-9.4955e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.116129
Average KL loss: 0.003603
Average total loss: 0.119732
tensor(0.0208, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-1.3690e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.122584
Average KL loss: 0.003600
Average total loss: 0.126184
tensor(0.0207, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-1.2973e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.116376
Average KL loss: 0.003598
Average total loss: 0.119974
tensor(0.0207, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-1.1511e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.120520
Average KL loss: 0.003596
Average total loss: 0.124116
tensor(0.0207, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-1.0953e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.114991
Average KL loss: 0.003594
Average total loss: 0.118584
tensor(0.0207, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-7.7902e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.116139
Average KL loss: 0.003592
Average total loss: 0.119731
tensor(0.0207, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-2.2233e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.118427
Average KL loss: 0.003590
Average total loss: 0.122016
tensor(0.0206, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-9.2939e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.111805
Average KL loss: 0.003588
Average total loss: 0.115393
tensor(0.0206, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-9.1197e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.118504
Average KL loss: 0.003586
Average total loss: 0.122090
tensor(0.0206, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.1925e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.113946
Average KL loss: 0.003584
Average total loss: 0.117530
tensor(0.0206, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.0278e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.112998
Average KL loss: 0.003583
Average total loss: 0.116581
tensor(0.0206, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-9.8188e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.118765
Average KL loss: 0.003581
Average total loss: 0.122346
tensor(0.0206, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.1869e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.120912
Average KL loss: 0.003580
Average total loss: 0.124492
tensor(0.0206, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-6.6796e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.114824
Average KL loss: 0.003579
Average total loss: 0.118403
tensor(0.0205, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.6441e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.110636
Average KL loss: 0.003578
Average total loss: 0.114214
tensor(0.0205, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.0176e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.110958
Average KL loss: 0.003576
Average total loss: 0.114534
tensor(0.0205, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-9.8675e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.111824
Average KL loss: 0.003575
Average total loss: 0.115400
tensor(0.0205, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.0333e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.112436
Average KL loss: 0.003574
Average total loss: 0.116010
tensor(0.0205, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-6.4357e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.111018
Average KL loss: 0.003573
Average total loss: 0.114591
tensor(0.0205, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.3018e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.118965
Average KL loss: 0.003572
Average total loss: 0.122537
tensor(0.0205, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-6.3152e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.115203
Average KL loss: 0.003572
Average total loss: 0.118775
tensor(0.0205, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-8.8148e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.111385
Average KL loss: 0.003571
Average total loss: 0.114955
tensor(0.0204, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.0942e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.117560
Average KL loss: 0.003570
Average total loss: 0.121130
tensor(0.0204, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-8.7575e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.110716
Average KL loss: 0.003569
Average total loss: 0.114285
tensor(0.0204, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.2078e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.109836
Average KL loss: 0.003569
Average total loss: 0.113405
tensor(0.0204, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.0789e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.112300
Average KL loss: 0.003568
Average total loss: 0.115868
tensor(0.0204, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.0146e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.111774
Average KL loss: 0.003568
Average total loss: 0.115342
tensor(0.0204, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.0312e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.106889
Average KL loss: 0.003567
Average total loss: 0.110456
tensor(0.0204, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.1944e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.112237
Average KL loss: 0.003567
Average total loss: 0.115804
tensor(0.0204, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-8.0696e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.113040
Average KL loss: 0.003566
Average total loss: 0.116606
tensor(0.0204, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-9.0631e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.105339
Average KL loss: 0.003566
Average total loss: 0.108905
tensor(0.0204, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-9.8218e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.109543
Average KL loss: 0.003565
Average total loss: 0.113108
tensor(0.0204, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-9.8623e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.107226
Average KL loss: 0.003565
Average total loss: 0.110791
tensor(0.0204, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-1.0173e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.112961
Average KL loss: 0.003565
Average total loss: 0.116525
tensor(0.0204, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-1.7072e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.108146
Average KL loss: 0.003564
Average total loss: 0.111710
tensor(0.0204, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-1.0174e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.103476
Average KL loss: 0.003564
Average total loss: 0.107041
tensor(0.0203, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-6.7270e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.109158
Average KL loss: 0.003564
Average total loss: 0.112722
tensor(0.0203, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-1.1795e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.107176
Average KL loss: 0.003564
Average total loss: 0.110740
tensor(0.0203, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-5.6312e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.103230
Average KL loss: 0.003563
Average total loss: 0.106793
tensor(0.0203, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-1.0799e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.106798
Average KL loss: 0.003563
Average total loss: 0.110362
tensor(0.0203, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-8.4882e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.108655
Average KL loss: 0.003563
Average total loss: 0.112218
tensor(0.0203, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-1.1209e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.108903
Average KL loss: 0.003563
Average total loss: 0.112466
tensor(0.0203, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-1.1579e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.101334
Average KL loss: 0.003563
Average total loss: 0.104897
tensor(0.0203, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-7.3654e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.102056
Average KL loss: 0.003563
Average total loss: 0.105619
tensor(0.0203, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-8.3715e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.103352
Average KL loss: 0.003563
Average total loss: 0.106915
tensor(0.0203, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-9.8062e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.102155
Average KL loss: 0.003563
Average total loss: 0.105718
tensor(0.0203, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-6.3018e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.100783
Average KL loss: 0.003563
Average total loss: 0.104346
tensor(0.0203, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-1.0006e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.102508
Average KL loss: 0.003563
Average total loss: 0.106071
tensor(0.0203, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-1.0185e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.101225
Average KL loss: 0.003563
Average total loss: 0.104787
tensor(0.0203, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-1.0135e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.104809
Average KL loss: 0.003563
Average total loss: 0.108372
tensor(0.0203, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-1.0114e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.107355
Average KL loss: 0.003563
Average total loss: 0.110918
tensor(0.0203, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-1.2581e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.102076
Average KL loss: 0.003563
Average total loss: 0.105639
tensor(0.0203, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-7.8522e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.101686
Average KL loss: 0.003563
Average total loss: 0.105249
tensor(0.0203, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-8.7244e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.104278
Average KL loss: 0.003563
Average total loss: 0.107841
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-9.8322e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.101597
Average KL loss: 0.003563
Average total loss: 0.105161
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-6.6177e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.102314
Average KL loss: 0.003564
Average total loss: 0.105877
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-7.4313e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.106949
Average KL loss: 0.003564
Average total loss: 0.110513
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-9.5522e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.103652
Average KL loss: 0.003564
Average total loss: 0.107216
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-8.1791e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.098720
Average KL loss: 0.003564
Average total loss: 0.102284
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-6.5317e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.099942
Average KL loss: 0.003564
Average total loss: 0.103506
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-7.0678e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.105707
Average KL loss: 0.003564
Average total loss: 0.109271
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-8.5966e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.100503
Average KL loss: 0.003564
Average total loss: 0.104068
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-1.0378e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.097841
Average KL loss: 0.003564
Average total loss: 0.101405
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-7.5260e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.105285
Average KL loss: 0.003564
Average total loss: 0.108849
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-8.1329e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.100288
Average KL loss: 0.003564
Average total loss: 0.103852
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-1.0043e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.103089
Average KL loss: 0.003564
Average total loss: 0.106653
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-8.3336e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.101640
Average KL loss: 0.003564
Average total loss: 0.105204
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-1.0753e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.102959
Average KL loss: 0.003564
Average total loss: 0.106523
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-9.3370e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.098165
Average KL loss: 0.003564
Average total loss: 0.101729
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-8.8868e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.100698
Average KL loss: 0.003564
Average total loss: 0.104262
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-1.0938e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.103813
Average KL loss: 0.003564
Average total loss: 0.107377
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-8.7469e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.101098
Average KL loss: 0.003564
Average total loss: 0.104662
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-7.6549e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.101058
Average KL loss: 0.003564
Average total loss: 0.104622
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-7.0970e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.106197
Average KL loss: 0.003564
Average total loss: 0.109762
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-1.1857e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.100160
Average KL loss: 0.003564
Average total loss: 0.103724
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-9.4037e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.099034
Average KL loss: 0.003564
Average total loss: 0.102598
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-7.4410e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.099823
Average KL loss: 0.003564
Average total loss: 0.103387
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-8.5713e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.103701
Average KL loss: 0.003564
Average total loss: 0.107266
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-9.5916e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.102383
Average KL loss: 0.003564
Average total loss: 0.105947
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-1.4036e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.101467
Average KL loss: 0.003564
Average total loss: 0.105031
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-1.3582e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.104614
Average KL loss: 0.003564
Average total loss: 0.108179
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-8.8513e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.103377
Average KL loss: 0.003564
Average total loss: 0.106941
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-1.1032e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.099898
Average KL loss: 0.003564
Average total loss: 0.103463
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-5.9280e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.104329
Average KL loss: 0.003564
Average total loss: 0.107894
tensor(0.0203, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-7.3926e-09, device='cuda:0')
 Percentile value: 2.3940497398376466
Non-zero model percentage: 0.5903157591819763%, Non-zero mask percentage: 0.5903157591819763%

--- Pruning Level [23/24]: ---
conv1.weight         | nonzeros =     152 /    1728             (  8.80%) | total_pruned =    1576 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      26 /   36864             (  0.07%) | total_pruned =   36838 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      42 /   36864             (  0.11%) | total_pruned =   36822 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     234 /   36864             (  0.63%) | total_pruned =   36630 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     487 /   36864             (  1.32%) | total_pruned =   36377 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1678 /   73728             (  2.28%) | total_pruned =   72050 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3613 /  147456             (  2.45%) | total_pruned =  143843 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     549 /    8192             (  6.70%) | total_pruned =    7643 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      63 /     128             ( 49.22%) | total_pruned =      65 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2087 /  147456             (  1.42%) | total_pruned =  145369 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2112 /  147456             (  1.43%) | total_pruned =  145344 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7427 /  294912             (  2.52%) | total_pruned =  287485 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   10746 /  589824             (  1.82%) | total_pruned =  579078 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     168 /     256             ( 65.62%) | total_pruned =      88 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1319 /   32768             (  4.03%) | total_pruned =   31449 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     120 /     256             ( 46.88%) | total_pruned =     136 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    4853 /  589824             (  0.82%) | total_pruned =  584971 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     114 /     256             ( 44.53%) | total_pruned =     142 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3820 /  589824             (  0.65%) | total_pruned =  586004 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     114 /     256             ( 44.53%) | total_pruned =     142 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   11357 / 1179648             (  0.96%) | total_pruned = 1168291 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     299 /     512             ( 58.40%) | total_pruned =     213 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    5887 / 2359296             (  0.25%) | total_pruned = 2353409 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     196 /     512             ( 38.28%) | total_pruned =     316 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      88 /     512             ( 17.19%) | total_pruned =     424 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     214 /  131072             (  0.16%) | total_pruned =  130858 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      81 /     512             ( 15.82%) | total_pruned =     431 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    2924 / 2359296             (  0.12%) | total_pruned = 2356372 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     159 /     512             ( 31.05%) | total_pruned =     353 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2589 / 2359296             (  0.11%) | total_pruned = 2356707 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     273 /     512             ( 53.32%) | total_pruned =     239 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     121 /     512             ( 23.63%) | total_pruned =     391 | shape = torch.Size([512])
linear.weight        | nonzeros =    1463 /    5120             ( 28.57%) | total_pruned =    3657 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 65990, pruned : 11112772, total: 11178762, Compression rate :     169.40x  ( 99.41% pruned)
Train Epoch: 55/100 Loss: 0.037933 Accuracy: 84.66 99.97 % Best test Accuracy: 85.56%
