Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/24]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2495e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302784
Average KL loss: 0.000238
Average total loss: 2.303021
tensor(2.1524e-05, device='cuda:0') tensor(1.4304e-06, device='cuda:0') tensor(-1.8841e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.303072
Average KL loss: 0.000252
Average total loss: 2.303324
tensor(2.8678e-05, device='cuda:0') tensor(2.1237e-06, device='cuda:0') tensor(-1.5648e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.302890
Average KL loss: 0.000262
Average total loss: 2.303151
tensor(3.6531e-05, device='cuda:0') tensor(2.9867e-06, device='cuda:0') tensor(-7.0837e-11, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.302848
Average KL loss: 0.000273
Average total loss: 2.303121
tensor(4.5550e-05, device='cuda:0') tensor(3.9135e-06, device='cuda:0') tensor(-2.5863e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.303081
Average KL loss: 0.000286
Average total loss: 2.303367
tensor(5.0177e-05, device='cuda:0') tensor(4.6136e-06, device='cuda:0') tensor(-2.5809e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.302809
Average KL loss: 0.000294
Average total loss: 2.303103
tensor(4.7773e-05, device='cuda:0') tensor(4.7941e-06, device='cuda:0') tensor(2.2917e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.302486
Average KL loss: 0.000300
Average total loss: 2.302786
tensor(6.1225e-05, device='cuda:0') tensor(5.8745e-06, device='cuda:0') tensor(-9.9136e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.302406
Average KL loss: 0.000319
Average total loss: 2.302726
tensor(7.3249e-05, device='cuda:0') tensor(7.1344e-06, device='cuda:0') tensor(-9.2138e-11, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.302480
Average KL loss: 0.000335
Average total loss: 2.302816
tensor(8.1198e-05, device='cuda:0') tensor(8.2985e-06, device='cuda:0') tensor(-3.1339e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.302155
Average KL loss: 0.000355
Average total loss: 2.302511
tensor(9.3260e-05, device='cuda:0') tensor(9.7565e-06, device='cuda:0') tensor(-5.5316e-11, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.302396
Average KL loss: 0.000372
Average total loss: 2.302768
tensor(0.0001, device='cuda:0') tensor(1.1582e-05, device='cuda:0') tensor(-8.6586e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.302121
Average KL loss: 0.000405
Average total loss: 2.302527
tensor(0.0001, device='cuda:0') tensor(1.3587e-05, device='cuda:0') tensor(-6.2388e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.301675
Average KL loss: 0.000436
Average total loss: 2.302112
tensor(0.0001, device='cuda:0') tensor(1.7392e-05, device='cuda:0') tensor(-7.4435e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.301547
Average KL loss: 0.000483
Average total loss: 2.302030
tensor(0.0002, device='cuda:0') tensor(1.9621e-05, device='cuda:0') tensor(3.3871e-11, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.301568
Average KL loss: 0.000524
Average total loss: 2.302091
tensor(0.0002, device='cuda:0') tensor(2.3171e-05, device='cuda:0') tensor(-3.0903e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.300760
Average KL loss: 0.000604
Average total loss: 2.301363
tensor(0.0002, device='cuda:0') tensor(3.0275e-05, device='cuda:0') tensor(-9.3059e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.300947
Average KL loss: 0.000679
Average total loss: 2.301627
tensor(0.0002, device='cuda:0') tensor(3.4695e-05, device='cuda:0') tensor(-1.2944e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.299989
Average KL loss: 0.000783
Average total loss: 2.300772
tensor(0.0003, device='cuda:0') tensor(4.3789e-05, device='cuda:0') tensor(-1.1885e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.298188
Average KL loss: 0.000931
Average total loss: 2.299119
tensor(0.0004, device='cuda:0') tensor(5.9206e-05, device='cuda:0') tensor(-2.5036e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.297188
Average KL loss: 0.001194
Average total loss: 2.298382
tensor(0.0005, device='cuda:0') tensor(7.9514e-05, device='cuda:0') tensor(-8.1646e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.294569
Average KL loss: 0.001507
Average total loss: 2.296076
tensor(0.0006, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-1.1809e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.292101
Average KL loss: 0.002024
Average total loss: 2.294125
tensor(0.0007, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-3.8378e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.285210
Average KL loss: 0.002698
Average total loss: 2.287908
tensor(0.0010, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-1.3597e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.280799
Average KL loss: 0.003688
Average total loss: 2.284487
tensor(0.0012, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.7316e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.267780
Average KL loss: 0.005056
Average total loss: 2.272836
tensor(0.0015, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.3009e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 2.246832
Average KL loss: 0.006923
Average total loss: 2.253755
tensor(0.0020, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.6819e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 2.224143
Average KL loss: 0.009556
Average total loss: 2.233699
tensor(0.0026, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-4.1531e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 2.186172
Average KL loss: 0.012714
Average total loss: 2.198887
tensor(0.0033, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-2.8943e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 2.149288
Average KL loss: 0.016797
Average total loss: 2.166085
tensor(0.0041, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.0443e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 2.095176
Average KL loss: 0.021520
Average total loss: 2.116696
tensor(0.0050, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-4.3650e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 2.040682
Average KL loss: 0.026712
Average total loss: 2.067394
tensor(0.0059, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-7.5284e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.968374
Average KL loss: 0.032510
Average total loss: 2.000885
tensor(0.0069, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-8.8118e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.907196
Average KL loss: 0.038442
Average total loss: 1.945639
tensor(0.0078, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-9.5019e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.860836
Average KL loss: 0.044576
Average total loss: 1.905411
tensor(0.0086, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.0879e-07, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.783952
Average KL loss: 0.050483
Average total loss: 1.834434
tensor(0.0094, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.2472e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.717388
Average KL loss: 0.055754
Average total loss: 1.773142
tensor(0.0101, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-9.2280e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.652066
Average KL loss: 0.060563
Average total loss: 1.712630
tensor(0.0107, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.1258e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.598531
Average KL loss: 0.064900
Average total loss: 1.663432
tensor(0.0113, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.0607e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.559782
Average KL loss: 0.068495
Average total loss: 1.628278
tensor(0.0117, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.2142e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.507472
Average KL loss: 0.072035
Average total loss: 1.579507
tensor(0.0120, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0386e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.452641
Average KL loss: 0.075097
Average total loss: 1.527738
tensor(0.0124, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.1606e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.429610
Average KL loss: 0.077792
Average total loss: 1.507402
tensor(0.0127, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-9.4762e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.365494
Average KL loss: 0.080253
Average total loss: 1.445747
tensor(0.0129, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-9.3129e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.345926
Average KL loss: 0.082721
Average total loss: 1.428646
tensor(0.0132, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.0374e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.309089
Average KL loss: 0.084979
Average total loss: 1.394068
tensor(0.0134, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.0528e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.272356
Average KL loss: 0.086814
Average total loss: 1.359170
tensor(0.0135, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-9.2294e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.234033
Average KL loss: 0.088350
Average total loss: 1.322383
tensor(0.0136, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-9.8530e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.202692
Average KL loss: 0.089587
Average total loss: 1.292280
tensor(0.0137, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.4511e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.191873
Average KL loss: 0.090848
Average total loss: 1.282721
tensor(0.0138, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.9051e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.146692
Average KL loss: 0.091967
Average total loss: 1.238659
tensor(0.0139, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-8.7581e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.132930
Average KL loss: 0.093039
Average total loss: 1.225969
tensor(0.0140, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.9722e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.112927
Average KL loss: 0.093979
Average total loss: 1.206906
tensor(0.0140, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-7.9185e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.090079
Average KL loss: 0.094765
Average total loss: 1.184844
tensor(0.0140, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-8.1129e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.095018
Average KL loss: 0.095504
Average total loss: 1.190521
tensor(0.0141, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.8363e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.049257
Average KL loss: 0.096190
Average total loss: 1.145446
tensor(0.0141, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.8971e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.043943
Average KL loss: 0.096838
Average total loss: 1.140781
tensor(0.0141, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-8.0622e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.020781
Average KL loss: 0.097522
Average total loss: 1.118303
tensor(0.0141, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.6813e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.008655
Average KL loss: 0.097985
Average total loss: 1.106640
tensor(0.0141, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.6115e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.988220
Average KL loss: 0.098390
Average total loss: 1.086610
tensor(0.0141, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-8.1561e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.992085
Average KL loss: 0.098822
Average total loss: 1.090907
tensor(0.0141, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-7.2021e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.942284
Average KL loss: 0.099130
Average total loss: 1.041413
tensor(0.0141, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.6481e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.957085
Average KL loss: 0.099315
Average total loss: 1.056400
tensor(0.0141, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-8.8074e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.918881
Average KL loss: 0.099534
Average total loss: 1.018415
tensor(0.0140, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.4258e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.905253
Average KL loss: 0.099522
Average total loss: 1.004775
tensor(0.0140, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.9652e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.901939
Average KL loss: 0.099619
Average total loss: 1.001559
tensor(0.0139, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.3500e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.903804
Average KL loss: 0.099659
Average total loss: 1.003464
tensor(0.0139, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-8.9946e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.871726
Average KL loss: 0.099739
Average total loss: 0.971465
tensor(0.0139, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.5073e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.860811
Average KL loss: 0.099711
Average total loss: 0.960522
tensor(0.0138, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-7.1923e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.856319
Average KL loss: 0.099709
Average total loss: 0.956028
tensor(0.0138, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.8137e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.850031
Average KL loss: 0.099682
Average total loss: 0.949714
tensor(0.0138, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-7.1337e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.832297
Average KL loss: 0.099752
Average total loss: 0.932049
tensor(0.0138, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.7215e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.842729
Average KL loss: 0.099812
Average total loss: 0.942541
tensor(0.0138, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.7839e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.823157
Average KL loss: 0.099855
Average total loss: 0.923012
tensor(0.0137, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.8850e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.792652
Average KL loss: 0.099785
Average total loss: 0.892437
tensor(0.0137, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.9422e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.801965
Average KL loss: 0.099643
Average total loss: 0.901608
tensor(0.0136, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.2741e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.792783
Average KL loss: 0.099575
Average total loss: 0.892358
tensor(0.0136, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-7.3942e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.784176
Average KL loss: 0.099568
Average total loss: 0.883743
tensor(0.0136, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.1540e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.779601
Average KL loss: 0.099436
Average total loss: 0.879038
tensor(0.0135, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.7236e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.761099
Average KL loss: 0.099334
Average total loss: 0.860434
tensor(0.0135, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.4336e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.758091
Average KL loss: 0.099238
Average total loss: 0.857329
tensor(0.0135, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.4057e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.754753
Average KL loss: 0.099178
Average total loss: 0.853931
tensor(0.0134, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.0385e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.739377
Average KL loss: 0.099113
Average total loss: 0.838490
tensor(0.0134, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.0461e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.740048
Average KL loss: 0.099041
Average total loss: 0.839090
tensor(0.0133, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.1654e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.735712
Average KL loss: 0.098941
Average total loss: 0.834653
tensor(0.0133, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.8988e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.715999
Average KL loss: 0.098801
Average total loss: 0.814800
tensor(0.0133, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.7008e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.708026
Average KL loss: 0.098662
Average total loss: 0.806688
tensor(0.0132, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.8525e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.711642
Average KL loss: 0.098483
Average total loss: 0.810125
tensor(0.0132, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.4723e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.693515
Average KL loss: 0.098339
Average total loss: 0.791854
tensor(0.0132, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.2194e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.691551
Average KL loss: 0.098186
Average total loss: 0.789737
tensor(0.0131, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.7765e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.686402
Average KL loss: 0.098140
Average total loss: 0.784542
tensor(0.0131, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.2266e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.700545
Average KL loss: 0.098065
Average total loss: 0.798610
tensor(0.0131, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.8400e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.677219
Average KL loss: 0.097975
Average total loss: 0.775194
tensor(0.0130, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.7903e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.666041
Average KL loss: 0.097796
Average total loss: 0.763837
tensor(0.0130, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.9345e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.671770
Average KL loss: 0.097610
Average total loss: 0.769381
tensor(0.0130, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.8256e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.668836
Average KL loss: 0.097500
Average total loss: 0.766336
tensor(0.0129, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.2023e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.652346
Average KL loss: 0.097360
Average total loss: 0.749706
tensor(0.0129, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.4690e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.657028
Average KL loss: 0.097240
Average total loss: 0.754268
tensor(0.0129, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.1722e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.647097
Average KL loss: 0.097177
Average total loss: 0.744273
tensor(0.0128, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.9731e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.641298
Average KL loss: 0.097069
Average total loss: 0.738367
tensor(0.0128, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.3216e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.639825
Average KL loss: 0.097022
Average total loss: 0.736846
tensor(0.0128, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.1577e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.626074
Average KL loss: 0.096898
Average total loss: 0.722972
tensor(0.0128, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.2397e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.625508
Average KL loss: 0.096774
Average total loss: 0.722282
tensor(0.0127, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.1583e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.624300
Average KL loss: 0.096638
Average total loss: 0.720938
tensor(0.0127, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.2144e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.602780
Average KL loss: 0.096503
Average total loss: 0.699283
tensor(0.0127, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.6236e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.600632
Average KL loss: 0.096386
Average total loss: 0.697017
tensor(0.0127, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.8265e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.594321
Average KL loss: 0.096271
Average total loss: 0.690592
tensor(0.0126, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.2482e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.598352
Average KL loss: 0.096078
Average total loss: 0.694431
tensor(0.0126, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-6.6973e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.599009
Average KL loss: 0.095934
Average total loss: 0.694943
tensor(0.0126, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.2903e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.589385
Average KL loss: 0.095779
Average total loss: 0.685165
tensor(0.0125, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.9469e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.581655
Average KL loss: 0.095637
Average total loss: 0.677291
tensor(0.0125, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.1913e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.580251
Average KL loss: 0.095503
Average total loss: 0.675755
tensor(0.0125, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.7782e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.573504
Average KL loss: 0.095449
Average total loss: 0.668953
tensor(0.0125, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.9753e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.576909
Average KL loss: 0.095246
Average total loss: 0.672155
tensor(0.0124, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.4733e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.567314
Average KL loss: 0.095143
Average total loss: 0.662457
tensor(0.0124, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.8172e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.559848
Average KL loss: 0.095070
Average total loss: 0.654919
tensor(0.0124, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.7144e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.563193
Average KL loss: 0.094906
Average total loss: 0.658099
tensor(0.0123, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.4438e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.548870
Average KL loss: 0.094767
Average total loss: 0.643637
tensor(0.0123, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.2526e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.556459
Average KL loss: 0.094621
Average total loss: 0.651081
tensor(0.0123, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.0196e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.548901
Average KL loss: 0.094529
Average total loss: 0.643429
tensor(0.0122, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.9237e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.539659
Average KL loss: 0.094438
Average total loss: 0.634097
tensor(0.0122, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.5091e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.546736
Average KL loss: 0.094334
Average total loss: 0.641070
tensor(0.0122, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.2235e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.548298
Average KL loss: 0.094296
Average total loss: 0.642594
tensor(0.0122, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.6042e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.541824
Average KL loss: 0.094208
Average total loss: 0.636032
tensor(0.0122, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.2627e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.523251
Average KL loss: 0.094092
Average total loss: 0.617343
tensor(0.0121, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.7170e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.531462
Average KL loss: 0.094033
Average total loss: 0.625495
tensor(0.0121, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.0327e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.517025
Average KL loss: 0.093885
Average total loss: 0.610910
tensor(0.0121, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.1807e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.523878
Average KL loss: 0.093769
Average total loss: 0.617647
tensor(0.0121, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.2031e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.520093
Average KL loss: 0.093648
Average total loss: 0.613741
tensor(0.0120, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.9156e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.517140
Average KL loss: 0.093559
Average total loss: 0.610700
tensor(0.0120, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.4361e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.504469
Average KL loss: 0.093436
Average total loss: 0.597905
tensor(0.0120, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.9145e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.518100
Average KL loss: 0.093321
Average total loss: 0.611421
tensor(0.0120, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.0695e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.502701
Average KL loss: 0.093249
Average total loss: 0.595950
tensor(0.0119, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.0636e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.508864
Average KL loss: 0.093112
Average total loss: 0.601976
tensor(0.0119, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.6091e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.508866
Average KL loss: 0.093088
Average total loss: 0.601954
tensor(0.0119, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.1975e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.492239
Average KL loss: 0.093053
Average total loss: 0.585292
tensor(0.0119, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.6401e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.490387
Average KL loss: 0.092955
Average total loss: 0.583343
tensor(0.0119, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.0340e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.492227
Average KL loss: 0.092879
Average total loss: 0.585107
tensor(0.0119, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.0021e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.493675
Average KL loss: 0.092791
Average total loss: 0.586466
tensor(0.0119, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.1785e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.483209
Average KL loss: 0.092736
Average total loss: 0.575945
tensor(0.0118, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.1267e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.476047
Average KL loss: 0.092666
Average total loss: 0.568713
tensor(0.0118, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.4097e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.479902
Average KL loss: 0.092579
Average total loss: 0.572481
tensor(0.0118, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.0415e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.480659
Average KL loss: 0.092516
Average total loss: 0.573174
tensor(0.0118, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.4700e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.473626
Average KL loss: 0.092465
Average total loss: 0.566091
tensor(0.0118, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.3739e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.475503
Average KL loss: 0.092395
Average total loss: 0.567899
tensor(0.0118, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.9539e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.467192
Average KL loss: 0.092330
Average total loss: 0.559522
tensor(0.0117, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.7471e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.462728
Average KL loss: 0.092204
Average total loss: 0.554932
tensor(0.0117, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.9285e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.463601
Average KL loss: 0.092090
Average total loss: 0.555691
tensor(0.0117, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.2909e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.458679
Average KL loss: 0.091972
Average total loss: 0.550651
tensor(0.0117, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.8238e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.446606
Average KL loss: 0.091842
Average total loss: 0.538449
tensor(0.0117, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.9424e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.453285
Average KL loss: 0.091759
Average total loss: 0.545044
tensor(0.0116, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.6624e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.455279
Average KL loss: 0.091682
Average total loss: 0.546961
tensor(0.0116, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3117e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.450612
Average KL loss: 0.091619
Average total loss: 0.542230
tensor(0.0116, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.4026e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.436551
Average KL loss: 0.091500
Average total loss: 0.528051
tensor(0.0116, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.9661e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.449796
Average KL loss: 0.091396
Average total loss: 0.541193
tensor(0.0116, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.9935e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.448876
Average KL loss: 0.091333
Average total loss: 0.540210
tensor(0.0116, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.2787e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.428783
Average KL loss: 0.091299
Average total loss: 0.520083
tensor(0.0116, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.0340e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.431747
Average KL loss: 0.091172
Average total loss: 0.522920
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.6800e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.434417
Average KL loss: 0.091095
Average total loss: 0.525512
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3386e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.436909
Average KL loss: 0.091022
Average total loss: 0.527931
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.3018e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.438702
Average KL loss: 0.090996
Average total loss: 0.529697
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.6819e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.425258
Average KL loss: 0.090961
Average total loss: 0.516219
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.7779e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.430923
Average KL loss: 0.090921
Average total loss: 0.521843
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.0678e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.431937
Average KL loss: 0.090901
Average total loss: 0.522838
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.9149e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.420391
Average KL loss: 0.090837
Average total loss: 0.511228
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.1540e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.420446
Average KL loss: 0.090759
Average total loss: 0.511206
tensor(0.0114, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.3577e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.426720
Average KL loss: 0.090696
Average total loss: 0.517416
tensor(0.0114, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.0425e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.414251
Average KL loss: 0.090646
Average total loss: 0.504897
tensor(0.0114, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.1868e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.410241
Average KL loss: 0.090547
Average total loss: 0.500788
tensor(0.0114, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.1651e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.409063
Average KL loss: 0.090440
Average total loss: 0.499503
tensor(0.0114, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.5064e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.406166
Average KL loss: 0.090388
Average total loss: 0.496555
tensor(0.0114, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.6049e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.404780
Average KL loss: 0.090298
Average total loss: 0.495078
tensor(0.0114, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.5409e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.411799
Average KL loss: 0.090272
Average total loss: 0.502071
tensor(0.0113, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.4672e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.400463
Average KL loss: 0.090255
Average total loss: 0.490718
tensor(0.0113, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.7945e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.398597
Average KL loss: 0.090192
Average total loss: 0.488789
tensor(0.0113, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.7315e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.399428
Average KL loss: 0.090095
Average total loss: 0.489523
tensor(0.0113, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.8066e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.398995
Average KL loss: 0.090065
Average total loss: 0.489060
tensor(0.0113, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.0002e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.396140
Average KL loss: 0.089966
Average total loss: 0.486106
tensor(0.0113, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.0582e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.399399
Average KL loss: 0.089909
Average total loss: 0.489308
tensor(0.0113, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.6049e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.386571
Average KL loss: 0.089877
Average total loss: 0.476448
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.6847e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.390330
Average KL loss: 0.089817
Average total loss: 0.480148
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.1636e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.391939
Average KL loss: 0.089742
Average total loss: 0.481681
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.4647e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.384593
Average KL loss: 0.089691
Average total loss: 0.474284
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.1607e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.386627
Average KL loss: 0.089650
Average total loss: 0.476277
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.8871e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.383859
Average KL loss: 0.089636
Average total loss: 0.473495
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.4482e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.385299
Average KL loss: 0.089600
Average total loss: 0.474898
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.9812e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.378705
Average KL loss: 0.089514
Average total loss: 0.468219
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.8860e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.377478
Average KL loss: 0.089431
Average total loss: 0.466909
tensor(0.0111, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.4413e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.380714
Average KL loss: 0.089371
Average total loss: 0.470085
tensor(0.0111, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.1176e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.372511
Average KL loss: 0.089312
Average total loss: 0.461823
tensor(0.0111, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.9422e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.369916
Average KL loss: 0.089247
Average total loss: 0.459163
tensor(0.0111, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.0304e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.367963
Average KL loss: 0.089156
Average total loss: 0.457119
tensor(0.0111, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.1143e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.369760
Average KL loss: 0.089102
Average total loss: 0.458862
tensor(0.0111, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.9515e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.363148
Average KL loss: 0.089044
Average total loss: 0.452191
tensor(0.0111, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.0506e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.367882
Average KL loss: 0.089015
Average total loss: 0.456898
tensor(0.0111, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.2777e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.370037
Average KL loss: 0.088941
Average total loss: 0.458978
tensor(0.0111, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.9141e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.365662
Average KL loss: 0.088938
Average total loss: 0.454601
tensor(0.0111, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.8167e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.359931
Average KL loss: 0.088873
Average total loss: 0.448804
tensor(0.0111, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.7600e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.360399
Average KL loss: 0.088834
Average total loss: 0.449233
tensor(0.0110, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.8086e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.363123
Average KL loss: 0.088806
Average total loss: 0.451929
tensor(0.0110, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.8623e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.357688
Average KL loss: 0.088783
Average total loss: 0.446471
 Percentile value: -7.23507735528983e-05
Non-zero model percentage: 80.0%, Non-zero mask percentage: 80.0%

--- Pruning Level [1/24]: ---
conv1.weight         | nonzeros =    1586 /    1728             ( 91.78%) | total_pruned =     142 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   32629 /   36864             ( 88.51%) | total_pruned =    4235 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   28208 /   36864             ( 76.52%) | total_pruned =    8656 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   26429 /   36864             ( 71.69%) | total_pruned =   10435 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   27866 /   36864             ( 75.59%) | total_pruned =    8998 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   47056 /   73728             ( 63.82%) | total_pruned =   26672 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   94384 /  147456             ( 64.01%) | total_pruned =   53072 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5554 /    8192             ( 67.80%) | total_pruned =    2638 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  102210 /  147456             ( 69.32%) | total_pruned =   45246 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  109062 /  147456             ( 73.96%) | total_pruned =   38394 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  176913 /  294912             ( 59.99%) | total_pruned =  117999 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  356630 /  589824             ( 60.46%) | total_pruned =  233194 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   21417 /   32768             ( 65.36%) | total_pruned =   11351 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  379682 /  589824             ( 64.37%) | total_pruned =  210142 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  423655 /  589824             ( 71.83%) | total_pruned =  166169 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  764959 / 1179648             ( 64.85%) | total_pruned =  414689 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1903579 / 2359296             ( 80.68%) | total_pruned =  455717 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     485 /     512             ( 94.73%) | total_pruned =      27 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     290 /     512             ( 56.64%) | total_pruned =     222 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  107743 /  131072             ( 82.20%) | total_pruned =   23329 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     287 /     512             ( 56.05%) | total_pruned =     225 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1982312 / 2359296             ( 84.02%) | total_pruned =  376984 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2334972 / 2359296             ( 98.97%) | total_pruned =   24324 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5028 /    5120             ( 98.20%) | total_pruned =      92 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 8943010, pruned : 2235752, total: 11178762, Compression rate :       1.25x  ( 20.00% pruned)
Train Epoch: 68/100 Loss: 0.016235 Accuracy: 90.18 100.00 % Best test Accuracy: 90.20%
tensor(0.0110, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.4287e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.917919
Average KL loss: 0.082759
Average total loss: 1.000678
tensor(0.0127, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.2145e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.885137
Average KL loss: 0.076561
Average total loss: 0.961698
tensor(0.0133, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.1511e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.852814
Average KL loss: 0.073715
Average total loss: 0.926530
tensor(0.0136, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.9137e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.810073
Average KL loss: 0.072345
Average total loss: 0.882418
tensor(0.0138, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.2589e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.771599
Average KL loss: 0.071707
Average total loss: 0.843306
tensor(0.0139, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-8.8999e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.754274
Average KL loss: 0.071454
Average total loss: 0.825729
tensor(0.0139, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.4367e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.706502
Average KL loss: 0.071385
Average total loss: 0.777887
tensor(0.0140, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.1555e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.716076
Average KL loss: 0.071528
Average total loss: 0.787604
tensor(0.0140, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.2802e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.676531
Average KL loss: 0.071666
Average total loss: 0.748196
tensor(0.0140, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-6.4337e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.665328
Average KL loss: 0.072014
Average total loss: 0.737342
tensor(0.0140, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-6.4667e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.660089
Average KL loss: 0.072327
Average total loss: 0.732415
tensor(0.0140, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-7.9095e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.668177
Average KL loss: 0.072686
Average total loss: 0.740863
tensor(0.0139, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-7.1494e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.613640
Average KL loss: 0.073088
Average total loss: 0.686728
tensor(0.0139, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.5792e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.609449
Average KL loss: 0.073433
Average total loss: 0.682882
tensor(0.0139, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.2213e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.599350
Average KL loss: 0.073785
Average total loss: 0.673135
tensor(0.0139, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.8370e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.605290
Average KL loss: 0.074146
Average total loss: 0.679436
tensor(0.0139, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-7.1455e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.596490
Average KL loss: 0.074525
Average total loss: 0.671015
tensor(0.0138, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.9115e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.575415
Average KL loss: 0.074905
Average total loss: 0.650320
tensor(0.0138, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.4034e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.562902
Average KL loss: 0.075272
Average total loss: 0.638174
tensor(0.0138, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.2418e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.555959
Average KL loss: 0.075587
Average total loss: 0.631546
tensor(0.0137, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.9274e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.566510
Average KL loss: 0.075908
Average total loss: 0.642418
tensor(0.0137, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.3424e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.538335
Average KL loss: 0.076200
Average total loss: 0.614535
tensor(0.0137, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.5337e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.537510
Average KL loss: 0.076434
Average total loss: 0.613944
tensor(0.0136, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.0411e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.547204
Average KL loss: 0.076725
Average total loss: 0.623930
tensor(0.0136, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.2771e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.523121
Average KL loss: 0.077063
Average total loss: 0.600185
tensor(0.0136, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.6865e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.521329
Average KL loss: 0.077403
Average total loss: 0.598732
tensor(0.0136, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.8917e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.519792
Average KL loss: 0.077624
Average total loss: 0.597416
tensor(0.0135, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.9367e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.519658
Average KL loss: 0.077900
Average total loss: 0.597557
tensor(0.0135, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.8897e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.518406
Average KL loss: 0.078135
Average total loss: 0.596541
tensor(0.0135, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.1513e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.510923
Average KL loss: 0.078398
Average total loss: 0.589321
tensor(0.0135, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.4111e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.498450
Average KL loss: 0.078709
Average total loss: 0.577159
tensor(0.0134, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.9978e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.486404
Average KL loss: 0.078949
Average total loss: 0.565353
tensor(0.0134, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.9619e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.503094
Average KL loss: 0.079196
Average total loss: 0.582290
tensor(0.0134, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.9165e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.496376
Average KL loss: 0.079385
Average total loss: 0.575761
tensor(0.0133, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.8091e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.490405
Average KL loss: 0.079586
Average total loss: 0.569991
tensor(0.0133, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.6042e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.477158
Average KL loss: 0.079800
Average total loss: 0.556958
tensor(0.0133, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.4476e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.468816
Average KL loss: 0.080005
Average total loss: 0.548821
tensor(0.0133, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.3247e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.476696
Average KL loss: 0.080272
Average total loss: 0.556969
tensor(0.0133, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.9677e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.465233
Average KL loss: 0.080498
Average total loss: 0.545731
tensor(0.0133, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.3080e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.475610
Average KL loss: 0.080663
Average total loss: 0.556273
tensor(0.0132, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.2128e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.443891
Average KL loss: 0.080845
Average total loss: 0.524736
tensor(0.0132, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.7870e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.455143
Average KL loss: 0.080993
Average total loss: 0.536136
tensor(0.0132, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.7077e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.446973
Average KL loss: 0.081226
Average total loss: 0.528199
tensor(0.0132, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.4082e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.439525
Average KL loss: 0.081403
Average total loss: 0.520929
tensor(0.0132, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.7576e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.438328
Average KL loss: 0.081549
Average total loss: 0.519877
tensor(0.0131, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.7902e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.457891
Average KL loss: 0.081697
Average total loss: 0.539588
tensor(0.0131, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.0618e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.435136
Average KL loss: 0.081816
Average total loss: 0.516952
tensor(0.0131, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.6988e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.433068
Average KL loss: 0.081965
Average total loss: 0.515033
tensor(0.0131, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.3843e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.426099
Average KL loss: 0.082100
Average total loss: 0.508200
tensor(0.0130, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.4414e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.414883
Average KL loss: 0.082196
Average total loss: 0.497078
tensor(0.0130, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.3760e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.428656
Average KL loss: 0.082297
Average total loss: 0.510953
tensor(0.0130, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.9725e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.414468
Average KL loss: 0.082459
Average total loss: 0.496927
tensor(0.0130, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.9901e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.412553
Average KL loss: 0.082568
Average total loss: 0.495121
tensor(0.0130, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.0402e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.413246
Average KL loss: 0.082659
Average total loss: 0.495905
tensor(0.0129, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.1877e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.409843
Average KL loss: 0.082762
Average total loss: 0.492605
tensor(0.0129, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.8973e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.418887
Average KL loss: 0.082856
Average total loss: 0.501743
tensor(0.0129, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.6584e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.402538
Average KL loss: 0.083024
Average total loss: 0.485562
tensor(0.0129, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.9361e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.394672
Average KL loss: 0.083097
Average total loss: 0.477769
tensor(0.0129, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.5489e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.398896
Average KL loss: 0.083175
Average total loss: 0.482071
tensor(0.0128, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.8021e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.405280
Average KL loss: 0.083301
Average total loss: 0.488581
tensor(0.0128, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.7796e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.387688
Average KL loss: 0.083406
Average total loss: 0.471093
tensor(0.0128, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.2437e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.393775
Average KL loss: 0.083464
Average total loss: 0.477239
tensor(0.0128, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.0103e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.376385
Average KL loss: 0.083501
Average total loss: 0.459886
tensor(0.0128, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.9403e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.392302
Average KL loss: 0.083543
Average total loss: 0.475845
tensor(0.0128, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.1083e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.387311
Average KL loss: 0.083671
Average total loss: 0.470982
tensor(0.0128, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.2534e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.400839
Average KL loss: 0.083761
Average total loss: 0.484601
tensor(0.0127, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.1485e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.395669
Average KL loss: 0.083887
Average total loss: 0.479555
tensor(0.0127, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.2971e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.381126
Average KL loss: 0.083987
Average total loss: 0.465113
tensor(0.0127, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.1924e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.372150
Average KL loss: 0.084062
Average total loss: 0.456212
tensor(0.0127, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.0333e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.385281
Average KL loss: 0.084120
Average total loss: 0.469401
tensor(0.0127, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.9489e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.372346
Average KL loss: 0.084242
Average total loss: 0.456588
tensor(0.0127, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.7171e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.377425
Average KL loss: 0.084266
Average total loss: 0.461691
tensor(0.0127, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.9736e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.374175
Average KL loss: 0.084327
Average total loss: 0.458502
tensor(0.0126, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.1030e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.371325
Average KL loss: 0.084350
Average total loss: 0.455675
tensor(0.0126, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.0542e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.371878
Average KL loss: 0.084403
Average total loss: 0.456281
tensor(0.0126, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.8383e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.359546
Average KL loss: 0.084477
Average total loss: 0.444022
tensor(0.0126, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.5260e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.369040
Average KL loss: 0.084516
Average total loss: 0.453556
tensor(0.0126, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.7352e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.359571
Average KL loss: 0.084619
Average total loss: 0.444190
tensor(0.0126, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.5561e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.350600
Average KL loss: 0.084629
Average total loss: 0.435229
tensor(0.0126, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.7903e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.354202
Average KL loss: 0.084650
Average total loss: 0.438852
tensor(0.0125, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.3143e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.352413
Average KL loss: 0.084690
Average total loss: 0.437103
tensor(0.0126, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.6329e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.356593
Average KL loss: 0.084783
Average total loss: 0.441376
tensor(0.0125, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.3837e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.355722
Average KL loss: 0.084808
Average total loss: 0.440530
tensor(0.0125, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.9192e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.351852
Average KL loss: 0.084914
Average total loss: 0.436766
tensor(0.0125, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.3711e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.341403
Average KL loss: 0.084932
Average total loss: 0.426335
tensor(0.0125, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.2951e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.335979
Average KL loss: 0.084978
Average total loss: 0.420956
tensor(0.0125, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.4066e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.348828
Average KL loss: 0.084964
Average total loss: 0.433792
tensor(0.0125, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.6363e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.345055
Average KL loss: 0.085011
Average total loss: 0.430065
tensor(0.0125, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.2026e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.344895
Average KL loss: 0.085033
Average total loss: 0.429928
tensor(0.0124, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.3090e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.342113
Average KL loss: 0.085105
Average total loss: 0.427217
tensor(0.0124, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.8548e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.338460
Average KL loss: 0.085152
Average total loss: 0.423612
tensor(0.0124, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.9149e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.330840
Average KL loss: 0.085215
Average total loss: 0.416055
tensor(0.0124, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.6563e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.332606
Average KL loss: 0.085231
Average total loss: 0.417837
tensor(0.0124, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.7464e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.337932
Average KL loss: 0.085233
Average total loss: 0.423165
tensor(0.0124, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.7012e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.331112
Average KL loss: 0.085262
Average total loss: 0.416374
tensor(0.0124, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.8081e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.329677
Average KL loss: 0.085287
Average total loss: 0.414964
tensor(0.0124, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.6249e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.338009
Average KL loss: 0.085290
Average total loss: 0.423298
tensor(0.0124, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.5226e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.328085
Average KL loss: 0.085307
Average total loss: 0.413392
tensor(0.0124, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.5096e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.318280
Average KL loss: 0.085350
Average total loss: 0.403631
tensor(0.0123, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.8372e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.327616
Average KL loss: 0.085372
Average total loss: 0.412988
tensor(0.0123, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.6768e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.320977
Average KL loss: 0.085396
Average total loss: 0.406373
tensor(0.0123, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.1588e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.317877
Average KL loss: 0.085391
Average total loss: 0.403268
tensor(0.0123, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.8353e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.320784
Average KL loss: 0.085432
Average total loss: 0.406216
tensor(0.0123, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.9860e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.320558
Average KL loss: 0.085486
Average total loss: 0.406044
tensor(0.0123, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.1838e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.327409
Average KL loss: 0.085503
Average total loss: 0.412911
tensor(0.0123, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.1837e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.305221
Average KL loss: 0.085495
Average total loss: 0.390717
tensor(0.0123, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.7123e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.307419
Average KL loss: 0.085486
Average total loss: 0.392906
tensor(0.0123, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.7964e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.301328
Average KL loss: 0.085486
Average total loss: 0.386814
tensor(0.0122, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.9901e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.318508
Average KL loss: 0.085534
Average total loss: 0.404043
tensor(0.0122, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.7350e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.316734
Average KL loss: 0.085579
Average total loss: 0.402314
tensor(0.0122, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-9.5058e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.294851
Average KL loss: 0.085596
Average total loss: 0.380447
tensor(0.0122, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.6790e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.300531
Average KL loss: 0.085571
Average total loss: 0.386102
tensor(0.0122, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.7417e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.303919
Average KL loss: 0.085566
Average total loss: 0.389484
tensor(0.0122, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.7076e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.301030
Average KL loss: 0.085577
Average total loss: 0.386608
tensor(0.0122, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.7238e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.311720
Average KL loss: 0.085611
Average total loss: 0.397332
tensor(0.0122, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.0370e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.309142
Average KL loss: 0.085655
Average total loss: 0.394797
tensor(0.0122, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.9922e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.311714
Average KL loss: 0.085698
Average total loss: 0.397412
tensor(0.0122, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-8.7635e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.304016
Average KL loss: 0.085752
Average total loss: 0.389768
tensor(0.0122, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.4776e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.298076
Average KL loss: 0.085805
Average total loss: 0.383882
tensor(0.0122, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.9420e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.294986
Average KL loss: 0.085765
Average total loss: 0.380751
tensor(0.0122, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.4326e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.295465
Average KL loss: 0.085768
Average total loss: 0.381233
tensor(0.0121, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.1344e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.290966
Average KL loss: 0.085739
Average total loss: 0.376705
tensor(0.0121, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.7083e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.286649
Average KL loss: 0.085709
Average total loss: 0.372358
tensor(0.0121, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.8160e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.282070
Average KL loss: 0.085668
Average total loss: 0.367737
tensor(0.0121, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.5945e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.284447
Average KL loss: 0.085646
Average total loss: 0.370093
tensor(0.0121, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.5562e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.289362
Average KL loss: 0.085671
Average total loss: 0.375033
tensor(0.0121, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.7842e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.286334
Average KL loss: 0.085668
Average total loss: 0.372002
tensor(0.0121, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.5484e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.287027
Average KL loss: 0.085657
Average total loss: 0.372684
tensor(0.0121, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.8214e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.286576
Average KL loss: 0.085646
Average total loss: 0.372223
tensor(0.0121, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-2.3259e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.288910
Average KL loss: 0.085653
Average total loss: 0.374563
tensor(0.0121, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.5109e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.280195
Average KL loss: 0.085660
Average total loss: 0.365856
tensor(0.0121, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-2.2252e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.282826
Average KL loss: 0.085690
Average total loss: 0.368516
tensor(0.0121, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.7567e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.280067
Average KL loss: 0.085717
Average total loss: 0.365784
tensor(0.0121, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.4068e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.280905
Average KL loss: 0.085723
Average total loss: 0.366627
tensor(0.0120, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.3543e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.283911
Average KL loss: 0.085735
Average total loss: 0.369646
tensor(0.0120, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.0537e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.288632
Average KL loss: 0.085752
Average total loss: 0.374384
tensor(0.0120, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.1266e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.281283
Average KL loss: 0.085759
Average total loss: 0.367042
tensor(0.0120, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.8995e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.273909
Average KL loss: 0.085759
Average total loss: 0.359668
tensor(0.0120, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.0076e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.276046
Average KL loss: 0.085762
Average total loss: 0.361808
tensor(0.0120, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.2155e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.273336
Average KL loss: 0.085773
Average total loss: 0.359108
tensor(0.0120, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.9366e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.278444
Average KL loss: 0.085762
Average total loss: 0.364206
tensor(0.0120, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.9589e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.267013
Average KL loss: 0.085762
Average total loss: 0.352776
tensor(0.0120, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.9192e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.277190
Average KL loss: 0.085767
Average total loss: 0.362957
tensor(0.0120, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.1833e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.274634
Average KL loss: 0.085761
Average total loss: 0.360394
tensor(0.0119, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.8848e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.267611
Average KL loss: 0.085745
Average total loss: 0.353356
tensor(0.0120, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.8588e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.272383
Average KL loss: 0.085774
Average total loss: 0.358157
tensor(0.0119, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.3057e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.263304
Average KL loss: 0.085758
Average total loss: 0.349062
tensor(0.0119, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.7393e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.263018
Average KL loss: 0.085712
Average total loss: 0.348730
tensor(0.0119, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.2923e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.264683
Average KL loss: 0.085665
Average total loss: 0.350348
tensor(0.0119, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.9028e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.258731
Average KL loss: 0.085630
Average total loss: 0.344361
tensor(0.0119, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.5651e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.261597
Average KL loss: 0.085596
Average total loss: 0.347192
tensor(0.0119, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.8241e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.262293
Average KL loss: 0.085577
Average total loss: 0.347869
tensor(0.0119, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.0481e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.260150
Average KL loss: 0.085552
Average total loss: 0.345702
tensor(0.0119, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.2182e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.263625
Average KL loss: 0.085575
Average total loss: 0.349200
tensor(0.0119, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.6331e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.259894
Average KL loss: 0.085559
Average total loss: 0.345453
tensor(0.0119, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.5825e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.263781
Average KL loss: 0.085528
Average total loss: 0.349309
tensor(0.0119, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.0407e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.260977
Average KL loss: 0.085488
Average total loss: 0.346465
tensor(0.0119, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.7118e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.247261
Average KL loss: 0.085483
Average total loss: 0.332745
tensor(0.0118, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.7090e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.260932
Average KL loss: 0.085489
Average total loss: 0.346421
tensor(0.0119, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.1665e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.265450
Average KL loss: 0.085525
Average total loss: 0.350975
tensor(0.0118, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.5930e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.245142
Average KL loss: 0.085505
Average total loss: 0.330648
tensor(0.0118, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.4034e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.256251
Average KL loss: 0.085470
Average total loss: 0.341721
tensor(0.0118, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.0575e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.248710
Average KL loss: 0.085450
Average total loss: 0.334160
tensor(0.0118, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.1306e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.256188
Average KL loss: 0.085426
Average total loss: 0.341613
tensor(0.0118, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.5354e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.245040
Average KL loss: 0.085390
Average total loss: 0.330430
tensor(0.0118, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.7845e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.248961
Average KL loss: 0.085383
Average total loss: 0.334344
tensor(0.0118, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-7.7480e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.247131
Average KL loss: 0.085355
Average total loss: 0.332486
tensor(0.0118, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.3549e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.244150
Average KL loss: 0.085329
Average total loss: 0.329479
tensor(0.0118, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-9.6201e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.243225
Average KL loss: 0.085288
Average total loss: 0.328514
tensor(0.0118, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.7611e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.255652
Average KL loss: 0.085280
Average total loss: 0.340932
tensor(0.0118, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.0900e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.247108
Average KL loss: 0.085290
Average total loss: 0.332398
tensor(0.0118, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-7.9371e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.244162
Average KL loss: 0.085296
Average total loss: 0.329459
tensor(0.0118, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-9.4517e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.240634
Average KL loss: 0.085283
Average total loss: 0.325917
tensor(0.0118, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-9.8066e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.239280
Average KL loss: 0.085251
Average total loss: 0.324532
tensor(0.0118, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-8.8436e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.243842
Average KL loss: 0.085243
Average total loss: 0.329085
tensor(0.0117, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.7984e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.241873
Average KL loss: 0.085228
Average total loss: 0.327101
tensor(0.0117, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.7432e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.242515
Average KL loss: 0.085201
Average total loss: 0.327716
tensor(0.0117, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.0056e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.245266
Average KL loss: 0.085226
Average total loss: 0.330492
tensor(0.0117, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.4140e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.240476
Average KL loss: 0.085257
Average total loss: 0.325732
tensor(0.0117, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.0097e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.243286
Average KL loss: 0.085229
Average total loss: 0.328515
tensor(0.0117, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-6.4877e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.237719
Average KL loss: 0.085218
Average total loss: 0.322937
tensor(0.0117, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.1117e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.241607
Average KL loss: 0.085220
Average total loss: 0.326828
tensor(0.0117, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.1884e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.234203
Average KL loss: 0.085216
Average total loss: 0.319420
tensor(0.0117, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-9.7455e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.237552
Average KL loss: 0.085213
Average total loss: 0.322765
tensor(0.0117, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.1395e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.230739
Average KL loss: 0.085209
Average total loss: 0.315948
tensor(0.0117, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.6444e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.234122
Average KL loss: 0.085176
Average total loss: 0.319298
tensor(0.0117, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-2.4094e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.236964
Average KL loss: 0.085151
Average total loss: 0.322115
tensor(0.0117, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.0931e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.225526
Average KL loss: 0.085138
Average total loss: 0.310664
tensor(0.0117, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-8.6884e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.237246
Average KL loss: 0.085097
Average total loss: 0.322343
tensor(0.0117, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.1874e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.230822
Average KL loss: 0.085087
Average total loss: 0.315909
tensor(0.0117, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.4186e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.224304
Average KL loss: 0.085032
Average total loss: 0.309337
tensor(0.0117, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-6.0341e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.226266
Average KL loss: 0.084967
Average total loss: 0.311233
tensor(0.0116, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-9.2147e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.226425
Average KL loss: 0.084941
Average total loss: 0.311365
tensor(0.0116, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-6.0973e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.229488
Average KL loss: 0.084935
Average total loss: 0.314423
tensor(0.0116, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.6667e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.226350
Average KL loss: 0.084930
Average total loss: 0.311280
tensor(0.0116, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-9.8512e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.224644
Average KL loss: 0.084909
Average total loss: 0.309553
tensor(0.0116, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.0533e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.233067
Average KL loss: 0.084853
Average total loss: 0.317919
tensor(0.0116, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.7965e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.225403
Average KL loss: 0.084867
Average total loss: 0.310270
tensor(0.0116, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.4198e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.228786
Average KL loss: 0.084831
Average total loss: 0.313617
tensor(0.0116, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.0748e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.227591
Average KL loss: 0.084826
Average total loss: 0.312417
 Percentile value: -1.624885044293478e-07
Non-zero model percentage: 64.0%, Non-zero mask percentage: 64.0%

--- Pruning Level [2/24]: ---
conv1.weight         | nonzeros =    1540 /    1728             ( 89.12%) | total_pruned =     188 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   31486 /   36864             ( 85.41%) | total_pruned =    5378 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   24239 /   36864             ( 65.75%) | total_pruned =   12625 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   21698 /   36864             ( 58.86%) | total_pruned =   15166 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   22327 /   36864             ( 60.57%) | total_pruned =   14537 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   31606 /   73728             ( 42.87%) | total_pruned =   42122 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   63685 /  147456             ( 43.19%) | total_pruned =   83771 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4192 /    8192             ( 51.17%) | total_pruned =    4000 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   75143 /  147456             ( 50.96%) | total_pruned =   72313 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   83871 /  147456             ( 56.88%) | total_pruned =   63585 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  112958 /  294912             ( 38.30%) | total_pruned =  181954 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  223789 /  589824             ( 37.94%) | total_pruned =  366035 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   14836 /   32768             ( 45.28%) | total_pruned =   17932 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     237 /     256             ( 92.58%) | total_pruned =      19 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  255739 /  589824             ( 43.36%) | total_pruned =  334085 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  303535 /  589824             ( 51.46%) | total_pruned =  286289 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  482471 / 1179648             ( 40.90%) | total_pruned =  697177 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1396169 / 2359296             ( 59.18%) | total_pruned =  963127 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     483 /     512             ( 94.34%) | total_pruned =      29 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     204 /     512             ( 39.84%) | total_pruned =     308 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   81859 /  131072             ( 62.45%) | total_pruned =   49213 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     205 /     512             ( 40.04%) | total_pruned =     307 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1686750 / 2359296             ( 71.49%) | total_pruned =  672546 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2220641 / 2359296             ( 94.12%) | total_pruned =  138655 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
linear.weight        | nonzeros =    4999 /    5120             ( 97.64%) | total_pruned =     121 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 7154408, pruned : 4024354, total: 11178762, Compression rate :       1.56x  ( 36.00% pruned)
Train Epoch: 60/100 Loss: 0.012801 Accuracy: 89.86 100.00 % Best test Accuracy: 89.86%
tensor(0.0116, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.3697e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.437860
Average KL loss: 0.081790
Average total loss: 0.519649
tensor(0.0125, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-4.9788e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.413413
Average KL loss: 0.078835
Average total loss: 0.492249
tensor(0.0128, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-4.1414e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.408814
Average KL loss: 0.077434
Average total loss: 0.486248
tensor(0.0129, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-3.7841e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.405402
Average KL loss: 0.076685
Average total loss: 0.482087
tensor(0.0130, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-3.4128e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.391805
Average KL loss: 0.076265
Average total loss: 0.468070
tensor(0.0130, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-5.0998e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.397576
Average KL loss: 0.076013
Average total loss: 0.473589
tensor(0.0130, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.4023e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.373065
Average KL loss: 0.075879
Average total loss: 0.448944
tensor(0.0129, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.3056e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.387782
Average KL loss: 0.075899
Average total loss: 0.463681
tensor(0.0129, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-3.2993e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.383524
Average KL loss: 0.075960
Average total loss: 0.459485
tensor(0.0129, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-3.2788e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.358829
Average KL loss: 0.075999
Average total loss: 0.434828
tensor(0.0129, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.2185e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.365904
Average KL loss: 0.076087
Average total loss: 0.441990
tensor(0.0128, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-2.7222e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.358180
Average KL loss: 0.076213
Average total loss: 0.434393
tensor(0.0128, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-2.9849e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.340864
Average KL loss: 0.076332
Average total loss: 0.417196
tensor(0.0127, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.7227e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.344251
Average KL loss: 0.076462
Average total loss: 0.420712
tensor(0.0127, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-3.5189e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.341872
Average KL loss: 0.076601
Average total loss: 0.418473
tensor(0.0127, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.8101e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.336823
Average KL loss: 0.076749
Average total loss: 0.413571
tensor(0.0126, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.6362e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.338480
Average KL loss: 0.076882
Average total loss: 0.415362
tensor(0.0126, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.7732e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.344151
Average KL loss: 0.077036
Average total loss: 0.421187
tensor(0.0126, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.8132e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.329075
Average KL loss: 0.077196
Average total loss: 0.406271
tensor(0.0125, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-3.3829e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.336820
Average KL loss: 0.077337
Average total loss: 0.414157
tensor(0.0125, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.6717e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.329775
Average KL loss: 0.077497
Average total loss: 0.407272
tensor(0.0125, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-3.2216e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.325504
Average KL loss: 0.077607
Average total loss: 0.403110
tensor(0.0125, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.0090e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.329009
Average KL loss: 0.077711
Average total loss: 0.406720
tensor(0.0124, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.0439e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.311700
Average KL loss: 0.077868
Average total loss: 0.389568
tensor(0.0124, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.9185e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.319162
Average KL loss: 0.078034
Average total loss: 0.397197
tensor(0.0124, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.6907e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.310573
Average KL loss: 0.078161
Average total loss: 0.388734
tensor(0.0124, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.6733e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.312293
Average KL loss: 0.078280
Average total loss: 0.390573
tensor(0.0123, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.5883e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.305751
Average KL loss: 0.078414
Average total loss: 0.384164
tensor(0.0123, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.8377e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.307061
Average KL loss: 0.078562
Average total loss: 0.385623
tensor(0.0123, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.9096e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.308478
Average KL loss: 0.078688
Average total loss: 0.387166
tensor(0.0123, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.1775e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.303744
Average KL loss: 0.078833
Average total loss: 0.382577
tensor(0.0123, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.6219e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.299538
Average KL loss: 0.078949
Average total loss: 0.378487
tensor(0.0122, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.4433e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.301275
Average KL loss: 0.079044
Average total loss: 0.380319
tensor(0.0122, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.7835e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.301150
Average KL loss: 0.079165
Average total loss: 0.380315
tensor(0.0122, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.0735e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.297408
Average KL loss: 0.079313
Average total loss: 0.376721
tensor(0.0122, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.2050e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.301711
Average KL loss: 0.079445
Average total loss: 0.381156
tensor(0.0122, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.6834e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.289060
Average KL loss: 0.079569
Average total loss: 0.368629
tensor(0.0122, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-2.2751e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.285577
Average KL loss: 0.079678
Average total loss: 0.365255
tensor(0.0121, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.1815e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.289910
Average KL loss: 0.079779
Average total loss: 0.369689
tensor(0.0121, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.9106e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.292956
Average KL loss: 0.079875
Average total loss: 0.372831
tensor(0.0121, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.7672e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.288385
Average KL loss: 0.079982
Average total loss: 0.368367
tensor(0.0121, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.9965e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.290441
Average KL loss: 0.080080
Average total loss: 0.370521
tensor(0.0121, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.7640e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.281793
Average KL loss: 0.080203
Average total loss: 0.361996
tensor(0.0121, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-9.0426e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.289161
Average KL loss: 0.080300
Average total loss: 0.369461
tensor(0.0120, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-2.5028e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.279157
Average KL loss: 0.080392
Average total loss: 0.359549
tensor(0.0120, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.7106e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.276062
Average KL loss: 0.080480
Average total loss: 0.356542
tensor(0.0120, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.6354e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.278128
Average KL loss: 0.080545
Average total loss: 0.358674
tensor(0.0120, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-2.0930e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.278520
Average KL loss: 0.080654
Average total loss: 0.359174
tensor(0.0120, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.1564e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.279718
Average KL loss: 0.080757
Average total loss: 0.360475
tensor(0.0120, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.7926e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.274177
Average KL loss: 0.080830
Average total loss: 0.355007
tensor(0.0120, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-6.7634e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.266404
Average KL loss: 0.080905
Average total loss: 0.347309
tensor(0.0120, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-2.6604e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.277361
Average KL loss: 0.081033
Average total loss: 0.358394
tensor(0.0120, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-2.1598e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.270524
Average KL loss: 0.081131
Average total loss: 0.351656
tensor(0.0119, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.4315e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.274395
Average KL loss: 0.081227
Average total loss: 0.355622
tensor(0.0119, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.5159e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.272500
Average KL loss: 0.081336
Average total loss: 0.353836
tensor(0.0119, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.3218e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.271237
Average KL loss: 0.081430
Average total loss: 0.352667
tensor(0.0119, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.9387e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.270840
Average KL loss: 0.081510
Average total loss: 0.352349
tensor(0.0119, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.0407e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.266755
Average KL loss: 0.081608
Average total loss: 0.348363
tensor(0.0119, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.2900e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.259733
Average KL loss: 0.081670
Average total loss: 0.341403
tensor(0.0119, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.8106e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.265840
Average KL loss: 0.081739
Average total loss: 0.347579
tensor(0.0119, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.7591e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.266810
Average KL loss: 0.081834
Average total loss: 0.348644
tensor(0.0119, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.2965e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.257561
Average KL loss: 0.081895
Average total loss: 0.339457
tensor(0.0118, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.2325e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.264633
Average KL loss: 0.081967
Average total loss: 0.346600
tensor(0.0118, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.4776e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.260456
Average KL loss: 0.082066
Average total loss: 0.342521
tensor(0.0118, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-9.4428e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.258752
Average KL loss: 0.082151
Average total loss: 0.340903
tensor(0.0118, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.9240e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.255852
Average KL loss: 0.082223
Average total loss: 0.338075
tensor(0.0118, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.5608e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.253054
Average KL loss: 0.082297
Average total loss: 0.335352
tensor(0.0118, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.3547e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.258618
Average KL loss: 0.082352
Average total loss: 0.340970
tensor(0.0118, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.0384e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.256957
Average KL loss: 0.082415
Average total loss: 0.339372
tensor(0.0118, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.3310e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.250053
Average KL loss: 0.082504
Average total loss: 0.332556
tensor(0.0118, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-6.4320e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.252909
Average KL loss: 0.082578
Average total loss: 0.335486
tensor(0.0118, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-2.0379e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.256725
Average KL loss: 0.082678
Average total loss: 0.339403
tensor(0.0118, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.7059e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.252763
Average KL loss: 0.082764
Average total loss: 0.335527
tensor(0.0117, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.3007e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.254769
Average KL loss: 0.082821
Average total loss: 0.337590
tensor(0.0117, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.0550e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.253504
Average KL loss: 0.082899
Average total loss: 0.336403
tensor(0.0117, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.4662e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.248821
Average KL loss: 0.082979
Average total loss: 0.331800
tensor(0.0117, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.0755e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.253469
Average KL loss: 0.083072
Average total loss: 0.336541
tensor(0.0117, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.4892e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.246721
Average KL loss: 0.083122
Average total loss: 0.329842
tensor(0.0117, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-8.1902e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.241451
Average KL loss: 0.083191
Average total loss: 0.324641
tensor(0.0117, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.3454e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.239293
Average KL loss: 0.083257
Average total loss: 0.322549
tensor(0.0117, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.2587e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.243128
Average KL loss: 0.083278
Average total loss: 0.326405
tensor(0.0117, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.2327e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.246124
Average KL loss: 0.083350
Average total loss: 0.329474
tensor(0.0117, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.8954e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.240033
Average KL loss: 0.083439
Average total loss: 0.323472
tensor(0.0117, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.0361e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.249979
Average KL loss: 0.083518
Average total loss: 0.333498
tensor(0.0117, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.1449e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.241935
Average KL loss: 0.083589
Average total loss: 0.325524
tensor(0.0117, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.4190e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.245398
Average KL loss: 0.083651
Average total loss: 0.329048
tensor(0.0116, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.0262e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.236431
Average KL loss: 0.083725
Average total loss: 0.320156
tensor(0.0116, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-2.0954e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.244263
Average KL loss: 0.083785
Average total loss: 0.328047
tensor(0.0116, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-9.9326e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.243839
Average KL loss: 0.083864
Average total loss: 0.327702
tensor(0.0116, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.3558e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.233552
Average KL loss: 0.083927
Average total loss: 0.317478
tensor(0.0116, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-6.1795e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.237870
Average KL loss: 0.083973
Average total loss: 0.321843
tensor(0.0116, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-8.4415e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.237577
Average KL loss: 0.084005
Average total loss: 0.321582
tensor(0.0116, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-2.4944e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.240130
Average KL loss: 0.084071
Average total loss: 0.324200
tensor(0.0116, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.7008e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.244250
Average KL loss: 0.084153
Average total loss: 0.328403
tensor(0.0116, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.5541e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.237561
Average KL loss: 0.084203
Average total loss: 0.321764
tensor(0.0116, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.4093e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.232509
Average KL loss: 0.084278
Average total loss: 0.316787
tensor(0.0116, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.1454e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.231803
Average KL loss: 0.084320
Average total loss: 0.316122
tensor(0.0116, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.9281e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.236148
Average KL loss: 0.084364
Average total loss: 0.320512
tensor(0.0116, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.0628e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.233405
Average KL loss: 0.084416
Average total loss: 0.317821
tensor(0.0116, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.2897e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.237655
Average KL loss: 0.084475
Average total loss: 0.322130
tensor(0.0116, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.2950e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.230595
Average KL loss: 0.084547
Average total loss: 0.315142
tensor(0.0116, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-7.2547e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.227986
Average KL loss: 0.084578
Average total loss: 0.312564
tensor(0.0116, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.2496e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.224980
Average KL loss: 0.084623
Average total loss: 0.309603
tensor(0.0116, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.2154e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.229271
Average KL loss: 0.084675
Average total loss: 0.313946
tensor(0.0116, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.2480e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.227473
Average KL loss: 0.084746
Average total loss: 0.312219
tensor(0.0115, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-6.9566e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.227161
Average KL loss: 0.084786
Average total loss: 0.311946
tensor(0.0115, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.0078e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.223628
Average KL loss: 0.084825
Average total loss: 0.308453
tensor(0.0115, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-9.7832e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.230930
Average KL loss: 0.084884
Average total loss: 0.315814
tensor(0.0115, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-5.8940e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.220095
Average KL loss: 0.084942
Average total loss: 0.305036
tensor(0.0115, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-7.5534e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.220733
Average KL loss: 0.084965
Average total loss: 0.305698
tensor(0.0115, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-6.3741e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.230717
Average KL loss: 0.085003
Average total loss: 0.315720
tensor(0.0115, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.3085e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.226486
Average KL loss: 0.085051
Average total loss: 0.311536
tensor(0.0115, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.1921e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.226186
Average KL loss: 0.085110
Average total loss: 0.311296
tensor(0.0115, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.3258e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.227117
Average KL loss: 0.085190
Average total loss: 0.312307
tensor(0.0115, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.2260e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.227428
Average KL loss: 0.085262
Average total loss: 0.312691
tensor(0.0115, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-7.2698e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.226476
Average KL loss: 0.085304
Average total loss: 0.311779
tensor(0.0115, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-7.1333e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.216274
Average KL loss: 0.085333
Average total loss: 0.301607
tensor(0.0115, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-7.0323e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.218656
Average KL loss: 0.085359
Average total loss: 0.304016
tensor(0.0115, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.1220e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.217780
Average KL loss: 0.085407
Average total loss: 0.303186
tensor(0.0115, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-9.8327e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.216116
Average KL loss: 0.085442
Average total loss: 0.301558
tensor(0.0115, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-5.9768e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.215627
Average KL loss: 0.085474
Average total loss: 0.301101
tensor(0.0115, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-9.2695e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.224961
Average KL loss: 0.085515
Average total loss: 0.310476
tensor(0.0115, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-9.3338e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.227789
Average KL loss: 0.085561
Average total loss: 0.313350
tensor(0.0115, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-8.2802e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.219773
Average KL loss: 0.085642
Average total loss: 0.305414
tensor(0.0115, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-8.5723e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.217367
Average KL loss: 0.085683
Average total loss: 0.303050
tensor(0.0115, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.1589e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.220173
Average KL loss: 0.085709
Average total loss: 0.305882
tensor(0.0115, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-9.5136e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.211251
Average KL loss: 0.085722
Average total loss: 0.296973
tensor(0.0115, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-6.5082e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.213620
Average KL loss: 0.085753
Average total loss: 0.299373
tensor(0.0115, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-4.9641e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.214501
Average KL loss: 0.085787
Average total loss: 0.300288
tensor(0.0115, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.4942e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.215996
Average KL loss: 0.085838
Average total loss: 0.301834
tensor(0.0114, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-8.9235e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.209842
Average KL loss: 0.085894
Average total loss: 0.295736
tensor(0.0115, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-7.8007e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.214705
Average KL loss: 0.085937
Average total loss: 0.300642
tensor(0.0114, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-8.6584e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.213155
Average KL loss: 0.085953
Average total loss: 0.299108
tensor(0.0114, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.3398e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.214387
Average KL loss: 0.085961
Average total loss: 0.300347
tensor(0.0114, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-8.9520e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.212308
Average KL loss: 0.086007
Average total loss: 0.298315
tensor(0.0114, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.4730e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.208687
Average KL loss: 0.086033
Average total loss: 0.294720
tensor(0.0114, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.0274e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.209660
Average KL loss: 0.086057
Average total loss: 0.295717
tensor(0.0114, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.0683e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.206288
Average KL loss: 0.086071
Average total loss: 0.292359
tensor(0.0114, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-7.9034e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.206382
Average KL loss: 0.086077
Average total loss: 0.292459
tensor(0.0114, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.5796e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.212010
Average KL loss: 0.086101
Average total loss: 0.298111
tensor(0.0114, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-9.0602e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.205746
Average KL loss: 0.086128
Average total loss: 0.291875
tensor(0.0114, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-7.5007e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.210615
Average KL loss: 0.086151
Average total loss: 0.296766
tensor(0.0114, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-8.4850e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.212722
Average KL loss: 0.086220
Average total loss: 0.298942
tensor(0.0114, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-9.6045e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.206623
Average KL loss: 0.086267
Average total loss: 0.292891
tensor(0.0114, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-7.2181e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.213149
Average KL loss: 0.086332
Average total loss: 0.299481
tensor(0.0114, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-7.8053e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.206433
Average KL loss: 0.086394
Average total loss: 0.292827
tensor(0.0114, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.9585e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.201918
Average KL loss: 0.086404
Average total loss: 0.288322
tensor(0.0114, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.4659e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.209331
Average KL loss: 0.086435
Average total loss: 0.295766
tensor(0.0114, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-8.6025e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.203513
Average KL loss: 0.086467
Average total loss: 0.289981
tensor(0.0114, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.2803e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.202267
Average KL loss: 0.086490
Average total loss: 0.288757
tensor(0.0114, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-4.4890e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.207131
Average KL loss: 0.086507
Average total loss: 0.293638
tensor(0.0114, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-7.8586e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.202241
Average KL loss: 0.086526
Average total loss: 0.288766
tensor(0.0114, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-8.0989e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.198854
Average KL loss: 0.086530
Average total loss: 0.285384
tensor(0.0114, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.6273e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.208813
Average KL loss: 0.086560
Average total loss: 0.295374
tensor(0.0114, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-8.5553e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.203888
Average KL loss: 0.086611
Average total loss: 0.290499
tensor(0.0114, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-5.0964e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.201102
Average KL loss: 0.086627
Average total loss: 0.287729
tensor(0.0114, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.0287e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.200543
Average KL loss: 0.086673
Average total loss: 0.287217
tensor(0.0114, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-8.1018e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.201553
Average KL loss: 0.086685
Average total loss: 0.288237
tensor(0.0114, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-9.8441e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.194023
Average KL loss: 0.086720
Average total loss: 0.280743
tensor(0.0113, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-8.7448e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.193825
Average KL loss: 0.086733
Average total loss: 0.280558
tensor(0.0113, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-7.2604e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.200221
Average KL loss: 0.086758
Average total loss: 0.286980
tensor(0.0113, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-9.7424e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.196957
Average KL loss: 0.086766
Average total loss: 0.283723
tensor(0.0113, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-8.7064e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.192132
Average KL loss: 0.086760
Average total loss: 0.278892
tensor(0.0113, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-5.7623e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.200381
Average KL loss: 0.086748
Average total loss: 0.287129
tensor(0.0113, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-7.1786e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.197892
Average KL loss: 0.086776
Average total loss: 0.284668
tensor(0.0113, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-3.4807e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.200598
Average KL loss: 0.086787
Average total loss: 0.287384
tensor(0.0113, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-2.0121e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.197285
Average KL loss: 0.086815
Average total loss: 0.284100
tensor(0.0113, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-5.5864e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.197138
Average KL loss: 0.086851
Average total loss: 0.283989
tensor(0.0113, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-6.7741e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.193844
Average KL loss: 0.086873
Average total loss: 0.280718
tensor(0.0113, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-9.9110e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.193950
Average KL loss: 0.086894
Average total loss: 0.280845
tensor(0.0113, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.4050e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.197250
Average KL loss: 0.086915
Average total loss: 0.284165
tensor(0.0113, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-7.6680e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.197714
Average KL loss: 0.086960
Average total loss: 0.284674
tensor(0.0113, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-8.2642e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.191364
Average KL loss: 0.086994
Average total loss: 0.278358
tensor(0.0113, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-7.6232e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.193692
Average KL loss: 0.087019
Average total loss: 0.280711
tensor(0.0113, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-7.4041e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.197455
Average KL loss: 0.087048
Average total loss: 0.284503
tensor(0.0113, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-3.0076e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.193603
Average KL loss: 0.087095
Average total loss: 0.280698
tensor(0.0113, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-9.3539e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.195757
Average KL loss: 0.087143
Average total loss: 0.282900
tensor(0.0113, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.0028e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.196088
Average KL loss: 0.087198
Average total loss: 0.283285
tensor(0.0113, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-6.8993e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.192858
Average KL loss: 0.087232
Average total loss: 0.280091
tensor(0.0113, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-3.8184e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.191898
Average KL loss: 0.087244
Average total loss: 0.279142
tensor(0.0113, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-7.1933e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.192127
Average KL loss: 0.087256
Average total loss: 0.279383
tensor(0.0113, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-7.7273e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.190675
Average KL loss: 0.087295
Average total loss: 0.277970
tensor(0.0113, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.0514e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.192942
Average KL loss: 0.087324
Average total loss: 0.280266
tensor(0.0113, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-7.1301e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.191938
Average KL loss: 0.087346
Average total loss: 0.279283
tensor(0.0113, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-2.7592e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.187964
Average KL loss: 0.087361
Average total loss: 0.275325
tensor(0.0113, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-6.7317e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.189379
Average KL loss: 0.087385
Average total loss: 0.276764
tensor(0.0113, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.0752e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.189198
Average KL loss: 0.087398
Average total loss: 0.276596
tensor(0.0113, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-8.3865e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.193199
Average KL loss: 0.087408
Average total loss: 0.280607
tensor(0.0113, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-6.2090e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.187771
Average KL loss: 0.087433
Average total loss: 0.275203
tensor(0.0113, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-7.0039e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.183228
Average KL loss: 0.087406
Average total loss: 0.270633
tensor(0.0113, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-8.9722e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.185598
Average KL loss: 0.087397
Average total loss: 0.272995
tensor(0.0113, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-5.0151e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.186953
Average KL loss: 0.087410
Average total loss: 0.274363
tensor(0.0113, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.1255e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.193737
Average KL loss: 0.087439
Average total loss: 0.281176
tensor(0.0113, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.4056e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.193584
Average KL loss: 0.087486
Average total loss: 0.281070
tensor(0.0113, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-6.6398e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.190273
Average KL loss: 0.087519
Average total loss: 0.277792
tensor(0.0113, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-7.8948e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.185735
Average KL loss: 0.087546
Average total loss: 0.273281
tensor(0.0113, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-8.2278e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.183472
Average KL loss: 0.087541
Average total loss: 0.271013
tensor(0.0112, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-2.3921e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.185793
Average KL loss: 0.087532
Average total loss: 0.273325
tensor(0.0112, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-6.5623e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.188284
Average KL loss: 0.087538
Average total loss: 0.275822
tensor(0.0112, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-9.8235e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.185219
Average KL loss: 0.087585
Average total loss: 0.272804
 Percentile value: -1.624221368956569e-07
Non-zero model percentage: 51.200008392333984%, Non-zero mask percentage: 51.200008392333984%

--- Pruning Level [3/24]: ---
conv1.weight         | nonzeros =    1513 /    1728             ( 87.56%) | total_pruned =     215 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   30875 /   36864             ( 83.75%) | total_pruned =    5989 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   21940 /   36864             ( 59.52%) | total_pruned =   14924 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   19362 /   36864             ( 52.52%) | total_pruned =   17502 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   19183 /   36864             ( 52.04%) | total_pruned =   17681 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   23705 /   73728             ( 32.15%) | total_pruned =   50023 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   46863 /  147456             ( 31.78%) | total_pruned =  100593 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3308 /    8192             ( 40.38%) | total_pruned =    4884 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   57506 /  147456             ( 39.00%) | total_pruned =   89950 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   66152 /  147456             ( 44.86%) | total_pruned =   81304 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   76541 /  294912             ( 25.95%) | total_pruned =  218371 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  145195 /  589824             ( 24.62%) | total_pruned =  444629 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   10790 /   32768             ( 32.93%) | total_pruned =   21978 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  170019 /  589824             ( 28.83%) | total_pruned =  419805 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  204928 /  589824             ( 34.74%) | total_pruned =  384896 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     236 /     256             ( 92.19%) | total_pruned =      20 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  312314 / 1179648             ( 26.48%) | total_pruned =  867334 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      51 /     512             (  9.96%) | total_pruned =     461 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  956787 / 2359296             ( 40.55%) | total_pruned = 1402509 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     479 /     512             ( 93.55%) | total_pruned =      33 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     180 /     512             ( 35.16%) | total_pruned =     332 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   59906 /  131072             ( 45.70%) | total_pruned =   71166 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     469 /     512             ( 91.60%) | total_pruned =      43 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     179 /     512             ( 34.96%) | total_pruned =     333 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1444465 / 2359296             ( 61.22%) | total_pruned =  914831 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2036529 / 2359296             ( 86.32%) | total_pruned =  322767 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     504 /     512             ( 98.44%) | total_pruned =       8 | shape = torch.Size([512])
linear.weight        | nonzeros =    4929 /    5120             ( 96.27%) | total_pruned =     191 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 5723527, pruned : 5455235, total: 11178762, Compression rate :       1.95x  ( 48.80% pruned)
Train Epoch: 47/100 Loss: 0.017895 Accuracy: 89.69 100.00 % Best test Accuracy: 89.69%
tensor(0.0112, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-3.2285e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.310830
Average KL loss: 0.085463
Average total loss: 0.396293
tensor(0.0117, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.9860e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.306952
Average KL loss: 0.083398
Average total loss: 0.390350
tensor(0.0119, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-3.1353e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.305459
Average KL loss: 0.082336
Average total loss: 0.387796
tensor(0.0119, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.8720e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.299350
Average KL loss: 0.081709
Average total loss: 0.381059
tensor(0.0119, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.8885e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.291259
Average KL loss: 0.081311
Average total loss: 0.372570
tensor(0.0119, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.4682e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.292821
Average KL loss: 0.081068
Average total loss: 0.373889
tensor(0.0119, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.1327e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.281714
Average KL loss: 0.080885
Average total loss: 0.362599
tensor(0.0119, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.8177e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.282396
Average KL loss: 0.080766
Average total loss: 0.363162
tensor(0.0118, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.6746e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.278703
Average KL loss: 0.080714
Average total loss: 0.359417
tensor(0.0118, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.4964e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.289289
Average KL loss: 0.080695
Average total loss: 0.369984
tensor(0.0118, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.2789e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.276233
Average KL loss: 0.080692
Average total loss: 0.356925
tensor(0.0118, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.9263e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.275711
Average KL loss: 0.080693
Average total loss: 0.356405
tensor(0.0117, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.3678e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.273436
Average KL loss: 0.080696
Average total loss: 0.354132
tensor(0.0117, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.0961e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.273532
Average KL loss: 0.080713
Average total loss: 0.354245
tensor(0.0117, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.6064e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.264146
Average KL loss: 0.080739
Average total loss: 0.344884
tensor(0.0116, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.2050e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.264660
Average KL loss: 0.080769
Average total loss: 0.345429
tensor(0.0116, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.8310e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.263916
Average KL loss: 0.080827
Average total loss: 0.344743
tensor(0.0116, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.6007e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.260209
Average KL loss: 0.080896
Average total loss: 0.341105
tensor(0.0116, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.7082e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.262626
Average KL loss: 0.080959
Average total loss: 0.343585
tensor(0.0115, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.4716e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.261231
Average KL loss: 0.081041
Average total loss: 0.342272
tensor(0.0115, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.1580e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.259806
Average KL loss: 0.081120
Average total loss: 0.340925
tensor(0.0115, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-9.2064e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.250125
Average KL loss: 0.081198
Average total loss: 0.331323
tensor(0.0115, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.1962e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.257507
Average KL loss: 0.081281
Average total loss: 0.338788
tensor(0.0115, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.3724e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.257664
Average KL loss: 0.081372
Average total loss: 0.339035
tensor(0.0114, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.1106e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.252332
Average KL loss: 0.081453
Average total loss: 0.333785
tensor(0.0114, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.7399e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.256670
Average KL loss: 0.081533
Average total loss: 0.338202
tensor(0.0114, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.2508e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.257192
Average KL loss: 0.081620
Average total loss: 0.338811
tensor(0.0114, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.4950e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.259112
Average KL loss: 0.081705
Average total loss: 0.340817
tensor(0.0114, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.3378e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.246814
Average KL loss: 0.081794
Average total loss: 0.328608
tensor(0.0113, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.5877e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.247728
Average KL loss: 0.081868
Average total loss: 0.329596
tensor(0.0113, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.1254e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.248672
Average KL loss: 0.081952
Average total loss: 0.330624
tensor(0.0113, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.7308e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.243254
Average KL loss: 0.082031
Average total loss: 0.325285
tensor(0.0113, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.6897e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.242328
Average KL loss: 0.082101
Average total loss: 0.324429
tensor(0.0113, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.3198e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.242806
Average KL loss: 0.082181
Average total loss: 0.324986
tensor(0.0113, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.5611e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.244599
Average KL loss: 0.082270
Average total loss: 0.326869
tensor(0.0113, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-9.0503e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.248532
Average KL loss: 0.082352
Average total loss: 0.330884
tensor(0.0113, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.2470e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.239972
Average KL loss: 0.082446
Average total loss: 0.322418
tensor(0.0112, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.0405e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.239481
Average KL loss: 0.082537
Average total loss: 0.322018
tensor(0.0112, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-6.8859e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.237410
Average KL loss: 0.082613
Average total loss: 0.320023
tensor(0.0112, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.1571e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.241153
Average KL loss: 0.082699
Average total loss: 0.323852
tensor(0.0112, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-8.4452e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.239199
Average KL loss: 0.082764
Average total loss: 0.321963
tensor(0.0112, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-9.2552e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.236945
Average KL loss: 0.082831
Average total loss: 0.319777
tensor(0.0112, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-8.4958e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.238213
Average KL loss: 0.082907
Average total loss: 0.321120
tensor(0.0112, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.5232e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.234898
Average KL loss: 0.082986
Average total loss: 0.317884
tensor(0.0112, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.1188e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.234198
Average KL loss: 0.083066
Average total loss: 0.317264
tensor(0.0112, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.4744e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.228992
Average KL loss: 0.083152
Average total loss: 0.312144
tensor(0.0112, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-9.8105e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.230840
Average KL loss: 0.083220
Average total loss: 0.314059
tensor(0.0111, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.3739e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.236890
Average KL loss: 0.083311
Average total loss: 0.320201
tensor(0.0111, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.2287e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.230602
Average KL loss: 0.083396
Average total loss: 0.313999
tensor(0.0111, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.1135e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.231687
Average KL loss: 0.083458
Average total loss: 0.315145
tensor(0.0111, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-2.0806e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.228691
Average KL loss: 0.083546
Average total loss: 0.312237
tensor(0.0111, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.1405e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.229083
Average KL loss: 0.083607
Average total loss: 0.312690
tensor(0.0111, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.5142e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.226951
Average KL loss: 0.083693
Average total loss: 0.310643
tensor(0.0111, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-8.4877e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.229678
Average KL loss: 0.083754
Average total loss: 0.313432
tensor(0.0111, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-7.8101e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.225104
Average KL loss: 0.083843
Average total loss: 0.308947
tensor(0.0111, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.5454e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.227663
Average KL loss: 0.083936
Average total loss: 0.311599
tensor(0.0111, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-9.1359e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.229139
Average KL loss: 0.084017
Average total loss: 0.313156
tensor(0.0111, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-8.5990e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.219389
Average KL loss: 0.084104
Average total loss: 0.303493
tensor(0.0111, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-6.3539e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.215910
Average KL loss: 0.084170
Average total loss: 0.300080
tensor(0.0111, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-7.9514e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.222265
Average KL loss: 0.084224
Average total loss: 0.306489
tensor(0.0110, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-9.2072e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.218960
Average KL loss: 0.084286
Average total loss: 0.303246
tensor(0.0110, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-7.5588e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.224071
Average KL loss: 0.084367
Average total loss: 0.308438
tensor(0.0110, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.0976e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.217815
Average KL loss: 0.084435
Average total loss: 0.302250
tensor(0.0110, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-9.4258e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.218198
Average KL loss: 0.084494
Average total loss: 0.302693
tensor(0.0110, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-7.3026e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.218653
Average KL loss: 0.084541
Average total loss: 0.303195
tensor(0.0110, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.4107e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.218784
Average KL loss: 0.084613
Average total loss: 0.303397
tensor(0.0110, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-8.7585e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.218545
Average KL loss: 0.084671
Average total loss: 0.303216
tensor(0.0110, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.2694e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.215239
Average KL loss: 0.084748
Average total loss: 0.299986
tensor(0.0110, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-5.1867e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.217753
Average KL loss: 0.084825
Average total loss: 0.302578
tensor(0.0110, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-9.8220e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.217830
Average KL loss: 0.084903
Average total loss: 0.302733
tensor(0.0110, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-9.3605e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.218737
Average KL loss: 0.084955
Average total loss: 0.303692
tensor(0.0110, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-8.4766e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.214482
Average KL loss: 0.085038
Average total loss: 0.299520
tensor(0.0110, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.4205e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.216175
Average KL loss: 0.085123
Average total loss: 0.301299
tensor(0.0110, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-6.5636e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.220391
Average KL loss: 0.085194
Average total loss: 0.305586
tensor(0.0110, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-9.6624e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.216186
Average KL loss: 0.085264
Average total loss: 0.301450
tensor(0.0110, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-4.1868e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.216105
Average KL loss: 0.085332
Average total loss: 0.301437
tensor(0.0110, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-7.5119e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.220542
Average KL loss: 0.085418
Average total loss: 0.305960
tensor(0.0110, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-9.9502e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.209903
Average KL loss: 0.085493
Average total loss: 0.295396
tensor(0.0110, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.0091e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.208646
Average KL loss: 0.085556
Average total loss: 0.294202
tensor(0.0109, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.4353e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.208941
Average KL loss: 0.085632
Average total loss: 0.294573
tensor(0.0109, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.6825e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.208735
Average KL loss: 0.085667
Average total loss: 0.294402
tensor(0.0109, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.1928e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.214772
Average KL loss: 0.085743
Average total loss: 0.300515
tensor(0.0109, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.0748e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.212855
Average KL loss: 0.085817
Average total loss: 0.298672
tensor(0.0109, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-3.5651e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.212150
Average KL loss: 0.085884
Average total loss: 0.298033
tensor(0.0109, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-9.4774e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.212849
Average KL loss: 0.085958
Average total loss: 0.298808
tensor(0.0109, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-4.5294e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.219664
Average KL loss: 0.086020
Average total loss: 0.305684
tensor(0.0109, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.0023e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.210242
Average KL loss: 0.086107
Average total loss: 0.296349
tensor(0.0109, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-6.9829e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.210559
Average KL loss: 0.086164
Average total loss: 0.296723
tensor(0.0109, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.2883e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.204035
Average KL loss: 0.086252
Average total loss: 0.290287
tensor(0.0109, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-7.1635e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.203737
Average KL loss: 0.086307
Average total loss: 0.290044
tensor(0.0109, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-4.7301e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.208806
Average KL loss: 0.086346
Average total loss: 0.295152
tensor(0.0109, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-6.8003e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.206282
Average KL loss: 0.086384
Average total loss: 0.292666
tensor(0.0109, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.3035e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.208174
Average KL loss: 0.086448
Average total loss: 0.294621
tensor(0.0109, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-7.3141e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.206236
Average KL loss: 0.086527
Average total loss: 0.292763
tensor(0.0109, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-9.5682e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.206802
Average KL loss: 0.086595
Average total loss: 0.293397
tensor(0.0109, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.0049e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.209148
Average KL loss: 0.086655
Average total loss: 0.295802
tensor(0.0109, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-4.4723e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.204516
Average KL loss: 0.086714
Average total loss: 0.291229
tensor(0.0109, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-8.2097e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.204575
Average KL loss: 0.086763
Average total loss: 0.291338
tensor(0.0109, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.3497e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.203284
Average KL loss: 0.086828
Average total loss: 0.290112
tensor(0.0109, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-5.1660e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.194209
Average KL loss: 0.086874
Average total loss: 0.281083
tensor(0.0109, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-6.4507e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.198935
Average KL loss: 0.086905
Average total loss: 0.285841
tensor(0.0109, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-6.3450e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.207782
Average KL loss: 0.086962
Average total loss: 0.294744
tensor(0.0109, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-6.3426e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.204011
Average KL loss: 0.087036
Average total loss: 0.291047
tensor(0.0109, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-8.0197e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.198033
Average KL loss: 0.087104
Average total loss: 0.285137
tensor(0.0109, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-8.2318e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.201494
Average KL loss: 0.087161
Average total loss: 0.288655
tensor(0.0109, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-8.1302e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.199776
Average KL loss: 0.087209
Average total loss: 0.286984
tensor(0.0109, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-7.9300e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.207706
Average KL loss: 0.087260
Average total loss: 0.294965
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.6070e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.197929
Average KL loss: 0.087324
Average total loss: 0.285253
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.7406e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.197419
Average KL loss: 0.087367
Average total loss: 0.284786
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.3307e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.198806
Average KL loss: 0.087421
Average total loss: 0.286227
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-6.6185e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.198764
Average KL loss: 0.087468
Average total loss: 0.286231
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-9.9888e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.199861
Average KL loss: 0.087497
Average total loss: 0.287358
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-8.9210e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.197534
Average KL loss: 0.087496
Average total loss: 0.285031
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.0412e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.201155
Average KL loss: 0.087496
Average total loss: 0.288652
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-7.1007e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.198648
Average KL loss: 0.087496
Average total loss: 0.286144
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.7829e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.201307
Average KL loss: 0.087496
Average total loss: 0.288803
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-7.5253e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.191651
Average KL loss: 0.087495
Average total loss: 0.279146
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.4517e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.197464
Average KL loss: 0.087493
Average total loss: 0.284956
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-8.0835e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.199010
Average KL loss: 0.087490
Average total loss: 0.286500
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-5.6008e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.194492
Average KL loss: 0.087491
Average total loss: 0.281983
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-6.9613e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.202361
Average KL loss: 0.087490
Average total loss: 0.289852
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-5.1043e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.193201
Average KL loss: 0.087490
Average total loss: 0.280691
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.3691e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.201402
Average KL loss: 0.087490
Average total loss: 0.288892
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-4.7650e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.198817
Average KL loss: 0.087491
Average total loss: 0.286308
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-9.6144e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.194885
Average KL loss: 0.087492
Average total loss: 0.282376
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.3932e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.197762
Average KL loss: 0.087492
Average total loss: 0.285254
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-7.2752e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.195613
Average KL loss: 0.087492
Average total loss: 0.283104
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-5.9758e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.197380
Average KL loss: 0.087492
Average total loss: 0.284872
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-9.0396e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.195123
Average KL loss: 0.087493
Average total loss: 0.282616
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-9.0033e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.195608
Average KL loss: 0.087493
Average total loss: 0.283100
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.4486e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.198061
Average KL loss: 0.087493
Average total loss: 0.285554
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-8.2155e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.193354
Average KL loss: 0.087493
Average total loss: 0.280846
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-9.7088e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.196419
Average KL loss: 0.087493
Average total loss: 0.283912
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.1506e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.195410
Average KL loss: 0.087492
Average total loss: 0.282903
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.4280e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.200177
Average KL loss: 0.087493
Average total loss: 0.287670
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.2314e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.196019
Average KL loss: 0.087493
Average total loss: 0.283511
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-7.2087e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.195916
Average KL loss: 0.087493
Average total loss: 0.283408
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.3951e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.197267
Average KL loss: 0.087493
Average total loss: 0.284760
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-4.2705e-09, device='cuda:0')
 Percentile value: -1.6522888302006322e-07
Non-zero model percentage: 40.96000671386719%, Non-zero mask percentage: 40.96000671386719%

--- Pruning Level [4/24]: ---
conv1.weight         | nonzeros =    1284 /    1728             ( 74.31%) | total_pruned =     444 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
bn1.weight           | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
bn1.bias             | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   28211 /   36864             ( 76.53%) | total_pruned =    8653 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   17892 /   36864             ( 48.54%) | total_pruned =   18972 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   16040 /   36864             ( 43.51%) | total_pruned =   20824 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   15458 /   36864             ( 41.93%) | total_pruned =   21406 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   18327 /   73728             ( 24.86%) | total_pruned =   55401 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   35699 /  147456             ( 24.21%) | total_pruned =  111757 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2642 /    8192             ( 32.25%) | total_pruned =    5550 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   44319 /  147456             ( 30.06%) | total_pruned =  103137 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   51115 /  147456             ( 34.66%) | total_pruned =   96341 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   55872 /  294912             ( 18.95%) | total_pruned =  239040 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     198 /     256             ( 77.34%) | total_pruned =      58 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  101686 /  589824             ( 17.24%) | total_pruned =  488138 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    8141 /   32768             ( 24.84%) | total_pruned =   24627 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  122036 /  589824             ( 20.69%) | total_pruned =  467788 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     219 /     256             ( 85.55%) | total_pruned =      37 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  147714 /  589824             ( 25.04%) | total_pruned =  442110 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  215749 / 1179648             ( 18.29%) | total_pruned =  963899 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     420 /     512             ( 82.03%) | total_pruned =      92 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     504 /     512             ( 98.44%) | total_pruned =       8 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  707613 / 2359296             ( 29.99%) | total_pruned = 1651683 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     445 /     512             ( 86.91%) | total_pruned =      67 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     471 /     512             ( 91.99%) | total_pruned =      41 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     173 /     512             ( 33.79%) | total_pruned =     339 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   45803 /  131072             ( 34.94%) | total_pruned =   85269 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     435 /     512             ( 84.96%) | total_pruned =      77 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     429 /     512             ( 83.79%) | total_pruned =      83 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     170 /     512             ( 33.20%) | total_pruned =     342 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1175476 / 2359296             ( 49.82%) | total_pruned = 1183820 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     443 /     512             ( 86.52%) | total_pruned =      69 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     463 /     512             ( 90.43%) | total_pruned =      49 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1753285 / 2359296             ( 74.31%) | total_pruned =  606011 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     443 /     512             ( 86.52%) | total_pruned =      69 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
linear.weight        | nonzeros =    4804 /    5120             ( 93.83%) | total_pruned =     316 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 4578822, pruned : 6599940, total: 11178762, Compression rate :       2.44x  ( 59.04% pruned)
Train Epoch: 52/100 Loss: 0.024896 Accuracy: 89.22 100.00 % Best test Accuracy: 89.22%
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-4.1154e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.313573
Average KL loss: 0.086082
Average total loss: 0.399656
tensor(0.0111, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.3791e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.299834
Average KL loss: 0.084894
Average total loss: 0.384728
tensor(0.0113, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.7717e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.292091
Average KL loss: 0.084345
Average total loss: 0.376436
tensor(0.0113, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.9400e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.291707
Average KL loss: 0.084051
Average total loss: 0.375758
tensor(0.0113, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.2494e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.287616
Average KL loss: 0.083924
Average total loss: 0.371540
tensor(0.0113, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.8898e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.283304
Average KL loss: 0.083856
Average total loss: 0.367161
tensor(0.0113, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.0729e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.277581
Average KL loss: 0.083872
Average total loss: 0.361453
tensor(0.0113, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.5462e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.272155
Average KL loss: 0.083921
Average total loss: 0.356076
tensor(0.0113, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.3876e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.269904
Average KL loss: 0.083959
Average total loss: 0.353862
tensor(0.0113, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.8927e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.266165
Average KL loss: 0.084041
Average total loss: 0.350206
tensor(0.0113, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.0940e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.268112
Average KL loss: 0.084136
Average total loss: 0.352248
tensor(0.0113, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.5171e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.260763
Average KL loss: 0.084232
Average total loss: 0.344995
tensor(0.0112, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.6123e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.265310
Average KL loss: 0.084322
Average total loss: 0.349632
tensor(0.0112, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.1120e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.262743
Average KL loss: 0.084432
Average total loss: 0.347175
tensor(0.0112, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.6640e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.253083
Average KL loss: 0.084544
Average total loss: 0.337627
tensor(0.0112, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.8084e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.261249
Average KL loss: 0.084670
Average total loss: 0.345919
tensor(0.0112, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.7243e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.253362
Average KL loss: 0.084795
Average total loss: 0.338157
tensor(0.0112, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.5926e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.255962
Average KL loss: 0.084901
Average total loss: 0.340863
tensor(0.0112, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.1706e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.257198
Average KL loss: 0.085019
Average total loss: 0.342217
tensor(0.0111, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.4675e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.251584
Average KL loss: 0.085142
Average total loss: 0.336726
tensor(0.0111, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.2342e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.248061
Average KL loss: 0.085257
Average total loss: 0.333318
tensor(0.0111, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.8792e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.251823
Average KL loss: 0.085374
Average total loss: 0.337197
tensor(0.0111, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.8322e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.245163
Average KL loss: 0.085490
Average total loss: 0.330653
tensor(0.0111, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.2729e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.248839
Average KL loss: 0.085595
Average total loss: 0.334434
tensor(0.0111, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.8024e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.244883
Average KL loss: 0.085708
Average total loss: 0.330591
tensor(0.0111, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.3132e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.249713
Average KL loss: 0.085813
Average total loss: 0.335526
tensor(0.0111, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.9283e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.242865
Average KL loss: 0.085956
Average total loss: 0.328821
tensor(0.0110, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.2643e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.236534
Average KL loss: 0.086076
Average total loss: 0.322610
tensor(0.0110, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.2164e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.241595
Average KL loss: 0.086191
Average total loss: 0.327787
tensor(0.0110, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.6572e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.240485
Average KL loss: 0.086316
Average total loss: 0.326801
tensor(0.0110, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.1565e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.232430
Average KL loss: 0.086436
Average total loss: 0.318866
tensor(0.0110, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.3268e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.234651
Average KL loss: 0.086534
Average total loss: 0.321185
tensor(0.0110, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-6.9357e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.233895
Average KL loss: 0.086620
Average total loss: 0.320515
tensor(0.0110, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.7127e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.237531
Average KL loss: 0.086728
Average total loss: 0.324259
tensor(0.0110, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.0344e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.234497
Average KL loss: 0.086825
Average total loss: 0.321321
tensor(0.0110, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.4599e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.233134
Average KL loss: 0.086938
Average total loss: 0.320071
tensor(0.0110, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.0564e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.227980
Average KL loss: 0.087033
Average total loss: 0.315014
tensor(0.0110, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.3605e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.232190
Average KL loss: 0.087131
Average total loss: 0.319321
tensor(0.0110, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.0998e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.229333
Average KL loss: 0.087229
Average total loss: 0.316563
tensor(0.0109, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.0517e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.222391
Average KL loss: 0.087328
Average total loss: 0.309720
tensor(0.0109, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.5943e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.223340
Average KL loss: 0.087409
Average total loss: 0.310749
tensor(0.0109, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-8.5079e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.226342
Average KL loss: 0.087480
Average total loss: 0.313821
tensor(0.0109, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-8.8608e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.225548
Average KL loss: 0.087562
Average total loss: 0.313110
tensor(0.0109, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.9084e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.230483
Average KL loss: 0.087646
Average total loss: 0.318129
tensor(0.0109, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.1122e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.217623
Average KL loss: 0.087741
Average total loss: 0.305364
tensor(0.0109, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.7780e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.218700
Average KL loss: 0.087807
Average total loss: 0.306507
tensor(0.0109, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.0633e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.225608
Average KL loss: 0.087887
Average total loss: 0.313495
tensor(0.0109, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.5381e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.227850
Average KL loss: 0.087987
Average total loss: 0.315837
tensor(0.0109, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.4843e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.220265
Average KL loss: 0.088086
Average total loss: 0.308351
tensor(0.0109, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.1369e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.219479
Average KL loss: 0.088185
Average total loss: 0.307665
tensor(0.0109, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-7.1197e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.218558
Average KL loss: 0.088261
Average total loss: 0.306820
tensor(0.0109, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.2968e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.213832
Average KL loss: 0.088367
Average total loss: 0.302199
tensor(0.0109, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.5998e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.222723
Average KL loss: 0.088443
Average total loss: 0.311165
tensor(0.0109, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-9.8644e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.218794
Average KL loss: 0.088552
Average total loss: 0.307346
tensor(0.0109, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.0260e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.222986
Average KL loss: 0.088654
Average total loss: 0.311641
tensor(0.0109, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-8.4834e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.219935
Average KL loss: 0.088748
Average total loss: 0.308683
tensor(0.0109, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-8.5775e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.214828
Average KL loss: 0.088854
Average total loss: 0.303682
tensor(0.0109, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.1498e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.215865
Average KL loss: 0.088943
Average total loss: 0.304808
tensor(0.0108, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-6.3873e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.217043
Average KL loss: 0.089018
Average total loss: 0.306061
tensor(0.0108, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.0129e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.213164
Average KL loss: 0.089105
Average total loss: 0.302269
tensor(0.0108, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.6919e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.215328
Average KL loss: 0.089198
Average total loss: 0.304526
tensor(0.0108, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-6.8151e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.214275
Average KL loss: 0.089300
Average total loss: 0.303575
tensor(0.0108, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.1502e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.214576
Average KL loss: 0.089393
Average total loss: 0.303969
tensor(0.0108, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.3422e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.214029
Average KL loss: 0.089435
Average total loss: 0.303464
tensor(0.0108, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-4.7563e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.205585
Average KL loss: 0.089439
Average total loss: 0.295024
tensor(0.0108, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-8.3574e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.207423
Average KL loss: 0.089443
Average total loss: 0.296865
tensor(0.0108, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-6.3004e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.214382
Average KL loss: 0.089446
Average total loss: 0.303829
tensor(0.0108, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-7.1764e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.212663
Average KL loss: 0.089455
Average total loss: 0.302118
tensor(0.0108, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.9758e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.211057
Average KL loss: 0.089459
Average total loss: 0.300517
tensor(0.0108, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.1328e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.209911
Average KL loss: 0.089464
Average total loss: 0.299375
tensor(0.0108, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-8.0239e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.211188
Average KL loss: 0.089470
Average total loss: 0.300658
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-9.2396e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.211793
Average KL loss: 0.089478
Average total loss: 0.301271
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.2247e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.209828
Average KL loss: 0.089485
Average total loss: 0.299313
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.3178e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.203778
Average KL loss: 0.089491
Average total loss: 0.293269
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-6.9762e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.209909
Average KL loss: 0.089496
Average total loss: 0.299404
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.1741e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.205882
Average KL loss: 0.089501
Average total loss: 0.295383
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-9.6399e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.207887
Average KL loss: 0.089506
Average total loss: 0.297392
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.2885e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.213572
Average KL loss: 0.089511
Average total loss: 0.303083
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-9.6321e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.210031
Average KL loss: 0.089518
Average total loss: 0.299549
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.0194e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.212544
Average KL loss: 0.089525
Average total loss: 0.302069
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.3280e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.213598
Average KL loss: 0.089532
Average total loss: 0.303130
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-9.8374e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.207514
Average KL loss: 0.089539
Average total loss: 0.297053
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.6158e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.213868
Average KL loss: 0.089545
Average total loss: 0.303413
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-9.9603e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.211484
Average KL loss: 0.089553
Average total loss: 0.301037
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-8.2441e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.209393
Average KL loss: 0.089558
Average total loss: 0.298951
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.4020e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.206571
Average KL loss: 0.089562
Average total loss: 0.296133
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.5376e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.210533
Average KL loss: 0.089562
Average total loss: 0.300095
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.0963e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.209540
Average KL loss: 0.089563
Average total loss: 0.299102
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.2829e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.209300
Average KL loss: 0.089563
Average total loss: 0.298863
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.3461e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.206183
Average KL loss: 0.089564
Average total loss: 0.295746
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.0340e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.217767
Average KL loss: 0.089564
Average total loss: 0.307331
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.5630e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.208833
Average KL loss: 0.089565
Average total loss: 0.298398
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-6.0011e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.207517
Average KL loss: 0.089566
Average total loss: 0.297082
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.6695e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.207905
Average KL loss: 0.089566
Average total loss: 0.297471
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-9.8451e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.210740
Average KL loss: 0.089567
Average total loss: 0.300307
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-6.4656e-09, device='cuda:0')
 Percentile value: -1.6521740064945334e-07
Non-zero model percentage: 32.76801300048828%, Non-zero mask percentage: 32.76801300048828%

--- Pruning Level [5/24]: ---
conv1.weight         | nonzeros =    1065 /    1728             ( 61.63%) | total_pruned =     663 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
bn1.weight           | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
bn1.bias             | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   25927 /   36864             ( 70.33%) | total_pruned =   10937 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   14896 /   36864             ( 40.41%) | total_pruned =   21968 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   13439 /   36864             ( 36.46%) | total_pruned =   23425 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   12640 /   36864             ( 34.29%) | total_pruned =   24224 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   14937 /   73728             ( 20.26%) | total_pruned =   58791 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   28412 /  147456             ( 19.27%) | total_pruned =  119044 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2168 /    8192             ( 26.46%) | total_pruned =    6024 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   34650 /  147456             ( 23.50%) | total_pruned =  112806 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   40237 /  147456             ( 27.29%) | total_pruned =  107219 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      73 /     128             ( 57.03%) | total_pruned =      55 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   43794 /  294912             ( 14.85%) | total_pruned =  251118 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     133 /     256             ( 51.95%) | total_pruned =     123 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   77112 /  589824             ( 13.07%) | total_pruned =  512712 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     141 /     256             ( 55.08%) | total_pruned =     115 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6389 /   32768             ( 19.50%) | total_pruned =   26379 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     143 /     256             ( 55.86%) | total_pruned =     113 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   91129 /  589824             ( 15.45%) | total_pruned =  498695 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     159 /     256             ( 62.11%) | total_pruned =      97 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  109538 /  589824             ( 18.57%) | total_pruned =  480286 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     138 /     256             ( 53.91%) | total_pruned =     118 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     214 /     256             ( 83.59%) | total_pruned =      42 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  158030 / 1179648             ( 13.40%) | total_pruned = 1021618 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     308 /     512             ( 60.16%) | total_pruned =     204 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      43 /     512             (  8.40%) | total_pruned =     469 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  531021 / 2359296             ( 22.51%) | total_pruned = 1828275 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     328 /     512             ( 64.06%) | total_pruned =     184 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     446 /     512             ( 87.11%) | total_pruned =      66 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     167 /     512             ( 32.62%) | total_pruned =     345 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   34616 /  131072             ( 26.41%) | total_pruned =   96456 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     350 /     512             ( 68.36%) | total_pruned =     162 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     374 /     512             ( 73.05%) | total_pruned =     138 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     163 /     512             ( 31.84%) | total_pruned =     349 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  943885 / 2359296             ( 40.01%) | total_pruned = 1415411 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     357 /     512             ( 69.73%) | total_pruned =     155 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     413 /     512             ( 80.66%) | total_pruned =      99 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1466398 / 2359296             ( 62.15%) | total_pruned =  892898 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     337 /     512             ( 65.82%) | total_pruned =     175 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     469 /     512             ( 91.60%) | total_pruned =      43 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     466 /     512             ( 91.02%) | total_pruned =      46 | shape = torch.Size([512])
linear.weight        | nonzeros =    4515 /    5120             ( 88.18%) | total_pruned =     605 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 3663058, pruned : 7515704, total: 11178762, Compression rate :       3.05x  ( 67.23% pruned)
Train Epoch: 62/100 Loss: 0.031300 Accuracy: 88.96 100.00 % Best test Accuracy: 89.08%
tensor(0.0108, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-4.7770e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.342404
Average KL loss: 0.088406
Average total loss: 0.430811
tensor(0.0109, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.0089e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.326853
Average KL loss: 0.087423
Average total loss: 0.414277
tensor(0.0110, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-4.1012e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.332084
Average KL loss: 0.086948
Average total loss: 0.419032
tensor(0.0110, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.4572e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.318585
Average KL loss: 0.086700
Average total loss: 0.405284
tensor(0.0110, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.3512e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.310116
Average KL loss: 0.086557
Average total loss: 0.396673
tensor(0.0109, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.0317e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.314721
Average KL loss: 0.086485
Average total loss: 0.401206
tensor(0.0109, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.0240e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.309234
Average KL loss: 0.086471
Average total loss: 0.395705
tensor(0.0109, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.1702e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.309188
Average KL loss: 0.086497
Average total loss: 0.395685
tensor(0.0109, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.8546e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.300941
Average KL loss: 0.086539
Average total loss: 0.387480
tensor(0.0109, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.8249e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.307540
Average KL loss: 0.086596
Average total loss: 0.394135
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.3593e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.305281
Average KL loss: 0.086667
Average total loss: 0.391948
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.1491e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.287833
Average KL loss: 0.086745
Average total loss: 0.374578
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.1011e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.291211
Average KL loss: 0.086835
Average total loss: 0.378045
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.9113e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.291887
Average KL loss: 0.086917
Average total loss: 0.378805
tensor(0.0108, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.7227e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.288094
Average KL loss: 0.087040
Average total loss: 0.375135
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.3137e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.279540
Average KL loss: 0.087132
Average total loss: 0.366672
tensor(0.0108, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.1118e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.279103
Average KL loss: 0.087233
Average total loss: 0.366337
tensor(0.0107, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.2381e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.276823
Average KL loss: 0.087356
Average total loss: 0.364179
tensor(0.0107, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.7662e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.276788
Average KL loss: 0.087479
Average total loss: 0.364267
tensor(0.0107, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.6621e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.268723
Average KL loss: 0.087609
Average total loss: 0.356333
tensor(0.0107, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.9078e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.277535
Average KL loss: 0.087726
Average total loss: 0.365262
tensor(0.0107, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.6498e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.271878
Average KL loss: 0.087858
Average total loss: 0.359737
tensor(0.0107, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.7807e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.271186
Average KL loss: 0.087998
Average total loss: 0.359183
tensor(0.0107, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.4006e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.268773
Average KL loss: 0.088111
Average total loss: 0.356884
tensor(0.0107, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.9709e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.273813
Average KL loss: 0.088252
Average total loss: 0.362066
tensor(0.0107, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.0898e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.262117
Average KL loss: 0.088364
Average total loss: 0.350482
tensor(0.0107, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.4417e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.260807
Average KL loss: 0.088470
Average total loss: 0.349277
tensor(0.0106, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.7503e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.267078
Average KL loss: 0.088603
Average total loss: 0.355681
tensor(0.0106, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.5669e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.263542
Average KL loss: 0.088766
Average total loss: 0.352308
tensor(0.0106, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.4118e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.262320
Average KL loss: 0.088880
Average total loss: 0.351201
tensor(0.0106, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.4660e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.257300
Average KL loss: 0.089007
Average total loss: 0.346306
tensor(0.0106, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.7408e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.254786
Average KL loss: 0.089124
Average total loss: 0.343910
tensor(0.0106, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.9165e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.258913
Average KL loss: 0.089234
Average total loss: 0.348146
tensor(0.0106, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.6939e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.255320
Average KL loss: 0.089339
Average total loss: 0.344660
tensor(0.0106, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.7893e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.255114
Average KL loss: 0.089467
Average total loss: 0.344580
tensor(0.0106, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.9295e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.254611
Average KL loss: 0.089582
Average total loss: 0.344193
tensor(0.0106, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.2458e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.252017
Average KL loss: 0.089702
Average total loss: 0.341719
tensor(0.0106, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.0796e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.245771
Average KL loss: 0.089803
Average total loss: 0.335574
tensor(0.0106, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.7840e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.249138
Average KL loss: 0.089889
Average total loss: 0.339027
tensor(0.0106, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.4437e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.240405
Average KL loss: 0.089991
Average total loss: 0.330397
tensor(0.0106, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.8188e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.246648
Average KL loss: 0.090107
Average total loss: 0.336754
tensor(0.0106, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-7.6250e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.244531
Average KL loss: 0.090213
Average total loss: 0.334744
tensor(0.0106, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.0368e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.251285
Average KL loss: 0.090324
Average total loss: 0.341610
tensor(0.0106, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.1645e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.247216
Average KL loss: 0.090441
Average total loss: 0.337656
tensor(0.0106, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-9.2245e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.243245
Average KL loss: 0.090555
Average total loss: 0.333800
tensor(0.0106, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.1463e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.244120
Average KL loss: 0.090674
Average total loss: 0.334793
tensor(0.0105, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.0678e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.242648
Average KL loss: 0.090778
Average total loss: 0.333426
tensor(0.0105, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-9.1280e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.242340
Average KL loss: 0.090877
Average total loss: 0.333217
tensor(0.0105, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.8300e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.240052
Average KL loss: 0.090990
Average total loss: 0.331042
tensor(0.0105, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.8042e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.239339
Average KL loss: 0.091099
Average total loss: 0.330438
tensor(0.0105, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.1555e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.247400
Average KL loss: 0.091228
Average total loss: 0.338629
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.5894e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.238381
Average KL loss: 0.091293
Average total loss: 0.329674
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.2641e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.237375
Average KL loss: 0.091299
Average total loss: 0.328674
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-8.6394e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.237228
Average KL loss: 0.091305
Average total loss: 0.328533
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.1720e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.236100
Average KL loss: 0.091312
Average total loss: 0.327412
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.5359e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.240901
Average KL loss: 0.091322
Average total loss: 0.332223
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.3722e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.237573
Average KL loss: 0.091331
Average total loss: 0.328904
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.1495e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.241950
Average KL loss: 0.091338
Average total loss: 0.333288
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.5640e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.236348
Average KL loss: 0.091346
Average total loss: 0.327694
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-5.2631e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.242060
Average KL loss: 0.091354
Average total loss: 0.333414
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.1606e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.238739
Average KL loss: 0.091363
Average total loss: 0.330101
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.1556e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.237678
Average KL loss: 0.091370
Average total loss: 0.329048
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.6942e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.240013
Average KL loss: 0.091378
Average total loss: 0.331391
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-6.7289e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.234575
Average KL loss: 0.091386
Average total loss: 0.325961
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.0116e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.236278
Average KL loss: 0.091394
Average total loss: 0.327673
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.1775e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.237590
Average KL loss: 0.091405
Average total loss: 0.328995
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.1739e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.238566
Average KL loss: 0.091415
Average total loss: 0.329981
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.2461e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.229486
Average KL loss: 0.091424
Average total loss: 0.320910
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.7464e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.241016
Average KL loss: 0.091432
Average total loss: 0.332448
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.3659e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.236416
Average KL loss: 0.091441
Average total loss: 0.327856
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.0433e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.236247
Average KL loss: 0.091450
Average total loss: 0.327697
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.3006e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.243540
Average KL loss: 0.091460
Average total loss: 0.335000
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.2155e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.235370
Average KL loss: 0.091471
Average total loss: 0.326841
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.6917e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.234967
Average KL loss: 0.091480
Average total loss: 0.326447
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-7.8644e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.235752
Average KL loss: 0.091489
Average total loss: 0.327241
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-7.5529e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.237776
Average KL loss: 0.091499
Average total loss: 0.329275
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.7181e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.234631
Average KL loss: 0.091509
Average total loss: 0.326140
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.2063e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.234842
Average KL loss: 0.091520
Average total loss: 0.326362
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.3429e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.235915
Average KL loss: 0.091530
Average total loss: 0.327446
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.1697e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.236704
Average KL loss: 0.091535
Average total loss: 0.328239
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.9687e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.235558
Average KL loss: 0.091536
Average total loss: 0.327094
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.5782e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.235670
Average KL loss: 0.091537
Average total loss: 0.327207
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-6.7433e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.240121
Average KL loss: 0.091538
Average total loss: 0.331659
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.2128e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.240430
Average KL loss: 0.091539
Average total loss: 0.331969
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.6068e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.231503
Average KL loss: 0.091539
Average total loss: 0.323043
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.5304e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.242751
Average KL loss: 0.091540
Average total loss: 0.334292
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.2904e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.233276
Average KL loss: 0.091541
Average total loss: 0.324817
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.3765e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.242059
Average KL loss: 0.091542
Average total loss: 0.333601
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.4668e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.238984
Average KL loss: 0.091543
Average total loss: 0.330527
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.8525e-08, device='cuda:0')
 Percentile value: -1.6521310897132935e-07
Non-zero model percentage: 26.214414596557617%, Non-zero mask percentage: 26.214414596557617%

--- Pruning Level [6/24]: ---
conv1.weight         | nonzeros =     863 /    1728             ( 49.94%) | total_pruned =     865 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
bn1.weight           | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   21900 /   36864             ( 59.41%) | total_pruned =   14964 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   12000 /   36864             ( 32.55%) | total_pruned =   24864 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   10812 /   36864             ( 29.33%) | total_pruned =   26052 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   10331 /   36864             ( 28.02%) | total_pruned =   26533 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   12374 /   73728             ( 16.78%) | total_pruned =   61354 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   23412 /  147456             ( 15.88%) | total_pruned =  124044 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1835 /    8192             ( 22.40%) | total_pruned =    6357 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   27610 /  147456             ( 18.72%) | total_pruned =  119846 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   31939 /  147456             ( 21.66%) | total_pruned =  115517 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   35856 /  294912             ( 12.16%) | total_pruned =  259056 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      79 /     256             ( 30.86%) | total_pruned =     177 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   61321 /  589824             ( 10.40%) | total_pruned =  528503 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    5212 /   32768             ( 15.91%) | total_pruned =   27556 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      95 /     256             ( 37.11%) | total_pruned =     161 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   70383 /  589824             ( 11.93%) | total_pruned =  519441 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     104 /     256             ( 40.62%) | total_pruned =     152 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   83907 /  589824             ( 14.23%) | total_pruned =  505917 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  120857 / 1179648             ( 10.25%) | total_pruned = 1058791 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     203 /     512             ( 39.65%) | total_pruned =     309 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     470 /     512             ( 91.80%) | total_pruned =      42 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  404084 / 2359296             ( 17.13%) | total_pruned = 1955212 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     231 /     512             ( 45.12%) | total_pruned =     281 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     419 /     512             ( 81.84%) | total_pruned =      93 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     160 /     512             ( 31.25%) | total_pruned =     352 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   26402 /  131072             ( 20.14%) | total_pruned =  104670 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     266 /     512             ( 51.95%) | total_pruned =     246 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     326 /     512             ( 63.67%) | total_pruned =     186 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     155 /     512             ( 30.27%) | total_pruned =     357 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  755001 / 2359296             ( 32.00%) | total_pruned = 1604295 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     265 /     512             ( 51.76%) | total_pruned =     247 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     371 /     512             ( 72.46%) | total_pruned =     141 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1203234 / 2359296             ( 51.00%) | total_pruned = 1156062 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     251 /     512             ( 49.02%) | total_pruned =     261 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     435 /     512             ( 84.96%) | total_pruned =      77 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     425 /     512             ( 83.01%) | total_pruned =      87 | shape = torch.Size([512])
linear.weight        | nonzeros =    4123 /    5120             ( 80.53%) | total_pruned =     997 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 2930447, pruned : 8248315, total: 11178762, Compression rate :       3.81x  ( 73.79% pruned)
Train Epoch: 49/100 Loss: 0.019893 Accuracy: 88.61 100.00 % Best test Accuracy: 88.63%
tensor(0.0105, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.4852e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.369428
Average KL loss: 0.090476
Average total loss: 0.459904
tensor(0.0105, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-3.3214e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.359863
Average KL loss: 0.089529
Average total loss: 0.449392
tensor(0.0105, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.1211e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.348416
Average KL loss: 0.088980
Average total loss: 0.437396
tensor(0.0105, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.2130e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.355780
Average KL loss: 0.088620
Average total loss: 0.444400
tensor(0.0105, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.5306e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.353130
Average KL loss: 0.088340
Average total loss: 0.441470
tensor(0.0105, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.5794e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.344013
Average KL loss: 0.088137
Average total loss: 0.432150
tensor(0.0104, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.0176e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.342467
Average KL loss: 0.087990
Average total loss: 0.430457
tensor(0.0104, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.2733e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.341013
Average KL loss: 0.087875
Average total loss: 0.428888
tensor(0.0104, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.5682e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.330819
Average KL loss: 0.087777
Average total loss: 0.418597
tensor(0.0104, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.2151e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.332136
Average KL loss: 0.087710
Average total loss: 0.419847
tensor(0.0103, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.6435e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.331125
Average KL loss: 0.087686
Average total loss: 0.418811
tensor(0.0103, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.7573e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.320969
Average KL loss: 0.087667
Average total loss: 0.408636
tensor(0.0103, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.5546e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.336351
Average KL loss: 0.087661
Average total loss: 0.424012
tensor(0.0103, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.5471e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.327484
Average KL loss: 0.087660
Average total loss: 0.415144
tensor(0.0102, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.7426e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.317059
Average KL loss: 0.087655
Average total loss: 0.404714
tensor(0.0102, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.5646e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.318108
Average KL loss: 0.087673
Average total loss: 0.405780
tensor(0.0102, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.2093e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.315048
Average KL loss: 0.087713
Average total loss: 0.402761
tensor(0.0102, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.7922e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.318926
Average KL loss: 0.087745
Average total loss: 0.406671
tensor(0.0102, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.3982e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.306317
Average KL loss: 0.087787
Average total loss: 0.394104
tensor(0.0102, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.8561e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.311810
Average KL loss: 0.087821
Average total loss: 0.399631
tensor(0.0102, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.5815e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.322435
Average KL loss: 0.087891
Average total loss: 0.410325
tensor(0.0101, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.0111e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.308386
Average KL loss: 0.087949
Average total loss: 0.396335
tensor(0.0101, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.5582e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.301014
Average KL loss: 0.088007
Average total loss: 0.389021
tensor(0.0101, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.9578e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.302178
Average KL loss: 0.088060
Average total loss: 0.390238
tensor(0.0101, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.9868e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.301890
Average KL loss: 0.088135
Average total loss: 0.390025
tensor(0.0101, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.1590e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.303257
Average KL loss: 0.088214
Average total loss: 0.391472
tensor(0.0101, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.6892e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.299752
Average KL loss: 0.088298
Average total loss: 0.388050
tensor(0.0101, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.1434e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.296696
Average KL loss: 0.088394
Average total loss: 0.385090
tensor(0.0101, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.0139e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.295830
Average KL loss: 0.088492
Average total loss: 0.384322
tensor(0.0101, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.6008e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.285571
Average KL loss: 0.088574
Average total loss: 0.374145
tensor(0.0101, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.2514e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.293161
Average KL loss: 0.088646
Average total loss: 0.381807
tensor(0.0100, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.3534e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.290197
Average KL loss: 0.088720
Average total loss: 0.378917
tensor(0.0100, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.0978e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.295189
Average KL loss: 0.088821
Average total loss: 0.384009
tensor(0.0100, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.5403e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.284730
Average KL loss: 0.088919
Average total loss: 0.373649
tensor(0.0100, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.6951e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.283732
Average KL loss: 0.088992
Average total loss: 0.372724
tensor(0.0100, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.7667e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.281448
Average KL loss: 0.089071
Average total loss: 0.370518
tensor(0.0100, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.4251e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.291225
Average KL loss: 0.089161
Average total loss: 0.380386
tensor(0.0100, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.7872e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.284867
Average KL loss: 0.089265
Average total loss: 0.374132
tensor(0.0100, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.5291e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.282715
Average KL loss: 0.089359
Average total loss: 0.372074
tensor(0.0100, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.5829e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.283678
Average KL loss: 0.089441
Average total loss: 0.373119
tensor(0.0100, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.6938e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.287720
Average KL loss: 0.089537
Average total loss: 0.377257
tensor(0.0100, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.2801e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.281437
Average KL loss: 0.089633
Average total loss: 0.371069
tensor(0.0100, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.6174e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.273615
Average KL loss: 0.089723
Average total loss: 0.363338
tensor(0.0100, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-8.5943e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.276914
Average KL loss: 0.089822
Average total loss: 0.366736
tensor(0.0100, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.2978e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.272577
Average KL loss: 0.089916
Average total loss: 0.362493
tensor(0.0100, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.0347e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.275720
Average KL loss: 0.090018
Average total loss: 0.365739
tensor(0.0100, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-6.5468e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.275080
Average KL loss: 0.090106
Average total loss: 0.365186
tensor(0.0100, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.7613e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.272430
Average KL loss: 0.090204
Average total loss: 0.362634
tensor(0.0100, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.3782e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.271779
Average KL loss: 0.090301
Average total loss: 0.362080
tensor(0.0100, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.8388e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.266856
Average KL loss: 0.090382
Average total loss: 0.357239
tensor(0.0100, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.6176e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.270299
Average KL loss: 0.090463
Average total loss: 0.360761
tensor(0.0100, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.8547e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.266907
Average KL loss: 0.090568
Average total loss: 0.357476
tensor(0.0099, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.5304e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.263709
Average KL loss: 0.090656
Average total loss: 0.354365
tensor(0.0099, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.8909e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.269275
Average KL loss: 0.090743
Average total loss: 0.360018
tensor(0.0099, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.1308e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.259192
Average KL loss: 0.090845
Average total loss: 0.350037
tensor(0.0099, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.1564e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.257080
Average KL loss: 0.090927
Average total loss: 0.348007
tensor(0.0099, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.3297e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.259742
Average KL loss: 0.091012
Average total loss: 0.350754
tensor(0.0099, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.2800e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.263886
Average KL loss: 0.091119
Average total loss: 0.355005
tensor(0.0099, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.3685e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.261150
Average KL loss: 0.091228
Average total loss: 0.352378
tensor(0.0099, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.7457e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.261052
Average KL loss: 0.091329
Average total loss: 0.352382
tensor(0.0099, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.3634e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.257165
Average KL loss: 0.091425
Average total loss: 0.348590
tensor(0.0099, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.5147e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.261849
Average KL loss: 0.091519
Average total loss: 0.353367
tensor(0.0099, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-7.7978e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.256513
Average KL loss: 0.091617
Average total loss: 0.348131
tensor(0.0099, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.0727e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.256243
Average KL loss: 0.091698
Average total loss: 0.347942
tensor(0.0099, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.6668e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.268375
Average KL loss: 0.091797
Average total loss: 0.360172
tensor(0.0099, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.2293e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.258957
Average KL loss: 0.091919
Average total loss: 0.350876
tensor(0.0099, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.1257e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.253542
Average KL loss: 0.092023
Average total loss: 0.345565
tensor(0.0099, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-9.2279e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.248133
Average KL loss: 0.092115
Average total loss: 0.340247
tensor(0.0099, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.1212e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.250426
Average KL loss: 0.092196
Average total loss: 0.342622
tensor(0.0099, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.4642e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.251626
Average KL loss: 0.092276
Average total loss: 0.343901
tensor(0.0099, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.7290e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.249406
Average KL loss: 0.092365
Average total loss: 0.341771
tensor(0.0099, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-8.3586e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.252785
Average KL loss: 0.092448
Average total loss: 0.345233
tensor(0.0099, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.8249e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.254197
Average KL loss: 0.092552
Average total loss: 0.346749
tensor(0.0099, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.2917e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.252379
Average KL loss: 0.092653
Average total loss: 0.345032
tensor(0.0099, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.3632e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.253608
Average KL loss: 0.092771
Average total loss: 0.346379
tensor(0.0099, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.2854e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.247147
Average KL loss: 0.092880
Average total loss: 0.340027
tensor(0.0099, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.3597e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.248229
Average KL loss: 0.092968
Average total loss: 0.341198
tensor(0.0099, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-8.6576e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.245672
Average KL loss: 0.093050
Average total loss: 0.338722
tensor(0.0099, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.1397e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.248577
Average KL loss: 0.093155
Average total loss: 0.341732
tensor(0.0099, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.8681e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.247882
Average KL loss: 0.093265
Average total loss: 0.341147
tensor(0.0099, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.8154e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.249124
Average KL loss: 0.093363
Average total loss: 0.342487
tensor(0.0099, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.2056e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.245077
Average KL loss: 0.093459
Average total loss: 0.338536
tensor(0.0099, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-9.3367e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.248162
Average KL loss: 0.093531
Average total loss: 0.341693
tensor(0.0099, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.8847e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.243045
Average KL loss: 0.093628
Average total loss: 0.336673
tensor(0.0099, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.0725e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.247263
Average KL loss: 0.093721
Average total loss: 0.340984
tensor(0.0099, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.4188e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.242537
Average KL loss: 0.093833
Average total loss: 0.336370
tensor(0.0099, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.4742e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.236571
Average KL loss: 0.093925
Average total loss: 0.330496
tensor(0.0099, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-9.5676e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.239775
Average KL loss: 0.094009
Average total loss: 0.333784
tensor(0.0099, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.2149e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.240342
Average KL loss: 0.094097
Average total loss: 0.334438
tensor(0.0099, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.1407e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.240826
Average KL loss: 0.094178
Average total loss: 0.335005
tensor(0.0099, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.0132e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.233833
Average KL loss: 0.094259
Average total loss: 0.328092
tensor(0.0099, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.4224e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.240127
Average KL loss: 0.094338
Average total loss: 0.334465
tensor(0.0099, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.5637e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.236324
Average KL loss: 0.094426
Average total loss: 0.330750
tensor(0.0099, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-5.9114e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.236117
Average KL loss: 0.094502
Average total loss: 0.330619
tensor(0.0099, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.2478e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.234574
Average KL loss: 0.094610
Average total loss: 0.329184
tensor(0.0099, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.0421e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.240020
Average KL loss: 0.094695
Average total loss: 0.334716
tensor(0.0099, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-8.0478e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.228632
Average KL loss: 0.094782
Average total loss: 0.323414
tensor(0.0099, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.1594e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.233362
Average KL loss: 0.094846
Average total loss: 0.328208
tensor(0.0099, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-9.5019e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.232173
Average KL loss: 0.094921
Average total loss: 0.327095
tensor(0.0099, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.3995e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.229238
Average KL loss: 0.095005
Average total loss: 0.324243
tensor(0.0099, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.0099e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.234530
Average KL loss: 0.095083
Average total loss: 0.329613
tensor(0.0099, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-7.1592e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.228433
Average KL loss: 0.095181
Average total loss: 0.323614
tensor(0.0099, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-8.0170e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.235514
Average KL loss: 0.095257
Average total loss: 0.330772
tensor(0.0099, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.1419e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.228123
Average KL loss: 0.095346
Average total loss: 0.323469
tensor(0.0099, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-8.4096e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.224972
Average KL loss: 0.095423
Average total loss: 0.320395
tensor(0.0099, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-5.7038e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.233904
Average KL loss: 0.095510
Average total loss: 0.329414
tensor(0.0099, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.5120e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.229638
Average KL loss: 0.095602
Average total loss: 0.325240
tensor(0.0099, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.0782e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.224671
Average KL loss: 0.095678
Average total loss: 0.320349
tensor(0.0099, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-5.9350e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.230990
Average KL loss: 0.095761
Average total loss: 0.326751
tensor(0.0099, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-8.9363e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.234231
Average KL loss: 0.095856
Average total loss: 0.330087
tensor(0.0099, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.4239e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.233030
Average KL loss: 0.095955
Average total loss: 0.328985
tensor(0.0099, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.7867e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.226301
Average KL loss: 0.096062
Average total loss: 0.322364
tensor(0.0099, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.5049e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.233899
Average KL loss: 0.096154
Average total loss: 0.330053
tensor(0.0099, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-5.2444e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.234244
Average KL loss: 0.096244
Average total loss: 0.330488
tensor(0.0099, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.4043e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.225847
Average KL loss: 0.096330
Average total loss: 0.322177
tensor(0.0099, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.2883e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.227117
Average KL loss: 0.096417
Average total loss: 0.323534
tensor(0.0099, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.8745e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.220600
Average KL loss: 0.096484
Average total loss: 0.317084
tensor(0.0099, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-6.0052e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.225338
Average KL loss: 0.096547
Average total loss: 0.321885
tensor(0.0099, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.0299e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.224232
Average KL loss: 0.096636
Average total loss: 0.320868
tensor(0.0099, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.2455e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.221621
Average KL loss: 0.096719
Average total loss: 0.318340
tensor(0.0099, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-8.3828e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.223618
Average KL loss: 0.096809
Average total loss: 0.320427
tensor(0.0099, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-4.6981e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.216086
Average KL loss: 0.096874
Average total loss: 0.312960
tensor(0.0099, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-8.9603e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.222417
Average KL loss: 0.096931
Average total loss: 0.319348
tensor(0.0099, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.2067e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.216517
Average KL loss: 0.096999
Average total loss: 0.313516
tensor(0.0099, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.1086e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.219032
Average KL loss: 0.097060
Average total loss: 0.316092
tensor(0.0099, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-8.7760e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.221037
Average KL loss: 0.097132
Average total loss: 0.318169
tensor(0.0099, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.1899e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.222588
Average KL loss: 0.097205
Average total loss: 0.319793
tensor(0.0099, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.2633e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.220104
Average KL loss: 0.097284
Average total loss: 0.317388
tensor(0.0099, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-8.4463e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.215511
Average KL loss: 0.097368
Average total loss: 0.312878
tensor(0.0099, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-8.1052e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.215907
Average KL loss: 0.097434
Average total loss: 0.313341
tensor(0.0099, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.0452e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.216616
Average KL loss: 0.097501
Average total loss: 0.314117
tensor(0.0099, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-8.8957e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.216818
Average KL loss: 0.097567
Average total loss: 0.314385
tensor(0.0099, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.2881e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.216568
Average KL loss: 0.097647
Average total loss: 0.314214
tensor(0.0099, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-9.6482e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.218760
Average KL loss: 0.097728
Average total loss: 0.316488
tensor(0.0099, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-7.5261e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.214092
Average KL loss: 0.097807
Average total loss: 0.311899
tensor(0.0099, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-7.9151e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.221271
Average KL loss: 0.097878
Average total loss: 0.319148
tensor(0.0099, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-6.9943e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.215462
Average KL loss: 0.097961
Average total loss: 0.313423
tensor(0.0099, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-7.9967e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.217814
Average KL loss: 0.098039
Average total loss: 0.315853
tensor(0.0099, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-3.0072e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.211915
Average KL loss: 0.098114
Average total loss: 0.310029
tensor(0.0099, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.0831e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.218063
Average KL loss: 0.098176
Average total loss: 0.316238
tensor(0.0099, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.4061e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.213495
Average KL loss: 0.098253
Average total loss: 0.311749
tensor(0.0099, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.0984e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.211992
Average KL loss: 0.098302
Average total loss: 0.310294
tensor(0.0099, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.0370e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.216958
Average KL loss: 0.098377
Average total loss: 0.315335
tensor(0.0099, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.0103e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.207725
Average KL loss: 0.098452
Average total loss: 0.306177
tensor(0.0099, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-9.2059e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.218966
Average KL loss: 0.098528
Average total loss: 0.317493
tensor(0.0099, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-4.2339e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.211444
Average KL loss: 0.098605
Average total loss: 0.310049
tensor(0.0099, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-6.4469e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.209415
Average KL loss: 0.098673
Average total loss: 0.308088
tensor(0.0099, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.0849e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.208743
Average KL loss: 0.098745
Average total loss: 0.307489
tensor(0.0099, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-5.8171e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.210174
Average KL loss: 0.098808
Average total loss: 0.308982
tensor(0.0099, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-8.0744e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.212281
Average KL loss: 0.098871
Average total loss: 0.311152
tensor(0.0099, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-9.8637e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.212825
Average KL loss: 0.098954
Average total loss: 0.311779
tensor(0.0099, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-6.6329e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.205222
Average KL loss: 0.099007
Average total loss: 0.304229
tensor(0.0099, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.0991e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.204987
Average KL loss: 0.099062
Average total loss: 0.304049
tensor(0.0099, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.2575e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.202602
Average KL loss: 0.099113
Average total loss: 0.301716
tensor(0.0099, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.5502e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.208085
Average KL loss: 0.099176
Average total loss: 0.307260
tensor(0.0099, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-4.2382e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.205426
Average KL loss: 0.099241
Average total loss: 0.304667
tensor(0.0099, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.4703e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.204270
Average KL loss: 0.099314
Average total loss: 0.303584
tensor(0.0099, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-5.8901e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.203754
Average KL loss: 0.099374
Average total loss: 0.303128
tensor(0.0099, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-6.3226e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.200875
Average KL loss: 0.099432
Average total loss: 0.300307
tensor(0.0099, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.4612e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.207324
Average KL loss: 0.099500
Average total loss: 0.306824
tensor(0.0099, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.0926e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.203330
Average KL loss: 0.099564
Average total loss: 0.302894
tensor(0.0099, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-6.4581e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.204939
Average KL loss: 0.099611
Average total loss: 0.304550
tensor(0.0099, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-6.7318e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.207419
Average KL loss: 0.099673
Average total loss: 0.307092
tensor(0.0099, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.7316e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.202933
Average KL loss: 0.099739
Average total loss: 0.302672
tensor(0.0099, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-5.9077e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.206815
Average KL loss: 0.099812
Average total loss: 0.306627
tensor(0.0099, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.7672e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.203013
Average KL loss: 0.099878
Average total loss: 0.302891
tensor(0.0099, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-6.5973e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.200303
Average KL loss: 0.099932
Average total loss: 0.300235
tensor(0.0099, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.0401e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.200195
Average KL loss: 0.099981
Average total loss: 0.300176
tensor(0.0099, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-4.5987e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.200329
Average KL loss: 0.100038
Average total loss: 0.300367
tensor(0.0099, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-9.0532e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.199958
Average KL loss: 0.100096
Average total loss: 0.300054
tensor(0.0099, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.4704e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.207583
Average KL loss: 0.100157
Average total loss: 0.307740
tensor(0.0099, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-8.6067e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.202848
Average KL loss: 0.100215
Average total loss: 0.303063
tensor(0.0099, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-7.6358e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.200305
Average KL loss: 0.100271
Average total loss: 0.300576
tensor(0.0099, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.0381e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.198970
Average KL loss: 0.100312
Average total loss: 0.299282
tensor(0.0099, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-6.6481e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.205991
Average KL loss: 0.100372
Average total loss: 0.306363
tensor(0.0099, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-9.8837e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.199378
Average KL loss: 0.100425
Average total loss: 0.299803
tensor(0.0099, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-6.1453e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.199740
Average KL loss: 0.100472
Average total loss: 0.300211
tensor(0.0099, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-7.3358e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.200779
Average KL loss: 0.100537
Average total loss: 0.301316
tensor(0.0099, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-7.8246e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.203579
Average KL loss: 0.100601
Average total loss: 0.304179
tensor(0.0099, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-8.8253e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.194698
Average KL loss: 0.100653
Average total loss: 0.295351
tensor(0.0099, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-6.1648e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.196293
Average KL loss: 0.100691
Average total loss: 0.296984
tensor(0.0099, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-8.2332e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.195351
Average KL loss: 0.100732
Average total loss: 0.296083
tensor(0.0099, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-9.3323e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.194523
Average KL loss: 0.100782
Average total loss: 0.295305
tensor(0.0099, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-5.9713e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.197122
Average KL loss: 0.100829
Average total loss: 0.297950
tensor(0.0099, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-7.4619e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.199700
Average KL loss: 0.100873
Average total loss: 0.300573
tensor(0.0099, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-8.0165e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.192556
Average KL loss: 0.100922
Average total loss: 0.293478
tensor(0.0099, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.2173e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.194159
Average KL loss: 0.100966
Average total loss: 0.295125
tensor(0.0099, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.8195e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.198060
Average KL loss: 0.101018
Average total loss: 0.299078
tensor(0.0099, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-7.4475e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.190912
Average KL loss: 0.101065
Average total loss: 0.291977
tensor(0.0099, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.0796e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.192619
Average KL loss: 0.101095
Average total loss: 0.293714
tensor(0.0099, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-8.7935e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.199394
Average KL loss: 0.101153
Average total loss: 0.300547
tensor(0.0099, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.9828e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.194857
Average KL loss: 0.101220
Average total loss: 0.296077
tensor(0.0099, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-7.5356e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.191544
Average KL loss: 0.101275
Average total loss: 0.292819
tensor(0.0099, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.1001e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.196530
Average KL loss: 0.101316
Average total loss: 0.297845
tensor(0.0099, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.0055e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.191416
Average KL loss: 0.101383
Average total loss: 0.292799
tensor(0.0099, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.5752e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.188643
Average KL loss: 0.101433
Average total loss: 0.290076
tensor(0.0099, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.0326e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.196441
Average KL loss: 0.101481
Average total loss: 0.297922
tensor(0.0099, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.0834e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.186489
Average KL loss: 0.101535
Average total loss: 0.288025
tensor(0.0099, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.7301e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.192430
Average KL loss: 0.101576
Average total loss: 0.294006
tensor(0.0099, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.8293e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.193258
Average KL loss: 0.101621
Average total loss: 0.294878
 Percentile value: -1.6453256534987304e-07
Non-zero model percentage: 20.971534729003906%, Non-zero mask percentage: 20.971534729003906%

--- Pruning Level [7/24]: ---
conv1.weight         | nonzeros =     694 /    1728             ( 40.16%) | total_pruned =    1034 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
bn1.weight           | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
bn1.bias             | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   18832 /   36864             ( 51.09%) | total_pruned =   18032 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    9472 /   36864             ( 25.69%) | total_pruned =   27392 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    8591 /   36864             ( 23.30%) | total_pruned =   28273 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    8275 /   36864             ( 22.45%) | total_pruned =   28589 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   10062 /   73728             ( 13.65%) | total_pruned =   63666 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   18721 /  147456             ( 12.70%) | total_pruned =  128735 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1485 /    8192             ( 18.13%) | total_pruned =    6707 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   21582 /  147456             ( 14.64%) | total_pruned =  125874 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   25223 /  147456             ( 17.11%) | total_pruned =  122233 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   28339 /  294912             (  9.61%) | total_pruned =  266573 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     246 /     256             ( 96.09%) | total_pruned =      10 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   47792 /  589824             (  8.10%) | total_pruned =  542032 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      61 /     256             ( 23.83%) | total_pruned =     195 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     246 /     256             ( 96.09%) | total_pruned =      10 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4148 /   32768             ( 12.66%) | total_pruned =   28620 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     201 /     256             ( 78.52%) | total_pruned =      55 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   54591 /  589824             (  9.26%) | total_pruned =  535233 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      81 /     256             ( 31.64%) | total_pruned =     175 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     199 /     256             ( 77.73%) | total_pruned =      57 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   65273 /  589824             ( 11.07%) | total_pruned =  524551 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      60 /     256             ( 23.44%) | total_pruned =     196 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     196 /     256             ( 76.56%) | total_pruned =      60 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   92933 / 1179648             (  7.88%) | total_pruned = 1086715 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     158 /     512             ( 30.86%) | total_pruned =     354 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     448 /     512             ( 87.50%) | total_pruned =      64 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      35 /     512             (  6.84%) | total_pruned =     477 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  314967 / 2359296             ( 13.35%) | total_pruned = 2044329 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     181 /     512             ( 35.35%) | total_pruned =     331 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     386 /     512             ( 75.39%) | total_pruned =     126 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     150 /     512             ( 29.30%) | total_pruned =     362 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   20739 /  131072             ( 15.82%) | total_pruned =  110333 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     187 /     512             ( 36.52%) | total_pruned =     325 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     287 /     512             ( 56.05%) | total_pruned =     225 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     143 /     512             ( 27.93%) | total_pruned =     369 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  601796 / 2359296             ( 25.51%) | total_pruned = 1757500 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     190 /     512             ( 37.11%) | total_pruned =     322 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     324 /     512             ( 63.28%) | total_pruned =     188 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  980938 / 2359296             ( 41.58%) | total_pruned = 1378358 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     182 /     512             ( 35.55%) | total_pruned =     330 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     402 /     512             ( 78.52%) | total_pruned =     110 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     386 /     512             ( 75.39%) | total_pruned =     126 | shape = torch.Size([512])
linear.weight        | nonzeros =    3776 /    5120             ( 73.75%) | total_pruned =    1344 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 2344358, pruned : 8834404, total: 11178762, Compression rate :       4.77x  ( 79.03% pruned)
Train Epoch: 54/100 Loss: 0.010608 Accuracy: 88.26 100.00 % Best test Accuracy: 88.51%
tensor(0.0099, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.9535e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.408316
Average KL loss: 0.100448
Average total loss: 0.508763
tensor(0.0099, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.7832e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.402265
Average KL loss: 0.099098
Average total loss: 0.501363
tensor(0.0099, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.4561e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.382139
Average KL loss: 0.098180
Average total loss: 0.480319
tensor(0.0099, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-4.2467e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.393026
Average KL loss: 0.097482
Average total loss: 0.490508
tensor(0.0099, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.9757e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.382830
Average KL loss: 0.096926
Average total loss: 0.479757
tensor(0.0099, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.9765e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.385888
Average KL loss: 0.096474
Average total loss: 0.482362
tensor(0.0099, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-4.5901e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.363612
Average KL loss: 0.096089
Average total loss: 0.459702
tensor(0.0099, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.3973e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.377128
Average KL loss: 0.095766
Average total loss: 0.472895
tensor(0.0099, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-3.2426e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.359622
Average KL loss: 0.095507
Average total loss: 0.455129
tensor(0.0098, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.7587e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.360809
Average KL loss: 0.095279
Average total loss: 0.456088
tensor(0.0098, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.9188e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.360834
Average KL loss: 0.095085
Average total loss: 0.455918
tensor(0.0098, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-3.7378e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.357380
Average KL loss: 0.094915
Average total loss: 0.452295
tensor(0.0098, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.2850e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.352987
Average KL loss: 0.094771
Average total loss: 0.447757
tensor(0.0098, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-3.0554e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.351475
Average KL loss: 0.094642
Average total loss: 0.446117
tensor(0.0097, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-3.1482e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.339083
Average KL loss: 0.094526
Average total loss: 0.433609
tensor(0.0097, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.4376e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.349266
Average KL loss: 0.094418
Average total loss: 0.443684
tensor(0.0097, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.6983e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.341860
Average KL loss: 0.094342
Average total loss: 0.436202
tensor(0.0097, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.4442e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.335127
Average KL loss: 0.094279
Average total loss: 0.429406
tensor(0.0097, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.8625e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.336743
Average KL loss: 0.094222
Average total loss: 0.430964
tensor(0.0097, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.6364e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.335585
Average KL loss: 0.094189
Average total loss: 0.429774
tensor(0.0096, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.7480e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.325156
Average KL loss: 0.094162
Average total loss: 0.419318
tensor(0.0096, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-3.0404e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.333683
Average KL loss: 0.094147
Average total loss: 0.427830
tensor(0.0096, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.4901e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.321634
Average KL loss: 0.094135
Average total loss: 0.415769
tensor(0.0096, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.0254e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.330862
Average KL loss: 0.094127
Average total loss: 0.424989
tensor(0.0096, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.1090e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.321128
Average KL loss: 0.094133
Average total loss: 0.415260
tensor(0.0096, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.2228e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.323686
Average KL loss: 0.094136
Average total loss: 0.417822
tensor(0.0096, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.3999e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.318174
Average KL loss: 0.094137
Average total loss: 0.412312
tensor(0.0096, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.2049e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.314541
Average KL loss: 0.094147
Average total loss: 0.408687
tensor(0.0096, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.9937e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.320150
Average KL loss: 0.094163
Average total loss: 0.414313
tensor(0.0095, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.3725e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.318558
Average KL loss: 0.094188
Average total loss: 0.412746
tensor(0.0095, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.3000e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.313461
Average KL loss: 0.094208
Average total loss: 0.407669
tensor(0.0095, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.7851e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.317945
Average KL loss: 0.094235
Average total loss: 0.412179
tensor(0.0095, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.1717e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.313016
Average KL loss: 0.094275
Average total loss: 0.407291
tensor(0.0095, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.2031e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.317117
Average KL loss: 0.094321
Average total loss: 0.411438
tensor(0.0095, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.2089e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.303078
Average KL loss: 0.094363
Average total loss: 0.397441
tensor(0.0095, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.9368e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.305267
Average KL loss: 0.094401
Average total loss: 0.399669
tensor(0.0095, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.5850e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.308280
Average KL loss: 0.094451
Average total loss: 0.402730
tensor(0.0095, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.5123e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.307740
Average KL loss: 0.094508
Average total loss: 0.402248
tensor(0.0095, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.9978e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.301969
Average KL loss: 0.094566
Average total loss: 0.396535
tensor(0.0095, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.0161e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.298223
Average KL loss: 0.094617
Average total loss: 0.392841
tensor(0.0095, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.6692e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.294841
Average KL loss: 0.094668
Average total loss: 0.389509
tensor(0.0095, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.5668e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.299887
Average KL loss: 0.094723
Average total loss: 0.394610
tensor(0.0095, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.3647e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.305639
Average KL loss: 0.094790
Average total loss: 0.400429
tensor(0.0095, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.6331e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.292984
Average KL loss: 0.094846
Average total loss: 0.387830
tensor(0.0095, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.4856e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.296583
Average KL loss: 0.094904
Average total loss: 0.391487
tensor(0.0095, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.9882e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.298597
Average KL loss: 0.094973
Average total loss: 0.393570
tensor(0.0095, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.5989e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.287014
Average KL loss: 0.095017
Average total loss: 0.382031
tensor(0.0094, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.8539e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.292075
Average KL loss: 0.095065
Average total loss: 0.387141
tensor(0.0094, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.6974e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.298125
Average KL loss: 0.095125
Average total loss: 0.393251
tensor(0.0094, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.8723e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.287938
Average KL loss: 0.095197
Average total loss: 0.383135
tensor(0.0094, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.8524e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.282336
Average KL loss: 0.095255
Average total loss: 0.377591
tensor(0.0094, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.6639e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.290066
Average KL loss: 0.095322
Average total loss: 0.385388
tensor(0.0094, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.2636e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.284264
Average KL loss: 0.095395
Average total loss: 0.379659
tensor(0.0094, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.7921e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.284056
Average KL loss: 0.095465
Average total loss: 0.379521
tensor(0.0094, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-9.4072e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.287162
Average KL loss: 0.095522
Average total loss: 0.382684
tensor(0.0094, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.5559e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.283779
Average KL loss: 0.095588
Average total loss: 0.379367
tensor(0.0094, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.5972e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.282056
Average KL loss: 0.095654
Average total loss: 0.377710
tensor(0.0094, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.6591e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.280832
Average KL loss: 0.095725
Average total loss: 0.376557
tensor(0.0094, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.4080e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.284394
Average KL loss: 0.095812
Average total loss: 0.380207
tensor(0.0094, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.7442e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.285669
Average KL loss: 0.095901
Average total loss: 0.381570
tensor(0.0094, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.2159e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.288442
Average KL loss: 0.095986
Average total loss: 0.384428
tensor(0.0094, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.2557e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.279188
Average KL loss: 0.096062
Average total loss: 0.375250
tensor(0.0094, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.5896e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.270261
Average KL loss: 0.096149
Average total loss: 0.366410
tensor(0.0094, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.4047e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.278660
Average KL loss: 0.096218
Average total loss: 0.374877
tensor(0.0094, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.7892e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.283467
Average KL loss: 0.096308
Average total loss: 0.379774
tensor(0.0094, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.2599e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.273386
Average KL loss: 0.096387
Average total loss: 0.369772
tensor(0.0094, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.5493e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.274342
Average KL loss: 0.096461
Average total loss: 0.370804
tensor(0.0094, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.4408e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.267387
Average KL loss: 0.096551
Average total loss: 0.363937
tensor(0.0094, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.3879e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.274701
Average KL loss: 0.096635
Average total loss: 0.371336
tensor(0.0094, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-9.9517e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.274427
Average KL loss: 0.096722
Average total loss: 0.371148
tensor(0.0094, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.4052e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.267637
Average KL loss: 0.096809
Average total loss: 0.364446
tensor(0.0094, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.3247e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.270636
Average KL loss: 0.096890
Average total loss: 0.367527
tensor(0.0094, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.4866e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.270080
Average KL loss: 0.096972
Average total loss: 0.367053
tensor(0.0094, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.5399e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.264022
Average KL loss: 0.097048
Average total loss: 0.361071
tensor(0.0094, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.5232e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.267608
Average KL loss: 0.097140
Average total loss: 0.364748
tensor(0.0094, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.5990e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.268452
Average KL loss: 0.097230
Average total loss: 0.365682
tensor(0.0094, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.4422e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.270307
Average KL loss: 0.097324
Average total loss: 0.367631
tensor(0.0094, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.3528e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.264863
Average KL loss: 0.097406
Average total loss: 0.362269
tensor(0.0094, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.3011e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.264393
Average KL loss: 0.097485
Average total loss: 0.361877
tensor(0.0094, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.1760e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.263034
Average KL loss: 0.097575
Average total loss: 0.360609
tensor(0.0094, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.6214e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.259698
Average KL loss: 0.097646
Average total loss: 0.357344
tensor(0.0094, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-7.4616e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.262454
Average KL loss: 0.097732
Average total loss: 0.360186
tensor(0.0094, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.1691e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.270344
Average KL loss: 0.097815
Average total loss: 0.368159
tensor(0.0094, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.7214e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.256118
Average KL loss: 0.097898
Average total loss: 0.354016
tensor(0.0094, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.4722e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.255106
Average KL loss: 0.097970
Average total loss: 0.353076
tensor(0.0094, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.3485e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.267664
Average KL loss: 0.098054
Average total loss: 0.365718
tensor(0.0094, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.7527e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.260496
Average KL loss: 0.098137
Average total loss: 0.358633
tensor(0.0094, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.8564e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.260047
Average KL loss: 0.098211
Average total loss: 0.358258
tensor(0.0094, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.1893e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.257742
Average KL loss: 0.098287
Average total loss: 0.356029
tensor(0.0094, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-7.4335e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.252680
Average KL loss: 0.098362
Average total loss: 0.351041
tensor(0.0094, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-8.2189e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.253001
Average KL loss: 0.098439
Average total loss: 0.351440
tensor(0.0094, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.5208e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.250763
Average KL loss: 0.098515
Average total loss: 0.349279
tensor(0.0094, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.4066e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.258334
Average KL loss: 0.098605
Average total loss: 0.356939
tensor(0.0094, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.9930e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.253971
Average KL loss: 0.098690
Average total loss: 0.352661
tensor(0.0094, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.5166e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.255591
Average KL loss: 0.098761
Average total loss: 0.354353
tensor(0.0094, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.6167e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.248943
Average KL loss: 0.098854
Average total loss: 0.347797
tensor(0.0094, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.4260e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.255218
Average KL loss: 0.098929
Average total loss: 0.354147
tensor(0.0094, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-9.7558e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.251220
Average KL loss: 0.099007
Average total loss: 0.350227
tensor(0.0094, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.3188e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.238857
Average KL loss: 0.099081
Average total loss: 0.337937
tensor(0.0094, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.3923e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.250946
Average KL loss: 0.099148
Average total loss: 0.350093
tensor(0.0094, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.4933e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.246073
Average KL loss: 0.099226
Average total loss: 0.345299
tensor(0.0094, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.3329e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.251724
Average KL loss: 0.099307
Average total loss: 0.351032
tensor(0.0094, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.6115e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.244477
Average KL loss: 0.099396
Average total loss: 0.343873
tensor(0.0094, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-7.8697e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.239456
Average KL loss: 0.099469
Average total loss: 0.338925
tensor(0.0094, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.5409e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.244513
Average KL loss: 0.099537
Average total loss: 0.344050
tensor(0.0094, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.7766e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.241529
Average KL loss: 0.099614
Average total loss: 0.341143
tensor(0.0094, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-6.9059e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.247169
Average KL loss: 0.099696
Average total loss: 0.346864
tensor(0.0094, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.0073e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.242467
Average KL loss: 0.099777
Average total loss: 0.342244
tensor(0.0094, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.0521e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.237892
Average KL loss: 0.099849
Average total loss: 0.337741
tensor(0.0094, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.1192e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.242869
Average KL loss: 0.099928
Average total loss: 0.342796
tensor(0.0094, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.0496e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.237898
Average KL loss: 0.100002
Average total loss: 0.337900
tensor(0.0094, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.3809e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.244590
Average KL loss: 0.100074
Average total loss: 0.344664
tensor(0.0094, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.1768e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.239216
Average KL loss: 0.100148
Average total loss: 0.339365
tensor(0.0094, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.6781e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.244496
Average KL loss: 0.100222
Average total loss: 0.344718
tensor(0.0094, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.0258e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.240735
Average KL loss: 0.100306
Average total loss: 0.341041
tensor(0.0094, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.5844e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.242493
Average KL loss: 0.100392
Average total loss: 0.342885
tensor(0.0094, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.2608e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.238789
Average KL loss: 0.100461
Average total loss: 0.339250
tensor(0.0094, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.3428e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.237256
Average KL loss: 0.100537
Average total loss: 0.337793
tensor(0.0094, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.3701e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.236985
Average KL loss: 0.100620
Average total loss: 0.337605
tensor(0.0094, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.2758e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.233059
Average KL loss: 0.100694
Average total loss: 0.333753
tensor(0.0094, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-9.3663e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.238498
Average KL loss: 0.100768
Average total loss: 0.339266
tensor(0.0094, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.4023e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.235275
Average KL loss: 0.100841
Average total loss: 0.336115
tensor(0.0094, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.0785e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.232780
Average KL loss: 0.100910
Average total loss: 0.333690
tensor(0.0094, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.1545e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.234979
Average KL loss: 0.100991
Average total loss: 0.335970
tensor(0.0094, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.2564e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.233322
Average KL loss: 0.101076
Average total loss: 0.334398
tensor(0.0094, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-8.9374e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.231360
Average KL loss: 0.101158
Average total loss: 0.332517
tensor(0.0094, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.0295e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.239533
Average KL loss: 0.101240
Average total loss: 0.340773
tensor(0.0094, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.1265e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.224818
Average KL loss: 0.101323
Average total loss: 0.326141
tensor(0.0094, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.5085e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.229081
Average KL loss: 0.101387
Average total loss: 0.330468
tensor(0.0094, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.0898e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.234368
Average KL loss: 0.101443
Average total loss: 0.335811
tensor(0.0094, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.3284e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.230120
Average KL loss: 0.101518
Average total loss: 0.331638
tensor(0.0094, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.1724e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.228447
Average KL loss: 0.101587
Average total loss: 0.330034
tensor(0.0094, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-9.7325e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.230725
Average KL loss: 0.101664
Average total loss: 0.332389
tensor(0.0094, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.1696e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.230744
Average KL loss: 0.101738
Average total loss: 0.332482
tensor(0.0094, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.9992e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.223686
Average KL loss: 0.101808
Average total loss: 0.325494
tensor(0.0094, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.4774e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.226757
Average KL loss: 0.101870
Average total loss: 0.328627
tensor(0.0094, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-9.2635e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.232008
Average KL loss: 0.101936
Average total loss: 0.333944
tensor(0.0094, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.8458e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.227259
Average KL loss: 0.102004
Average total loss: 0.329263
tensor(0.0094, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-7.4999e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.232191
Average KL loss: 0.102070
Average total loss: 0.334261
tensor(0.0094, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.3826e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.227360
Average KL loss: 0.102149
Average total loss: 0.329509
tensor(0.0094, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-7.7323e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.223305
Average KL loss: 0.102223
Average total loss: 0.325529
tensor(0.0094, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.3358e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.221677
Average KL loss: 0.102301
Average total loss: 0.323978
tensor(0.0094, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.3638e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.223689
Average KL loss: 0.102370
Average total loss: 0.326058
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-6.1037e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.224663
Average KL loss: 0.102434
Average total loss: 0.327096
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.0403e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.219094
Average KL loss: 0.102505
Average total loss: 0.321599
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-7.4324e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.219476
Average KL loss: 0.102572
Average total loss: 0.322049
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.3901e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.217379
Average KL loss: 0.102643
Average total loss: 0.320022
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-9.5245e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.226278
Average KL loss: 0.102719
Average total loss: 0.328997
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.3465e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.219732
Average KL loss: 0.102799
Average total loss: 0.322530
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.4882e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.220811
Average KL loss: 0.102876
Average total loss: 0.323687
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-7.1580e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.222027
Average KL loss: 0.102948
Average total loss: 0.324975
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.0753e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.216006
Average KL loss: 0.103015
Average total loss: 0.319021
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-9.1001e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.220634
Average KL loss: 0.103078
Average total loss: 0.323712
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-7.4640e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.221747
Average KL loss: 0.103149
Average total loss: 0.324896
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-8.2608e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.214000
Average KL loss: 0.103225
Average total loss: 0.317225
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.0396e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.215229
Average KL loss: 0.103275
Average total loss: 0.318503
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.2491e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.215821
Average KL loss: 0.103337
Average total loss: 0.319158
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-9.6959e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.215161
Average KL loss: 0.103409
Average total loss: 0.318570
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.1150e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.219763
Average KL loss: 0.103482
Average total loss: 0.323244
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-8.4028e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.220821
Average KL loss: 0.103560
Average total loss: 0.324381
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.3135e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.216919
Average KL loss: 0.103633
Average total loss: 0.320552
tensor(0.0094, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.4983e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.212706
Average KL loss: 0.103702
Average total loss: 0.316408
tensor(0.0094, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.0855e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.210964
Average KL loss: 0.103764
Average total loss: 0.314728
tensor(0.0094, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-8.2812e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.217565
Average KL loss: 0.103827
Average total loss: 0.321391
tensor(0.0094, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-6.2128e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.212003
Average KL loss: 0.103894
Average total loss: 0.315897
tensor(0.0094, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-7.2986e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.211519
Average KL loss: 0.103954
Average total loss: 0.315473
tensor(0.0094, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-6.9847e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.214010
Average KL loss: 0.104015
Average total loss: 0.318025
tensor(0.0094, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-5.4936e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.213233
Average KL loss: 0.104073
Average total loss: 0.317306
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-9.6852e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.207100
Average KL loss: 0.104134
Average total loss: 0.311234
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-9.8582e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.212441
Average KL loss: 0.104195
Average total loss: 0.316636
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-9.1589e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.215729
Average KL loss: 0.104261
Average total loss: 0.319990
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.3082e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.212929
Average KL loss: 0.104333
Average total loss: 0.317262
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-9.2792e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.209643
Average KL loss: 0.104403
Average total loss: 0.314046
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.4582e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.213440
Average KL loss: 0.104469
Average total loss: 0.317909
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-8.5256e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.208185
Average KL loss: 0.104525
Average total loss: 0.312711
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-4.2815e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.210153
Average KL loss: 0.104575
Average total loss: 0.314728
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.1054e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.205633
Average KL loss: 0.104634
Average total loss: 0.310267
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.1376e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.212257
Average KL loss: 0.104693
Average total loss: 0.316950
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.0016e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.212353
Average KL loss: 0.104763
Average total loss: 0.317115
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.5304e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.204780
Average KL loss: 0.104828
Average total loss: 0.309608
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-9.1773e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.209952
Average KL loss: 0.104888
Average total loss: 0.314839
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-8.9012e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.204511
Average KL loss: 0.104936
Average total loss: 0.309448
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.1109e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.211017
Average KL loss: 0.104995
Average total loss: 0.316013
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.4691e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.214621
Average KL loss: 0.105070
Average total loss: 0.319691
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.5883e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.215244
Average KL loss: 0.105144
Average total loss: 0.320388
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-5.7570e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.204069
Average KL loss: 0.105216
Average total loss: 0.309285
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-6.3032e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.200274
Average KL loss: 0.105266
Average total loss: 0.305540
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.0363e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.205934
Average KL loss: 0.105325
Average total loss: 0.311259
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-9.4397e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.208713
Average KL loss: 0.105387
Average total loss: 0.314100
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.1163e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.203648
Average KL loss: 0.105449
Average total loss: 0.309097
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.7282e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.201252
Average KL loss: 0.105500
Average total loss: 0.306752
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-9.6960e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.202323
Average KL loss: 0.105557
Average total loss: 0.307880
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-7.1222e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.206636
Average KL loss: 0.105604
Average total loss: 0.312240
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-4.4029e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.204694
Average KL loss: 0.105671
Average total loss: 0.310365
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.4217e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.202464
Average KL loss: 0.105736
Average total loss: 0.308199
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.0875e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.203008
Average KL loss: 0.105793
Average total loss: 0.308801
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-9.9527e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.202288
Average KL loss: 0.105841
Average total loss: 0.308129
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.0835e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.199153
Average KL loss: 0.105892
Average total loss: 0.305045
tensor(0.0095, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-5.2785e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.207053
Average KL loss: 0.105943
Average total loss: 0.312995
tensor(0.0095, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-6.2284e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.199112
Average KL loss: 0.106011
Average total loss: 0.305123
 Percentile value: -1.6131912161654327e-07
Non-zero model percentage: 16.777233123779297%, Non-zero mask percentage: 16.777233123779297%

--- Pruning Level [8/24]: ---
conv1.weight         | nonzeros =     586 /    1728             ( 33.91%) | total_pruned =    1142 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
bn1.weight           | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
bn1.bias             | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   17472 /   36864             ( 47.40%) | total_pruned =   19392 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    7698 /   36864             ( 20.88%) | total_pruned =   29166 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    7040 /   36864             ( 19.10%) | total_pruned =   29824 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    6610 /   36864             ( 17.93%) | total_pruned =   30254 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    8104 /   73728             ( 10.99%) | total_pruned =   65624 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   15080 /  147456             ( 10.23%) | total_pruned =  132376 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1218 /    8192             ( 14.87%) | total_pruned =    6974 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   17126 /  147456             ( 11.61%) | total_pruned =  130330 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   20111 /  147456             ( 13.64%) | total_pruned =  127345 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   22988 /  294912             (  7.79%) | total_pruned =  271924 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      55 /     256             ( 21.48%) | total_pruned =     201 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   38526 /  589824             (  6.53%) | total_pruned =  551298 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      43 /     256             ( 16.80%) | total_pruned =     213 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3389 /   32768             ( 10.34%) | total_pruned =   29379 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      68 /     256             ( 26.56%) | total_pruned =     188 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     193 /     256             ( 75.39%) | total_pruned =      63 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   43183 /  589824             (  7.32%) | total_pruned =  546641 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      65 /     256             ( 25.39%) | total_pruned =     191 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     194 /     256             ( 75.78%) | total_pruned =      62 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   51214 /  589824             (  8.68%) | total_pruned =  538610 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     191 /     256             ( 74.61%) | total_pruned =      65 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   73843 / 1179648             (  6.26%) | total_pruned = 1105805 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     130 /     512             ( 25.39%) | total_pruned =     382 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     430 /     512             ( 83.98%) | total_pruned =      82 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      29 /     512             (  5.66%) | total_pruned =     483 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  249440 / 2359296             ( 10.57%) | total_pruned = 2109856 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     146 /     512             ( 28.52%) | total_pruned =     366 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     363 /     512             ( 70.90%) | total_pruned =     149 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     138 /     512             ( 26.95%) | total_pruned =     374 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   16263 /  131072             ( 12.41%) | total_pruned =  114809 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     155 /     512             ( 30.27%) | total_pruned =     357 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     258 /     512             ( 50.39%) | total_pruned =     254 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     130 /     512             ( 25.39%) | total_pruned =     382 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  474501 / 2359296             ( 20.11%) | total_pruned = 1884795 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     158 /     512             ( 30.86%) | total_pruned =     354 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     287 /     512             ( 56.05%) | total_pruned =     225 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  792134 / 2359296             ( 33.58%) | total_pruned = 1567162 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     150 /     512             ( 29.30%) | total_pruned =     362 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     387 /     512             ( 75.59%) | total_pruned =     125 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     345 /     512             ( 67.38%) | total_pruned =     167 | shape = torch.Size([512])
linear.weight        | nonzeros =    3429 /    5120             ( 66.97%) | total_pruned =    1691 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 1875487, pruned : 9303275, total: 11178762, Compression rate :       5.96x  ( 83.22% pruned)
Train Epoch: 47/100 Loss: 0.014721 Accuracy: 88.09 100.00 % Best test Accuracy: 88.15%
tensor(0.0095, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.0722e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.347820
Average KL loss: 0.105127
Average total loss: 0.452947
tensor(0.0095, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-4.5377e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.369734
Average KL loss: 0.104251
Average total loss: 0.473985
tensor(0.0095, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.8331e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.326618
Average KL loss: 0.103685
Average total loss: 0.430303
tensor(0.0096, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.7811e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.332573
Average KL loss: 0.103257
Average total loss: 0.435831
tensor(0.0096, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.6607e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.336025
Average KL loss: 0.102916
Average total loss: 0.438941
tensor(0.0096, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.3852e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.326566
Average KL loss: 0.102662
Average total loss: 0.429228
tensor(0.0096, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.9557e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.332770
Average KL loss: 0.102456
Average total loss: 0.435226
tensor(0.0096, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.2997e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.319461
Average KL loss: 0.102276
Average total loss: 0.421737
tensor(0.0096, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.2859e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.312200
Average KL loss: 0.102136
Average total loss: 0.414336
tensor(0.0095, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.1018e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.324406
Average KL loss: 0.102019
Average total loss: 0.426425
tensor(0.0095, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.0574e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.313799
Average KL loss: 0.101922
Average total loss: 0.415721
tensor(0.0095, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.9300e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.315031
Average KL loss: 0.101834
Average total loss: 0.416865
tensor(0.0095, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.6984e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.319705
Average KL loss: 0.101762
Average total loss: 0.421468
tensor(0.0095, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.7320e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.311803
Average KL loss: 0.101716
Average total loss: 0.413519
tensor(0.0095, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.8656e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.301498
Average KL loss: 0.101677
Average total loss: 0.403175
tensor(0.0095, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.7979e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.298652
Average KL loss: 0.101643
Average total loss: 0.400295
tensor(0.0095, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.3151e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.306027
Average KL loss: 0.101608
Average total loss: 0.407635
tensor(0.0095, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.7248e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.307883
Average KL loss: 0.101585
Average total loss: 0.409468
tensor(0.0095, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.5207e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.305002
Average KL loss: 0.101572
Average total loss: 0.406574
tensor(0.0095, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.5886e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.298654
Average KL loss: 0.101572
Average total loss: 0.400225
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.9664e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.293806
Average KL loss: 0.101578
Average total loss: 0.395384
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.0800e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.288641
Average KL loss: 0.101575
Average total loss: 0.390216
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.0722e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.300585
Average KL loss: 0.101591
Average total loss: 0.402176
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.4726e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.291778
Average KL loss: 0.101609
Average total loss: 0.393388
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.9476e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.286678
Average KL loss: 0.101634
Average total loss: 0.388311
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-3.2378e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.286075
Average KL loss: 0.101651
Average total loss: 0.387726
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.5544e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.290215
Average KL loss: 0.101679
Average total loss: 0.391894
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.3270e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.285652
Average KL loss: 0.101701
Average total loss: 0.387353
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.8028e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.289136
Average KL loss: 0.101726
Average total loss: 0.390862
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.7911e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.270830
Average KL loss: 0.101754
Average total loss: 0.372584
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.4756e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.285984
Average KL loss: 0.101783
Average total loss: 0.387767
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.6727e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.287109
Average KL loss: 0.101823
Average total loss: 0.388933
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.1324e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.280437
Average KL loss: 0.101861
Average total loss: 0.382298
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.0533e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.281067
Average KL loss: 0.101905
Average total loss: 0.382973
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.6591e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.282326
Average KL loss: 0.101946
Average total loss: 0.384272
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.9193e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.280291
Average KL loss: 0.101983
Average total loss: 0.382274
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.1161e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.279551
Average KL loss: 0.102019
Average total loss: 0.381570
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.6585e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.280974
Average KL loss: 0.102065
Average total loss: 0.383039
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-4.2132e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.274132
Average KL loss: 0.102115
Average total loss: 0.376247
tensor(0.0093, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.1911e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.276166
Average KL loss: 0.102155
Average total loss: 0.378321
tensor(0.0093, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.4218e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.276047
Average KL loss: 0.102205
Average total loss: 0.378252
tensor(0.0093, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.3961e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.263059
Average KL loss: 0.102233
Average total loss: 0.365292
tensor(0.0093, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.5497e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.256509
Average KL loss: 0.102236
Average total loss: 0.358745
tensor(0.0093, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.2488e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.274940
Average KL loss: 0.102239
Average total loss: 0.377180
