Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/100 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-2.1415e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.072658
Average KL loss: 0.000577
Average total loss: 2.073235
tensor(0.0001, device='cuda:0') tensor(5.6240e-05, device='cuda:0') tensor(-1.0110e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.097976
Average KL loss: 0.001529
Average total loss: 2.099505
tensor(0.0002, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-1.5653e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.978525
Average KL loss: 0.002684
Average total loss: 1.981209
tensor(0.0002, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-2.1044e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.942312
Average KL loss: 0.003921
Average total loss: 1.946233
tensor(0.0003, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.0662e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.845623
Average KL loss: 0.005196
Average total loss: 1.850819
tensor(0.0003, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.4435e-07, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.848021
Average KL loss: 0.006482
Average total loss: 1.854503
tensor(0.0003, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-8.3700e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.780949
Average KL loss: 0.007802
Average total loss: 1.788751
tensor(0.0004, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.1160e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.759695
Average KL loss: 0.009096
Average total loss: 1.768792
tensor(0.0004, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-1.8766e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.694774
Average KL loss: 0.010387
Average total loss: 1.705161
tensor(0.0004, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-1.2231e-07, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.629213
Average KL loss: 0.011616
Average total loss: 1.640828
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-9.6541e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.642665
Average KL loss: 0.012759
Average total loss: 1.655424
tensor(0.0004, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-1.7749e-07, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.601003
Average KL loss: 0.013912
Average total loss: 1.614916
tensor(0.0004, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-1.2311e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.592584
Average KL loss: 0.015159
Average total loss: 1.607743
tensor(0.0004, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.2787e-07, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.539939
Average KL loss: 0.016237
Average total loss: 1.556177
tensor(0.0004, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-1.2692e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.509820
Average KL loss: 0.017235
Average total loss: 1.527055
tensor(0.0005, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-1.2373e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.478170
Average KL loss: 0.018207
Average total loss: 1.496377
tensor(0.0005, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-1.1533e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.456380
Average KL loss: 0.019106
Average total loss: 1.475487
tensor(0.0005, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.7048e-07, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.462919
Average KL loss: 0.019929
Average total loss: 1.482848
tensor(0.0005, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.8700e-07, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.393868
Average KL loss: 0.020648
Average total loss: 1.414516
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.5137e-07, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.435955
Average KL loss: 0.021370
Average total loss: 1.457325
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.8810e-07, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.396559
Average KL loss: 0.022120
Average total loss: 1.418679
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.0344e-07, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.362600
Average KL loss: 0.022864
Average total loss: 1.385464
tensor(0.0005, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.7080e-07, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.323014
Average KL loss: 0.023555
Average total loss: 1.346568
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.3334e-07, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.330643
Average KL loss: 0.024193
Average total loss: 1.354837
tensor(0.0005, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.4372e-07, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.319557
Average KL loss: 0.024857
Average total loss: 1.344414
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.5813e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.268116
Average KL loss: 0.025489
Average total loss: 1.293605
tensor(0.0005, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.0774e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.279544
Average KL loss: 0.026039
Average total loss: 1.305583
tensor(0.0005, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.3100e-07, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.247323
Average KL loss: 0.026592
Average total loss: 1.273915
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2171e-07, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.233888
Average KL loss: 0.027066
Average total loss: 1.260954
tensor(0.0006, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-8.4930e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.220761
Average KL loss: 0.027545
Average total loss: 1.248306
tensor(0.0006, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.1821e-07, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.222800
Average KL loss: 0.028028
Average total loss: 1.250829
tensor(0.0006, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.0479e-07, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.195362
Average KL loss: 0.028561
Average total loss: 1.223923
tensor(0.0006, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.1576e-07, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.182320
Average KL loss: 0.029068
Average total loss: 1.211388
tensor(0.0006, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.1883e-07, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.163615
Average KL loss: 0.029565
Average total loss: 1.193180
tensor(0.0007, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.0433e-07, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.175671
Average KL loss: 0.029949
Average total loss: 1.205620
tensor(0.0007, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.1094e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.149040
Average KL loss: 0.030333
Average total loss: 1.179373
tensor(0.0007, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.2361e-07, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.156235
Average KL loss: 0.030794
Average total loss: 1.187029
tensor(0.0007, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.4335e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.149267
Average KL loss: 0.031258
Average total loss: 1.180525
tensor(0.0007, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-8.1347e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.139265
Average KL loss: 0.031695
Average total loss: 1.170960
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-8.7884e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.120319
Average KL loss: 0.032105
Average total loss: 1.152424
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.2331e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.112378
Average KL loss: 0.032546
Average total loss: 1.144923
tensor(0.0008, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.1381e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.095808
Average KL loss: 0.032966
Average total loss: 1.128775
tensor(0.0008, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.2466e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.077746
Average KL loss: 0.033405
Average total loss: 1.111151
tensor(0.0008, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.0759e-07, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.076136
Average KL loss: 0.033760
Average total loss: 1.109896
tensor(0.0009, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.2968e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.063095
Average KL loss: 0.034084
Average total loss: 1.097179
tensor(0.0009, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.0214e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.044255
Average KL loss: 0.034386
Average total loss: 1.078642
tensor(0.0009, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-9.4933e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.044947
Average KL loss: 0.034765
Average total loss: 1.079712
tensor(0.0009, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.3111e-07, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.049686
Average KL loss: 0.035090
Average total loss: 1.084776
tensor(0.0009, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.0434e-07, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.029947
Average KL loss: 0.035430
Average total loss: 1.065377
tensor(0.0010, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.0733e-07, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.002027
Average KL loss: 0.035762
Average total loss: 1.037789
tensor(0.0010, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.0530e-07, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.014951
Average KL loss: 0.036035
Average total loss: 1.050986
tensor(0.0010, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.4714e-07, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.988630
Average KL loss: 0.036313
Average total loss: 1.024943
tensor(0.0010, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.1413e-07, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.999965
Average KL loss: 0.036648
Average total loss: 1.036613
tensor(0.0010, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.2049e-07, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.976284
Average KL loss: 0.036957
Average total loss: 1.013241
tensor(0.0011, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.0762e-07, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.956416
Average KL loss: 0.037179
Average total loss: 0.993596
tensor(0.0011, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.3457e-07, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.969657
Average KL loss: 0.037421
Average total loss: 1.007078
tensor(0.0011, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-8.9014e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.958254
Average KL loss: 0.037748
Average total loss: 0.996002
tensor(0.0011, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.1980e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.966343
Average KL loss: 0.038095
Average total loss: 1.004437
tensor(0.0012, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.1014e-07, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.942150
Average KL loss: 0.038429
Average total loss: 0.980579
tensor(0.0012, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.1709e-07, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.939403
Average KL loss: 0.038755
Average total loss: 0.978157
tensor(0.0012, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-8.6294e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.907359
Average KL loss: 0.039053
Average total loss: 0.946412
tensor(0.0012, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-8.4497e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.911129
Average KL loss: 0.039286
Average total loss: 0.950414
tensor(0.0013, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-9.4357e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.913695
Average KL loss: 0.039578
Average total loss: 0.953272
tensor(0.0013, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-8.0890e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.901517
Average KL loss: 0.039856
Average total loss: 0.941373
tensor(0.0013, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-7.0676e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.883785
Average KL loss: 0.040128
Average total loss: 0.923913
tensor(0.0013, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-9.0956e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.888103
Average KL loss: 0.040305
Average total loss: 0.928408
tensor(0.0013, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-6.6221e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.850119
Average KL loss: 0.040477
Average total loss: 0.890596
tensor(0.0014, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.1791e-07, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.883900
Average KL loss: 0.040681
Average total loss: 0.924581
tensor(0.0014, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.0247e-07, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.878302
Average KL loss: 0.040880
Average total loss: 0.919182
tensor(0.0014, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-9.1233e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.841371
Average KL loss: 0.041083
Average total loss: 0.882453
tensor(0.0014, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-7.3349e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.866452
Average KL loss: 0.041328
Average total loss: 0.907780
tensor(0.0014, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-9.6312e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.839983
Average KL loss: 0.041571
Average total loss: 0.881554
tensor(0.0015, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-9.5700e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.836368
Average KL loss: 0.041807
Average total loss: 0.878175
tensor(0.0015, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.0344e-07, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.835907
Average KL loss: 0.041987
Average total loss: 0.877894
tensor(0.0015, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-7.1250e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.814518
Average KL loss: 0.042180
Average total loss: 0.856698
tensor(0.0015, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-8.1246e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.807350
Average KL loss: 0.042374
Average total loss: 0.849724
tensor(0.0016, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-7.7606e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.806241
Average KL loss: 0.042547
Average total loss: 0.848788
tensor(0.0016, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.0255e-07, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.818111
Average KL loss: 0.042703
Average total loss: 0.860814
tensor(0.0016, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-9.2041e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.811978
Average KL loss: 0.042912
Average total loss: 0.854890
tensor(0.0016, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.0041e-07, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.794659
Average KL loss: 0.043146
Average total loss: 0.837804
tensor(0.0017, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-9.8909e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.796938
Average KL loss: 0.043344
Average total loss: 0.840282
tensor(0.0017, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-7.1448e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.782563
Average KL loss: 0.043488
Average total loss: 0.826051
tensor(0.0017, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-6.7671e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.779774
Average KL loss: 0.043688
Average total loss: 0.823462
tensor(0.0017, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-7.8235e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.762684
Average KL loss: 0.043907
Average total loss: 0.806590
tensor(0.0017, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-7.7915e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.761642
Average KL loss: 0.044036
Average total loss: 0.805678
tensor(0.0018, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.3854e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.758738
Average KL loss: 0.044219
Average total loss: 0.802958
tensor(0.0018, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.1384e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.761732
Average KL loss: 0.044396
Average total loss: 0.806128
tensor(0.0018, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.2353e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.727575
Average KL loss: 0.044550
Average total loss: 0.772125
tensor(0.0018, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.8056e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.739175
Average KL loss: 0.044675
Average total loss: 0.783850
tensor(0.0018, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.8984e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.736970
Average KL loss: 0.044856
Average total loss: 0.781827
tensor(0.0019, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.5569e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.737424
Average KL loss: 0.045014
Average total loss: 0.782438
tensor(0.0019, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.1150e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.725302
Average KL loss: 0.045113
Average total loss: 0.770415
tensor(0.0019, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.8838e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.724833
Average KL loss: 0.045244
Average total loss: 0.770076
tensor(0.0019, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.7588e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.708620
Average KL loss: 0.045404
Average total loss: 0.754024
tensor(0.0019, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-7.5484e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.711289
Average KL loss: 0.045503
Average total loss: 0.756792
tensor(0.0020, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.2332e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.703495
Average KL loss: 0.045597
Average total loss: 0.749092
tensor(0.0020, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.7691e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.697106
Average KL loss: 0.045731
Average total loss: 0.742838
tensor(0.0020, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.6274e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.710226
Average KL loss: 0.045857
Average total loss: 0.756084
tensor(0.0020, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-8.0881e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.687628
Average KL loss: 0.045964
Average total loss: 0.733592
tensor(0.0020, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-9.6304e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.691597
Average KL loss: 0.046066
Average total loss: 0.737664
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.5278e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.684390
Average KL loss: 0.046191
Average total loss: 0.730580
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.3704e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.681953
Average KL loss: 0.046340
Average total loss: 0.728293
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.4093e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.673025
Average KL loss: 0.046508
Average total loss: 0.719533
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-7.6099e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.664855
Average KL loss: 0.046647
Average total loss: 0.711502
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-7.6809e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.664271
Average KL loss: 0.046721
Average total loss: 0.710992
tensor(0.0022, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-7.5218e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.654088
Average KL loss: 0.046800
Average total loss: 0.700888
tensor(0.0022, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-5.6613e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.641372
Average KL loss: 0.046869
Average total loss: 0.688240
tensor(0.0022, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-6.3107e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.652014
Average KL loss: 0.046981
Average total loss: 0.698995
tensor(0.0022, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-7.8603e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.638253
Average KL loss: 0.047094
Average total loss: 0.685347
tensor(0.0022, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-8.6693e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.646783
Average KL loss: 0.047220
Average total loss: 0.694003
tensor(0.0023, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-5.6960e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.651855
Average KL loss: 0.047336
Average total loss: 0.699191
tensor(0.0023, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-7.4587e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.635351
Average KL loss: 0.047474
Average total loss: 0.682825
tensor(0.0023, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-8.1658e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.619032
Average KL loss: 0.047558
Average total loss: 0.666590
tensor(0.0023, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-6.0658e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.615128
Average KL loss: 0.047581
Average total loss: 0.662709
tensor(0.0023, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-7.6461e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.613439
Average KL loss: 0.047625
Average total loss: 0.661064
tensor(0.0024, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-8.2218e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.616791
Average KL loss: 0.047681
Average total loss: 0.664472
tensor(0.0024, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-6.2670e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.624133
Average KL loss: 0.047747
Average total loss: 0.671879
tensor(0.0024, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-7.3790e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.614026
Average KL loss: 0.047868
Average total loss: 0.661894
tensor(0.0024, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.0305e-07, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.604598
Average KL loss: 0.047935
Average total loss: 0.652533
tensor(0.0024, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-6.0479e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.592119
Average KL loss: 0.047963
Average total loss: 0.640082
tensor(0.0024, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-6.4890e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.587447
Average KL loss: 0.047977
Average total loss: 0.635425
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-6.8991e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.582305
Average KL loss: 0.048045
Average total loss: 0.630350
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-7.6028e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.589893
Average KL loss: 0.048084
Average total loss: 0.637977
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-4.6928e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.577220
Average KL loss: 0.048158
Average total loss: 0.625378
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.1299e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.570588
Average KL loss: 0.048196
Average total loss: 0.618784
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.1876e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.572598
Average KL loss: 0.048209
Average total loss: 0.620807
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.1505e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.573175
Average KL loss: 0.048275
Average total loss: 0.621449
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.8182e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.569675
Average KL loss: 0.048363
Average total loss: 0.618038
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-4.0557e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.563873
Average KL loss: 0.048420
Average total loss: 0.612292
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.5524e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.555133
Average KL loss: 0.048433
Average total loss: 0.603565
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.1199e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.548634
Average KL loss: 0.048479
Average total loss: 0.597113
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-9.5152e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.560086
Average KL loss: 0.048504
Average total loss: 0.608590
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.8630e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.541530
Average KL loss: 0.048538
Average total loss: 0.590068
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.6877e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.545024
Average KL loss: 0.048554
Average total loss: 0.593578
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-4.7550e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.534066
Average KL loss: 0.048571
Average total loss: 0.582637
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.1701e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.553801
Average KL loss: 0.048668
Average total loss: 0.602469
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.5153e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.521118
Average KL loss: 0.048709
Average total loss: 0.569826
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.3232e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.527725
Average KL loss: 0.048726
Average total loss: 0.576450
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.8015e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.531507
Average KL loss: 0.048804
Average total loss: 0.580311
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.2708e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.520034
Average KL loss: 0.048831
Average total loss: 0.568865
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.4624e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.529012
Average KL loss: 0.048911
Average total loss: 0.577923
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.8374e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.520469
Average KL loss: 0.048964
Average total loss: 0.569433
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-7.2117e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.509171
Average KL loss: 0.049032
Average total loss: 0.558203
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.0415e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.498188
Average KL loss: 0.049069
Average total loss: 0.547257
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.6793e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.520242
Average KL loss: 0.049122
Average total loss: 0.569364
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.1924e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.500876
Average KL loss: 0.049197
Average total loss: 0.550073
tensor(0.0028, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.9502e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.507915
Average KL loss: 0.049247
Average total loss: 0.557163
tensor(0.0029, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.5253e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.489861
Average KL loss: 0.049279
Average total loss: 0.539140
tensor(0.0029, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.8595e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.490026
Average KL loss: 0.049315
Average total loss: 0.539341
tensor(0.0029, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.2721e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.482751
Average KL loss: 0.049338
Average total loss: 0.532089
tensor(0.0029, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-6.0168e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.489435
Average KL loss: 0.049353
Average total loss: 0.538788
tensor(0.0029, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.5503e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.482457
Average KL loss: 0.049397
Average total loss: 0.531854
tensor(0.0029, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.5263e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.480360
Average KL loss: 0.049419
Average total loss: 0.529778
tensor(0.0029, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-6.4976e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.476190
Average KL loss: 0.049445
Average total loss: 0.525635
tensor(0.0030, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.5127e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.473159
Average KL loss: 0.049495
Average total loss: 0.522654
tensor(0.0030, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.0126e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.470722
Average KL loss: 0.049512
Average total loss: 0.520235
tensor(0.0030, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-6.0390e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.472231
Average KL loss: 0.049542
Average total loss: 0.521773
tensor(0.0030, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.3827e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.465271
Average KL loss: 0.049531
Average total loss: 0.514802
tensor(0.0030, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.4118e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.473439
Average KL loss: 0.049545
Average total loss: 0.522984
tensor(0.0030, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.5975e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.466593
Average KL loss: 0.049584
Average total loss: 0.516177
tensor(0.0030, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-6.0105e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.455297
Average KL loss: 0.049641
Average total loss: 0.504938
tensor(0.0030, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.1649e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.447093
Average KL loss: 0.049656
Average total loss: 0.496750
tensor(0.0031, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-6.2003e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.458714
Average KL loss: 0.049676
Average total loss: 0.508390
tensor(0.0031, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.7921e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.448297
Average KL loss: 0.049669
Average total loss: 0.497966
tensor(0.0031, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.7200e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.446773
Average KL loss: 0.049705
Average total loss: 0.496478
tensor(0.0031, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.7814e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.439858
Average KL loss: 0.049727
Average total loss: 0.489585
tensor(0.0031, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.9630e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.435784
Average KL loss: 0.049734
Average total loss: 0.485518
tensor(0.0031, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-6.6568e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.446650
Average KL loss: 0.049782
Average total loss: 0.496431
tensor(0.0031, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.6150e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.444461
Average KL loss: 0.049840
Average total loss: 0.494301
tensor(0.0032, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.1233e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.425096
Average KL loss: 0.049829
Average total loss: 0.474925
tensor(0.0032, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.1964e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.435570
Average KL loss: 0.049841
Average total loss: 0.485411
tensor(0.0032, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.3512e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.419998
Average KL loss: 0.049897
Average total loss: 0.469895
tensor(0.0032, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.4483e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.431203
Average KL loss: 0.049905
Average total loss: 0.481108
tensor(0.0032, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.9512e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.420439
Average KL loss: 0.049912
Average total loss: 0.470351
tensor(0.0032, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.7670e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.419644
Average KL loss: 0.049957
Average total loss: 0.469601
tensor(0.0032, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.9925e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.416477
Average KL loss: 0.049959
Average total loss: 0.466437
tensor(0.0032, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-6.2594e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.417219
Average KL loss: 0.049975
Average total loss: 0.467193
tensor(0.0033, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.5511e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.424491
Average KL loss: 0.050061
Average total loss: 0.474551
tensor(0.0033, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.4566e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.407617
Average KL loss: 0.050138
Average total loss: 0.457756
tensor(0.0033, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.6228e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.401799
Average KL loss: 0.050091
Average total loss: 0.451890
tensor(0.0033, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.3534e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.405935
Average KL loss: 0.050070
Average total loss: 0.456006
tensor(0.0033, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.5526e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.400356
Average KL loss: 0.050094
Average total loss: 0.450450
tensor(0.0033, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.0513e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.398614
Average KL loss: 0.050094
Average total loss: 0.448708
tensor(0.0033, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.6766e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.390116
Average KL loss: 0.050090
Average total loss: 0.440207
tensor(0.0033, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.7758e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.393849
Average KL loss: 0.050136
Average total loss: 0.443985
tensor(0.0033, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.2655e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.389462
Average KL loss: 0.050155
Average total loss: 0.439617
tensor(0.0034, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.7081e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.385977
Average KL loss: 0.050170
Average total loss: 0.436147
tensor(0.0034, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.5851e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.378585
Average KL loss: 0.050183
Average total loss: 0.428768
tensor(0.0034, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.9563e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.382044
Average KL loss: 0.050149
Average total loss: 0.432194
tensor(0.0034, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.1512e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.387468
Average KL loss: 0.050179
Average total loss: 0.437646
tensor(0.0034, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.2615e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.377308
Average KL loss: 0.050230
Average total loss: 0.427537
tensor(0.0034, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.6608e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.383293
Average KL loss: 0.050265
Average total loss: 0.433559
tensor(0.0034, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.1794e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.380337
Average KL loss: 0.050304
Average total loss: 0.430641
tensor(0.0034, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.0320e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.371536
Average KL loss: 0.050362
Average total loss: 0.421897
tensor(0.0034, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.4036e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.382420
Average KL loss: 0.050393
Average total loss: 0.432813
tensor(0.0034, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.4737e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.364741
Average KL loss: 0.050381
Average total loss: 0.415122
tensor(0.0034, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.5384e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.360794
Average KL loss: 0.050399
Average total loss: 0.411193
tensor(0.0035, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.5808e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.363578
Average KL loss: 0.050400
Average total loss: 0.413977
tensor(0.0035, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.6050e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.371811
Average KL loss: 0.050423
Average total loss: 0.422234
tensor(0.0035, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.4170e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.362384
Average KL loss: 0.050445
Average total loss: 0.412829
 Percentile value: 0.011765844188630581
Non-zero model percentage: 49.999996185302734%, Non-zero mask percentage: 49.999996185302734%

--- Pruning Level [1/12]: ---
conv1.weight         | nonzeros =    1244 /    1728             ( 71.99%) | total_pruned =     484 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   19648 /   36864             ( 53.30%) | total_pruned =   17216 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   19905 /   36864             ( 54.00%) | total_pruned =   16959 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   20016 /   36864             ( 54.30%) | total_pruned =   16848 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   19364 /   36864             ( 52.53%) | total_pruned =   17500 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   39735 /   73728             ( 53.89%) | total_pruned =   33993 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   78089 /  147456             ( 52.96%) | total_pruned =   69367 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5158 /    8192             ( 62.96%) | total_pruned =    3034 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   77221 /  147456             ( 52.37%) | total_pruned =   70235 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   75504 /  147456             ( 51.20%) | total_pruned =   71952 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  157168 /  294912             ( 53.29%) | total_pruned =  137744 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     144 /     256             ( 56.25%) | total_pruned =     112 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  310392 /  589824             ( 52.62%) | total_pruned =  279432 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     128 /     256             ( 50.00%) | total_pruned =     128 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   19549 /   32768             ( 59.66%) | total_pruned =   13219 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     129 /     256             ( 50.39%) | total_pruned =     127 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  300361 /  589824             ( 50.92%) | total_pruned =  289463 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     202 /     256             ( 78.91%) | total_pruned =      54 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  291596 /  589824             ( 49.44%) | total_pruned =  298228 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      76 /     256             ( 29.69%) | total_pruned =     180 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  610221 / 1179648             ( 51.73%) | total_pruned =  569427 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     391 /     512             ( 76.37%) | total_pruned =     121 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1182966 / 2359296             ( 50.14%) | total_pruned = 1176330 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     476 /     512             ( 92.97%) | total_pruned =      36 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   71030 /  131072             ( 54.19%) | total_pruned =   60042 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     427 /     512             ( 83.40%) | total_pruned =      85 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     464 /     512             ( 90.62%) | total_pruned =      48 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1151307 / 2359296             ( 48.80%) | total_pruned = 1207989 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     420 /     512             ( 82.03%) | total_pruned =      92 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     436 /     512             ( 85.16%) | total_pruned =      76 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1127112 / 2359296             ( 47.77%) | total_pruned = 1232184 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     373 /     512             ( 72.85%) | total_pruned =     139 | shape = torch.Size([512])
linear.weight        | nonzeros =    3970 /    5120             ( 77.54%) | total_pruned =    1150 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 5589381, pruned : 5589381, total: 11178762, Compression rate :       2.00x  ( 50.00% pruned)
Train Epoch: 55/100 Loss: 0.000023 Accuracy: 86.71 100.00 % Best test Accuracy: 86.71%
tensor(0.0035, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.7747e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.522483
Average KL loss: 0.044226
Average total loss: 0.566710
tensor(0.0096, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-4.6060e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.505841
Average KL loss: 0.038330
Average total loss: 0.544171
tensor(0.0113, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-5.4337e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.476646
Average KL loss: 0.035843
Average total loss: 0.512489
tensor(0.0120, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-4.6478e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.469384
Average KL loss: 0.034623
Average total loss: 0.504007
tensor(0.0124, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.0913e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.463889
Average KL loss: 0.034032
Average total loss: 0.497921
tensor(0.0126, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.7878e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.453142
Average KL loss: 0.033791
Average total loss: 0.486933
tensor(0.0127, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-4.0053e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.461851
Average KL loss: 0.033773
Average total loss: 0.495624
tensor(0.0127, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-5.8091e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.447127
Average KL loss: 0.033870
Average total loss: 0.480998
tensor(0.0127, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.2411e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.426848
Average KL loss: 0.034042
Average total loss: 0.460890
tensor(0.0126, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.5052e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.419619
Average KL loss: 0.034266
Average total loss: 0.453885
tensor(0.0126, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.9488e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.412420
Average KL loss: 0.034490
Average total loss: 0.446910
tensor(0.0125, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.4714e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.421355
Average KL loss: 0.034728
Average total loss: 0.456083
tensor(0.0124, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.2904e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.418528
Average KL loss: 0.034996
Average total loss: 0.453524
tensor(0.0123, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.3290e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.403402
Average KL loss: 0.035284
Average total loss: 0.438686
tensor(0.0123, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.0970e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.406205
Average KL loss: 0.035585
Average total loss: 0.441790
tensor(0.0122, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.8446e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.377208
Average KL loss: 0.035871
Average total loss: 0.413079
tensor(0.0121, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.2250e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.385148
Average KL loss: 0.036111
Average total loss: 0.421259
tensor(0.0120, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.0439e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.384586
Average KL loss: 0.036364
Average total loss: 0.420950
tensor(0.0120, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.8782e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.390597
Average KL loss: 0.036608
Average total loss: 0.427204
tensor(0.0119, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.1141e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.370162
Average KL loss: 0.036849
Average total loss: 0.407011
tensor(0.0118, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-4.1231e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.368868
Average KL loss: 0.037068
Average total loss: 0.405936
tensor(0.0117, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.5031e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.361274
Average KL loss: 0.037302
Average total loss: 0.398576
tensor(0.0117, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.8345e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.366730
Average KL loss: 0.037513
Average total loss: 0.404243
tensor(0.0116, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.2311e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.366284
Average KL loss: 0.037746
Average total loss: 0.404030
tensor(0.0115, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.7899e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.366153
Average KL loss: 0.037958
Average total loss: 0.404111
tensor(0.0115, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.3829e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.345475
Average KL loss: 0.038182
Average total loss: 0.383657
tensor(0.0114, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.7938e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.359165
Average KL loss: 0.038402
Average total loss: 0.397567
tensor(0.0113, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.9096e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.342523
Average KL loss: 0.038616
Average total loss: 0.381139
tensor(0.0113, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.2515e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.344840
Average KL loss: 0.038803
Average total loss: 0.383643
tensor(0.0112, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.5523e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.344301
Average KL loss: 0.038986
Average total loss: 0.383287
tensor(0.0111, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.7075e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.336952
Average KL loss: 0.039160
Average total loss: 0.376112
tensor(0.0111, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.3400e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.342654
Average KL loss: 0.039349
Average total loss: 0.382002
tensor(0.0110, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.9337e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.334332
Average KL loss: 0.039532
Average total loss: 0.373864
tensor(0.0110, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.8893e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.328847
Average KL loss: 0.039694
Average total loss: 0.368541
tensor(0.0109, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.1285e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.336678
Average KL loss: 0.039857
Average total loss: 0.376535
tensor(0.0108, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-3.7632e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.330938
Average KL loss: 0.040023
Average total loss: 0.370961
tensor(0.0108, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.4674e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.319047
Average KL loss: 0.040190
Average total loss: 0.359237
tensor(0.0107, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.3938e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.331482
Average KL loss: 0.040353
Average total loss: 0.371836
tensor(0.0107, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.9981e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.319819
Average KL loss: 0.040540
Average total loss: 0.360359
tensor(0.0106, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-3.4833e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.320827
Average KL loss: 0.040688
Average total loss: 0.361515
tensor(0.0106, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.1340e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.317747
Average KL loss: 0.040836
Average total loss: 0.358583
tensor(0.0105, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.1176e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.314239
Average KL loss: 0.040977
Average total loss: 0.355215
tensor(0.0105, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.4843e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.302606
Average KL loss: 0.041098
Average total loss: 0.343705
tensor(0.0104, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.1998e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.304976
Average KL loss: 0.041229
Average total loss: 0.346204
tensor(0.0104, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.3629e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.309713
Average KL loss: 0.041351
Average total loss: 0.351064
tensor(0.0103, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.6100e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.316362
Average KL loss: 0.041487
Average total loss: 0.357849
tensor(0.0103, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-4.6269e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.303881
Average KL loss: 0.041664
Average total loss: 0.345545
tensor(0.0103, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.1089e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.301858
Average KL loss: 0.041805
Average total loss: 0.343663
tensor(0.0102, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.8722e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.301584
Average KL loss: 0.041913
Average total loss: 0.343497
tensor(0.0102, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.3155e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.301094
Average KL loss: 0.042035
Average total loss: 0.343129
tensor(0.0101, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-3.1193e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.300009
Average KL loss: 0.042156
Average total loss: 0.342165
tensor(0.0101, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-3.4031e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.288023
Average KL loss: 0.042253
Average total loss: 0.330277
tensor(0.0100, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.6261e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.305463
Average KL loss: 0.042391
Average total loss: 0.347854
tensor(0.0100, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.0514e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.289562
Average KL loss: 0.042559
Average total loss: 0.332121
tensor(0.0100, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.3965e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.290662
Average KL loss: 0.042692
Average total loss: 0.333353
tensor(0.0099, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2251e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.288258
Average KL loss: 0.042814
Average total loss: 0.331073
tensor(0.0099, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-3.8468e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.292030
Average KL loss: 0.042935
Average total loss: 0.334965
tensor(0.0098, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-3.2617e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.288278
Average KL loss: 0.043055
Average total loss: 0.331333
tensor(0.0098, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.0422e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.281728
Average KL loss: 0.043178
Average total loss: 0.324907
tensor(0.0098, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.3079e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.278408
Average KL loss: 0.043294
Average total loss: 0.321702
tensor(0.0097, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.9568e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.275803
Average KL loss: 0.043401
Average total loss: 0.319204
tensor(0.0097, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.0005e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.282141
Average KL loss: 0.043503
Average total loss: 0.325645
tensor(0.0097, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.9550e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.278889
Average KL loss: 0.043631
Average total loss: 0.322520
tensor(0.0096, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.9044e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.280817
Average KL loss: 0.043758
Average total loss: 0.324575
tensor(0.0096, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.5011e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.262601
Average KL loss: 0.043845
Average total loss: 0.306445
tensor(0.0096, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.2867e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.262912
Average KL loss: 0.043921
Average total loss: 0.306833
tensor(0.0095, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.9337e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.269904
Average KL loss: 0.043995
Average total loss: 0.313899
tensor(0.0095, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.9506e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.272999
Average KL loss: 0.044113
Average total loss: 0.317112
tensor(0.0095, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.6819e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.264031
Average KL loss: 0.044212
Average total loss: 0.308243
tensor(0.0094, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.8015e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.264895
Average KL loss: 0.044343
Average total loss: 0.309238
tensor(0.0094, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.1619e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.263171
Average KL loss: 0.044443
Average total loss: 0.307614
tensor(0.0094, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.3745e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.257873
Average KL loss: 0.044510
Average total loss: 0.302383
tensor(0.0094, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.1005e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.247605
Average KL loss: 0.044591
Average total loss: 0.292196
tensor(0.0093, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.4450e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.252116
Average KL loss: 0.044653
Average total loss: 0.296769
tensor(0.0093, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-8.9532e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.260506
Average KL loss: 0.044741
Average total loss: 0.305247
tensor(0.0093, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.8589e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.247482
Average KL loss: 0.044837
Average total loss: 0.292319
tensor(0.0092, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.1425e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.252896
Average KL loss: 0.044929
Average total loss: 0.297825
tensor(0.0092, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.3233e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.252913
Average KL loss: 0.045020
Average total loss: 0.297933
tensor(0.0092, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.5470e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.250188
Average KL loss: 0.045107
Average total loss: 0.295295
tensor(0.0092, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.3353e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.249815
Average KL loss: 0.045187
Average total loss: 0.295002
tensor(0.0091, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.8230e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.242252
Average KL loss: 0.045273
Average total loss: 0.287524
tensor(0.0091, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.6879e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.241437
Average KL loss: 0.045343
Average total loss: 0.286780
tensor(0.0091, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.0362e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.239050
Average KL loss: 0.045408
Average total loss: 0.284458
tensor(0.0090, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-7.8312e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.240310
Average KL loss: 0.045466
Average total loss: 0.285776
tensor(0.0090, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.6424e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.246031
Average KL loss: 0.045535
Average total loss: 0.291566
tensor(0.0090, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.7017e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.237761
Average KL loss: 0.045625
Average total loss: 0.283385
tensor(0.0090, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.6646e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.237445
Average KL loss: 0.045695
Average total loss: 0.283140
tensor(0.0089, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.3040e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.232918
Average KL loss: 0.045760
Average total loss: 0.278678
tensor(0.0089, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.9183e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.234584
Average KL loss: 0.045834
Average total loss: 0.280417
tensor(0.0089, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.1944e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.236570
Average KL loss: 0.045895
Average total loss: 0.282465
tensor(0.0089, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.5363e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.238098
Average KL loss: 0.046003
Average total loss: 0.284101
tensor(0.0088, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.2788e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.230207
Average KL loss: 0.046078
Average total loss: 0.276285
tensor(0.0088, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.0743e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.229261
Average KL loss: 0.046143
Average total loss: 0.275405
tensor(0.0088, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.4432e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.232011
Average KL loss: 0.046196
Average total loss: 0.278207
tensor(0.0088, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.0744e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.221857
Average KL loss: 0.046241
Average total loss: 0.268098
tensor(0.0088, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.0338e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.223147
Average KL loss: 0.046281
Average total loss: 0.269428
tensor(0.0087, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.3642e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.230544
Average KL loss: 0.046356
Average total loss: 0.276901
tensor(0.0087, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.4184e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.221856
Average KL loss: 0.046407
Average total loss: 0.268263
tensor(0.0087, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.2530e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.217429
Average KL loss: 0.046454
Average total loss: 0.263882
tensor(0.0087, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.6103e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.226894
Average KL loss: 0.046495
Average total loss: 0.273389
tensor(0.0086, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.6590e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.221075
Average KL loss: 0.046571
Average total loss: 0.267646
tensor(0.0086, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.1710e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.220730
Average KL loss: 0.046651
Average total loss: 0.267381
tensor(0.0086, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.8588e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.219477
Average KL loss: 0.046719
Average total loss: 0.266196
tensor(0.0086, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.3344e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.219222
Average KL loss: 0.046798
Average total loss: 0.266020
tensor(0.0086, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.3632e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.214974
Average KL loss: 0.046882
Average total loss: 0.261856
tensor(0.0085, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.6938e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.218655
Average KL loss: 0.046934
Average total loss: 0.265590
tensor(0.0085, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.3146e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.214495
Average KL loss: 0.047023
Average total loss: 0.261518
tensor(0.0085, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.6141e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.211255
Average KL loss: 0.047089
Average total loss: 0.258344
tensor(0.0085, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.9280e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.208312
Average KL loss: 0.047151
Average total loss: 0.255463
tensor(0.0084, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.2389e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.209668
Average KL loss: 0.047200
Average total loss: 0.256868
tensor(0.0084, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.0832e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.208197
Average KL loss: 0.047257
Average total loss: 0.255454
tensor(0.0084, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.6632e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.204350
Average KL loss: 0.047308
Average total loss: 0.251658
tensor(0.0084, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.1420e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.205525
Average KL loss: 0.047366
Average total loss: 0.252892
tensor(0.0084, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.6735e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.208355
Average KL loss: 0.047426
Average total loss: 0.255781
tensor(0.0084, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.6669e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.198223
Average KL loss: 0.047493
Average total loss: 0.245716
tensor(0.0083, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.8170e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.201190
Average KL loss: 0.047532
Average total loss: 0.248722
tensor(0.0083, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.7665e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.210732
Average KL loss: 0.047609
Average total loss: 0.258341
tensor(0.0083, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-9.6229e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.204053
Average KL loss: 0.047681
Average total loss: 0.251734
tensor(0.0083, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-9.2294e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.206954
Average KL loss: 0.047713
Average total loss: 0.254666
tensor(0.0083, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.1382e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.200566
Average KL loss: 0.047776
Average total loss: 0.248342
tensor(0.0082, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.4454e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.203777
Average KL loss: 0.047826
Average total loss: 0.251603
tensor(0.0082, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-7.0640e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.198489
Average KL loss: 0.047874
Average total loss: 0.246362
tensor(0.0082, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.7687e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.201984
Average KL loss: 0.047922
Average total loss: 0.249907
tensor(0.0082, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.1260e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.194381
Average KL loss: 0.047977
Average total loss: 0.242359
tensor(0.0082, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.4652e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.194332
Average KL loss: 0.048046
Average total loss: 0.242378
tensor(0.0082, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-8.8864e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.197661
Average KL loss: 0.048107
Average total loss: 0.245767
tensor(0.0081, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.4760e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.192601
Average KL loss: 0.048147
Average total loss: 0.240748
tensor(0.0081, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.0068e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.193463
Average KL loss: 0.048199
Average total loss: 0.241662
tensor(0.0081, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3116e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.189587
Average KL loss: 0.048237
Average total loss: 0.237825
tensor(0.0081, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.8108e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.191650
Average KL loss: 0.048267
Average total loss: 0.239917
tensor(0.0081, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.8096e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.187531
Average KL loss: 0.048330
Average total loss: 0.235860
tensor(0.0081, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.1368e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.188105
Average KL loss: 0.048389
Average total loss: 0.236494
tensor(0.0080, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.2929e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.186043
Average KL loss: 0.048424
Average total loss: 0.234468
tensor(0.0080, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.9747e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.191972
Average KL loss: 0.048458
Average total loss: 0.240430
tensor(0.0080, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.4332e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.181860
Average KL loss: 0.048524
Average total loss: 0.230384
tensor(0.0080, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3124e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.185756
Average KL loss: 0.048565
Average total loss: 0.234321
tensor(0.0080, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.2291e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.183718
Average KL loss: 0.048611
Average total loss: 0.232329
tensor(0.0080, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.7968e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.189104
Average KL loss: 0.048682
Average total loss: 0.237786
tensor(0.0080, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.7012e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.185223
Average KL loss: 0.048723
Average total loss: 0.233946
tensor(0.0079, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-8.6039e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.172931
Average KL loss: 0.048751
Average total loss: 0.221682
tensor(0.0079, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.1616e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.170621
Average KL loss: 0.048765
Average total loss: 0.219386
tensor(0.0079, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.5681e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.178108
Average KL loss: 0.048770
Average total loss: 0.226879
tensor(0.0079, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.3841e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.179030
Average KL loss: 0.048803
Average total loss: 0.227833
tensor(0.0079, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.1764e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.179837
Average KL loss: 0.048860
Average total loss: 0.228697
tensor(0.0079, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.0207e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.175127
Average KL loss: 0.048915
Average total loss: 0.224042
tensor(0.0078, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.3545e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.173024
Average KL loss: 0.048924
Average total loss: 0.221948
tensor(0.0078, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.1564e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.168404
Average KL loss: 0.048937
Average total loss: 0.217341
tensor(0.0078, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.3940e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.180767
Average KL loss: 0.048948
Average total loss: 0.229715
tensor(0.0078, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.1454e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.172726
Average KL loss: 0.049005
Average total loss: 0.221731
tensor(0.0078, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-4.4582e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.178501
Average KL loss: 0.049060
Average total loss: 0.227561
tensor(0.0078, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-9.3850e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.174767
Average KL loss: 0.049112
Average total loss: 0.223878
tensor(0.0078, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.7632e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.173102
Average KL loss: 0.049164
Average total loss: 0.222265
tensor(0.0078, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.1044e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.167782
Average KL loss: 0.049202
Average total loss: 0.216984
tensor(0.0077, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.2982e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.170644
Average KL loss: 0.049233
Average total loss: 0.219878
tensor(0.0077, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2372e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.168637
Average KL loss: 0.049288
Average total loss: 0.217925
tensor(0.0077, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.4532e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.166979
Average KL loss: 0.049313
Average total loss: 0.216292
tensor(0.0077, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.4795e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.171682
Average KL loss: 0.049362
Average total loss: 0.221045
tensor(0.0077, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.5892e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.168513
Average KL loss: 0.049394
Average total loss: 0.217906
tensor(0.0077, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.8713e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.162750
Average KL loss: 0.049441
Average total loss: 0.212191
tensor(0.0077, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.1849e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.163969
Average KL loss: 0.049466
Average total loss: 0.213435
tensor(0.0077, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.0211e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.164920
Average KL loss: 0.049495
Average total loss: 0.214416
tensor(0.0076, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.0206e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.162753
Average KL loss: 0.049525
Average total loss: 0.212278
tensor(0.0076, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.9306e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.166676
Average KL loss: 0.049555
Average total loss: 0.216231
tensor(0.0076, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.0041e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.162248
Average KL loss: 0.049607
Average total loss: 0.211855
tensor(0.0076, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.8974e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.164019
Average KL loss: 0.049647
Average total loss: 0.213667
tensor(0.0076, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-8.5381e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.158342
Average KL loss: 0.049659
Average total loss: 0.208001
tensor(0.0076, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.3228e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.159744
Average KL loss: 0.049694
Average total loss: 0.209438
tensor(0.0076, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.9456e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.157496
Average KL loss: 0.049726
Average total loss: 0.207221
tensor(0.0076, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.4903e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.154202
Average KL loss: 0.049754
Average total loss: 0.203956
tensor(0.0075, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.5862e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.165070
Average KL loss: 0.049776
Average total loss: 0.214846
tensor(0.0075, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.3212e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.156586
Average KL loss: 0.049824
Average total loss: 0.206410
tensor(0.0075, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2823e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.158356
Average KL loss: 0.049848
Average total loss: 0.208204
tensor(0.0075, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.0682e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.155269
Average KL loss: 0.049877
Average total loss: 0.205145
tensor(0.0075, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.7056e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.154844
Average KL loss: 0.049917
Average total loss: 0.204761
tensor(0.0075, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.1288e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.150112
Average KL loss: 0.049946
Average total loss: 0.200057
tensor(0.0075, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.3315e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.147028
Average KL loss: 0.049974
Average total loss: 0.197003
tensor(0.0075, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.4812e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.151081
Average KL loss: 0.049979
Average total loss: 0.201060
tensor(0.0074, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.3061e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.153134
Average KL loss: 0.050004
Average total loss: 0.203139
tensor(0.0074, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.0356e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.153025
Average KL loss: 0.050053
Average total loss: 0.203078
tensor(0.0074, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.8517e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.150394
Average KL loss: 0.050105
Average total loss: 0.200500
tensor(0.0074, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.9587e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.148227
Average KL loss: 0.050099
Average total loss: 0.198326
tensor(0.0074, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.1888e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.147851
Average KL loss: 0.050117
Average total loss: 0.197968
tensor(0.0074, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.0004e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.155463
Average KL loss: 0.050138
Average total loss: 0.205601
tensor(0.0074, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.5600e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.150952
Average KL loss: 0.050175
Average total loss: 0.201127
tensor(0.0074, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0741e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.146684
Average KL loss: 0.050198
Average total loss: 0.196881
tensor(0.0074, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.7743e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.146728
Average KL loss: 0.050224
Average total loss: 0.196952
tensor(0.0073, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.3168e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.151699
Average KL loss: 0.050247
Average total loss: 0.201946
tensor(0.0073, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.4514e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.149738
Average KL loss: 0.050299
Average total loss: 0.200037
tensor(0.0073, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.8528e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.150110
Average KL loss: 0.050334
Average total loss: 0.200444
tensor(0.0073, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.6725e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.141791
Average KL loss: 0.050370
Average total loss: 0.192160
tensor(0.0073, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.6563e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.147490
Average KL loss: 0.050396
Average total loss: 0.197886
tensor(0.0073, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.5164e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.141236
Average KL loss: 0.050418
Average total loss: 0.191654
tensor(0.0073, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0602e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.136742
Average KL loss: 0.050435
Average total loss: 0.187177
tensor(0.0073, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.8146e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.147997
Average KL loss: 0.050460
Average total loss: 0.198457
tensor(0.0073, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.1473e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.142036
Average KL loss: 0.050517
Average total loss: 0.192553
tensor(0.0072, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4829e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.138309
Average KL loss: 0.050536
Average total loss: 0.188844
tensor(0.0072, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4063e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.144244
Average KL loss: 0.050538
Average total loss: 0.194782
tensor(0.0072, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4127e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.135993
Average KL loss: 0.050565
Average total loss: 0.186558
tensor(0.0072, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0479e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.144573
Average KL loss: 0.050580
Average total loss: 0.195153
tensor(0.0072, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4668e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.139123
Average KL loss: 0.050622
Average total loss: 0.189745
 Percentile value: 0.020790230482816696
Non-zero model percentage: 25.000003814697266%, Non-zero mask percentage: 25.000003814697266%

--- Pruning Level [2/12]: ---
conv1.weight         | nonzeros =    1159 /    1728             ( 67.07%) | total_pruned =     569 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   13262 /   36864             ( 35.98%) | total_pruned =   23602 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   13655 /   36864             ( 37.04%) | total_pruned =   23209 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   13544 /   36864             ( 36.74%) | total_pruned =   23320 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   12996 /   36864             ( 35.25%) | total_pruned =   23868 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   25940 /   73728             ( 35.18%) | total_pruned =   47788 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   49418 /  147456             ( 33.51%) | total_pruned =   98038 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4092 /    8192             ( 49.95%) | total_pruned =    4100 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   44104 /  147456             ( 29.91%) | total_pruned =  103352 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   42908 /  147456             ( 29.10%) | total_pruned =  104548 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   95633 /  294912             ( 32.43%) | total_pruned =  199279 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     138 /     256             ( 53.91%) | total_pruned =     118 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  183264 /  589824             ( 31.07%) | total_pruned =  406560 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   14616 /   32768             ( 44.60%) | total_pruned =   18152 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     126 /     256             ( 49.22%) | total_pruned =     130 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  138265 /  589824             ( 23.44%) | total_pruned =  451559 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  133903 /  589824             ( 22.70%) | total_pruned =  455921 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      76 /     256             ( 29.69%) | total_pruned =     180 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  345091 / 1179648             ( 29.25%) | total_pruned =  834557 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     375 /     512             ( 73.24%) | total_pruned =     137 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  621050 / 2359296             ( 26.32%) | total_pruned = 1738246 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     466 /     512             ( 91.02%) | total_pruned =      46 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   38378 /  131072             ( 29.28%) | total_pruned =   92694 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     425 /     512             ( 83.01%) | total_pruned =      87 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     454 /     512             ( 88.67%) | total_pruned =      58 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  500873 / 2359296             ( 21.23%) | total_pruned = 1858423 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     420 /     512             ( 82.03%) | total_pruned =      92 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     336 /     512             ( 65.62%) | total_pruned =     176 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  491255 / 2359296             ( 20.82%) | total_pruned = 1868041 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     315 /     512             ( 61.52%) | total_pruned =     197 | shape = torch.Size([512])
linear.weight        | nonzeros =    3765 /    5120             ( 73.54%) | total_pruned =    1355 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 2794691, pruned : 8384071, total: 11178762, Compression rate :       4.00x  ( 75.00% pruned)
Train Epoch: 28/100 Loss: 0.000006 Accuracy: 86.93 100.00 % Best test Accuracy: 87.28%
tensor(0.0072, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.6525e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.249808
Average KL loss: 0.047449
Average total loss: 0.297257
tensor(0.0106, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.5258e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.239618
Average KL loss: 0.044784
Average total loss: 0.284403
tensor(0.0115, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.7745e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.244896
Average KL loss: 0.043870
Average total loss: 0.288765
tensor(0.0118, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.5071e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.233637
Average KL loss: 0.043512
Average total loss: 0.277149
tensor(0.0119, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.9166e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.236719
Average KL loss: 0.043403
Average total loss: 0.280122
tensor(0.0120, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-7.1473e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.232380
Average KL loss: 0.043395
Average total loss: 0.275775
tensor(0.0120, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.6218e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.228274
Average KL loss: 0.043443
Average total loss: 0.271717
tensor(0.0119, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.2481e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.227742
Average KL loss: 0.043527
Average total loss: 0.271269
tensor(0.0119, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.4570e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.228327
Average KL loss: 0.043631
Average total loss: 0.271958
tensor(0.0118, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(9.0425e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.220752
Average KL loss: 0.043739
Average total loss: 0.264491
tensor(0.0118, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.9629e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.217955
Average KL loss: 0.043852
Average total loss: 0.261808
tensor(0.0117, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.0477e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.215892
Average KL loss: 0.043971
Average total loss: 0.259863
tensor(0.0116, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-6.5632e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.209321
Average KL loss: 0.044091
Average total loss: 0.253412
tensor(0.0116, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.2116e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.200603
Average KL loss: 0.044193
Average total loss: 0.244796
tensor(0.0115, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.7012e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.204020
Average KL loss: 0.044299
Average total loss: 0.248319
tensor(0.0115, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.2137e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.208118
Average KL loss: 0.044421
Average total loss: 0.252539
tensor(0.0114, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.2305e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.207872
Average KL loss: 0.044534
Average total loss: 0.252407
tensor(0.0113, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.3079e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.203375
Average KL loss: 0.044648
Average total loss: 0.248023
tensor(0.0113, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-8.8427e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.202416
Average KL loss: 0.044765
Average total loss: 0.247182
tensor(0.0112, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.2653e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.203143
Average KL loss: 0.044878
Average total loss: 0.248021
tensor(0.0112, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.0870e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.193963
Average KL loss: 0.044965
Average total loss: 0.238928
tensor(0.0111, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.8767e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.191438
Average KL loss: 0.045062
Average total loss: 0.236501
tensor(0.0111, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.4816e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.194698
Average KL loss: 0.045182
Average total loss: 0.239879
tensor(0.0110, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.8505e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.192226
Average KL loss: 0.045290
Average total loss: 0.237516
tensor(0.0110, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-8.5639e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.193809
Average KL loss: 0.045398
Average total loss: 0.239207
tensor(0.0109, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.9958e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.189676
Average KL loss: 0.045490
Average total loss: 0.235167
tensor(0.0109, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.5643e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.193360
Average KL loss: 0.045602
Average total loss: 0.238962
tensor(0.0109, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.0423e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.191045
Average KL loss: 0.045724
Average total loss: 0.236769
tensor(0.0108, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.1924e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.187068
Average KL loss: 0.045846
Average total loss: 0.232914
tensor(0.0108, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.3780e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.182400
Average KL loss: 0.045948
Average total loss: 0.228348
tensor(0.0107, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.1832e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.185165
Average KL loss: 0.046031
Average total loss: 0.231196
tensor(0.0107, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.1056e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.183811
Average KL loss: 0.046124
Average total loss: 0.229935
tensor(0.0106, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-7.3068e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.188388
Average KL loss: 0.046237
Average total loss: 0.234625
tensor(0.0106, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.2166e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.185510
Average KL loss: 0.046347
Average total loss: 0.231857
tensor(0.0106, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-7.7526e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.179111
Average KL loss: 0.046450
Average total loss: 0.225561
tensor(0.0105, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.2993e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.181406
Average KL loss: 0.046530
Average total loss: 0.227936
tensor(0.0105, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.2771e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.173331
Average KL loss: 0.046612
Average total loss: 0.219944
tensor(0.0104, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.5426e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.175638
Average KL loss: 0.046697
Average total loss: 0.222335
tensor(0.0104, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.7068e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.171084
Average KL loss: 0.046773
Average total loss: 0.217857
tensor(0.0104, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2390e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.180073
Average KL loss: 0.046869
Average total loss: 0.226942
tensor(0.0103, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.5388e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.167527
Average KL loss: 0.046951
Average total loss: 0.214478
tensor(0.0103, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.8390e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.179104
Average KL loss: 0.047030
Average total loss: 0.226134
tensor(0.0103, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.7837e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.176339
Average KL loss: 0.047124
Average total loss: 0.223463
tensor(0.0102, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-9.3085e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.173554
Average KL loss: 0.047223
Average total loss: 0.220777
tensor(0.0102, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.0741e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.177668
Average KL loss: 0.047313
Average total loss: 0.224981
tensor(0.0102, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.3886e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.168465
Average KL loss: 0.047407
Average total loss: 0.215872
tensor(0.0101, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-8.5275e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.171328
Average KL loss: 0.047491
Average total loss: 0.218820
tensor(0.0101, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.0157e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.163522
Average KL loss: 0.047579
Average total loss: 0.211101
tensor(0.0101, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.5880e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.172881
Average KL loss: 0.047663
Average total loss: 0.220544
tensor(0.0101, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0958e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.171112
Average KL loss: 0.047771
Average total loss: 0.218883
tensor(0.0100, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0678e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.161873
Average KL loss: 0.047860
Average total loss: 0.209732
tensor(0.0100, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.2338e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.173030
Average KL loss: 0.047941
Average total loss: 0.220971
tensor(0.0100, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.0868e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.165067
Average KL loss: 0.048051
Average total loss: 0.213118
tensor(0.0099, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.2471e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.161018
Average KL loss: 0.048116
Average total loss: 0.209135
tensor(0.0099, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.8848e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.165218
Average KL loss: 0.048182
Average total loss: 0.213400
tensor(0.0099, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.7833e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.164169
Average KL loss: 0.048257
Average total loss: 0.212426
tensor(0.0099, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0986e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.165130
Average KL loss: 0.048335
Average total loss: 0.213464
tensor(0.0098, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.5349e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.159351
Average KL loss: 0.048412
Average total loss: 0.207762
tensor(0.0098, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.3152e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.162483
Average KL loss: 0.048482
Average total loss: 0.210965
tensor(0.0098, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.7908e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.157425
Average KL loss: 0.048570
Average total loss: 0.205995
tensor(0.0097, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4854e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.155095
Average KL loss: 0.048635
Average total loss: 0.203730
tensor(0.0097, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-9.7957e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.159049
Average KL loss: 0.048696
Average total loss: 0.207745
tensor(0.0097, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.3163e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.163571
Average KL loss: 0.048781
Average total loss: 0.212352
tensor(0.0097, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.6055e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.153230
Average KL loss: 0.048868
Average total loss: 0.202098
tensor(0.0096, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.4726e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.156576
Average KL loss: 0.048929
Average total loss: 0.205505
tensor(0.0096, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4265e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.152006
Average KL loss: 0.048985
Average total loss: 0.200991
tensor(0.0096, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4375e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.158530
Average KL loss: 0.049032
Average total loss: 0.207562
tensor(0.0096, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.0680e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.147735
Average KL loss: 0.049116
Average total loss: 0.196851
tensor(0.0095, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0622e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.149278
Average KL loss: 0.049182
Average total loss: 0.198460
tensor(0.0095, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.0383e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.150477
Average KL loss: 0.049233
Average total loss: 0.199710
tensor(0.0095, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-9.8660e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.148455
Average KL loss: 0.049283
Average total loss: 0.197739
tensor(0.0095, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-9.0250e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.149229
Average KL loss: 0.049342
Average total loss: 0.198572
tensor(0.0094, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-9.6642e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.151207
Average KL loss: 0.049396
Average total loss: 0.200603
tensor(0.0094, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-6.3907e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.151440
Average KL loss: 0.049458
Average total loss: 0.200898
tensor(0.0094, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(7.9965e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.149689
Average KL loss: 0.049523
Average total loss: 0.199212
tensor(0.0094, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.3209e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.151563
Average KL loss: 0.049592
Average total loss: 0.201155
tensor(0.0094, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.5790e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.146352
Average KL loss: 0.049680
Average total loss: 0.196032
tensor(0.0093, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.8462e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.147919
Average KL loss: 0.049755
Average total loss: 0.197674
tensor(0.0093, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-6.5485e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.144084
Average KL loss: 0.049825
Average total loss: 0.193909
tensor(0.0093, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-9.2991e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.145945
Average KL loss: 0.049877
Average total loss: 0.195821
tensor(0.0093, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.4055e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.145521
Average KL loss: 0.049933
Average total loss: 0.195453
tensor(0.0092, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.9691e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.137545
Average KL loss: 0.049974
Average total loss: 0.187520
tensor(0.0092, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.4864e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.143513
Average KL loss: 0.050009
Average total loss: 0.193522
tensor(0.0092, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-9.0343e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.140141
Average KL loss: 0.050066
Average total loss: 0.190206
tensor(0.0092, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.3351e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.141743
Average KL loss: 0.050113
Average total loss: 0.191856
tensor(0.0092, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.5574e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.149635
Average KL loss: 0.050171
Average total loss: 0.199806
tensor(0.0091, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.8011e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.143459
Average KL loss: 0.050241
Average total loss: 0.193700
tensor(0.0091, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.2944e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.138099
Average KL loss: 0.050303
Average total loss: 0.188403
tensor(0.0091, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.0152e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.138798
Average KL loss: 0.050363
Average total loss: 0.189161
tensor(0.0091, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(1.8540e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.142711
Average KL loss: 0.050416
Average total loss: 0.193126
tensor(0.0091, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.4727e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.142332
Average KL loss: 0.050486
Average total loss: 0.192818
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.5225e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.142619
Average KL loss: 0.050543
Average total loss: 0.193162
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.9918e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.139346
Average KL loss: 0.050622
Average total loss: 0.189968
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.3501e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.142604
Average KL loss: 0.050653
Average total loss: 0.193257
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.4747e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.142222
Average KL loss: 0.050647
Average total loss: 0.192869
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.1923e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.136442
Average KL loss: 0.050640
Average total loss: 0.187082
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-9.9167e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.139854
Average KL loss: 0.050632
Average total loss: 0.190486
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-5.0680e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.135749
Average KL loss: 0.050624
Average total loss: 0.186373
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.3649e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.142853
Average KL loss: 0.050617
Average total loss: 0.193470
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.9679e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.139218
Average KL loss: 0.050611
Average total loss: 0.189829
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(2.1362e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.137820
Average KL loss: 0.050603
Average total loss: 0.188423
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.1000e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.141070
Average KL loss: 0.050597
Average total loss: 0.191666
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.0178e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.134604
Average KL loss: 0.050590
Average total loss: 0.185194
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.7107e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.133295
Average KL loss: 0.050581
Average total loss: 0.183876
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.6732e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.135618
Average KL loss: 0.050574
Average total loss: 0.186191
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.8682e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.138433
Average KL loss: 0.050568
Average total loss: 0.189001
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.4765e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.143972
Average KL loss: 0.050562
Average total loss: 0.194534
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.1293e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.144254
Average KL loss: 0.050558
Average total loss: 0.194812
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.4191e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.136967
Average KL loss: 0.050552
Average total loss: 0.187519
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.5815e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.133539
Average KL loss: 0.050545
Average total loss: 0.184084
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(4.8305e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.137427
Average KL loss: 0.050536
Average total loss: 0.187963
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.7135e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.136557
Average KL loss: 0.050530
Average total loss: 0.187087
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.6577e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.139330
Average KL loss: 0.050525
Average total loss: 0.189856
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.5220e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.135212
Average KL loss: 0.050521
Average total loss: 0.185733
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-5.3014e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.139164
Average KL loss: 0.050516
Average total loss: 0.189679
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.0609e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.138431
Average KL loss: 0.050513
Average total loss: 0.188944
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.2067e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.141837
Average KL loss: 0.050512
Average total loss: 0.192349
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.3302e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.137572
Average KL loss: 0.050512
Average total loss: 0.188084
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.3147e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.138355
Average KL loss: 0.050511
Average total loss: 0.188866
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-9.6428e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.140273
Average KL loss: 0.050510
Average total loss: 0.190783
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.5641e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.139790
Average KL loss: 0.050510
Average total loss: 0.190299
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.0663e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.137908
Average KL loss: 0.050509
Average total loss: 0.188417
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.2842e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.137645
Average KL loss: 0.050509
Average total loss: 0.188154
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.5890e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.142364
Average KL loss: 0.050508
Average total loss: 0.192872
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.2065e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.134352
Average KL loss: 0.050508
Average total loss: 0.184859
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.5945e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.133055
Average KL loss: 0.050507
Average total loss: 0.183562
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.9450e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.135216
Average KL loss: 0.050506
Average total loss: 0.185722
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-5.5286e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.140608
Average KL loss: 0.050506
Average total loss: 0.191114
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.3566e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.138467
Average KL loss: 0.050505
Average total loss: 0.188972
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-9.4918e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.137610
Average KL loss: 0.050504
Average total loss: 0.188115
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-5.3061e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.135138
Average KL loss: 0.050504
Average total loss: 0.185641
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.5076e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.139000
Average KL loss: 0.050503
Average total loss: 0.189503
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.7055e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.129764
Average KL loss: 0.050502
Average total loss: 0.180266
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.0183e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.140495
Average KL loss: 0.050502
Average total loss: 0.190997
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(5.6405e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.135977
Average KL loss: 0.050501
Average total loss: 0.186478
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-9.7455e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.140033
Average KL loss: 0.050500
Average total loss: 0.190533
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.1059e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.140228
Average KL loss: 0.050500
Average total loss: 0.190728
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.0053e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.144667
Average KL loss: 0.050499
Average total loss: 0.195166
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.2534e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.136379
Average KL loss: 0.050498
Average total loss: 0.186878
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.1704e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.139008
Average KL loss: 0.050498
Average total loss: 0.189505
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-5.1065e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.135478
Average KL loss: 0.050497
Average total loss: 0.185975
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.6652e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.137468
Average KL loss: 0.050496
Average total loss: 0.187964
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.9682e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.134131
Average KL loss: 0.050496
Average total loss: 0.184627
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-9.3745e-09, device='cuda:0')
 Percentile value: 0.051007889211177826
Non-zero model percentage: 12.500005722045898%, Non-zero mask percentage: 12.500005722045898%

--- Pruning Level [3/12]: ---
conv1.weight         | nonzeros =    1126 /    1728             ( 65.16%) | total_pruned =     602 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   10204 /   36864             ( 27.68%) | total_pruned =   26660 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   10522 /   36864             ( 28.54%) | total_pruned =   26342 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   10074 /   36864             ( 27.33%) | total_pruned =   26790 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    9599 /   36864             ( 26.04%) | total_pruned =   27265 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   18705 /   73728             ( 25.37%) | total_pruned =   55023 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   34184 /  147456             ( 23.18%) | total_pruned =  113272 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3632 /    8192             ( 44.34%) | total_pruned =    4560 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   26729 /  147456             ( 18.13%) | total_pruned =  120727 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   25872 /  147456             ( 17.55%) | total_pruned =  121584 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   63764 /  294912             ( 21.62%) | total_pruned =  231148 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  115740 /  589824             ( 19.62%) | total_pruned =  474084 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   12175 /   32768             ( 37.16%) | total_pruned =   20593 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     126 /     256             ( 49.22%) | total_pruned =     130 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   72780 /  589824             ( 12.34%) | total_pruned =  517044 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     151 /     256             ( 58.98%) | total_pruned =     105 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   70207 /  589824             ( 11.90%) | total_pruned =  519617 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      76 /     256             ( 29.69%) | total_pruned =     180 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  207280 / 1179648             ( 17.57%) | total_pruned =  972368 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     374 /     512             ( 73.05%) | total_pruned =     138 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  307596 / 2359296             ( 13.04%) | total_pruned = 2051700 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     466 /     512             ( 91.02%) | total_pruned =      46 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   26183 /  131072             ( 19.98%) | total_pruned =  104889 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     425 /     512             ( 83.01%) | total_pruned =      87 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     454 /     512             ( 88.67%) | total_pruned =      58 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  207580 / 2359296             (  8.80%) | total_pruned = 2151716 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     420 /     512             ( 82.03%) | total_pruned =      92 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     329 /     512             ( 64.26%) | total_pruned =     183 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  152291 / 2359296             (  6.45%) | total_pruned = 2207005 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     293 /     512             ( 57.23%) | total_pruned =     219 | shape = torch.Size([512])
linear.weight        | nonzeros =    3632 /    5120             ( 70.94%) | total_pruned =    1488 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 1397346, pruned : 9781416, total: 11178762, Compression rate :       8.00x  ( 87.50% pruned)
Train Epoch: 24/100 Loss: 0.000277 Accuracy: 87.00 100.00 % Best test Accuracy: 87.42%
tensor(0.0090, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.4601e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.238945
Average KL loss: 0.048774
Average total loss: 0.287719
tensor(0.0106, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.1975e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.234996
Average KL loss: 0.047593
Average total loss: 0.282589
tensor(0.0110, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.1910e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.237903
Average KL loss: 0.047292
Average total loss: 0.285195
tensor(0.0112, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.4111e-11, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.228642
Average KL loss: 0.047223
Average total loss: 0.275865
tensor(0.0112, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0376e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.220238
Average KL loss: 0.047244
Average total loss: 0.267482
tensor(0.0112, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.3125e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.219921
Average KL loss: 0.047288
Average total loss: 0.267208
tensor(0.0112, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.2201e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.218137
Average KL loss: 0.047360
Average total loss: 0.265497
tensor(0.0111, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.2587e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.210354
Average KL loss: 0.047438
Average total loss: 0.257792
tensor(0.0111, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.5452e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.217649
Average KL loss: 0.047521
Average total loss: 0.265170
tensor(0.0111, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0705e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.214054
Average KL loss: 0.047619
Average total loss: 0.261673
tensor(0.0110, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-9.2457e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.210010
Average KL loss: 0.047722
Average total loss: 0.257732
tensor(0.0110, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-9.9451e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.207079
Average KL loss: 0.047813
Average total loss: 0.254893
tensor(0.0109, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.2680e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.207298
Average KL loss: 0.047913
Average total loss: 0.255210
tensor(0.0109, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-6.0845e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.198382
Average KL loss: 0.048018
Average total loss: 0.246400
tensor(0.0109, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.0540e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.197357
Average KL loss: 0.048102
Average total loss: 0.245459
tensor(0.0108, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-9.7533e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.199319
Average KL loss: 0.048195
Average total loss: 0.247514
tensor(0.0108, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.4186e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.202395
Average KL loss: 0.048301
Average total loss: 0.250695
tensor(0.0108, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.7868e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.195414
Average KL loss: 0.048404
Average total loss: 0.243818
tensor(0.0108, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.7297e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.193725
Average KL loss: 0.048505
Average total loss: 0.242229
tensor(0.0107, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.1445e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.204098
Average KL loss: 0.048605
Average total loss: 0.252703
tensor(0.0107, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.0822e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.191244
Average KL loss: 0.048717
Average total loss: 0.239961
tensor(0.0107, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.7060e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.188911
Average KL loss: 0.048820
Average total loss: 0.237730
tensor(0.0106, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.2406e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.184482
Average KL loss: 0.048913
Average total loss: 0.233395
tensor(0.0106, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.0807e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.186072
Average KL loss: 0.049009
Average total loss: 0.235081
tensor(0.0106, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.2803e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.185487
Average KL loss: 0.049105
Average total loss: 0.234592
tensor(0.0106, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-9.6396e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.181045
Average KL loss: 0.049202
Average total loss: 0.230246
tensor(0.0105, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.3748e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.185543
Average KL loss: 0.049309
Average total loss: 0.234852
tensor(0.0105, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.0843e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.183234
Average KL loss: 0.049411
Average total loss: 0.232646
tensor(0.0105, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.2114e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.180059
Average KL loss: 0.049514
Average total loss: 0.229572
tensor(0.0105, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-9.5937e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.187109
Average KL loss: 0.049618
Average total loss: 0.236728
tensor(0.0104, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.6822e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.184067
Average KL loss: 0.049727
Average total loss: 0.233794
tensor(0.0104, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.0869e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.184575
Average KL loss: 0.049824
Average total loss: 0.234400
tensor(0.0104, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-8.2739e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.186721
Average KL loss: 0.049925
Average total loss: 0.236646
tensor(0.0104, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.3671e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.179477
Average KL loss: 0.050039
Average total loss: 0.229516
tensor(0.0104, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-6.3008e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.174945
Average KL loss: 0.050138
Average total loss: 0.225083
tensor(0.0103, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-7.9195e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.176594
Average KL loss: 0.050219
Average total loss: 0.226813
tensor(0.0103, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-3.6469e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.169999
Average KL loss: 0.050309
Average total loss: 0.220308
tensor(0.0103, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.2737e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.171795
Average KL loss: 0.050396
Average total loss: 0.222191
tensor(0.0103, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.5862e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.174646
Average KL loss: 0.050482
Average total loss: 0.225128
tensor(0.0102, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.6257e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.168493
Average KL loss: 0.050567
Average total loss: 0.219060
tensor(0.0102, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-7.0307e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.173993
Average KL loss: 0.050657
Average total loss: 0.224650
tensor(0.0102, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.5948e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.169587
Average KL loss: 0.050756
Average total loss: 0.220343
tensor(0.0102, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-9.5840e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.168590
Average KL loss: 0.050852
Average total loss: 0.219443
tensor(0.0102, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.1360e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.170038
Average KL loss: 0.050944
Average total loss: 0.220982
tensor(0.0101, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.2094e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.172344
Average KL loss: 0.051037
Average total loss: 0.223380
tensor(0.0101, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.4127e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.172054
Average KL loss: 0.051135
Average total loss: 0.223189
tensor(0.0101, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(2.4345e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.166074
Average KL loss: 0.051231
Average total loss: 0.217305
tensor(0.0101, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.8408e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.172534
Average KL loss: 0.051318
Average total loss: 0.223852
tensor(0.0101, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.0682e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.169283
Average KL loss: 0.051403
Average total loss: 0.220686
tensor(0.0101, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-7.8539e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.172955
Average KL loss: 0.051512
Average total loss: 0.224467
tensor(0.0100, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-5.3943e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.166267
Average KL loss: 0.051619
Average total loss: 0.217886
tensor(0.0100, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-8.7860e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.162888
Average KL loss: 0.051723
Average total loss: 0.214611
tensor(0.0100, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-2.9114e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.163008
Average KL loss: 0.051809
Average total loss: 0.214817
tensor(0.0100, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.0132e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.169291
Average KL loss: 0.051911
Average total loss: 0.221202
tensor(0.0100, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.2996e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.164671
Average KL loss: 0.052007
Average total loss: 0.216678
tensor(0.0100, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-7.9945e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.170443
Average KL loss: 0.052086
Average total loss: 0.222529
tensor(0.0099, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-9.8755e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.154548
Average KL loss: 0.052172
Average total loss: 0.206719
tensor(0.0099, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.3675e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.158255
Average KL loss: 0.052261
Average total loss: 0.210515
tensor(0.0099, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-7.0999e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.159281
Average KL loss: 0.052353
Average total loss: 0.211635
tensor(0.0099, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.0784e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.166739
Average KL loss: 0.052445
Average total loss: 0.219184
tensor(0.0099, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.0143e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.164122
Average KL loss: 0.052541
Average total loss: 0.216662
tensor(0.0099, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.0753e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.155128
Average KL loss: 0.052631
Average total loss: 0.207759
tensor(0.0098, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-7.6847e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.160402
Average KL loss: 0.052698
Average total loss: 0.213100
tensor(0.0098, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-7.5253e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.157887
Average KL loss: 0.052799
Average total loss: 0.210685
tensor(0.0098, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.3028e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.151160
Average KL loss: 0.052881
Average total loss: 0.204041
tensor(0.0098, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.4074e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.160846
Average KL loss: 0.052947
Average total loss: 0.213793
tensor(0.0098, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.2875e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.156749
Average KL loss: 0.053022
Average total loss: 0.209771
tensor(0.0098, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.1793e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.155661
Average KL loss: 0.053099
Average total loss: 0.208760
tensor(0.0098, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.3896e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.156105
Average KL loss: 0.053171
Average total loss: 0.209277
tensor(0.0097, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-9.8753e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.153787
Average KL loss: 0.053256
Average total loss: 0.207043
tensor(0.0097, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-6.3332e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.154102
Average KL loss: 0.053339
Average total loss: 0.207441
tensor(0.0097, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.0045e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.153711
Average KL loss: 0.053419
Average total loss: 0.207130
tensor(0.0097, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-8.5167e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.154347
Average KL loss: 0.053496
Average total loss: 0.207843
tensor(0.0097, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.3074e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.148881
Average KL loss: 0.053585
Average total loss: 0.202466
tensor(0.0097, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.5739e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.151439
Average KL loss: 0.053658
Average total loss: 0.205098
tensor(0.0097, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-7.0240e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.147397
Average KL loss: 0.053737
Average total loss: 0.201134
tensor(0.0097, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-5.3445e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.147322
Average KL loss: 0.053820
Average total loss: 0.201141
tensor(0.0096, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-6.6541e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.153953
Average KL loss: 0.053891
Average total loss: 0.207845
tensor(0.0096, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.9098e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.147456
Average KL loss: 0.053974
Average total loss: 0.201430
tensor(0.0096, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.0852e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.154322
Average KL loss: 0.054047
Average total loss: 0.208369
tensor(0.0096, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(4.5062e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.146255
Average KL loss: 0.054107
Average total loss: 0.200362
tensor(0.0096, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.2142e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.146338
Average KL loss: 0.054175
Average total loss: 0.200513
tensor(0.0096, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.1576e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.146817
Average KL loss: 0.054232
Average total loss: 0.201049
tensor(0.0096, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-7.1334e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.145031
Average KL loss: 0.054293
Average total loss: 0.199324
tensor(0.0095, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.1306e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.141754
Average KL loss: 0.054358
Average total loss: 0.196112
tensor(0.0095, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.1402e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.149666
Average KL loss: 0.054429
Average total loss: 0.204095
tensor(0.0095, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-3.8936e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.142465
Average KL loss: 0.054506
Average total loss: 0.196970
tensor(0.0095, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-7.2405e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.141148
Average KL loss: 0.054574
Average total loss: 0.195721
tensor(0.0095, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-4.5281e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.140140
Average KL loss: 0.054629
Average total loss: 0.194769
tensor(0.0095, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-9.2033e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.145321
Average KL loss: 0.054691
Average total loss: 0.200012
tensor(0.0095, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-5.0301e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.147454
Average KL loss: 0.054761
Average total loss: 0.202215
tensor(0.0095, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.1954e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.143810
Average KL loss: 0.054833
Average total loss: 0.198643
tensor(0.0095, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-8.7501e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.142489
Average KL loss: 0.054906
Average total loss: 0.197395
tensor(0.0094, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.2282e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.141273
Average KL loss: 0.054972
Average total loss: 0.196245
tensor(0.0094, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(2.1488e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.137911
Average KL loss: 0.055030
Average total loss: 0.192942
tensor(0.0094, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.8118e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.142938
Average KL loss: 0.055096
Average total loss: 0.198034
tensor(0.0094, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(4.4872e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.139411
Average KL loss: 0.055159
Average total loss: 0.194570
tensor(0.0094, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.1378e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.147597
Average KL loss: 0.055244
Average total loss: 0.202841
tensor(0.0094, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.9654e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.139195
Average KL loss: 0.055319
Average total loss: 0.194514
tensor(0.0094, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-5.3009e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.135037
Average KL loss: 0.055378
Average total loss: 0.190415
tensor(0.0094, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.2242e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.140539
Average KL loss: 0.055428
Average total loss: 0.195967
tensor(0.0093, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(3.5723e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.139308
Average KL loss: 0.055488
Average total loss: 0.194795
tensor(0.0093, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.2937e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.135280
Average KL loss: 0.055558
Average total loss: 0.190838
tensor(0.0093, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.6075e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.141664
Average KL loss: 0.055624
Average total loss: 0.197287
tensor(0.0093, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-6.1839e-11, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.143935
Average KL loss: 0.055701
Average total loss: 0.199636
tensor(0.0093, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.2071e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.131688
Average KL loss: 0.055769
Average total loss: 0.187457
tensor(0.0093, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.3349e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.142867
Average KL loss: 0.055822
Average total loss: 0.198689
tensor(0.0093, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.2399e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.133347
Average KL loss: 0.055893
Average total loss: 0.189240
tensor(0.0093, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.1370e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.133019
Average KL loss: 0.055949
Average total loss: 0.188969
tensor(0.0093, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-4.3701e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.134374
Average KL loss: 0.056012
Average total loss: 0.190386
tensor(0.0093, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-5.7541e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.138981
Average KL loss: 0.056078
Average total loss: 0.195059
tensor(0.0092, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(2.1374e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.131976
Average KL loss: 0.056146
Average total loss: 0.188122
tensor(0.0092, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.2724e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.131518
Average KL loss: 0.056206
Average total loss: 0.187723
tensor(0.0092, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.9200e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.130210
Average KL loss: 0.056249
Average total loss: 0.186459
tensor(0.0092, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.2601e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.133802
Average KL loss: 0.056302
Average total loss: 0.190103
tensor(0.0092, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.0388e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.132636
Average KL loss: 0.056355
Average total loss: 0.188991
tensor(0.0092, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.6835e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.137060
Average KL loss: 0.056420
Average total loss: 0.193480
tensor(0.0092, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.6976e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.136873
Average KL loss: 0.056494
Average total loss: 0.193367
tensor(0.0092, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(3.7861e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.129091
Average KL loss: 0.056558
Average total loss: 0.185649
tensor(0.0092, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-8.3120e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.131774
Average KL loss: 0.056609
Average total loss: 0.188384
tensor(0.0092, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(2.5179e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.127269
Average KL loss: 0.056659
Average total loss: 0.183928
tensor(0.0092, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.3776e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.129522
Average KL loss: 0.056701
Average total loss: 0.186223
tensor(0.0091, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.1808e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.133575
Average KL loss: 0.056754
Average total loss: 0.190329
tensor(0.0091, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.0581e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.126991
Average KL loss: 0.056806
Average total loss: 0.183797
tensor(0.0091, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.7536e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.129700
Average KL loss: 0.056855
Average total loss: 0.186556
tensor(0.0091, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.5295e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.128911
Average KL loss: 0.056910
Average total loss: 0.185821
tensor(0.0091, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.4074e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.131025
Average KL loss: 0.056967
Average total loss: 0.187992
tensor(0.0091, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.0513e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.129957
Average KL loss: 0.057032
Average total loss: 0.186989
tensor(0.0091, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.5665e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.126618
Average KL loss: 0.057073
Average total loss: 0.183691
tensor(0.0091, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.5094e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.127578
Average KL loss: 0.057126
Average total loss: 0.184704
tensor(0.0091, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.0021e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.118262
Average KL loss: 0.057166
Average total loss: 0.175429
tensor(0.0091, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.0079e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.125879
Average KL loss: 0.057200
Average total loss: 0.183079
tensor(0.0091, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-8.1977e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.131374
Average KL loss: 0.057248
Average total loss: 0.188622
tensor(0.0090, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-8.0447e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.126749
Average KL loss: 0.057301
Average total loss: 0.184050
tensor(0.0090, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.5942e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.126630
Average KL loss: 0.057355
Average total loss: 0.183986
tensor(0.0090, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.0837e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.123928
Average KL loss: 0.057401
Average total loss: 0.181329
tensor(0.0090, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.6745e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.125470
Average KL loss: 0.057451
Average total loss: 0.182921
tensor(0.0090, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.9461e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.124131
Average KL loss: 0.057503
Average total loss: 0.181634
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-4.2211e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.123812
Average KL loss: 0.057552
Average total loss: 0.181364
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.1656e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.127937
Average KL loss: 0.057614
Average total loss: 0.185551
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.0027e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.124156
Average KL loss: 0.057677
Average total loss: 0.181833
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.1380e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.125617
Average KL loss: 0.057725
Average total loss: 0.183342
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.8109e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.125213
Average KL loss: 0.057753
Average total loss: 0.182966
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.0456e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.120854
Average KL loss: 0.057752
Average total loss: 0.178606
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.3271e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.122688
Average KL loss: 0.057750
Average total loss: 0.180438
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-4.0509e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.119555
Average KL loss: 0.057748
Average total loss: 0.177303
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(2.6784e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.123515
Average KL loss: 0.057746
Average total loss: 0.181260
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-4.4394e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.121148
Average KL loss: 0.057744
Average total loss: 0.178891
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.7339e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.119408
Average KL loss: 0.057741
Average total loss: 0.177149
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(1.5748e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.124881
Average KL loss: 0.057738
Average total loss: 0.182618
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.6820e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.124698
Average KL loss: 0.057736
Average total loss: 0.182434
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.0058e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.122583
Average KL loss: 0.057735
Average total loss: 0.180318
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-4.9177e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.127058
Average KL loss: 0.057734
Average total loss: 0.184792
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-4.5687e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.126930
Average KL loss: 0.057733
Average total loss: 0.184663
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-3.8498e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.125631
Average KL loss: 0.057733
Average total loss: 0.183364
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-8.4876e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.120544
Average KL loss: 0.057733
Average total loss: 0.178277
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.6659e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.122243
Average KL loss: 0.057733
Average total loss: 0.179976
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.1386e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.119775
Average KL loss: 0.057732
Average total loss: 0.177508
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.3491e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.121189
Average KL loss: 0.057732
Average total loss: 0.178921
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.1805e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.121447
Average KL loss: 0.057732
Average total loss: 0.179179
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-4.5696e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.122575
Average KL loss: 0.057731
Average total loss: 0.180306
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.5642e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.122273
Average KL loss: 0.057731
Average total loss: 0.180004
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-3.3383e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.125174
Average KL loss: 0.057731
Average total loss: 0.182905
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.6278e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.117525
Average KL loss: 0.057730
Average total loss: 0.175256
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-9.5031e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.124695
Average KL loss: 0.057730
Average total loss: 0.182425
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-3.5064e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.127323
Average KL loss: 0.057730
Average total loss: 0.185052
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-3.3748e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.123634
Average KL loss: 0.057730
Average total loss: 0.181363
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.7038e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.125525
Average KL loss: 0.057729
Average total loss: 0.183254
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.1812e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.124290
Average KL loss: 0.057729
Average total loss: 0.182019
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.0293e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.123129
Average KL loss: 0.057729
Average total loss: 0.180858
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.6605e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.119060
Average KL loss: 0.057729
Average total loss: 0.176788
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-3.8844e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.119365
Average KL loss: 0.057728
Average total loss: 0.177094
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.4153e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.127058
Average KL loss: 0.057728
Average total loss: 0.184786
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.0185e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.123020
Average KL loss: 0.057728
Average total loss: 0.180748
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(3.6156e-09, device='cuda:0')
 Percentile value: 0.10736718028783798
Non-zero model percentage: 6.250002861022949%, Non-zero mask percentage: 6.250002861022949%

--- Pruning Level [4/12]: ---
conv1.weight         | nonzeros =    1075 /    1728             ( 62.21%) | total_pruned =     653 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    7552 /   36864             ( 20.49%) | total_pruned =   29312 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    7937 /   36864             ( 21.53%) | total_pruned =   28927 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    7389 /   36864             ( 20.04%) | total_pruned =   29475 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    6857 /   36864             ( 18.60%) | total_pruned =   30007 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   13356 /   73728             ( 18.12%) | total_pruned =   60372 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   22941 /  147456             ( 15.56%) | total_pruned =  124515 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3131 /    8192             ( 38.22%) | total_pruned =    5061 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   15680 /  147456             ( 10.63%) | total_pruned =  131776 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   14868 /  147456             ( 10.08%) | total_pruned =  132588 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   42020 /  294912             ( 14.25%) | total_pruned =  252892 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   70971 /  589824             ( 12.03%) | total_pruned =  518853 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     122 /     256             ( 47.66%) | total_pruned =     134 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    9857 /   32768             ( 30.08%) | total_pruned =   22911 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     125 /     256             ( 48.83%) | total_pruned =     131 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   36874 /  589824             (  6.25%) | total_pruned =  552950 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     149 /     256             ( 58.20%) | total_pruned =     107 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   34780 /  589824             (  5.90%) | total_pruned =  555044 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      73 /     256             ( 28.52%) | total_pruned =     183 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  118661 / 1179648             ( 10.06%) | total_pruned = 1060987 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     372 /     512             ( 72.66%) | total_pruned =     140 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  137892 / 2359296             (  5.84%) | total_pruned = 2221404 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     466 /     512             ( 91.02%) | total_pruned =      46 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   17314 /  131072             ( 13.21%) | total_pruned =  113758 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     424 /     512             ( 82.81%) | total_pruned =      88 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     454 /     512             ( 88.67%) | total_pruned =      58 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   75141 / 2359296             (  3.18%) | total_pruned = 2284155 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     420 /     512             ( 82.03%) | total_pruned =      92 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     322 /     512             ( 62.89%) | total_pruned =     190 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   43504 / 2359296             (  1.84%) | total_pruned = 2315792 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     509 /     512             ( 99.41%) | total_pruned =       3 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     264 /     512             ( 51.56%) | total_pruned =     248 | shape = torch.Size([512])
linear.weight        | nonzeros =    3465 /    5120             ( 67.68%) | total_pruned =    1655 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 698673, pruned : 10480089, total: 11178762, Compression rate :      16.00x  ( 93.75% pruned)
Train Epoch: 21/100 Loss: 0.000030 Accuracy: 86.77 100.00 % Best test Accuracy: 86.86%
tensor(0.0090, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.3400e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.254921
Average KL loss: 0.056467
Average total loss: 0.311388
tensor(0.0096, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.6752e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.256785
Average KL loss: 0.055583
Average total loss: 0.312368
tensor(0.0100, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.1988e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.257135
Average KL loss: 0.055320
Average total loss: 0.312456
tensor(0.0101, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.1753e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.253625
Average KL loss: 0.055261
Average total loss: 0.308886
tensor(0.0102, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.5028e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.243118
Average KL loss: 0.055296
Average total loss: 0.298414
tensor(0.0102, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.6877e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.243881
Average KL loss: 0.055355
Average total loss: 0.299235
tensor(0.0103, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.4293e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.238297
Average KL loss: 0.055437
Average total loss: 0.293734
tensor(0.0103, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.6095e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.232044
Average KL loss: 0.055518
Average total loss: 0.287562
tensor(0.0103, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.0190e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.239724
Average KL loss: 0.055615
Average total loss: 0.295339
tensor(0.0103, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.5486e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.230831
Average KL loss: 0.055726
Average total loss: 0.286557
tensor(0.0103, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.0305e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.235358
Average KL loss: 0.055834
Average total loss: 0.291192
tensor(0.0103, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.5376e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.228374
Average KL loss: 0.055944
Average total loss: 0.284318
tensor(0.0103, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.1791e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.222270
Average KL loss: 0.056056
Average total loss: 0.278326
tensor(0.0103, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.8752e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.229580
Average KL loss: 0.056173
Average total loss: 0.285753
tensor(0.0103, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.8021e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.232195
Average KL loss: 0.056285
Average total loss: 0.288480
tensor(0.0103, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.1391e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.225916
Average KL loss: 0.056417
Average total loss: 0.282332
tensor(0.0103, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.0574e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.214527
Average KL loss: 0.056536
Average total loss: 0.271063
tensor(0.0102, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.9711e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.214579
Average KL loss: 0.056641
Average total loss: 0.271220
tensor(0.0102, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.8483e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.222067
Average KL loss: 0.056757
Average total loss: 0.278825
tensor(0.0102, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.4845e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.221302
Average KL loss: 0.056878
Average total loss: 0.278180
tensor(0.0102, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.3728e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.212202
Average KL loss: 0.056995
Average total loss: 0.269198
tensor(0.0102, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.9600e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.213543
Average KL loss: 0.057113
Average total loss: 0.270656
tensor(0.0102, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.6086e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.216601
Average KL loss: 0.057232
Average total loss: 0.273833
tensor(0.0102, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.8991e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.210641
Average KL loss: 0.057348
Average total loss: 0.267989
tensor(0.0102, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.8595e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.214437
Average KL loss: 0.057470
Average total loss: 0.271908
tensor(0.0102, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.2034e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.206409
Average KL loss: 0.057584
Average total loss: 0.263993
tensor(0.0102, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.8683e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.212632
Average KL loss: 0.057700
Average total loss: 0.270331
tensor(0.0102, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.7858e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.206081
Average KL loss: 0.057826
Average total loss: 0.263907
tensor(0.0102, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.5272e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.203554
Average KL loss: 0.057936
Average total loss: 0.261490
tensor(0.0102, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.1156e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.204444
Average KL loss: 0.058035
Average total loss: 0.262479
tensor(0.0102, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.6373e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.204308
Average KL loss: 0.058145
Average total loss: 0.262453
tensor(0.0102, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.1321e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.208417
Average KL loss: 0.058263
Average total loss: 0.266681
tensor(0.0102, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.4912e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.196730
Average KL loss: 0.058383
Average total loss: 0.255113
tensor(0.0102, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.1230e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.202746
Average KL loss: 0.058489
Average total loss: 0.261235
tensor(0.0102, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.2928e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.212314
Average KL loss: 0.058608
Average total loss: 0.270923
tensor(0.0102, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.5904e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.192243
Average KL loss: 0.058715
Average total loss: 0.250959
tensor(0.0102, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.0266e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.192660
Average KL loss: 0.058812
Average total loss: 0.251472
tensor(0.0102, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.9743e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.187577
Average KL loss: 0.058906
Average total loss: 0.246482
tensor(0.0102, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.5803e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.196247
Average KL loss: 0.058993
Average total loss: 0.255240
tensor(0.0102, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-7.8237e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.199407
Average KL loss: 0.059102
Average total loss: 0.258509
tensor(0.0102, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.2416e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.189379
Average KL loss: 0.059221
Average total loss: 0.248600
tensor(0.0102, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.4729e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.196070
Average KL loss: 0.059333
Average total loss: 0.255403
tensor(0.0102, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.4821e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.196473
Average KL loss: 0.059455
Average total loss: 0.255928
tensor(0.0102, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.7064e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.194433
Average KL loss: 0.059569
Average total loss: 0.254002
tensor(0.0102, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.4362e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.195394
Average KL loss: 0.059686
Average total loss: 0.255080
tensor(0.0102, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-8.2769e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.187548
Average KL loss: 0.059795
Average total loss: 0.247343
tensor(0.0101, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.9459e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.189713
Average KL loss: 0.059896
Average total loss: 0.249609
tensor(0.0101, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-9.5235e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.189987
Average KL loss: 0.060005
Average total loss: 0.249991
tensor(0.0101, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.5105e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.183349
Average KL loss: 0.060106
Average total loss: 0.243455
tensor(0.0101, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.6105e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.185833
Average KL loss: 0.060209
Average total loss: 0.246042
tensor(0.0101, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-8.4917e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.187007
Average KL loss: 0.060308
Average total loss: 0.247314
tensor(0.0101, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-6.7849e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.185698
Average KL loss: 0.060402
Average total loss: 0.246100
tensor(0.0101, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-2.2662e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.184237
Average KL loss: 0.060500
Average total loss: 0.244737
tensor(0.0101, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-7.5244e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.180363
Average KL loss: 0.060596
Average total loss: 0.240959
tensor(0.0101, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.9789e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.183180
Average KL loss: 0.060691
Average total loss: 0.243871
tensor(0.0101, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-9.1888e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.188361
Average KL loss: 0.060796
Average total loss: 0.249157
tensor(0.0101, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.4958e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.181664
Average KL loss: 0.060902
Average total loss: 0.242567
tensor(0.0101, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.6975e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.178513
Average KL loss: 0.061008
Average total loss: 0.239521
tensor(0.0101, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.1767e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.180818
Average KL loss: 0.061107
Average total loss: 0.241925
tensor(0.0101, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-7.8061e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.172889
Average KL loss: 0.061196
Average total loss: 0.234084
tensor(0.0101, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-2.3295e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.179033
Average KL loss: 0.061286
Average total loss: 0.240319
tensor(0.0101, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-7.8439e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.176672
Average KL loss: 0.061393
Average total loss: 0.238065
tensor(0.0101, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-7.9919e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.169709
Average KL loss: 0.061486
Average total loss: 0.231195
tensor(0.0101, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-7.5042e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.178577
Average KL loss: 0.061572
Average total loss: 0.240149
tensor(0.0101, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.5515e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.176488
Average KL loss: 0.061662
Average total loss: 0.238151
tensor(0.0101, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-5.6131e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.174916
Average KL loss: 0.061764
Average total loss: 0.236680
tensor(0.0101, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.0562e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.170229
Average KL loss: 0.061862
Average total loss: 0.232091
tensor(0.0101, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(3.2114e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.172180
Average KL loss: 0.061951
Average total loss: 0.234131
tensor(0.0101, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.9360e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.176422
Average KL loss: 0.062056
Average total loss: 0.238478
tensor(0.0101, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-2.9970e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.171165
Average KL loss: 0.062153
Average total loss: 0.233317
tensor(0.0101, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.5877e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.168006
Average KL loss: 0.062247
Average total loss: 0.230253
tensor(0.0101, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-5.6607e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.167142
Average KL loss: 0.062332
Average total loss: 0.229473
tensor(0.0101, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-7.4574e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.167842
Average KL loss: 0.062417
Average total loss: 0.230259
tensor(0.0101, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.6349e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.176685
Average KL loss: 0.062498
Average total loss: 0.239183
tensor(0.0101, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.9662e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.169070
Average KL loss: 0.062586
Average total loss: 0.231655
tensor(0.0101, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.0153e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.172849
Average KL loss: 0.062676
Average total loss: 0.235525
tensor(0.0100, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.5049e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.165805
Average KL loss: 0.062762
Average total loss: 0.228567
tensor(0.0100, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-2.0385e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.165792
Average KL loss: 0.062843
Average total loss: 0.228635
tensor(0.0100, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-2.3824e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.169495
Average KL loss: 0.062924
Average total loss: 0.232419
tensor(0.0100, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-8.7272e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.166340
Average KL loss: 0.063008
Average total loss: 0.229348
tensor(0.0100, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-8.2996e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.160522
Average KL loss: 0.063092
Average total loss: 0.223614
tensor(0.0100, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-6.8266e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.165289
Average KL loss: 0.063169
Average total loss: 0.228459
tensor(0.0100, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-6.9481e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.158766
Average KL loss: 0.063256
Average total loss: 0.222022
tensor(0.0100, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.1884e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.168208
Average KL loss: 0.063337
Average total loss: 0.231545
tensor(0.0100, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.6172e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.165141
Average KL loss: 0.063432
Average total loss: 0.228573
tensor(0.0100, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.2323e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.163035
Average KL loss: 0.063523
Average total loss: 0.226558
tensor(0.0100, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.2469e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.166886
Average KL loss: 0.063608
Average total loss: 0.230494
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.1182e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.163093
Average KL loss: 0.063696
Average total loss: 0.226788
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.0432e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.166797
Average KL loss: 0.063791
Average total loss: 0.230588
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-3.2687e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.168618
Average KL loss: 0.063879
Average total loss: 0.232497
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.0818e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.158053
Average KL loss: 0.063974
Average total loss: 0.222027
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.1583e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.158958
Average KL loss: 0.064052
Average total loss: 0.223010
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-5.4785e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.169127
Average KL loss: 0.064134
Average total loss: 0.233261
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.2566e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.158701
Average KL loss: 0.064218
Average total loss: 0.222919
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.9494e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.158071
Average KL loss: 0.064263
Average total loss: 0.222335
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.2088e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.161309
Average KL loss: 0.064268
Average total loss: 0.225577
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.5395e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.164475
Average KL loss: 0.064273
Average total loss: 0.228748
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.0721e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.159011
Average KL loss: 0.064279
Average total loss: 0.223290
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.4906e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.157786
Average KL loss: 0.064284
Average total loss: 0.222069
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-9.7509e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.158344
Average KL loss: 0.064289
Average total loss: 0.222632
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.1731e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.159610
Average KL loss: 0.064294
Average total loss: 0.223904
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-3.2016e-11, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.154472
Average KL loss: 0.064299
Average total loss: 0.218770
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-8.9692e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.163386
Average KL loss: 0.064304
Average total loss: 0.227690
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.5389e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.158851
Average KL loss: 0.064309
Average total loss: 0.223160
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-8.1204e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.157736
Average KL loss: 0.064314
Average total loss: 0.222050
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.1454e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.156748
Average KL loss: 0.064318
Average total loss: 0.221066
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.5461e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.165242
Average KL loss: 0.064323
Average total loss: 0.229565
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.5258e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.162633
Average KL loss: 0.064329
Average total loss: 0.226962
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-7.4993e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.160598
Average KL loss: 0.064333
Average total loss: 0.224931
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.4880e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.154595
Average KL loss: 0.064338
Average total loss: 0.218933
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.3255e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.164279
Average KL loss: 0.064343
Average total loss: 0.228622
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.4313e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.156048
Average KL loss: 0.064348
Average total loss: 0.220397
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-6.9254e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.158340
Average KL loss: 0.064353
Average total loss: 0.222693
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.1236e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.153381
Average KL loss: 0.064355
Average total loss: 0.217736
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.3767e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.158672
Average KL loss: 0.064356
Average total loss: 0.223027
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-8.9123e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.155658
Average KL loss: 0.064356
Average total loss: 0.220014
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-7.3412e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.154860
Average KL loss: 0.064357
Average total loss: 0.219217
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-7.2668e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.160991
Average KL loss: 0.064357
Average total loss: 0.225348
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.6573e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.161828
Average KL loss: 0.064358
Average total loss: 0.226186
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(3.1730e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.160898
Average KL loss: 0.064358
Average total loss: 0.225257
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-8.5905e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.154956
Average KL loss: 0.064358
Average total loss: 0.219315
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.1054e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.155524
Average KL loss: 0.064359
Average total loss: 0.219883
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-5.3622e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.161081
Average KL loss: 0.064359
Average total loss: 0.225440
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.4206e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.158622
Average KL loss: 0.064360
Average total loss: 0.222982
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-7.9546e-09, device='cuda:0')
 Percentile value: 0.22069211304187775
Non-zero model percentage: 3.1250059604644775%, Non-zero mask percentage: 3.1250059604644775%

--- Pruning Level [5/12]: ---
conv1.weight         | nonzeros =    1031 /    1728             ( 59.66%) | total_pruned =     697 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5209 /   36864             ( 14.13%) | total_pruned =   31655 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    5628 /   36864             ( 15.27%) | total_pruned =   31236 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    5280 /   36864             ( 14.32%) | total_pruned =   31584 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4792 /   36864             ( 13.00%) | total_pruned =   32072 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    9234 /   73728             ( 12.52%) | total_pruned =   64494 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   14881 /  147456             ( 10.09%) | total_pruned =  132575 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2708 /    8192             ( 33.06%) | total_pruned =    5484 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8620 /  147456             (  5.85%) | total_pruned =  138836 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    8086 /  147456             (  5.48%) | total_pruned =  139370 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   26361 /  294912             (  8.94%) | total_pruned =  268551 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   41358 /  589824             (  7.01%) | total_pruned =  548466 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     120 /     256             ( 46.88%) | total_pruned =     136 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    7844 /   32768             ( 23.94%) | total_pruned =   24924 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     124 /     256             ( 48.44%) | total_pruned =     132 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   16128 /  589824             (  2.73%) | total_pruned =  573696 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     148 /     256             ( 57.81%) | total_pruned =     108 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   15183 /  589824             (  2.57%) | total_pruned =  574641 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   63676 / 1179648             (  5.40%) | total_pruned = 1115972 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     369 /     512             ( 72.07%) | total_pruned =     143 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   55887 / 2359296             (  2.37%) | total_pruned = 2303409 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     466 /     512             ( 91.02%) | total_pruned =      46 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   10600 /  131072             (  8.09%) | total_pruned =  120472 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     423 /     512             ( 82.62%) | total_pruned =      89 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     454 /     512             ( 88.67%) | total_pruned =      58 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   25018 / 2359296             (  1.06%) | total_pruned = 2334278 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     420 /     512             ( 82.03%) | total_pruned =      92 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     303 /     512             ( 59.18%) | total_pruned =     209 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   11333 / 2359296             (  0.48%) | total_pruned = 2347963 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     201 /     512             ( 39.26%) | total_pruned =     311 | shape = torch.Size([512])
linear.weight        | nonzeros =    3188 /    5120             ( 62.27%) | total_pruned =    1932 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 349337, pruned : 10829425, total: 11178762, Compression rate :      32.00x  ( 96.87% pruned)
Train Epoch: 23/100 Loss: 0.000066 Accuracy: 86.44 100.00 % Best test Accuracy: 86.77%
tensor(0.0100, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-6.2741e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.398554
Average KL loss: 0.063374
Average total loss: 0.461928
tensor(0.0096, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-5.4779e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.389636
Average KL loss: 0.062769
Average total loss: 0.452405
tensor(0.0094, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.5276e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.384816
Average KL loss: 0.062740
Average total loss: 0.447556
tensor(0.0094, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-4.9539e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.383674
Average KL loss: 0.062862
Average total loss: 0.446537
tensor(0.0094, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.3946e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.399772
Average KL loss: 0.063033
Average total loss: 0.462806
tensor(0.0094, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-5.6986e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.368256
Average KL loss: 0.063212
Average total loss: 0.431468
tensor(0.0095, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.0730e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.388302
Average KL loss: 0.063393
Average total loss: 0.451695
tensor(0.0095, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.9992e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.370186
Average KL loss: 0.063577
Average total loss: 0.433763
tensor(0.0095, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.0181e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.366772
Average KL loss: 0.063756
Average total loss: 0.430528
tensor(0.0095, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.2739e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.356445
Average KL loss: 0.063940
Average total loss: 0.420385
tensor(0.0095, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-6.6770e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.362220
Average KL loss: 0.064124
Average total loss: 0.426344
tensor(0.0095, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.4863e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.353422
Average KL loss: 0.064308
Average total loss: 0.417730
tensor(0.0095, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.1683e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.360768
Average KL loss: 0.064491
Average total loss: 0.425260
tensor(0.0095, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.6816e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.347644
Average KL loss: 0.064681
Average total loss: 0.412325
tensor(0.0096, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.8644e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.358015
Average KL loss: 0.064862
Average total loss: 0.422877
tensor(0.0096, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.4587e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.336752
Average KL loss: 0.065050
Average total loss: 0.401802
tensor(0.0096, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.7473e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.350788
Average KL loss: 0.065233
Average total loss: 0.416021
tensor(0.0096, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.0340e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.357153
Average KL loss: 0.065420
Average total loss: 0.422574
tensor(0.0096, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.0352e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.348671
Average KL loss: 0.065602
Average total loss: 0.414272
tensor(0.0096, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.0047e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.341952
Average KL loss: 0.065782
Average total loss: 0.407734
tensor(0.0096, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.8603e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.348626
Average KL loss: 0.065977
Average total loss: 0.414603
tensor(0.0096, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.8053e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.339746
Average KL loss: 0.066161
Average total loss: 0.405907
tensor(0.0096, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.9727e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.344733
Average KL loss: 0.066349
Average total loss: 0.411082
tensor(0.0097, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.8620e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.336606
Average KL loss: 0.066540
Average total loss: 0.403146
tensor(0.0097, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.2037e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.337472
Average KL loss: 0.066719
Average total loss: 0.404191
tensor(0.0097, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.4267e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.325458
Average KL loss: 0.066900
Average total loss: 0.392358
tensor(0.0097, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-3.5408e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.325109
Average KL loss: 0.067071
Average total loss: 0.392181
tensor(0.0097, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.3298e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.330785
Average KL loss: 0.067247
Average total loss: 0.398032
tensor(0.0097, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.1304e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.330490
Average KL loss: 0.067426
Average total loss: 0.397916
tensor(0.0097, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.9744e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.338056
Average KL loss: 0.067607
Average total loss: 0.405663
tensor(0.0097, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.8792e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.333106
Average KL loss: 0.067799
Average total loss: 0.400905
tensor(0.0097, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.8085e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.341914
Average KL loss: 0.067980
Average total loss: 0.409894
tensor(0.0097, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.3519e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.326538
Average KL loss: 0.068168
Average total loss: 0.394707
tensor(0.0098, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.5060e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.316971
Average KL loss: 0.068339
Average total loss: 0.385310
tensor(0.0098, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.7027e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.330624
Average KL loss: 0.068527
Average total loss: 0.399151
tensor(0.0098, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.9620e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.321489
Average KL loss: 0.068704
Average total loss: 0.390192
tensor(0.0098, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.2637e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.324349
Average KL loss: 0.068874
Average total loss: 0.393223
tensor(0.0098, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.9330e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.324481
Average KL loss: 0.069045
Average total loss: 0.393527
tensor(0.0098, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.8387e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.317130
Average KL loss: 0.069223
Average total loss: 0.386354
tensor(0.0098, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.9362e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.310834
Average KL loss: 0.069387
Average total loss: 0.380221
tensor(0.0098, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.9628e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.307396
Average KL loss: 0.069540
Average total loss: 0.376936
tensor(0.0098, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.3216e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.306185
Average KL loss: 0.069691
Average total loss: 0.375877
tensor(0.0098, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.4043e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.299347
Average KL loss: 0.069844
Average total loss: 0.369191
tensor(0.0098, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.8868e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.310528
Average KL loss: 0.070003
Average total loss: 0.380531
tensor(0.0098, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-9.3117e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.299789
Average KL loss: 0.070161
Average total loss: 0.369950
tensor(0.0099, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.3518e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.305925
Average KL loss: 0.070316
Average total loss: 0.376241
tensor(0.0099, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.2867e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.305635
Average KL loss: 0.070480
Average total loss: 0.376115
tensor(0.0099, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.1478e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.304851
Average KL loss: 0.070643
Average total loss: 0.375495
tensor(0.0099, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.8613e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.295228
Average KL loss: 0.070795
Average total loss: 0.366023
tensor(0.0099, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.5876e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.307896
Average KL loss: 0.070952
Average total loss: 0.378847
tensor(0.0099, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.7373e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.302229
Average KL loss: 0.071109
Average total loss: 0.373338
tensor(0.0099, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.7034e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.294295
Average KL loss: 0.071278
Average total loss: 0.365573
tensor(0.0099, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.8545e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.302312
Average KL loss: 0.071438
Average total loss: 0.373750
tensor(0.0099, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.1034e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.298948
Average KL loss: 0.071601
Average total loss: 0.370549
tensor(0.0099, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.8428e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.296493
Average KL loss: 0.071764
Average total loss: 0.368256
tensor(0.0099, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.4576e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.298055
Average KL loss: 0.071922
Average total loss: 0.369977
tensor(0.0099, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.9548e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.290543
Average KL loss: 0.072085
Average total loss: 0.362628
tensor(0.0099, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.0116e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.286487
Average KL loss: 0.072231
Average total loss: 0.358719
tensor(0.0100, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.7734e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.292950
Average KL loss: 0.072378
Average total loss: 0.365328
tensor(0.0100, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.5561e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.286777
Average KL loss: 0.072542
Average total loss: 0.359319
tensor(0.0100, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.8119e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.292263
Average KL loss: 0.072691
Average total loss: 0.364954
tensor(0.0100, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.3481e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.298354
Average KL loss: 0.072842
Average total loss: 0.371196
tensor(0.0100, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.0853e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.291399
Average KL loss: 0.073001
Average total loss: 0.364400
tensor(0.0100, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.6467e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.289778
Average KL loss: 0.073158
Average total loss: 0.362935
tensor(0.0100, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.5002e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.294718
Average KL loss: 0.073307
Average total loss: 0.368026
tensor(0.0100, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.0458e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.290282
Average KL loss: 0.073464
Average total loss: 0.363746
tensor(0.0100, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.9178e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.283257
Average KL loss: 0.073607
Average total loss: 0.356865
tensor(0.0100, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.7272e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.284755
Average KL loss: 0.073760
Average total loss: 0.358515
tensor(0.0100, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.0553e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.277693
Average KL loss: 0.073910
Average total loss: 0.351603
tensor(0.0100, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.3505e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.288419
Average KL loss: 0.074063
Average total loss: 0.362482
tensor(0.0100, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.8193e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.287968
Average KL loss: 0.074219
Average total loss: 0.362187
tensor(0.0100, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.9600e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.276827
Average KL loss: 0.074377
Average total loss: 0.351204
tensor(0.0101, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.0950e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.281074
Average KL loss: 0.074516
Average total loss: 0.355590
tensor(0.0101, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.1792e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.282765
Average KL loss: 0.074675
Average total loss: 0.357440
tensor(0.0101, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.1512e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.278450
Average KL loss: 0.074828
Average total loss: 0.353278
tensor(0.0101, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.2782e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.281290
Average KL loss: 0.074984
Average total loss: 0.356274
tensor(0.0101, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-9.9422e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.276165
Average KL loss: 0.075134
Average total loss: 0.351299
tensor(0.0101, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.7411e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.267814
Average KL loss: 0.075279
Average total loss: 0.343093
tensor(0.0101, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.0139e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.266870
Average KL loss: 0.075419
Average total loss: 0.342288
tensor(0.0101, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.5058e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.275104
Average KL loss: 0.075544
Average total loss: 0.350648
tensor(0.0101, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.3378e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.276668
Average KL loss: 0.075685
Average total loss: 0.352352
tensor(0.0101, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.8112e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.282153
Average KL loss: 0.075839
Average total loss: 0.357992
tensor(0.0101, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.0969e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.267803
Average KL loss: 0.075985
Average total loss: 0.343788
tensor(0.0101, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.9184e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.279377
Average KL loss: 0.076120
Average total loss: 0.355497
tensor(0.0101, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.4338e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.267838
Average KL loss: 0.076257
Average total loss: 0.344096
tensor(0.0101, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.3872e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.264955
Average KL loss: 0.076391
Average total loss: 0.341346
tensor(0.0101, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.7428e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.276211
Average KL loss: 0.076521
Average total loss: 0.352732
tensor(0.0101, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.5342e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.272289
Average KL loss: 0.076669
Average total loss: 0.348958
tensor(0.0102, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.7158e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.277936
Average KL loss: 0.076815
Average total loss: 0.354751
tensor(0.0102, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.5286e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.266480
Average KL loss: 0.076956
Average total loss: 0.343435
tensor(0.0102, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.1021e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.276507
Average KL loss: 0.077101
Average total loss: 0.353607
tensor(0.0102, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.2940e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.271170
Average KL loss: 0.077260
Average total loss: 0.348429
tensor(0.0102, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.2413e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.276160
Average KL loss: 0.077400
Average total loss: 0.353561
tensor(0.0102, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.4710e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.268093
Average KL loss: 0.077548
Average total loss: 0.345642
tensor(0.0102, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.7918e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.269047
Average KL loss: 0.077682
Average total loss: 0.346729
tensor(0.0102, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.1359e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.257157
Average KL loss: 0.077815
Average total loss: 0.334972
tensor(0.0102, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.1756e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.270939
Average KL loss: 0.077941
Average total loss: 0.348880
tensor(0.0102, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.6022e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.267022
Average KL loss: 0.078091
Average total loss: 0.345113
tensor(0.0102, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.6690e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.263568
Average KL loss: 0.078231
Average total loss: 0.341799
tensor(0.0102, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.1268e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.260924
Average KL loss: 0.078360
Average total loss: 0.339284
tensor(0.0102, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.8673e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.258869
Average KL loss: 0.078495
Average total loss: 0.337364
tensor(0.0102, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-8.8179e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.268783
Average KL loss: 0.078628
Average total loss: 0.347411
tensor(0.0102, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.1650e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.252240
Average KL loss: 0.078761
Average total loss: 0.331002
tensor(0.0102, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.1326e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.246381
Average KL loss: 0.078878
Average total loss: 0.325260
tensor(0.0102, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.1438e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.266908
Average KL loss: 0.079000
Average total loss: 0.345908
tensor(0.0102, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.4920e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.265276
Average KL loss: 0.079143
Average total loss: 0.344419
tensor(0.0103, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.1121e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.267108
Average KL loss: 0.079287
Average total loss: 0.346395
tensor(0.0103, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.1793e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.251931
Average KL loss: 0.079412
Average total loss: 0.331344
tensor(0.0103, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.4075e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.263310
Average KL loss: 0.079535
Average total loss: 0.342845
tensor(0.0103, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.1076e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.261674
Average KL loss: 0.079681
Average total loss: 0.341355
tensor(0.0103, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.5593e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.253769
Average KL loss: 0.079815
Average total loss: 0.333584
tensor(0.0103, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-8.5707e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.254996
Average KL loss: 0.079936
Average total loss: 0.334932
tensor(0.0103, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.9491e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.256522
Average KL loss: 0.080063
Average total loss: 0.336586
tensor(0.0103, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.2468e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.250417
Average KL loss: 0.080189
Average total loss: 0.330605
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.5614e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.257252
Average KL loss: 0.080306
Average total loss: 0.337558
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.3111e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.259223
Average KL loss: 0.080374
Average total loss: 0.339597
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.8569e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.242424
Average KL loss: 0.080384
Average total loss: 0.322808
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.3693e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.247617
Average KL loss: 0.080395
Average total loss: 0.328012
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.0342e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.258576
Average KL loss: 0.080407
Average total loss: 0.338983
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.3326e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.250753
Average KL loss: 0.080418
Average total loss: 0.331171
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.1681e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.256365
Average KL loss: 0.080430
Average total loss: 0.336795
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.1652e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.244850
Average KL loss: 0.080441
Average total loss: 0.325290
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.3517e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.258642
Average KL loss: 0.080452
Average total loss: 0.339094
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.7451e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.248402
Average KL loss: 0.080464
Average total loss: 0.328866
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.2103e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.248942
Average KL loss: 0.080474
Average total loss: 0.329416
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.2250e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.269710
Average KL loss: 0.080485
Average total loss: 0.350195
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.4102e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.260889
Average KL loss: 0.080499
Average total loss: 0.341388
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.3302e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.260846
Average KL loss: 0.080512
Average total loss: 0.341357
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.4221e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.254839
Average KL loss: 0.080519
Average total loss: 0.335357
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.4922e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.248912
Average KL loss: 0.080520
Average total loss: 0.329432
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.0299e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.260908
Average KL loss: 0.080521
Average total loss: 0.341429
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.0803e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.243141
Average KL loss: 0.080522
Average total loss: 0.323662
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.6307e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.253112
Average KL loss: 0.080523
Average total loss: 0.333635
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.6779e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.253295
Average KL loss: 0.080524
Average total loss: 0.333819
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.4086e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.246691
Average KL loss: 0.080525
Average total loss: 0.327216
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.4608e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.257228
Average KL loss: 0.080526
Average total loss: 0.337754
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.8094e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.250981
Average KL loss: 0.080528
Average total loss: 0.331509
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.0505e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.249046
Average KL loss: 0.080529
Average total loss: 0.329575
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.3658e-08, device='cuda:0')
 Percentile value: 0.41465142369270325
Non-zero model percentage: 1.5625073909759521%, Non-zero mask percentage: 1.5625073909759521%

--- Pruning Level [6/12]: ---
conv1.weight         | nonzeros =     969 /    1728             ( 56.08%) | total_pruned =     759 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    3296 /   36864             (  8.94%) | total_pruned =   33568 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    3549 /   36864             (  9.63%) | total_pruned =   33315 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3394 /   36864             (  9.21%) | total_pruned =   33470 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3024 /   36864             (  8.20%) | total_pruned =   33840 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    5780 /   73728             (  7.84%) | total_pruned =   67948 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    8769 /  147456             (  5.95%) | total_pruned =  138687 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2221 /    8192             ( 27.11%) | total_pruned =    5971 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4459 /  147456             (  3.02%) | total_pruned =  142997 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    4110 /  147456             (  2.79%) | total_pruned =  143346 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   15123 /  294912             (  5.13%) | total_pruned =  279789 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     132 /     256             ( 51.56%) | total_pruned =     124 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   21662 /  589824             (  3.67%) | total_pruned =  568162 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     114 /     256             ( 44.53%) | total_pruned =     142 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    5770 /   32768             ( 17.61%) | total_pruned =   26998 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     120 /     256             ( 46.88%) | total_pruned =     136 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    6500 /  589824             (  1.10%) | total_pruned =  583324 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    6203 /  589824             (  1.05%) | total_pruned =  583621 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      60 /     256             ( 23.44%) | total_pruned =     196 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   29872 / 1179648             (  2.53%) | total_pruned = 1149776 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     357 /     512             ( 69.73%) | total_pruned =     155 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   21449 / 2359296             (  0.91%) | total_pruned = 2337847 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     463 /     512             ( 90.43%) | total_pruned =      49 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    5417 /  131072             (  4.13%) | total_pruned =  125655 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     417 /     512             ( 81.45%) | total_pruned =      95 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     449 /     512             ( 87.70%) | total_pruned =      63 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    9302 / 2359296             (  0.39%) | total_pruned = 2349994 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     419 /     512             ( 81.84%) | total_pruned =      93 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     230 /     512             ( 44.92%) | total_pruned =     282 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    4051 / 2359296             (  0.17%) | total_pruned = 2355245 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     504 /     512             ( 98.44%) | total_pruned =       8 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     117 /     512             ( 22.85%) | total_pruned =     395 | shape = torch.Size([512])
linear.weight        | nonzeros =    2709 /    5120             ( 52.91%) | total_pruned =    2411 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 174669, pruned : 11004093, total: 11178762, Compression rate :      64.00x  ( 98.44% pruned)
Train Epoch: 24/100 Loss: 0.001084 Accuracy: 85.48 100.00 % Best test Accuracy: 85.87%
tensor(0.0103, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.3020e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.797158
Average KL loss: 0.079147
Average total loss: 0.876305
tensor(0.0098, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-8.4702e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.781021
Average KL loss: 0.077483
Average total loss: 0.858503
tensor(0.0094, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-8.7469e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.752241
Average KL loss: 0.076612
Average total loss: 0.828852
tensor(0.0091, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.5192e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.763134
Average KL loss: 0.076219
Average total loss: 0.839354
tensor(0.0089, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.1585e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.770350
Average KL loss: 0.076115
Average total loss: 0.846465
tensor(0.0087, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.9408e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.710919
Average KL loss: 0.076173
Average total loss: 0.787092
tensor(0.0086, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-9.7390e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.721739
Average KL loss: 0.076315
Average total loss: 0.798054
tensor(0.0086, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.9638e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.721166
Average KL loss: 0.076495
Average total loss: 0.797660
tensor(0.0085, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.6839e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.697807
Average KL loss: 0.076702
Average total loss: 0.774508
tensor(0.0085, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-8.1365e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.725131
Average KL loss: 0.076918
Average total loss: 0.802049
tensor(0.0085, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.0823e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.706329
Average KL loss: 0.077153
Average total loss: 0.783482
tensor(0.0085, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.4323e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.705694
Average KL loss: 0.077379
Average total loss: 0.783073
tensor(0.0085, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-9.1709e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.706076
Average KL loss: 0.077608
Average total loss: 0.783684
tensor(0.0085, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.8437e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.693623
Average KL loss: 0.077845
Average total loss: 0.771468
tensor(0.0086, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-9.1017e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.687679
Average KL loss: 0.078085
Average total loss: 0.765764
tensor(0.0086, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.8773e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.692591
Average KL loss: 0.078319
Average total loss: 0.770910
tensor(0.0086, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.7063e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.683558
Average KL loss: 0.078552
Average total loss: 0.762110
tensor(0.0086, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.6552e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.668374
Average KL loss: 0.078781
Average total loss: 0.747155
tensor(0.0086, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.3443e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.669076
Average KL loss: 0.079007
Average total loss: 0.748083
tensor(0.0086, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.1469e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.649107
Average KL loss: 0.079235
Average total loss: 0.728342
tensor(0.0086, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.8495e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.647118
Average KL loss: 0.079459
Average total loss: 0.726577
tensor(0.0086, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-8.5736e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.684593
Average KL loss: 0.079685
Average total loss: 0.764277
tensor(0.0087, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-8.4107e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.671379
Average KL loss: 0.079925
Average total loss: 0.751304
tensor(0.0087, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.9739e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.660715
Average KL loss: 0.080168
Average total loss: 0.740883
tensor(0.0087, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.0269e-07, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.668724
Average KL loss: 0.080405
Average total loss: 0.749129
tensor(0.0087, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.9992e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.657341
Average KL loss: 0.080644
Average total loss: 0.737985
tensor(0.0087, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.7691e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.662961
Average KL loss: 0.080884
Average total loss: 0.743845
tensor(0.0087, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.5434e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.662512
Average KL loss: 0.081118
Average total loss: 0.743631
tensor(0.0087, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.0258e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.665247
Average KL loss: 0.081354
Average total loss: 0.746601
tensor(0.0087, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.8087e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.636125
Average KL loss: 0.081589
Average total loss: 0.717714
tensor(0.0088, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.2598e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.631527
Average KL loss: 0.081819
Average total loss: 0.713346
tensor(0.0088, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.8578e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.627748
Average KL loss: 0.082045
Average total loss: 0.709794
tensor(0.0088, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.6725e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.628115
Average KL loss: 0.082272
Average total loss: 0.710388
tensor(0.0088, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.1158e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.604315
Average KL loss: 0.082495
Average total loss: 0.686810
tensor(0.0088, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.6609e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.592465
Average KL loss: 0.082702
Average total loss: 0.675168
tensor(0.0088, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.9014e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.612199
Average KL loss: 0.082914
Average total loss: 0.695113
tensor(0.0088, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.3422e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.626229
Average KL loss: 0.083131
Average total loss: 0.709360
tensor(0.0088, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.0201e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.621798
Average KL loss: 0.083349
Average total loss: 0.705147
tensor(0.0088, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.1606e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.584043
Average KL loss: 0.083573
Average total loss: 0.667616
tensor(0.0088, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.1047e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.575877
Average KL loss: 0.083775
Average total loss: 0.659651
tensor(0.0089, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-7.3832e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.606576
Average KL loss: 0.083994
Average total loss: 0.690570
tensor(0.0089, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-9.5001e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.634727
Average KL loss: 0.084221
Average total loss: 0.718948
tensor(0.0089, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.2040e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.591205
Average KL loss: 0.084446
Average total loss: 0.675651
tensor(0.0089, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-9.9780e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.602230
Average KL loss: 0.084661
Average total loss: 0.686891
tensor(0.0089, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.3770e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.592293
Average KL loss: 0.084874
Average total loss: 0.677167
tensor(0.0089, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.1308e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.592612
Average KL loss: 0.085091
Average total loss: 0.677703
tensor(0.0089, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.9304e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.585196
Average KL loss: 0.085305
Average total loss: 0.670501
tensor(0.0089, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.0263e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.604322
Average KL loss: 0.085518
Average total loss: 0.689840
tensor(0.0089, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-6.2120e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.589968
Average KL loss: 0.085749
Average total loss: 0.675716
tensor(0.0090, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-4.3699e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.593201
Average KL loss: 0.085957
Average total loss: 0.679158
tensor(0.0090, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-4.5370e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.574598
Average KL loss: 0.086166
Average total loss: 0.660764
tensor(0.0090, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-9.8169e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.605170
Average KL loss: 0.086287
Average total loss: 0.691456
tensor(0.0090, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-6.9952e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.578938
Average KL loss: 0.086309
Average total loss: 0.665247
tensor(0.0090, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.2916e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.604730
Average KL loss: 0.086331
Average total loss: 0.691060
tensor(0.0090, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-6.3805e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.579805
Average KL loss: 0.086351
Average total loss: 0.666156
tensor(0.0090, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-4.3131e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.585843
Average KL loss: 0.086372
Average total loss: 0.672216
tensor(0.0090, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-5.5578e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.573327
Average KL loss: 0.086394
Average total loss: 0.659720
tensor(0.0090, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-5.5378e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.577373
Average KL loss: 0.086415
Average total loss: 0.663788
tensor(0.0090, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-4.5082e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.588218
Average KL loss: 0.086436
Average total loss: 0.674653
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-5.4389e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.589887
Average KL loss: 0.086457
Average total loss: 0.676344
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-6.5774e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.595741
Average KL loss: 0.086479
Average total loss: 0.682220
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-2.6868e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.583175
Average KL loss: 0.086501
Average total loss: 0.669675
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-5.9359e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.586931
Average KL loss: 0.086513
Average total loss: 0.673444
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.0530e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.565473
Average KL loss: 0.086516
Average total loss: 0.651989
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-6.2289e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.598843
Average KL loss: 0.086518
Average total loss: 0.685360
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-2.9506e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.570474
Average KL loss: 0.086520
Average total loss: 0.656994
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.0740e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.586532
Average KL loss: 0.086522
Average total loss: 0.673054
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-5.5127e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.575265
Average KL loss: 0.086524
Average total loss: 0.661789
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-5.7149e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.583638
Average KL loss: 0.086526
Average total loss: 0.670165
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-5.1923e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.579696
Average KL loss: 0.086528
Average total loss: 0.666224
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-5.1224e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.560794
Average KL loss: 0.086530
Average total loss: 0.647324
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.8413e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.593747
Average KL loss: 0.086532
Average total loss: 0.680279
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.8395e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.596762
Average KL loss: 0.086535
Average total loss: 0.683296
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.1534e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.588582
Average KL loss: 0.086537
Average total loss: 0.675119
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.4742e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.586395
Average KL loss: 0.086539
Average total loss: 0.672934
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-3.7542e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.586490
Average KL loss: 0.086541
Average total loss: 0.673031
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-5.2025e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.599361
Average KL loss: 0.086543
Average total loss: 0.685904
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-6.2493e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.576477
Average KL loss: 0.086546
Average total loss: 0.663022
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.0540e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.619628
Average KL loss: 0.086548
Average total loss: 0.706175
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-5.4856e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.587847
Average KL loss: 0.086550
Average total loss: 0.674397
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-2.5438e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.586340
Average KL loss: 0.086552
Average total loss: 0.672892
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-5.8262e-08, device='cuda:0')
 Percentile value: 0.6477094292640686
Non-zero model percentage: 0.781258225440979%, Non-zero mask percentage: 0.781258225440979%

--- Pruning Level [7/12]: ---
conv1.weight         | nonzeros =     884 /    1728             ( 51.16%) | total_pruned =     844 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1895 /   36864             (  5.14%) | total_pruned =   34969 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2162 /   36864             (  5.86%) | total_pruned =   34702 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2106 /   36864             (  5.71%) | total_pruned =   34758 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1855 /   36864             (  5.03%) | total_pruned =   35009 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3383 /   73728             (  4.59%) | total_pruned =   70345 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4934 /  147456             (  3.35%) | total_pruned =  142522 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1751 /    8192             ( 21.37%) | total_pruned =    6441 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2171 /  147456             (  1.47%) | total_pruned =  145285 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2064 /  147456             (  1.40%) | total_pruned =  145392 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7908 /  294912             (  2.68%) | total_pruned =  287004 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     122 /     256             ( 47.66%) | total_pruned =     134 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   10588 /  589824             (  1.80%) | total_pruned =  579236 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     102 /     256             ( 39.84%) | total_pruned =     154 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3921 /   32768             ( 11.97%) | total_pruned =   28847 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     110 /     256             ( 42.97%) | total_pruned =     146 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2555 /  589824             (  0.43%) | total_pruned =  587269 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     206 /     256             ( 80.47%) | total_pruned =      50 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     121 /     256             ( 47.27%) | total_pruned =     135 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2562 /  589824             (  0.43%) | total_pruned =  587262 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      44 /     256             ( 17.19%) | total_pruned =     212 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   12907 / 1179648             (  1.09%) | total_pruned = 1166741 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     341 /     512             ( 66.60%) | total_pruned =     171 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    8196 / 2359296             (  0.35%) | total_pruned = 2351100 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     444 /     512             ( 86.72%) | total_pruned =      68 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2432 /  131072             (  1.86%) | total_pruned =  128640 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     430 /     512             ( 83.98%) | total_pruned =      82 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3489 / 2359296             (  0.15%) | total_pruned = 2355807 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     391 /     512             ( 76.37%) | total_pruned =     121 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     169 /     512             ( 33.01%) | total_pruned =     343 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     945 / 2359296             (  0.04%) | total_pruned = 2358351 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     488 /     512             ( 95.31%) | total_pruned =      24 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      48 /     512             (  9.38%) | total_pruned =     464 | shape = torch.Size([512])
linear.weight        | nonzeros =    1932 /    5120             ( 37.73%) | total_pruned =    3188 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 87335, pruned : 11091427, total: 11178762, Compression rate :     128.00x  ( 99.22% pruned)
Train Epoch: 31/100 Loss: 0.003754 Accuracy: 83.93 100.00 % Best test Accuracy: 84.47%
tensor(0.0090, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-2.3624e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.988571
Average KL loss: 0.084911
Average total loss: 2.073482
tensor(0.0086, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.0519e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.866300
Average KL loss: 0.082272
Average total loss: 1.948572
tensor(0.0083, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.1488e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.898099
Average KL loss: 0.080231
Average total loss: 1.978330
tensor(0.0080, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.2213e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.806491
Average KL loss: 0.078681
Average total loss: 1.885172
tensor(0.0078, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.1699e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.996673
Average KL loss: 0.077542
Average total loss: 2.074214
tensor(0.0075, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.7801e-07, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.792286
Average KL loss: 0.076739
Average total loss: 1.869025
tensor(0.0074, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2455e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.877075
Average KL loss: 0.076188
Average total loss: 1.953263
tensor(0.0072, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.7496e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.750127
Average KL loss: 0.075845
Average total loss: 1.825972
tensor(0.0071, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.3671e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.720093
Average KL loss: 0.075639
Average total loss: 1.795733
tensor(0.0070, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.7023e-07, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.706013
Average KL loss: 0.075544
Average total loss: 1.781556
tensor(0.0069, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.5547e-07, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.732792
Average KL loss: 0.075537
Average total loss: 1.808330
tensor(0.0068, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.3324e-07, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.692112
Average KL loss: 0.075598
Average total loss: 1.767710
tensor(0.0067, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.7134e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.787956
Average KL loss: 0.075691
Average total loss: 1.863647
tensor(0.0067, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.9254e-07, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.725929
Average KL loss: 0.075820
Average total loss: 1.801748
tensor(0.0067, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.2505e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.694412
Average KL loss: 0.075961
Average total loss: 1.770373
tensor(0.0066, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.5769e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.689728
Average KL loss: 0.076122
Average total loss: 1.765850
tensor(0.0066, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.5126e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.594471
Average KL loss: 0.076285
Average total loss: 1.670755
tensor(0.0066, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.6657e-07, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.548989
Average KL loss: 0.076446
Average total loss: 1.625435
tensor(0.0066, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.3088e-07, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.638025
Average KL loss: 0.076615
Average total loss: 1.714640
tensor(0.0066, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.6286e-07, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.640178
Average KL loss: 0.076803
Average total loss: 1.716980
tensor(0.0066, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1757e-07, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.640473
Average KL loss: 0.076983
Average total loss: 1.717456
tensor(0.0066, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.0009e-07, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.578590
Average KL loss: 0.077159
Average total loss: 1.655749
tensor(0.0066, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.4113e-07, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.566639
Average KL loss: 0.077332
Average total loss: 1.643971
tensor(0.0066, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.4155e-07, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.588527
Average KL loss: 0.077506
Average total loss: 1.666033
tensor(0.0066, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.3481e-07, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.553312
Average KL loss: 0.077690
Average total loss: 1.631003
tensor(0.0066, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.7851e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.484355
Average KL loss: 0.077862
Average total loss: 1.562217
tensor(0.0066, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.2387e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.496300
Average KL loss: 0.078029
Average total loss: 1.574329
tensor(0.0066, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.0510e-07, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.521181
Average KL loss: 0.078203
Average total loss: 1.599384
tensor(0.0066, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-7.0401e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.511296
Average KL loss: 0.078383
Average total loss: 1.589679
tensor(0.0066, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.1142e-07, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.451708
Average KL loss: 0.078563
Average total loss: 1.530271
tensor(0.0066, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.2650e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.461800
Average KL loss: 0.078737
Average total loss: 1.540538
tensor(0.0067, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.3142e-07, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.526560
Average KL loss: 0.078921
Average total loss: 1.605481
tensor(0.0067, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.3071e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.464741
Average KL loss: 0.079106
Average total loss: 1.543847
tensor(0.0067, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.1664e-07, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.438211
Average KL loss: 0.079285
Average total loss: 1.517496
tensor(0.0067, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-8.3386e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.555191
Average KL loss: 0.079468
Average total loss: 1.634658
tensor(0.0067, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.1793e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.445672
Average KL loss: 0.079659
Average total loss: 1.525330
tensor(0.0067, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-8.7412e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.465881
Average KL loss: 0.079841
Average total loss: 1.545722
tensor(0.0067, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-9.1451e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.469636
Average KL loss: 0.080022
Average total loss: 1.549658
tensor(0.0067, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-7.8860e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.381928
Average KL loss: 0.080203
Average total loss: 1.462131
tensor(0.0067, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.1028e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.403375
Average KL loss: 0.080385
Average total loss: 1.483760
tensor(0.0067, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.6473e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.342946
Average KL loss: 0.080567
Average total loss: 1.423513
tensor(0.0067, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.4574e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.418836
Average KL loss: 0.080756
Average total loss: 1.499592
tensor(0.0067, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.1557e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.455908
Average KL loss: 0.080946
Average total loss: 1.536854
tensor(0.0067, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.4715e-07, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.382905
Average KL loss: 0.081133
Average total loss: 1.464038
tensor(0.0067, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.8260e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.378597
Average KL loss: 0.081315
Average total loss: 1.459912
tensor(0.0067, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-7.9679e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.406213
Average KL loss: 0.081488
Average total loss: 1.487700
tensor(0.0068, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.7855e-07, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.407049
Average KL loss: 0.081674
Average total loss: 1.488723
tensor(0.0068, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.4084e-07, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.368306
Average KL loss: 0.081872
Average total loss: 1.450178
tensor(0.0068, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-9.1350e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.365156
Average KL loss: 0.082053
Average total loss: 1.447208
tensor(0.0068, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-3.8489e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.432287
Average KL loss: 0.082244
Average total loss: 1.514531
tensor(0.0068, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-8.9205e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.356412
Average KL loss: 0.082436
Average total loss: 1.438848
tensor(0.0068, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.3678e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.348574
Average KL loss: 0.082621
Average total loss: 1.431195
tensor(0.0068, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.2212e-07, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.339744
Average KL loss: 0.082723
Average total loss: 1.422467
tensor(0.0068, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-6.7733e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.357138
Average KL loss: 0.082741
Average total loss: 1.439879
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.0723e-07, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.332210
Average KL loss: 0.082759
Average total loss: 1.414969
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-7.5790e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.338715
Average KL loss: 0.082777
Average total loss: 1.421492
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-4.7968e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.340545
Average KL loss: 0.082795
Average total loss: 1.423340
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-9.4520e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.376296
Average KL loss: 0.082814
Average total loss: 1.459110
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.1695e-07, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.325237
Average KL loss: 0.082833
Average total loss: 1.408070
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.5606e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.362356
Average KL loss: 0.082851
Average total loss: 1.445208
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.3014e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.315606
Average KL loss: 0.082871
Average total loss: 1.398477
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-6.2409e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.362351
Average KL loss: 0.082890
Average total loss: 1.445241
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.0484e-07, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.328255
Average KL loss: 0.082909
Average total loss: 1.411164
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.2065e-07, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.336617
Average KL loss: 0.082927
Average total loss: 1.419544
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-5.9259e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.367222
Average KL loss: 0.082946
Average total loss: 1.450168
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.0518e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.387790
Average KL loss: 0.082966
Average total loss: 1.470756
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.9760e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.371738
Average KL loss: 0.082985
Average total loss: 1.454723
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-7.6819e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.397753
Average KL loss: 0.083005
Average total loss: 1.480758
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-5.3210e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.377793
Average KL loss: 0.083025
Average total loss: 1.460818
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.0466e-07, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.351874
Average KL loss: 0.083045
Average total loss: 1.434919
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.9517e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.401998
Average KL loss: 0.083065
Average total loss: 1.485063
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-7.4248e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.378298
Average KL loss: 0.083085
Average total loss: 1.461384
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.3225e-07, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.358073
Average KL loss: 0.083096
Average total loss: 1.441170
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-6.0986e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.413616
Average KL loss: 0.083098
Average total loss: 1.496714
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.2479e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.380734
Average KL loss: 0.083100
Average total loss: 1.463834
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-6.0713e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.286095
Average KL loss: 0.083102
Average total loss: 1.369197
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.1304e-07, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.256241
Average KL loss: 0.083104
Average total loss: 1.339345
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-7.4346e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.326679
Average KL loss: 0.083106
Average total loss: 1.409784
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-9.0189e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.332467
Average KL loss: 0.083108
Average total loss: 1.415574
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.4949e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.358158
Average KL loss: 0.083110
Average total loss: 1.441268
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.4396e-07, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.396355
Average KL loss: 0.083112
Average total loss: 1.479467
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.5488e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.301215
Average KL loss: 0.083113
Average total loss: 1.384328
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.3431e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.390891
Average KL loss: 0.083115
Average total loss: 1.474007
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-6.3111e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.378794
Average KL loss: 0.083118
Average total loss: 1.461911
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-4.7800e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.285521
Average KL loss: 0.083120
Average total loss: 1.368641
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.1891e-07, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.345432
Average KL loss: 0.083122
Average total loss: 1.428554
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-9.6297e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.394507
Average KL loss: 0.083123
Average total loss: 1.477630
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.5392e-07, device='cuda:0')
 Percentile value: 0.9736427068710327
Non-zero model percentage: 0.39063358306884766%, Non-zero mask percentage: 0.39063358306884766%

--- Pruning Level [8/12]: ---
conv1.weight         | nonzeros =     778 /    1728             ( 45.02%) | total_pruned =     950 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1052 /   36864             (  2.85%) | total_pruned =   35812 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1216 /   36864             (  3.30%) | total_pruned =   35648 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1222 /   36864             (  3.31%) | total_pruned =   35642 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1108 /   36864             (  3.01%) | total_pruned =   35756 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1790 /   73728             (  2.43%) | total_pruned =   71938 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      31 /     128             ( 24.22%) | total_pruned =      97 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2554 /  147456             (  1.73%) | total_pruned =  144902 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      27 /     128             ( 21.09%) | total_pruned =     101 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1246 /    8192             ( 15.21%) | total_pruned =    6946 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1062 /  147456             (  0.72%) | total_pruned =  146394 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     122 /     128             ( 95.31%) | total_pruned =       6 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     987 /  147456             (  0.67%) | total_pruned =  146469 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3860 /  294912             (  1.31%) | total_pruned =  291052 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     108 /     256             ( 42.19%) | total_pruned =     148 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    4851 /  589824             (  0.82%) | total_pruned =  584973 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2354 /   32768             (  7.18%) | total_pruned =   30414 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      92 /     256             ( 35.94%) | total_pruned =     164 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     984 /  589824             (  0.17%) | total_pruned =  588840 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     196 /     256             ( 76.56%) | total_pruned =      60 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      97 /     256             ( 37.89%) | total_pruned =     159 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1005 /  589824             (  0.17%) | total_pruned =  588819 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     241 /     256             ( 94.14%) | total_pruned =      15 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      32 /     256             ( 12.50%) | total_pruned =     224 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    5321 / 1179648             (  0.45%) | total_pruned = 1174327 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     290 /     512             ( 56.64%) | total_pruned =     222 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    3075 / 2359296             (  0.13%) | total_pruned = 2356221 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     388 /     512             ( 75.78%) | total_pruned =     124 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     928 /  131072             (  0.71%) | total_pruned =  130144 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     364 /     512             ( 71.09%) | total_pruned =     148 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     366 /     512             ( 71.48%) | total_pruned =     146 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1084 / 2359296             (  0.05%) | total_pruned = 2358212 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     274 /     512             ( 53.52%) | total_pruned =     238 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      98 /     512             ( 19.14%) | total_pruned =     414 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     115 / 2359296             (  0.00%) | total_pruned = 2359181 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     315 /     512             ( 61.52%) | total_pruned =     197 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
linear.weight        | nonzeros =    1160 /    5120             ( 22.66%) | total_pruned =    3960 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 43668, pruned : 11135094, total: 11178762, Compression rate :     255.99x  ( 99.61% pruned)
Train Epoch: 82/100 Loss: 0.034669 Accuracy: 79.73 100.00 % Best test Accuracy: 80.80%
tensor(0.0068, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-3.0011e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 4.143672
Average KL loss: 0.081771
Average total loss: 4.225443
tensor(0.0066, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-3.3196e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 4.127301
Average KL loss: 0.079382
Average total loss: 4.206683
tensor(0.0064, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.2845e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 4.192029
Average KL loss: 0.077289
Average total loss: 4.269318
tensor(0.0063, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.1200e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 4.016020
Average KL loss: 0.075462
Average total loss: 4.091481
tensor(0.0061, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.7818e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 4.162002
Average KL loss: 0.073880
Average total loss: 4.235881
tensor(0.0060, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.6315e-07, device='cuda:0')
Epoch 6
Average batch original loss after noise: 3.990906
Average KL loss: 0.072523
Average total loss: 4.063430
tensor(0.0058, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.8273e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 4.030326
Average KL loss: 0.071368
Average total loss: 4.101694
tensor(0.0057, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.3967e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 3.780922
Average KL loss: 0.070395
Average total loss: 3.851317
tensor(0.0056, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.3749e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 3.748194
Average KL loss: 0.069582
Average total loss: 3.817776
tensor(0.0055, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.5681e-07, device='cuda:0')
Epoch 10
Average batch original loss after noise: 4.008761
Average KL loss: 0.068912
Average total loss: 4.077673
tensor(0.0054, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.7182e-07, device='cuda:0')
Epoch 11
Average batch original loss after noise: 3.978550
Average KL loss: 0.068365
Average total loss: 4.046914
tensor(0.0053, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.5456e-07, device='cuda:0')
Epoch 12
Average batch original loss after noise: 3.849892
Average KL loss: 0.067923
Average total loss: 3.917815
tensor(0.0052, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.4129e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 3.849575
Average KL loss: 0.067569
Average total loss: 3.917145
tensor(0.0051, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.8299e-07, device='cuda:0')
Epoch 14
Average batch original loss after noise: 3.723122
Average KL loss: 0.067288
Average total loss: 3.790410
tensor(0.0051, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.5888e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 3.815614
Average KL loss: 0.067070
Average total loss: 3.882685
tensor(0.0050, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.9942e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 3.729769
Average KL loss: 0.066906
Average total loss: 3.796676
tensor(0.0050, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.9876e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 3.674325
Average KL loss: 0.066787
Average total loss: 3.741112
tensor(0.0049, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.4737e-07, device='cuda:0')
Epoch 18
Average batch original loss after noise: 3.496955
Average KL loss: 0.066694
Average total loss: 3.563649
tensor(0.0049, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.4254e-07, device='cuda:0')
Epoch 19
Average batch original loss after noise: 3.708528
Average KL loss: 0.066635
Average total loss: 3.775163
tensor(0.0049, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.6720e-07, device='cuda:0')
Epoch 20
Average batch original loss after noise: 3.557107
Average KL loss: 0.066602
Average total loss: 3.623709
tensor(0.0048, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.7490e-07, device='cuda:0')
Epoch 21
Average batch original loss after noise: 3.688162
Average KL loss: 0.066585
Average total loss: 3.754746
tensor(0.0048, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.8760e-07, device='cuda:0')
Epoch 22
Average batch original loss after noise: 3.691128
Average KL loss: 0.066584
Average total loss: 3.757711
tensor(0.0048, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.0909e-07, device='cuda:0')
Epoch 23
Average batch original loss after noise: 3.636978
Average KL loss: 0.066592
Average total loss: 3.703570
tensor(0.0048, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.7492e-07, device='cuda:0')
Epoch 24
Average batch original loss after noise: 3.530659
Average KL loss: 0.066607
Average total loss: 3.597266
tensor(0.0048, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.2928e-07, device='cuda:0')
Epoch 25
Average batch original loss after noise: 3.361178
Average KL loss: 0.066629
Average total loss: 3.427807
tensor(0.0047, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.5595e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 3.592812
Average KL loss: 0.066657
Average total loss: 3.659469
tensor(0.0047, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.2724e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 3.397016
Average KL loss: 0.066696
Average total loss: 3.463712
tensor(0.0047, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.7148e-07, device='cuda:0')
Epoch 28
Average batch original loss after noise: 3.465879
Average KL loss: 0.066737
Average total loss: 3.532616
tensor(0.0047, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.8907e-07, device='cuda:0')
Epoch 29
Average batch original loss after noise: 3.412909
Average KL loss: 0.066784
Average total loss: 3.479692
tensor(0.0047, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.0166e-07, device='cuda:0')
Epoch 30
Average batch original loss after noise: 3.388937
Average KL loss: 0.066833
Average total loss: 3.455770
tensor(0.0047, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.0747e-07, device='cuda:0')
Epoch 31
Average batch original loss after noise: 3.438038
Average KL loss: 0.066890
Average total loss: 3.504928
tensor(0.0047, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.3499e-07, device='cuda:0')
Epoch 32
Average batch original loss after noise: 3.484817
Average KL loss: 0.066945
Average total loss: 3.551762
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-9.7120e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 3.207672
Average KL loss: 0.067000
Average total loss: 3.274672
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.6515e-07, device='cuda:0')
Epoch 34
Average batch original loss after noise: 3.426050
Average KL loss: 0.067061
Average total loss: 3.493111
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.7530e-07, device='cuda:0')
Epoch 35
Average batch original loss after noise: 3.242629
Average KL loss: 0.067122
Average total loss: 3.309752
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.1391e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 3.287014
Average KL loss: 0.067186
Average total loss: 3.354200
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.1681e-07, device='cuda:0')
Epoch 37
Average batch original loss after noise: 3.189242
Average KL loss: 0.067252
Average total loss: 3.256495
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.7982e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 3.269730
Average KL loss: 0.067316
Average total loss: 3.337046
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5958e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 3.282674
Average KL loss: 0.067385
Average total loss: 3.350059
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.1468e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 3.347520
Average KL loss: 0.067456
Average total loss: 3.414976
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.3189e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 3.123749
Average KL loss: 0.067529
Average total loss: 3.191278
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.4201e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 3.354271
Average KL loss: 0.067604
Average total loss: 3.421875
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.2955e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 3.332345
Average KL loss: 0.067682
Average total loss: 3.400027
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.7524e-07, device='cuda:0')
Epoch 44
Average batch original loss after noise: 3.236612
Average KL loss: 0.067761
Average total loss: 3.304372
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.3448e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 3.199186
Average KL loss: 0.067838
Average total loss: 3.267025
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.9702e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 3.176622
Average KL loss: 0.067918
Average total loss: 3.244539
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.5475e-07, device='cuda:0')
Epoch 47
Average batch original loss after noise: 3.133266
Average KL loss: 0.067995
Average total loss: 3.201261
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.0500e-07, device='cuda:0')
Epoch 48
Average batch original loss after noise: 3.044143
Average KL loss: 0.068075
Average total loss: 3.112218
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.5344e-07, device='cuda:0')
Epoch 49
Average batch original loss after noise: 3.120933
Average KL loss: 0.068152
Average total loss: 3.189084
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.6908e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 3.063287
Average KL loss: 0.068233
Average total loss: 3.131519
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.1276e-07, device='cuda:0')
Epoch 51
Average batch original loss after noise: 3.152685
Average KL loss: 0.068314
Average total loss: 3.220999
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.6024e-07, device='cuda:0')
Epoch 52
Average batch original loss after noise: 3.104877
Average KL loss: 0.068396
Average total loss: 3.173273
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.6914e-07, device='cuda:0')
Epoch 53
Average batch original loss after noise: 2.995651
Average KL loss: 0.068483
Average total loss: 3.064134
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.3746e-07, device='cuda:0')
Epoch 54
Average batch original loss after noise: 3.047497
Average KL loss: 0.068566
Average total loss: 3.116063
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.9063e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 2.905523
Average KL loss: 0.068650
Average total loss: 2.974173
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.4661e-07, device='cuda:0')
Epoch 56
Average batch original loss after noise: 2.977641
Average KL loss: 0.068733
Average total loss: 3.046374
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.2534e-07, device='cuda:0')
Epoch 57
Average batch original loss after noise: 3.107885
Average KL loss: 0.068820
Average total loss: 3.176706
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-8.9377e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 2.983528
Average KL loss: 0.068912
Average total loss: 3.052440
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-9.0921e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 3.200969
Average KL loss: 0.068996
Average total loss: 3.269964
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.1676e-07, device='cuda:0')
Epoch 60
Average batch original loss after noise: 2.923784
Average KL loss: 0.069086
Average total loss: 2.992869
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.7620e-07, device='cuda:0')
Epoch 61
Average batch original loss after noise: 2.913557
Average KL loss: 0.069171
Average total loss: 2.982727
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.3648e-07, device='cuda:0')
Epoch 62
Average batch original loss after noise: 2.900761
Average KL loss: 0.069259
Average total loss: 2.970020
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.6417e-07, device='cuda:0')
Epoch 63
Average batch original loss after noise: 2.986247
Average KL loss: 0.069352
Average total loss: 3.055599
tensor(0.0048, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-8.1021e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 2.841916
Average KL loss: 0.069441
Average total loss: 2.911356
tensor(0.0048, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2560e-07, device='cuda:0')
Epoch 65
Average batch original loss after noise: 2.900234
Average KL loss: 0.069531
Average total loss: 2.969765
tensor(0.0048, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.3410e-07, device='cuda:0')
Epoch 66
Average batch original loss after noise: 2.977613
Average KL loss: 0.069620
Average total loss: 3.047234
tensor(0.0048, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.3287e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 3.014332
Average KL loss: 0.069710
Average total loss: 3.084042
tensor(0.0048, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.9957e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 2.822582
Average KL loss: 0.069797
Average total loss: 2.892380
tensor(0.0048, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.6320e-07, device='cuda:0')
Epoch 69
Average batch original loss after noise: 2.946246
Average KL loss: 0.069884
Average total loss: 3.016130
tensor(0.0048, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.5399e-07, device='cuda:0')
Epoch 70
Average batch original loss after noise: 2.928390
Average KL loss: 0.069972
Average total loss: 2.998361
tensor(0.0048, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.4438e-07, device='cuda:0')
Epoch 71
Average batch original loss after noise: 2.851763
Average KL loss: 0.070063
Average total loss: 2.921827
tensor(0.0048, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.4809e-07, device='cuda:0')
Epoch 72
Average batch original loss after noise: 2.840886
Average KL loss: 0.070160
Average total loss: 2.911046
tensor(0.0048, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-9.9349e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 2.898902
Average KL loss: 0.070252
Average total loss: 2.969153
tensor(0.0048, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.6278e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 2.796100
Average KL loss: 0.070343
Average total loss: 2.866443
tensor(0.0048, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.6374e-07, device='cuda:0')
Epoch 75
Average batch original loss after noise: 2.893958
Average KL loss: 0.070436
Average total loss: 2.964394
tensor(0.0048, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.1705e-07, device='cuda:0')
Epoch 76
Average batch original loss after noise: 2.801901
Average KL loss: 0.070530
Average total loss: 2.872431
tensor(0.0048, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-9.4389e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 2.742824
Average KL loss: 0.070619
Average total loss: 2.813444
tensor(0.0048, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.6716e-07, device='cuda:0')
Epoch 78
Average batch original loss after noise: 2.822003
Average KL loss: 0.070709
Average total loss: 2.892711
tensor(0.0048, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.5714e-07, device='cuda:0')
Epoch 79
Average batch original loss after noise: 2.915742
Average KL loss: 0.070800
Average total loss: 2.986542
tensor(0.0048, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.3234e-07, device='cuda:0')
Epoch 80
Average batch original loss after noise: 2.862683
Average KL loss: 0.070892
Average total loss: 2.933575
tensor(0.0048, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.6382e-07, device='cuda:0')
Epoch 81
Average batch original loss after noise: 2.769711
Average KL loss: 0.070978
Average total loss: 2.840689
tensor(0.0048, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.1131e-07, device='cuda:0')
Epoch 82
Average batch original loss after noise: 2.619493
Average KL loss: 0.071063
Average total loss: 2.690557
tensor(0.0048, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.1625e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 2.772146
Average KL loss: 0.071150
Average total loss: 2.843295
tensor(0.0048, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-8.1027e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 2.773205
Average KL loss: 0.071241
Average total loss: 2.844446
tensor(0.0048, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.5521e-07, device='cuda:0')
Epoch 85
Average batch original loss after noise: 2.720344
Average KL loss: 0.071332
Average total loss: 2.791676
tensor(0.0048, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.2602e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 2.871911
Average KL loss: 0.071421
Average total loss: 2.943332
tensor(0.0048, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.1249e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 2.870671
Average KL loss: 0.071519
Average total loss: 2.942189
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.2142e-07, device='cuda:0')
Epoch 88
Average batch original loss after noise: 2.702989
Average KL loss: 0.071617
Average total loss: 2.774606
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.3812e-07, device='cuda:0')
Epoch 89
Average batch original loss after noise: 2.750864
Average KL loss: 0.071709
Average total loss: 2.822573
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.9325e-07, device='cuda:0')
Epoch 90
Average batch original loss after noise: 2.620360
Average KL loss: 0.071798
Average total loss: 2.692159
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.1909e-07, device='cuda:0')
Epoch 91
Average batch original loss after noise: 2.656405
Average KL loss: 0.071888
Average total loss: 2.728293
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.3970e-07, device='cuda:0')
Epoch 92
Average batch original loss after noise: 2.745147
Average KL loss: 0.071978
Average total loss: 2.817125
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.2563e-07, device='cuda:0')
Epoch 93
Average batch original loss after noise: 2.635313
Average KL loss: 0.072069
Average total loss: 2.707382
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.0743e-07, device='cuda:0')
Epoch 94
Average batch original loss after noise: 2.758333
Average KL loss: 0.072116
Average total loss: 2.830450
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.2945e-07, device='cuda:0')
Epoch 95
Average batch original loss after noise: 2.678947
Average KL loss: 0.072125
Average total loss: 2.751073
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.6029e-07, device='cuda:0')
Epoch 96
Average batch original loss after noise: 2.612274
Average KL loss: 0.072134
Average total loss: 2.684408
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.8250e-07, device='cuda:0')
Epoch 97
Average batch original loss after noise: 2.686129
Average KL loss: 0.072143
Average total loss: 2.758271
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.7438e-07, device='cuda:0')
Epoch 98
Average batch original loss after noise: 2.718032
Average KL loss: 0.072151
Average total loss: 2.790183
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(6.1220e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 2.774519
Average KL loss: 0.072160
Average total loss: 2.846679
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-8.7670e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 2.685431
Average KL loss: 0.072169
Average total loss: 2.757601
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.8827e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 2.733408
Average KL loss: 0.072178
Average total loss: 2.805587
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.3311e-07, device='cuda:0')
Epoch 102
Average batch original loss after noise: 2.551400
Average KL loss: 0.072187
Average total loss: 2.623587
tensor(0.0048, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.3970e-07, device='cuda:0')
Epoch 103
Average batch original loss after noise: 2.804078
Average KL loss: 0.072196
Average total loss: 2.876275
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-7.6621e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 2.619838
Average KL loss: 0.072206
Average total loss: 2.692044
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.8072e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 2.654975
Average KL loss: 0.072215
Average total loss: 2.727190
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-9.0816e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 2.593681
Average KL loss: 0.072224
Average total loss: 2.665905
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.2024e-07, device='cuda:0')
Epoch 107
Average batch original loss after noise: 2.774352
Average KL loss: 0.072233
Average total loss: 2.846585
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.4982e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 2.645944
Average KL loss: 0.072243
Average total loss: 2.718187
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-9.0907e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 2.566171
Average KL loss: 0.072252
Average total loss: 2.638423
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.8367e-07, device='cuda:0')
Epoch 110
Average batch original loss after noise: 2.548436
Average KL loss: 0.072261
Average total loss: 2.620697
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.3984e-07, device='cuda:0')
Epoch 111
Average batch original loss after noise: 2.576089
Average KL loss: 0.072269
Average total loss: 2.648358
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.9088e-07, device='cuda:0')
Epoch 112
Average batch original loss after noise: 2.698593
Average KL loss: 0.072279
Average total loss: 2.770872
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.7324e-07, device='cuda:0')
Epoch 113
Average batch original loss after noise: 2.643939
Average KL loss: 0.072289
Average total loss: 2.716227
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.1114e-07, device='cuda:0')
Epoch 114
Average batch original loss after noise: 2.681332
Average KL loss: 0.072298
Average total loss: 2.753630
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.3047e-07, device='cuda:0')
Epoch 115
Average batch original loss after noise: 2.815061
Average KL loss: 0.072308
Average total loss: 2.887369
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.8733e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 2.550017
Average KL loss: 0.072318
Average total loss: 2.622335
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.2289e-07, device='cuda:0')
Epoch 117
Average batch original loss after noise: 2.677058
Average KL loss: 0.072327
Average total loss: 2.749385
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.9223e-07, device='cuda:0')
Epoch 118
Average batch original loss after noise: 2.649239
Average KL loss: 0.072337
Average total loss: 2.721576
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.6971e-07, device='cuda:0')
Epoch 119
Average batch original loss after noise: 2.641882
Average KL loss: 0.072346
Average total loss: 2.714228
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.6672e-07, device='cuda:0')
Epoch 120
Average batch original loss after noise: 2.723752
Average KL loss: 0.072356
Average total loss: 2.796107
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.1810e-07, device='cuda:0')
Epoch 121
Average batch original loss after noise: 2.551913
Average KL loss: 0.072365
Average total loss: 2.624278
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.2778e-07, device='cuda:0')
Epoch 122
Average batch original loss after noise: 2.681998
Average KL loss: 0.072371
Average total loss: 2.754368
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.8798e-07, device='cuda:0')
Epoch 123
Average batch original loss after noise: 2.685148
Average KL loss: 0.072371
Average total loss: 2.757519
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.3063e-07, device='cuda:0')
Epoch 124
Average batch original loss after noise: 2.626329
Average KL loss: 0.072372
Average total loss: 2.698701
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.9973e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 2.707437
Average KL loss: 0.072373
Average total loss: 2.779811
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.1198e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 2.737092
Average KL loss: 0.072374
Average total loss: 2.809466
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.0106e-07, device='cuda:0')
Epoch 127
Average batch original loss after noise: 2.702745
Average KL loss: 0.072375
Average total loss: 2.775120
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.5046e-07, device='cuda:0')
Epoch 128
Average batch original loss after noise: 2.616953
Average KL loss: 0.072376
Average total loss: 2.689329
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.2029e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 2.709083
Average KL loss: 0.072377
Average total loss: 2.781460
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.7750e-07, device='cuda:0')
Epoch 130
Average batch original loss after noise: 2.733177
Average KL loss: 0.072378
Average total loss: 2.805555
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-4.4330e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 2.633063
Average KL loss: 0.072379
Average total loss: 2.705442
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.8433e-07, device='cuda:0')
 Percentile value: 1.4589094519615173
Non-zero model percentage: 0.19531679153442383%, Non-zero mask percentage: 0.19531679153442383%

--- Pruning Level [9/12]: ---
conv1.weight         | nonzeros =     664 /    1728             ( 38.43%) | total_pruned =    1064 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     535 /   36864             (  1.45%) | total_pruned =   36329 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     671 /   36864             (  1.82%) | total_pruned =   36193 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     697 /   36864             (  1.89%) | total_pruned =   36167 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     672 /   36864             (  1.82%) | total_pruned =   36192 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     914 /   73728             (  1.24%) | total_pruned =   72814 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1293 /  147456             (  0.88%) | total_pruned =  146163 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     788 /    8192             (  9.62%) | total_pruned =    7404 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     515 /  147456             (  0.35%) | total_pruned =  146941 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     488 /  147456             (  0.33%) | total_pruned =  146968 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1857 /  294912             (  0.63%) | total_pruned =  293055 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      86 /     256             ( 33.59%) | total_pruned =     170 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2193 /  589824             (  0.37%) | total_pruned =  587631 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      52 /     256             ( 20.31%) | total_pruned =     204 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1214 /   32768             (  3.70%) | total_pruned =   31554 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      54 /     256             ( 21.09%) | total_pruned =     202 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     400 /  589824             (  0.07%) | total_pruned =  589424 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     155 /     256             ( 60.55%) | total_pruned =     101 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     396 /  589824             (  0.07%) | total_pruned =  589428 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2138 / 1179648             (  0.18%) | total_pruned = 1177510 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     473 /     512             ( 92.38%) | total_pruned =      39 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     209 /     512             ( 40.82%) | total_pruned =     303 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1017 / 2359296             (  0.04%) | total_pruned = 2358279 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     431 /     512             ( 84.18%) | total_pruned =      81 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     218 /     512             ( 42.58%) | total_pruned =     294 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     313 /  131072             (  0.24%) | total_pruned =  130759 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     240 /     512             ( 46.88%) | total_pruned =     272 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     202 /     512             ( 39.45%) | total_pruned =     310 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     163 / 2359296             (  0.01%) | total_pruned = 2359133 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      69 /     512             ( 13.48%) | total_pruned =     443 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =       9 / 2359296             (  0.00%) | total_pruned = 2359287 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      47 /     512             (  9.18%) | total_pruned =     465 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     468 /    5120             (  9.14%) | total_pruned =    4652 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 21834, pruned : 11156928, total: 11178762, Compression rate :     511.99x  ( 99.80% pruned)
Train Epoch: 99/100 Loss: 0.431030 Accuracy: 74.74 92.87 % Best test Accuracy: 76.43%
tensor(0.0048, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.1100e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 3.551736
Average KL loss: 0.071454
Average total loss: 3.623190
tensor(0.0047, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.2575e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 3.812760
Average KL loss: 0.069769
Average total loss: 3.882529
tensor(0.0047, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.9781e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 3.460327
Average KL loss: 0.068201
Average total loss: 3.528528
tensor(0.0046, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.1333e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 3.399682
Average KL loss: 0.066737
Average total loss: 3.466419
tensor(0.0045, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.6752e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 3.595317
Average KL loss: 0.065374
Average total loss: 3.660691
tensor(0.0044, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.1340e-07, device='cuda:0')
Epoch 6
Average batch original loss after noise: 3.432770
Average KL loss: 0.064111
Average total loss: 3.496881
tensor(0.0043, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.4820e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 3.532846
Average KL loss: 0.062945
Average total loss: 3.595791
tensor(0.0042, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.8339e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 3.515490
Average KL loss: 0.061875
Average total loss: 3.577366
tensor(0.0042, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.2610e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 3.446808
Average KL loss: 0.060895
Average total loss: 3.507702
tensor(0.0041, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.7650e-07, device='cuda:0')
Epoch 10
Average batch original loss after noise: 3.295818
Average KL loss: 0.060001
Average total loss: 3.355820
tensor(0.0040, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.1833e-07, device='cuda:0')
Epoch 11
Average batch original loss after noise: 3.401596
Average KL loss: 0.059191
Average total loss: 3.460787
tensor(0.0040, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.7928e-07, device='cuda:0')
Epoch 12
Average batch original loss after noise: 3.413565
Average KL loss: 0.058457
Average total loss: 3.472022
tensor(0.0039, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.7278e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 3.336685
Average KL loss: 0.057795
Average total loss: 3.394480
tensor(0.0039, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.6217e-07, device='cuda:0')
Epoch 14
Average batch original loss after noise: 3.334568
Average KL loss: 0.057202
Average total loss: 3.391770
tensor(0.0038, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.3269e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 3.343969
Average KL loss: 0.056671
Average total loss: 3.400639
tensor(0.0038, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.0760e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 3.209277
Average KL loss: 0.056193
Average total loss: 3.265470
tensor(0.0037, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.7135e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 3.379899
Average KL loss: 0.055766
Average total loss: 3.435664
tensor(0.0037, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.7977e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 3.253614
Average KL loss: 0.055388
Average total loss: 3.309002
tensor(0.0036, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.0850e-07, device='cuda:0')
Epoch 19
Average batch original loss after noise: 3.158460
Average KL loss: 0.055053
Average total loss: 3.213512
tensor(0.0036, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.8960e-07, device='cuda:0')
Epoch 20
Average batch original loss after noise: 3.237637
Average KL loss: 0.054756
Average total loss: 3.292393
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.1979e-07, device='cuda:0')
Epoch 21
Average batch original loss after noise: 3.287289
Average KL loss: 0.054496
Average total loss: 3.341786
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.8234e-07, device='cuda:0')
Epoch 22
Average batch original loss after noise: 3.202116
Average KL loss: 0.054268
Average total loss: 3.256384
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.9865e-07, device='cuda:0')
Epoch 23
Average batch original loss after noise: 3.411323
Average KL loss: 0.054065
Average total loss: 3.465387
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.2447e-07, device='cuda:0')
Epoch 24
Average batch original loss after noise: 3.284372
Average KL loss: 0.053885
Average total loss: 3.338258
tensor(0.0034, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.2075e-07, device='cuda:0')
Epoch 25
Average batch original loss after noise: 3.170481
Average KL loss: 0.053727
Average total loss: 3.224209
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.3217e-07, device='cuda:0')
Epoch 26
Average batch original loss after noise: 3.168715
Average KL loss: 0.053589
Average total loss: 3.222304
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.3626e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 3.135925
Average KL loss: 0.053466
Average total loss: 3.189391
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.4624e-07, device='cuda:0')
Epoch 28
Average batch original loss after noise: 3.004898
Average KL loss: 0.053356
Average total loss: 3.058254
tensor(0.0033, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.3448e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 3.193192
Average KL loss: 0.053263
Average total loss: 3.246455
tensor(0.0033, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-9.4694e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 3.188426
Average KL loss: 0.053179
Average total loss: 3.241604
tensor(0.0033, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.3688e-07, device='cuda:0')
Epoch 31
Average batch original loss after noise: 3.225900
Average KL loss: 0.053105
Average total loss: 3.279005
tensor(0.0033, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.3671e-07, device='cuda:0')
Epoch 32
Average batch original loss after noise: 2.993121
Average KL loss: 0.053042
Average total loss: 3.046163
tensor(0.0033, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.8226e-07, device='cuda:0')
Epoch 33
Average batch original loss after noise: 3.077547
Average KL loss: 0.052986
Average total loss: 3.130533
tensor(0.0033, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.1881e-07, device='cuda:0')
Epoch 34
Average batch original loss after noise: 3.084282
Average KL loss: 0.052936
Average total loss: 3.137219
tensor(0.0033, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.0101e-07, device='cuda:0')
Epoch 35
Average batch original loss after noise: 3.170026
Average KL loss: 0.052892
Average total loss: 3.222919
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.5905e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 3.034802
Average KL loss: 0.052854
Average total loss: 3.087656
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.4408e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 3.120247
Average KL loss: 0.052821
Average total loss: 3.173068
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.7046e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 3.021341
Average KL loss: 0.052793
Average total loss: 3.074133
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.3848e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 2.980545
Average KL loss: 0.052768
Average total loss: 3.033313
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.9809e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 2.944064
Average KL loss: 0.052748
Average total loss: 2.996812
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-8.5991e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 2.894668
Average KL loss: 0.052732
Average total loss: 2.947401
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.0278e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 3.025027
Average KL loss: 0.052721
Average total loss: 3.077748
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.5176e-07, device='cuda:0')
Epoch 43
Average batch original loss after noise: 2.996873
Average KL loss: 0.052712
Average total loss: 3.049585
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.9149e-07, device='cuda:0')
Epoch 44
Average batch original loss after noise: 2.919845
Average KL loss: 0.052707
Average total loss: 2.972552
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.8294e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 2.914303
Average KL loss: 0.052703
Average total loss: 2.967006
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.0974e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 3.055347
Average KL loss: 0.052705
Average total loss: 3.108052
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.1026e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 3.114881
Average KL loss: 0.052709
Average total loss: 3.167591
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.8108e-07, device='cuda:0')
Epoch 48
Average batch original loss after noise: 2.957660
Average KL loss: 0.052715
Average total loss: 3.010376
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.3752e-07, device='cuda:0')
Epoch 49
Average batch original loss after noise: 2.852142
Average KL loss: 0.052723
Average total loss: 2.904865
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.5541e-07, device='cuda:0')
Epoch 50
Average batch original loss after noise: 2.842370
Average KL loss: 0.052733
Average total loss: 2.895103
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.8370e-07, device='cuda:0')
Epoch 51
Average batch original loss after noise: 2.964318
Average KL loss: 0.052746
Average total loss: 3.017064
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.6305e-07, device='cuda:0')
Epoch 52
Average batch original loss after noise: 2.847417
Average KL loss: 0.052761
Average total loss: 2.900178
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.4830e-07, device='cuda:0')
Epoch 53
Average batch original loss after noise: 2.937798
Average KL loss: 0.052780
Average total loss: 2.990578
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.2027e-07, device='cuda:0')
Epoch 54
Average batch original loss after noise: 2.917291
Average KL loss: 0.052801
Average total loss: 2.970092
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-9.6542e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 2.950617
Average KL loss: 0.052825
Average total loss: 3.003441
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.4102e-07, device='cuda:0')
Epoch 56
Average batch original loss after noise: 2.889813
Average KL loss: 0.052848
Average total loss: 2.942661
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.0541e-07, device='cuda:0')
Epoch 57
Average batch original loss after noise: 2.755659
Average KL loss: 0.052870
Average total loss: 2.808530
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.2919e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 2.803289
Average KL loss: 0.052895
Average total loss: 2.856184
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-8.8005e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 2.840252
Average KL loss: 0.052921
Average total loss: 2.893173
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.1669e-07, device='cuda:0')
Epoch 60
Average batch original loss after noise: 2.861483
Average KL loss: 0.052949
Average total loss: 2.914432
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.1036e-07, device='cuda:0')
Epoch 61
Average batch original loss after noise: 2.763868
Average KL loss: 0.052975
Average total loss: 2.816844
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.2416e-07, device='cuda:0')
Epoch 62
Average batch original loss after noise: 2.704169
Average KL loss: 0.053005
Average total loss: 2.757174
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-8.3000e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 2.817577
Average KL loss: 0.053038
Average total loss: 2.870614
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.1900e-07, device='cuda:0')
Epoch 64
Average batch original loss after noise: 2.670506
Average KL loss: 0.053068
Average total loss: 2.723574
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.9748e-07, device='cuda:0')
Epoch 65
Average batch original loss after noise: 2.782671
Average KL loss: 0.053096
Average total loss: 2.835768
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.4768e-07, device='cuda:0')
Epoch 66
Average batch original loss after noise: 2.771253
Average KL loss: 0.053128
Average total loss: 2.824381
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.5370e-07, device='cuda:0')
Epoch 67
Average batch original loss after noise: 2.827379
Average KL loss: 0.053161
Average total loss: 2.880540
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.0265e-07, device='cuda:0')
Epoch 68
Average batch original loss after noise: 2.677199
Average KL loss: 0.053193
Average total loss: 2.730393
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-8.5893e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 2.842477
Average KL loss: 0.053225
Average total loss: 2.895702
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.4233e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 2.688382
Average KL loss: 0.053259
Average total loss: 2.741641
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.5743e-07, device='cuda:0')
Epoch 71
Average batch original loss after noise: 2.783260
Average KL loss: 0.053293
Average total loss: 2.836552
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-8.2616e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 2.747956
Average KL loss: 0.053326
Average total loss: 2.801283
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.5706e-07, device='cuda:0')
Epoch 73
Average batch original loss after noise: 2.694128
Average KL loss: 0.053361
Average total loss: 2.747489
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.5904e-07, device='cuda:0')
Epoch 74
Average batch original loss after noise: 2.676511
Average KL loss: 0.053396
Average total loss: 2.729907
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.0005e-07, device='cuda:0')
Epoch 75
Average batch original loss after noise: 2.695278
Average KL loss: 0.053430
Average total loss: 2.748708
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.6196e-07, device='cuda:0')
Epoch 76
Average batch original loss after noise: 2.659841
Average KL loss: 0.053449
Average total loss: 2.713290
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.5940e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 2.574619
Average KL loss: 0.053453
Average total loss: 2.628072
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.0578e-07, device='cuda:0')
Epoch 78
Average batch original loss after noise: 2.698884
Average KL loss: 0.053456
Average total loss: 2.752340
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.1936e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 2.691556
Average KL loss: 0.053459
Average total loss: 2.745015
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.3367e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 2.655478
Average KL loss: 0.053463
Average total loss: 2.708941
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.5105e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 2.665133
Average KL loss: 0.053466
Average total loss: 2.718599
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.0865e-07, device='cuda:0')
Epoch 82
Average batch original loss after noise: 2.746373
Average KL loss: 0.053470
Average total loss: 2.799843
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.3737e-07, device='cuda:0')
Epoch 83
Average batch original loss after noise: 2.789376
Average KL loss: 0.053474
Average total loss: 2.842850
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.0076e-07, device='cuda:0')
Epoch 84
Average batch original loss after noise: 2.782550
Average KL loss: 0.053477
Average total loss: 2.836028
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.8895e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 2.564426
Average KL loss: 0.053481
Average total loss: 2.617908
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.9448e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 2.665623
Average KL loss: 0.053485
Average total loss: 2.719108
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.0223e-07, device='cuda:0')
Epoch 87
Average batch original loss after noise: 2.641208
Average KL loss: 0.053489
Average total loss: 2.694697
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.2210e-07, device='cuda:0')
Epoch 88
Average batch original loss after noise: 2.657138
Average KL loss: 0.053492
Average total loss: 2.710631
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.2913e-07, device='cuda:0')
Epoch 89
Average batch original loss after noise: 2.714189
Average KL loss: 0.053496
Average total loss: 2.767685
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.1748e-07, device='cuda:0')
Epoch 90
Average batch original loss after noise: 2.682490
Average KL loss: 0.053500
Average total loss: 2.735989
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.3421e-07, device='cuda:0')
Epoch 91
Average batch original loss after noise: 2.744722
Average KL loss: 0.053503
Average total loss: 2.798225
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.8339e-07, device='cuda:0')
Epoch 92
Average batch original loss after noise: 2.656449
Average KL loss: 0.053507
Average total loss: 2.709955
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.0480e-07, device='cuda:0')
Epoch 93
Average batch original loss after noise: 2.620903
Average KL loss: 0.053510
Average total loss: 2.674413
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.4569e-07, device='cuda:0')
Epoch 94
Average batch original loss after noise: 2.711787
Average KL loss: 0.053514
Average total loss: 2.765301
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.3166e-07, device='cuda:0')
Epoch 95
Average batch original loss after noise: 2.583541
Average KL loss: 0.053518
Average total loss: 2.637059
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.0907e-07, device='cuda:0')
Epoch 96
Average batch original loss after noise: 2.606572
Average KL loss: 0.053522
Average total loss: 2.660093
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.9655e-07, device='cuda:0')
Epoch 97
Average batch original loss after noise: 2.628911
Average KL loss: 0.053524
Average total loss: 2.682434
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.4688e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 2.509852
Average KL loss: 0.053524
Average total loss: 2.563376
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.7780e-07, device='cuda:0')
Epoch 99
Average batch original loss after noise: 2.808306
Average KL loss: 0.053524
Average total loss: 2.861830
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.8633e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 2.698004
Average KL loss: 0.053525
Average total loss: 2.751529
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.3266e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 2.820919
Average KL loss: 0.053525
Average total loss: 2.874445
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.1223e-07, device='cuda:0')
Epoch 102
Average batch original loss after noise: 2.733502
Average KL loss: 0.053525
Average total loss: 2.787028
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.1828e-07, device='cuda:0')
Epoch 103
Average batch original loss after noise: 2.627606
Average KL loss: 0.053526
Average total loss: 2.681132
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.3156e-07, device='cuda:0')
Epoch 104
Average batch original loss after noise: 2.633714
Average KL loss: 0.053526
Average total loss: 2.687240
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.2881e-07, device='cuda:0')
Epoch 105
Average batch original loss after noise: 2.687279
Average KL loss: 0.053527
Average total loss: 2.740806
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.1722e-07, device='cuda:0')
Epoch 106
Average batch original loss after noise: 2.741655
Average KL loss: 0.053527
Average total loss: 2.795182
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.1236e-07, device='cuda:0')
Epoch 107
Average batch original loss after noise: 2.658122
Average KL loss: 0.053527
Average total loss: 2.711650
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.8985e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 2.686711
Average KL loss: 0.053528
Average total loss: 2.740239
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-9.1554e-08, device='cuda:0')
 Percentile value: 1.9493001699447632
Non-zero model percentage: 0.09765839576721191%, Non-zero mask percentage: 0.09765839576721191%

--- Pruning Level [10/12]: ---
conv1.weight         | nonzeros =     548 /    1728             ( 31.71%) | total_pruned =    1180 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     283 /   36864             (  0.77%) | total_pruned =   36581 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     370 /   36864             (  1.00%) | total_pruned =   36494 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     398 /   36864             (  1.08%) | total_pruned =   36466 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      30 /      64             ( 46.88%) | total_pruned =      34 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     391 /   36864             (  1.06%) | total_pruned =   36473 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     460 /   73728             (  0.62%) | total_pruned =   73268 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     629 /  147456             (  0.43%) | total_pruned =  146827 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     492 /    8192             (  6.01%) | total_pruned =    7700 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     238 /  147456             (  0.16%) | total_pruned =  147218 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     247 /  147456             (  0.17%) | total_pruned =  147209 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     844 /  294912             (  0.29%) | total_pruned =  294068 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      70 /     256             ( 27.34%) | total_pruned =     186 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     979 /  589824             (  0.17%) | total_pruned =  588845 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     549 /   32768             (  1.68%) | total_pruned =   32219 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     179 /  589824             (  0.03%) | total_pruned =  589645 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     108 /     256             ( 42.19%) | total_pruned =     148 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     169 /  589824             (  0.03%) | total_pruned =  589655 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     144 /     256             ( 56.25%) | total_pruned =     112 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     774 / 1179648             (  0.07%) | total_pruned = 1178874 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     297 /     512             ( 58.01%) | total_pruned =     215 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      82 /     512             ( 16.02%) | total_pruned =     430 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     242 / 2359296             (  0.01%) | total_pruned = 2359054 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     197 /     512             ( 38.48%) | total_pruned =     315 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      43 /     512             (  8.40%) | total_pruned =     469 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      74 /  131072             (  0.06%) | total_pruned =  130998 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      88 /     512             ( 17.19%) | total_pruned =     424 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      48 /     512             (  9.38%) | total_pruned =     464 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       5 / 2359296             (  0.00%) | total_pruned = 2359291 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =       1 / 2359296             (  0.00%) | total_pruned = 2359295 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     135 /    5120             (  2.64%) | total_pruned =    4985 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 10917, pruned : 11167845, total: 11178762, Compression rate :    1023.98x  ( 99.90% pruned)
Train Epoch: 99/100 Loss: 0.766301 Accuracy: 69.26 77.80 % Best test Accuracy: 69.75%
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-8.6178e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.642711
Average KL loss: 0.052978
Average total loss: 2.695689
tensor(0.0031, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.3135e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.690214
Average KL loss: 0.051956
Average total loss: 2.742171
tensor(0.0031, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.7361e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.553509
Average KL loss: 0.050965
Average total loss: 2.604474
tensor(0.0031, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.0739e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.596595
Average KL loss: 0.049997
Average total loss: 2.646592
tensor(0.0030, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.4643e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.513204
Average KL loss: 0.049055
Average total loss: 2.562259
tensor(0.0030, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.0319e-07, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.580454
Average KL loss: 0.048140
Average total loss: 2.628594
tensor(0.0029, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0791e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.520816
Average KL loss: 0.047252
Average total loss: 2.568068
tensor(0.0029, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-7.7124e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.535719
Average KL loss: 0.046394
Average total loss: 2.582113
tensor(0.0028, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.1904e-07, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.616201
Average KL loss: 0.045569
Average total loss: 2.661771
tensor(0.0028, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.0905e-07, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.626446
Average KL loss: 0.044778
Average total loss: 2.671224
tensor(0.0028, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.1359e-07, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.543374
Average KL loss: 0.044021
Average total loss: 2.587395
tensor(0.0027, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-9.3365e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.468833
Average KL loss: 0.043300
Average total loss: 2.512133
tensor(0.0027, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.3061e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.573849
Average KL loss: 0.042613
Average total loss: 2.616461
tensor(0.0026, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.9247e-07, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.401656
Average KL loss: 0.041961
Average total loss: 2.443617
tensor(0.0026, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-9.2395e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.465127
Average KL loss: 0.041345
Average total loss: 2.506472
tensor(0.0026, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.3131e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.479522
Average KL loss: 0.040763
Average total loss: 2.520285
tensor(0.0025, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-6.6653e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.456906
Average KL loss: 0.040217
Average total loss: 2.497124
tensor(0.0025, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-8.8255e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.491589
Average KL loss: 0.039706
Average total loss: 2.531296
tensor(0.0025, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.2521e-07, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.558389
Average KL loss: 0.039227
Average total loss: 2.597615
tensor(0.0024, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.4649e-07, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.467760
Average KL loss: 0.038779
Average total loss: 2.506539
tensor(0.0024, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.3613e-07, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.410405
Average KL loss: 0.038362
Average total loss: 2.448767
tensor(0.0024, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-8.7930e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.450856
Average KL loss: 0.037973
Average total loss: 2.488829
tensor(0.0023, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.2644e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.344402
Average KL loss: 0.037610
Average total loss: 2.382012
tensor(0.0023, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.3205e-07, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.379734
Average KL loss: 0.037275
Average total loss: 2.417009
tensor(0.0023, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.5418e-07, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.414975
Average KL loss: 0.036964
Average total loss: 2.451939
tensor(0.0023, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-8.8582e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 2.460727
Average KL loss: 0.036676
Average total loss: 2.497403
tensor(0.0022, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.1280e-07, device='cuda:0')
Epoch 27
Average batch original loss after noise: 2.272999
Average KL loss: 0.036411
Average total loss: 2.309410
tensor(0.0022, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.4543e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 2.518651
Average KL loss: 0.036164
Average total loss: 2.554815
tensor(0.0022, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.1294e-07, device='cuda:0')
Epoch 29
Average batch original loss after noise: 2.485636
Average KL loss: 0.035934
Average total loss: 2.521570
tensor(0.0022, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-6.5663e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 2.377722
Average KL loss: 0.035725
Average total loss: 2.413447
tensor(0.0022, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.2368e-07, device='cuda:0')
Epoch 31
Average batch original loss after noise: 2.312058
Average KL loss: 0.035531
Average total loss: 2.347589
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.8600e-07, device='cuda:0')
Epoch 32
Average batch original loss after noise: 2.305068
Average KL loss: 0.035351
Average total loss: 2.340418
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-7.9295e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 2.258625
Average KL loss: 0.035184
Average total loss: 2.293809
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.5941e-07, device='cuda:0')
Epoch 34
Average batch original loss after noise: 2.296746
Average KL loss: 0.035029
Average total loss: 2.331775
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0734e-07, device='cuda:0')
Epoch 35
Average batch original loss after noise: 2.264707
Average KL loss: 0.034887
Average total loss: 2.299594
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.8134e-07, device='cuda:0')
Epoch 36
Average batch original loss after noise: 2.186458
Average KL loss: 0.034756
Average total loss: 2.221214
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.9991e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 2.495355
Average KL loss: 0.034634
Average total loss: 2.529988
tensor(0.0020, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.8498e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 2.360905
Average KL loss: 0.034520
Average total loss: 2.395425
tensor(0.0020, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.1362e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 2.339740
Average KL loss: 0.034414
Average total loss: 2.374153
tensor(0.0020, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.2560e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 2.327453
Average KL loss: 0.034317
Average total loss: 2.361770
tensor(0.0020, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-2.9812e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 2.280574
Average KL loss: 0.034228
Average total loss: 2.314802
tensor(0.0020, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-4.1556e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 2.242839
Average KL loss: 0.034147
Average total loss: 2.276986
tensor(0.0020, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-9.6421e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 2.280251
Average KL loss: 0.034071
Average total loss: 2.314321
tensor(0.0020, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-4.2119e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 2.321345
Average KL loss: 0.034001
Average total loss: 2.355346
tensor(0.0020, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-8.8673e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 2.277172
Average KL loss: 0.033936
Average total loss: 2.311109
tensor(0.0020, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.0844e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 2.174820
Average KL loss: 0.033877
Average total loss: 2.208696
tensor(0.0020, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-9.5490e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 2.289986
Average KL loss: 0.033824
Average total loss: 2.323810
tensor(0.0020, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.3000e-07, device='cuda:0')
Epoch 48
Average batch original loss after noise: 2.189208
Average KL loss: 0.033773
Average total loss: 2.222981
tensor(0.0020, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.4624e-07, device='cuda:0')
Epoch 49
Average batch original loss after noise: 2.236075
Average KL loss: 0.033727
Average total loss: 2.269802
tensor(0.0019, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-6.8139e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 2.259907
Average KL loss: 0.033687
Average total loss: 2.293594
tensor(0.0019, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.6274e-07, device='cuda:0')
Epoch 51
Average batch original loss after noise: 2.129826
Average KL loss: 0.033652
Average total loss: 2.163477
tensor(0.0019, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.0335e-07, device='cuda:0')
Epoch 52
Average batch original loss after noise: 2.248833
Average KL loss: 0.033620
Average total loss: 2.282453
tensor(0.0019, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.8544e-07, device='cuda:0')
Epoch 53
Average batch original loss after noise: 2.309789
Average KL loss: 0.033590
Average total loss: 2.343379
tensor(0.0019, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.8179e-07, device='cuda:0')
Epoch 54
Average batch original loss after noise: 2.163648
Average KL loss: 0.033566
Average total loss: 2.197214
tensor(0.0019, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.5162e-07, device='cuda:0')
Epoch 55
Average batch original loss after noise: 2.254690
Average KL loss: 0.033546
Average total loss: 2.288236
tensor(0.0019, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-4.0951e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 2.266333
Average KL loss: 0.033528
Average total loss: 2.299861
tensor(0.0019, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.4783e-07, device='cuda:0')
Epoch 57
Average batch original loss after noise: 2.266077
Average KL loss: 0.033512
Average total loss: 2.299589
tensor(0.0019, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.3179e-07, device='cuda:0')
Epoch 58
Average batch original loss after noise: 2.230704
Average KL loss: 0.033499
Average total loss: 2.264203
tensor(0.0019, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.6151e-07, device='cuda:0')
Epoch 59
Average batch original loss after noise: 2.400098
Average KL loss: 0.033491
Average total loss: 2.433589
tensor(0.0019, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.0078e-07, device='cuda:0')
Epoch 60
Average batch original loss after noise: 2.153721
Average KL loss: 0.033484
Average total loss: 2.187205
tensor(0.0019, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-4.0403e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 2.080771
Average KL loss: 0.033479
Average total loss: 2.114251
tensor(0.0019, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.8251e-07, device='cuda:0')
Epoch 62
Average batch original loss after noise: 2.226496
Average KL loss: 0.033476
Average total loss: 2.259973
tensor(0.0019, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.8196e-07, device='cuda:0')
Epoch 63
Average batch original loss after noise: 2.191957
Average KL loss: 0.033475
Average total loss: 2.225432
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-7.8837e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 2.108751
Average KL loss: 0.033475
Average total loss: 2.142227
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0639e-07, device='cuda:0')
Epoch 65
Average batch original loss after noise: 2.141587
Average KL loss: 0.033477
Average total loss: 2.175064
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.7207e-07, device='cuda:0')
Epoch 66
Average batch original loss after noise: 2.176801
Average KL loss: 0.033481
Average total loss: 2.210282
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.2200e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 2.104897
Average KL loss: 0.033487
Average total loss: 2.138384
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-9.4232e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 2.050281
Average KL loss: 0.033492
Average total loss: 2.083773
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-9.4208e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 2.169140
Average KL loss: 0.033500
Average total loss: 2.202639
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.3830e-07, device='cuda:0')
Epoch 70
Average batch original loss after noise: 2.150392
Average KL loss: 0.033508
Average total loss: 2.183901
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0091e-07, device='cuda:0')
Epoch 71
Average batch original loss after noise: 2.055893
Average KL loss: 0.033518
Average total loss: 2.089411
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-8.4522e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 2.108979
Average KL loss: 0.033528
Average total loss: 2.142507
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.3995e-07, device='cuda:0')
Epoch 73
Average batch original loss after noise: 2.042761
Average KL loss: 0.033538
Average total loss: 2.076299
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-7.9912e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 2.112405
Average KL loss: 0.033549
Average total loss: 2.145954
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-9.6414e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 2.110355
Average KL loss: 0.033561
Average total loss: 2.143916
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0126e-07, device='cuda:0')
Epoch 76
Average batch original loss after noise: 2.070972
Average KL loss: 0.033574
Average total loss: 2.104546
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-9.7661e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 2.168333
Average KL loss: 0.033587
Average total loss: 2.201920
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1136e-07, device='cuda:0')
Epoch 78
Average batch original loss after noise: 2.138462
Average KL loss: 0.033599
Average total loss: 2.172061
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.8849e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 2.104956
Average KL loss: 0.033613
Average total loss: 2.138569
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1920e-07, device='cuda:0')
Epoch 80
Average batch original loss after noise: 2.179964
Average KL loss: 0.033627
Average total loss: 2.213591
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.6674e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 2.066520
Average KL loss: 0.033641
Average total loss: 2.100162
tensor(0.0019, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-9.8316e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 2.125958
Average KL loss: 0.033656
Average total loss: 2.159614
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-9.1373e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 2.098193
Average KL loss: 0.033671
Average total loss: 2.131864
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.3357e-07, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.977971
Average KL loss: 0.033687
Average total loss: 2.011658
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.1875e-07, device='cuda:0')
Epoch 85
Average batch original loss after noise: 2.140386
Average KL loss: 0.033702
Average total loss: 2.174088
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.1620e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 2.145542
Average KL loss: 0.033717
Average total loss: 2.179258
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-8.1126e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 2.005457
Average KL loss: 0.033731
Average total loss: 2.039187
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.4813e-07, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.977302
Average KL loss: 0.033745
Average total loss: 2.011047
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-8.8385e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.980429
Average KL loss: 0.033759
Average total loss: 2.014188
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.6383e-07, device='cuda:0')
Epoch 90
Average batch original loss after noise: 2.046345
Average KL loss: 0.033773
Average total loss: 2.080118
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-7.9337e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 2.082645
Average KL loss: 0.033787
Average total loss: 2.116432
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.4696e-07, device='cuda:0')
Epoch 92
Average batch original loss after noise: 2.017745
Average KL loss: 0.033801
Average total loss: 2.051546
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.6704e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.993931
Average KL loss: 0.033815
Average total loss: 2.027746
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.8487e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.989244
Average KL loss: 0.033830
Average total loss: 2.023074
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-8.3794e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.928252
Average KL loss: 0.033843
Average total loss: 1.962096
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.5688e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.982902
Average KL loss: 0.033858
Average total loss: 2.016760
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-7.0826e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 2.034365
Average KL loss: 0.033872
Average total loss: 2.068237
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.4791e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.846652
Average KL loss: 0.033887
Average total loss: 1.880539
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-8.1992e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 2.022290
Average KL loss: 0.033901
Average total loss: 2.056191
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-6.0870e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.971964
Average KL loss: 0.033915
Average total loss: 2.005879
tensor(0.0019, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-7.3592e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.972773
Average KL loss: 0.033930
Average total loss: 2.006704
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.8835e-07, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.932853
Average KL loss: 0.033946
Average total loss: 1.966799
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-8.8032e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.963960
Average KL loss: 0.033963
Average total loss: 1.997923
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.1293e-07, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.931167
Average KL loss: 0.033977
Average total loss: 1.965145
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.8823e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.933249
Average KL loss: 0.033992
Average total loss: 1.967241
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.2004e-07, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.981369
Average KL loss: 0.034005
Average total loss: 2.015375
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-9.1528e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.984421
Average KL loss: 0.034018
Average total loss: 2.018439
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.7664e-07, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.978114
Average KL loss: 0.034032
Average total loss: 2.012145
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.2195e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.915678
Average KL loss: 0.034046
Average total loss: 1.949724
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.0655e-07, device='cuda:0')
Epoch 110
Average batch original loss after noise: 2.007373
Average KL loss: 0.034054
Average total loss: 2.041427
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.9342e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.971557
Average KL loss: 0.034055
Average total loss: 2.005612
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.2343e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.978042
Average KL loss: 0.034056
Average total loss: 2.012099
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.9680e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.893597
Average KL loss: 0.034058
Average total loss: 1.927655
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.7190e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.922296
Average KL loss: 0.034059
Average total loss: 1.956355
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.4568e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.901316
Average KL loss: 0.034061
Average total loss: 1.935377
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.9166e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.923566
Average KL loss: 0.034062
Average total loss: 1.957629
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.1682e-07, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.866030
Average KL loss: 0.034064
Average total loss: 1.900094
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-9.9404e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.946687
Average KL loss: 0.034065
Average total loss: 1.980753
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-9.2189e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.950441
Average KL loss: 0.034067
Average total loss: 1.984508
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.9946e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.917596
Average KL loss: 0.034068
Average total loss: 1.951664
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.2518e-07, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.866321
Average KL loss: 0.034069
Average total loss: 1.900390
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-9.0774e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 2.037061
Average KL loss: 0.034069
Average total loss: 2.071130
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.0631e-07, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.748229
Average KL loss: 0.034069
Average total loss: 1.782298
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.2355e-07, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.935471
Average KL loss: 0.034069
Average total loss: 1.969540
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-4.0961e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.859859
Average KL loss: 0.034070
Average total loss: 1.893929
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.1848e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.929796
Average KL loss: 0.034070
Average total loss: 1.963866
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.7611e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.950162
Average KL loss: 0.034070
Average total loss: 1.984231
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.0193e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.898726
Average KL loss: 0.034070
Average total loss: 1.932796
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-4.3446e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.924288
Average KL loss: 0.034070
Average total loss: 1.958358
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.5389e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.946895
Average KL loss: 0.034070
Average total loss: 1.980965
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-8.5397e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.908324
Average KL loss: 0.034070
Average total loss: 1.942395
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.0198e-07, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.814858
Average KL loss: 0.034071
Average total loss: 1.848929
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.2568e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.923365
Average KL loss: 0.034071
Average total loss: 1.957435
tensor(0.0019, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.9338e-08, device='cuda:0')
 Percentile value: 2.5617189407348633
Non-zero model percentage: 0.04883367195725441%, Non-zero mask percentage: 0.04883367195725441%

--- Pruning Level [11/12]: ---
conv1.weight         | nonzeros =     421 /    1728             ( 24.36%) | total_pruned =    1307 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     161 /   36864             (  0.44%) | total_pruned =   36703 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     210 /   36864             (  0.57%) | total_pruned =   36654 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     234 /   36864             (  0.63%) | total_pruned =   36630 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     220 /   36864             (  0.60%) | total_pruned =   36644 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     224 /   73728             (  0.30%) | total_pruned =   73504 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     282 /  147456             (  0.19%) | total_pruned =  147174 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     289 /    8192             (  3.53%) | total_pruned =    7903 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     121 /  147456             (  0.08%) | total_pruned =  147335 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     120 /  147456             (  0.08%) | total_pruned =  147336 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     366 /  294912             (  0.12%) | total_pruned =  294546 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     212 /     256             ( 82.81%) | total_pruned =      44 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     403 /  589824             (  0.07%) | total_pruned =  589421 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     200 /   32768             (  0.61%) | total_pruned =   32568 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     141 /     256             ( 55.08%) | total_pruned =     115 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =      69 /  589824             (  0.01%) | total_pruned =  589755 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      55 /     256             ( 21.48%) | total_pruned =     201 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =      61 /  589824             (  0.01%) | total_pruned =  589763 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      62 /     256             ( 24.22%) | total_pruned =     194 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     204 / 1179648             (  0.02%) | total_pruned = 1179444 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      98 /     512             ( 19.14%) | total_pruned =     414 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =      66 / 2359296             (  0.00%) | total_pruned = 2359230 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      52 /     512             ( 10.16%) | total_pruned =     460 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      23 /  131072             (  0.02%) | total_pruned =  131049 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =       0 / 2359296             (  0.00%) | total_pruned = 2359296 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =      53 /    5120             (  1.04%) | total_pruned =    5067 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 5459, pruned : 11173303, total: 11178762, Compression rate :    2047.77x  ( 99.95% pruned)
Train Epoch: 99/100 Loss: 0.848736 Accuracy: 62.71 67.36 % Best test Accuracy: 63.21%
