Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/24]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2827e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302672
Average KL loss: 0.002684
Average total loss: 2.305356
tensor(2.6577e-05, device='cuda:0') tensor(4.0590e-06, device='cuda:0') tensor(2.5648e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.302747
Average KL loss: 0.002979
Average total loss: 2.305725
tensor(1.1998e-05, device='cuda:0') tensor(5.8761e-06, device='cuda:0') tensor(-3.2052e-12, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.301992
Average KL loss: 0.003515
Average total loss: 2.305508
tensor(2.8506e-05, device='cuda:0') tensor(1.2379e-05, device='cuda:0') tensor(-3.4651e-11, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.300801
Average KL loss: 0.004661
Average total loss: 2.305462
tensor(6.8023e-05, device='cuda:0') tensor(2.7850e-05, device='cuda:0') tensor(3.0066e-13, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.296340
Average KL loss: 0.008573
Average total loss: 2.304913
tensor(0.0002, device='cuda:0') tensor(7.7966e-05, device='cuda:0') tensor(-5.9129e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.242151
Average KL loss: 0.030764
Average total loss: 2.272915
tensor(0.0009, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-2.3138e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.904220
Average KL loss: 0.124509
Average total loss: 2.028728
tensor(0.0026, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-8.4956e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.381591
Average KL loss: 0.250861
Average total loss: 1.632452
tensor(0.0031, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.8293e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.031771
Average KL loss: 0.302618
Average total loss: 1.334389
tensor(0.0030, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.9341e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.881427
Average KL loss: 0.308868
Average total loss: 1.190295
tensor(0.0029, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-5.1496e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.798027
Average KL loss: 0.309036
Average total loss: 1.107063
tensor(0.0029, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.4536e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.754729
Average KL loss: 0.311400
Average total loss: 1.066129
tensor(0.0028, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.2742e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.695266
Average KL loss: 0.309724
Average total loss: 1.004990
tensor(0.0028, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-3.3761e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.644160
Average KL loss: 0.305798
Average total loss: 0.949959
tensor(0.0028, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-6.8511e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.616043
Average KL loss: 0.304813
Average total loss: 0.920857
tensor(0.0028, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.6214e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.595678
Average KL loss: 0.303582
Average total loss: 0.899260
tensor(0.0028, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.1181e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.571360
Average KL loss: 0.301201
Average total loss: 0.872560
tensor(0.0028, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.7522e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.553082
Average KL loss: 0.300057
Average total loss: 0.853139
tensor(0.0027, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.0667e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.543076
Average KL loss: 0.299864
Average total loss: 0.842941
tensor(0.0028, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2289e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.520515
Average KL loss: 0.298806
Average total loss: 0.819322
tensor(0.0028, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2023e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.515513
Average KL loss: 0.299252
Average total loss: 0.814765
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.2000e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.499175
Average KL loss: 0.298311
Average total loss: 0.797486
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.2749e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.495127
Average KL loss: 0.301150
Average total loss: 0.796278
tensor(0.0028, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.7852e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.478750
Average KL loss: 0.299744
Average total loss: 0.778495
tensor(0.0028, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.5389e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.477695
Average KL loss: 0.299493
Average total loss: 0.777188
tensor(0.0028, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.4146e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.462231
Average KL loss: 0.298533
Average total loss: 0.760764
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.1999e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.455008
Average KL loss: 0.300123
Average total loss: 0.755131
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.1936e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.454331
Average KL loss: 0.299698
Average total loss: 0.754029
tensor(0.0028, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.0792e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.430505
Average KL loss: 0.298222
Average total loss: 0.728727
tensor(0.0028, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.7253e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.441425
Average KL loss: 0.299654
Average total loss: 0.741079
tensor(0.0028, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2778e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.429539
Average KL loss: 0.299546
Average total loss: 0.729085
tensor(0.0028, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3964e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.421279
Average KL loss: 0.299815
Average total loss: 0.721094
tensor(0.0028, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.1763e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.418745
Average KL loss: 0.299948
Average total loss: 0.718693
tensor(0.0029, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.3651e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.417771
Average KL loss: 0.301744
Average total loss: 0.719515
tensor(0.0029, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.0321e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.408453
Average KL loss: 0.301415
Average total loss: 0.709869
tensor(0.0029, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2605e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.406461
Average KL loss: 0.302058
Average total loss: 0.708519
tensor(0.0029, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2266e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.400730
Average KL loss: 0.301606
Average total loss: 0.702336
tensor(0.0029, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-7.6823e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.397688
Average KL loss: 0.301894
Average total loss: 0.699583
tensor(0.0029, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.6183e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.390997
Average KL loss: 0.302276
Average total loss: 0.693273
tensor(0.0029, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.5471e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.396720
Average KL loss: 0.303744
Average total loss: 0.700464
tensor(0.0029, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.4151e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.384471
Average KL loss: 0.303673
Average total loss: 0.688143
tensor(0.0029, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-5.6547e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.383196
Average KL loss: 0.303071
Average total loss: 0.686267
tensor(0.0029, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.3213e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.378353
Average KL loss: 0.302777
Average total loss: 0.681130
tensor(0.0029, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.0410e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.382397
Average KL loss: 0.304443
Average total loss: 0.686840
tensor(0.0029, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.0742e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.372872
Average KL loss: 0.303917
Average total loss: 0.676789
tensor(0.0029, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.8271e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.368683
Average KL loss: 0.303230
Average total loss: 0.671913
tensor(0.0029, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.5151e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.373898
Average KL loss: 0.304088
Average total loss: 0.677987
tensor(0.0030, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.3642e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.366455
Average KL loss: 0.306385
Average total loss: 0.672841
tensor(0.0030, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.4247e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.369430
Average KL loss: 0.305466
Average total loss: 0.674896
tensor(0.0030, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.9913e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.355943
Average KL loss: 0.304933
Average total loss: 0.660876
tensor(0.0029, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-5.2284e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.361495
Average KL loss: 0.305657
Average total loss: 0.667152
tensor(0.0029, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-7.0756e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.359149
Average KL loss: 0.305430
Average total loss: 0.664579
tensor(0.0030, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.2929e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.357564
Average KL loss: 0.306753
Average total loss: 0.664317
tensor(0.0030, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-9.5667e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.352447
Average KL loss: 0.306648
Average total loss: 0.659095
tensor(0.0030, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.9713e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.348188
Average KL loss: 0.305937
Average total loss: 0.654125
tensor(0.0030, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-5.0642e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.350813
Average KL loss: 0.307290
Average total loss: 0.658103
tensor(0.0030, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-7.4972e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.348743
Average KL loss: 0.306650
Average total loss: 0.655393
tensor(0.0030, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.5554e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.344358
Average KL loss: 0.306008
Average total loss: 0.650366
tensor(0.0030, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.8567e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.344477
Average KL loss: 0.307396
Average total loss: 0.651873
tensor(0.0030, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.5832e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.347760
Average KL loss: 0.307994
Average total loss: 0.655754
tensor(0.0030, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.6681e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.339191
Average KL loss: 0.308534
Average total loss: 0.647725
tensor(0.0030, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.7072e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.341612
Average KL loss: 0.308409
Average total loss: 0.650021
tensor(0.0030, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-6.2547e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.339154
Average KL loss: 0.309087
Average total loss: 0.648240
tensor(0.0030, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.9382e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.334873
Average KL loss: 0.309406
Average total loss: 0.644279
tensor(0.0030, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.3912e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.334543
Average KL loss: 0.308697
Average total loss: 0.643240
tensor(0.0030, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-6.5834e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.334045
Average KL loss: 0.308845
Average total loss: 0.642890
tensor(0.0030, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(3.2238e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.328669
Average KL loss: 0.307674
Average total loss: 0.636343
tensor(0.0030, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-3.1677e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.330733
Average KL loss: 0.309187
Average total loss: 0.639920
tensor(0.0030, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.4925e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.330107
Average KL loss: 0.308965
Average total loss: 0.639072
tensor(0.0030, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.3198e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.332467
Average KL loss: 0.310391
Average total loss: 0.642858
tensor(0.0030, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1547e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.332513
Average KL loss: 0.311353
Average total loss: 0.643866
tensor(0.0030, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(4.7039e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.328166
Average KL loss: 0.311207
Average total loss: 0.639373
tensor(0.0030, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.4217e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.331470
Average KL loss: 0.311498
Average total loss: 0.642968
tensor(0.0031, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.1813e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.325514
Average KL loss: 0.311096
Average total loss: 0.636609
tensor(0.0030, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.6673e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.322756
Average KL loss: 0.310572
Average total loss: 0.633328
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(9.3856e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.324293
Average KL loss: 0.310967
Average total loss: 0.635261
tensor(0.0031, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.8980e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.322791
Average KL loss: 0.311973
Average total loss: 0.634764
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.0939e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.322608
Average KL loss: 0.311570
Average total loss: 0.634178
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-2.6271e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.322892
Average KL loss: 0.313285
Average total loss: 0.636178
tensor(0.0031, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(6.9156e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.320143
Average KL loss: 0.313006
Average total loss: 0.633149
tensor(0.0031, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.8358e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.318661
Average KL loss: 0.313077
Average total loss: 0.631738
tensor(0.0031, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.2900e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.321448
Average KL loss: 0.313067
Average total loss: 0.634515
tensor(0.0031, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.8174e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.318586
Average KL loss: 0.313321
Average total loss: 0.631908
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-5.8857e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.318531
Average KL loss: 0.313399
Average total loss: 0.631930
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.5323e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.315570
Average KL loss: 0.313156
Average total loss: 0.628726
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-4.2423e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.318805
Average KL loss: 0.313512
Average total loss: 0.632317
tensor(0.0031, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.7784e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.316196
Average KL loss: 0.314286
Average total loss: 0.630482
tensor(0.0031, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.3620e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.314958
Average KL loss: 0.313336
Average total loss: 0.628294
tensor(0.0031, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.9559e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.312144
Average KL loss: 0.313444
Average total loss: 0.625588
tensor(0.0031, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-5.9755e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.315220
Average KL loss: 0.313748
Average total loss: 0.628968
tensor(0.0031, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-4.7535e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.314807
Average KL loss: 0.314898
Average total loss: 0.629704
tensor(0.0031, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-6.9040e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.311816
Average KL loss: 0.314734
Average total loss: 0.626550
tensor(0.0031, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(4.5258e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.310645
Average KL loss: 0.314392
Average total loss: 0.625036
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.0594e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.311993
Average KL loss: 0.315058
Average total loss: 0.627051
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(1.6422e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.311613
Average KL loss: 0.315098
Average total loss: 0.626711
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.9490e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.309061
Average KL loss: 0.314885
Average total loss: 0.623946
tensor(0.0031, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.3461e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.310720
Average KL loss: 0.315092
Average total loss: 0.625812
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(2.1839e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.310587
Average KL loss: 0.315305
Average total loss: 0.625891
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-4.7079e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.307078
Average KL loss: 0.314877
Average total loss: 0.621956
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.1982e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.310115
Average KL loss: 0.315148
Average total loss: 0.625263
tensor(0.0031, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-9.0616e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.306154
Average KL loss: 0.314411
Average total loss: 0.620566
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(1.6405e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.308740
Average KL loss: 0.315252
Average total loss: 0.623992
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.1401e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.305619
Average KL loss: 0.315246
Average total loss: 0.620865
tensor(0.0031, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.0127e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.310232
Average KL loss: 0.316691
Average total loss: 0.626922
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.4810e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.301800
Average KL loss: 0.316424
Average total loss: 0.618224
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.3429e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.303254
Average KL loss: 0.315679
Average total loss: 0.618933
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(8.2033e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.303851
Average KL loss: 0.315579
Average total loss: 0.619431
tensor(0.0031, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-3.8590e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.306397
Average KL loss: 0.316086
Average total loss: 0.622483
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(2.6833e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.304565
Average KL loss: 0.317610
Average total loss: 0.622175
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.0165e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.303958
Average KL loss: 0.317102
Average total loss: 0.621061
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.3028e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.302356
Average KL loss: 0.316738
Average total loss: 0.619093
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.0874e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.301272
Average KL loss: 0.317020
Average total loss: 0.618293
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.5851e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.302122
Average KL loss: 0.316443
Average total loss: 0.618565
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(5.9515e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.302712
Average KL loss: 0.317099
Average total loss: 0.619811
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(6.5320e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.301318
Average KL loss: 0.317207
Average total loss: 0.618525
tensor(0.0032, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(3.9346e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.303331
Average KL loss: 0.317486
Average total loss: 0.620817
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.2038e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.302171
Average KL loss: 0.311490
Average total loss: 0.613661
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.3115e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.297085
Average KL loss: 0.303492
Average total loss: 0.600577
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.1054e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.296952
Average KL loss: 0.299613
Average total loss: 0.596565
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.3049e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.296429
Average KL loss: 0.297289
Average total loss: 0.593718
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(4.3097e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.303861
Average KL loss: 0.295690
Average total loss: 0.599551
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.7434e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.299297
Average KL loss: 0.294589
Average total loss: 0.593885
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(5.5730e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.299572
Average KL loss: 0.293731
Average total loss: 0.593302
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.6080e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.297962
Average KL loss: 0.293067
Average total loss: 0.591029
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.9358e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.300435
Average KL loss: 0.292598
Average total loss: 0.593033
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-8.4561e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.300297
Average KL loss: 0.292253
Average total loss: 0.592550
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.4206e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.303111
Average KL loss: 0.291910
Average total loss: 0.595021
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.1833e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.300009
Average KL loss: 0.291737
Average total loss: 0.591746
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.0906e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.298371
Average KL loss: 0.291403
Average total loss: 0.589775
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-5.0561e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.300339
Average KL loss: 0.291098
Average total loss: 0.591437
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(6.0543e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.301461
Average KL loss: 0.290967
Average total loss: 0.592428
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(6.0308e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.301101
Average KL loss: 0.290740
Average total loss: 0.591840
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(8.6308e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.299242
Average KL loss: 0.290556
Average total loss: 0.589798
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.5625e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.299013
Average KL loss: 0.290444
Average total loss: 0.589457
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.0136e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.299418
Average KL loss: 0.290282
Average total loss: 0.589700
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.3191e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.299462
Average KL loss: 0.290224
Average total loss: 0.589685
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.0240e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.300726
Average KL loss: 0.290216
Average total loss: 0.590942
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.9843e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.297846
Average KL loss: 0.290020
Average total loss: 0.587866
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.2266e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.298812
Average KL loss: 0.289880
Average total loss: 0.588692
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(2.3254e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.295722
Average KL loss: 0.289853
Average total loss: 0.585575
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.3492e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.300447
Average KL loss: 0.289835
Average total loss: 0.590281
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(5.2945e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.298634
Average KL loss: 0.289771
Average total loss: 0.588405
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(1.8410e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.299482
Average KL loss: 0.289720
Average total loss: 0.589202
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.5690e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.298981
Average KL loss: 0.289695
Average total loss: 0.588676
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(3.3160e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.298836
Average KL loss: 0.289661
Average total loss: 0.588497
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.4229e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.298603
Average KL loss: 0.289579
Average total loss: 0.588182
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.6243e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.299793
Average KL loss: 0.289523
Average total loss: 0.589316
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.6452e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.297734
Average KL loss: 0.289438
Average total loss: 0.587171
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.9939e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.295528
Average KL loss: 0.289406
Average total loss: 0.584934
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.8764e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.297291
Average KL loss: 0.289461
Average total loss: 0.586752
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.3630e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.298736
Average KL loss: 0.289337
Average total loss: 0.588074
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.4711e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.298988
Average KL loss: 0.289242
Average total loss: 0.588230
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.0883e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.298516
Average KL loss: 0.289197
Average total loss: 0.587714
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.1816e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.299162
Average KL loss: 0.289323
Average total loss: 0.588485
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.6868e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.296932
Average KL loss: 0.289342
Average total loss: 0.586274
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.7322e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.294781
Average KL loss: 0.289319
Average total loss: 0.584101
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.0525e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.295517
Average KL loss: 0.289128
Average total loss: 0.584645
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0918e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.298547
Average KL loss: 0.289096
Average total loss: 0.587642
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(4.0567e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.301097
Average KL loss: 0.289173
Average total loss: 0.590269
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.3429e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.297061
Average KL loss: 0.289244
Average total loss: 0.586305
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.3445e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.295213
Average KL loss: 0.289223
Average total loss: 0.584436
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.4253e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.293798
Average KL loss: 0.289093
Average total loss: 0.582891
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.3094e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.295295
Average KL loss: 0.288935
Average total loss: 0.584230
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.0817e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.298816
Average KL loss: 0.288934
Average total loss: 0.587750
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.0890e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.299009
Average KL loss: 0.289056
Average total loss: 0.588065
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.7580e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.299208
Average KL loss: 0.289138
Average total loss: 0.588346
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.7396e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.298439
Average KL loss: 0.289153
Average total loss: 0.587592
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.2199e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.294563
Average KL loss: 0.289111
Average total loss: 0.583674
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.1560e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.302569
Average KL loss: 0.289086
Average total loss: 0.591656
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0593e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.297357
Average KL loss: 0.289210
Average total loss: 0.586567
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.3717e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.296936
Average KL loss: 0.289177
Average total loss: 0.586114
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.8442e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.300125
Average KL loss: 0.289271
Average total loss: 0.589396
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.0999e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.299169
Average KL loss: 0.289313
Average total loss: 0.588482
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.2752e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.292199
Average KL loss: 0.289241
Average total loss: 0.581441
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.8882e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.298745
Average KL loss: 0.288986
Average total loss: 0.587731
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.0302e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.298329
Average KL loss: 0.288815
Average total loss: 0.587143
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.3348e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.295989
Average KL loss: 0.288666
Average total loss: 0.584655
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.4154e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.297100
Average KL loss: 0.288538
Average total loss: 0.585638
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.6435e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.296065
Average KL loss: 0.288427
Average total loss: 0.584491
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.3132e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.300114
Average KL loss: 0.288328
Average total loss: 0.588443
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.3388e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.296444
Average KL loss: 0.288237
Average total loss: 0.584681
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(2.5738e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.297537
Average KL loss: 0.288149
Average total loss: 0.585686
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5993e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.296707
Average KL loss: 0.288081
Average total loss: 0.584787
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.2960e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.298621
Average KL loss: 0.288018
Average total loss: 0.586639
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.3165e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.298793
Average KL loss: 0.287961
Average total loss: 0.586754
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.6959e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.298290
Average KL loss: 0.287925
Average total loss: 0.586215
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.3860e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.298897
Average KL loss: 0.287915
Average total loss: 0.586812
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(3.3096e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.297919
Average KL loss: 0.287906
Average total loss: 0.585825
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.1511e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.296225
Average KL loss: 0.287897
Average total loss: 0.584122
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.0544e-12, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.298449
Average KL loss: 0.287887
Average total loss: 0.586336
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.2273e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.297753
Average KL loss: 0.287879
Average total loss: 0.585631
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.9166e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.297042
Average KL loss: 0.287870
Average total loss: 0.584912
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5891e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.296852
Average KL loss: 0.287861
Average total loss: 0.584713
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.1500e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.295027
Average KL loss: 0.287853
Average total loss: 0.582880
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.5896e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.294179
Average KL loss: 0.287845
Average total loss: 0.582024
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.4734e-09, device='cuda:0')
 Percentile value: -9.275619049731173e-07
Non-zero model percentage: 80.0%, Non-zero mask percentage: 80.0%

--- Pruning Level [1/24]: ---
conv1.weight         | nonzeros =    1604 /    1728             ( 92.82%) | total_pruned =     124 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   33391 /   36864             ( 90.58%) | total_pruned =    3473 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   29533 /   36864             ( 80.11%) | total_pruned =    7331 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   27233 /   36864             ( 73.87%) | total_pruned =    9631 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   28057 /   36864             ( 76.11%) | total_pruned =    8807 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   46961 /   73728             ( 63.69%) | total_pruned =   26767 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   91470 /  147456             ( 62.03%) | total_pruned =   55986 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5670 /    8192             ( 69.21%) | total_pruned =    2522 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  102478 /  147456             ( 69.50%) | total_pruned =   44978 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  110778 /  147456             ( 75.13%) | total_pruned =   36678 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  171849 /  294912             ( 58.27%) | total_pruned =  123063 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     112 /     256             ( 43.75%) | total_pruned =     144 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  350548 /  589824             ( 59.43%) | total_pruned =  239276 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   21462 /   32768             ( 65.50%) | total_pruned =   11306 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      77 /     256             ( 30.08%) | total_pruned =     179 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  383373 /  589824             ( 65.00%) | total_pruned =  206451 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  434089 /  589824             ( 73.60%) | total_pruned =  155735 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  768122 / 1179648             ( 65.11%) | total_pruned =  411526 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     119 /     512             ( 23.24%) | total_pruned =     393 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1929922 / 2359296             ( 81.80%) | total_pruned =  429374 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     482 /     512             ( 94.14%) | total_pruned =      30 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     283 /     512             ( 55.27%) | total_pruned =     229 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  113304 /  131072             ( 86.44%) | total_pruned =   17768 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     501 /     512             ( 97.85%) | total_pruned =      11 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     278 /     512             ( 54.30%) | total_pruned =     234 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1944423 / 2359296             ( 82.42%) | total_pruned =  414873 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2331995 / 2359296             ( 98.84%) | total_pruned =   27301 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5097 /    5120             ( 99.55%) | total_pruned =      23 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 8943010, pruned : 2235752, total: 11178762, Compression rate :       1.25x  ( 20.00% pruned)
Train Epoch: 51/100 Loss: 0.016748 Accuracy: 88.77 100.00 % Best test Accuracy: 89.08%
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.5426e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.892634
Average KL loss: 0.314635
Average total loss: 1.207269
tensor(0.0038, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-3.9192e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.708914
Average KL loss: 0.342563
Average total loss: 1.051477
tensor(0.0039, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.1266e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.630375
Average KL loss: 0.345794
Average total loss: 0.976169
tensor(0.0038, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.0803e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.596361
Average KL loss: 0.345095
Average total loss: 0.941456
tensor(0.0038, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.2721e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.565835
Average KL loss: 0.341222
Average total loss: 0.907057
tensor(0.0037, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.8782e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.549332
Average KL loss: 0.338309
Average total loss: 0.887641
tensor(0.0037, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.7461e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.531850
Average KL loss: 0.336661
Average total loss: 0.868512
tensor(0.0037, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.3835e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.505976
Average KL loss: 0.335523
Average total loss: 0.841499
tensor(0.0037, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.1996e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.499471
Average KL loss: 0.334314
Average total loss: 0.833785
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.9544e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.495432
Average KL loss: 0.333571
Average total loss: 0.829002
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-4.0951e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.476032
Average KL loss: 0.333785
Average total loss: 0.809817
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.3253e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.467087
Average KL loss: 0.332420
Average total loss: 0.799507
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.2189e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.466419
Average KL loss: 0.331546
Average total loss: 0.797965
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.1492e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.452314
Average KL loss: 0.330975
Average total loss: 0.783289
tensor(0.0036, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.0432e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.456270
Average KL loss: 0.331209
Average total loss: 0.787479
tensor(0.0036, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.0976e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.447026
Average KL loss: 0.331598
Average total loss: 0.778624
tensor(0.0036, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.2306e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.438905
Average KL loss: 0.332147
Average total loss: 0.771052
tensor(0.0035, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-2.2249e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.432181
Average KL loss: 0.330148
Average total loss: 0.762329
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.3317e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.431985
Average KL loss: 0.330675
Average total loss: 0.762660
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.2699e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.422002
Average KL loss: 0.330451
Average total loss: 0.752453
tensor(0.0035, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-3.7267e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.427577
Average KL loss: 0.330883
Average total loss: 0.758459
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-4.3946e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.417796
Average KL loss: 0.329993
Average total loss: 0.747789
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-9.2700e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.418898
Average KL loss: 0.330835
Average total loss: 0.749733
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-3.9842e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.412953
Average KL loss: 0.330889
Average total loss: 0.743842
tensor(0.0035, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-7.1162e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.416519
Average KL loss: 0.331110
Average total loss: 0.747629
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-1.2335e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.408320
Average KL loss: 0.332257
Average total loss: 0.740578
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.7439e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.399781
Average KL loss: 0.330585
Average total loss: 0.730366
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-5.1441e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.398070
Average KL loss: 0.330741
Average total loss: 0.728812
tensor(0.0035, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(7.4131e-11, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.395894
Average KL loss: 0.329899
Average total loss: 0.725793
tensor(0.0035, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-2.0777e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.390554
Average KL loss: 0.331153
Average total loss: 0.721707
tensor(0.0035, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-7.7639e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.389574
Average KL loss: 0.330964
Average total loss: 0.720538
tensor(0.0035, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.4769e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.391851
Average KL loss: 0.330820
Average total loss: 0.722672
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-7.2534e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.385175
Average KL loss: 0.330918
Average total loss: 0.716093
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.4220e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.384591
Average KL loss: 0.330269
Average total loss: 0.714859
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.1904e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.386785
Average KL loss: 0.331624
Average total loss: 0.718409
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.3296e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.383396
Average KL loss: 0.331091
Average total loss: 0.714488
tensor(0.0035, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(1.2599e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.381206
Average KL loss: 0.330684
Average total loss: 0.711890
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-5.7222e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.374407
Average KL loss: 0.331044
Average total loss: 0.705451
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.0367e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.374710
Average KL loss: 0.331029
Average total loss: 0.705739
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.1544e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.363529
Average KL loss: 0.329637
Average total loss: 0.693166
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.4083e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.373555
Average KL loss: 0.329776
Average total loss: 0.703331
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.7071e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.371041
Average KL loss: 0.331223
Average total loss: 0.702263
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-7.6447e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.370520
Average KL loss: 0.331022
Average total loss: 0.701542
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.3683e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.360652
Average KL loss: 0.330974
Average total loss: 0.691626
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.2667e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.361573
Average KL loss: 0.330765
Average total loss: 0.692338
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.3229e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.362022
Average KL loss: 0.330542
Average total loss: 0.692564
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(4.6287e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.363708
Average KL loss: 0.330922
Average total loss: 0.694630
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.6124e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.357475
Average KL loss: 0.330651
Average total loss: 0.688125
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(4.7876e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.366065
Average KL loss: 0.330480
Average total loss: 0.696545
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(4.8592e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.367647
Average KL loss: 0.332355
Average total loss: 0.700001
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(1.7803e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.355623
Average KL loss: 0.333088
Average total loss: 0.688712
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.0417e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.358457
Average KL loss: 0.332017
Average total loss: 0.690474
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.2360e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.352272
Average KL loss: 0.332516
Average total loss: 0.684788
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.9201e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.356772
Average KL loss: 0.332206
Average total loss: 0.688978
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.2144e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.354966
Average KL loss: 0.332267
Average total loss: 0.687233
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.5014e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.354220
Average KL loss: 0.332745
Average total loss: 0.686965
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.5651e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.351657
Average KL loss: 0.331990
Average total loss: 0.683648
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(5.4931e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.348955
Average KL loss: 0.331774
Average total loss: 0.680729
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.6898e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.352218
Average KL loss: 0.333040
Average total loss: 0.685258
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(1.0236e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.350193
Average KL loss: 0.331760
Average total loss: 0.681953
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.9883e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.346513
Average KL loss: 0.332913
Average total loss: 0.679425
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-9.6636e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.342498
Average KL loss: 0.331894
Average total loss: 0.674392
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(2.7690e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.344568
Average KL loss: 0.332099
Average total loss: 0.676667
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.9519e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.350618
Average KL loss: 0.332977
Average total loss: 0.683595
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.1457e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.346341
Average KL loss: 0.334115
Average total loss: 0.680456
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.7666e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.344078
Average KL loss: 0.333601
Average total loss: 0.677679
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.7288e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.342088
Average KL loss: 0.333271
Average total loss: 0.675359
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.9577e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.340266
Average KL loss: 0.333153
Average total loss: 0.673419
tensor(0.0036, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.8141e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.337694
Average KL loss: 0.333550
Average total loss: 0.671244
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(2.4959e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.345290
Average KL loss: 0.332353
Average total loss: 0.677643
tensor(0.0036, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.9380e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.341725
Average KL loss: 0.334258
Average total loss: 0.675983
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(1.8456e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.339693
Average KL loss: 0.334493
Average total loss: 0.674187
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.8670e-11, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.345545
Average KL loss: 0.333998
Average total loss: 0.679543
tensor(0.0036, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.0738e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.340846
Average KL loss: 0.334962
Average total loss: 0.675808
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.6758e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.339598
Average KL loss: 0.334734
Average total loss: 0.674332
tensor(0.0036, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(2.4225e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.341848
Average KL loss: 0.335354
Average total loss: 0.677202
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(1.4507e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.334453
Average KL loss: 0.335263
Average total loss: 0.669716
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.2140e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.335379
Average KL loss: 0.335478
Average total loss: 0.670857
tensor(0.0036, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.0916e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.330935
Average KL loss: 0.335424
Average total loss: 0.666359
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.7479e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.334729
Average KL loss: 0.334497
Average total loss: 0.669226
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(5.1204e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.331517
Average KL loss: 0.334022
Average total loss: 0.665539
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-8.2457e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.330446
Average KL loss: 0.333948
Average total loss: 0.664394
tensor(0.0036, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(4.0601e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.332428
Average KL loss: 0.334572
Average total loss: 0.667000
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(9.3597e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.332530
Average KL loss: 0.334608
Average total loss: 0.667138
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(2.7379e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.331746
Average KL loss: 0.334880
Average total loss: 0.666626
tensor(0.0036, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.1886e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.334150
Average KL loss: 0.335115
Average total loss: 0.669264
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.8476e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.327727
Average KL loss: 0.335967
Average total loss: 0.663694
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(2.1051e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.326407
Average KL loss: 0.334823
Average total loss: 0.661230
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.1891e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.331257
Average KL loss: 0.334299
Average total loss: 0.665556
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(4.3871e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.329723
Average KL loss: 0.335275
Average total loss: 0.664998
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(4.9484e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.329933
Average KL loss: 0.336068
Average total loss: 0.666001
tensor(0.0036, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.7366e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.329240
Average KL loss: 0.336709
Average total loss: 0.665949
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.5301e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.329363
Average KL loss: 0.336434
Average total loss: 0.665797
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.6324e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.330940
Average KL loss: 0.336698
Average total loss: 0.667638
tensor(0.0036, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9077e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.330090
Average KL loss: 0.336128
Average total loss: 0.666217
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(4.0787e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.324420
Average KL loss: 0.335470
Average total loss: 0.659890
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.0807e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.325760
Average KL loss: 0.334892
Average total loss: 0.660652
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(6.5881e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.329509
Average KL loss: 0.335336
Average total loss: 0.664845
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.5244e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.327806
Average KL loss: 0.336282
Average total loss: 0.664088
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.2033e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.327138
Average KL loss: 0.336734
Average total loss: 0.663872
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.0815e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.326069
Average KL loss: 0.336279
Average total loss: 0.662348
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(5.3587e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.321999
Average KL loss: 0.335771
Average total loss: 0.657770
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.5253e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.326157
Average KL loss: 0.336118
Average total loss: 0.662276
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.8186e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.322730
Average KL loss: 0.335769
Average total loss: 0.658499
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.8650e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.321153
Average KL loss: 0.335533
Average total loss: 0.656686
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.6502e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.323163
Average KL loss: 0.335894
Average total loss: 0.659057
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.6211e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.322662
Average KL loss: 0.336218
Average total loss: 0.658880
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.1534e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.327172
Average KL loss: 0.335925
Average total loss: 0.663098
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.0195e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.325384
Average KL loss: 0.336933
Average total loss: 0.662317
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(3.4906e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.321112
Average KL loss: 0.335473
Average total loss: 0.656585
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.5247e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.322780
Average KL loss: 0.336747
Average total loss: 0.659527
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.1757e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.319426
Average KL loss: 0.336813
Average total loss: 0.656239
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.6012e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.321218
Average KL loss: 0.336170
Average total loss: 0.657387
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.7579e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.322716
Average KL loss: 0.336895
Average total loss: 0.659611
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.7361e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.321813
Average KL loss: 0.336617
Average total loss: 0.658430
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.5732e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.320085
Average KL loss: 0.336588
Average total loss: 0.656673
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-9.2762e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.319563
Average KL loss: 0.336642
Average total loss: 0.656205
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(4.6047e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.321738
Average KL loss: 0.336882
Average total loss: 0.658620
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(4.7279e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.320061
Average KL loss: 0.337424
Average total loss: 0.657485
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-9.1422e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.319930
Average KL loss: 0.337651
Average total loss: 0.657581
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.2116e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.320458
Average KL loss: 0.337202
Average total loss: 0.657659
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.0603e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.317355
Average KL loss: 0.337362
Average total loss: 0.654716
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.4815e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.315817
Average KL loss: 0.336481
Average total loss: 0.652297
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.0139e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.315601
Average KL loss: 0.336880
Average total loss: 0.652480
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.3888e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.317276
Average KL loss: 0.336683
Average total loss: 0.653959
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.2809e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.317987
Average KL loss: 0.336696
Average total loss: 0.654683
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.4237e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.319615
Average KL loss: 0.337892
Average total loss: 0.657506
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.7624e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.318750
Average KL loss: 0.337191
Average total loss: 0.655941
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(6.1505e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.310408
Average KL loss: 0.337499
Average total loss: 0.647907
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.2967e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.320334
Average KL loss: 0.336922
Average total loss: 0.657256
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.5612e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.315763
Average KL loss: 0.337759
Average total loss: 0.653522
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.7561e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.316754
Average KL loss: 0.337180
Average total loss: 0.653934
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.2466e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.316577
Average KL loss: 0.337147
Average total loss: 0.653724
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(3.8393e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.312404
Average KL loss: 0.337443
Average total loss: 0.649847
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.8868e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.314948
Average KL loss: 0.336929
Average total loss: 0.651878
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.1658e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.316703
Average KL loss: 0.336816
Average total loss: 0.653520
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.6697e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.319925
Average KL loss: 0.337795
Average total loss: 0.657720
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.2677e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.314709
Average KL loss: 0.337541
Average total loss: 0.652250
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.0461e-11, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.314415
Average KL loss: 0.337880
Average total loss: 0.652295
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.7654e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.314315
Average KL loss: 0.337308
Average total loss: 0.651623
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.8064e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.314126
Average KL loss: 0.333623
Average total loss: 0.647749
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(5.8226e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.312363
Average KL loss: 0.327942
Average total loss: 0.640306
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.8787e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.315878
Average KL loss: 0.324663
Average total loss: 0.640540
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.6799e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.312575
Average KL loss: 0.322359
Average total loss: 0.634934
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(4.0409e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.313695
Average KL loss: 0.320747
Average total loss: 0.634442
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.0707e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.309449
Average KL loss: 0.319319
Average total loss: 0.628767
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.2303e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.310263
Average KL loss: 0.318024
Average total loss: 0.628287
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.3387e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.310392
Average KL loss: 0.317043
Average total loss: 0.627435
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.9491e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.310982
Average KL loss: 0.316160
Average total loss: 0.627142
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.2564e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.309960
Average KL loss: 0.315441
Average total loss: 0.625401
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.4360e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.315507
Average KL loss: 0.314856
Average total loss: 0.630363
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-7.6067e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.310534
Average KL loss: 0.314418
Average total loss: 0.624951
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(8.5744e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.312664
Average KL loss: 0.314037
Average total loss: 0.626701
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.4783e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.308570
Average KL loss: 0.313648
Average total loss: 0.622218
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.2163e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.309501
Average KL loss: 0.313247
Average total loss: 0.622748
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.3668e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.312780
Average KL loss: 0.312899
Average total loss: 0.625679
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.2414e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.311341
Average KL loss: 0.312682
Average total loss: 0.624022
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.0031e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.312284
Average KL loss: 0.312456
Average total loss: 0.624740
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.6086e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.312475
Average KL loss: 0.312203
Average total loss: 0.624678
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.7287e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.308129
Average KL loss: 0.311930
Average total loss: 0.620059
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.8315e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.313613
Average KL loss: 0.311664
Average total loss: 0.625277
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.0395e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.314341
Average KL loss: 0.311425
Average total loss: 0.625767
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(3.5500e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.310522
Average KL loss: 0.311268
Average total loss: 0.621790
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.7742e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.315992
Average KL loss: 0.311045
Average total loss: 0.627037
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(3.0297e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.315080
Average KL loss: 0.310980
Average total loss: 0.626061
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.4157e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.309974
Average KL loss: 0.310921
Average total loss: 0.620895
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.0054e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.309124
Average KL loss: 0.310790
Average total loss: 0.619914
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.6355e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.311111
Average KL loss: 0.310645
Average total loss: 0.621756
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.7382e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.312040
Average KL loss: 0.310577
Average total loss: 0.622617
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(6.3788e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.312757
Average KL loss: 0.310426
Average total loss: 0.623183
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.2749e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.314010
Average KL loss: 0.310299
Average total loss: 0.624308
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.6166e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.313128
Average KL loss: 0.310263
Average total loss: 0.623391
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.6942e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.310925
Average KL loss: 0.310229
Average total loss: 0.621153
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.4975e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.313997
Average KL loss: 0.310177
Average total loss: 0.624174
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(9.2473e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.313956
Average KL loss: 0.310213
Average total loss: 0.624169
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-7.6914e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.312120
Average KL loss: 0.310300
Average total loss: 0.622420
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.1920e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.313756
Average KL loss: 0.310218
Average total loss: 0.623974
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.6141e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.310857
Average KL loss: 0.310041
Average total loss: 0.620898
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.3392e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.310830
Average KL loss: 0.309917
Average total loss: 0.620747
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.0653e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.308533
Average KL loss: 0.309771
Average total loss: 0.618304
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.7139e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.309270
Average KL loss: 0.309654
Average total loss: 0.618924
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(5.6039e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.313813
Average KL loss: 0.309550
Average total loss: 0.623363
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.3966e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.310327
Average KL loss: 0.309456
Average total loss: 0.619783
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.1675e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.309083
Average KL loss: 0.309362
Average total loss: 0.618444
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.8651e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.312834
Average KL loss: 0.309281
Average total loss: 0.622115
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.2780e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.310382
Average KL loss: 0.309204
Average total loss: 0.619586
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.0314e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.313426
Average KL loss: 0.309134
Average total loss: 0.622560
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.8317e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.312771
Average KL loss: 0.309081
Average total loss: 0.621851
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.4088e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.310266
Average KL loss: 0.309039
Average total loss: 0.619305
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(6.3862e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.312196
Average KL loss: 0.308983
Average total loss: 0.621179
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.1155e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.311078
Average KL loss: 0.308934
Average total loss: 0.620012
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-9.0931e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.312965
Average KL loss: 0.308903
Average total loss: 0.621868
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.1634e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.312397
Average KL loss: 0.308897
Average total loss: 0.621293
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.1522e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.314410
Average KL loss: 0.308891
Average total loss: 0.623300
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.3381e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.309239
Average KL loss: 0.308884
Average total loss: 0.618124
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.8527e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.311048
Average KL loss: 0.308878
Average total loss: 0.619926
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.6066e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.311273
Average KL loss: 0.308871
Average total loss: 0.620143
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.8175e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.309270
Average KL loss: 0.308863
Average total loss: 0.618133
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.0154e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.311934
Average KL loss: 0.308856
Average total loss: 0.620789
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.3988e-11, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.308444
Average KL loss: 0.308850
Average total loss: 0.617293
 Percentile value: 8.015941261874105e-08
Non-zero model percentage: 64.0%, Non-zero mask percentage: 64.0%

--- Pruning Level [2/24]: ---
conv1.weight         | nonzeros =    1565 /    1728             ( 90.57%) | total_pruned =     163 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   32468 /   36864             ( 88.08%) | total_pruned =    4396 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   27055 /   36864             ( 73.39%) | total_pruned =    9809 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   23123 /   36864             ( 62.73%) | total_pruned =   13741 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   23193 /   36864             ( 62.92%) | total_pruned =   13671 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   31867 /   73728             ( 43.22%) | total_pruned =   41861 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   60566 /  147456             ( 41.07%) | total_pruned =   86890 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4183 /    8192             ( 51.06%) | total_pruned =    4009 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   77102 /  147456             ( 52.29%) | total_pruned =   70354 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   87786 /  147456             ( 59.53%) | total_pruned =   59670 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  111713 /  294912             ( 37.88%) | total_pruned =  183199 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      90 /     256             ( 35.16%) | total_pruned =     166 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  231861 /  589824             ( 39.31%) | total_pruned =  357963 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   15042 /   32768             ( 45.90%) | total_pruned =   17726 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     238 /     256             ( 92.97%) | total_pruned =      18 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      52 /     256             ( 20.31%) | total_pruned =     204 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  265752 /  589824             ( 45.06%) | total_pruned =  324072 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  325164 /  589824             ( 55.13%) | total_pruned =  264660 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  491386 / 1179648             ( 41.66%) | total_pruned =  688262 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     100 /     512             ( 19.53%) | total_pruned =     412 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1421879 / 2359296             ( 60.27%) | total_pruned =  937417 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     469 /     512             ( 91.60%) | total_pruned =      43 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     138 /     512             ( 26.95%) | total_pruned =     374 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   87928 /  131072             ( 67.08%) | total_pruned =   43144 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     471 /     512             ( 91.99%) | total_pruned =      41 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     142 /     512             ( 27.73%) | total_pruned =     370 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1621371 / 2359296             ( 68.72%) | total_pruned =  737925 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2197353 / 2359296             ( 93.14%) | total_pruned =  161943 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5082 /    5120             ( 99.26%) | total_pruned =      38 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 7154408, pruned : 4024354, total: 11178762, Compression rate :       1.56x  ( 36.00% pruned)
Train Epoch: 57/100 Loss: 0.015541 Accuracy: 88.53 100.00 % Best test Accuracy: 88.74%
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.3174e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.817340
Average KL loss: 0.314684
Average total loss: 1.132024
tensor(0.0036, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.3647e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.634664
Average KL loss: 0.336335
Average total loss: 0.970999
tensor(0.0036, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.5865e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.572399
Average KL loss: 0.339704
Average total loss: 0.912103
tensor(0.0036, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.8211e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.548934
Average KL loss: 0.339808
Average total loss: 0.888742
tensor(0.0036, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.7856e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.514576
Average KL loss: 0.338682
Average total loss: 0.853258
tensor(0.0036, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.0796e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.496711
Average KL loss: 0.336834
Average total loss: 0.833545
tensor(0.0036, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.6859e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.487578
Average KL loss: 0.334828
Average total loss: 0.822406
tensor(0.0036, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.7336e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.469601
Average KL loss: 0.334341
Average total loss: 0.803942
tensor(0.0036, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-2.2854e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.462719
Average KL loss: 0.335124
Average total loss: 0.797843
tensor(0.0036, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-8.3663e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.455008
Average KL loss: 0.335437
Average total loss: 0.790445
tensor(0.0036, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-5.8633e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.443444
Average KL loss: 0.334189
Average total loss: 0.777633
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-8.7910e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.440187
Average KL loss: 0.335009
Average total loss: 0.775195
tensor(0.0035, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.1940e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.432329
Average KL loss: 0.335367
Average total loss: 0.767696
tensor(0.0036, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.3941e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.422980
Average KL loss: 0.335170
Average total loss: 0.758149
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.0658e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.417033
Average KL loss: 0.334193
Average total loss: 0.751226
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.6565e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.421003
Average KL loss: 0.335095
Average total loss: 0.756098
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.0660e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.407790
Average KL loss: 0.334663
Average total loss: 0.742453
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.4112e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.407532
Average KL loss: 0.334600
Average total loss: 0.742133
tensor(0.0035, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.9321e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.405535
Average KL loss: 0.334245
Average total loss: 0.739780
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0102e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.397796
Average KL loss: 0.334456
Average total loss: 0.732252
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.6827e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.393943
Average KL loss: 0.333568
Average total loss: 0.727511
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.2392e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.391256
Average KL loss: 0.333520
Average total loss: 0.724776
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.4269e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.389513
Average KL loss: 0.333795
Average total loss: 0.723309
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0290e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.393343
Average KL loss: 0.333886
Average total loss: 0.727229
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.1627e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.388240
Average KL loss: 0.334986
Average total loss: 0.723226
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.4899e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.385543
Average KL loss: 0.333936
Average total loss: 0.719479
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.7372e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.386342
Average KL loss: 0.334825
Average total loss: 0.721168
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.0335e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.378889
Average KL loss: 0.334454
Average total loss: 0.713343
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(3.8323e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.380380
Average KL loss: 0.334945
Average total loss: 0.715325
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.9939e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.377315
Average KL loss: 0.334640
Average total loss: 0.711955
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.1984e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.373305
Average KL loss: 0.334133
Average total loss: 0.707437
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(2.1240e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.375210
Average KL loss: 0.334862
Average total loss: 0.710072
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.7437e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.376141
Average KL loss: 0.335336
Average total loss: 0.711477
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.3046e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.371784
Average KL loss: 0.334863
Average total loss: 0.706647
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.7696e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.366959
Average KL loss: 0.335078
Average total loss: 0.702037
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.0116e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.365545
Average KL loss: 0.334458
Average total loss: 0.700002
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.5871e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.365497
Average KL loss: 0.334695
Average total loss: 0.700192
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.5736e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.364834
Average KL loss: 0.334722
Average total loss: 0.699556
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.2823e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.362899
Average KL loss: 0.334820
Average total loss: 0.697718
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.2510e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.356320
Average KL loss: 0.335064
Average total loss: 0.691384
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.5939e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.358781
Average KL loss: 0.334155
Average total loss: 0.692936
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(9.9530e-10, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.356055
Average KL loss: 0.333266
Average total loss: 0.689321
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.9952e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.359736
Average KL loss: 0.334043
Average total loss: 0.693779
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-4.8517e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.357591
Average KL loss: 0.335189
Average total loss: 0.692779
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.9923e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.356696
Average KL loss: 0.335128
Average total loss: 0.691824
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.8706e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.352186
Average KL loss: 0.335225
Average total loss: 0.687411
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.1627e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.355288
Average KL loss: 0.334614
Average total loss: 0.689902
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.6165e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.357792
Average KL loss: 0.335583
Average total loss: 0.693375
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(5.2745e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.352587
Average KL loss: 0.335162
Average total loss: 0.687748
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(1.0002e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.352443
Average KL loss: 0.335421
Average total loss: 0.687863
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.3384e-11, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.350915
Average KL loss: 0.336180
Average total loss: 0.687095
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.6669e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.346852
Average KL loss: 0.335359
Average total loss: 0.682211
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.6419e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.354157
Average KL loss: 0.335179
Average total loss: 0.689336
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.4916e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.345098
Average KL loss: 0.336155
Average total loss: 0.681253
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(1.4551e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.345863
Average KL loss: 0.335376
Average total loss: 0.681239
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.6761e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.347329
Average KL loss: 0.334685
Average total loss: 0.682014
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(4.1441e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.347859
Average KL loss: 0.334504
Average total loss: 0.682364
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.9331e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.349589
Average KL loss: 0.335069
Average total loss: 0.684657
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-8.7767e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.345337
Average KL loss: 0.334887
Average total loss: 0.680224
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.7031e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.346908
Average KL loss: 0.335088
Average total loss: 0.681996
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.9738e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.346209
Average KL loss: 0.335625
Average total loss: 0.681833
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.2404e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.342118
Average KL loss: 0.335561
Average total loss: 0.677679
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.2432e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.345505
Average KL loss: 0.335375
Average total loss: 0.680880
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.6612e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.343214
Average KL loss: 0.335497
Average total loss: 0.678711
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.1722e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.344039
Average KL loss: 0.335834
Average total loss: 0.679873
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(7.1381e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.341781
Average KL loss: 0.335411
Average total loss: 0.677191
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.0989e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.348863
Average KL loss: 0.336693
Average total loss: 0.685556
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(6.2602e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.339582
Average KL loss: 0.335735
Average total loss: 0.675318
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.4712e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.340293
Average KL loss: 0.335935
Average total loss: 0.676228
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.4466e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.337804
Average KL loss: 0.336362
Average total loss: 0.674166
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.3371e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.340801
Average KL loss: 0.336411
Average total loss: 0.677212
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(1.4851e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.341475
Average KL loss: 0.336591
Average total loss: 0.678066
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.9761e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.340181
Average KL loss: 0.336665
Average total loss: 0.676846
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(4.0392e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.337724
Average KL loss: 0.335204
Average total loss: 0.672928
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.8976e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.339459
Average KL loss: 0.336894
Average total loss: 0.676352
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.2393e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.339542
Average KL loss: 0.336626
Average total loss: 0.676168
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.5947e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.339549
Average KL loss: 0.336628
Average total loss: 0.676178
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.1505e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.336795
Average KL loss: 0.336528
Average total loss: 0.673323
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.6899e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.341784
Average KL loss: 0.336197
Average total loss: 0.677981
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.1763e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.336141
Average KL loss: 0.337325
Average total loss: 0.673466
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.0142e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.340263
Average KL loss: 0.336867
Average total loss: 0.677129
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.8502e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.335649
Average KL loss: 0.337085
Average total loss: 0.672734
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.8279e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.335513
Average KL loss: 0.336577
Average total loss: 0.672090
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.8146e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.333990
Average KL loss: 0.336515
Average total loss: 0.670505
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.4994e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.337401
Average KL loss: 0.336797
Average total loss: 0.674198
tensor(0.0036, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(2.8655e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.334166
Average KL loss: 0.336883
Average total loss: 0.671049
tensor(0.0035, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.7753e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.337877
Average KL loss: 0.337531
Average total loss: 0.675408
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.8513e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.329455
Average KL loss: 0.337087
Average total loss: 0.666542
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(3.7791e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.334971
Average KL loss: 0.336102
Average total loss: 0.671073
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.3104e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.340417
Average KL loss: 0.336615
Average total loss: 0.677033
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.3118e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.334619
Average KL loss: 0.336967
Average total loss: 0.671586
tensor(0.0035, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.2592e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.333783
Average KL loss: 0.336787
Average total loss: 0.670570
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.3424e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.328136
Average KL loss: 0.337087
Average total loss: 0.665224
tensor(0.0036, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.4643e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.332050
Average KL loss: 0.336422
Average total loss: 0.668472
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.8407e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.330000
Average KL loss: 0.336560
Average total loss: 0.666560
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.4578e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.329968
Average KL loss: 0.336241
Average total loss: 0.666209
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.8472e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.335157
Average KL loss: 0.337155
Average total loss: 0.672312
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.4718e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.332437
Average KL loss: 0.336995
Average total loss: 0.669432
tensor(0.0036, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.8119e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.335173
Average KL loss: 0.337593
Average total loss: 0.672766
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.5655e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.336814
Average KL loss: 0.337847
Average total loss: 0.674662
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.1657e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.334505
Average KL loss: 0.338502
Average total loss: 0.673007
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.7278e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.330296
Average KL loss: 0.338105
Average total loss: 0.668400
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.7501e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.327813
Average KL loss: 0.337115
Average total loss: 0.664928
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.0747e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.332548
Average KL loss: 0.337088
Average total loss: 0.669636
tensor(0.0036, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.9016e-11, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.329583
Average KL loss: 0.337499
Average total loss: 0.667082
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.1379e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.330889
Average KL loss: 0.337951
Average total loss: 0.668840
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.9391e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.331699
Average KL loss: 0.337777
Average total loss: 0.669477
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.9072e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.326377
Average KL loss: 0.337731
Average total loss: 0.664108
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.2260e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.332356
Average KL loss: 0.337934
Average total loss: 0.670291
tensor(0.0036, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.0159e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.330171
Average KL loss: 0.338501
Average total loss: 0.668672
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.0022e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.329720
Average KL loss: 0.338615
Average total loss: 0.668334
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.0552e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.327139
Average KL loss: 0.337797
Average total loss: 0.664936
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.5601e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.326935
Average KL loss: 0.337333
Average total loss: 0.664268
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.0972e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.323867
Average KL loss: 0.337263
Average total loss: 0.661130
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.5575e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.328701
Average KL loss: 0.337852
Average total loss: 0.666553
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.5990e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.327274
Average KL loss: 0.337969
Average total loss: 0.665244
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.7560e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.325096
Average KL loss: 0.337972
Average total loss: 0.663068
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.2673e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.329843
Average KL loss: 0.338349
Average total loss: 0.668192
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.7266e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.328699
Average KL loss: 0.338141
Average total loss: 0.666840
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-9.7718e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.328900
Average KL loss: 0.337591
Average total loss: 0.666491
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.9418e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.327538
Average KL loss: 0.338028
Average total loss: 0.665565
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.7023e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.329530
Average KL loss: 0.338045
Average total loss: 0.667574
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.5850e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.329405
Average KL loss: 0.337590
Average total loss: 0.666996
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.8237e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.326397
Average KL loss: 0.337508
Average total loss: 0.663904
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.2438e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.322558
Average KL loss: 0.337649
Average total loss: 0.660207
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.9862e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.326705
Average KL loss: 0.337546
Average total loss: 0.664251
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.3100e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.326300
Average KL loss: 0.338050
Average total loss: 0.664350
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.8299e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.328283
Average KL loss: 0.337829
Average total loss: 0.666112
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.6306e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.327593
Average KL loss: 0.338207
Average total loss: 0.665800
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.0217e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.330627
Average KL loss: 0.338083
Average total loss: 0.668709
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.3357e-11, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.327774
Average KL loss: 0.338406
Average total loss: 0.666181
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.0859e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.327262
Average KL loss: 0.337651
Average total loss: 0.664913
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.4579e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.322850
Average KL loss: 0.337554
Average total loss: 0.660403
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.8127e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.328161
Average KL loss: 0.338050
Average total loss: 0.666211
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.1672e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.328141
Average KL loss: 0.338418
Average total loss: 0.666559
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.4712e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.326871
Average KL loss: 0.338996
Average total loss: 0.665867
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.9182e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.325314
Average KL loss: 0.336452
Average total loss: 0.661766
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.3584e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.326648
Average KL loss: 0.332004
Average total loss: 0.658652
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.7065e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.319553
Average KL loss: 0.329146
Average total loss: 0.648699
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.1069e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.322557
Average KL loss: 0.326950
Average total loss: 0.649506
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(8.9381e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.324520
Average KL loss: 0.325230
Average total loss: 0.649750
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-7.5378e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.321873
Average KL loss: 0.323902
Average total loss: 0.645775
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.4768e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.325220
Average KL loss: 0.322652
Average total loss: 0.647872
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-8.0050e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.322645
Average KL loss: 0.321584
Average total loss: 0.644230
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.7816e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.323207
Average KL loss: 0.320749
Average total loss: 0.643956
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(5.5096e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.325023
Average KL loss: 0.320055
Average total loss: 0.645079
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.8202e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.326046
Average KL loss: 0.319468
Average total loss: 0.645514
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.6863e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.321251
Average KL loss: 0.318857
Average total loss: 0.640108
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(4.1099e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.326820
Average KL loss: 0.318241
Average total loss: 0.645060
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.6357e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.322190
Average KL loss: 0.317819
Average total loss: 0.640009
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-9.6868e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.323449
Average KL loss: 0.317318
Average total loss: 0.640767
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.1705e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.322748
Average KL loss: 0.316955
Average total loss: 0.639702
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.7106e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.328414
Average KL loss: 0.316606
Average total loss: 0.645020
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-8.6593e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.325633
Average KL loss: 0.316444
Average total loss: 0.642076
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.5761e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.324550
Average KL loss: 0.316124
Average total loss: 0.640674
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.9502e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.321941
Average KL loss: 0.315767
Average total loss: 0.637708
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.9158e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.326105
Average KL loss: 0.315547
Average total loss: 0.641652
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.0215e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.324017
Average KL loss: 0.315245
Average total loss: 0.639261
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.6606e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.326728
Average KL loss: 0.315041
Average total loss: 0.641769
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.0996e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.322320
Average KL loss: 0.314829
Average total loss: 0.637148
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.4417e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.317856
Average KL loss: 0.314702
Average total loss: 0.632558
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.1496e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.324491
Average KL loss: 0.314441
Average total loss: 0.638932
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.5299e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.322426
Average KL loss: 0.314310
Average total loss: 0.636736
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.8201e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.322749
Average KL loss: 0.314131
Average total loss: 0.636880
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.4726e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.324994
Average KL loss: 0.314025
Average total loss: 0.639020
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.1846e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.320306
Average KL loss: 0.313878
Average total loss: 0.634184
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.5294e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.321632
Average KL loss: 0.313742
Average total loss: 0.635373
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.6986e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.322621
Average KL loss: 0.313558
Average total loss: 0.636179
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.1255e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.320098
Average KL loss: 0.313513
Average total loss: 0.633611
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(7.2725e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.324428
Average KL loss: 0.313444
Average total loss: 0.637872
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.3742e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.325493
Average KL loss: 0.313321
Average total loss: 0.638814
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.3016e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.324357
Average KL loss: 0.313260
Average total loss: 0.637617
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.4979e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.321520
Average KL loss: 0.313260
Average total loss: 0.634780
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.2487e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.324795
Average KL loss: 0.313160
Average total loss: 0.637955
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.2135e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.324719
Average KL loss: 0.313072
Average total loss: 0.637791
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.1664e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.324684
Average KL loss: 0.312998
Average total loss: 0.637681
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.5755e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.321629
Average KL loss: 0.312927
Average total loss: 0.634556
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.8442e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.326225
Average KL loss: 0.312862
Average total loss: 0.639088
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.4869e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.323237
Average KL loss: 0.312799
Average total loss: 0.636036
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.3728e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.322028
Average KL loss: 0.312737
Average total loss: 0.634765
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.2078e-11, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.328059
Average KL loss: 0.312686
Average total loss: 0.640744
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(8.6063e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.321741
Average KL loss: 0.312629
Average total loss: 0.634370
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.5904e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.319908
Average KL loss: 0.312576
Average total loss: 0.632484
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(8.8201e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.323684
Average KL loss: 0.312520
Average total loss: 0.636204
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.7018e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.322437
Average KL loss: 0.312472
Average total loss: 0.634909
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.7787e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.319945
Average KL loss: 0.312417
Average total loss: 0.632362
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.4111e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.323225
Average KL loss: 0.312376
Average total loss: 0.635601
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.0014e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.321818
Average KL loss: 0.312334
Average total loss: 0.634153
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.4337e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.321485
Average KL loss: 0.312294
Average total loss: 0.633778
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.2578e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.321596
Average KL loss: 0.312247
Average total loss: 0.633843
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.3421e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.326450
Average KL loss: 0.312202
Average total loss: 0.638653
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.3246e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.323869
Average KL loss: 0.312169
Average total loss: 0.636038
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.5213e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.320095
Average KL loss: 0.312130
Average total loss: 0.632225
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-4.2958e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.321305
Average KL loss: 0.312086
Average total loss: 0.633391
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.5867e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.322596
Average KL loss: 0.312060
Average total loss: 0.634656
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.3218e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.324928
Average KL loss: 0.312028
Average total loss: 0.636956
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.4684e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.319748
Average KL loss: 0.311989
Average total loss: 0.631737
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(4.2207e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.325968
Average KL loss: 0.311950
Average total loss: 0.637918
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(2.0007e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.326290
Average KL loss: 0.311922
Average total loss: 0.638212
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(3.8062e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.322202
Average KL loss: 0.311903
Average total loss: 0.634105
 Percentile value: 5.600681163286936e-08
Non-zero model percentage: 51.200008392333984%, Non-zero mask percentage: 51.200008392333984%

--- Pruning Level [3/24]: ---
conv1.weight         | nonzeros =    1516 /    1728             ( 87.73%) | total_pruned =     212 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   31957 /   36864             ( 86.69%) | total_pruned =    4907 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   25473 /   36864             ( 69.10%) | total_pruned =   11391 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   21497 /   36864             ( 58.31%) | total_pruned =   15367 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   20635 /   36864             ( 55.98%) | total_pruned =   16229 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   23842 /   73728             ( 32.34%) | total_pruned =   49886 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   44915 /  147456             ( 30.46%) | total_pruned =  102541 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3407 /    8192             ( 41.59%) | total_pruned =    4785 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   60546 /  147456             ( 41.06%) | total_pruned =   86910 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   70595 /  147456             ( 47.88%) | total_pruned =   76861 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   79433 /  294912             ( 26.93%) | total_pruned =  215479 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  165795 /  589824             ( 28.11%) | total_pruned =  424029 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      45 /     256             ( 17.58%) | total_pruned =     211 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   11453 /   32768             ( 34.95%) | total_pruned =   21315 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     233 /     256             ( 91.02%) | total_pruned =      23 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      51 /     256             ( 19.92%) | total_pruned =     205 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  183873 /  589824             ( 31.17%) | total_pruned =  405951 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  223877 /  589824             ( 37.96%) | total_pruned =  365947 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  325737 / 1179648             ( 27.61%) | total_pruned =  853911 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      92 /     512             ( 17.97%) | total_pruned =     420 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  964245 / 2359296             ( 40.87%) | total_pruned = 1395051 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     434 /     512             ( 84.77%) | total_pruned =      78 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     112 /     512             ( 21.88%) | total_pruned =     400 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   60975 /  131072             ( 46.52%) | total_pruned =   70097 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     429 /     512             ( 83.79%) | total_pruned =      83 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1380279 / 2359296             ( 58.50%) | total_pruned =  979017 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2007750 / 2359296             ( 85.10%) | total_pruned =  351546 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     506 /     512             ( 98.83%) | total_pruned =       6 | shape = torch.Size([512])
linear.weight        | nonzeros =    5014 /    5120             ( 97.93%) | total_pruned =     106 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 5723527, pruned : 5455235, total: 11178762, Compression rate :       1.95x  ( 48.80% pruned)
Train Epoch: 48/100 Loss: 0.015917 Accuracy: 88.05 100.00 % Best test Accuracy: 88.39%
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-8.8542e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.626570
Average KL loss: 0.317071
Average total loss: 0.943641
tensor(0.0038, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.3818e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.514524
Average KL loss: 0.341816
Average total loss: 0.856339
tensor(0.0038, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.2481e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.485626
Average KL loss: 0.350048
Average total loss: 0.835674
tensor(0.0038, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.6581e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.465048
Average KL loss: 0.353764
Average total loss: 0.818812
tensor(0.0038, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.1989e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.460004
Average KL loss: 0.356041
Average total loss: 0.816046
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.1891e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.448617
Average KL loss: 0.357755
Average total loss: 0.806372
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.0886e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.445083
Average KL loss: 0.358576
Average total loss: 0.803658
tensor(0.0037, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.2633e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.432394
Average KL loss: 0.360214
Average total loss: 0.792608
tensor(0.0037, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.5636e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.439573
Average KL loss: 0.361446
Average total loss: 0.801019
tensor(0.0037, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.3621e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.432262
Average KL loss: 0.361985
Average total loss: 0.794246
tensor(0.0037, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.0186e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.422907
Average KL loss: 0.362769
Average total loss: 0.785675
tensor(0.0037, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(4.0919e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.417266
Average KL loss: 0.363420
Average total loss: 0.780686
tensor(0.0037, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.4005e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.417230
Average KL loss: 0.364166
Average total loss: 0.781396
tensor(0.0037, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.5083e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.412551
Average KL loss: 0.364597
Average total loss: 0.777148
tensor(0.0037, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.0002e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.407743
Average KL loss: 0.363889
Average total loss: 0.771632
tensor(0.0037, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.0218e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.415822
Average KL loss: 0.364963
Average total loss: 0.780785
tensor(0.0037, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(3.0222e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.407926
Average KL loss: 0.366243
Average total loss: 0.774169
tensor(0.0037, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-9.1892e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.403892
Average KL loss: 0.365410
Average total loss: 0.769302
tensor(0.0037, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(2.1755e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.403206
Average KL loss: 0.365713
Average total loss: 0.768919
tensor(0.0037, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-7.3390e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.408558
Average KL loss: 0.365669
Average total loss: 0.774227
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.3852e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.400452
Average KL loss: 0.367342
Average total loss: 0.767793
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.5234e-11, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.399018
Average KL loss: 0.367537
Average total loss: 0.766555
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-8.8141e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.403489
Average KL loss: 0.367019
Average total loss: 0.770508
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(2.7176e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.398490
Average KL loss: 0.367145
Average total loss: 0.765635
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.6534e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.399888
Average KL loss: 0.367693
Average total loss: 0.767581
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.0283e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.397513
Average KL loss: 0.367770
Average total loss: 0.765283
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-3.0046e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.396958
Average KL loss: 0.368243
Average total loss: 0.765201
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.5658e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.395860
Average KL loss: 0.368248
Average total loss: 0.764108
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-9.3837e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.389794
Average KL loss: 0.367730
Average total loss: 0.757524
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(9.9658e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.393878
Average KL loss: 0.367144
Average total loss: 0.761022
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.8947e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.394708
Average KL loss: 0.368278
Average total loss: 0.762985
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-6.0846e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.394091
Average KL loss: 0.368115
Average total loss: 0.762205
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(7.7727e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.392760
Average KL loss: 0.369335
Average total loss: 0.762095
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.9891e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.390566
Average KL loss: 0.368529
Average total loss: 0.759094
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.2742e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.392695
Average KL loss: 0.368747
Average total loss: 0.761442
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.2341e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.392240
Average KL loss: 0.368985
Average total loss: 0.761226
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(4.8193e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.383642
Average KL loss: 0.368888
Average total loss: 0.752530
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.0142e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.383163
Average KL loss: 0.368603
Average total loss: 0.751766
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.7491e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.387862
Average KL loss: 0.368288
Average total loss: 0.756150
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.2818e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.386166
Average KL loss: 0.368963
Average total loss: 0.755129
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-7.5796e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.382332
Average KL loss: 0.368185
Average total loss: 0.750517
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.4817e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.393507
Average KL loss: 0.368443
Average total loss: 0.761950
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.2808e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.389347
Average KL loss: 0.369092
Average total loss: 0.758439
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(2.9803e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.383055
Average KL loss: 0.368531
Average total loss: 0.751586
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.6872e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.387739
Average KL loss: 0.368123
Average total loss: 0.755861
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.0983e-10, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.385629
Average KL loss: 0.368536
Average total loss: 0.754165
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.8765e-10, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.386669
Average KL loss: 0.369515
Average total loss: 0.756184
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.9099e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.385931
Average KL loss: 0.369937
Average total loss: 0.755869
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.2776e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.383867
Average KL loss: 0.369034
Average total loss: 0.752901
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.7449e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.378778
Average KL loss: 0.369252
Average total loss: 0.748030
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.2151e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.382894
Average KL loss: 0.368949
Average total loss: 0.751843
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-8.4245e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.381774
Average KL loss: 0.369151
Average total loss: 0.750925
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.9727e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.375908
Average KL loss: 0.369447
Average total loss: 0.745355
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.5719e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.377189
Average KL loss: 0.369115
Average total loss: 0.746304
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.1852e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.379203
Average KL loss: 0.369238
Average total loss: 0.748442
tensor(0.0038, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.5069e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.381201
Average KL loss: 0.369739
Average total loss: 0.750940
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.8888e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.377864
Average KL loss: 0.369081
Average total loss: 0.746945
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(8.4392e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.383480
Average KL loss: 0.369660
Average total loss: 0.753140
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.9229e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.377768
Average KL loss: 0.369342
Average total loss: 0.747110
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.7224e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.380701
Average KL loss: 0.369644
Average total loss: 0.750345
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.2816e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.381515
Average KL loss: 0.369568
Average total loss: 0.751083
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.0318e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.379186
Average KL loss: 0.369480
Average total loss: 0.748666
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.2804e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.377003
Average KL loss: 0.369185
Average total loss: 0.746188
tensor(0.0038, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.7035e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.378066
Average KL loss: 0.368721
Average total loss: 0.746788
tensor(0.0038, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.5157e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.375924
Average KL loss: 0.367249
Average total loss: 0.743173
tensor(0.0038, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.5000e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.379800
Average KL loss: 0.364168
Average total loss: 0.743968
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.2984e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.379243
Average KL loss: 0.362016
Average total loss: 0.741259
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.5284e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.376710
Average KL loss: 0.360296
Average total loss: 0.737005
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.9848e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.373869
Average KL loss: 0.358771
Average total loss: 0.732640
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.6624e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.371239
Average KL loss: 0.357588
Average total loss: 0.728827
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(8.5782e-11, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.376579
Average KL loss: 0.356548
Average total loss: 0.733127
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.8449e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.376469
Average KL loss: 0.355689
Average total loss: 0.732158
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.4678e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.375143
Average KL loss: 0.354997
Average total loss: 0.730140
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.9130e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.375905
Average KL loss: 0.354463
Average total loss: 0.730367
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.0636e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.376194
Average KL loss: 0.353815
Average total loss: 0.730009
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.0169e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.380494
Average KL loss: 0.353246
Average total loss: 0.733741
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.7860e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.376466
Average KL loss: 0.352728
Average total loss: 0.729194
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.4846e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.377460
Average KL loss: 0.352278
Average total loss: 0.729738
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.2159e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.372341
Average KL loss: 0.351880
Average total loss: 0.724222
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.8941e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.381202
Average KL loss: 0.351387
Average total loss: 0.732588
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.9341e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.379886
Average KL loss: 0.351052
Average total loss: 0.730939
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.0716e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.376516
Average KL loss: 0.350765
Average total loss: 0.727281
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-6.0637e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.377705
Average KL loss: 0.350514
Average total loss: 0.728219
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.3695e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.377039
Average KL loss: 0.350295
Average total loss: 0.727334
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.4241e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.380229
Average KL loss: 0.350109
Average total loss: 0.730338
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.0105e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.375912
Average KL loss: 0.349878
Average total loss: 0.725790
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.8598e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.372647
Average KL loss: 0.349523
Average total loss: 0.722169
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.4093e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.384607
Average KL loss: 0.349251
Average total loss: 0.733858
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.1157e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.377532
Average KL loss: 0.349101
Average total loss: 0.726632
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.4069e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.378198
Average KL loss: 0.349025
Average total loss: 0.727223
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.9383e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.373017
Average KL loss: 0.348769
Average total loss: 0.721786
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-8.6120e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.378686
Average KL loss: 0.348527
Average total loss: 0.727213
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.6786e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.373680
Average KL loss: 0.348296
Average total loss: 0.721976
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-8.6126e-11, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.373673
Average KL loss: 0.348078
Average total loss: 0.721750
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.1043e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.377192
Average KL loss: 0.347858
Average total loss: 0.725050
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.3619e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.375318
Average KL loss: 0.347823
Average total loss: 0.723141
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(4.0524e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.379278
Average KL loss: 0.347732
Average total loss: 0.727010
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.3819e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.375528
Average KL loss: 0.347610
Average total loss: 0.723138
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(4.4649e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.376884
Average KL loss: 0.347514
Average total loss: 0.724398
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.7504e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.373319
Average KL loss: 0.347266
Average total loss: 0.720585
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-6.5799e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.376983
Average KL loss: 0.347123
Average total loss: 0.724106
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-9.0194e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.373717
Average KL loss: 0.347006
Average total loss: 0.720723
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.9821e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.374330
Average KL loss: 0.346864
Average total loss: 0.721193
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(4.3172e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.378195
Average KL loss: 0.346689
Average total loss: 0.724884
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.6173e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.374234
Average KL loss: 0.346647
Average total loss: 0.720882
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.1015e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.378312
Average KL loss: 0.346557
Average total loss: 0.724870
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.6503e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.372150
Average KL loss: 0.346452
Average total loss: 0.718602
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.0859e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.378185
Average KL loss: 0.346254
Average total loss: 0.724439
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.1530e-11, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.378822
Average KL loss: 0.346177
Average total loss: 0.724999
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(6.4235e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.376241
Average KL loss: 0.346088
Average total loss: 0.722328
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.6650e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.376794
Average KL loss: 0.345968
Average total loss: 0.722762
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.5990e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.375003
Average KL loss: 0.345897
Average total loss: 0.720899
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(5.5685e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.377499
Average KL loss: 0.345820
Average total loss: 0.723319
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.0514e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.374413
Average KL loss: 0.345794
Average total loss: 0.720207
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.3025e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.376262
Average KL loss: 0.345751
Average total loss: 0.722013
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.4327e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.379232
Average KL loss: 0.345621
Average total loss: 0.724853
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.5796e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.374032
Average KL loss: 0.345439
Average total loss: 0.719472
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.1148e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.378964
Average KL loss: 0.345348
Average total loss: 0.724312
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.3421e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.377275
Average KL loss: 0.345307
Average total loss: 0.722582
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.8485e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.376528
Average KL loss: 0.345247
Average total loss: 0.721776
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.3682e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.379642
Average KL loss: 0.345197
Average total loss: 0.724838
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.2938e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.376396
Average KL loss: 0.345156
Average total loss: 0.721552
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(5.4530e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.380007
Average KL loss: 0.345113
Average total loss: 0.725119
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(6.8432e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.375951
Average KL loss: 0.345077
Average total loss: 0.721028
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.5537e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.381401
Average KL loss: 0.345034
Average total loss: 0.726435
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.0436e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.378061
Average KL loss: 0.345008
Average total loss: 0.723070
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(9.0328e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.379736
Average KL loss: 0.344979
Average total loss: 0.724715
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.4583e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.376877
Average KL loss: 0.344955
Average total loss: 0.721831
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.1693e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.375524
Average KL loss: 0.344915
Average total loss: 0.720439
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.4866e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.376930
Average KL loss: 0.344891
Average total loss: 0.721821
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.8442e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.384244
Average KL loss: 0.344888
Average total loss: 0.729133
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.5407e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.373886
Average KL loss: 0.344884
Average total loss: 0.718770
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.6622e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.373292
Average KL loss: 0.344880
Average total loss: 0.718172
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2935e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.379239
Average KL loss: 0.344877
Average total loss: 0.724116
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.0146e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.377217
Average KL loss: 0.344875
Average total loss: 0.722092
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.7657e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.379555
Average KL loss: 0.344871
Average total loss: 0.724426
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.9071e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.375138
Average KL loss: 0.344868
Average total loss: 0.720006
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.4328e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.381145
Average KL loss: 0.344865
Average total loss: 0.726011
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.8560e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.380406
Average KL loss: 0.344862
Average total loss: 0.725267
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.8635e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.374639
Average KL loss: 0.344859
Average total loss: 0.719498
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.8254e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.376687
Average KL loss: 0.344856
Average total loss: 0.721543
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.0822e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.371416
Average KL loss: 0.344852
Average total loss: 0.716268
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(5.9856e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.374930
Average KL loss: 0.344847
Average total loss: 0.719777
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.1537e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.375400
Average KL loss: 0.344843
Average total loss: 0.720243
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.7449e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.377269
Average KL loss: 0.344840
Average total loss: 0.722109
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.2525e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.373791
Average KL loss: 0.344837
Average total loss: 0.718628
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.9416e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.376028
Average KL loss: 0.344834
Average total loss: 0.720862
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.3903e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.376878
Average KL loss: 0.344833
Average total loss: 0.721711
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.3634e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.375856
Average KL loss: 0.344830
Average total loss: 0.720686
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.5809e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.377184
Average KL loss: 0.344828
Average total loss: 0.722012
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.0172e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.381349
Average KL loss: 0.344825
Average total loss: 0.726174
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.3003e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.371482
Average KL loss: 0.344822
Average total loss: 0.716303
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-9.2264e-09, device='cuda:0')
 Percentile value: 8.02192374749211e-08
Non-zero model percentage: 40.96000671386719%, Non-zero mask percentage: 40.96000671386719%

--- Pruning Level [4/24]: ---
conv1.weight         | nonzeros =    1324 /    1728             ( 76.62%) | total_pruned =     404 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
bn1.weight           | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
bn1.bias             | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   29414 /   36864             ( 79.79%) | total_pruned =    7450 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   21730 /   36864             ( 58.95%) | total_pruned =   15134 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   18416 /   36864             ( 49.96%) | total_pruned =   18448 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   17384 /   36864             ( 47.16%) | total_pruned =   19480 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   17980 /   73728             ( 24.39%) | total_pruned =   55748 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   33704 /  147456             ( 22.86%) | total_pruned =  113752 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2755 /    8192             ( 33.63%) | total_pruned =    5437 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   46662 /  147456             ( 31.64%) | total_pruned =  100794 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   55244 /  147456             ( 37.46%) | total_pruned =   92212 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   57582 /  294912             ( 19.53%) | total_pruned =  237330 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      59 /     256             ( 23.05%) | total_pruned =     197 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  118880 /  589824             ( 20.16%) | total_pruned =  470944 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      43 /     256             ( 16.80%) | total_pruned =     213 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    8648 /   32768             ( 26.39%) | total_pruned =   24120 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      41 /     256             ( 16.02%) | total_pruned =     215 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  129833 /  589824             ( 22.01%) | total_pruned =  459991 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  159730 /  589824             ( 27.08%) | total_pruned =  430094 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  222251 / 1179648             ( 18.84%) | total_pruned =  957397 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     471 /     512             ( 91.99%) | total_pruned =      41 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      77 /     512             ( 15.04%) | total_pruned =     435 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  681459 / 2359296             ( 28.88%) | total_pruned = 1677837 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     468 /     512             ( 91.41%) | total_pruned =      44 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     401 /     512             ( 78.32%) | total_pruned =     111 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     108 /     512             ( 21.09%) | total_pruned =     404 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   43662 /  131072             ( 33.31%) | total_pruned =   87410 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     460 /     512             ( 89.84%) | total_pruned =      52 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     108 /     512             ( 21.09%) | total_pruned =     404 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1141262 / 2359296             ( 48.37%) | total_pruned = 1218034 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     441 /     512             ( 86.13%) | total_pruned =      71 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1756061 / 2359296             ( 74.43%) | total_pruned =  603235 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     470 /     512             ( 91.80%) | total_pruned =      42 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     483 /     512             ( 94.34%) | total_pruned =      29 | shape = torch.Size([512])
linear.weight        | nonzeros =    4844 /    5120             ( 94.61%) | total_pruned =     276 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 4578822, pruned : 6599940, total: 11178762, Compression rate :       2.44x  ( 59.04% pruned)
Train Epoch: 55/100 Loss: 0.039590 Accuracy: 88.62 100.00 % Best test Accuracy: 88.72%
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.3822e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.664272
Average KL loss: 0.330209
Average total loss: 0.994481
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.6364e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.571938
Average KL loss: 0.340610
Average total loss: 0.912548
tensor(0.0036, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.8113e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.544838
Average KL loss: 0.346577
Average total loss: 0.891415
tensor(0.0036, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.3915e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.523836
Average KL loss: 0.351312
Average total loss: 0.875148
tensor(0.0036, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.1340e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.511882
Average KL loss: 0.354002
Average total loss: 0.865884
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.2229e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.507253
Average KL loss: 0.355007
Average total loss: 0.862260
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(6.8648e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.495493
Average KL loss: 0.356686
Average total loss: 0.852178
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.6504e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.482392
Average KL loss: 0.358195
Average total loss: 0.840587
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-8.5747e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.485085
Average KL loss: 0.359222
Average total loss: 0.844307
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-4.5148e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.478342
Average KL loss: 0.360037
Average total loss: 0.838379
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.7713e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.465030
Average KL loss: 0.361438
Average total loss: 0.826468
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(5.3888e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.478005
Average KL loss: 0.362025
Average total loss: 0.840030
tensor(0.0035, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.4829e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.471253
Average KL loss: 0.363027
Average total loss: 0.834280
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.8054e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.465072
Average KL loss: 0.363902
Average total loss: 0.828974
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.6029e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.462672
Average KL loss: 0.363392
Average total loss: 0.826064
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-9.8293e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.468056
Average KL loss: 0.365609
Average total loss: 0.833665
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-6.4270e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.450857
Average KL loss: 0.364684
Average total loss: 0.815541
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.9893e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.449916
Average KL loss: 0.365240
Average total loss: 0.815156
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.7924e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.442667
Average KL loss: 0.365194
Average total loss: 0.807861
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(1.1098e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.446748
Average KL loss: 0.364828
Average total loss: 0.811576
tensor(0.0035, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(6.3557e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.444481
Average KL loss: 0.365370
Average total loss: 0.809851
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.2976e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.437792
Average KL loss: 0.366874
Average total loss: 0.804666
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.2135e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.437108
Average KL loss: 0.366850
Average total loss: 0.803958
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.2377e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.439457
Average KL loss: 0.367136
Average total loss: 0.806593
tensor(0.0035, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.3561e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.439577
Average KL loss: 0.367024
Average total loss: 0.806601
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-8.2974e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.434433
Average KL loss: 0.367012
Average total loss: 0.801445
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-8.0296e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.444380
Average KL loss: 0.367565
Average total loss: 0.811945
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(7.3443e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.431285
Average KL loss: 0.367810
Average total loss: 0.799095
tensor(0.0035, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.5407e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.430732
Average KL loss: 0.367312
Average total loss: 0.798044
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.8412e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.435252
Average KL loss: 0.366949
Average total loss: 0.802201
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.9152e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.428959
Average KL loss: 0.366975
Average total loss: 0.795934
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.4301e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.434033
Average KL loss: 0.367459
Average total loss: 0.801492
tensor(0.0035, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.2113e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.427129
Average KL loss: 0.367560
Average total loss: 0.794689
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(6.5636e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.432193
Average KL loss: 0.367471
Average total loss: 0.799664
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.6872e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.433460
Average KL loss: 0.367854
Average total loss: 0.801314
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.7095e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.425327
Average KL loss: 0.367616
Average total loss: 0.792943
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.5481e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.425581
Average KL loss: 0.367762
Average total loss: 0.793343
tensor(0.0035, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.0391e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.428381
Average KL loss: 0.367939
Average total loss: 0.796320
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.6890e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.427947
Average KL loss: 0.368270
Average total loss: 0.796216
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.1235e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.422880
Average KL loss: 0.368542
Average total loss: 0.791422
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.2371e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.424870
Average KL loss: 0.368253
Average total loss: 0.793123
tensor(0.0035, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.6100e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.422387
Average KL loss: 0.369431
Average total loss: 0.791818
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-9.4277e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.418830
Average KL loss: 0.369313
Average total loss: 0.788143
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.0887e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.414781
Average KL loss: 0.368207
Average total loss: 0.782988
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.0256e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.423603
Average KL loss: 0.368820
Average total loss: 0.792423
tensor(0.0035, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.6780e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.416736
Average KL loss: 0.368768
Average total loss: 0.785503
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.7192e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.421550
Average KL loss: 0.369588
Average total loss: 0.791138
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.4058e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.415560
Average KL loss: 0.369608
Average total loss: 0.785168
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.7974e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.415512
Average KL loss: 0.369411
Average total loss: 0.784923
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(2.5242e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.413367
Average KL loss: 0.370024
Average total loss: 0.783391
tensor(0.0035, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.6364e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.416485
Average KL loss: 0.369750
Average total loss: 0.786236
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.2183e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.415613
Average KL loss: 0.369777
Average total loss: 0.785390
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.1805e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.422441
Average KL loss: 0.370337
Average total loss: 0.792778
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.0161e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.414774
Average KL loss: 0.370505
Average total loss: 0.785279
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.2395e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.416306
Average KL loss: 0.370373
Average total loss: 0.786679
tensor(0.0035, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.3202e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.410623
Average KL loss: 0.369107
Average total loss: 0.779730
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.0741e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.411361
Average KL loss: 0.366878
Average total loss: 0.778239
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.0047e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.416559
Average KL loss: 0.365259
Average total loss: 0.781818
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.0857e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.413404
Average KL loss: 0.363972
Average total loss: 0.777376
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.8328e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.409236
Average KL loss: 0.362932
Average total loss: 0.772167
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.3465e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.415935
Average KL loss: 0.361998
Average total loss: 0.777933
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(8.2216e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.413094
Average KL loss: 0.361159
Average total loss: 0.774253
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.1316e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.409961
Average KL loss: 0.360391
Average total loss: 0.770352
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4605e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.406060
Average KL loss: 0.359653
Average total loss: 0.765713
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.8157e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.415459
Average KL loss: 0.358928
Average total loss: 0.774387
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4513e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.411863
Average KL loss: 0.358406
Average total loss: 0.770269
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.7360e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.410910
Average KL loss: 0.357858
Average total loss: 0.768768
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.0331e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.413390
Average KL loss: 0.357429
Average total loss: 0.770819
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.5280e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.406736
Average KL loss: 0.356982
Average total loss: 0.763718
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.4399e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.409878
Average KL loss: 0.356573
Average total loss: 0.766451
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.7076e-11, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.409298
Average KL loss: 0.356179
Average total loss: 0.765478
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.9730e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.409500
Average KL loss: 0.355778
Average total loss: 0.765278
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.2870e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.416688
Average KL loss: 0.355365
Average total loss: 0.772053
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.3055e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.411407
Average KL loss: 0.355102
Average total loss: 0.766509
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.3060e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.411268
Average KL loss: 0.354771
Average total loss: 0.766039
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.6921e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.409512
Average KL loss: 0.354490
Average total loss: 0.764002
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.6017e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.410635
Average KL loss: 0.354184
Average total loss: 0.764818
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.4716e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.403656
Average KL loss: 0.353861
Average total loss: 0.757517
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(7.3945e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.413827
Average KL loss: 0.353603
Average total loss: 0.767429
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.7406e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.407376
Average KL loss: 0.353286
Average total loss: 0.760663
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.8620e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.413130
Average KL loss: 0.353015
Average total loss: 0.766145
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.4024e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.412524
Average KL loss: 0.352809
Average total loss: 0.765333
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.0857e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.410927
Average KL loss: 0.352592
Average total loss: 0.763518
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.0246e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.407445
Average KL loss: 0.352367
Average total loss: 0.759811
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.1084e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.406327
Average KL loss: 0.352217
Average total loss: 0.758544
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.6076e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.409912
Average KL loss: 0.352002
Average total loss: 0.761915
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.8406e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.413242
Average KL loss: 0.351858
Average total loss: 0.765101
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.1746e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.415977
Average KL loss: 0.351749
Average total loss: 0.767725
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.6023e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.413993
Average KL loss: 0.351674
Average total loss: 0.765667
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.1275e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.413879
Average KL loss: 0.351610
Average total loss: 0.765489
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.6783e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.412324
Average KL loss: 0.351564
Average total loss: 0.763887
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3908e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.411518
Average KL loss: 0.351525
Average total loss: 0.763043
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.5042e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.410463
Average KL loss: 0.351484
Average total loss: 0.761947
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.6210e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.412038
Average KL loss: 0.351441
Average total loss: 0.763479
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.1661e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.407295
Average KL loss: 0.351402
Average total loss: 0.758697
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.9618e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.408813
Average KL loss: 0.351366
Average total loss: 0.760179
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.4773e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.415142
Average KL loss: 0.351327
Average total loss: 0.766469
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.6389e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.406466
Average KL loss: 0.351288
Average total loss: 0.757754
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(8.9884e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.409367
Average KL loss: 0.351247
Average total loss: 0.760614
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.1979e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.406861
Average KL loss: 0.351209
Average total loss: 0.758071
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(6.5982e-11, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.410121
Average KL loss: 0.351181
Average total loss: 0.761302
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.3989e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.411000
Average KL loss: 0.351177
Average total loss: 0.762177
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.7708e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.405690
Average KL loss: 0.351174
Average total loss: 0.756864
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.9018e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.410588
Average KL loss: 0.351170
Average total loss: 0.761758
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.3862e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.409385
Average KL loss: 0.351165
Average total loss: 0.760550
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.5427e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.410118
Average KL loss: 0.351161
Average total loss: 0.761280
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.2053e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.407687
Average KL loss: 0.351158
Average total loss: 0.758845
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9535e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.405772
Average KL loss: 0.351154
Average total loss: 0.756925
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.5665e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.408768
Average KL loss: 0.351150
Average total loss: 0.759917
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.2371e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.408169
Average KL loss: 0.351145
Average total loss: 0.759314
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.6196e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.409757
Average KL loss: 0.351141
Average total loss: 0.760897
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.9642e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.405520
Average KL loss: 0.351137
Average total loss: 0.756657
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.0229e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.404994
Average KL loss: 0.351132
Average total loss: 0.756126
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9953e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.408476
Average KL loss: 0.351128
Average total loss: 0.759604
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3513e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.411259
Average KL loss: 0.351125
Average total loss: 0.762384
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4363e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.409818
Average KL loss: 0.351121
Average total loss: 0.760940
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9906e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.411275
Average KL loss: 0.351118
Average total loss: 0.762393
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.0029e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.407225
Average KL loss: 0.351115
Average total loss: 0.758340
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.8255e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.406387
Average KL loss: 0.351111
Average total loss: 0.757498
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.9098e-11, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.407259
Average KL loss: 0.351107
Average total loss: 0.758366
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9184e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.409115
Average KL loss: 0.351103
Average total loss: 0.760218
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9381e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.411683
Average KL loss: 0.351100
Average total loss: 0.762784
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.2621e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.410001
Average KL loss: 0.351097
Average total loss: 0.761097
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.4018e-09, device='cuda:0')
 Percentile value: 8.040932186759164e-08
Non-zero model percentage: 32.76801300048828%, Non-zero mask percentage: 32.76801300048828%

--- Pruning Level [5/24]: ---
conv1.weight         | nonzeros =    1049 /    1728             ( 60.71%) | total_pruned =     679 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
bn1.weight           | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
bn1.bias             | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   10540 /   36864             ( 28.59%) | total_pruned =   26324 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   16797 /   36864             ( 45.56%) | total_pruned =   20067 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   12974 /   36864             ( 35.19%) | total_pruned =   23890 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   13922 /   36864             ( 37.77%) | total_pruned =   22942 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      44 /      64             ( 68.75%) | total_pruned =      20 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   13612 /   73728             ( 18.46%) | total_pruned =   60116 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      96 /     128             ( 75.00%) | total_pruned =      32 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   25400 /  147456             ( 17.23%) | total_pruned =  122056 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2154 /    8192             ( 26.29%) | total_pruned =    6038 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   34804 /  147456             ( 23.60%) | total_pruned =  112652 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   41502 /  147456             ( 28.15%) | total_pruned =  105954 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   42193 /  294912             ( 14.31%) | total_pruned =  252719 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     161 /     256             ( 62.89%) | total_pruned =      95 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   86283 /  589824             ( 14.63%) | total_pruned =  503541 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     189 /     256             ( 73.83%) | total_pruned =      67 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     246 /     256             ( 96.09%) | total_pruned =      10 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6562 /   32768             ( 20.03%) | total_pruned =   26206 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     175 /     256             ( 68.36%) | total_pruned =      81 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   92287 /  589824             ( 15.65%) | total_pruned =  497537 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  116013 /  589824             ( 19.67%) | total_pruned =  473811 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     184 /     256             ( 71.88%) | total_pruned =      72 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     190 /     256             ( 74.22%) | total_pruned =      66 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  150929 / 1179648             ( 12.79%) | total_pruned = 1028719 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     331 /     512             ( 64.65%) | total_pruned =     181 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      70 /     512             ( 13.67%) | total_pruned =     442 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  491801 / 2359296             ( 20.85%) | total_pruned = 1867495 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     344 /     512             ( 67.19%) | total_pruned =     168 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     368 /     512             ( 71.88%) | total_pruned =     144 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     108 /     512             ( 21.09%) | total_pruned =     404 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   32929 /  131072             ( 25.12%) | total_pruned =   98143 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     358 /     512             ( 69.92%) | total_pruned =     154 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     337 /     512             ( 65.82%) | total_pruned =     175 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     105 /     512             ( 20.51%) | total_pruned =     407 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  951727 / 2359296             ( 40.34%) | total_pruned = 1407569 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     322 /     512             ( 62.89%) | total_pruned =     190 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     451 /     512             ( 88.09%) | total_pruned =      61 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1506485 / 2359296             ( 63.85%) | total_pruned =  852811 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     357 /     512             ( 69.73%) | total_pruned =     155 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     457 /     512             ( 89.26%) | total_pruned =      55 | shape = torch.Size([512])
linear.weight        | nonzeros =    4551 /    5120             ( 88.89%) | total_pruned =     569 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 3663058, pruned : 7515704, total: 11178762, Compression rate :       3.05x  ( 67.23% pruned)
Train Epoch: 56/100 Loss: 0.016493 Accuracy: 88.13 100.00 % Best test Accuracy: 88.33%
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.1711e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.630993
Average KL loss: 0.332381
Average total loss: 0.963374
tensor(0.0035, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-2.3497e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.570244
Average KL loss: 0.338381
Average total loss: 0.908625
tensor(0.0035, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.0426e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.546127
Average KL loss: 0.344318
Average total loss: 0.890445
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.3860e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.530031
Average KL loss: 0.348915
Average total loss: 0.878946
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.9429e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.517751
Average KL loss: 0.351928
Average total loss: 0.869678
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-7.5434e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.503786
Average KL loss: 0.354135
Average total loss: 0.857920
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.7352e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.502048
Average KL loss: 0.356027
Average total loss: 0.858075
tensor(0.0034, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-8.9545e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.496394
Average KL loss: 0.358637
Average total loss: 0.855030
tensor(0.0034, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-4.9168e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.483625
Average KL loss: 0.360137
Average total loss: 0.843762
tensor(0.0034, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-3.5312e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.481662
Average KL loss: 0.360918
Average total loss: 0.842580
tensor(0.0033, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.5006e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.477889
Average KL loss: 0.361103
Average total loss: 0.838992
tensor(0.0033, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.3086e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.479084
Average KL loss: 0.362387
Average total loss: 0.841472
tensor(0.0033, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.2886e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.470208
Average KL loss: 0.363334
Average total loss: 0.833542
tensor(0.0033, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.7042e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.468230
Average KL loss: 0.363301
Average total loss: 0.831531
tensor(0.0033, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-7.9714e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.472870
Average KL loss: 0.364249
Average total loss: 0.837119
tensor(0.0033, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.1573e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.470347
Average KL loss: 0.365309
Average total loss: 0.835656
tensor(0.0033, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.3035e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.461142
Average KL loss: 0.365541
Average total loss: 0.826682
tensor(0.0033, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.2358e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.463725
Average KL loss: 0.365597
Average total loss: 0.829322
tensor(0.0033, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.9542e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.454765
Average KL loss: 0.365810
Average total loss: 0.820575
tensor(0.0033, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.9019e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.449840
Average KL loss: 0.365853
Average total loss: 0.815693
tensor(0.0033, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-7.4982e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.454363
Average KL loss: 0.365940
Average total loss: 0.820303
tensor(0.0033, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.2780e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.460513
Average KL loss: 0.366213
Average total loss: 0.826726
tensor(0.0033, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.8586e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.454652
Average KL loss: 0.366930
Average total loss: 0.821581
tensor(0.0033, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(1.2031e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.458071
Average KL loss: 0.368720
Average total loss: 0.826791
tensor(0.0033, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.9099e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.449282
Average KL loss: 0.369159
Average total loss: 0.818441
tensor(0.0033, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-2.1625e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.450856
Average KL loss: 0.369089
Average total loss: 0.819945
tensor(0.0033, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.3454e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.450570
Average KL loss: 0.369028
Average total loss: 0.819598
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.1393e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.449697
Average KL loss: 0.369818
Average total loss: 0.819514
tensor(0.0033, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.7904e-12, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.451281
Average KL loss: 0.369857
Average total loss: 0.821138
tensor(0.0034, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-6.6113e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.448316
Average KL loss: 0.369975
Average total loss: 0.818291
tensor(0.0034, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(8.1236e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.443902
Average KL loss: 0.370234
Average total loss: 0.814136
tensor(0.0033, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.7236e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.444148
Average KL loss: 0.369960
Average total loss: 0.814109
tensor(0.0033, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.4820e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.450545
Average KL loss: 0.369959
Average total loss: 0.820504
tensor(0.0034, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.6904e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.448169
Average KL loss: 0.370952
Average total loss: 0.819121
tensor(0.0034, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-6.9371e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.443863
Average KL loss: 0.371718
Average total loss: 0.815581
tensor(0.0034, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(8.0577e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.442216
Average KL loss: 0.370771
Average total loss: 0.812987
tensor(0.0034, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.6275e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.441079
Average KL loss: 0.371384
Average total loss: 0.812463
tensor(0.0034, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-8.8027e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.444992
Average KL loss: 0.371715
Average total loss: 0.816707
tensor(0.0034, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(2.5211e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.443809
Average KL loss: 0.371446
Average total loss: 0.815254
tensor(0.0034, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.8860e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.439112
Average KL loss: 0.371291
Average total loss: 0.810403
tensor(0.0034, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.0424e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.444401
Average KL loss: 0.371350
Average total loss: 0.815751
tensor(0.0034, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.6482e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.432773
Average KL loss: 0.371629
Average total loss: 0.804402
tensor(0.0034, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.7698e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.441699
Average KL loss: 0.371081
Average total loss: 0.812780
tensor(0.0034, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.1969e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.437161
Average KL loss: 0.371618
Average total loss: 0.808779
tensor(0.0034, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.5894e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.440941
Average KL loss: 0.371798
Average total loss: 0.812739
tensor(0.0034, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(1.2324e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.433243
Average KL loss: 0.371733
Average total loss: 0.804975
tensor(0.0034, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.2231e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.439764
Average KL loss: 0.371783
Average total loss: 0.811547
tensor(0.0034, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(1.1493e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.438636
Average KL loss: 0.372039
Average total loss: 0.810675
tensor(0.0034, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.4051e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.434566
Average KL loss: 0.372295
Average total loss: 0.806861
tensor(0.0034, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.5227e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.437032
Average KL loss: 0.372162
Average total loss: 0.809194
tensor(0.0034, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.9353e-11, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.431791
Average KL loss: 0.372525
Average total loss: 0.804316
tensor(0.0034, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(3.5945e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.434393
Average KL loss: 0.372609
Average total loss: 0.807003
tensor(0.0034, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(1.0424e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.435529
Average KL loss: 0.372554
Average total loss: 0.808084
tensor(0.0034, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(3.2717e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.433909
Average KL loss: 0.373336
Average total loss: 0.807245
tensor(0.0034, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(3.9248e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.432360
Average KL loss: 0.373384
Average total loss: 0.805743
tensor(0.0034, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(2.3535e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.436076
Average KL loss: 0.373313
Average total loss: 0.809389
tensor(0.0034, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.2639e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.432764
Average KL loss: 0.373860
Average total loss: 0.806624
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.8473e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.430676
Average KL loss: 0.373776
Average total loss: 0.804452
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.7098e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.431769
Average KL loss: 0.373681
Average total loss: 0.805450
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.8886e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.433225
Average KL loss: 0.373149
Average total loss: 0.806374
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.4227e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.431139
Average KL loss: 0.373389
Average total loss: 0.804528
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.7467e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.433656
Average KL loss: 0.373776
Average total loss: 0.807433
tensor(0.0034, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.6256e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.435178
Average KL loss: 0.373532
Average total loss: 0.808709
tensor(0.0034, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.1214e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.424201
Average KL loss: 0.372005
Average total loss: 0.796206
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.7749e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.430773
Average KL loss: 0.370842
Average total loss: 0.801615
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.2109e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.431042
Average KL loss: 0.369855
Average total loss: 0.800897
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.4362e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.431951
Average KL loss: 0.368964
Average total loss: 0.800915
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.8202e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.433885
Average KL loss: 0.368182
Average total loss: 0.802067
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.1214e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.429738
Average KL loss: 0.367484
Average total loss: 0.797221
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.8001e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.432066
Average KL loss: 0.366879
Average total loss: 0.798944
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.1406e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.428051
Average KL loss: 0.366300
Average total loss: 0.794352
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.9300e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.432131
Average KL loss: 0.365770
Average total loss: 0.797901
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.9203e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.433541
Average KL loss: 0.365320
Average total loss: 0.798861
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.5847e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.427853
Average KL loss: 0.364868
Average total loss: 0.792721
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.6989e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.426890
Average KL loss: 0.364427
Average total loss: 0.791317
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.8330e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.425824
Average KL loss: 0.364022
Average total loss: 0.789847
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.7469e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.426965
Average KL loss: 0.363547
Average total loss: 0.790511
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.7101e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.427144
Average KL loss: 0.363183
Average total loss: 0.790327
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.5636e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.426960
Average KL loss: 0.362816
Average total loss: 0.789776
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(7.7676e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.424281
Average KL loss: 0.362507
Average total loss: 0.786787
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.5334e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.430864
Average KL loss: 0.362168
Average total loss: 0.793032
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.2664e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.424797
Average KL loss: 0.361811
Average total loss: 0.786608
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.5390e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.431162
Average KL loss: 0.361523
Average total loss: 0.792685
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.4668e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.426479
Average KL loss: 0.361303
Average total loss: 0.787782
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.5556e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.428075
Average KL loss: 0.361044
Average total loss: 0.789119
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(6.9483e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.428507
Average KL loss: 0.360800
Average total loss: 0.789306
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.0408e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.430077
Average KL loss: 0.360547
Average total loss: 0.790624
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.2895e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.428278
Average KL loss: 0.360363
Average total loss: 0.788642
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.6158e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.428405
Average KL loss: 0.360158
Average total loss: 0.788562
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.1880e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.425471
Average KL loss: 0.359998
Average total loss: 0.785469
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.1067e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.429021
Average KL loss: 0.359754
Average total loss: 0.788774
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.3870e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.429596
Average KL loss: 0.359547
Average total loss: 0.789142
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.2858e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.432109
Average KL loss: 0.359439
Average total loss: 0.791547
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.9337e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.430036
Average KL loss: 0.359303
Average total loss: 0.789339
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(6.0309e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.427031
Average KL loss: 0.359125
Average total loss: 0.786156
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.2955e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.429226
Average KL loss: 0.358971
Average total loss: 0.788197
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(6.1200e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.426424
Average KL loss: 0.358865
Average total loss: 0.785288
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.9063e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.424628
Average KL loss: 0.358787
Average total loss: 0.783415
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.4136e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.426340
Average KL loss: 0.358675
Average total loss: 0.785015
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.3623e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.426437
Average KL loss: 0.358627
Average total loss: 0.785064
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.5840e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.424526
Average KL loss: 0.358505
Average total loss: 0.783031
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.6195e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.431213
Average KL loss: 0.358301
Average total loss: 0.789514
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.1268e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.432100
Average KL loss: 0.358168
Average total loss: 0.790268
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.5516e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.431919
Average KL loss: 0.358010
Average total loss: 0.789930
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.1470e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.425955
Average KL loss: 0.357909
Average total loss: 0.783864
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.7060e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.426265
Average KL loss: 0.357834
Average total loss: 0.784099
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-9.8288e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.429875
Average KL loss: 0.357722
Average total loss: 0.787597
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9941e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.426129
Average KL loss: 0.357554
Average total loss: 0.783683
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.6782e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.426359
Average KL loss: 0.357381
Average total loss: 0.783740
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.7960e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.423586
Average KL loss: 0.357324
Average total loss: 0.780910
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.1873e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.429364
Average KL loss: 0.357261
Average total loss: 0.786625
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.7520e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.423390
Average KL loss: 0.357196
Average total loss: 0.780587
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.3138e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.427227
Average KL loss: 0.357122
Average total loss: 0.784349
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.5001e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.432162
Average KL loss: 0.356975
Average total loss: 0.789137
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.6293e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.428239
Average KL loss: 0.356888
Average total loss: 0.785127
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.4022e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.425534
Average KL loss: 0.356794
Average total loss: 0.782328
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.3117e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.425718
Average KL loss: 0.356597
Average total loss: 0.782316
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.4720e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.422882
Average KL loss: 0.356428
Average total loss: 0.779310
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(4.9144e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.427341
Average KL loss: 0.356303
Average total loss: 0.783644
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.1539e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.430308
Average KL loss: 0.356310
Average total loss: 0.786618
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.6590e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.425612
Average KL loss: 0.356251
Average total loss: 0.781863
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.0317e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.431163
Average KL loss: 0.356165
Average total loss: 0.787328
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(8.7973e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.424778
Average KL loss: 0.356090
Average total loss: 0.780869
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(4.2174e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.427433
Average KL loss: 0.356022
Average total loss: 0.783455
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.7644e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.426088
Average KL loss: 0.355905
Average total loss: 0.781993
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.1822e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.431167
Average KL loss: 0.355873
Average total loss: 0.787040
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.5726e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.425912
Average KL loss: 0.355815
Average total loss: 0.781726
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.7297e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.427351
Average KL loss: 0.355684
Average total loss: 0.783035
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.4762e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.428251
Average KL loss: 0.355683
Average total loss: 0.783934
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.9325e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.425199
Average KL loss: 0.355649
Average total loss: 0.780848
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.5397e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.428417
Average KL loss: 0.355625
Average total loss: 0.784042
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.9888e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.428051
Average KL loss: 0.355594
Average total loss: 0.783645
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.1847e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.426200
Average KL loss: 0.355563
Average total loss: 0.781763
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.1863e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.425879
Average KL loss: 0.355541
Average total loss: 0.781420
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.5611e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.427044
Average KL loss: 0.355523
Average total loss: 0.782567
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.0059e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.426072
Average KL loss: 0.355495
Average total loss: 0.781568
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.7281e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.429347
Average KL loss: 0.355465
Average total loss: 0.784812
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(3.3241e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.426935
Average KL loss: 0.355443
Average total loss: 0.782378
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.7767e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.421785
Average KL loss: 0.355419
Average total loss: 0.777204
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.1313e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.430211
Average KL loss: 0.355393
Average total loss: 0.785604
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.7186e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.421209
Average KL loss: 0.355373
Average total loss: 0.776582
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(6.3702e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.429472
Average KL loss: 0.355352
Average total loss: 0.784825
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.1743e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.424649
Average KL loss: 0.355338
Average total loss: 0.779987
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-8.6270e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.431008
Average KL loss: 0.355319
Average total loss: 0.786326
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.8428e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.425461
Average KL loss: 0.355308
Average total loss: 0.780769
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.4627e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.429523
Average KL loss: 0.355289
Average total loss: 0.784812
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(9.7496e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.425168
Average KL loss: 0.355271
Average total loss: 0.780439
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.0338e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.427367
Average KL loss: 0.355255
Average total loss: 0.782622
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(9.2315e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.431287
Average KL loss: 0.355237
Average total loss: 0.786525
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.3845e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.425167
Average KL loss: 0.355222
Average total loss: 0.780388
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.0179e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.428005
Average KL loss: 0.355207
Average total loss: 0.783212
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.8518e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.427751
Average KL loss: 0.355191
Average total loss: 0.782942
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(5.8191e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.429647
Average KL loss: 0.355181
Average total loss: 0.784828
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.8232e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.429474
Average KL loss: 0.355179
Average total loss: 0.784653
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.2331e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.425286
Average KL loss: 0.355177
Average total loss: 0.780463
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.2183e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.425996
Average KL loss: 0.355175
Average total loss: 0.781171
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.1730e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.428492
Average KL loss: 0.355173
Average total loss: 0.783665
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.9507e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.432454
Average KL loss: 0.355172
Average total loss: 0.787626
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.0341e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.427816
Average KL loss: 0.355170
Average total loss: 0.782986
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.3181e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.428102
Average KL loss: 0.355168
Average total loss: 0.783270
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(4.9847e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.432862
Average KL loss: 0.355166
Average total loss: 0.788028
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.5801e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.427403
Average KL loss: 0.355165
Average total loss: 0.782568
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.7083e-09, device='cuda:0')
 Percentile value: 7.98184913719524e-08
Non-zero model percentage: 26.214414596557617%, Non-zero mask percentage: 26.214414596557617%

--- Pruning Level [6/24]: ---
conv1.weight         | nonzeros =     848 /    1728             ( 49.07%) | total_pruned =     880 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
bn1.weight           | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
bn1.bias             | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    8399 /   36864             ( 22.78%) | total_pruned =   28465 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   13514 /   36864             ( 36.66%) | total_pruned =   23350 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   10374 /   36864             ( 28.14%) | total_pruned =   26490 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   11154 /   36864             ( 30.26%) | total_pruned =   25710 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   10510 /   73728             ( 14.26%) | total_pruned =   63218 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   19577 /  147456             ( 13.28%) | total_pruned =  127879 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1670 /    8192             ( 20.39%) | total_pruned =    6522 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   27006 /  147456             ( 18.31%) | total_pruned =  120450 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   32237 /  147456             ( 21.86%) | total_pruned =  115219 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   31954 /  294912             ( 10.84%) | total_pruned =  262958 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   64924 /  589824             ( 11.01%) | total_pruned =  524900 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     149 /     256             ( 58.20%) | total_pruned =     107 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    5069 /   32768             ( 15.47%) | total_pruned =   27699 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     152 /     256             ( 59.38%) | total_pruned =     104 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     196 /     256             ( 76.56%) | total_pruned =      60 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   67452 /  589824             ( 11.44%) | total_pruned =  522372 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     160 /     256             ( 62.50%) | total_pruned =      96 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     240 /     256             ( 93.75%) | total_pruned =      16 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   86000 /  589824             ( 14.58%) | total_pruned =  503824 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     165 /     256             ( 64.45%) | total_pruned =      91 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      15 /     256             (  5.86%) | total_pruned =     241 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  108291 / 1179648             (  9.18%) | total_pruned = 1071357 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     274 /     512             ( 53.52%) | total_pruned =     238 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     491 /     512             ( 95.90%) | total_pruned =      21 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      61 /     512             ( 11.91%) | total_pruned =     451 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  371563 / 2359296             ( 15.75%) | total_pruned = 1987733 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     288 /     512             ( 56.25%) | total_pruned =     224 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     343 /     512             ( 66.99%) | total_pruned =     169 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     105 /     512             ( 20.51%) | total_pruned =     407 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   25191 /  131072             ( 19.22%) | total_pruned =  105881 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     302 /     512             ( 58.98%) | total_pruned =     210 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     304 /     512             ( 59.38%) | total_pruned =     208 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     104 /     512             ( 20.31%) | total_pruned =     408 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  760110 / 2359296             ( 32.22%) | total_pruned = 1599186 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     283 /     512             ( 55.27%) | total_pruned =     229 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1262706 / 2359296             ( 53.52%) | total_pruned = 1096590 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     307 /     512             ( 59.96%) | total_pruned =     205 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     485 /     512             ( 94.73%) | total_pruned =      27 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     415 /     512             ( 81.05%) | total_pruned =      97 | shape = torch.Size([512])
linear.weight        | nonzeros =    4202 /    5120             ( 82.07%) | total_pruned =     918 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 2930447, pruned : 8248315, total: 11178762, Compression rate :       3.81x  ( 73.79% pruned)
Train Epoch: 61/100 Loss: 0.026736 Accuracy: 87.80 100.00 % Best test Accuracy: 87.90%
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.9622e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.750648
Average KL loss: 0.334545
Average total loss: 1.085193
tensor(0.0034, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.5958e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.673145
Average KL loss: 0.336902
Average total loss: 1.010047
tensor(0.0033, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-2.3051e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.643142
Average KL loss: 0.342571
Average total loss: 0.985713
tensor(0.0032, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-2.7034e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.624138
Average KL loss: 0.347169
Average total loss: 0.971307
tensor(0.0032, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.3171e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.605661
Average KL loss: 0.350430
Average total loss: 0.956091
tensor(0.0032, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.7398e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.602434
Average KL loss: 0.352562
Average total loss: 0.954996
tensor(0.0032, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.0985e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.577291
Average KL loss: 0.355321
Average total loss: 0.932612
tensor(0.0032, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-5.1158e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.565905
Average KL loss: 0.357398
Average total loss: 0.923303
tensor(0.0032, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-5.4707e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.559907
Average KL loss: 0.359445
Average total loss: 0.919353
tensor(0.0032, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-1.2619e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.556514
Average KL loss: 0.361765
Average total loss: 0.918278
tensor(0.0032, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.0013e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.559554
Average KL loss: 0.363454
Average total loss: 0.923008
tensor(0.0032, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(4.0475e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.542852
Average KL loss: 0.365090
Average total loss: 0.907943
tensor(0.0032, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(5.0198e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.536723
Average KL loss: 0.365564
Average total loss: 0.902288
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.2447e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.534783
Average KL loss: 0.366326
Average total loss: 0.901109
tensor(0.0031, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.6237e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.534934
Average KL loss: 0.367974
Average total loss: 0.902908
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.2258e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.528249
Average KL loss: 0.368836
Average total loss: 0.897085
tensor(0.0032, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-7.7234e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.523067
Average KL loss: 0.369547
Average total loss: 0.892614
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-3.7682e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.525960
Average KL loss: 0.370073
Average total loss: 0.896033
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-1.1391e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.521968
Average KL loss: 0.370556
Average total loss: 0.892524
tensor(0.0032, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.9537e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.520173
Average KL loss: 0.370926
Average total loss: 0.891099
tensor(0.0032, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.4367e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.517031
Average KL loss: 0.371680
Average total loss: 0.888711
tensor(0.0032, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(1.3605e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.514423
Average KL loss: 0.372317
Average total loss: 0.886739
tensor(0.0032, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.2287e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.508902
Average KL loss: 0.372698
Average total loss: 0.881600
tensor(0.0032, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-7.3545e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.503728
Average KL loss: 0.372865
Average total loss: 0.876593
tensor(0.0032, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(3.8069e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.511035
Average KL loss: 0.373499
Average total loss: 0.884534
tensor(0.0032, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.9395e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.503373
Average KL loss: 0.373595
Average total loss: 0.876968
tensor(0.0032, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.1612e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.508660
Average KL loss: 0.373565
Average total loss: 0.882225
tensor(0.0032, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(3.0830e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.495488
Average KL loss: 0.374273
Average total loss: 0.869761
tensor(0.0032, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-6.0847e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.496028
Average KL loss: 0.374116
Average total loss: 0.870144
tensor(0.0032, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-9.7529e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.489214
Average KL loss: 0.373701
Average total loss: 0.862914
tensor(0.0032, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.0044e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.494472
Average KL loss: 0.373870
Average total loss: 0.868342
tensor(0.0032, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.9432e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.498870
Average KL loss: 0.374931
Average total loss: 0.873801
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.2225e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.492277
Average KL loss: 0.375034
Average total loss: 0.867311
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.1006e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.495040
Average KL loss: 0.375136
Average total loss: 0.870176
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-9.7166e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.489885
Average KL loss: 0.375803
Average total loss: 0.865688
tensor(0.0032, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.0249e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.488028
Average KL loss: 0.375662
Average total loss: 0.863690
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.0918e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.485076
Average KL loss: 0.375751
Average total loss: 0.860827
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.6190e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.493847
Average KL loss: 0.375924
Average total loss: 0.869771
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.1292e-11, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.492705
Average KL loss: 0.376753
Average total loss: 0.869459
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.7816e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.481931
Average KL loss: 0.377410
Average total loss: 0.859341
tensor(0.0032, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.2682e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.478000
Average KL loss: 0.377130
Average total loss: 0.855130
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.1036e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.486491
Average KL loss: 0.376831
Average total loss: 0.863321
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(1.4938e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.478086
Average KL loss: 0.377185
Average total loss: 0.855271
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(3.3350e-10, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.475873
Average KL loss: 0.377519
Average total loss: 0.853393
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(7.1479e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.480471
Average KL loss: 0.377263
Average total loss: 0.857734
tensor(0.0032, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-9.0056e-11, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.476793
Average KL loss: 0.377194
Average total loss: 0.853987
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.4784e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.477510
Average KL loss: 0.377795
Average total loss: 0.855305
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.9223e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.470966
Average KL loss: 0.378126
Average total loss: 0.849092
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.3593e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.479386
Average KL loss: 0.378859
Average total loss: 0.858245
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.9070e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.471554
Average KL loss: 0.378986
Average total loss: 0.850540
tensor(0.0032, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.6567e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.478036
Average KL loss: 0.378897
Average total loss: 0.856933
tensor(0.0032, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.5880e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.470284
Average KL loss: 0.378727
Average total loss: 0.849011
tensor(0.0032, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.0461e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.475790
Average KL loss: 0.378683
Average total loss: 0.854473
tensor(0.0032, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.3157e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.472084
Average KL loss: 0.378926
Average total loss: 0.851010
tensor(0.0032, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(5.2887e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.472702
Average KL loss: 0.379016
Average total loss: 0.851718
tensor(0.0032, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.3731e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.472669
Average KL loss: 0.378639
Average total loss: 0.851308
tensor(0.0032, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.9012e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.469773
Average KL loss: 0.378668
Average total loss: 0.848440
tensor(0.0032, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.1224e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.468486
Average KL loss: 0.379368
Average total loss: 0.847854
tensor(0.0032, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.9209e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.465197
Average KL loss: 0.379577
Average total loss: 0.844774
tensor(0.0032, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(5.7895e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.475668
Average KL loss: 0.379781
Average total loss: 0.855448
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.1741e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.465184
Average KL loss: 0.379648
Average total loss: 0.844832
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-7.5740e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.465126
Average KL loss: 0.379991
Average total loss: 0.845117
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.3995e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.473211
Average KL loss: 0.380212
Average total loss: 0.853424
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.5820e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.468713
Average KL loss: 0.380828
Average total loss: 0.849541
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(1.9804e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.466952
Average KL loss: 0.381301
Average total loss: 0.848253
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.5794e-11, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.468035
Average KL loss: 0.381690
Average total loss: 0.849726
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.5156e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.464108
Average KL loss: 0.381744
Average total loss: 0.845851
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.5739e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.461652
Average KL loss: 0.381135
Average total loss: 0.842788
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.6196e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.460585
Average KL loss: 0.380835
Average total loss: 0.841421
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.2969e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.463703
Average KL loss: 0.381020
Average total loss: 0.844723
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.8814e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.468264
Average KL loss: 0.380739
Average total loss: 0.849003
tensor(0.0032, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.2304e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.465244
Average KL loss: 0.381671
Average total loss: 0.846914
tensor(0.0033, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.7898e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.466971
Average KL loss: 0.382172
Average total loss: 0.849143
tensor(0.0033, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.0954e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.468105
Average KL loss: 0.382176
Average total loss: 0.850282
tensor(0.0033, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.9052e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.461030
Average KL loss: 0.382144
Average total loss: 0.843174
tensor(0.0033, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.3307e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.461394
Average KL loss: 0.381956
Average total loss: 0.843350
tensor(0.0033, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.3461e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.465133
Average KL loss: 0.382052
Average total loss: 0.847185
tensor(0.0033, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.4855e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.457109
Average KL loss: 0.382332
Average total loss: 0.839441
tensor(0.0033, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(9.7440e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.463090
Average KL loss: 0.382510
Average total loss: 0.845599
tensor(0.0033, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.3602e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.468727
Average KL loss: 0.382340
Average total loss: 0.851067
tensor(0.0033, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.6439e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.459252
Average KL loss: 0.382128
Average total loss: 0.841380
tensor(0.0033, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(1.5407e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.459194
Average KL loss: 0.381885
Average total loss: 0.841079
tensor(0.0033, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.7187e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.468419
Average KL loss: 0.382026
Average total loss: 0.850445
tensor(0.0033, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.5148e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.455922
Average KL loss: 0.382780
Average total loss: 0.838701
tensor(0.0033, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.2062e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.457449
Average KL loss: 0.382285
Average total loss: 0.839734
tensor(0.0033, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.6982e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.456297
Average KL loss: 0.382595
Average total loss: 0.838893
tensor(0.0033, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.8466e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.458489
Average KL loss: 0.382458
Average total loss: 0.840946
tensor(0.0033, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.6850e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.452391
Average KL loss: 0.382265
Average total loss: 0.834656
tensor(0.0033, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.2930e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.463927
Average KL loss: 0.382170
Average total loss: 0.846098
tensor(0.0033, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.1357e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.460474
Average KL loss: 0.382833
Average total loss: 0.843307
tensor(0.0033, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.2299e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.462096
Average KL loss: 0.382837
Average total loss: 0.844933
tensor(0.0033, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.0240e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.451783
Average KL loss: 0.382832
Average total loss: 0.834614
tensor(0.0033, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.7356e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.453696
Average KL loss: 0.382119
Average total loss: 0.835815
tensor(0.0033, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.7957e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.458790
Average KL loss: 0.382594
Average total loss: 0.841384
tensor(0.0033, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.8497e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.450433
Average KL loss: 0.382425
Average total loss: 0.832858
tensor(0.0033, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.6752e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.452360
Average KL loss: 0.382522
Average total loss: 0.834882
tensor(0.0033, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.4210e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.456627
Average KL loss: 0.383037
Average total loss: 0.839664
tensor(0.0033, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.8162e-11, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.457046
Average KL loss: 0.382657
Average total loss: 0.839703
tensor(0.0033, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.3413e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.456595
Average KL loss: 0.382621
Average total loss: 0.839216
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1809e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.457364
Average KL loss: 0.383061
Average total loss: 0.840425
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(6.9291e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.451664
Average KL loss: 0.383285
Average total loss: 0.834948
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.6704e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.457248
Average KL loss: 0.383574
Average total loss: 0.840822
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.1182e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.465076
Average KL loss: 0.383622
Average total loss: 0.848698
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.6288e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.452870
Average KL loss: 0.383997
Average total loss: 0.836867
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.4554e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.455946
Average KL loss: 0.383836
Average total loss: 0.839782
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.0471e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.454775
Average KL loss: 0.384283
Average total loss: 0.839059
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.7635e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.451099
Average KL loss: 0.383860
Average total loss: 0.834960
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.0866e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.450462
Average KL loss: 0.382753
Average total loss: 0.833215
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(4.0237e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.453390
Average KL loss: 0.381902
Average total loss: 0.835292
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-5.8469e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.457317
Average KL loss: 0.381200
Average total loss: 0.838517
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-6.4064e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.462509
Average KL loss: 0.380560
Average total loss: 0.843069
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.9024e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.453915
Average KL loss: 0.380010
Average total loss: 0.833926
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.1642e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.453331
Average KL loss: 0.379483
Average total loss: 0.832814
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.8437e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.453359
Average KL loss: 0.379030
Average total loss: 0.832389
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(6.2346e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.450169
Average KL loss: 0.378566
Average total loss: 0.828734
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.3592e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.453228
Average KL loss: 0.378128
Average total loss: 0.831356
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-4.6987e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.450624
Average KL loss: 0.377781
Average total loss: 0.828405
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.3836e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.448147
Average KL loss: 0.377417
Average total loss: 0.825565
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.5599e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.451012
Average KL loss: 0.377029
Average total loss: 0.828041
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.4387e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.451839
Average KL loss: 0.376616
Average total loss: 0.828456
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.9376e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.454856
Average KL loss: 0.376290
Average total loss: 0.831147
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(3.8960e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.451005
Average KL loss: 0.375994
Average total loss: 0.826999
tensor(0.0033, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.8804e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.452609
Average KL loss: 0.375701
Average total loss: 0.828311
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.0226e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.451287
Average KL loss: 0.375403
Average total loss: 0.826689
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.8479e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.448492
Average KL loss: 0.375100
Average total loss: 0.823592
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.5882e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.450953
Average KL loss: 0.374814
Average total loss: 0.825767
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.6957e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.448807
Average KL loss: 0.374526
Average total loss: 0.823333
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.1936e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.450237
Average KL loss: 0.374295
Average total loss: 0.824532
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.5258e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.450591
Average KL loss: 0.374047
Average total loss: 0.824638
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.8723e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.447346
Average KL loss: 0.373810
Average total loss: 0.821156
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.0753e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.451357
Average KL loss: 0.373564
Average total loss: 0.824921
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.4893e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.462575
Average KL loss: 0.373399
Average total loss: 0.835975
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.3837e-11, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.451015
Average KL loss: 0.373232
Average total loss: 0.824247
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.0532e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.453192
Average KL loss: 0.373015
Average total loss: 0.826206
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.8055e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.451781
Average KL loss: 0.372840
Average total loss: 0.824621
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.8065e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.449497
Average KL loss: 0.372678
Average total loss: 0.822175
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(8.9111e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.451346
Average KL loss: 0.372553
Average total loss: 0.823899
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.2088e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.450140
Average KL loss: 0.372408
Average total loss: 0.822548
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(6.0239e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.448168
Average KL loss: 0.372229
Average total loss: 0.820397
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.7770e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.453850
Average KL loss: 0.372065
Average total loss: 0.825915
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1314e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.454774
Average KL loss: 0.371893
Average total loss: 0.826667
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.1539e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.453943
Average KL loss: 0.371688
Average total loss: 0.825631
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.5992e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.452190
Average KL loss: 0.371526
Average total loss: 0.823716
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.2725e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.460450
Average KL loss: 0.371413
Average total loss: 0.831864
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.4340e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.448597
Average KL loss: 0.371297
Average total loss: 0.819894
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.5874e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.445465
Average KL loss: 0.371130
Average total loss: 0.816595
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.8013e-11, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.448060
Average KL loss: 0.370989
Average total loss: 0.819048
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.5376e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.450838
Average KL loss: 0.370846
Average total loss: 0.821685
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.0272e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.455249
Average KL loss: 0.370788
Average total loss: 0.826037
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.3026e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.457189
Average KL loss: 0.370698
Average total loss: 0.827887
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.1475e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.450379
Average KL loss: 0.370604
Average total loss: 0.820983
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-8.6376e-10, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.453385
Average KL loss: 0.370532
Average total loss: 0.823916
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.3887e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.447976
Average KL loss: 0.370426
Average total loss: 0.818402
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.1138e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.456155
Average KL loss: 0.370316
Average total loss: 0.826471
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.5785e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.453079
Average KL loss: 0.370273
Average total loss: 0.823352
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.4769e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.455988
Average KL loss: 0.370151
Average total loss: 0.826139
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.9030e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.448684
Average KL loss: 0.370061
Average total loss: 0.818745
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.1961e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.450052
Average KL loss: 0.369994
Average total loss: 0.820046
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1723e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.451382
Average KL loss: 0.369968
Average total loss: 0.821350
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.9441e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.447480
Average KL loss: 0.369946
Average total loss: 0.817426
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.2595e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.446454
Average KL loss: 0.369925
Average total loss: 0.816379
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.4824e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.452760
Average KL loss: 0.369901
Average total loss: 0.822661
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(4.0891e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.448080
Average KL loss: 0.369879
Average total loss: 0.817959
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.8753e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.453503
Average KL loss: 0.369858
Average total loss: 0.823361
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.7513e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.450159
Average KL loss: 0.369836
Average total loss: 0.819995
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.7005e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.453682
Average KL loss: 0.369815
Average total loss: 0.823497
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(4.0911e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.451451
Average KL loss: 0.369802
Average total loss: 0.821253
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.1358e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.453318
Average KL loss: 0.369781
Average total loss: 0.823099
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.5302e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.459149
Average KL loss: 0.369761
Average total loss: 0.828910
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(5.6800e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.449828
Average KL loss: 0.369747
Average total loss: 0.819575
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.5577e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.451664
Average KL loss: 0.369729
Average total loss: 0.821393
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.6651e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.451637
Average KL loss: 0.369709
Average total loss: 0.821346
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(3.9959e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.451659
Average KL loss: 0.369694
Average total loss: 0.821352
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(2.8226e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.450987
Average KL loss: 0.369691
Average total loss: 0.820678
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(8.1283e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.451024
Average KL loss: 0.369690
Average total loss: 0.820714
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.4460e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.452931
Average KL loss: 0.369689
Average total loss: 0.822620
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-5.4011e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.447162
Average KL loss: 0.369687
Average total loss: 0.816849
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-9.8792e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.447486
Average KL loss: 0.369686
Average total loss: 0.817172
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.0961e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.447913
Average KL loss: 0.369684
Average total loss: 0.817597
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.2739e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.448728
Average KL loss: 0.369683
Average total loss: 0.818411
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1367e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.455824
Average KL loss: 0.369681
Average total loss: 0.825506
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.2390e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.450940
Average KL loss: 0.369679
Average total loss: 0.820619
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(4.5046e-09, device='cuda:0')
 Percentile value: 7.982733052358526e-08
Non-zero model percentage: 20.971534729003906%, Non-zero mask percentage: 20.971534729003906%

--- Pruning Level [7/24]: ---
conv1.weight         | nonzeros =     700 /    1728             ( 40.51%) | total_pruned =    1028 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.weight           | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
bn1.bias             | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    6857 /   36864             ( 18.60%) | total_pruned =   30007 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   10549 /   36864             ( 28.62%) | total_pruned =   26315 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    8029 /   36864             ( 21.78%) | total_pruned =   28835 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    8583 /   36864             ( 23.28%) | total_pruned =   28281 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    7918 /   73728             ( 10.74%) | total_pruned =   65810 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   14715 /  147456             (  9.98%) | total_pruned =  132741 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      15 /     128             ( 11.72%) | total_pruned =     113 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1293 /    8192             ( 15.78%) | total_pruned =    6899 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   20162 /  147456             ( 13.67%) | total_pruned =  127294 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   24160 /  147456             ( 16.38%) | total_pruned =  123296 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   23702 /  294912             (  8.04%) | total_pruned =  271210 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     103 /     256             ( 40.23%) | total_pruned =     153 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      40 /     256             ( 15.62%) | total_pruned =     216 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   47255 /  589824             (  8.01%) | total_pruned =  542569 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     238 /     256             ( 92.97%) | total_pruned =      18 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3802 /   32768             ( 11.60%) | total_pruned =   28966 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     122 /     256             ( 47.66%) | total_pruned =     134 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     181 /     256             ( 70.70%) | total_pruned =      75 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      34 /     256             ( 13.28%) | total_pruned =     222 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   48380 /  589824             (  8.20%) | total_pruned =  541444 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     134 /     256             ( 52.34%) | total_pruned =     122 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   63784 /  589824             ( 10.81%) | total_pruned =  526040 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     131 /     256             ( 51.17%) | total_pruned =     125 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   78627 / 1179648             (  6.67%) | total_pruned = 1101021 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     215 /     512             ( 41.99%) | total_pruned =     297 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     479 /     512             ( 93.55%) | total_pruned =      33 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      55 /     512             ( 10.74%) | total_pruned =     457 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  276561 / 2359296             ( 11.72%) | total_pruned = 2082735 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     224 /     512             ( 43.75%) | total_pruned =     288 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     305 /     512             ( 59.57%) | total_pruned =     207 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      98 /     512             ( 19.14%) | total_pruned =     414 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   18771 /  131072             ( 14.32%) | total_pruned =  112301 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     236 /     512             ( 46.09%) | total_pruned =     276 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     258 /     512             ( 50.39%) | total_pruned =     254 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      99 /     512             ( 19.34%) | total_pruned =     413 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  583575 / 2359296             ( 24.74%) | total_pruned = 1775721 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     231 /     512             ( 45.12%) | total_pruned =     281 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     344 /     512             ( 67.19%) | total_pruned =     168 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1086339 / 2359296             ( 46.05%) | total_pruned = 1272957 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     258 /     512             ( 50.39%) | total_pruned =     254 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     461 /     512             ( 90.04%) | total_pruned =      51 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     373 /     512             ( 72.85%) | total_pruned =     139 | shape = torch.Size([512])
linear.weight        | nonzeros =    3787 /    5120             ( 73.96%) | total_pruned =    1333 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 2344358, pruned : 8834404, total: 11178762, Compression rate :       4.77x  ( 79.03% pruned)
Train Epoch: 67/100 Loss: 0.019904 Accuracy: 87.00 100.00 % Best test Accuracy: 87.19%
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.7521e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.691258
Average KL loss: 0.347197
Average total loss: 1.038455
tensor(0.0032, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.4714e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.631136
Average KL loss: 0.344269
Average total loss: 0.975405
tensor(0.0032, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.2960e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.598927
Average KL loss: 0.347849
Average total loss: 0.946776
tensor(0.0031, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-3.5751e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.584509
Average KL loss: 0.350546
Average total loss: 0.935055
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.1905e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.572740
Average KL loss: 0.353498
Average total loss: 0.926238
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-6.9896e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.561882
Average KL loss: 0.355588
Average total loss: 0.917471
tensor(0.0031, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.7210e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.555027
Average KL loss: 0.357434
Average total loss: 0.912461
tensor(0.0030, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-5.6161e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.557900
Average KL loss: 0.359525
Average total loss: 0.917425
tensor(0.0030, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-2.6303e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.545545
Average KL loss: 0.361489
Average total loss: 0.907034
tensor(0.0030, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-6.8953e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.530063
Average KL loss: 0.362780
Average total loss: 0.892843
tensor(0.0030, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-9.0931e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.531788
Average KL loss: 0.363604
Average total loss: 0.895392
tensor(0.0030, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.1860e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.521037
Average KL loss: 0.364720
Average total loss: 0.885757
tensor(0.0030, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-4.1352e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.528633
Average KL loss: 0.365903
Average total loss: 0.894536
tensor(0.0030, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.3195e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.515128
Average KL loss: 0.367013
Average total loss: 0.882141
tensor(0.0030, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(8.8735e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.512166
Average KL loss: 0.368118
Average total loss: 0.880284
tensor(0.0030, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.4201e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.512539
Average KL loss: 0.368798
Average total loss: 0.881337
tensor(0.0030, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-5.8688e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.510388
Average KL loss: 0.369163
Average total loss: 0.879552
tensor(0.0030, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(1.7998e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.517264
Average KL loss: 0.370174
Average total loss: 0.887438
tensor(0.0030, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-1.0906e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.509782
Average KL loss: 0.370917
Average total loss: 0.880700
tensor(0.0030, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.1329e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.498198
Average KL loss: 0.370988
Average total loss: 0.869186
tensor(0.0030, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-4.9845e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.500188
Average KL loss: 0.371640
Average total loss: 0.871828
tensor(0.0030, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-8.7067e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.503404
Average KL loss: 0.372132
Average total loss: 0.875536
tensor(0.0030, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.2058e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.494976
Average KL loss: 0.372716
Average total loss: 0.867691
tensor(0.0030, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-2.5029e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.495139
Average KL loss: 0.373020
Average total loss: 0.868158
tensor(0.0030, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-3.8562e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.501015
Average KL loss: 0.373649
Average total loss: 0.874664
tensor(0.0030, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(2.1149e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.489774
Average KL loss: 0.373621
Average total loss: 0.863395
tensor(0.0030, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.5806e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.492997
Average KL loss: 0.373829
Average total loss: 0.866826
tensor(0.0030, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.6350e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.496326
Average KL loss: 0.374280
Average total loss: 0.870606
tensor(0.0030, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.9406e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.497905
Average KL loss: 0.374538
Average total loss: 0.872443
tensor(0.0030, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.2834e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.486853
Average KL loss: 0.374810
Average total loss: 0.861662
tensor(0.0030, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.9227e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.495115
Average KL loss: 0.375204
Average total loss: 0.870319
tensor(0.0030, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-2.4961e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.483295
Average KL loss: 0.375321
Average total loss: 0.858616
tensor(0.0030, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.7117e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.486847
Average KL loss: 0.375977
Average total loss: 0.862824
tensor(0.0030, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.7961e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.484429
Average KL loss: 0.376460
Average total loss: 0.860889
tensor(0.0030, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-4.5671e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.487632
Average KL loss: 0.377254
Average total loss: 0.864887
tensor(0.0030, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(6.6864e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.497420
Average KL loss: 0.377160
Average total loss: 0.874580
tensor(0.0030, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.5888e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.483341
Average KL loss: 0.376999
Average total loss: 0.860339
tensor(0.0030, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-2.9830e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.481586
Average KL loss: 0.377475
Average total loss: 0.859061
tensor(0.0030, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(2.7079e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.477692
Average KL loss: 0.377966
Average total loss: 0.855658
tensor(0.0030, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(5.4625e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.481204
Average KL loss: 0.377718
Average total loss: 0.858922
tensor(0.0030, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.9681e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.481798
Average KL loss: 0.377839
Average total loss: 0.859637
tensor(0.0030, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(2.3027e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.475517
Average KL loss: 0.378276
Average total loss: 0.853794
tensor(0.0030, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(5.2371e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.477928
Average KL loss: 0.377919
Average total loss: 0.855847
tensor(0.0030, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.6886e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.476531
Average KL loss: 0.377927
Average total loss: 0.854459
tensor(0.0030, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-8.6326e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.485348
Average KL loss: 0.378195
Average total loss: 0.863543
tensor(0.0030, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-7.2042e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.481322
Average KL loss: 0.378492
Average total loss: 0.859814
tensor(0.0030, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(3.8805e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.475185
Average KL loss: 0.378601
Average total loss: 0.853786
tensor(0.0031, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.8483e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.474090
Average KL loss: 0.378749
Average total loss: 0.852839
tensor(0.0031, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-9.4751e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.473979
Average KL loss: 0.378678
Average total loss: 0.852657
tensor(0.0031, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(6.0465e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.472103
Average KL loss: 0.378514
Average total loss: 0.850617
tensor(0.0031, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.6486e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.475445
Average KL loss: 0.378762
Average total loss: 0.854206
tensor(0.0031, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.6352e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.471953
Average KL loss: 0.379233
Average total loss: 0.851186
tensor(0.0031, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(1.7979e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.477802
Average KL loss: 0.379459
Average total loss: 0.857261
tensor(0.0031, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.6638e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.474466
Average KL loss: 0.379375
Average total loss: 0.853841
tensor(0.0031, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.3071e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.470332
Average KL loss: 0.379503
Average total loss: 0.849834
tensor(0.0031, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.1862e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.466232
Average KL loss: 0.379922
Average total loss: 0.846154
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.1812e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.470265
Average KL loss: 0.379546
Average total loss: 0.849811
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.4143e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.475332
Average KL loss: 0.379870
Average total loss: 0.855202
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.7389e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.474119
Average KL loss: 0.380432
Average total loss: 0.854551
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.1856e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.475156
Average KL loss: 0.380222
Average total loss: 0.855378
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.9284e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.468217
Average KL loss: 0.380753
Average total loss: 0.848970
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(1.9878e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.466054
Average KL loss: 0.380806
Average total loss: 0.846860
tensor(0.0031, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.5116e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.469455
Average KL loss: 0.380778
Average total loss: 0.850233
tensor(0.0031, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.6905e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.468098
Average KL loss: 0.380587
Average total loss: 0.848685
tensor(0.0031, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-9.0547e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.470020
Average KL loss: 0.380811
Average total loss: 0.850830
tensor(0.0031, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-8.0676e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.464230
Average KL loss: 0.380730
Average total loss: 0.844961
tensor(0.0031, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-8.1229e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.465060
Average KL loss: 0.381034
Average total loss: 0.846094
tensor(0.0031, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.4794e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.470768
Average KL loss: 0.381086
Average total loss: 0.851855
tensor(0.0031, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(8.7450e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.469196
Average KL loss: 0.380963
Average total loss: 0.850159
tensor(0.0031, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.3031e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.474400
Average KL loss: 0.380695
Average total loss: 0.855095
tensor(0.0031, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-4.8369e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.462289
Average KL loss: 0.380780
Average total loss: 0.843069
tensor(0.0031, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.5148e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.467106
Average KL loss: 0.381016
Average total loss: 0.848122
tensor(0.0031, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.2057e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.462722
Average KL loss: 0.380973
Average total loss: 0.843695
tensor(0.0031, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(3.9305e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.463169
Average KL loss: 0.380890
Average total loss: 0.844059
tensor(0.0031, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.6338e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.464602
Average KL loss: 0.381068
Average total loss: 0.845670
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.9259e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.466745
Average KL loss: 0.381658
Average total loss: 0.848404
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.1539e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.464593
Average KL loss: 0.381829
Average total loss: 0.846422
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-9.9805e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.456763
Average KL loss: 0.381947
Average total loss: 0.838709
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.9754e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.468164
Average KL loss: 0.381782
Average total loss: 0.849946
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.3290e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.468272
Average KL loss: 0.381584
Average total loss: 0.849856
tensor(0.0031, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(3.4825e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.464292
Average KL loss: 0.381872
Average total loss: 0.846164
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.3837e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.461953
Average KL loss: 0.382117
Average total loss: 0.844070
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.6773e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.464832
Average KL loss: 0.382257
Average total loss: 0.847089
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(6.1722e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.464385
Average KL loss: 0.382529
Average total loss: 0.846914
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.2519e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.462508
Average KL loss: 0.382514
Average total loss: 0.845022
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.1909e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.464246
Average KL loss: 0.382416
Average total loss: 0.846662
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.4509e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.467906
Average KL loss: 0.382636
Average total loss: 0.850542
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.6002e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.461743
Average KL loss: 0.382497
Average total loss: 0.844240
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.0536e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.462099
Average KL loss: 0.382268
Average total loss: 0.844367
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.4972e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.463405
Average KL loss: 0.381796
Average total loss: 0.845201
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.9646e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.458623
Average KL loss: 0.381141
Average total loss: 0.839764
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.1518e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.460737
Average KL loss: 0.380584
Average total loss: 0.841321
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.2149e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.464416
Average KL loss: 0.380110
Average total loss: 0.844527
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.8232e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.462349
Average KL loss: 0.379659
Average total loss: 0.842008
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.6154e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.463117
Average KL loss: 0.379258
Average total loss: 0.842375
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.8145e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.465556
Average KL loss: 0.378893
Average total loss: 0.844449
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.4320e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.459723
Average KL loss: 0.378571
Average total loss: 0.838294
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.6640e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.463232
Average KL loss: 0.378186
Average total loss: 0.841418
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.3000e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.466084
Average KL loss: 0.377861
Average total loss: 0.843945
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.3081e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.464682
Average KL loss: 0.377555
Average total loss: 0.842237
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.7123e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.463010
Average KL loss: 0.377314
Average total loss: 0.840324
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-6.6701e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.456565
Average KL loss: 0.377084
Average total loss: 0.833649
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.4339e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.460034
Average KL loss: 0.376845
Average total loss: 0.836879
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.6951e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.462501
Average KL loss: 0.376612
Average total loss: 0.839113
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.0961e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.462288
Average KL loss: 0.376400
Average total loss: 0.838688
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.3400e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.455600
Average KL loss: 0.376136
Average total loss: 0.831736
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.3757e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.458765
Average KL loss: 0.375919
Average total loss: 0.834684
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(1.0413e-11, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.464211
Average KL loss: 0.375745
Average total loss: 0.839956
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(3.9059e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.459443
Average KL loss: 0.375525
Average total loss: 0.834968
tensor(0.0031, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.9965e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.459568
Average KL loss: 0.375318
Average total loss: 0.834886
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.3669e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.461799
Average KL loss: 0.375101
Average total loss: 0.836900
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.1914e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.463570
Average KL loss: 0.374913
Average total loss: 0.838483
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.2496e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.462767
Average KL loss: 0.374739
Average total loss: 0.837506
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.3730e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.461172
Average KL loss: 0.374573
Average total loss: 0.835745
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.8317e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.459319
Average KL loss: 0.374408
Average total loss: 0.833727
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.0840e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.459022
Average KL loss: 0.374270
Average total loss: 0.833293
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.3676e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.458100
Average KL loss: 0.374096
Average total loss: 0.832196
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.5720e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.461779
Average KL loss: 0.374007
Average total loss: 0.835786
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.7964e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.458175
Average KL loss: 0.373976
Average total loss: 0.832151
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.0693e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.460694
Average KL loss: 0.373953
Average total loss: 0.834647
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.7518e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.455063
Average KL loss: 0.373929
Average total loss: 0.828992
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.8459e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.455179
Average KL loss: 0.373902
Average total loss: 0.829081
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.6829e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.458405
Average KL loss: 0.373875
Average total loss: 0.832280
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.4913e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.462602
Average KL loss: 0.373850
Average total loss: 0.836452
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.3516e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.455514
Average KL loss: 0.373829
Average total loss: 0.829343
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(5.7616e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.461655
Average KL loss: 0.373809
Average total loss: 0.835465
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.3306e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.455462
Average KL loss: 0.373789
Average total loss: 0.829251
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.5690e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.460022
Average KL loss: 0.373772
Average total loss: 0.833794
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(4.4530e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.460897
Average KL loss: 0.373751
Average total loss: 0.834648
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.5616e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.453883
Average KL loss: 0.373726
Average total loss: 0.827609
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.4420e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.459239
Average KL loss: 0.373704
Average total loss: 0.832943
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.3705e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.456657
Average KL loss: 0.373676
Average total loss: 0.830333
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.8783e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.458833
Average KL loss: 0.373651
Average total loss: 0.832483
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.0505e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.462550
Average KL loss: 0.373631
Average total loss: 0.836181
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(6.4051e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.463886
Average KL loss: 0.373607
Average total loss: 0.837492
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(3.8577e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.455861
Average KL loss: 0.373587
Average total loss: 0.829448
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(1.1662e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.456943
Average KL loss: 0.373566
Average total loss: 0.830509
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(9.4458e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.457089
Average KL loss: 0.373548
Average total loss: 0.830637
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.2286e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.458384
Average KL loss: 0.373533
Average total loss: 0.831917
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.6440e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.464275
Average KL loss: 0.373515
Average total loss: 0.837790
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.8306e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.456751
Average KL loss: 0.373495
Average total loss: 0.830246
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.2538e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.463296
Average KL loss: 0.373484
Average total loss: 0.836779
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.9953e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.462012
Average KL loss: 0.373482
Average total loss: 0.835494
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.8688e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.460345
Average KL loss: 0.373480
Average total loss: 0.833825
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.1376e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.464007
Average KL loss: 0.373478
Average total loss: 0.837485
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(6.8556e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.459598
Average KL loss: 0.373477
Average total loss: 0.833075
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(2.1218e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.457562
Average KL loss: 0.373474
Average total loss: 0.831036
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-5.3052e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.459295
Average KL loss: 0.373472
Average total loss: 0.832767
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-4.7757e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.460283
Average KL loss: 0.373470
Average total loss: 0.833754
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.2518e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.459798
Average KL loss: 0.373468
Average total loss: 0.833266
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.9494e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.461990
Average KL loss: 0.373466
Average total loss: 0.835456
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.6945e-09, device='cuda:0')
 Percentile value: 7.981464733575194e-08
Non-zero model percentage: 16.777233123779297%, Non-zero mask percentage: 16.777233123779297%

--- Pruning Level [8/24]: ---
conv1.weight         | nonzeros =     321 /    1728             ( 18.58%) | total_pruned =    1407 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.weight           | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
bn1.bias             | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2933 /   36864             (  7.96%) | total_pruned =   33931 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4952 /   36864             ( 13.43%) | total_pruned =   31912 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3887 /   36864             ( 10.54%) | total_pruned =   32977 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4491 /   36864             ( 12.18%) | total_pruned =   32373 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4635 /   73728             (  6.29%) | total_pruned =   69093 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    8374 /  147456             (  5.68%) | total_pruned =  139082 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     736 /    8192             (  8.98%) | total_pruned =    7456 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   10365 /  147456             (  7.03%) | total_pruned =  137091 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   12318 /  147456             (  8.35%) | total_pruned =  135138 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   13719 /  294912             (  4.65%) | total_pruned =  281193 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      82 /     256             ( 32.03%) | total_pruned =     174 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      29 /     256             ( 11.33%) | total_pruned =     227 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   26951 /  589824             (  4.57%) | total_pruned =  562873 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      85 /     256             ( 33.20%) | total_pruned =     171 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     227 /     256             ( 88.67%) | total_pruned =      29 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      23 /     256             (  8.98%) | total_pruned =     233 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2246 /   32768             (  6.85%) | total_pruned =   30522 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      90 /     256             ( 35.16%) | total_pruned =     166 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   26485 /  589824             (  4.49%) | total_pruned =  563339 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      96 /     256             ( 37.50%) | total_pruned =     160 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   43817 /  589824             (  7.43%) | total_pruned =  546007 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     108 /     256             ( 42.19%) | total_pruned =     148 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   61087 / 1179648             (  5.18%) | total_pruned = 1118561 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     160 /     512             ( 31.25%) | total_pruned =     352 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     462 /     512             ( 90.23%) | total_pruned =      50 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      49 /     512             (  9.57%) | total_pruned =     463 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  221787 / 2359296             (  9.40%) | total_pruned = 2137509 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     182 /     512             ( 35.55%) | total_pruned =     330 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     278 /     512             ( 54.30%) | total_pruned =     234 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      93 /     512             ( 18.16%) | total_pruned =     419 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   14983 /  131072             ( 11.43%) | total_pruned =  116089 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     180 /     512             ( 35.16%) | total_pruned =     332 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     219 /     512             ( 42.77%) | total_pruned =     293 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      95 /     512             ( 18.55%) | total_pruned =     417 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  485583 / 2359296             ( 20.58%) | total_pruned = 1873713 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     178 /     512             ( 34.77%) | total_pruned =     334 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     301 /     512             ( 58.79%) | total_pruned =     211 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  916831 / 2359296             ( 38.86%) | total_pruned = 1442465 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     202 /     512             ( 39.45%) | total_pruned =     310 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     421 /     512             ( 82.23%) | total_pruned =      91 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     322 /     512             ( 62.89%) | total_pruned =     190 | shape = torch.Size([512])
linear.weight        | nonzeros =    3304 /    5120             ( 64.53%) | total_pruned =    1816 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 1875487, pruned : 9303275, total: 11178762, Compression rate :       5.96x  ( 83.22% pruned)
Train Epoch: 71/100 Loss: 0.024885 Accuracy: 86.57 100.00 % Best test Accuracy: 86.94%
tensor(0.0031, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.1253e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.783107
Average KL loss: 0.349932
Average total loss: 1.133039
tensor(0.0030, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.0520e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.715359
Average KL loss: 0.342863
Average total loss: 1.058222
tensor(0.0029, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-2.7688e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.691263
Average KL loss: 0.344463
Average total loss: 1.035726
tensor(0.0029, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.3824e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.664813
Average KL loss: 0.346824
Average total loss: 1.011637
tensor(0.0029, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-8.8442e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.652238
Average KL loss: 0.348647
Average total loss: 1.000885
tensor(0.0029, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-4.5592e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.632125
Average KL loss: 0.350593
Average total loss: 0.982718
tensor(0.0028, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.4716e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.615862
Average KL loss: 0.352389
Average total loss: 0.968252
tensor(0.0028, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.0560e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.602028
Average KL loss: 0.354430
Average total loss: 0.956457
tensor(0.0028, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-1.2125e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.600861
Average KL loss: 0.357083
Average total loss: 0.957944
tensor(0.0028, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.6821e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.587557
Average KL loss: 0.359471
Average total loss: 0.947028
tensor(0.0028, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.3714e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.584704
Average KL loss: 0.361482
Average total loss: 0.946186
tensor(0.0028, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-6.1190e-09, device='cuda:0')
