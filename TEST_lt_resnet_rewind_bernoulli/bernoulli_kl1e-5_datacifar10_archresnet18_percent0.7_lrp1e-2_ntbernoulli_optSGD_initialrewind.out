Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/8]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2495e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302564
Average KL loss: 0.000500
Average total loss: 2.303064
tensor(7.6487e-05, device='cuda:0') tensor(3.5076e-05, device='cuda:0') tensor(-3.8485e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.301695
Average KL loss: 0.001069
Average total loss: 2.302764
tensor(0.0003, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-1.3330e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.282632
Average KL loss: 0.004838
Average total loss: 2.287470
tensor(0.0018, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-2.7959e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.006642
Average KL loss: 0.039386
Average total loss: 2.046029
tensor(0.0096, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-1.2844e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.444332
Average KL loss: 0.106510
Average total loss: 1.550842
tensor(0.0133, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-9.4699e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.050513
Average KL loss: 0.139389
Average total loss: 1.189902
tensor(0.0139, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-7.3141e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.853224
Average KL loss: 0.146624
Average total loss: 0.999848
tensor(0.0134, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-5.8211e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.737139
Average KL loss: 0.145759
Average total loss: 0.882899
tensor(0.0132, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-2.9181e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.650316
Average KL loss: 0.143699
Average total loss: 0.794015
tensor(0.0127, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.7861e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.597376
Average KL loss: 0.140005
Average total loss: 0.737382
tensor(0.0124, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-3.5607e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.559680
Average KL loss: 0.137209
Average total loss: 0.696889
tensor(0.0123, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-3.3669e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.539250
Average KL loss: 0.135701
Average total loss: 0.674951
tensor(0.0120, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.9774e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.498233
Average KL loss: 0.134435
Average total loss: 0.632668
tensor(0.0120, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.8701e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.462583
Average KL loss: 0.131944
Average total loss: 0.594527
tensor(0.0117, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-4.6733e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.438513
Average KL loss: 0.129735
Average total loss: 0.568248
tensor(0.0116, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-3.3913e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.421607
Average KL loss: 0.127925
Average total loss: 0.549532
tensor(0.0116, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-2.3345e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.402548
Average KL loss: 0.126253
Average total loss: 0.528802
tensor(0.0115, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-3.1518e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.385932
Average KL loss: 0.124723
Average total loss: 0.510655
tensor(0.0113, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-2.3247e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.372559
Average KL loss: 0.123239
Average total loss: 0.495798
tensor(0.0113, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.8899e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.360962
Average KL loss: 0.121612
Average total loss: 0.482574
tensor(0.0112, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.6826e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.351820
Average KL loss: 0.120835
Average total loss: 0.472656
tensor(0.0112, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.8407e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.334454
Average KL loss: 0.119843
Average total loss: 0.454297
tensor(0.0112, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.9755e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.330196
Average KL loss: 0.119264
Average total loss: 0.449459
tensor(0.0111, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-2.1628e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.316995
Average KL loss: 0.118542
Average total loss: 0.435537
tensor(0.0110, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.5594e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.316221
Average KL loss: 0.117440
Average total loss: 0.433661
tensor(0.0110, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.6141e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.303528
Average KL loss: 0.116897
Average total loss: 0.420425
tensor(0.0110, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.0436e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.294821
Average KL loss: 0.116214
Average total loss: 0.411035
tensor(0.0110, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.4228e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.294668
Average KL loss: 0.115550
Average total loss: 0.410218
tensor(0.0110, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.6191e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.275515
Average KL loss: 0.114529
Average total loss: 0.390043
tensor(0.0108, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.7645e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.279202
Average KL loss: 0.113496
Average total loss: 0.392698
tensor(0.0108, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.4536e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.269773
Average KL loss: 0.112866
Average total loss: 0.382639
tensor(0.0108, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.2158e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.261288
Average KL loss: 0.111971
Average total loss: 0.373259
tensor(0.0108, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-8.8445e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.260588
Average KL loss: 0.111195
Average total loss: 0.371784
tensor(0.0107, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.5584e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.259452
Average KL loss: 0.111320
Average total loss: 0.370772
tensor(0.0108, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-7.5467e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.251179
Average KL loss: 0.110552
Average total loss: 0.361732
tensor(0.0107, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.2371e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.249211
Average KL loss: 0.110356
Average total loss: 0.359567
tensor(0.0107, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.1239e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.240621
Average KL loss: 0.109680
Average total loss: 0.350301
tensor(0.0107, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-7.3965e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.239300
Average KL loss: 0.109155
Average total loss: 0.348455
tensor(0.0107, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.1758e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.232368
Average KL loss: 0.108896
Average total loss: 0.341264
tensor(0.0107, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-8.7357e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.237194
Average KL loss: 0.108880
Average total loss: 0.346074
tensor(0.0107, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-7.8926e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.226131
Average KL loss: 0.108298
Average total loss: 0.334429
tensor(0.0107, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-7.7866e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.225679
Average KL loss: 0.107592
Average total loss: 0.333271
tensor(0.0107, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.0621e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.220496
Average KL loss: 0.107039
Average total loss: 0.327535
tensor(0.0107, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-8.2760e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.221924
Average KL loss: 0.106903
Average total loss: 0.328827
tensor(0.0107, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-7.9839e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.215022
Average KL loss: 0.106556
Average total loss: 0.321578
tensor(0.0106, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-4.6431e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.212421
Average KL loss: 0.106221
Average total loss: 0.318642
tensor(0.0107, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-2.6877e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.213750
Average KL loss: 0.105828
Average total loss: 0.319578
tensor(0.0107, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-8.8351e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.207954
Average KL loss: 0.106147
Average total loss: 0.314101
tensor(0.0107, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-9.7096e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.209205
Average KL loss: 0.105555
Average total loss: 0.314760
tensor(0.0106, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-9.2697e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.201605
Average KL loss: 0.105178
Average total loss: 0.306783
tensor(0.0106, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-6.1854e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.203634
Average KL loss: 0.104791
Average total loss: 0.308425
tensor(0.0106, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-6.7955e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.201259
Average KL loss: 0.104495
Average total loss: 0.305754
tensor(0.0106, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.2037e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.200895
Average KL loss: 0.104371
Average total loss: 0.305266
tensor(0.0107, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-7.3664e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.194829
Average KL loss: 0.104563
Average total loss: 0.299392
tensor(0.0107, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-8.2347e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.190186
Average KL loss: 0.103683
Average total loss: 0.293870
tensor(0.0107, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-7.2331e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.192425
Average KL loss: 0.103628
Average total loss: 0.296053
tensor(0.0107, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-8.9003e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.192378
Average KL loss: 0.103495
Average total loss: 0.295873
tensor(0.0107, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-7.7739e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.185988
Average KL loss: 0.103042
Average total loss: 0.289030
tensor(0.0106, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-5.7787e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.185983
Average KL loss: 0.102868
Average total loss: 0.288851
tensor(0.0107, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-6.5726e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.187530
Average KL loss: 0.102887
Average total loss: 0.290417
tensor(0.0106, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.4548e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.181874
Average KL loss: 0.102761
Average total loss: 0.284635
tensor(0.0106, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.7312e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.182940
Average KL loss: 0.102400
Average total loss: 0.285340
tensor(0.0107, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-5.0262e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.180391
Average KL loss: 0.102317
Average total loss: 0.282708
tensor(0.0106, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.6666e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.178004
Average KL loss: 0.102136
Average total loss: 0.280141
tensor(0.0106, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-3.4630e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.178429
Average KL loss: 0.101901
Average total loss: 0.280330
tensor(0.0106, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-6.5493e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.176254
Average KL loss: 0.101581
Average total loss: 0.277834
tensor(0.0106, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-4.2553e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.171436
Average KL loss: 0.100969
Average total loss: 0.272405
tensor(0.0107, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-6.4758e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.174391
Average KL loss: 0.100904
Average total loss: 0.275295
tensor(0.0106, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.9303e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.174126
Average KL loss: 0.101081
Average total loss: 0.275207
tensor(0.0106, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-5.8292e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.172571
Average KL loss: 0.101363
Average total loss: 0.273935
tensor(0.0106, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-5.9867e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.172196
Average KL loss: 0.101540
Average total loss: 0.273736
tensor(0.0107, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(2.1698e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.171307
Average KL loss: 0.101518
Average total loss: 0.272825
tensor(0.0106, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.6367e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.171666
Average KL loss: 0.101483
Average total loss: 0.273148
tensor(0.0107, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-2.9029e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.167767
Average KL loss: 0.101391
Average total loss: 0.269158
tensor(0.0107, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-4.6315e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.164638
Average KL loss: 0.100851
Average total loss: 0.265489
tensor(0.0106, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-3.4123e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.164945
Average KL loss: 0.100463
Average total loss: 0.265408
tensor(0.0107, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.7286e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.163332
Average KL loss: 0.100505
Average total loss: 0.263837
tensor(0.0107, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.2660e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.164677
Average KL loss: 0.100462
Average total loss: 0.265139
tensor(0.0107, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.6419e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.161558
Average KL loss: 0.100600
Average total loss: 0.262158
tensor(0.0106, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.0041e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.161499
Average KL loss: 0.100252
Average total loss: 0.261751
tensor(0.0107, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.9843e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.157930
Average KL loss: 0.100193
Average total loss: 0.258123
tensor(0.0106, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.4387e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.161412
Average KL loss: 0.100008
Average total loss: 0.261420
tensor(0.0106, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-5.7085e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.160924
Average KL loss: 0.100285
Average total loss: 0.261208
tensor(0.0106, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-3.6761e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.158146
Average KL loss: 0.100120
Average total loss: 0.258265
tensor(0.0107, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.8419e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.158239
Average KL loss: 0.100271
Average total loss: 0.258510
tensor(0.0107, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-4.6433e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.158332
Average KL loss: 0.100229
Average total loss: 0.258561
tensor(0.0107, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.1905e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.154110
Average KL loss: 0.100096
Average total loss: 0.254206
tensor(0.0107, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-3.7583e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.156293
Average KL loss: 0.099710
Average total loss: 0.256002
tensor(0.0107, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.5104e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.152861
Average KL loss: 0.099843
Average total loss: 0.252704
tensor(0.0107, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.5939e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.154069
Average KL loss: 0.099536
Average total loss: 0.253605
tensor(0.0107, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.3257e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.152916
Average KL loss: 0.099761
Average total loss: 0.252678
tensor(0.0107, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-4.9510e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.151247
Average KL loss: 0.099556
Average total loss: 0.250803
tensor(0.0107, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(1.3727e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.152220
Average KL loss: 0.099424
Average total loss: 0.251644
tensor(0.0107, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.9681e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.151915
Average KL loss: 0.099694
Average total loss: 0.251609
tensor(0.0107, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(3.6134e-11, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.151946
Average KL loss: 0.099866
Average total loss: 0.251812
tensor(0.0107, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.1153e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.149003
Average KL loss: 0.099500
Average total loss: 0.248503
tensor(0.0107, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.7590e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.149994
Average KL loss: 0.099307
Average total loss: 0.249301
tensor(0.0107, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(4.8766e-11, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.149718
Average KL loss: 0.099514
Average total loss: 0.249232
tensor(0.0107, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-3.6639e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.148058
Average KL loss: 0.099349
Average total loss: 0.247407
tensor(0.0107, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-3.0299e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.148045
Average KL loss: 0.099394
Average total loss: 0.247439
tensor(0.0107, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-3.3734e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.147105
Average KL loss: 0.099140
Average total loss: 0.246245
tensor(0.0106, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-6.1595e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.147648
Average KL loss: 0.099276
Average total loss: 0.246924
tensor(0.0106, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-5.0141e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.145933
Average KL loss: 0.099014
Average total loss: 0.244947
tensor(0.0106, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-8.1983e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.148665
Average KL loss: 0.099323
Average total loss: 0.247988
tensor(0.0107, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-7.4238e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.141160
Average KL loss: 0.099126
Average total loss: 0.240285
tensor(0.0107, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-2.5719e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.143483
Average KL loss: 0.098940
Average total loss: 0.242423
tensor(0.0106, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-9.7711e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.143464
Average KL loss: 0.098851
Average total loss: 0.242315
tensor(0.0107, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-3.4925e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.144339
Average KL loss: 0.098792
Average total loss: 0.243131
tensor(0.0107, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(1.2250e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.142865
Average KL loss: 0.099283
Average total loss: 0.242148
tensor(0.0107, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-3.2516e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.142792
Average KL loss: 0.099108
Average total loss: 0.241901
tensor(0.0106, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-2.1319e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.140531
Average KL loss: 0.098905
Average total loss: 0.239436
tensor(0.0107, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(2.8490e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.141103
Average KL loss: 0.098577
Average total loss: 0.239680
tensor(0.0106, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.6779e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.140750
Average KL loss: 0.098782
Average total loss: 0.239532
tensor(0.0106, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-7.6456e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.141860
Average KL loss: 0.098792
Average total loss: 0.240651
tensor(0.0106, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(1.4308e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.139076
Average KL loss: 0.098853
Average total loss: 0.237929
tensor(0.0106, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-5.4494e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.142094
Average KL loss: 0.098804
Average total loss: 0.240898
tensor(0.0106, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(4.8459e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.141122
Average KL loss: 0.099010
Average total loss: 0.240132
tensor(0.0106, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-2.8428e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.138782
Average KL loss: 0.098923
Average total loss: 0.237704
tensor(0.0106, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(6.9124e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.138701
Average KL loss: 0.098674
Average total loss: 0.237374
tensor(0.0106, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.1235e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.138555
Average KL loss: 0.098573
Average total loss: 0.237128
tensor(0.0106, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.0242e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.140295
Average KL loss: 0.098744
Average total loss: 0.239040
tensor(0.0107, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-3.7390e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.138721
Average KL loss: 0.099100
Average total loss: 0.237822
tensor(0.0106, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-4.8196e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.136878
Average KL loss: 0.098804
Average total loss: 0.235682
tensor(0.0106, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-1.5130e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.138007
Average KL loss: 0.098730
Average total loss: 0.236737
tensor(0.0107, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-8.7487e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.137395
Average KL loss: 0.098794
Average total loss: 0.236189
tensor(0.0106, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-2.2471e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.136747
Average KL loss: 0.098811
Average total loss: 0.235558
tensor(0.0107, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-6.4143e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.137932
Average KL loss: 0.098643
Average total loss: 0.236576
tensor(0.0107, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-8.3280e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.137960
Average KL loss: 0.099253
Average total loss: 0.237213
tensor(0.0107, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(1.7124e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.135366
Average KL loss: 0.099149
Average total loss: 0.234514
tensor(0.0106, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-2.8124e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.134990
Average KL loss: 0.098961
Average total loss: 0.233951
tensor(0.0106, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-1.0508e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.135223
Average KL loss: 0.098711
Average total loss: 0.233934
tensor(0.0107, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-7.1163e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.135545
Average KL loss: 0.099045
Average total loss: 0.234590
tensor(0.0107, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-1.6853e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.136011
Average KL loss: 0.099040
Average total loss: 0.235051
tensor(0.0107, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(5.6815e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.135323
Average KL loss: 0.098813
Average total loss: 0.234136
tensor(0.0107, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.2994e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.135480
Average KL loss: 0.099058
Average total loss: 0.234538
tensor(0.0107, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-1.0000e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.133636
Average KL loss: 0.098960
Average total loss: 0.232596
tensor(0.0107, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-7.2795e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.135387
Average KL loss: 0.099083
Average total loss: 0.234469
tensor(0.0107, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-1.4875e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.132790
Average KL loss: 0.099066
Average total loss: 0.231856
tensor(0.0106, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-8.4984e-11, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.132469
Average KL loss: 0.098924
Average total loss: 0.231393
tensor(0.0106, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-1.7925e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.131093
Average KL loss: 0.098715
Average total loss: 0.229808
tensor(0.0107, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-1.1236e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.132477
Average KL loss: 0.098617
Average total loss: 0.231094
tensor(0.0107, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.4687e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.132405
Average KL loss: 0.098382
Average total loss: 0.230787
tensor(0.0106, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(3.9400e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.133711
Average KL loss: 0.098675
Average total loss: 0.232386
tensor(0.0106, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-2.9745e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.132492
Average KL loss: 0.098879
Average total loss: 0.231372
tensor(0.0107, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-2.2167e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.132412
Average KL loss: 0.099044
Average total loss: 0.231456
tensor(0.0107, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(2.4374e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.132159
Average KL loss: 0.098740
Average total loss: 0.230899
tensor(0.0106, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-8.1472e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.131354
Average KL loss: 0.098665
Average total loss: 0.230019
tensor(0.0107, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(1.4786e-11, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.131613
Average KL loss: 0.098868
Average total loss: 0.230481
tensor(0.0106, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(6.0522e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.128837
Average KL loss: 0.098691
Average total loss: 0.227528
tensor(0.0107, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-1.0329e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.131643
Average KL loss: 0.098561
Average total loss: 0.230204
tensor(0.0107, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-2.0246e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.131208
Average KL loss: 0.098700
Average total loss: 0.229908
tensor(0.0107, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-1.2002e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.130435
Average KL loss: 0.098986
Average total loss: 0.229422
tensor(0.0107, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.5300e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.130097
Average KL loss: 0.098504
Average total loss: 0.228600
tensor(0.0107, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(1.0880e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.129431
Average KL loss: 0.098887
Average total loss: 0.228318
tensor(0.0107, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(1.2609e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.130057
Average KL loss: 0.099167
Average total loss: 0.229224
tensor(0.0107, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(1.8203e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.128454
Average KL loss: 0.098650
Average total loss: 0.227104
tensor(0.0107, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-1.5809e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.127743
Average KL loss: 0.098033
Average total loss: 0.225776
tensor(0.0107, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.4410e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.129113
Average KL loss: 0.098270
Average total loss: 0.227383
tensor(0.0107, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(6.8866e-11, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.129482
Average KL loss: 0.098600
Average total loss: 0.228082
tensor(0.0107, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-1.2111e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.128964
Average KL loss: 0.098558
Average total loss: 0.227522
tensor(0.0107, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-7.8264e-10, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.127787
Average KL loss: 0.098492
Average total loss: 0.226279
tensor(0.0107, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.9323e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.126841
Average KL loss: 0.098564
Average total loss: 0.225405
tensor(0.0107, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.3081e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.127436
Average KL loss: 0.098188
Average total loss: 0.225624
tensor(0.0107, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-2.4387e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.127832
Average KL loss: 0.098341
Average total loss: 0.226173
tensor(0.0107, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-2.3279e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.128439
Average KL loss: 0.098586
Average total loss: 0.227026
tensor(0.0107, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.1384e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.126644
Average KL loss: 0.098519
Average total loss: 0.225163
tensor(0.0106, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.5120e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.127284
Average KL loss: 0.098488
Average total loss: 0.225772
tensor(0.0107, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-7.1320e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.126771
Average KL loss: 0.098399
Average total loss: 0.225170
tensor(0.0106, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(3.3613e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.129075
Average KL loss: 0.098430
Average total loss: 0.227505
tensor(0.0107, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-1.0284e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.126040
Average KL loss: 0.098654
Average total loss: 0.224694
tensor(0.0107, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(6.4055e-11, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.125921
Average KL loss: 0.098355
Average total loss: 0.224277
tensor(0.0107, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-8.5788e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.126847
Average KL loss: 0.098434
Average total loss: 0.225281
tensor(0.0107, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(4.8553e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.125048
Average KL loss: 0.098286
Average total loss: 0.223334
tensor(0.0107, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-1.0315e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.124365
Average KL loss: 0.097974
Average total loss: 0.222338
tensor(0.0106, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-3.8978e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.126596
Average KL loss: 0.098147
Average total loss: 0.224744
tensor(0.0107, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(5.2515e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.126425
Average KL loss: 0.098549
Average total loss: 0.224974
tensor(0.0107, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-5.8284e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.124599
Average KL loss: 0.098512
Average total loss: 0.223111
tensor(0.0107, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(9.6623e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.125169
Average KL loss: 0.098222
Average total loss: 0.223390
tensor(0.0107, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.2758e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.126715
Average KL loss: 0.098595
Average total loss: 0.225310
tensor(0.0107, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-2.1160e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.126356
Average KL loss: 0.098706
Average total loss: 0.225062
tensor(0.0107, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-1.3962e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.125176
Average KL loss: 0.098846
Average total loss: 0.224021
tensor(0.0107, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(1.3091e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.125398
Average KL loss: 0.098801
Average total loss: 0.224199
tensor(0.0107, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(6.8943e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.125241
Average KL loss: 0.098792
Average total loss: 0.224033
tensor(0.0107, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(2.0465e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.125953
Average KL loss: 0.098806
Average total loss: 0.224759
tensor(0.0107, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-8.9131e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.126171
Average KL loss: 0.099003
Average total loss: 0.225173
tensor(0.0107, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-1.6468e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.124003
Average KL loss: 0.097839
Average total loss: 0.221842
tensor(0.0107, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.0247e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.124168
Average KL loss: 0.095978
Average total loss: 0.220147
tensor(0.0107, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-5.2381e-11, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.124132
Average KL loss: 0.094656
Average total loss: 0.218788
tensor(0.0107, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(8.7250e-10, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.122286
Average KL loss: 0.093625
Average total loss: 0.215911
tensor(0.0107, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(7.2177e-11, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.122762
Average KL loss: 0.092770
Average total loss: 0.215532
tensor(0.0107, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-2.0024e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.122101
Average KL loss: 0.092040
Average total loss: 0.214141
tensor(0.0107, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(9.8727e-11, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.122740
Average KL loss: 0.091405
Average total loss: 0.214145
tensor(0.0107, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(1.2235e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.121205
Average KL loss: 0.090840
Average total loss: 0.212045
tensor(0.0107, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(3.8293e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.121845
Average KL loss: 0.090334
Average total loss: 0.212179
tensor(0.0107, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-1.7419e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.122182
Average KL loss: 0.089873
Average total loss: 0.212054
tensor(0.0107, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-5.3790e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.122593
Average KL loss: 0.089470
Average total loss: 0.212063
tensor(0.0107, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-5.4101e-10, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.122677
Average KL loss: 0.089099
Average total loss: 0.211776
tensor(0.0107, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-5.7147e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.123040
Average KL loss: 0.088774
Average total loss: 0.211814
tensor(0.0107, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(1.5860e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.123771
Average KL loss: 0.088484
Average total loss: 0.212256
tensor(0.0107, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-1.8158e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.123274
Average KL loss: 0.088240
Average total loss: 0.211514
 Percentile value: 0.032879696041345566
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/8]: ---
conv1.weight         | nonzeros =     484 /    1728             ( 28.01%) | total_pruned =    1244 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
bn1.bias             | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5544 /   36864             ( 15.04%) | total_pruned =   31320 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   12263 /   36864             ( 33.27%) | total_pruned =   24601 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   12110 /   36864             ( 32.85%) | total_pruned =   24754 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   14179 /   36864             ( 38.46%) | total_pruned =   22685 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   35129 /   73728             ( 47.65%) | total_pruned =   38599 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   70134 /  147456             ( 47.56%) | total_pruned =   77322 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4705 /    8192             ( 57.43%) | total_pruned =    3487 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   51761 /  147456             ( 35.10%) | total_pruned =   95695 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   48727 /  147456             ( 33.05%) | total_pruned =   98729 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  142640 /  294912             ( 48.37%) | total_pruned =  152272 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     168 /     256             ( 65.62%) | total_pruned =      88 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  275819 /  589824             ( 46.76%) | total_pruned =  314005 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     140 /     256             ( 54.69%) | total_pruned =     116 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   16605 /   32768             ( 50.67%) | total_pruned =   16163 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  233695 /  589824             ( 39.62%) | total_pruned =  356129 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  197496 /  589824             ( 33.48%) | total_pruned =  392328 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     144 /     256             ( 56.25%) | total_pruned =     112 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  460030 / 1179648             ( 39.00%) | total_pruned =  719618 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     142 /     512             ( 27.73%) | total_pruned =     370 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  560660 / 2359296             ( 23.76%) | total_pruned = 1798636 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     316 /     512             ( 61.72%) | total_pruned =     196 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   28630 /  131072             ( 21.84%) | total_pruned =  102442 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     504 /     512             ( 98.44%) | total_pruned =       8 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     322 /     512             ( 62.89%) | total_pruned =     190 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  517833 / 2359296             ( 21.95%) | total_pruned = 1841463 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  652983 / 2359296             ( 27.68%) | total_pruned = 1706313 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5078 /    5120             ( 99.18%) | total_pruned =      42 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 54/100 Loss: 0.011249 Accuracy: 88.68 100.00 % Best test Accuracy: 88.68%
tensor(0.0107, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-1.6256e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.632655
Average KL loss: 0.084303
Average total loss: 0.716957
tensor(0.0125, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-6.1595e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.425517
Average KL loss: 0.094845
Average total loss: 0.520362
tensor(0.0127, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-4.2384e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.376044
Average KL loss: 0.099477
Average total loss: 0.475521
tensor(0.0127, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-2.6858e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.343391
Average KL loss: 0.102102
Average total loss: 0.445493
tensor(0.0126, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-2.3564e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.323097
Average KL loss: 0.103776
Average total loss: 0.426873
tensor(0.0127, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-1.4758e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.305773
Average KL loss: 0.105286
Average total loss: 0.411058
tensor(0.0126, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-1.9046e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.293096
Average KL loss: 0.106557
Average total loss: 0.399653
tensor(0.0126, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.1146e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.272349
Average KL loss: 0.107751
Average total loss: 0.380099
tensor(0.0126, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-2.0990e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.268357
Average KL loss: 0.108659
Average total loss: 0.377016
tensor(0.0125, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-1.5726e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.261094
Average KL loss: 0.109816
Average total loss: 0.370910
tensor(0.0126, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.2372e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.250479
Average KL loss: 0.110873
Average total loss: 0.361352
tensor(0.0126, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-6.6039e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.246190
Average KL loss: 0.111778
Average total loss: 0.357968
tensor(0.0126, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.6146e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.240330
Average KL loss: 0.112634
Average total loss: 0.352963
tensor(0.0126, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-1.2055e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.238980
Average KL loss: 0.113363
Average total loss: 0.352344
tensor(0.0126, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-9.9921e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.231494
Average KL loss: 0.113983
Average total loss: 0.345477
tensor(0.0126, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.3384e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.230033
Average KL loss: 0.114487
Average total loss: 0.344521
tensor(0.0126, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-1.3499e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.227343
Average KL loss: 0.115012
Average total loss: 0.342355
tensor(0.0126, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-1.2268e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.224932
Average KL loss: 0.115663
Average total loss: 0.340595
tensor(0.0126, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-5.6066e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.217460
Average KL loss: 0.116294
Average total loss: 0.333754
tensor(0.0126, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-9.5387e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.212822
Average KL loss: 0.116580
Average total loss: 0.329402
tensor(0.0126, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-9.0854e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.213479
Average KL loss: 0.116958
Average total loss: 0.330438
tensor(0.0126, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-4.8986e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.208525
Average KL loss: 0.117152
Average total loss: 0.325677
tensor(0.0126, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-4.4544e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.204945
Average KL loss: 0.117362
Average total loss: 0.322306
tensor(0.0127, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-4.8510e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.203443
Average KL loss: 0.117629
Average total loss: 0.321072
tensor(0.0127, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-3.6008e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.202504
Average KL loss: 0.117884
Average total loss: 0.320388
tensor(0.0126, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-8.7296e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.199978
Average KL loss: 0.118060
Average total loss: 0.318038
tensor(0.0127, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-1.1324e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.198639
Average KL loss: 0.118476
Average total loss: 0.317116
tensor(0.0127, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-3.7869e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.191450
Average KL loss: 0.118754
Average total loss: 0.310204
tensor(0.0127, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-4.0480e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.194303
Average KL loss: 0.118930
Average total loss: 0.313233
tensor(0.0127, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-5.7861e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.193480
Average KL loss: 0.119280
Average total loss: 0.312759
tensor(0.0127, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-8.8018e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.191406
Average KL loss: 0.119498
Average total loss: 0.310904
tensor(0.0127, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-5.8567e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.188423
Average KL loss: 0.119537
Average total loss: 0.307960
tensor(0.0127, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-5.2287e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.186208
Average KL loss: 0.119662
Average total loss: 0.305869
tensor(0.0127, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-5.1380e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.185280
Average KL loss: 0.119896
Average total loss: 0.305176
tensor(0.0127, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-4.5197e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.185794
Average KL loss: 0.120126
Average total loss: 0.305920
tensor(0.0127, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-8.2562e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.184690
Average KL loss: 0.120453
Average total loss: 0.305143
tensor(0.0127, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-4.1294e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.182786
Average KL loss: 0.120677
Average total loss: 0.303463
tensor(0.0127, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-3.9284e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.181134
Average KL loss: 0.120627
Average total loss: 0.301761
tensor(0.0127, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-4.9302e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.180829
Average KL loss: 0.120719
Average total loss: 0.301548
tensor(0.0127, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(3.7982e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.178652
Average KL loss: 0.120796
Average total loss: 0.299448
tensor(0.0127, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-3.1871e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.175733
Average KL loss: 0.120834
Average total loss: 0.296567
tensor(0.0126, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-5.5819e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.176342
Average KL loss: 0.120846
Average total loss: 0.297188
tensor(0.0126, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-2.0899e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.174057
Average KL loss: 0.120924
Average total loss: 0.294981
tensor(0.0126, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-2.7055e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.175024
Average KL loss: 0.121159
Average total loss: 0.296184
tensor(0.0126, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-3.3009e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.175645
Average KL loss: 0.121299
Average total loss: 0.296945
tensor(0.0126, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-3.5990e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.175445
Average KL loss: 0.121571
Average total loss: 0.297016
tensor(0.0126, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-4.5660e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.170174
Average KL loss: 0.121663
Average total loss: 0.291836
tensor(0.0126, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(6.1883e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.170552
Average KL loss: 0.121530
Average total loss: 0.292081
tensor(0.0126, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-3.3707e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.167113
Average KL loss: 0.121589
Average total loss: 0.288702
tensor(0.0126, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-3.7641e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.170129
Average KL loss: 0.121679
Average total loss: 0.291808
tensor(0.0126, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-3.4110e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.165835
Average KL loss: 0.121776
Average total loss: 0.287611
tensor(0.0126, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-7.8225e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.166814
Average KL loss: 0.121558
Average total loss: 0.288371
tensor(0.0126, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(1.2593e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.165938
Average KL loss: 0.121767
Average total loss: 0.287705
tensor(0.0126, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-3.1180e-11, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.164833
Average KL loss: 0.121771
Average total loss: 0.286604
tensor(0.0126, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-4.7991e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.166779
Average KL loss: 0.121887
Average total loss: 0.288666
tensor(0.0126, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-4.6799e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.165109
Average KL loss: 0.122081
Average total loss: 0.287190
tensor(0.0126, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-3.3485e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.165965
Average KL loss: 0.122197
Average total loss: 0.288163
tensor(0.0126, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-5.0286e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.164547
Average KL loss: 0.122307
Average total loss: 0.286853
tensor(0.0126, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-1.2743e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.160594
Average KL loss: 0.122524
Average total loss: 0.283118
tensor(0.0126, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-3.4419e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.161665
Average KL loss: 0.122389
Average total loss: 0.284053
tensor(0.0126, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-1.9400e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.160605
Average KL loss: 0.122459
Average total loss: 0.283064
tensor(0.0126, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(8.5308e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.162682
Average KL loss: 0.122573
Average total loss: 0.285254
tensor(0.0126, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-1.8918e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.157906
Average KL loss: 0.122614
Average total loss: 0.280520
tensor(0.0126, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-1.8548e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.158683
Average KL loss: 0.122563
Average total loss: 0.281247
tensor(0.0126, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-2.6641e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.159557
Average KL loss: 0.122590
Average total loss: 0.282147
tensor(0.0126, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-3.3398e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.163180
Average KL loss: 0.122754
Average total loss: 0.285934
tensor(0.0126, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(3.6740e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.158771
Average KL loss: 0.123217
Average total loss: 0.281988
tensor(0.0126, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-2.1446e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.156292
Average KL loss: 0.123106
Average total loss: 0.279398
tensor(0.0125, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.7650e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.157204
Average KL loss: 0.122880
Average total loss: 0.280084
tensor(0.0126, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.1734e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.156212
Average KL loss: 0.122918
Average total loss: 0.279130
tensor(0.0126, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-8.3544e-11, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.153626
Average KL loss: 0.122980
Average total loss: 0.276606
tensor(0.0126, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-4.5052e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.158966
Average KL loss: 0.123009
Average total loss: 0.281975
tensor(0.0125, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-8.6654e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.157597
Average KL loss: 0.123230
Average total loss: 0.280827
tensor(0.0125, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-4.1133e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.152753
Average KL loss: 0.123251
Average total loss: 0.276004
tensor(0.0125, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(1.0995e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.153931
Average KL loss: 0.123106
Average total loss: 0.277037
tensor(0.0125, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-1.2628e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.151636
Average KL loss: 0.123047
Average total loss: 0.274683
tensor(0.0126, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-4.3565e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.152797
Average KL loss: 0.123078
Average total loss: 0.275875
tensor(0.0126, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-4.2512e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.154661
Average KL loss: 0.123227
Average total loss: 0.277888
tensor(0.0125, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-2.5922e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.152178
Average KL loss: 0.123350
Average total loss: 0.275528
tensor(0.0125, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(4.3121e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.152261
Average KL loss: 0.123393
Average total loss: 0.275654
tensor(0.0125, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-1.2060e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.152303
Average KL loss: 0.123403
Average total loss: 0.275705
tensor(0.0125, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-9.2956e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.151246
Average KL loss: 0.123389
Average total loss: 0.274635
tensor(0.0125, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-1.6752e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.149480
Average KL loss: 0.123269
Average total loss: 0.272749
tensor(0.0125, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-6.5535e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.151592
Average KL loss: 0.123364
Average total loss: 0.274956
tensor(0.0125, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-1.7795e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.150753
Average KL loss: 0.123385
Average total loss: 0.274138
tensor(0.0125, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-2.4812e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.149242
Average KL loss: 0.123383
Average total loss: 0.272626
tensor(0.0125, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-1.9643e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.151338
Average KL loss: 0.123564
Average total loss: 0.274903
tensor(0.0125, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-4.0767e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.152154
Average KL loss: 0.123908
Average total loss: 0.276062
tensor(0.0125, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-2.1878e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.151635
Average KL loss: 0.124028
Average total loss: 0.275663
tensor(0.0125, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-2.6612e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.147846
Average KL loss: 0.123992
Average total loss: 0.271838
tensor(0.0125, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-2.5555e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.147870
Average KL loss: 0.123613
Average total loss: 0.271483
tensor(0.0125, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-3.2368e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.149837
Average KL loss: 0.123642
Average total loss: 0.273479
tensor(0.0125, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-1.3477e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.145699
Average KL loss: 0.123666
Average total loss: 0.269366
tensor(0.0125, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-2.2683e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.147576
Average KL loss: 0.123687
Average total loss: 0.271263
tensor(0.0125, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-2.3247e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.149914
Average KL loss: 0.123931
Average total loss: 0.273845
tensor(0.0125, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-1.5848e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.148826
Average KL loss: 0.123943
Average total loss: 0.272769
tensor(0.0125, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-9.7751e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.146803
Average KL loss: 0.124161
Average total loss: 0.270963
tensor(0.0125, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-5.0031e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.145601
Average KL loss: 0.123796
Average total loss: 0.269397
tensor(0.0125, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-1.4015e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.146089
Average KL loss: 0.123625
Average total loss: 0.269713
tensor(0.0125, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(1.5102e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.143870
Average KL loss: 0.123525
Average total loss: 0.267395
tensor(0.0125, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(6.5203e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.145836
Average KL loss: 0.123457
Average total loss: 0.269293
tensor(0.0125, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-6.6186e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.144759
Average KL loss: 0.123667
Average total loss: 0.268426
tensor(0.0125, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-1.1705e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.146024
Average KL loss: 0.123794
Average total loss: 0.269818
tensor(0.0125, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(1.9068e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.147487
Average KL loss: 0.123808
Average total loss: 0.271295
tensor(0.0125, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-9.7921e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.145489
Average KL loss: 0.124121
Average total loss: 0.269610
tensor(0.0125, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(2.9698e-11, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.143197
Average KL loss: 0.123970
Average total loss: 0.267167
tensor(0.0125, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.1346e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.145879
Average KL loss: 0.123941
Average total loss: 0.269819
tensor(0.0125, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(4.9652e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.141741
Average KL loss: 0.123958
Average total loss: 0.265699
tensor(0.0125, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-3.4289e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.142939
Average KL loss: 0.123875
Average total loss: 0.266814
tensor(0.0125, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-7.0890e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.143893
Average KL loss: 0.123766
Average total loss: 0.267660
tensor(0.0125, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-2.0590e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.143350
Average KL loss: 0.123929
Average total loss: 0.267278
tensor(0.0125, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-2.5065e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.145347
Average KL loss: 0.124102
Average total loss: 0.269449
tensor(0.0125, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-1.9166e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.141315
Average KL loss: 0.124133
Average total loss: 0.265448
tensor(0.0125, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-2.5385e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.142594
Average KL loss: 0.124029
Average total loss: 0.266623
tensor(0.0125, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(2.7473e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.142553
Average KL loss: 0.124167
Average total loss: 0.266720
tensor(0.0125, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.2548e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.141626
Average KL loss: 0.124085
Average total loss: 0.265711
tensor(0.0125, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(9.5348e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.143206
Average KL loss: 0.123926
Average total loss: 0.267132
tensor(0.0124, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-2.1744e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.142765
Average KL loss: 0.123956
Average total loss: 0.266721
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-8.4311e-12, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.140815
Average KL loss: 0.123945
Average total loss: 0.264760
tensor(0.0125, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-3.6357e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.141232
Average KL loss: 0.124063
Average total loss: 0.265295
tensor(0.0125, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.7073e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.141123
Average KL loss: 0.124081
Average total loss: 0.265204
tensor(0.0125, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(1.4293e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.143987
Average KL loss: 0.124096
Average total loss: 0.268083
tensor(0.0125, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.0327e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.142551
Average KL loss: 0.124251
Average total loss: 0.266802
tensor(0.0125, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.8005e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.141781
Average KL loss: 0.124336
Average total loss: 0.266117
tensor(0.0125, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(1.0000e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.141639
Average KL loss: 0.124500
Average total loss: 0.266139
tensor(0.0124, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-3.2857e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.140644
Average KL loss: 0.124462
Average total loss: 0.265106
tensor(0.0125, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-2.2760e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.143098
Average KL loss: 0.124317
Average total loss: 0.267415
tensor(0.0125, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-1.6474e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.140541
Average KL loss: 0.124533
Average total loss: 0.265074
tensor(0.0124, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-1.8521e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.144784
Average KL loss: 0.124344
Average total loss: 0.269128
tensor(0.0125, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-1.3504e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.140217
Average KL loss: 0.124544
Average total loss: 0.264761
tensor(0.0124, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(6.5498e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.139641
Average KL loss: 0.124053
Average total loss: 0.263693
tensor(0.0125, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(3.1989e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.139189
Average KL loss: 0.123349
Average total loss: 0.262538
tensor(0.0125, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-5.6832e-10, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.138288
Average KL loss: 0.122756
Average total loss: 0.261044
tensor(0.0125, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-8.3014e-11, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.137106
Average KL loss: 0.122231
Average total loss: 0.259337
tensor(0.0125, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(3.3396e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.138016
Average KL loss: 0.121764
Average total loss: 0.259780
tensor(0.0125, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(2.1598e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.139375
Average KL loss: 0.121339
Average total loss: 0.260714
tensor(0.0125, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(4.5939e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.137913
Average KL loss: 0.120962
Average total loss: 0.258875
tensor(0.0125, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-2.7405e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.139320
Average KL loss: 0.120597
Average total loss: 0.259918
tensor(0.0125, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-1.2031e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.139360
Average KL loss: 0.120281
Average total loss: 0.259641
tensor(0.0125, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-9.0114e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.140595
Average KL loss: 0.119969
Average total loss: 0.260564
tensor(0.0125, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-8.3470e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.139824
Average KL loss: 0.119683
Average total loss: 0.259507
tensor(0.0125, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-3.4082e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.138221
Average KL loss: 0.119416
Average total loss: 0.257637
tensor(0.0125, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.2351e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.139331
Average KL loss: 0.119131
Average total loss: 0.258462
tensor(0.0125, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.1325e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.136348
Average KL loss: 0.118894
Average total loss: 0.255242
tensor(0.0125, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-5.3656e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.139385
Average KL loss: 0.118645
Average total loss: 0.258030
tensor(0.0124, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-3.6549e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.137522
Average KL loss: 0.118410
Average total loss: 0.255932
tensor(0.0124, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.2385e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.137892
Average KL loss: 0.118208
Average total loss: 0.256100
tensor(0.0125, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.3254e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.136808
Average KL loss: 0.118015
Average total loss: 0.254823
tensor(0.0125, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(6.4461e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.137730
Average KL loss: 0.117811
Average total loss: 0.255542
tensor(0.0124, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-4.2124e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.137978
Average KL loss: 0.117623
Average total loss: 0.255602
tensor(0.0125, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-2.0465e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.138740
Average KL loss: 0.117449
Average total loss: 0.256189
tensor(0.0125, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-3.0296e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.138118
Average KL loss: 0.117271
Average total loss: 0.255389
tensor(0.0124, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-8.3130e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.138008
Average KL loss: 0.117099
Average total loss: 0.255107
tensor(0.0124, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.1899e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.137535
Average KL loss: 0.116929
Average total loss: 0.254465
tensor(0.0124, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.2244e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.137838
Average KL loss: 0.116736
Average total loss: 0.254573
tensor(0.0124, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.4310e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.137011
Average KL loss: 0.116587
Average total loss: 0.253598
tensor(0.0124, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(7.3870e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.136741
Average KL loss: 0.116448
Average total loss: 0.253189
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(1.4430e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.137656
Average KL loss: 0.116297
Average total loss: 0.253952
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(8.2492e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.138460
Average KL loss: 0.116156
Average total loss: 0.254616
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(1.4992e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.137130
Average KL loss: 0.116018
Average total loss: 0.253147
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(9.6231e-11, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.138440
Average KL loss: 0.115875
Average total loss: 0.254314
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-8.3558e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.138867
Average KL loss: 0.115755
Average total loss: 0.254621
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-1.5189e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.135790
Average KL loss: 0.115646
Average total loss: 0.251437
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-8.1736e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.137018
Average KL loss: 0.115523
Average total loss: 0.252542
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(5.0875e-11, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.137263
Average KL loss: 0.115407
Average total loss: 0.252670
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.9071e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.137635
Average KL loss: 0.115307
Average total loss: 0.252942
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-1.0059e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.137888
Average KL loss: 0.115201
Average total loss: 0.253089
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(1.1173e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.136352
Average KL loss: 0.115079
Average total loss: 0.251431
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(3.5510e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.138961
Average KL loss: 0.114985
Average total loss: 0.253947
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-1.7406e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.138005
Average KL loss: 0.114873
Average total loss: 0.252879
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-3.6428e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.137460
Average KL loss: 0.114753
Average total loss: 0.252213
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-5.4943e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.138219
Average KL loss: 0.114659
Average total loss: 0.252878
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-5.6608e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.138832
Average KL loss: 0.114561
Average total loss: 0.253394
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(2.4507e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.139221
Average KL loss: 0.114486
Average total loss: 0.253707
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.3425e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.136097
Average KL loss: 0.114433
Average total loss: 0.250529
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.5691e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.139059
Average KL loss: 0.114415
Average total loss: 0.253474
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(3.6412e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.139527
Average KL loss: 0.114398
Average total loss: 0.253925
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-1.1657e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.138369
Average KL loss: 0.114381
Average total loss: 0.252751
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.2845e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.135763
Average KL loss: 0.114363
Average total loss: 0.250126
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(3.1826e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.136571
Average KL loss: 0.114345
Average total loss: 0.250916
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(2.1511e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.139818
Average KL loss: 0.114329
Average total loss: 0.254147
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.2765e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.136841
Average KL loss: 0.114315
Average total loss: 0.251156
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(2.5126e-12, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.138955
Average KL loss: 0.114300
Average total loss: 0.253256
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.3822e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.137933
Average KL loss: 0.114287
Average total loss: 0.252220
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(3.9399e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.138564
Average KL loss: 0.114274
Average total loss: 0.252839
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-3.6439e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.136478
Average KL loss: 0.114259
Average total loss: 0.250736
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.9958e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.138590
Average KL loss: 0.114243
Average total loss: 0.252834
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(3.1296e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.137218
Average KL loss: 0.114229
Average total loss: 0.251447
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.0993e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.136531
Average KL loss: 0.114214
Average total loss: 0.250745
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(4.1956e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.138064
Average KL loss: 0.114198
Average total loss: 0.252262
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.0762e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.136940
Average KL loss: 0.114190
Average total loss: 0.251130
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.3631e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.137211
Average KL loss: 0.114188
Average total loss: 0.251399
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-1.7087e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.137538
Average KL loss: 0.114186
Average total loss: 0.251724
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.3309e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.136886
Average KL loss: 0.114185
Average total loss: 0.251070
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-1.7129e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.138733
Average KL loss: 0.114183
Average total loss: 0.252916
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-6.9637e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.136598
Average KL loss: 0.114181
Average total loss: 0.250780
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-6.5441e-12, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.139319
Average KL loss: 0.114180
Average total loss: 0.253498
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-9.0320e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.139509
Average KL loss: 0.114178
Average total loss: 0.253687
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-4.7688e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.139262
Average KL loss: 0.114177
Average total loss: 0.253439
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(9.7721e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.138547
Average KL loss: 0.114175
Average total loss: 0.252722
 Percentile value: 0.11127143055200577
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/8]: ---
conv1.weight         | nonzeros =     259 /    1728             ( 14.99%) | total_pruned =    1469 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
bn1.bias             | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1004 /   36864             (  2.72%) | total_pruned =   35860 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2073 /   36864             (  5.62%) | total_pruned =   34791 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2619 /   36864             (  7.10%) | total_pruned =   34245 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3600 /   36864             (  9.77%) | total_pruned =   33264 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   13274 /   73728             ( 18.00%) | total_pruned =   60454 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   27059 /  147456             ( 18.35%) | total_pruned =  120397 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      29 /     128             ( 22.66%) | total_pruned =      99 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1935 /    8192             ( 23.62%) | total_pruned =    6257 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   15642 /  147456             ( 10.61%) | total_pruned =  131814 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   14866 /  147456             ( 10.08%) | total_pruned =  132590 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      41 /     128             ( 32.03%) | total_pruned =      87 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   56926 /  294912             ( 19.30%) | total_pruned =  237986 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     104 /     256             ( 40.62%) | total_pruned =     152 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   95813 /  589824             ( 16.24%) | total_pruned =  494011 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      93 /     256             ( 36.33%) | total_pruned =     163 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    7092 /   32768             ( 21.64%) | total_pruned =   25676 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     208 /     256             ( 81.25%) | total_pruned =      48 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      99 /     256             ( 38.67%) | total_pruned =     157 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   64573 /  589824             ( 10.95%) | total_pruned =  525251 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   46059 /  589824             (  7.81%) | total_pruned =  543765 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     212 /     256             ( 82.81%) | total_pruned =      44 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      72 /     256             ( 28.12%) | total_pruned =     184 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  164397 / 1179648             ( 13.94%) | total_pruned = 1015251 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     466 /     512             ( 91.02%) | total_pruned =      46 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      88 /     512             ( 17.19%) | total_pruned =     424 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  142701 / 2359296             (  6.05%) | total_pruned = 2216595 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     476 /     512             ( 92.97%) | total_pruned =      36 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     234 /     512             ( 45.70%) | total_pruned =     278 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3945 /  131072             (  3.01%) | total_pruned =  127127 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     260 /     512             ( 50.78%) | total_pruned =     252 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     247 /     512             ( 48.24%) | total_pruned =     265 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  119965 / 2359296             (  5.08%) | total_pruned = 2239331 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     424 /     512             ( 82.81%) | total_pruned =      88 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  211963 / 2359296             (  8.98%) | total_pruned = 2147333 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     487 /     512             ( 95.12%) | total_pruned =      25 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     480 /     512             ( 93.75%) | total_pruned =      32 | shape = torch.Size([512])
linear.weight        | nonzeros =    4721 /    5120             ( 92.21%) | total_pruned =     399 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 62/100 Loss: 0.021076 Accuracy: 88.13 100.00 % Best test Accuracy: 88.16%
tensor(0.0124, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-7.5535e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.562167
Average KL loss: 0.102731
Average total loss: 0.664898
tensor(0.0117, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-4.2136e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.458262
Average KL loss: 0.100707
Average total loss: 0.558968
tensor(0.0114, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-3.4367e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.401897
Average KL loss: 0.101610
Average total loss: 0.503507
tensor(0.0112, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-2.8065e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.379411
Average KL loss: 0.102555
Average total loss: 0.481966
tensor(0.0110, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-2.0049e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.358194
Average KL loss: 0.103294
Average total loss: 0.461488
tensor(0.0109, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-2.7890e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.342263
Average KL loss: 0.104154
Average total loss: 0.446417
tensor(0.0108, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-1.7688e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.329792
Average KL loss: 0.104790
Average total loss: 0.434582
tensor(0.0108, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-2.1369e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.321198
Average KL loss: 0.105731
Average total loss: 0.426929
tensor(0.0108, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-1.9490e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.303602
Average KL loss: 0.106880
Average total loss: 0.410481
tensor(0.0108, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-1.1356e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.299390
Average KL loss: 0.108143
Average total loss: 0.407533
tensor(0.0108, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-2.0892e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.290889
Average KL loss: 0.109256
Average total loss: 0.400145
tensor(0.0108, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-1.9096e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.282938
Average KL loss: 0.110304
Average total loss: 0.393242
tensor(0.0108, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.9492e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.273320
Average KL loss: 0.111292
Average total loss: 0.384612
tensor(0.0108, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.8629e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.267772
Average KL loss: 0.112283
Average total loss: 0.380055
tensor(0.0108, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-1.2310e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.260277
Average KL loss: 0.113043
Average total loss: 0.373320
tensor(0.0108, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-8.7493e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.261169
Average KL loss: 0.113893
Average total loss: 0.375062
tensor(0.0109, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-1.5162e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.249720
Average KL loss: 0.114714
Average total loss: 0.364434
tensor(0.0109, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.2092e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.250792
Average KL loss: 0.115394
Average total loss: 0.366186
tensor(0.0109, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-6.6076e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.244719
Average KL loss: 0.116001
Average total loss: 0.360721
tensor(0.0109, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-1.4531e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.243811
Average KL loss: 0.116832
Average total loss: 0.360643
tensor(0.0110, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.4750e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.237157
Average KL loss: 0.117466
Average total loss: 0.354623
tensor(0.0110, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-1.0704e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.236857
Average KL loss: 0.118097
Average total loss: 0.354954
tensor(0.0110, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-7.4908e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.233447
Average KL loss: 0.118739
Average total loss: 0.352186
tensor(0.0110, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-6.8295e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.228646
Average KL loss: 0.119387
Average total loss: 0.348033
tensor(0.0110, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-7.9634e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.227507
Average KL loss: 0.120041
Average total loss: 0.347548
tensor(0.0111, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-8.6662e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.225655
Average KL loss: 0.120589
Average total loss: 0.346244
tensor(0.0111, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-6.0202e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.218522
Average KL loss: 0.121098
Average total loss: 0.339619
tensor(0.0111, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.0562e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.219554
Average KL loss: 0.121592
Average total loss: 0.341146
tensor(0.0111, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-7.3748e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.221245
Average KL loss: 0.122175
Average total loss: 0.343419
tensor(0.0111, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-4.5542e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.215823
Average KL loss: 0.122623
Average total loss: 0.338446
tensor(0.0111, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-8.8289e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.211806
Average KL loss: 0.123072
Average total loss: 0.334878
tensor(0.0112, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-9.0501e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.208613
Average KL loss: 0.123441
Average total loss: 0.332054
tensor(0.0112, device='cuda:0') tensor(0.0200, device='cuda:0') tensor(-9.7260e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.208319
Average KL loss: 0.123838
Average total loss: 0.332157
tensor(0.0112, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-2.5275e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.204408
Average KL loss: 0.124265
Average total loss: 0.328673
tensor(0.0112, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-8.2864e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.204541
Average KL loss: 0.124656
Average total loss: 0.329196
tensor(0.0112, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-6.7328e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.201259
Average KL loss: 0.125008
Average total loss: 0.326267
tensor(0.0112, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-6.2712e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.196644
Average KL loss: 0.125333
Average total loss: 0.321976
tensor(0.0113, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-3.5709e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.197171
Average KL loss: 0.125823
Average total loss: 0.322994
tensor(0.0113, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-9.1712e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.197328
Average KL loss: 0.126213
Average total loss: 0.323541
tensor(0.0113, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-7.0008e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.194183
Average KL loss: 0.126633
Average total loss: 0.320817
tensor(0.0113, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-4.8611e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.196951
Average KL loss: 0.126988
Average total loss: 0.323939
tensor(0.0113, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-6.9429e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.194209
Average KL loss: 0.127278
Average total loss: 0.321487
tensor(0.0114, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-7.5233e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.191696
Average KL loss: 0.127727
Average total loss: 0.319423
tensor(0.0114, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-4.1526e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.190589
Average KL loss: 0.127982
Average total loss: 0.318571
tensor(0.0114, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-6.3249e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.189050
Average KL loss: 0.128260
Average total loss: 0.317310
tensor(0.0114, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-6.2379e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.188320
Average KL loss: 0.128635
Average total loss: 0.316956
tensor(0.0114, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-6.9614e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.185245
Average KL loss: 0.128907
Average total loss: 0.314152
tensor(0.0114, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-5.1010e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.192144
Average KL loss: 0.129227
Average total loss: 0.321371
tensor(0.0114, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-1.1338e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.183151
Average KL loss: 0.129585
Average total loss: 0.312736
tensor(0.0114, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-4.4759e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.180615
Average KL loss: 0.129804
Average total loss: 0.310419
tensor(0.0115, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(6.0430e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.179681
Average KL loss: 0.130005
Average total loss: 0.309687
tensor(0.0115, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-1.2406e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.181702
Average KL loss: 0.130227
Average total loss: 0.311929
tensor(0.0115, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-3.9271e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.179035
Average KL loss: 0.130487
Average total loss: 0.309522
tensor(0.0115, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-1.1325e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.181628
Average KL loss: 0.130769
Average total loss: 0.312398
tensor(0.0115, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-5.2175e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.178954
Average KL loss: 0.131072
Average total loss: 0.310026
tensor(0.0115, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-2.0677e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.175888
Average KL loss: 0.131301
Average total loss: 0.307189
tensor(0.0115, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-3.1846e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.174858
Average KL loss: 0.131503
Average total loss: 0.306361
tensor(0.0115, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-4.9799e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.175520
Average KL loss: 0.131744
Average total loss: 0.307264
tensor(0.0115, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-1.8597e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.173067
Average KL loss: 0.131920
Average total loss: 0.304986
tensor(0.0115, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-3.6762e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.174156
Average KL loss: 0.132034
Average total loss: 0.306190
tensor(0.0115, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-2.2196e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.174632
Average KL loss: 0.132365
Average total loss: 0.306998
tensor(0.0116, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-9.8896e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.170173
Average KL loss: 0.132716
Average total loss: 0.302889
tensor(0.0116, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-3.8862e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.172245
Average KL loss: 0.132903
Average total loss: 0.305148
tensor(0.0116, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-8.6462e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.173005
Average KL loss: 0.133153
Average total loss: 0.306157
tensor(0.0116, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-3.6264e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.169385
Average KL loss: 0.133401
Average total loss: 0.302785
tensor(0.0116, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-2.5832e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.167193
Average KL loss: 0.133524
Average total loss: 0.300717
tensor(0.0116, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-2.7004e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.169672
Average KL loss: 0.133664
Average total loss: 0.303336
tensor(0.0116, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-3.2885e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.163210
Average KL loss: 0.133794
Average total loss: 0.297004
tensor(0.0116, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-4.6885e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.165806
Average KL loss: 0.133831
Average total loss: 0.299637
tensor(0.0116, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-2.0125e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.162861
Average KL loss: 0.133908
Average total loss: 0.296769
tensor(0.0116, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-6.1583e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.168186
Average KL loss: 0.134150
Average total loss: 0.302336
tensor(0.0116, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-3.1205e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.169446
Average KL loss: 0.134586
Average total loss: 0.304033
tensor(0.0116, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(5.3382e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.164828
Average KL loss: 0.134802
Average total loss: 0.299631
tensor(0.0116, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(2.0358e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.165412
Average KL loss: 0.134819
Average total loss: 0.300231
tensor(0.0116, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-4.7412e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.165670
Average KL loss: 0.135005
Average total loss: 0.300675
tensor(0.0116, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-1.0085e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.161853
Average KL loss: 0.135168
Average total loss: 0.297020
tensor(0.0117, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.7823e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.161916
Average KL loss: 0.135341
Average total loss: 0.297257
tensor(0.0117, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.0586e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.161816
Average KL loss: 0.135451
Average total loss: 0.297267
tensor(0.0117, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(9.6388e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.163696
Average KL loss: 0.135635
Average total loss: 0.299331
tensor(0.0117, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.0817e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.160495
Average KL loss: 0.135808
Average total loss: 0.296303
tensor(0.0117, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-3.1516e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.160726
Average KL loss: 0.135866
Average total loss: 0.296591
tensor(0.0117, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-7.2977e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.158661
Average KL loss: 0.136062
Average total loss: 0.294722
tensor(0.0117, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(3.8244e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.159268
Average KL loss: 0.136122
Average total loss: 0.295391
tensor(0.0117, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-3.1870e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.157041
Average KL loss: 0.136183
Average total loss: 0.293224
tensor(0.0117, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-3.0336e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.157491
Average KL loss: 0.136391
Average total loss: 0.293882
tensor(0.0117, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-1.1424e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.154774
Average KL loss: 0.136360
Average total loss: 0.291134
tensor(0.0117, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-3.3437e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.154432
Average KL loss: 0.136430
Average total loss: 0.290862
tensor(0.0117, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.3901e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.157140
Average KL loss: 0.136554
Average total loss: 0.293694
tensor(0.0117, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-5.7715e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.156349
Average KL loss: 0.136725
Average total loss: 0.293074
tensor(0.0117, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.5956e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.158322
Average KL loss: 0.136806
Average total loss: 0.295128
tensor(0.0117, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-4.5438e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.154457
Average KL loss: 0.137015
Average total loss: 0.291472
tensor(0.0117, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-3.7986e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.156583
Average KL loss: 0.137135
Average total loss: 0.293718
tensor(0.0117, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-3.7378e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.156234
Average KL loss: 0.137184
Average total loss: 0.293419
tensor(0.0117, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-4.8511e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.152332
Average KL loss: 0.137264
Average total loss: 0.289595
tensor(0.0117, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-1.4543e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.155272
Average KL loss: 0.137395
Average total loss: 0.292667
tensor(0.0118, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-1.6650e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.154460
Average KL loss: 0.137503
Average total loss: 0.291963
tensor(0.0118, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-1.3183e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.151989
Average KL loss: 0.137759
Average total loss: 0.289748
tensor(0.0118, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-3.2088e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.152996
Average KL loss: 0.137857
Average total loss: 0.290853
tensor(0.0118, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-3.8275e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.151553
Average KL loss: 0.137822
Average total loss: 0.289375
tensor(0.0118, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-2.1493e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.152689
Average KL loss: 0.137943
Average total loss: 0.290631
tensor(0.0118, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-5.6138e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.153309
Average KL loss: 0.138088
Average total loss: 0.291397
tensor(0.0118, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-6.4687e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.151121
Average KL loss: 0.138173
Average total loss: 0.289295
tensor(0.0118, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-4.6761e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.152201
Average KL loss: 0.138288
Average total loss: 0.290489
tensor(0.0118, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-1.7469e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.149709
Average KL loss: 0.138499
Average total loss: 0.288208
tensor(0.0118, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-4.1899e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.148647
Average KL loss: 0.138581
Average total loss: 0.287228
tensor(0.0118, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.6760e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.150580
Average KL loss: 0.138569
Average total loss: 0.289149
tensor(0.0118, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(1.0907e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.150626
Average KL loss: 0.138620
Average total loss: 0.289246
tensor(0.0118, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-5.0549e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.149994
Average KL loss: 0.138858
Average total loss: 0.288852
tensor(0.0118, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-1.7410e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.148329
Average KL loss: 0.138810
Average total loss: 0.287139
tensor(0.0118, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(3.2972e-11, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.152110
Average KL loss: 0.138918
Average total loss: 0.291027
tensor(0.0118, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(1.7034e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.147240
Average KL loss: 0.139092
Average total loss: 0.286333
tensor(0.0119, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-3.6992e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.148900
Average KL loss: 0.139045
Average total loss: 0.287945
tensor(0.0118, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(1.7944e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.147414
Average KL loss: 0.139167
Average total loss: 0.286581
tensor(0.0119, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(1.7655e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.149610
Average KL loss: 0.139293
Average total loss: 0.288903
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.3870e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.149512
Average KL loss: 0.139404
Average total loss: 0.288916
tensor(0.0119, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(1.0566e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.146658
Average KL loss: 0.139460
Average total loss: 0.286118
tensor(0.0119, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.7458e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.147689
Average KL loss: 0.139531
Average total loss: 0.287220
tensor(0.0118, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-6.6234e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.146794
Average KL loss: 0.139612
Average total loss: 0.286407
tensor(0.0119, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(6.9793e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.146359
Average KL loss: 0.139719
Average total loss: 0.286078
tensor(0.0119, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-4.4115e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.149627
Average KL loss: 0.139786
Average total loss: 0.289413
tensor(0.0119, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-2.3774e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.145074
Average KL loss: 0.139892
Average total loss: 0.284966
tensor(0.0119, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(1.0892e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.145745
Average KL loss: 0.139832
Average total loss: 0.285577
tensor(0.0119, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-4.1453e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.147510
Average KL loss: 0.139919
Average total loss: 0.287429
tensor(0.0119, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.5738e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.144586
Average KL loss: 0.140048
Average total loss: 0.284634
tensor(0.0119, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.2667e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.146070
Average KL loss: 0.139981
Average total loss: 0.286051
tensor(0.0119, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-2.7945e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.145073
Average KL loss: 0.139946
Average total loss: 0.285019
tensor(0.0119, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.4090e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.146520
Average KL loss: 0.139889
Average total loss: 0.286409
tensor(0.0119, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-3.1622e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.145581
Average KL loss: 0.139954
Average total loss: 0.285535
tensor(0.0119, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(1.3025e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.147267
Average KL loss: 0.140066
Average total loss: 0.287333
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-2.5498e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.146371
Average KL loss: 0.140324
Average total loss: 0.286694
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(2.3405e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.146514
Average KL loss: 0.140470
Average total loss: 0.286984
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-5.2164e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.146995
Average KL loss: 0.140516
Average total loss: 0.287511
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.9125e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.144508
Average KL loss: 0.140648
Average total loss: 0.285156
tensor(0.0119, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(3.7119e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.145064
Average KL loss: 0.140669
Average total loss: 0.285733
tensor(0.0119, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-2.0442e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.146010
Average KL loss: 0.140747
Average total loss: 0.286758
tensor(0.0119, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-2.4104e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.144946
Average KL loss: 0.140640
Average total loss: 0.285586
tensor(0.0119, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-1.2818e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.144453
Average KL loss: 0.140357
Average total loss: 0.284811
tensor(0.0119, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(6.4784e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.142673
Average KL loss: 0.140097
Average total loss: 0.282770
tensor(0.0119, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-2.2755e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.144488
Average KL loss: 0.139891
Average total loss: 0.284379
tensor(0.0119, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-2.8640e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.143087
Average KL loss: 0.139697
Average total loss: 0.282784
tensor(0.0119, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-2.8167e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.144657
Average KL loss: 0.139505
Average total loss: 0.284161
tensor(0.0119, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-6.0579e-11, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.142428
Average KL loss: 0.139322
Average total loss: 0.281750
tensor(0.0119, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(1.3576e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.140092
Average KL loss: 0.139151
Average total loss: 0.279243
tensor(0.0119, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(2.1887e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.142592
Average KL loss: 0.138974
Average total loss: 0.281566
tensor(0.0119, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-3.8587e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.141928
Average KL loss: 0.138815
Average total loss: 0.280743
tensor(0.0119, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(2.4719e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.143308
Average KL loss: 0.138634
Average total loss: 0.281942
tensor(0.0119, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(5.1990e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.142136
Average KL loss: 0.138475
Average total loss: 0.280611
tensor(0.0119, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-3.8397e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.142413
Average KL loss: 0.138341
Average total loss: 0.280755
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(1.0434e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.142185
Average KL loss: 0.138205
Average total loss: 0.280390
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-4.9971e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.140855
Average KL loss: 0.138065
Average total loss: 0.278920
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(5.9054e-11, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.144582
Average KL loss: 0.137922
Average total loss: 0.282503
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-2.4198e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.144831
Average KL loss: 0.137793
Average total loss: 0.282624
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.6406e-10, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.143528
Average KL loss: 0.137674
Average total loss: 0.281202
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-2.3813e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.141391
Average KL loss: 0.137575
Average total loss: 0.278966
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-2.7314e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.143827
Average KL loss: 0.137467
Average total loss: 0.281294
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-2.5821e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.143697
Average KL loss: 0.137376
Average total loss: 0.281073
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-2.1653e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.141987
Average KL loss: 0.137275
Average total loss: 0.279262
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.1989e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.142392
Average KL loss: 0.137161
Average total loss: 0.279553
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-2.1919e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.142936
Average KL loss: 0.137056
Average total loss: 0.279993
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(1.5970e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.142806
Average KL loss: 0.136946
Average total loss: 0.279752
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-2.0461e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.140548
Average KL loss: 0.136854
Average total loss: 0.277402
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-3.3795e-11, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.142006
Average KL loss: 0.136748
Average total loss: 0.278754
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-2.1846e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.140460
Average KL loss: 0.136653
Average total loss: 0.277114
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-8.6920e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.140769
Average KL loss: 0.136571
Average total loss: 0.277341
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(2.6758e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.142609
Average KL loss: 0.136477
Average total loss: 0.279085
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-2.2157e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.141805
Average KL loss: 0.136391
Average total loss: 0.278196
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.0264e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.142590
Average KL loss: 0.136321
Average total loss: 0.278910
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(7.9499e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.141477
Average KL loss: 0.136246
Average total loss: 0.277722
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-7.0330e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.141697
Average KL loss: 0.136161
Average total loss: 0.277858
tensor(0.0119, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(1.5269e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.141958
Average KL loss: 0.136080
Average total loss: 0.278038
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-4.1359e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.142973
Average KL loss: 0.135986
Average total loss: 0.278959
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-4.0777e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.141813
Average KL loss: 0.135912
Average total loss: 0.277725
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-2.8136e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.143223
Average KL loss: 0.135830
Average total loss: 0.279053
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-3.1727e-10, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.141333
Average KL loss: 0.135762
Average total loss: 0.277095
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.9670e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.142691
Average KL loss: 0.135721
Average total loss: 0.278412
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-2.6711e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.139403
Average KL loss: 0.135710
Average total loss: 0.275114
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-7.5282e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.140432
Average KL loss: 0.135699
Average total loss: 0.276131
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(1.8004e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.141441
Average KL loss: 0.135688
Average total loss: 0.277129
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-6.7247e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.143084
Average KL loss: 0.135678
Average total loss: 0.278762
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.0116e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.141699
Average KL loss: 0.135670
Average total loss: 0.277369
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(5.2298e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.142086
Average KL loss: 0.135659
Average total loss: 0.277745
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.0920e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.141602
Average KL loss: 0.135647
Average total loss: 0.277249
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-3.6513e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.142158
Average KL loss: 0.135636
Average total loss: 0.277795
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-2.9267e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.141286
Average KL loss: 0.135626
Average total loss: 0.276912
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.9452e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.141521
Average KL loss: 0.135615
Average total loss: 0.277136
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.2925e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.144527
Average KL loss: 0.135605
Average total loss: 0.280132
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(9.3616e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.141808
Average KL loss: 0.135596
Average total loss: 0.277404
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(1.0823e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.140767
Average KL loss: 0.135590
Average total loss: 0.276357
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-3.2289e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.141255
Average KL loss: 0.135589
Average total loss: 0.276843
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.8804e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.144816
Average KL loss: 0.135588
Average total loss: 0.280404
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-2.4959e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.141232
Average KL loss: 0.135587
Average total loss: 0.276819
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-4.3308e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.142896
Average KL loss: 0.135586
Average total loss: 0.278482
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.3208e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.144535
Average KL loss: 0.135585
Average total loss: 0.280119
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.9811e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.145131
Average KL loss: 0.135584
Average total loss: 0.280714
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.1806e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.141580
Average KL loss: 0.135583
Average total loss: 0.277162
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.8514e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.141193
Average KL loss: 0.135581
Average total loss: 0.276775
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.0626e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.139560
Average KL loss: 0.135580
Average total loss: 0.275140
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-2.1285e-09, device='cuda:0')
 Percentile value: 0.37248222827911376
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/8]: ---
conv1.weight         | nonzeros =     148 /    1728             (  8.56%) | total_pruned =    1580 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
bn1.bias             | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     334 /   36864             (  0.91%) | total_pruned =   36530 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     575 /   36864             (  1.56%) | total_pruned =   36289 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     598 /   36864             (  1.62%) | total_pruned =   36266 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1069 /   36864             (  2.90%) | total_pruned =   35795 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4470 /   73728             (  6.06%) | total_pruned =   69258 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     103 /     128             ( 80.47%) | total_pruned =      25 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      25 /     128             ( 19.53%) | total_pruned =     103 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   10407 /  147456             (  7.06%) | total_pruned =  137049 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     867 /    8192             ( 10.58%) | total_pruned =    7325 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    5599 /  147456             (  3.80%) | total_pruned =  141857 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    5030 /  147456             (  3.41%) | total_pruned =  142426 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      28 /     128             ( 21.88%) | total_pruned =     100 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   23438 /  294912             (  7.95%) | total_pruned =  271474 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     192 /     256             ( 75.00%) | total_pruned =      64 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      83 /     256             ( 32.42%) | total_pruned =     173 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   33754 /  589824             (  5.72%) | total_pruned =  556070 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     186 /     256             ( 72.66%) | total_pruned =      70 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2787 /   32768             (  8.51%) | total_pruned =   29981 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     159 /     256             ( 62.11%) | total_pruned =      97 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      77 /     256             ( 30.08%) | total_pruned =     179 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   18360 /  589824             (  3.11%) | total_pruned =  571464 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     187 /     256             ( 73.05%) | total_pruned =      69 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   11898 /  589824             (  2.02%) | total_pruned =  577926 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     156 /     256             ( 60.94%) | total_pruned =     100 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      55 /     256             ( 21.48%) | total_pruned =     201 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   48032 / 1179648             (  4.07%) | total_pruned = 1131616 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     424 /     512             ( 82.81%) | total_pruned =      88 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      50 /     512             (  9.77%) | total_pruned =     462 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   35279 / 2359296             (  1.50%) | total_pruned = 2324017 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     370 /     512             ( 72.27%) | total_pruned =     142 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     205 /     512             ( 40.04%) | total_pruned =     307 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     640 /  131072             (  0.49%) | total_pruned =  130432 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     103 /     512             ( 20.12%) | total_pruned =     409 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     220 /     512             ( 42.97%) | total_pruned =     292 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   33506 / 2359296             (  1.42%) | total_pruned = 2325790 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     249 /     512             ( 48.63%) | total_pruned =     263 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   56733 / 2359296             (  2.40%) | total_pruned = 2302563 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     435 /     512             ( 84.96%) | total_pruned =      77 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     417 /     512             ( 81.45%) | total_pruned =      95 | shape = torch.Size([512])
linear.weight        | nonzeros =    3914 /    5120             ( 76.45%) | total_pruned =    1206 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 60/100 Loss: 0.019733 Accuracy: 87.42 100.00 % Best test Accuracy: 87.66%
tensor(0.0119, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-3.6095e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.424601
Average KL loss: 0.124040
Average total loss: 0.548640
tensor(0.0110, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-2.1839e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.378393
Average KL loss: 0.118266
Average total loss: 0.496659
tensor(0.0107, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-2.9713e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.357149
Average KL loss: 0.116767
Average total loss: 0.473916
tensor(0.0105, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-1.9774e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.337803
Average KL loss: 0.116095
Average total loss: 0.453898
tensor(0.0103, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-2.1842e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.329510
Average KL loss: 0.115736
Average total loss: 0.445246
tensor(0.0102, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-1.4797e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.311466
Average KL loss: 0.115552
Average total loss: 0.427018
tensor(0.0101, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-1.4912e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.306154
Average KL loss: 0.115582
Average total loss: 0.421736
tensor(0.0100, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-1.2495e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.290609
Average KL loss: 0.115920
Average total loss: 0.406528
tensor(0.0099, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-2.1825e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.288407
Average KL loss: 0.116484
Average total loss: 0.404891
tensor(0.0099, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(-8.8215e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.285494
Average KL loss: 0.117250
Average total loss: 0.402744
tensor(0.0099, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.5073e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.274807
Average KL loss: 0.117998
Average total loss: 0.392805
tensor(0.0099, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.5233e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.273723
Average KL loss: 0.118671
Average total loss: 0.392394
tensor(0.0099, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.0653e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.268001
Average KL loss: 0.119379
Average total loss: 0.387380
tensor(0.0099, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.0383e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.263292
Average KL loss: 0.120016
Average total loss: 0.383308
tensor(0.0099, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-4.7957e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.253572
Average KL loss: 0.120644
Average total loss: 0.374215
tensor(0.0099, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-1.3783e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.250401
Average KL loss: 0.121244
Average total loss: 0.371645
tensor(0.0099, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-1.3168e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.249058
Average KL loss: 0.121822
Average total loss: 0.370880
tensor(0.0099, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-6.5878e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.247640
Average KL loss: 0.122512
Average total loss: 0.370153
tensor(0.0099, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-1.2043e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.245476
Average KL loss: 0.123141
Average total loss: 0.368617
tensor(0.0099, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(-1.0108e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.235329
Average KL loss: 0.123702
Average total loss: 0.359031
tensor(0.0099, device='cuda:0') tensor(0.0204, device='cuda:0') tensor(-1.3044e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.231138
Average KL loss: 0.124234
Average total loss: 0.355372
tensor(0.0099, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-6.8539e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.228706
Average KL loss: 0.124790
Average total loss: 0.353496
tensor(0.0099, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-8.2923e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.226136
Average KL loss: 0.125350
Average total loss: 0.351486
tensor(0.0099, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(-4.8060e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.226137
Average KL loss: 0.125800
Average total loss: 0.351937
tensor(0.0099, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-8.2783e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.220607
Average KL loss: 0.126247
Average total loss: 0.346854
tensor(0.0100, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-4.0575e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.223225
Average KL loss: 0.126599
Average total loss: 0.349825
tensor(0.0100, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-8.7075e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.220697
Average KL loss: 0.127137
Average total loss: 0.347834
tensor(0.0100, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-8.6978e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.214474
Average KL loss: 0.127745
Average total loss: 0.342219
tensor(0.0100, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-6.6579e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.215778
Average KL loss: 0.128205
Average total loss: 0.343983
tensor(0.0100, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-7.0385e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.213771
Average KL loss: 0.128676
Average total loss: 0.342448
tensor(0.0100, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-5.3086e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.208866
Average KL loss: 0.129126
Average total loss: 0.337992
tensor(0.0100, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-1.0045e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.206237
Average KL loss: 0.129544
Average total loss: 0.335781
tensor(0.0100, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-2.6931e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.203531
Average KL loss: 0.129953
Average total loss: 0.333485
tensor(0.0100, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-6.5020e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.204786
Average KL loss: 0.130369
Average total loss: 0.335155
tensor(0.0101, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-4.0635e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.205078
Average KL loss: 0.130726
Average total loss: 0.335804
tensor(0.0101, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-5.6730e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.195552
Average KL loss: 0.131148
Average total loss: 0.326700
tensor(0.0101, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-4.7480e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.199029
Average KL loss: 0.131543
Average total loss: 0.330571
tensor(0.0101, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-5.6067e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.201238
Average KL loss: 0.131945
Average total loss: 0.333183
tensor(0.0101, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-2.8625e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.197656
Average KL loss: 0.132360
Average total loss: 0.330017
tensor(0.0101, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-4.9253e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.189997
Average KL loss: 0.132652
Average total loss: 0.322649
tensor(0.0101, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-3.8969e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.194344
Average KL loss: 0.133045
Average total loss: 0.327389
tensor(0.0101, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-6.4608e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.188730
Average KL loss: 0.133410
Average total loss: 0.322140
tensor(0.0102, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-6.4713e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.188814
Average KL loss: 0.133723
Average total loss: 0.322537
tensor(0.0102, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-2.8390e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.189671
Average KL loss: 0.134123
Average total loss: 0.323793
tensor(0.0102, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-9.8609e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.184469
Average KL loss: 0.134495
Average total loss: 0.318963
tensor(0.0102, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-3.6673e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.186458
Average KL loss: 0.134866
Average total loss: 0.321324
tensor(0.0102, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-2.0348e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.185546
Average KL loss: 0.135209
Average total loss: 0.320755
tensor(0.0102, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-5.3192e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.179520
Average KL loss: 0.135524
Average total loss: 0.315044
tensor(0.0102, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-4.2430e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.179724
Average KL loss: 0.135838
Average total loss: 0.315561
tensor(0.0102, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-5.3147e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.183116
Average KL loss: 0.136143
Average total loss: 0.319260
tensor(0.0103, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-4.3867e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.180464
Average KL loss: 0.136507
Average total loss: 0.316971
tensor(0.0103, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-6.1056e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.180494
Average KL loss: 0.136820
Average total loss: 0.317314
tensor(0.0103, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-7.9806e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.176900
Average KL loss: 0.137074
Average total loss: 0.313975
tensor(0.0103, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-8.0906e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.176303
Average KL loss: 0.137296
Average total loss: 0.313598
tensor(0.0103, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-5.7436e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.175416
Average KL loss: 0.137617
Average total loss: 0.313032
tensor(0.0103, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-4.3831e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.174175
Average KL loss: 0.137892
Average total loss: 0.312066
tensor(0.0103, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.5372e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.173725
Average KL loss: 0.138186
Average total loss: 0.311910
tensor(0.0103, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-4.8562e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.172335
Average KL loss: 0.138524
Average total loss: 0.310859
tensor(0.0103, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.6257e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.175659
Average KL loss: 0.138805
Average total loss: 0.314464
tensor(0.0103, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-1.2667e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.170687
Average KL loss: 0.139030
Average total loss: 0.309717
tensor(0.0104, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-5.5196e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.171895
Average KL loss: 0.139326
Average total loss: 0.311220
tensor(0.0104, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.8177e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.172290
Average KL loss: 0.139560
Average total loss: 0.311849
tensor(0.0104, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-3.8313e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.169822
Average KL loss: 0.139838
Average total loss: 0.309659
tensor(0.0104, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-3.9650e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.165958
Average KL loss: 0.140150
Average total loss: 0.306108
tensor(0.0104, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-4.2801e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.168425
Average KL loss: 0.140329
Average total loss: 0.308754
tensor(0.0104, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-1.7698e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.167513
Average KL loss: 0.140496
Average total loss: 0.308009
tensor(0.0104, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-1.8805e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.164993
Average KL loss: 0.140884
Average total loss: 0.305877
tensor(0.0105, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-4.5591e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.166845
Average KL loss: 0.141230
Average total loss: 0.308075
tensor(0.0105, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-1.2139e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.164746
Average KL loss: 0.141465
Average total loss: 0.306210
tensor(0.0105, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-4.2632e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.163852
Average KL loss: 0.141722
Average total loss: 0.305574
tensor(0.0105, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-4.9934e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.160054
Average KL loss: 0.142008
Average total loss: 0.302062
tensor(0.0105, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-4.1320e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.159813
Average KL loss: 0.142226
Average total loss: 0.302039
tensor(0.0105, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-1.3104e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.158868
Average KL loss: 0.142346
Average total loss: 0.301214
tensor(0.0105, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-2.0013e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.160915
Average KL loss: 0.142470
Average total loss: 0.303384
tensor(0.0105, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-3.4175e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.161257
Average KL loss: 0.142773
Average total loss: 0.304031
tensor(0.0105, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-8.2702e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.156615
Average KL loss: 0.143040
Average total loss: 0.299654
tensor(0.0105, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-6.2719e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.157714
Average KL loss: 0.143177
Average total loss: 0.300892
tensor(0.0106, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-1.3880e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.156254
Average KL loss: 0.143327
Average total loss: 0.299581
tensor(0.0106, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-4.0293e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.158629
Average KL loss: 0.143512
Average total loss: 0.302141
tensor(0.0106, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-2.3252e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.159749
Average KL loss: 0.143791
Average total loss: 0.303540
tensor(0.0106, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.6736e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.155046
Average KL loss: 0.143896
Average total loss: 0.298942
tensor(0.0106, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.0595e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.157945
Average KL loss: 0.144128
Average total loss: 0.302073
tensor(0.0106, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-4.4351e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.156424
Average KL loss: 0.144377
Average total loss: 0.300802
tensor(0.0106, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-2.0529e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.153064
Average KL loss: 0.144493
Average total loss: 0.297556
tensor(0.0106, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-1.4306e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.153326
Average KL loss: 0.144733
Average total loss: 0.298059
tensor(0.0106, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.1079e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.151501
Average KL loss: 0.144805
Average total loss: 0.296305
tensor(0.0106, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.3482e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.152140
Average KL loss: 0.144866
Average total loss: 0.297006
tensor(0.0106, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-4.8581e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.153479
Average KL loss: 0.145002
Average total loss: 0.298481
tensor(0.0106, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(4.0535e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.151378
Average KL loss: 0.145236
Average total loss: 0.296614
tensor(0.0107, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-3.1441e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.149196
Average KL loss: 0.145469
Average total loss: 0.294664
tensor(0.0107, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-4.2387e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.152184
Average KL loss: 0.145605
Average total loss: 0.297789
tensor(0.0107, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-1.8408e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.152801
Average KL loss: 0.145799
Average total loss: 0.298600
tensor(0.0107, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-8.7985e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.147459
Average KL loss: 0.146049
Average total loss: 0.293508
tensor(0.0107, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-3.9861e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.149673
Average KL loss: 0.146191
Average total loss: 0.295864
tensor(0.0107, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-3.0829e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.149754
Average KL loss: 0.146397
Average total loss: 0.296151
tensor(0.0107, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(1.2067e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.151228
Average KL loss: 0.146552
Average total loss: 0.297780
tensor(0.0107, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-7.9483e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.149816
Average KL loss: 0.146692
Average total loss: 0.296508
tensor(0.0107, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-2.8540e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.147309
Average KL loss: 0.146873
Average total loss: 0.294182
tensor(0.0107, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-2.9315e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.144386
Average KL loss: 0.146935
Average total loss: 0.291321
tensor(0.0107, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-3.9655e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.146665
Average KL loss: 0.147080
Average total loss: 0.293745
tensor(0.0107, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-3.5728e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.146563
Average KL loss: 0.147220
Average total loss: 0.293783
tensor(0.0107, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-2.4465e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.148376
Average KL loss: 0.147365
Average total loss: 0.295742
tensor(0.0107, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-2.1149e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.144275
Average KL loss: 0.147498
Average total loss: 0.291773
tensor(0.0108, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-1.6540e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.143553
Average KL loss: 0.147582
Average total loss: 0.291136
tensor(0.0108, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-2.7467e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.146283
Average KL loss: 0.147601
Average total loss: 0.293884
tensor(0.0108, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-3.4774e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.140531
Average KL loss: 0.147729
Average total loss: 0.288259
tensor(0.0108, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-8.8136e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.143223
Average KL loss: 0.147825
Average total loss: 0.291048
tensor(0.0108, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-4.2944e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.142638
Average KL loss: 0.147952
Average total loss: 0.290589
tensor(0.0108, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-3.1747e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.145283
Average KL loss: 0.148159
Average total loss: 0.293442
tensor(0.0108, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-1.5442e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.146408
Average KL loss: 0.148292
Average total loss: 0.294700
tensor(0.0108, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(1.1182e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.145497
Average KL loss: 0.148494
Average total loss: 0.293991
tensor(0.0108, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-2.3939e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.142507
Average KL loss: 0.148627
Average total loss: 0.291134
tensor(0.0108, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-1.6821e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.141422
Average KL loss: 0.148788
Average total loss: 0.290209
tensor(0.0108, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(1.5535e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.139600
Average KL loss: 0.148869
Average total loss: 0.288469
tensor(0.0108, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-1.8718e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.141287
Average KL loss: 0.148961
Average total loss: 0.290248
tensor(0.0108, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-2.0388e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.141722
Average KL loss: 0.149095
Average total loss: 0.290818
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.8799e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.142922
Average KL loss: 0.149263
Average total loss: 0.292185
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-6.4540e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.139393
Average KL loss: 0.149291
Average total loss: 0.288684
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.5341e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.139750
Average KL loss: 0.149196
Average total loss: 0.288947
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(2.4846e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.139299
Average KL loss: 0.149112
Average total loss: 0.288410
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.5256e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.138939
Average KL loss: 0.149042
Average total loss: 0.287981
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.3608e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.141876
Average KL loss: 0.148967
Average total loss: 0.290843
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-9.4797e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.142134
Average KL loss: 0.148910
Average total loss: 0.291044
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.5971e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.140267
Average KL loss: 0.148852
Average total loss: 0.289119
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.7127e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.142798
Average KL loss: 0.148795
Average total loss: 0.291593
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.7365e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.139524
Average KL loss: 0.148734
Average total loss: 0.288257
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-5.5435e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.139688
Average KL loss: 0.148676
Average total loss: 0.288364
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.9610e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.142316
Average KL loss: 0.148627
Average total loss: 0.290943
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.3090e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.141027
Average KL loss: 0.148581
Average total loss: 0.289608
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-9.1139e-10, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.138875
Average KL loss: 0.148523
Average total loss: 0.287398
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(2.7191e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.137590
Average KL loss: 0.148474
Average total loss: 0.286064
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.0522e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.140978
Average KL loss: 0.148423
Average total loss: 0.289401
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.6328e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.137077
Average KL loss: 0.148374
Average total loss: 0.285451
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-8.5072e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.140080
Average KL loss: 0.148329
Average total loss: 0.288409
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.2652e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.136727
Average KL loss: 0.148291
Average total loss: 0.285019
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.2339e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.141310
Average KL loss: 0.148247
Average total loss: 0.289558
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.1578e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.140966
Average KL loss: 0.148208
Average total loss: 0.289175
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.1139e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.138489
Average KL loss: 0.148174
Average total loss: 0.286663
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(2.8365e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.138496
Average KL loss: 0.148133
Average total loss: 0.286629
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.5147e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.140392
Average KL loss: 0.148101
Average total loss: 0.288492
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.0658e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.137342
Average KL loss: 0.148067
Average total loss: 0.285409
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-4.3532e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.137345
Average KL loss: 0.148021
Average total loss: 0.285366
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.9251e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.137833
Average KL loss: 0.147975
Average total loss: 0.285808
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.0659e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.139201
Average KL loss: 0.147934
Average total loss: 0.287135
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.0112e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.137437
Average KL loss: 0.147892
Average total loss: 0.285329
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.9250e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.140575
Average KL loss: 0.147856
Average total loss: 0.288431
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.1603e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.138511
Average KL loss: 0.147839
Average total loss: 0.286350
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.1206e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.139614
Average KL loss: 0.147836
Average total loss: 0.287450
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(7.3458e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.139591
Average KL loss: 0.147831
Average total loss: 0.287422
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.9745e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.135434
Average KL loss: 0.147827
Average total loss: 0.283261
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-5.3941e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.139624
Average KL loss: 0.147824
Average total loss: 0.287448
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.8378e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.139074
Average KL loss: 0.147821
Average total loss: 0.286894
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.5502e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.137322
Average KL loss: 0.147817
Average total loss: 0.285139
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.8270e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.137078
Average KL loss: 0.147812
Average total loss: 0.284889
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(4.5482e-10, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.137998
Average KL loss: 0.147807
Average total loss: 0.285805
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.7155e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.139710
Average KL loss: 0.147803
Average total loss: 0.287512
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.3383e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.140702
Average KL loss: 0.147799
Average total loss: 0.288501
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.9410e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.140545
Average KL loss: 0.147796
Average total loss: 0.288340
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(6.9029e-11, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.138886
Average KL loss: 0.147792
Average total loss: 0.286678
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-9.1948e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.136384
Average KL loss: 0.147788
Average total loss: 0.284172
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.3582e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.140894
Average KL loss: 0.147783
Average total loss: 0.288677
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.4228e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.139237
Average KL loss: 0.147781
Average total loss: 0.287017
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.0780e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.141767
Average KL loss: 0.147780
Average total loss: 0.289548
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-8.3500e-10, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.137445
Average KL loss: 0.147780
Average total loss: 0.285225
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.8447e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.139801
Average KL loss: 0.147780
Average total loss: 0.287581
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.4586e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.139549
Average KL loss: 0.147779
Average total loss: 0.287328
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.5693e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.136477
Average KL loss: 0.147779
Average total loss: 0.284256
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(8.3899e-11, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.137795
Average KL loss: 0.147778
Average total loss: 0.285574
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-4.1939e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.140425
Average KL loss: 0.147778
Average total loss: 0.288203
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(3.2141e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.138813
Average KL loss: 0.147778
Average total loss: 0.286590
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-3.6950e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.139278
Average KL loss: 0.147777
Average total loss: 0.287055
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.5599e-09, device='cuda:0')
 Percentile value: 1.2837986707687379
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/8]: ---
conv1.weight         | nonzeros =     114 /    1728             (  6.60%) | total_pruned =    1614 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     147 /   36864             (  0.40%) | total_pruned =   36717 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     244 /   36864             (  0.66%) | total_pruned =   36620 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     334 /   36864             (  0.91%) | total_pruned =   36530 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     471 /   36864             (  1.28%) | total_pruned =   36393 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1798 /   73728             (  2.44%) | total_pruned =   71930 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3887 /  147456             (  2.64%) | total_pruned =  143569 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     396 /    8192             (  4.83%) | total_pruned =    7796 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2140 /  147456             (  1.45%) | total_pruned =  145316 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2116 /  147456             (  1.44%) | total_pruned =  145340 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    8585 /  294912             (  2.91%) | total_pruned =  286327 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     173 /     256             ( 67.58%) | total_pruned =      83 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      56 /     256             ( 21.88%) | total_pruned =     200 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   12006 /  589824             (  2.04%) | total_pruned =  577818 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     173 /     256             ( 67.58%) | total_pruned =      83 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1164 /   32768             (  3.55%) | total_pruned =   31604 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      69 /     256             ( 26.95%) | total_pruned =     187 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    6408 /  589824             (  1.09%) | total_pruned =  583416 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     166 /     256             ( 64.84%) | total_pruned =      90 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    4408 /  589824             (  0.75%) | total_pruned =  585416 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     122 /     256             ( 47.66%) | total_pruned =     134 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      46 /     256             ( 17.97%) | total_pruned =     210 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   13606 / 1179648             (  1.15%) | total_pruned = 1166042 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     382 /     512             ( 74.61%) | total_pruned =     130 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    9701 / 2359296             (  0.41%) | total_pruned = 2349595 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     277 /     512             ( 54.10%) | total_pruned =     235 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     171 /     512             ( 33.40%) | total_pruned =     341 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     147 /  131072             (  0.11%) | total_pruned =  130925 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     181 /     512             ( 35.35%) | total_pruned =     331 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    7597 / 2359296             (  0.32%) | total_pruned = 2351699 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     163 /     512             ( 31.84%) | total_pruned =     349 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    9604 / 2359296             (  0.41%) | total_pruned = 2349692 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     326 /     512             ( 63.67%) | total_pruned =     186 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     291 /     512             ( 56.84%) | total_pruned =     221 | shape = torch.Size([512])
linear.weight        | nonzeros =    2210 /    5120             ( 43.16%) | total_pruned =    2910 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 51/100 Loss: 0.027322 Accuracy: 85.59 100.00 % Best test Accuracy: 86.68%
tensor(0.0109, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.5531e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.384828
Average KL loss: 0.137473
Average total loss: 0.522301
tensor(0.0095, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-2.4024e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.348196
Average KL loss: 0.131037
Average total loss: 0.479233
tensor(0.0092, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.1156e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.345715
Average KL loss: 0.128363
Average total loss: 0.474078
tensor(0.0090, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-3.1787e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.326433
Average KL loss: 0.126528
Average total loss: 0.452961
tensor(0.0088, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-1.3140e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.319507
Average KL loss: 0.125189
Average total loss: 0.444696
tensor(0.0087, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-2.0631e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.310897
Average KL loss: 0.124283
Average total loss: 0.435180
tensor(0.0086, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-1.5144e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.299258
Average KL loss: 0.123727
Average total loss: 0.422985
tensor(0.0086, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-1.4427e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.289346
Average KL loss: 0.123531
Average total loss: 0.412877
tensor(0.0085, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(-1.6967e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.283546
Average KL loss: 0.123696
Average total loss: 0.407241
tensor(0.0085, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-1.2561e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.277229
Average KL loss: 0.124026
Average total loss: 0.401255
tensor(0.0085, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-1.2693e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.274960
Average KL loss: 0.124408
Average total loss: 0.399368
tensor(0.0085, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-1.0386e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.277535
Average KL loss: 0.124814
Average total loss: 0.402350
tensor(0.0085, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-1.1830e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.261403
Average KL loss: 0.125195
Average total loss: 0.386598
tensor(0.0085, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-9.9889e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.272863
Average KL loss: 0.125631
Average total loss: 0.398495
tensor(0.0085, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-1.2334e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.265925
Average KL loss: 0.126115
Average total loss: 0.392039
tensor(0.0085, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(-7.9705e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.251348
Average KL loss: 0.126547
Average total loss: 0.377895
tensor(0.0085, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(-9.5299e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.252542
Average KL loss: 0.127010
Average total loss: 0.379553
tensor(0.0086, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-8.6370e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.243884
Average KL loss: 0.127497
Average total loss: 0.371381
tensor(0.0086, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(-4.7422e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.238689
Average KL loss: 0.127880
Average total loss: 0.366569
tensor(0.0086, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(-1.0400e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.230415
Average KL loss: 0.128235
Average total loss: 0.358650
tensor(0.0086, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-7.6895e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.224818
Average KL loss: 0.128642
Average total loss: 0.353460
tensor(0.0086, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-9.0611e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.248195
Average KL loss: 0.129051
Average total loss: 0.377247
tensor(0.0086, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-4.1007e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.227278
Average KL loss: 0.129427
Average total loss: 0.356706
tensor(0.0086, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-1.0713e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.229548
Average KL loss: 0.129827
Average total loss: 0.359374
tensor(0.0086, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-1.4939e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.214373
Average KL loss: 0.130220
Average total loss: 0.344593
tensor(0.0086, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-7.4962e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.215020
Average KL loss: 0.130640
Average total loss: 0.345660
tensor(0.0087, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-1.4418e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.215775
Average KL loss: 0.131031
Average total loss: 0.346806
tensor(0.0087, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-5.6961e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.208521
Average KL loss: 0.131491
Average total loss: 0.340012
tensor(0.0087, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(-5.4168e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.211982
Average KL loss: 0.131880
Average total loss: 0.343862
tensor(0.0087, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-7.2209e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.204253
Average KL loss: 0.132265
Average total loss: 0.336518
tensor(0.0087, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-9.3000e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.212699
Average KL loss: 0.132659
Average total loss: 0.345358
tensor(0.0087, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-5.3423e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.198489
Average KL loss: 0.133010
Average total loss: 0.331499
tensor(0.0087, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-7.9785e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.196538
Average KL loss: 0.133367
Average total loss: 0.329905
tensor(0.0088, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-4.9180e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.200194
Average KL loss: 0.133676
Average total loss: 0.333870
tensor(0.0088, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-1.1404e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.195153
Average KL loss: 0.134046
Average total loss: 0.329200
tensor(0.0088, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-7.2779e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.197264
Average KL loss: 0.134364
Average total loss: 0.331628
tensor(0.0088, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-2.6397e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.207536
Average KL loss: 0.134626
Average total loss: 0.342162
tensor(0.0088, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-5.2775e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.192083
Average KL loss: 0.134968
Average total loss: 0.327051
tensor(0.0088, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-4.7261e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.186499
Average KL loss: 0.135301
Average total loss: 0.321800
tensor(0.0088, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-6.4907e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.189488
Average KL loss: 0.135621
Average total loss: 0.325109
tensor(0.0088, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-7.7814e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.185472
Average KL loss: 0.136009
Average total loss: 0.321481
tensor(0.0089, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-8.6632e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.181095
Average KL loss: 0.136324
Average total loss: 0.317419
tensor(0.0089, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-6.1954e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.181031
Average KL loss: 0.136617
Average total loss: 0.317648
tensor(0.0089, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-4.4894e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.178492
Average KL loss: 0.136920
Average total loss: 0.315412
tensor(0.0089, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-8.5204e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.179665
Average KL loss: 0.137298
Average total loss: 0.316964
tensor(0.0089, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-7.2087e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.175353
Average KL loss: 0.137587
Average total loss: 0.312940
tensor(0.0089, device='cuda:0') tensor(0.0250, device='cuda:0') tensor(-1.0286e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.172646
Average KL loss: 0.137936
Average total loss: 0.310582
tensor(0.0089, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-5.3508e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.172963
Average KL loss: 0.138265
Average total loss: 0.311228
tensor(0.0090, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-2.8802e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.173986
Average KL loss: 0.138627
Average total loss: 0.312612
tensor(0.0090, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-8.9610e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.177617
Average KL loss: 0.138923
Average total loss: 0.316540
tensor(0.0090, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-5.1705e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.170424
Average KL loss: 0.139211
Average total loss: 0.309635
tensor(0.0090, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-6.4305e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.169772
Average KL loss: 0.139502
Average total loss: 0.309275
tensor(0.0090, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-7.0711e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.165265
Average KL loss: 0.139829
Average total loss: 0.305094
tensor(0.0090, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-3.6535e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.164835
Average KL loss: 0.140142
Average total loss: 0.304978
tensor(0.0090, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.7481e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.161579
Average KL loss: 0.140456
Average total loss: 0.302035
tensor(0.0090, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-8.4841e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.161860
Average KL loss: 0.140680
Average total loss: 0.302539
tensor(0.0091, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-4.2149e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.160655
Average KL loss: 0.140994
Average total loss: 0.301648
tensor(0.0091, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-3.3368e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.161261
Average KL loss: 0.141280
Average total loss: 0.302541
tensor(0.0091, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-6.1078e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.161580
Average KL loss: 0.141577
Average total loss: 0.303157
tensor(0.0091, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-6.3933e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.156630
Average KL loss: 0.141856
Average total loss: 0.298486
tensor(0.0091, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-6.4987e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.153745
Average KL loss: 0.142125
Average total loss: 0.295871
tensor(0.0091, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-7.4955e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.156093
Average KL loss: 0.142416
Average total loss: 0.298509
tensor(0.0092, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-3.8378e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.153242
Average KL loss: 0.142682
Average total loss: 0.295924
tensor(0.0092, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-2.7187e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.152804
Average KL loss: 0.142919
Average total loss: 0.295722
tensor(0.0092, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(2.1782e-11, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.153092
Average KL loss: 0.143191
Average total loss: 0.296283
tensor(0.0092, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-4.0079e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.148674
Average KL loss: 0.143447
Average total loss: 0.292121
tensor(0.0092, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-5.0063e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.153417
Average KL loss: 0.143687
Average total loss: 0.297105
tensor(0.0092, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-2.1931e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.150854
Average KL loss: 0.143942
Average total loss: 0.294796
tensor(0.0092, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-8.5382e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.150269
Average KL loss: 0.144202
Average total loss: 0.294470
tensor(0.0092, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-4.2757e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.147516
Average KL loss: 0.144450
Average total loss: 0.291965
tensor(0.0093, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-2.0953e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.142283
Average KL loss: 0.144633
Average total loss: 0.286916
tensor(0.0093, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-3.6052e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.147886
Average KL loss: 0.144800
Average total loss: 0.292685
tensor(0.0093, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-2.1765e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.141033
Average KL loss: 0.144993
Average total loss: 0.286027
tensor(0.0093, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-2.4027e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.149697
Average KL loss: 0.145211
Average total loss: 0.294909
tensor(0.0093, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-5.4856e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.146439
Average KL loss: 0.145433
Average total loss: 0.291872
tensor(0.0093, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-8.3144e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.142891
Average KL loss: 0.145711
Average total loss: 0.288602
tensor(0.0093, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-3.1340e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.137141
Average KL loss: 0.145957
Average total loss: 0.283098
tensor(0.0094, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-6.3597e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.138523
Average KL loss: 0.146145
Average total loss: 0.284668
tensor(0.0094, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-3.5599e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.138943
Average KL loss: 0.146340
Average total loss: 0.285282
tensor(0.0094, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-5.5831e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.135404
Average KL loss: 0.146552
Average total loss: 0.281956
tensor(0.0094, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-3.7505e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.135950
Average KL loss: 0.146773
Average total loss: 0.282723
tensor(0.0094, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-1.5758e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.141772
Average KL loss: 0.146991
Average total loss: 0.288763
tensor(0.0094, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-2.3896e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.134788
Average KL loss: 0.147176
Average total loss: 0.281963
tensor(0.0094, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-5.0544e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.134237
Average KL loss: 0.147377
Average total loss: 0.281614
tensor(0.0094, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-5.2895e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.133317
Average KL loss: 0.147565
Average total loss: 0.280881
tensor(0.0095, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-7.9148e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.133654
Average KL loss: 0.147764
Average total loss: 0.281418
tensor(0.0095, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-3.1652e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.130579
Average KL loss: 0.147932
Average total loss: 0.278512
tensor(0.0095, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-5.1811e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.132529
Average KL loss: 0.148103
Average total loss: 0.280632
tensor(0.0095, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-1.4883e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.131330
Average KL loss: 0.148276
Average total loss: 0.279606
tensor(0.0095, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.8212e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.130612
Average KL loss: 0.148479
Average total loss: 0.279091
tensor(0.0095, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-2.3124e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.127262
Average KL loss: 0.148644
Average total loss: 0.275905
tensor(0.0095, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-2.9626e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.133133
Average KL loss: 0.148780
Average total loss: 0.281913
tensor(0.0095, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-3.9575e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.130833
Average KL loss: 0.148987
Average total loss: 0.279820
tensor(0.0095, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-7.0209e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.132458
Average KL loss: 0.149190
Average total loss: 0.281648
tensor(0.0096, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-3.2326e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.129162
Average KL loss: 0.149404
Average total loss: 0.278565
tensor(0.0096, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-5.8104e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.128243
Average KL loss: 0.149583
Average total loss: 0.277826
tensor(0.0096, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-2.8621e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.126715
Average KL loss: 0.149713
Average total loss: 0.276429
tensor(0.0096, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-1.3612e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.124977
Average KL loss: 0.149901
Average total loss: 0.274878
tensor(0.0096, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-3.1068e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.123382
Average KL loss: 0.150079
Average total loss: 0.273461
tensor(0.0096, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-4.0074e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.125098
Average KL loss: 0.150257
Average total loss: 0.275355
tensor(0.0096, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-3.2715e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.128375
Average KL loss: 0.150422
Average total loss: 0.278797
tensor(0.0096, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-4.3792e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.123673
Average KL loss: 0.150550
Average total loss: 0.274223
tensor(0.0097, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-2.4366e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.124056
Average KL loss: 0.150701
Average total loss: 0.274757
tensor(0.0097, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-4.4061e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.118899
Average KL loss: 0.150848
Average total loss: 0.269747
tensor(0.0097, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-4.7031e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.128839
Average KL loss: 0.150960
Average total loss: 0.279799
tensor(0.0097, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-3.2013e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.126136
Average KL loss: 0.151111
Average total loss: 0.277247
tensor(0.0097, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-2.9964e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.123900
Average KL loss: 0.151290
Average total loss: 0.275190
tensor(0.0097, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-3.6295e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.122378
Average KL loss: 0.151469
Average total loss: 0.273846
tensor(0.0097, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-3.5846e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.120684
Average KL loss: 0.151631
Average total loss: 0.272315
tensor(0.0097, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-5.7899e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.124183
Average KL loss: 0.151796
Average total loss: 0.275980
tensor(0.0098, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-1.9241e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.120854
Average KL loss: 0.151924
Average total loss: 0.272778
tensor(0.0098, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-1.1427e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.116011
Average KL loss: 0.152056
Average total loss: 0.268067
tensor(0.0098, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-8.3203e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.120037
Average KL loss: 0.152179
Average total loss: 0.272216
tensor(0.0098, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-3.0187e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.122232
Average KL loss: 0.152322
Average total loss: 0.274554
tensor(0.0098, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-1.2179e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.118692
Average KL loss: 0.152487
Average total loss: 0.271179
tensor(0.0098, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-2.1524e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.118052
Average KL loss: 0.152592
Average total loss: 0.270644
tensor(0.0098, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-2.9646e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.115962
Average KL loss: 0.152751
Average total loss: 0.268714
tensor(0.0098, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-9.7690e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.119873
Average KL loss: 0.152886
Average total loss: 0.272759
tensor(0.0098, device='cuda:0') tensor(0.0322, device='cuda:0') tensor(-2.7239e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.115892
Average KL loss: 0.152988
Average total loss: 0.268880
tensor(0.0098, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(-9.7696e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.112739
Average KL loss: 0.153145
Average total loss: 0.265884
tensor(0.0099, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(-4.7165e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.116667
Average KL loss: 0.153273
Average total loss: 0.269940
tensor(0.0099, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-8.5971e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.112651
Average KL loss: 0.153389
Average total loss: 0.266040
tensor(0.0099, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-4.9802e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.113587
Average KL loss: 0.153497
Average total loss: 0.267084
tensor(0.0099, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-9.2290e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.112464
Average KL loss: 0.153584
Average total loss: 0.266048
tensor(0.0099, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-5.2591e-11, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.115376
Average KL loss: 0.153673
Average total loss: 0.269049
tensor(0.0099, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-3.7550e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.112533
Average KL loss: 0.153782
Average total loss: 0.266314
tensor(0.0099, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.8551e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.113998
Average KL loss: 0.153862
Average total loss: 0.267860
tensor(0.0099, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-2.5498e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.115865
Average KL loss: 0.154012
Average total loss: 0.269877
tensor(0.0099, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-3.4912e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.111341
Average KL loss: 0.154181
Average total loss: 0.265522
tensor(0.0100, device='cuda:0') tensor(0.0331, device='cuda:0') tensor(-3.0616e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.111081
Average KL loss: 0.154292
Average total loss: 0.265373
tensor(0.0100, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-1.1285e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.126961
Average KL loss: 0.154395
Average total loss: 0.281357
tensor(0.0100, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(-2.0549e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.111782
Average KL loss: 0.154553
Average total loss: 0.266334
tensor(0.0100, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-4.7199e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.111899
Average KL loss: 0.154615
Average total loss: 0.266514
tensor(0.0100, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(-3.9666e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.109222
Average KL loss: 0.154714
Average total loss: 0.263936
tensor(0.0100, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(-3.7804e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.108203
Average KL loss: 0.154825
Average total loss: 0.263028
tensor(0.0100, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-3.9287e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.106503
Average KL loss: 0.154921
Average total loss: 0.261424
tensor(0.0100, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-2.1630e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.109374
Average KL loss: 0.155030
Average total loss: 0.264405
tensor(0.0100, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-1.0352e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.106929
Average KL loss: 0.155126
Average total loss: 0.262054
tensor(0.0100, device='cuda:0') tensor(0.0339, device='cuda:0') tensor(-9.8347e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.108875
Average KL loss: 0.155199
Average total loss: 0.264074
tensor(0.0100, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-1.7326e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.107891
Average KL loss: 0.155252
Average total loss: 0.263143
tensor(0.0100, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-2.8149e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.107167
Average KL loss: 0.155334
Average total loss: 0.262501
tensor(0.0101, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-3.1206e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.108435
Average KL loss: 0.155435
Average total loss: 0.263870
tensor(0.0101, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-1.7719e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.106672
Average KL loss: 0.155522
Average total loss: 0.262194
tensor(0.0101, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(5.8997e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.106840
Average KL loss: 0.155587
Average total loss: 0.262427
tensor(0.0101, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(-1.7247e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.107747
Average KL loss: 0.155682
Average total loss: 0.263428
tensor(0.0101, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-2.8607e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.110232
Average KL loss: 0.155764
Average total loss: 0.265996
tensor(0.0101, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(1.4171e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.105983
Average KL loss: 0.155850
Average total loss: 0.261832
tensor(0.0101, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-2.0107e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.105819
Average KL loss: 0.155868
Average total loss: 0.261687
tensor(0.0101, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-4.4379e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.106890
Average KL loss: 0.155862
Average total loss: 0.262752
tensor(0.0101, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-2.5850e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.107081
Average KL loss: 0.155858
Average total loss: 0.262939
tensor(0.0101, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-2.0281e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.103164
Average KL loss: 0.155854
Average total loss: 0.259018
tensor(0.0101, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-1.6069e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.105689
Average KL loss: 0.155848
Average total loss: 0.261537
tensor(0.0101, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-1.3256e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.104097
Average KL loss: 0.155840
Average total loss: 0.259937
tensor(0.0101, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-3.3596e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.107598
Average KL loss: 0.155832
Average total loss: 0.263430
tensor(0.0101, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-1.8125e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.105877
Average KL loss: 0.155830
Average total loss: 0.261706
tensor(0.0101, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-1.8462e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.105580
Average KL loss: 0.155824
Average total loss: 0.261405
tensor(0.0101, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-3.2990e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.104928
Average KL loss: 0.155818
Average total loss: 0.260745
tensor(0.0101, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-6.3958e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.106833
Average KL loss: 0.155817
Average total loss: 0.262650
tensor(0.0101, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-1.4534e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.105590
Average KL loss: 0.155819
Average total loss: 0.261408
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-2.8031e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.105485
Average KL loss: 0.155816
Average total loss: 0.261302
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.9393e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.104993
Average KL loss: 0.155811
Average total loss: 0.260804
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.0408e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.104248
Average KL loss: 0.155802
Average total loss: 0.260050
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-2.3422e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.105725
Average KL loss: 0.155799
Average total loss: 0.261524
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-2.0954e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.105921
Average KL loss: 0.155799
Average total loss: 0.261720
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.2429e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.104810
Average KL loss: 0.155799
Average total loss: 0.260609
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.3090e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.106795
Average KL loss: 0.155798
Average total loss: 0.262594
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(2.5491e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.104897
Average KL loss: 0.155798
Average total loss: 0.260695
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-2.7098e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.105402
Average KL loss: 0.155797
Average total loss: 0.261199
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-2.7787e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.111344
Average KL loss: 0.155796
Average total loss: 0.267140
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-4.2482e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.106548
Average KL loss: 0.155795
Average total loss: 0.262343
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.4108e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.105223
Average KL loss: 0.155794
Average total loss: 0.261017
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.1613e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.104789
Average KL loss: 0.155793
Average total loss: 0.260582
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-2.7583e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.105371
Average KL loss: 0.155793
Average total loss: 0.261164
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-2.5993e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.102050
Average KL loss: 0.155793
Average total loss: 0.257843
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-6.0876e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.103934
Average KL loss: 0.155793
Average total loss: 0.259727
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-3.1943e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.106265
Average KL loss: 0.155793
Average total loss: 0.262058
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-3.9822e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.105685
Average KL loss: 0.155793
Average total loss: 0.261477
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.6864e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.103197
Average KL loss: 0.155793
Average total loss: 0.258990
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.1994e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.103423
Average KL loss: 0.155793
Average total loss: 0.259216
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.9892e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.106056
Average KL loss: 0.155793
Average total loss: 0.261848
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.0077e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.105985
Average KL loss: 0.155793
Average total loss: 0.261778
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(6.3610e-10, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.107685
Average KL loss: 0.155793
Average total loss: 0.263478
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.4714e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.104525
Average KL loss: 0.155793
Average total loss: 0.260318
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-2.8788e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.105236
Average KL loss: 0.155792
Average total loss: 0.261028
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(3.4600e-10, device='cuda:0')
 Percentile value: 3.785597467422485
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/8]: ---
conv1.weight         | nonzeros =      72 /    1728             (  4.17%) | total_pruned =    1656 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      77 /   36864             (  0.21%) | total_pruned =   36787 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     108 /   36864             (  0.29%) | total_pruned =   36756 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     122 /   36864             (  0.33%) | total_pruned =   36742 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     237 /   36864             (  0.64%) | total_pruned =   36627 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     753 /   73728             (  1.02%) | total_pruned =   72975 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1651 /  147456             (  1.12%) | total_pruned =  145805 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     182 /    8192             (  2.22%) | total_pruned =    8010 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     983 /  147456             (  0.67%) | total_pruned =  146473 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     958 /  147456             (  0.65%) | total_pruned =  146498 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      17 /     128             ( 13.28%) | total_pruned =     111 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2869 /  294912             (  0.97%) | total_pruned =  292043 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     160 /     256             ( 62.50%) | total_pruned =      96 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    4034 /  589824             (  0.68%) | total_pruned =  585790 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     159 /     256             ( 62.11%) | total_pruned =      97 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     433 /   32768             (  1.32%) | total_pruned =   32335 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     108 /     256             ( 42.19%) | total_pruned =     148 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      50 /     256             ( 19.53%) | total_pruned =     206 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2226 /  589824             (  0.38%) | total_pruned =  587598 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1676 /  589824             (  0.28%) | total_pruned =  588148 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     103 /     256             ( 40.23%) | total_pruned =     153 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      31 /     256             ( 12.11%) | total_pruned =     225 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    3130 / 1179648             (  0.27%) | total_pruned = 1176518 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     343 /     512             ( 66.99%) | total_pruned =     169 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      27 /     512             (  5.27%) | total_pruned =     485 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    2258 / 2359296             (  0.10%) | total_pruned = 2357038 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     180 /     512             ( 35.16%) | total_pruned =     332 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     107 /     512             ( 20.90%) | total_pruned =     405 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      40 /  131072             (  0.03%) | total_pruned =  131032 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     117 /     512             ( 22.85%) | total_pruned =     395 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1237 / 2359296             (  0.05%) | total_pruned = 2358059 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      96 /     512             ( 18.75%) | total_pruned =     416 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     945 / 2359296             (  0.04%) | total_pruned = 2358351 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     201 /     512             ( 39.26%) | total_pruned =     311 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     105 /     512             ( 20.51%) | total_pruned =     407 | shape = torch.Size([512])
linear.weight        | nonzeros =     619 /    5120             ( 12.09%) | total_pruned =    4501 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 99/100 Loss: 0.086606 Accuracy: 83.44 99.79 % Best test Accuracy: 84.82%
tensor(0.0101, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-6.4496e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.230333
Average KL loss: 0.143702
Average total loss: 0.374035
tensor(0.0086, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-1.5958e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.229657
Average KL loss: 0.130110
Average total loss: 0.359767
tensor(0.0079, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.4373e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.230227
Average KL loss: 0.124064
Average total loss: 0.354290
tensor(0.0075, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-1.0022e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.225914
Average KL loss: 0.120903
Average total loss: 0.346817
tensor(0.0072, device='cuda:0') tensor(0.0260, device='cuda:0') tensor(-1.3737e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.238392
Average KL loss: 0.118791
Average total loss: 0.357183
tensor(0.0071, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-7.0585e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.224492
Average KL loss: 0.117131
Average total loss: 0.341623
tensor(0.0070, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-1.1257e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.212989
Average KL loss: 0.115806
Average total loss: 0.328795
tensor(0.0069, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-1.9069e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.219374
Average KL loss: 0.114923
Average total loss: 0.334297
tensor(0.0069, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-1.0462e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.209545
Average KL loss: 0.114555
Average total loss: 0.324100
tensor(0.0068, device='cuda:0') tensor(0.0253, device='cuda:0') tensor(-1.1720e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.225415
Average KL loss: 0.114498
Average total loss: 0.339913
tensor(0.0068, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-1.9026e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.204573
Average KL loss: 0.114533
Average total loss: 0.319105
tensor(0.0069, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-1.3076e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.206461
Average KL loss: 0.114592
Average total loss: 0.321053
tensor(0.0069, device='cuda:0') tensor(0.0256, device='cuda:0') tensor(-1.0106e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.205222
Average KL loss: 0.114655
Average total loss: 0.319877
tensor(0.0069, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-1.0178e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.199140
Average KL loss: 0.114753
Average total loss: 0.313893
tensor(0.0069, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-8.1418e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.201641
Average KL loss: 0.114860
Average total loss: 0.316500
tensor(0.0069, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-9.9947e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.202954
Average KL loss: 0.114965
Average total loss: 0.317919
tensor(0.0069, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-1.0259e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.203578
Average KL loss: 0.115061
Average total loss: 0.318639
tensor(0.0069, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-7.0899e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.187552
Average KL loss: 0.115154
Average total loss: 0.302706
tensor(0.0069, device='cuda:0') tensor(0.0265, device='cuda:0') tensor(-1.2131e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.182881
Average KL loss: 0.115272
Average total loss: 0.298153
tensor(0.0070, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-1.1482e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.179366
Average KL loss: 0.115392
Average total loss: 0.294759
tensor(0.0070, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-6.0729e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.178889
Average KL loss: 0.115496
Average total loss: 0.294385
tensor(0.0070, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-1.6042e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.198748
Average KL loss: 0.115615
Average total loss: 0.314363
tensor(0.0070, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-7.7772e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.177908
Average KL loss: 0.115736
Average total loss: 0.293644
tensor(0.0070, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-5.9831e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.169187
Average KL loss: 0.115859
Average total loss: 0.285046
tensor(0.0070, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-7.3692e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.168110
Average KL loss: 0.115971
Average total loss: 0.284081
tensor(0.0070, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-1.2588e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.175468
Average KL loss: 0.116085
Average total loss: 0.291553
tensor(0.0071, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-8.3649e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.166112
Average KL loss: 0.116211
Average total loss: 0.282323
tensor(0.0071, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-7.0824e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.170487
Average KL loss: 0.116339
Average total loss: 0.286827
tensor(0.0071, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-6.7990e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.158384
Average KL loss: 0.116456
Average total loss: 0.274841
tensor(0.0071, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-1.0824e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.155531
Average KL loss: 0.116561
Average total loss: 0.272092
tensor(0.0071, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-6.1793e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.173281
Average KL loss: 0.116658
Average total loss: 0.289939
tensor(0.0071, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-6.5676e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.154033
Average KL loss: 0.116765
Average total loss: 0.270798
tensor(0.0071, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-5.4378e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.164992
Average KL loss: 0.116849
Average total loss: 0.281841
tensor(0.0072, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-6.7265e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.147145
Average KL loss: 0.116958
Average total loss: 0.264103
tensor(0.0072, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-8.7925e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.147482
Average KL loss: 0.117081
Average total loss: 0.264564
tensor(0.0072, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-1.0452e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.154633
Average KL loss: 0.117187
Average total loss: 0.271821
tensor(0.0072, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-5.3935e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.141325
Average KL loss: 0.117298
Average total loss: 0.258622
tensor(0.0072, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-7.6395e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.146879
Average KL loss: 0.117413
Average total loss: 0.264292
tensor(0.0072, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-3.9433e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.136177
Average KL loss: 0.117521
Average total loss: 0.253698
tensor(0.0072, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-6.5943e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.146832
Average KL loss: 0.117650
Average total loss: 0.264482
tensor(0.0073, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-7.8365e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.148320
Average KL loss: 0.117764
Average total loss: 0.266084
tensor(0.0073, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-5.8815e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.147415
Average KL loss: 0.117866
Average total loss: 0.265281
tensor(0.0073, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-3.1143e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.141221
Average KL loss: 0.117981
Average total loss: 0.259202
tensor(0.0073, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-6.0968e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.135122
Average KL loss: 0.118101
Average total loss: 0.253223
tensor(0.0073, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-1.0805e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.147028
Average KL loss: 0.118207
Average total loss: 0.265235
tensor(0.0073, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-5.4420e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.138455
Average KL loss: 0.118315
Average total loss: 0.256770
tensor(0.0074, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-5.7245e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.131444
Average KL loss: 0.118426
Average total loss: 0.249869
tensor(0.0074, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-6.1179e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.135481
Average KL loss: 0.118522
Average total loss: 0.254003
tensor(0.0074, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-7.7465e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.125181
Average KL loss: 0.118606
Average total loss: 0.243787
tensor(0.0074, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-4.4664e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.141110
Average KL loss: 0.118697
Average total loss: 0.259807
tensor(0.0074, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-5.1722e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.129652
Average KL loss: 0.118789
Average total loss: 0.248440
tensor(0.0074, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-3.6493e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.133476
Average KL loss: 0.118877
Average total loss: 0.252354
tensor(0.0074, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-1.2281e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.123783
Average KL loss: 0.118960
Average total loss: 0.242743
tensor(0.0074, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-4.4257e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.121990
Average KL loss: 0.119050
Average total loss: 0.241040
tensor(0.0075, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-3.4537e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.124440
Average KL loss: 0.119129
Average total loss: 0.243569
tensor(0.0075, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-8.9569e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.120772
Average KL loss: 0.119204
Average total loss: 0.239976
tensor(0.0075, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-5.0627e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.119319
Average KL loss: 0.119277
Average total loss: 0.238596
tensor(0.0075, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-4.5384e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.116325
Average KL loss: 0.119359
Average total loss: 0.235683
tensor(0.0075, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-3.8080e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.120234
Average KL loss: 0.119449
Average total loss: 0.239683
tensor(0.0075, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-3.5143e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.116242
Average KL loss: 0.119527
Average total loss: 0.235769
tensor(0.0075, device='cuda:0') tensor(0.0322, device='cuda:0') tensor(-4.9913e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.120872
Average KL loss: 0.119602
Average total loss: 0.240474
tensor(0.0076, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-4.9248e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.125318
Average KL loss: 0.119684
Average total loss: 0.245002
tensor(0.0076, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-2.4360e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.116091
Average KL loss: 0.119777
Average total loss: 0.235868
tensor(0.0076, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-4.9913e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.116805
Average KL loss: 0.119857
Average total loss: 0.236661
tensor(0.0076, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-5.6008e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.125136
Average KL loss: 0.119954
Average total loss: 0.245090
tensor(0.0076, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-3.6084e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.113239
Average KL loss: 0.120042
Average total loss: 0.233281
tensor(0.0076, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-5.1496e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.110910
Average KL loss: 0.120121
Average total loss: 0.231031
tensor(0.0076, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-4.3599e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.117954
Average KL loss: 0.120197
Average total loss: 0.238151
tensor(0.0077, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(-2.1785e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.117676
Average KL loss: 0.120280
Average total loss: 0.237956
tensor(0.0077, device='cuda:0') tensor(0.0334, device='cuda:0') tensor(-2.0073e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.108926
Average KL loss: 0.120369
Average total loss: 0.229294
tensor(0.0077, device='cuda:0') tensor(0.0336, device='cuda:0') tensor(-1.5192e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.113747
Average KL loss: 0.120463
Average total loss: 0.234210
tensor(0.0077, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-2.8194e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.115493
Average KL loss: 0.120535
Average total loss: 0.236028
tensor(0.0077, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-4.8630e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.112538
Average KL loss: 0.120617
Average total loss: 0.233155
tensor(0.0077, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-4.6151e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.107069
Average KL loss: 0.120702
Average total loss: 0.227771
tensor(0.0077, device='cuda:0') tensor(0.0341, device='cuda:0') tensor(-4.1151e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.108688
Average KL loss: 0.120772
Average total loss: 0.229460
tensor(0.0078, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-1.7360e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.107939
Average KL loss: 0.120827
Average total loss: 0.228766
tensor(0.0078, device='cuda:0') tensor(0.0344, device='cuda:0') tensor(-1.6113e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.109230
Average KL loss: 0.120900
Average total loss: 0.230131
tensor(0.0078, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-8.4927e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.110025
Average KL loss: 0.120973
Average total loss: 0.230998
tensor(0.0078, device='cuda:0') tensor(0.0346, device='cuda:0') tensor(-4.4387e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.101865
Average KL loss: 0.121054
Average total loss: 0.222919
tensor(0.0078, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-4.2306e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.105762
Average KL loss: 0.121114
Average total loss: 0.226877
tensor(0.0078, device='cuda:0') tensor(0.0349, device='cuda:0') tensor(-6.2785e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.107196
Average KL loss: 0.121180
Average total loss: 0.228377
tensor(0.0078, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-4.3275e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.103645
Average KL loss: 0.121255
Average total loss: 0.224900
tensor(0.0078, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-2.2633e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.102542
Average KL loss: 0.121335
Average total loss: 0.223877
tensor(0.0079, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-2.3835e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.102167
Average KL loss: 0.121389
Average total loss: 0.223556
tensor(0.0079, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-2.8804e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.102384
Average KL loss: 0.121436
Average total loss: 0.223820
tensor(0.0079, device='cuda:0') tensor(0.0355, device='cuda:0') tensor(-3.5982e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.100563
Average KL loss: 0.121492
Average total loss: 0.222054
tensor(0.0079, device='cuda:0') tensor(0.0357, device='cuda:0') tensor(-7.9494e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.103264
Average KL loss: 0.121578
Average total loss: 0.224842
tensor(0.0079, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-3.2682e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.098165
Average KL loss: 0.121655
Average total loss: 0.219820
tensor(0.0079, device='cuda:0') tensor(0.0360, device='cuda:0') tensor(-3.4184e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.108778
Average KL loss: 0.121719
Average total loss: 0.230497
tensor(0.0079, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-2.7811e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.105065
Average KL loss: 0.121772
Average total loss: 0.226836
tensor(0.0079, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-5.6965e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.096877
Average KL loss: 0.121821
Average total loss: 0.218698
tensor(0.0080, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-4.4226e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.100443
Average KL loss: 0.121870
Average total loss: 0.222313
tensor(0.0080, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-2.6501e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.100959
Average KL loss: 0.121944
Average total loss: 0.222903
tensor(0.0080, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-7.3654e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.101913
Average KL loss: 0.122016
Average total loss: 0.223929
tensor(0.0080, device='cuda:0') tensor(0.0367, device='cuda:0') tensor(-2.6581e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.098929
Average KL loss: 0.122077
Average total loss: 0.221006
tensor(0.0080, device='cuda:0') tensor(0.0369, device='cuda:0') tensor(-2.6491e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.098810
Average KL loss: 0.122136
Average total loss: 0.220946
tensor(0.0080, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-1.8046e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.099720
Average KL loss: 0.122192
Average total loss: 0.221911
tensor(0.0080, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-2.4836e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.108295
Average KL loss: 0.122246
Average total loss: 0.230540
tensor(0.0080, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(-1.6972e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.098019
Average KL loss: 0.122294
Average total loss: 0.220313
tensor(0.0081, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-3.3350e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.096910
Average KL loss: 0.122342
Average total loss: 0.219252
tensor(0.0081, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(-4.5649e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.099716
Average KL loss: 0.122389
Average total loss: 0.222105
tensor(0.0081, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-3.5649e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.091897
Average KL loss: 0.122449
Average total loss: 0.214347
tensor(0.0081, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-2.0338e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.089238
Average KL loss: 0.122505
Average total loss: 0.211743
tensor(0.0081, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-2.7892e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.091849
Average KL loss: 0.122544
Average total loss: 0.214392
tensor(0.0081, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-2.6594e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.089757
Average KL loss: 0.122596
Average total loss: 0.212353
tensor(0.0081, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-1.0833e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.090780
Average KL loss: 0.122644
Average total loss: 0.213425
tensor(0.0081, device='cuda:0') tensor(0.0382, device='cuda:0') tensor(-2.1614e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.091630
Average KL loss: 0.122707
Average total loss: 0.214337
tensor(0.0082, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-2.1295e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.108281
Average KL loss: 0.122778
Average total loss: 0.231059
tensor(0.0082, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-1.7712e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.091617
Average KL loss: 0.122834
Average total loss: 0.214452
tensor(0.0082, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-3.7521e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.091721
Average KL loss: 0.122889
Average total loss: 0.214610
tensor(0.0082, device='cuda:0') tensor(0.0387, device='cuda:0') tensor(-1.2484e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.089210
Average KL loss: 0.122931
Average total loss: 0.212141
tensor(0.0082, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-2.6123e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.093072
Average KL loss: 0.122978
Average total loss: 0.216050
tensor(0.0082, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-2.0144e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.087452
Average KL loss: 0.123028
Average total loss: 0.210479
tensor(0.0082, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-2.3214e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.090277
Average KL loss: 0.123070
Average total loss: 0.213347
tensor(0.0082, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-2.2272e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.090769
Average KL loss: 0.123111
Average total loss: 0.213880
tensor(0.0083, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-1.3813e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.099784
Average KL loss: 0.123161
Average total loss: 0.222946
tensor(0.0083, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-1.1970e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.088322
Average KL loss: 0.123210
Average total loss: 0.211531
tensor(0.0083, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(-1.5250e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.087154
Average KL loss: 0.123253
Average total loss: 0.210407
tensor(0.0083, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(-7.1721e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.085748
Average KL loss: 0.123300
Average total loss: 0.209048
tensor(0.0083, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-2.0802e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.089630
Average KL loss: 0.123333
Average total loss: 0.212964
tensor(0.0083, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-2.6811e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.086071
Average KL loss: 0.123379
Average total loss: 0.209450
tensor(0.0083, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-1.4042e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.088077
Average KL loss: 0.123430
Average total loss: 0.211507
tensor(0.0083, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-2.8244e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.087407
Average KL loss: 0.123476
Average total loss: 0.210882
tensor(0.0084, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-2.0707e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.086183
Average KL loss: 0.123521
Average total loss: 0.209704
tensor(0.0084, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(-1.5958e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.083861
Average KL loss: 0.123565
Average total loss: 0.207426
tensor(0.0084, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-2.4490e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.084420
Average KL loss: 0.123618
Average total loss: 0.208038
tensor(0.0084, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-1.0250e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.088253
Average KL loss: 0.123656
Average total loss: 0.211909
tensor(0.0084, device='cuda:0') tensor(0.0409, device='cuda:0') tensor(-1.8299e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.081573
Average KL loss: 0.123704
Average total loss: 0.205277
tensor(0.0084, device='cuda:0') tensor(0.0410, device='cuda:0') tensor(-8.9400e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.087989
Average KL loss: 0.123738
Average total loss: 0.211728
tensor(0.0084, device='cuda:0') tensor(0.0411, device='cuda:0') tensor(-1.7895e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.085918
Average KL loss: 0.123795
Average total loss: 0.209713
tensor(0.0084, device='cuda:0') tensor(0.0412, device='cuda:0') tensor(-1.7108e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.082349
Average KL loss: 0.123828
Average total loss: 0.206177
tensor(0.0084, device='cuda:0') tensor(0.0413, device='cuda:0') tensor(-1.6688e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.082608
Average KL loss: 0.123853
Average total loss: 0.206461
tensor(0.0085, device='cuda:0') tensor(0.0415, device='cuda:0') tensor(-1.1381e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.082505
Average KL loss: 0.123870
Average total loss: 0.206375
tensor(0.0085, device='cuda:0') tensor(0.0416, device='cuda:0') tensor(-2.9695e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.093286
Average KL loss: 0.123893
Average total loss: 0.217179
tensor(0.0085, device='cuda:0') tensor(0.0417, device='cuda:0') tensor(-7.2046e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.083709
Average KL loss: 0.123910
Average total loss: 0.207620
tensor(0.0085, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-9.4041e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.082290
Average KL loss: 0.123953
Average total loss: 0.206243
tensor(0.0085, device='cuda:0') tensor(0.0419, device='cuda:0') tensor(-7.1195e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.079168
Average KL loss: 0.123988
Average total loss: 0.203156
tensor(0.0085, device='cuda:0') tensor(0.0420, device='cuda:0') tensor(-8.8864e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.087786
Average KL loss: 0.124015
Average total loss: 0.211801
tensor(0.0085, device='cuda:0') tensor(0.0421, device='cuda:0') tensor(-1.7640e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.081457
Average KL loss: 0.124038
Average total loss: 0.205495
tensor(0.0085, device='cuda:0') tensor(0.0423, device='cuda:0') tensor(-1.4517e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.088120
Average KL loss: 0.124058
Average total loss: 0.212178
tensor(0.0085, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-1.5014e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.084369
Average KL loss: 0.124099
Average total loss: 0.208468
tensor(0.0086, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-5.0315e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.081329
Average KL loss: 0.124126
Average total loss: 0.205455
tensor(0.0086, device='cuda:0') tensor(0.0426, device='cuda:0') tensor(-1.0416e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.081294
Average KL loss: 0.124162
Average total loss: 0.205456
tensor(0.0086, device='cuda:0') tensor(0.0427, device='cuda:0') tensor(-2.2410e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.081561
Average KL loss: 0.124193
Average total loss: 0.205753
tensor(0.0086, device='cuda:0') tensor(0.0428, device='cuda:0') tensor(-1.5067e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.077737
Average KL loss: 0.124215
Average total loss: 0.201952
tensor(0.0086, device='cuda:0') tensor(0.0430, device='cuda:0') tensor(-1.0079e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.084670
Average KL loss: 0.124235
Average total loss: 0.208905
tensor(0.0086, device='cuda:0') tensor(0.0431, device='cuda:0') tensor(-1.7911e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.081854
Average KL loss: 0.124279
Average total loss: 0.206133
tensor(0.0086, device='cuda:0') tensor(0.0432, device='cuda:0') tensor(-1.3827e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.086626
Average KL loss: 0.124320
Average total loss: 0.210946
tensor(0.0086, device='cuda:0') tensor(0.0433, device='cuda:0') tensor(-1.0179e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.077506
Average KL loss: 0.124341
Average total loss: 0.201847
tensor(0.0086, device='cuda:0') tensor(0.0434, device='cuda:0') tensor(-7.3053e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.081868
Average KL loss: 0.124359
Average total loss: 0.206228
tensor(0.0086, device='cuda:0') tensor(0.0435, device='cuda:0') tensor(-4.8690e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.082836
Average KL loss: 0.124381
Average total loss: 0.207217
tensor(0.0087, device='cuda:0') tensor(0.0436, device='cuda:0') tensor(-1.6900e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.084834
Average KL loss: 0.124422
Average total loss: 0.209256
tensor(0.0087, device='cuda:0') tensor(0.0438, device='cuda:0') tensor(-3.7715e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.078052
Average KL loss: 0.124452
Average total loss: 0.202504
tensor(0.0087, device='cuda:0') tensor(0.0439, device='cuda:0') tensor(-7.4725e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.082387
Average KL loss: 0.124480
Average total loss: 0.206867
tensor(0.0087, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-1.5137e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.083814
Average KL loss: 0.124507
Average total loss: 0.208321
tensor(0.0087, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(-2.3103e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.079888
Average KL loss: 0.124540
Average total loss: 0.204428
tensor(0.0087, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-1.2528e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.077718
Average KL loss: 0.124569
Average total loss: 0.202287
tensor(0.0087, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-9.5725e-10, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.074462
Average KL loss: 0.124590
Average total loss: 0.199052
tensor(0.0087, device='cuda:0') tensor(0.0445, device='cuda:0') tensor(-1.7729e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.076390
Average KL loss: 0.124600
Average total loss: 0.200990
tensor(0.0087, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-8.0902e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.075031
Average KL loss: 0.124613
Average total loss: 0.199645
tensor(0.0087, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.8013e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.081829
Average KL loss: 0.124636
Average total loss: 0.206465
tensor(0.0088, device='cuda:0') tensor(0.0448, device='cuda:0') tensor(-2.2591e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.076327
Average KL loss: 0.124665
Average total loss: 0.200992
tensor(0.0088, device='cuda:0') tensor(0.0449, device='cuda:0') tensor(-5.8320e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.076946
Average KL loss: 0.124682
Average total loss: 0.201628
tensor(0.0088, device='cuda:0') tensor(0.0450, device='cuda:0') tensor(-3.1291e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.078533
Average KL loss: 0.124705
Average total loss: 0.203238
tensor(0.0088, device='cuda:0') tensor(0.0451, device='cuda:0') tensor(-1.2179e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.075329
Average KL loss: 0.124720
Average total loss: 0.200048
tensor(0.0088, device='cuda:0') tensor(0.0452, device='cuda:0') tensor(-1.4210e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.080716
Average KL loss: 0.124730
Average total loss: 0.205446
tensor(0.0088, device='cuda:0') tensor(0.0453, device='cuda:0') tensor(-1.4528e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.073182
Average KL loss: 0.124759
Average total loss: 0.197941
tensor(0.0088, device='cuda:0') tensor(0.0454, device='cuda:0') tensor(-1.6930e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.076922
Average KL loss: 0.124791
Average total loss: 0.201714
tensor(0.0088, device='cuda:0') tensor(0.0455, device='cuda:0') tensor(-1.2317e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.074368
Average KL loss: 0.124825
Average total loss: 0.199194
tensor(0.0088, device='cuda:0') tensor(0.0456, device='cuda:0') tensor(-1.5181e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.075798
Average KL loss: 0.124850
Average total loss: 0.200648
tensor(0.0088, device='cuda:0') tensor(0.0457, device='cuda:0') tensor(-2.4397e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.077153
Average KL loss: 0.124877
Average total loss: 0.202030
tensor(0.0089, device='cuda:0') tensor(0.0459, device='cuda:0') tensor(-4.5786e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.075990
Average KL loss: 0.124892
Average total loss: 0.200882
tensor(0.0089, device='cuda:0') tensor(0.0459, device='cuda:0') tensor(-2.2373e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.072991
Average KL loss: 0.124904
Average total loss: 0.197896
tensor(0.0089, device='cuda:0') tensor(0.0461, device='cuda:0') tensor(-1.7612e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.081682
Average KL loss: 0.124916
Average total loss: 0.206598
tensor(0.0089, device='cuda:0') tensor(0.0462, device='cuda:0') tensor(-1.4106e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.074446
Average KL loss: 0.124925
Average total loss: 0.199371
tensor(0.0089, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(-1.4086e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.074253
Average KL loss: 0.124940
Average total loss: 0.199193
tensor(0.0089, device='cuda:0') tensor(0.0464, device='cuda:0') tensor(-9.6288e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.073834
Average KL loss: 0.124957
Average total loss: 0.198791
tensor(0.0089, device='cuda:0') tensor(0.0465, device='cuda:0') tensor(-1.3408e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.077145
Average KL loss: 0.124984
Average total loss: 0.202129
tensor(0.0089, device='cuda:0') tensor(0.0466, device='cuda:0') tensor(-1.0103e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.073769
Average KL loss: 0.125017
Average total loss: 0.198786
tensor(0.0089, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.4514e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.079589
Average KL loss: 0.125039
Average total loss: 0.204628
tensor(0.0089, device='cuda:0') tensor(0.0468, device='cuda:0') tensor(-7.7522e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.079036
Average KL loss: 0.125066
Average total loss: 0.204102
tensor(0.0089, device='cuda:0') tensor(0.0469, device='cuda:0') tensor(-1.6336e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.076404
Average KL loss: 0.125092
Average total loss: 0.201496
tensor(0.0090, device='cuda:0') tensor(0.0470, device='cuda:0') tensor(-8.0936e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.076930
Average KL loss: 0.125117
Average total loss: 0.202046
tensor(0.0090, device='cuda:0') tensor(0.0471, device='cuda:0') tensor(-1.6616e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.079653
Average KL loss: 0.125142
Average total loss: 0.204795
tensor(0.0090, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-3.4540e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.072288
Average KL loss: 0.125154
Average total loss: 0.197443
tensor(0.0090, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-6.9289e-10, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.076818
Average KL loss: 0.125156
Average total loss: 0.201974
tensor(0.0090, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-2.1630e-10, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.075514
Average KL loss: 0.125158
Average total loss: 0.200672
tensor(0.0090, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-3.2490e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.073947
Average KL loss: 0.125161
Average total loss: 0.199108
tensor(0.0090, device='cuda:0') tensor(0.0472, device='cuda:0') tensor(-1.1606e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.075333
Average KL loss: 0.125162
Average total loss: 0.200495
tensor(0.0090, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-1.4250e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.074112
Average KL loss: 0.125164
Average total loss: 0.199276
tensor(0.0090, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-1.7490e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.072776
Average KL loss: 0.125167
Average total loss: 0.197943
tensor(0.0090, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-1.4304e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.075318
Average KL loss: 0.125168
Average total loss: 0.200486
tensor(0.0090, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-1.1130e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.078786
Average KL loss: 0.125170
Average total loss: 0.203956
tensor(0.0090, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-1.4536e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.072321
Average KL loss: 0.125172
Average total loss: 0.197493
tensor(0.0090, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-2.0162e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.081374
Average KL loss: 0.125173
Average total loss: 0.206547
tensor(0.0090, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-1.6213e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.073282
Average KL loss: 0.125176
Average total loss: 0.198457
tensor(0.0090, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-2.1795e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.075433
Average KL loss: 0.125176
Average total loss: 0.200609
tensor(0.0090, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-1.6362e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.078093
Average KL loss: 0.125177
Average total loss: 0.203270
tensor(0.0090, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-6.5433e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.073689
Average KL loss: 0.125177
Average total loss: 0.198866
tensor(0.0090, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-8.5340e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.073023
Average KL loss: 0.125177
Average total loss: 0.198200
 Percentile value: 6.669446992874145
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/8]: ---
conv1.weight         | nonzeros =      69 /    1728             (  3.99%) | total_pruned =    1659 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      42 /   36864             (  0.11%) | total_pruned =   36822 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      55 /   36864             (  0.15%) | total_pruned =   36809 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      76 /   36864             (  0.21%) | total_pruned =   36788 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     166 /   36864             (  0.45%) | total_pruned =   36698 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     404 /   73728             (  0.55%) | total_pruned =   73324 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     604 /  147456             (  0.41%) | total_pruned =  146852 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      84 /     128             ( 65.62%) | total_pruned =      44 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      98 /    8192             (  1.20%) | total_pruned =    8094 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     378 /  147456             (  0.26%) | total_pruned =  147078 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     303 /  147456             (  0.21%) | total_pruned =  147153 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     711 /  294912             (  0.24%) | total_pruned =  294201 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     150 /     256             ( 58.59%) | total_pruned =     106 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     897 /  589824             (  0.15%) | total_pruned =  588927 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     140 /     256             ( 54.69%) | total_pruned =     116 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      33 /     256             ( 12.89%) | total_pruned =     223 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     107 /   32768             (  0.33%) | total_pruned =   32661 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      74 /     256             ( 28.91%) | total_pruned =     182 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      31 /     256             ( 12.11%) | total_pruned =     225 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     579 /  589824             (  0.10%) | total_pruned =  589245 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     142 /     256             ( 55.47%) | total_pruned =     114 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     532 /  589824             (  0.09%) | total_pruned =  589292 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      71 /     256             ( 27.73%) | total_pruned =     185 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     454 / 1179648             (  0.04%) | total_pruned = 1179194 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     254 /     512             ( 49.61%) | total_pruned =     258 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     423 / 2359296             (  0.02%) | total_pruned = 2358873 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      82 /     512             ( 16.02%) | total_pruned =     430 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      53 /     512             ( 10.35%) | total_pruned =     459 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       5 /  131072             (  0.00%) | total_pruned =  131067 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      62 /     512             ( 12.11%) | total_pruned =     450 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     213 / 2359296             (  0.01%) | total_pruned = 2359083 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      53 /     512             ( 10.35%) | total_pruned =     459 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     203 / 2359296             (  0.01%) | total_pruned = 2359093 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      31 /     512             (  6.05%) | total_pruned =     481 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      16 /     512             (  3.12%) | total_pruned =     496 | shape = torch.Size([512])
linear.weight        | nonzeros =     130 /    5120             (  2.54%) | total_pruned =    4990 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 99/100 Loss: 0.706945 Accuracy: 70.67 75.39 % Best test Accuracy: 71.18%
tensor(0.0090, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-3.9605e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.749647
Average KL loss: 0.121417
Average total loss: 0.871064
tensor(0.0081, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(-1.5100e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.754084
Average KL loss: 0.112985
Average total loss: 0.867069
tensor(0.0071, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-1.5173e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.748873
Average KL loss: 0.102354
Average total loss: 0.851227
tensor(0.0062, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-6.6541e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.763066
Average KL loss: 0.088476
Average total loss: 0.851542
tensor(0.0052, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.3799e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.777846
Average KL loss: 0.071414
Average total loss: 0.849259
tensor(0.0043, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.6425e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.775492
Average KL loss: 0.054087
Average total loss: 0.829579
tensor(0.0035, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.3366e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.766047
Average KL loss: 0.041467
Average total loss: 0.807514
tensor(0.0029, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.3831e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.773863
Average KL loss: 0.035326
Average total loss: 0.809188
tensor(0.0026, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.4819e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.774584
Average KL loss: 0.033340
Average total loss: 0.807924
tensor(0.0025, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.4311e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.776500
Average KL loss: 0.032915
Average total loss: 0.809414
tensor(0.0024, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-4.2479e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.785257
Average KL loss: 0.032824
Average total loss: 0.818080
tensor(0.0024, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-6.8735e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.775914
Average KL loss: 0.032771
Average total loss: 0.808686
tensor(0.0024, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.9199e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.782795
Average KL loss: 0.032728
Average total loss: 0.815523
tensor(0.0024, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.8779e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.762251
Average KL loss: 0.032688
Average total loss: 0.794939
tensor(0.0024, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.1377e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.772944
Average KL loss: 0.032653
Average total loss: 0.805598
tensor(0.0024, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.1855e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.773906
Average KL loss: 0.032619
Average total loss: 0.806525
tensor(0.0024, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-7.5185e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.764408
Average KL loss: 0.032586
Average total loss: 0.796994
tensor(0.0024, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.6004e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.772826
Average KL loss: 0.032556
Average total loss: 0.805382
tensor(0.0024, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.6262e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.768892
Average KL loss: 0.032532
Average total loss: 0.801424
tensor(0.0024, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.0009e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.758653
Average KL loss: 0.032505
Average total loss: 0.791158
tensor(0.0024, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-4.9107e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.756725
Average KL loss: 0.032480
Average total loss: 0.789205
tensor(0.0024, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.5575e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.763877
Average KL loss: 0.032462
Average total loss: 0.796339
tensor(0.0024, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-5.8948e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.761889
Average KL loss: 0.032441
Average total loss: 0.794329
tensor(0.0024, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-4.4669e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.764935
Average KL loss: 0.032416
Average total loss: 0.797352
tensor(0.0024, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.9087e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.759502
Average KL loss: 0.032394
Average total loss: 0.791897
tensor(0.0024, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-3.4159e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.766733
Average KL loss: 0.032370
Average total loss: 0.799102
tensor(0.0024, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.2817e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.774562
Average KL loss: 0.032350
Average total loss: 0.806911
tensor(0.0024, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.3088e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.755713
Average KL loss: 0.032329
Average total loss: 0.788043
tensor(0.0024, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.4309e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.753436
Average KL loss: 0.032308
Average total loss: 0.785744
tensor(0.0024, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.1283e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.753094
Average KL loss: 0.032286
Average total loss: 0.785380
tensor(0.0024, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.1343e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.767672
Average KL loss: 0.032269
Average total loss: 0.799941
tensor(0.0024, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.0474e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.755576
Average KL loss: 0.032249
Average total loss: 0.787824
tensor(0.0024, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-6.8499e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.763663
Average KL loss: 0.032232
Average total loss: 0.795895
tensor(0.0024, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.1856e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.754279
Average KL loss: 0.032216
Average total loss: 0.786495
tensor(0.0024, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.9279e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.761990
Average KL loss: 0.032203
Average total loss: 0.794193
tensor(0.0024, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.1574e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.762802
Average KL loss: 0.032186
Average total loss: 0.794988
tensor(0.0024, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.7338e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.762939
Average KL loss: 0.032170
Average total loss: 0.795109
tensor(0.0024, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.8622e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.757804
Average KL loss: 0.032157
Average total loss: 0.789961
tensor(0.0024, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-8.4034e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.777838
Average KL loss: 0.032141
Average total loss: 0.809979
tensor(0.0025, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-4.6512e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.753193
Average KL loss: 0.032130
Average total loss: 0.785324
tensor(0.0025, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.0591e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.742520
Average KL loss: 0.032117
Average total loss: 0.774638
tensor(0.0025, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.8820e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.751347
Average KL loss: 0.032104
Average total loss: 0.783451
tensor(0.0025, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.5670e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.757102
Average KL loss: 0.032090
Average total loss: 0.789192
tensor(0.0025, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.6018e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.743604
Average KL loss: 0.032077
Average total loss: 0.775681
tensor(0.0025, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.6583e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.752424
Average KL loss: 0.032061
Average total loss: 0.784485
tensor(0.0025, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.2998e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.746749
Average KL loss: 0.032046
Average total loss: 0.778795
tensor(0.0025, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-4.9771e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.755459
Average KL loss: 0.032034
Average total loss: 0.787494
tensor(0.0025, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.3381e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.747223
Average KL loss: 0.032022
Average total loss: 0.779244
tensor(0.0025, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-4.0035e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.743997
Average KL loss: 0.032008
Average total loss: 0.776005
tensor(0.0025, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.0203e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.750893
Average KL loss: 0.031996
Average total loss: 0.782889
tensor(0.0025, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-9.7263e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.747219
Average KL loss: 0.031985
Average total loss: 0.779204
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-3.2720e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.752049
Average KL loss: 0.031975
Average total loss: 0.784024
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-3.8232e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.749748
Average KL loss: 0.031968
Average total loss: 0.781716
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-9.8440e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.754732
Average KL loss: 0.031967
Average total loss: 0.786699
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-7.9531e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.744029
Average KL loss: 0.031966
Average total loss: 0.775996
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.0115e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.746109
Average KL loss: 0.031965
Average total loss: 0.778074
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.4228e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.747410
Average KL loss: 0.031964
Average total loss: 0.779374
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.6364e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.747557
Average KL loss: 0.031963
Average total loss: 0.779521
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.7314e-11, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.751393
Average KL loss: 0.031963
Average total loss: 0.783356
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-9.0861e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.743498
Average KL loss: 0.031962
Average total loss: 0.775460
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-4.1257e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.737305
Average KL loss: 0.031961
Average total loss: 0.769267
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-8.9201e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.744417
Average KL loss: 0.031960
Average total loss: 0.776377
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-5.1774e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.750256
Average KL loss: 0.031960
Average total loss: 0.782216
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-9.5631e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.755803
Average KL loss: 0.031959
Average total loss: 0.787762
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.4468e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.753122
Average KL loss: 0.031958
Average total loss: 0.785081
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-4.4295e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.740853
Average KL loss: 0.031957
Average total loss: 0.772811
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.0015e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.762136
Average KL loss: 0.031957
Average total loss: 0.794092
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.0305e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.754348
Average KL loss: 0.031956
Average total loss: 0.786304
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.5441e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.748646
Average KL loss: 0.031955
Average total loss: 0.780601
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.1013e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.741454
Average KL loss: 0.031954
Average total loss: 0.773409
tensor(0.0025, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-8.8376e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.741249
Average KL loss: 0.031953
Average total loss: 0.773202
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.9333e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.748868
Average KL loss: 0.031953
Average total loss: 0.780820
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.9026e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.753558
Average KL loss: 0.031953
Average total loss: 0.785511
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.2855e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.747814
Average KL loss: 0.031953
Average total loss: 0.779767
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.4070e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.739738
Average KL loss: 0.031952
Average total loss: 0.771691
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-5.6092e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.749526
Average KL loss: 0.031952
Average total loss: 0.781478
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.0735e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.749899
Average KL loss: 0.031952
Average total loss: 0.781852
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-3.8896e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.747985
Average KL loss: 0.031952
Average total loss: 0.779937
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.0694e-11, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.746212
Average KL loss: 0.031952
Average total loss: 0.778165
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.3254e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.748704
Average KL loss: 0.031952
Average total loss: 0.780656
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-5.8725e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.746808
Average KL loss: 0.031952
Average total loss: 0.778760
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-5.1208e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.747594
Average KL loss: 0.031952
Average total loss: 0.779546
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.0047e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.741310
Average KL loss: 0.031952
Average total loss: 0.773262
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.5931e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.747356
Average KL loss: 0.031952
Average total loss: 0.779308
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-3.6576e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.750667
Average KL loss: 0.031952
Average total loss: 0.782619
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.0701e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.752778
Average KL loss: 0.031952
Average total loss: 0.784730
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.0670e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.743550
Average KL loss: 0.031952
Average total loss: 0.775502
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-9.8127e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.747143
Average KL loss: 0.031952
Average total loss: 0.779095
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.0462e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.749194
Average KL loss: 0.031952
Average total loss: 0.781146
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.6119e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.739788
Average KL loss: 0.031952
Average total loss: 0.771740
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.0943e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.734817
Average KL loss: 0.031952
Average total loss: 0.766769
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.4414e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.744732
Average KL loss: 0.031952
Average total loss: 0.776684
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-4.2335e-11, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.740499
Average KL loss: 0.031952
Average total loss: 0.772452
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.0339e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.750573
Average KL loss: 0.031952
Average total loss: 0.782525
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-9.6320e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.754181
Average KL loss: 0.031952
Average total loss: 0.786133
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-7.7183e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.757937
Average KL loss: 0.031952
Average total loss: 0.789889
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(3.6044e-11, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.743716
Average KL loss: 0.031952
Average total loss: 0.775668
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.4279e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.751118
Average KL loss: 0.031952
Average total loss: 0.783070
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.4095e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.745944
Average KL loss: 0.031952
Average total loss: 0.777896
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.5816e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.766624
Average KL loss: 0.031952
Average total loss: 0.798576
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.7403e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.761441
Average KL loss: 0.031952
Average total loss: 0.793393
tensor(0.0025, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-4.7070e-10, device='cuda:0')
 Percentile value: 6.720022964477539
Non-zero model percentage: 0.02187183126807213%, Non-zero mask percentage: 0.02187183126807213%

--- Pruning Level [7/8]: ---
conv1.weight         | nonzeros =      56 /    1728             (  3.24%) | total_pruned =    1672 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
bn1.bias             | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      16 /   36864             (  0.04%) | total_pruned =   36848 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      21 /   36864             (  0.06%) | total_pruned =   36843 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      47 /   36864             (  0.13%) | total_pruned =   36817 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      70 /   36864             (  0.19%) | total_pruned =   36794 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     137 /   73728             (  0.19%) | total_pruned =   73591 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     160 /  147456             (  0.11%) | total_pruned =  147296 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      34 /    8192             (  0.42%) | total_pruned =    8158 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     139 /  147456             (  0.09%) | total_pruned =  147317 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =      94 /  147456             (  0.06%) | total_pruned =  147362 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     176 /  294912             (  0.06%) | total_pruned =  294736 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      79 /     256             ( 30.86%) | total_pruned =     177 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     166 /  589824             (  0.03%) | total_pruned =  589658 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      72 /     256             ( 28.12%) | total_pruned =     184 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      20 /   32768             (  0.06%) | total_pruned =   32748 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     141 /  589824             (  0.02%) | total_pruned =  589683 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      68 /     256             ( 26.56%) | total_pruned =     188 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     147 /  589824             (  0.02%) | total_pruned =  589677 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      25 /     256             (  9.77%) | total_pruned =     231 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =      81 / 1179648             (  0.01%) | total_pruned = 1179567 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      50 /     512             (  9.77%) | total_pruned =     462 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =      62 / 2359296             (  0.00%) | total_pruned = 2359234 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      25 /     512             (  4.88%) | total_pruned =     487 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =       1 /  131072             (  0.00%) | total_pruned =  131071 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =      50 / 2359296             (  0.00%) | total_pruned = 2359246 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =      52 / 2359296             (  0.00%) | total_pruned = 2359244 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
linear.weight        | nonzeros =      54 /    5120             (  1.05%) | total_pruned =    5066 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 2445, pruned : 11176317, total: 11178762, Compression rate :    4572.09x  ( 99.98% pruned)
Train Epoch: 99/100 Loss: 1.614616 Accuracy: 35.80 35.22 % Best test Accuracy: 35.80%
