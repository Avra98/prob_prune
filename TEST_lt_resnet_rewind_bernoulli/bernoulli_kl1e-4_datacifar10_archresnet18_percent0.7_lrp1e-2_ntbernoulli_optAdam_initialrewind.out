Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/8]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/100 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-2.1415e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.807059
Average KL loss: 0.099185
Average total loss: 1.906244
tensor(0.0003, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-1.1158e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.536392
Average KL loss: 0.187266
Average total loss: 1.723659
tensor(0.0004, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.5550e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.335482
Average KL loss: 0.203975
Average total loss: 1.539457
tensor(0.0005, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.5427e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.212567
Average KL loss: 0.202521
Average total loss: 1.415087
tensor(0.0006, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-1.1285e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.129356
Average KL loss: 0.200126
Average total loss: 1.329483
tensor(0.0007, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-8.2994e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.053372
Average KL loss: 0.193159
Average total loss: 1.246531
tensor(0.0007, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-9.0651e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.990716
Average KL loss: 0.189515
Average total loss: 1.180231
tensor(0.0008, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-1.0346e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.936735
Average KL loss: 0.190883
Average total loss: 1.127618
tensor(0.0008, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-8.4514e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.867394
Average KL loss: 0.186818
Average total loss: 1.054212
tensor(0.0009, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-8.5210e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.837765
Average KL loss: 0.183669
Average total loss: 1.021434
tensor(0.0009, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.3236e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.803425
Average KL loss: 0.180601
Average total loss: 0.984025
tensor(0.0009, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.5203e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.762233
Average KL loss: 0.181105
Average total loss: 0.943337
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.8003e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.725372
Average KL loss: 0.180500
Average total loss: 0.905872
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.2455e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.705688
Average KL loss: 0.179686
Average total loss: 0.885374
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.0426e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.676358
Average KL loss: 0.178742
Average total loss: 0.855100
tensor(0.0010, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.2488e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.640558
Average KL loss: 0.178544
Average total loss: 0.819103
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.3782e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.606625
Average KL loss: 0.174541
Average total loss: 0.781166
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.9983e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.600385
Average KL loss: 0.175483
Average total loss: 0.775868
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.0676e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.577382
Average KL loss: 0.176672
Average total loss: 0.754053
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-5.7464e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.558715
Average KL loss: 0.178658
Average total loss: 0.737373
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.1693e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.541920
Average KL loss: 0.177504
Average total loss: 0.719423
tensor(0.0011, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.0752e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.518534
Average KL loss: 0.178593
Average total loss: 0.697127
tensor(0.0012, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.5057e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.506354
Average KL loss: 0.177409
Average total loss: 0.683763
tensor(0.0012, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-3.3033e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.494398
Average KL loss: 0.179375
Average total loss: 0.673773
tensor(0.0012, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-3.1493e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.476142
Average KL loss: 0.179700
Average total loss: 0.655842
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.1391e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.455866
Average KL loss: 0.178950
Average total loss: 0.634816
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.3682e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.450275
Average KL loss: 0.180364
Average total loss: 0.630638
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.0559e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.438472
Average KL loss: 0.181340
Average total loss: 0.619812
tensor(0.0012, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.1282e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.428657
Average KL loss: 0.183476
Average total loss: 0.612133
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.1405e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.412652
Average KL loss: 0.184110
Average total loss: 0.596762
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-3.3505e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.411501
Average KL loss: 0.183051
Average total loss: 0.594552
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.9416e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.396269
Average KL loss: 0.185423
Average total loss: 0.581692
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.9326e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.382219
Average KL loss: 0.184027
Average total loss: 0.566246
tensor(0.0013, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-2.2416e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.380810
Average KL loss: 0.185709
Average total loss: 0.566519
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.2523e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.380224
Average KL loss: 0.187513
Average total loss: 0.567737
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-1.7453e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.364830
Average KL loss: 0.188788
Average total loss: 0.553617
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.4571e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.365615
Average KL loss: 0.192358
Average total loss: 0.557973
tensor(0.0013, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.9617e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.352055
Average KL loss: 0.192461
Average total loss: 0.544516
tensor(0.0014, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.2759e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.349910
Average KL loss: 0.194233
Average total loss: 0.544143
tensor(0.0014, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-2.6210e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.332771
Average KL loss: 0.191596
Average total loss: 0.524367
tensor(0.0014, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.2670e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.322691
Average KL loss: 0.190435
Average total loss: 0.513126
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.0044e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.316701
Average KL loss: 0.192265
Average total loss: 0.508967
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.1508e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.309037
Average KL loss: 0.191794
Average total loss: 0.500831
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.1331e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.320648
Average KL loss: 0.195304
Average total loss: 0.515952
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.6913e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.307518
Average KL loss: 0.197531
Average total loss: 0.505049
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-6.8348e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.297495
Average KL loss: 0.195246
Average total loss: 0.492741
tensor(0.0014, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-1.9455e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.307040
Average KL loss: 0.197189
Average total loss: 0.504229
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.2557e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.292938
Average KL loss: 0.200869
Average total loss: 0.493807
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.5634e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.277423
Average KL loss: 0.199692
Average total loss: 0.477115
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.6869e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.284466
Average KL loss: 0.200903
Average total loss: 0.485369
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.2269e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.276868
Average KL loss: 0.201698
Average total loss: 0.478566
tensor(0.0014, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.1950e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.269127
Average KL loss: 0.203121
Average total loss: 0.472248
tensor(0.0015, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-1.7374e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.268780
Average KL loss: 0.202764
Average total loss: 0.471545
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.6602e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.266839
Average KL loss: 0.203028
Average total loss: 0.469867
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-7.5060e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.262231
Average KL loss: 0.203778
Average total loss: 0.466009
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.3536e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.258842
Average KL loss: 0.204688
Average total loss: 0.463530
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.5026e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.253502
Average KL loss: 0.205340
Average total loss: 0.458842
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.9029e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.255296
Average KL loss: 0.208157
Average total loss: 0.463453
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.4473e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.247212
Average KL loss: 0.207342
Average total loss: 0.454555
tensor(0.0015, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.4583e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.240889
Average KL loss: 0.208367
Average total loss: 0.449256
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.1806e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.237087
Average KL loss: 0.207449
Average total loss: 0.444536
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.7222e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.236286
Average KL loss: 0.207388
Average total loss: 0.443674
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.0600e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.240660
Average KL loss: 0.211750
Average total loss: 0.452409
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2634e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.232147
Average KL loss: 0.210598
Average total loss: 0.442745
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.0407e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.224523
Average KL loss: 0.209690
Average total loss: 0.434213
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-8.1484e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.235560
Average KL loss: 0.211457
Average total loss: 0.447017
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.2632e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.217586
Average KL loss: 0.212457
Average total loss: 0.430043
tensor(0.0015, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.2295e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.225713
Average KL loss: 0.213914
Average total loss: 0.439627
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.6760e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.229061
Average KL loss: 0.213877
Average total loss: 0.442938
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.1710e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.219295
Average KL loss: 0.215570
Average total loss: 0.434865
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(1.7053e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.221248
Average KL loss: 0.215788
Average total loss: 0.437036
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.6463e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.217305
Average KL loss: 0.216244
Average total loss: 0.433549
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.4341e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.210955
Average KL loss: 0.215536
Average total loss: 0.426492
tensor(0.0015, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-7.9265e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.216271
Average KL loss: 0.218344
Average total loss: 0.434615
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(3.7528e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.202925
Average KL loss: 0.216895
Average total loss: 0.419820
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-7.0934e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.212403
Average KL loss: 0.218813
Average total loss: 0.431216
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.0850e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.210299
Average KL loss: 0.220755
Average total loss: 0.431053
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-4.6704e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.205627
Average KL loss: 0.219302
Average total loss: 0.424929
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-7.9027e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.202450
Average KL loss: 0.221513
Average total loss: 0.423963
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.3602e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.198652
Average KL loss: 0.219973
Average total loss: 0.418625
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-8.6931e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.195221
Average KL loss: 0.219281
Average total loss: 0.414501
tensor(0.0015, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-4.8131e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.198325
Average KL loss: 0.219646
Average total loss: 0.417971
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-6.4182e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.192492
Average KL loss: 0.219272
Average total loss: 0.411764
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-5.9062e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.196327
Average KL loss: 0.220652
Average total loss: 0.416979
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.3770e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.190611
Average KL loss: 0.222206
Average total loss: 0.412817
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-8.9424e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.197929
Average KL loss: 0.223260
Average total loss: 0.421189
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.7825e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.188567
Average KL loss: 0.222689
Average total loss: 0.411255
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.3350e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.185629
Average KL loss: 0.222791
Average total loss: 0.408420
tensor(0.0015, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.6804e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.183710
Average KL loss: 0.221060
Average total loss: 0.404769
tensor(0.0016, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-9.8454e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.188986
Average KL loss: 0.224582
Average total loss: 0.413568
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.1714e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.187043
Average KL loss: 0.224000
Average total loss: 0.411043
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.0405e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.183116
Average KL loss: 0.225752
Average total loss: 0.408868
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(3.6225e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.187383
Average KL loss: 0.225236
Average total loss: 0.412619
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-5.0871e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.176161
Average KL loss: 0.225162
Average total loss: 0.401323
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(4.1458e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.185668
Average KL loss: 0.226110
Average total loss: 0.411777
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.1823e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.175576
Average KL loss: 0.227127
Average total loss: 0.402703
tensor(0.0016, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-9.4672e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.176807
Average KL loss: 0.224252
Average total loss: 0.401058
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-8.5301e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.179821
Average KL loss: 0.227517
Average total loss: 0.407337
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.0387e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.171994
Average KL loss: 0.226376
Average total loss: 0.398370
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.1696e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.182151
Average KL loss: 0.227728
Average total loss: 0.409879
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.7677e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.168456
Average KL loss: 0.227924
Average total loss: 0.396380
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.8047e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.175817
Average KL loss: 0.225758
Average total loss: 0.401575
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.4577e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.171529
Average KL loss: 0.230236
Average total loss: 0.401765
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.2269e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.169237
Average KL loss: 0.227331
Average total loss: 0.396568
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.3344e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.169595
Average KL loss: 0.227030
Average total loss: 0.396625
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.8767e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.164188
Average KL loss: 0.227564
Average total loss: 0.391752
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.0248e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.168932
Average KL loss: 0.228591
Average total loss: 0.397523
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.6000e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.165910
Average KL loss: 0.229551
Average total loss: 0.395460
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-4.3244e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.164127
Average KL loss: 0.226335
Average total loss: 0.390462
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.8939e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.167070
Average KL loss: 0.227716
Average total loss: 0.394786
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.0560e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.170337
Average KL loss: 0.230945
Average total loss: 0.401282
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-6.6526e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.161741
Average KL loss: 0.229987
Average total loss: 0.391728
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-9.2412e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.163254
Average KL loss: 0.229954
Average total loss: 0.393207
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(2.0527e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.163210
Average KL loss: 0.230847
Average total loss: 0.394057
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-7.3006e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.158021
Average KL loss: 0.229052
Average total loss: 0.387073
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(1.1930e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.166417
Average KL loss: 0.229697
Average total loss: 0.396114
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.5153e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.165748
Average KL loss: 0.233115
Average total loss: 0.398863
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-4.6513e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.165887
Average KL loss: 0.233430
Average total loss: 0.399317
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(3.2160e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.157928
Average KL loss: 0.231227
Average total loss: 0.389155
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(6.8215e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.154485
Average KL loss: 0.229284
Average total loss: 0.383769
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-7.6395e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.155625
Average KL loss: 0.229152
Average total loss: 0.384777
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(2.5944e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.158604
Average KL loss: 0.229032
Average total loss: 0.387637
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.1190e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.157715
Average KL loss: 0.232058
Average total loss: 0.389772
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.8133e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.157833
Average KL loss: 0.231639
Average total loss: 0.389472
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.3500e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.153189
Average KL loss: 0.230401
Average total loss: 0.383589
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.6304e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.159175
Average KL loss: 0.235594
Average total loss: 0.394768
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(5.4253e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.157668
Average KL loss: 0.233618
Average total loss: 0.391286
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-9.6045e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.159794
Average KL loss: 0.234932
Average total loss: 0.394727
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.0774e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.160614
Average KL loss: 0.234984
Average total loss: 0.395598
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.1610e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.154253
Average KL loss: 0.233846
Average total loss: 0.388099
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-8.6472e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.157686
Average KL loss: 0.235569
Average total loss: 0.393255
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-4.8835e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.154858
Average KL loss: 0.232819
Average total loss: 0.387678
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.5621e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.149807
Average KL loss: 0.234041
Average total loss: 0.383848
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(8.9533e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.152601
Average KL loss: 0.233083
Average total loss: 0.385684
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.0672e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.154026
Average KL loss: 0.234128
Average total loss: 0.388154
tensor(0.0016, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-4.7850e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.159618
Average KL loss: 0.238231
Average total loss: 0.397849
tensor(0.0016, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.8592e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.142910
Average KL loss: 0.227620
Average total loss: 0.370530
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(9.2778e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.151309
Average KL loss: 0.212144
Average total loss: 0.363453
tensor(0.0016, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(2.4408e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.147320
Average KL loss: 0.204227
Average total loss: 0.351547
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(7.5886e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.148397
Average KL loss: 0.198986
Average total loss: 0.347383
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(7.3057e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.150280
Average KL loss: 0.195374
Average total loss: 0.345654
tensor(0.0016, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(6.1297e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.155224
Average KL loss: 0.192704
Average total loss: 0.347928
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.8799e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.145883
Average KL loss: 0.190539
Average total loss: 0.336422
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.5059e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.145148
Average KL loss: 0.188691
Average total loss: 0.333838
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-9.6645e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.153055
Average KL loss: 0.187313
Average total loss: 0.340368
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.2114e-10, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.148332
Average KL loss: 0.186243
Average total loss: 0.334576
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-4.1194e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.148167
Average KL loss: 0.185169
Average total loss: 0.333336
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-8.5450e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.148688
Average KL loss: 0.184380
Average total loss: 0.333068
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.9628e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.149513
Average KL loss: 0.183687
Average total loss: 0.333199
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-7.5904e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.146320
Average KL loss: 0.182995
Average total loss: 0.329316
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3732e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.151292
Average KL loss: 0.182332
Average total loss: 0.333624
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.7288e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.149852
Average KL loss: 0.181943
Average total loss: 0.331795
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.0082e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.148049
Average KL loss: 0.181506
Average total loss: 0.329555
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.1388e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.150221
Average KL loss: 0.181241
Average total loss: 0.331462
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.4935e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.149710
Average KL loss: 0.180978
Average total loss: 0.330688
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.9497e-10, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.145694
Average KL loss: 0.180661
Average total loss: 0.326354
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.2410e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.148091
Average KL loss: 0.180261
Average total loss: 0.328352
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(7.6919e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.143940
Average KL loss: 0.179923
Average total loss: 0.323863
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.4525e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.149216
Average KL loss: 0.179591
Average total loss: 0.328807
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.1190e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.146853
Average KL loss: 0.179376
Average total loss: 0.326229
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.8073e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.146650
Average KL loss: 0.179159
Average total loss: 0.325809
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.4381e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.148533
Average KL loss: 0.179077
Average total loss: 0.327609
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(5.0903e-10, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.150763
Average KL loss: 0.178985
Average total loss: 0.329748
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3397e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.144303
Average KL loss: 0.178709
Average total loss: 0.323012
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.6915e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.147804
Average KL loss: 0.178494
Average total loss: 0.326298
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-8.8366e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.147946
Average KL loss: 0.178427
Average total loss: 0.326374
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.1850e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.150105
Average KL loss: 0.178309
Average total loss: 0.328413
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.3981e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.149309
Average KL loss: 0.178257
Average total loss: 0.327566
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-6.0313e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.148691
Average KL loss: 0.178164
Average total loss: 0.326855
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.7121e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.150380
Average KL loss: 0.178037
Average total loss: 0.328417
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.7112e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.152333
Average KL loss: 0.178050
Average total loss: 0.330383
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.2672e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.151242
Average KL loss: 0.178058
Average total loss: 0.329300
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.1964e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.153341
Average KL loss: 0.178049
Average total loss: 0.331390
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(5.8018e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.150486
Average KL loss: 0.177973
Average total loss: 0.328459
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(4.8043e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.148168
Average KL loss: 0.177822
Average total loss: 0.325990
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.1695e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.148577
Average KL loss: 0.177577
Average total loss: 0.326154
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.5610e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.152439
Average KL loss: 0.177205
Average total loss: 0.329644
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.9239e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.148372
Average KL loss: 0.176907
Average total loss: 0.325279
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-6.5382e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.148874
Average KL loss: 0.176661
Average total loss: 0.325535
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.9526e-10, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.144449
Average KL loss: 0.176428
Average total loss: 0.320877
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.8556e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.145889
Average KL loss: 0.176222
Average total loss: 0.322112
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.1828e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.150094
Average KL loss: 0.176039
Average total loss: 0.326133
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.3502e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.145606
Average KL loss: 0.175870
Average total loss: 0.321477
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.0667e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.147988
Average KL loss: 0.175722
Average total loss: 0.323710
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(2.3835e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.148484
Average KL loss: 0.175585
Average total loss: 0.324070
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.8706e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.146919
Average KL loss: 0.175458
Average total loss: 0.322377
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.5113e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.143155
Average KL loss: 0.175330
Average total loss: 0.318485
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.3377e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.144687
Average KL loss: 0.175210
Average total loss: 0.319897
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.6213e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.146123
Average KL loss: 0.175092
Average total loss: 0.321215
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3516e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.149649
Average KL loss: 0.174986
Average total loss: 0.324635
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(9.0040e-10, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.142598
Average KL loss: 0.174888
Average total loss: 0.317485
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-5.1123e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.149470
Average KL loss: 0.174792
Average total loss: 0.324262
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(3.1113e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.144864
Average KL loss: 0.174701
Average total loss: 0.319565
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.3838e-10, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.144288
Average KL loss: 0.174614
Average total loss: 0.318902
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-7.8579e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.151849
Average KL loss: 0.174537
Average total loss: 0.326386
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-7.7433e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.148325
Average KL loss: 0.174455
Average total loss: 0.322780
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(4.5472e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.147037
Average KL loss: 0.174380
Average total loss: 0.321418
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.7694e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.144989
Average KL loss: 0.174305
Average total loss: 0.319295
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.2202e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.150460
Average KL loss: 0.174233
Average total loss: 0.324694
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(1.5892e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.143727
Average KL loss: 0.174164
Average total loss: 0.317891
 Percentile value: 0.005206593684852123
Non-zero model percentage: 30.000001907348633%, Non-zero mask percentage: 30.000001907348633%

--- Pruning Level [1/8]: ---
conv1.weight         | nonzeros =    1300 /    1728             ( 75.23%) | total_pruned =     428 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   18694 /   36864             ( 50.71%) | total_pruned =   18170 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   19308 /   36864             ( 52.38%) | total_pruned =   17556 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   18952 /   36864             ( 51.41%) | total_pruned =   17912 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   18766 /   36864             ( 50.91%) | total_pruned =   18098 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   37141 /   73728             ( 50.38%) | total_pruned =   36587 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   72406 /  147456             ( 49.10%) | total_pruned =   75050 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5256 /    8192             ( 64.16%) | total_pruned =    2936 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   66321 /  147456             ( 44.98%) | total_pruned =   81135 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   66964 /  147456             ( 45.41%) | total_pruned =   80492 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =     101 /     128             ( 78.91%) | total_pruned =      27 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  141371 /  294912             ( 47.94%) | total_pruned =  153541 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     237 /     256             ( 92.58%) | total_pruned =      19 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  271958 /  589824             ( 46.11%) | total_pruned =  317866 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   18996 /   32768             ( 57.97%) | total_pruned =   13772 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  221581 /  589824             ( 37.57%) | total_pruned =  368243 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  219229 /  589824             ( 37.17%) | total_pruned =  370595 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     213 /     256             ( 83.20%) | total_pruned =      43 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  499238 / 1179648             ( 42.32%) | total_pruned =  680410 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     470 /     512             ( 91.80%) | total_pruned =      42 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  752611 / 2359296             ( 31.90%) | total_pruned = 1606685 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     502 /     512             ( 98.05%) | total_pruned =      10 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     401 /     512             ( 78.32%) | total_pruned =     111 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   62974 /  131072             ( 48.05%) | total_pruned =   68098 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     404 /     512             ( 78.91%) | total_pruned =     108 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  503008 / 2359296             ( 21.32%) | total_pruned = 1856288 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     417 /     512             ( 81.45%) | total_pruned =      95 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  324988 / 2359296             ( 13.77%) | total_pruned = 2034308 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     131 /     512             ( 25.59%) | total_pruned =     381 | shape = torch.Size([512])
linear.weight        | nonzeros =    4272 /    5120             ( 83.44%) | total_pruned =     848 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       6 /      10             ( 60.00%) | total_pruned =       4 | shape = torch.Size([10])
alive: 3353629, pruned : 7825133, total: 11178762, Compression rate :       3.33x  ( 70.00% pruned)
Train Epoch: 37/100 Loss: 0.000233 Accuracy: 86.71 100.00 % Best test Accuracy: 86.79%
tensor(0.0016, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.4806e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.325225
Average KL loss: 0.203459
Average total loss: 0.528684
tensor(0.0019, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.1979e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.310229
Average KL loss: 0.233863
Average total loss: 0.544092
tensor(0.0020, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.9144e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.290585
Average KL loss: 0.241193
Average total loss: 0.531779
tensor(0.0020, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.6094e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.282016
Average KL loss: 0.247860
Average total loss: 0.529876
tensor(0.0020, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-5.7585e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.268851
Average KL loss: 0.249754
Average total loss: 0.518605
tensor(0.0020, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.3351e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.264486
Average KL loss: 0.250630
Average total loss: 0.515116
tensor(0.0020, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.2419e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.269814
Average KL loss: 0.253208
Average total loss: 0.523023
tensor(0.0020, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.9109e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.259932
Average KL loss: 0.254597
Average total loss: 0.514529
tensor(0.0020, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-4.4448e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.256337
Average KL loss: 0.256850
Average total loss: 0.513187
tensor(0.0021, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.3811e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.257354
Average KL loss: 0.256780
Average total loss: 0.514134
tensor(0.0021, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-6.6272e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.250531
Average KL loss: 0.257804
Average total loss: 0.508336
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.0061e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.249060
Average KL loss: 0.257556
Average total loss: 0.506617
tensor(0.0021, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.2122e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.248325
Average KL loss: 0.259060
Average total loss: 0.507386
tensor(0.0021, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(6.0908e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.242355
Average KL loss: 0.259520
Average total loss: 0.501876
tensor(0.0020, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-9.9143e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.247616
Average KL loss: 0.261966
Average total loss: 0.509582
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-2.0296e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.246670
Average KL loss: 0.263848
Average total loss: 0.510518
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-9.2636e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.238423
Average KL loss: 0.263582
Average total loss: 0.502005
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(1.6383e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.249042
Average KL loss: 0.264252
Average total loss: 0.513293
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(5.5001e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.235646
Average KL loss: 0.264090
Average total loss: 0.499735
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(2.3414e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.230532
Average KL loss: 0.262322
Average total loss: 0.492854
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-9.5816e-11, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.228984
Average KL loss: 0.263165
Average total loss: 0.492149
tensor(0.0021, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-8.1859e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.238992
Average KL loss: 0.264363
Average total loss: 0.503355
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.2246e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.229391
Average KL loss: 0.264903
Average total loss: 0.494294
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.9183e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.223004
Average KL loss: 0.263595
Average total loss: 0.486599
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.8025e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.230140
Average KL loss: 0.264689
Average total loss: 0.494829
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.6336e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.223284
Average KL loss: 0.264624
Average total loss: 0.487908
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.1642e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.229827
Average KL loss: 0.267827
Average total loss: 0.497655
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.8571e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.227504
Average KL loss: 0.268352
Average total loss: 0.495856
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(6.6310e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.220333
Average KL loss: 0.265451
Average total loss: 0.485784
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.2389e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.223510
Average KL loss: 0.266124
Average total loss: 0.489634
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.9614e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.222339
Average KL loss: 0.267672
Average total loss: 0.490011
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(5.1302e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.219926
Average KL loss: 0.268036
Average total loss: 0.487962
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.1326e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.224086
Average KL loss: 0.268872
Average total loss: 0.492958
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.6322e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.221991
Average KL loss: 0.269583
Average total loss: 0.491574
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-6.9467e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.219208
Average KL loss: 0.271413
Average total loss: 0.490621
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.4742e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.220884
Average KL loss: 0.271010
Average total loss: 0.491894
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.6360e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.207368
Average KL loss: 0.268000
Average total loss: 0.475368
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.1609e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.213365
Average KL loss: 0.267388
Average total loss: 0.480753
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.5191e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.208087
Average KL loss: 0.266313
Average total loss: 0.474401
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.9068e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.216782
Average KL loss: 0.267355
Average total loss: 0.484137
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.2820e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.216597
Average KL loss: 0.271894
Average total loss: 0.488492
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.9658e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.211947
Average KL loss: 0.271483
Average total loss: 0.483430
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.4993e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.210695
Average KL loss: 0.270227
Average total loss: 0.480922
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-7.9649e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.219916
Average KL loss: 0.272079
Average total loss: 0.491996
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-9.1794e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.211401
Average KL loss: 0.271888
Average total loss: 0.483289
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.5397e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.212841
Average KL loss: 0.271201
Average total loss: 0.484041
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-9.9712e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.211245
Average KL loss: 0.272502
Average total loss: 0.483746
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.2125e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.212545
Average KL loss: 0.272076
Average total loss: 0.484621
tensor(0.0021, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(8.1360e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.209412
Average KL loss: 0.273796
Average total loss: 0.483208
tensor(0.0021, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.4625e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.207710
Average KL loss: 0.273626
Average total loss: 0.481336
tensor(0.0021, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.3349e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.202468
Average KL loss: 0.268110
Average total loss: 0.470578
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(6.0229e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.206636
Average KL loss: 0.258679
Average total loss: 0.465315
tensor(0.0021, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.5901e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.208559
Average KL loss: 0.251886
Average total loss: 0.460444
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(2.2862e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.204462
Average KL loss: 0.246844
Average total loss: 0.451306
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(3.6740e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.205490
Average KL loss: 0.242879
Average total loss: 0.448370
tensor(0.0021, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.7313e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.205947
Average KL loss: 0.239585
Average total loss: 0.445533
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(2.1693e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.207734
Average KL loss: 0.236849
Average total loss: 0.444582
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.8546e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.208975
Average KL loss: 0.234583
Average total loss: 0.443558
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.9206e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.205637
Average KL loss: 0.232570
Average total loss: 0.438207
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.7507e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.207153
Average KL loss: 0.230803
Average total loss: 0.437956
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(1.1182e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.208295
Average KL loss: 0.229410
Average total loss: 0.437706
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(4.2473e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.200885
Average KL loss: 0.228028
Average total loss: 0.428913
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(2.4885e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.204464
Average KL loss: 0.226755
Average total loss: 0.431220
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(7.0129e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.207526
Average KL loss: 0.225725
Average total loss: 0.433251
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.0810e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.204140
Average KL loss: 0.224774
Average total loss: 0.428914
tensor(0.0021, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-4.7924e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.204125
Average KL loss: 0.223865
Average total loss: 0.427990
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.7096e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.205890
Average KL loss: 0.223034
Average total loss: 0.428925
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.5267e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.207732
Average KL loss: 0.222460
Average total loss: 0.430192
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.8729e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.203340
Average KL loss: 0.221814
Average total loss: 0.425154
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(6.4587e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.198519
Average KL loss: 0.221180
Average total loss: 0.419698
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.0357e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.205943
Average KL loss: 0.220657
Average total loss: 0.426600
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.2947e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.198730
Average KL loss: 0.220112
Average total loss: 0.418842
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.3286e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.204965
Average KL loss: 0.219672
Average total loss: 0.424637
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.1457e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.203380
Average KL loss: 0.219337
Average total loss: 0.422717
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.3677e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.207158
Average KL loss: 0.218997
Average total loss: 0.426155
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.2174e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.208340
Average KL loss: 0.218664
Average total loss: 0.427004
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.2340e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.208424
Average KL loss: 0.218351
Average total loss: 0.426776
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.7154e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.200459
Average KL loss: 0.218096
Average total loss: 0.418555
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(6.1340e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.202347
Average KL loss: 0.217765
Average total loss: 0.420112
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.5489e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.201559
Average KL loss: 0.217474
Average total loss: 0.419033
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.6678e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.199146
Average KL loss: 0.217185
Average total loss: 0.416331
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.3079e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.207782
Average KL loss: 0.216887
Average total loss: 0.424669
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.2330e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.206317
Average KL loss: 0.216737
Average total loss: 0.423054
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.2009e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.203825
Average KL loss: 0.216558
Average total loss: 0.420383
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.4772e-10, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.212480
Average KL loss: 0.216370
Average total loss: 0.428850
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0273e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.204344
Average KL loss: 0.216254
Average total loss: 0.420598
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(4.4909e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.200530
Average KL loss: 0.216117
Average total loss: 0.416647
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.2032e-11, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.203397
Average KL loss: 0.215932
Average total loss: 0.419328
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.2335e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.206308
Average KL loss: 0.215813
Average total loss: 0.422121
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.0934e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.200126
Average KL loss: 0.215704
Average total loss: 0.415830
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.3040e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.205192
Average KL loss: 0.215489
Average total loss: 0.420682
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(5.0769e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.212792
Average KL loss: 0.215434
Average total loss: 0.428226
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(5.9499e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.199218
Average KL loss: 0.215405
Average total loss: 0.414624
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(4.6079e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.201645
Average KL loss: 0.215248
Average total loss: 0.416893
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.5142e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.207829
Average KL loss: 0.215197
Average total loss: 0.423026
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.4883e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.205509
Average KL loss: 0.215164
Average total loss: 0.420673
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(9.9038e-11, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.204015
Average KL loss: 0.215071
Average total loss: 0.419086
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.9276e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.202480
Average KL loss: 0.214955
Average total loss: 0.417435
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.9489e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.198455
Average KL loss: 0.214827
Average total loss: 0.413283
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.9629e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.204247
Average KL loss: 0.214782
Average total loss: 0.419029
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.1711e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.204321
Average KL loss: 0.214673
Average total loss: 0.418994
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.3518e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.205663
Average KL loss: 0.214573
Average total loss: 0.420236
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.5926e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.206526
Average KL loss: 0.214514
Average total loss: 0.421039
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.6243e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.196483
Average KL loss: 0.214523
Average total loss: 0.411006
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.4856e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.205189
Average KL loss: 0.214428
Average total loss: 0.419618
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.3501e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.199834
Average KL loss: 0.214381
Average total loss: 0.414215
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.3273e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.197513
Average KL loss: 0.214302
Average total loss: 0.411816
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.7161e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.202019
Average KL loss: 0.214203
Average total loss: 0.416222
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.1507e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.201035
Average KL loss: 0.214101
Average total loss: 0.415136
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(4.9378e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.206805
Average KL loss: 0.213995
Average total loss: 0.420800
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(5.9144e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.199827
Average KL loss: 0.213968
Average total loss: 0.413795
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.7214e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.196953
Average KL loss: 0.213831
Average total loss: 0.410784
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(5.9753e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.194318
Average KL loss: 0.213689
Average total loss: 0.408007
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.5707e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.207970
Average KL loss: 0.213663
Average total loss: 0.421633
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(9.4012e-11, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.200680
Average KL loss: 0.213719
Average total loss: 0.414399
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.9660e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.196488
Average KL loss: 0.213675
Average total loss: 0.410163
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0706e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.207062
Average KL loss: 0.213668
Average total loss: 0.420730
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.8127e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.199161
Average KL loss: 0.213696
Average total loss: 0.412856
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.2257e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.202086
Average KL loss: 0.213569
Average total loss: 0.415655
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.9003e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.198614
Average KL loss: 0.213526
Average total loss: 0.412140
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.8039e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.206994
Average KL loss: 0.213490
Average total loss: 0.420485
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.6239e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.207009
Average KL loss: 0.213574
Average total loss: 0.420583
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(4.3738e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.199620
Average KL loss: 0.213536
Average total loss: 0.413156
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.6727e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.205673
Average KL loss: 0.213519
Average total loss: 0.419192
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.3126e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.202544
Average KL loss: 0.213470
Average total loss: 0.416014
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(7.7553e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.200106
Average KL loss: 0.213326
Average total loss: 0.413432
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.2710e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.196177
Average KL loss: 0.213179
Average total loss: 0.409357
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.6973e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.204705
Average KL loss: 0.213044
Average total loss: 0.417749
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.8002e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.199291
Average KL loss: 0.212923
Average total loss: 0.412214
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(1.1935e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.199765
Average KL loss: 0.212799
Average total loss: 0.412563
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.0508e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.200781
Average KL loss: 0.212686
Average total loss: 0.413467
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.5405e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.198806
Average KL loss: 0.212580
Average total loss: 0.411386
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.4888e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.199044
Average KL loss: 0.212474
Average total loss: 0.411518
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.8993e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.205458
Average KL loss: 0.212374
Average total loss: 0.417832
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.6962e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.197332
Average KL loss: 0.212283
Average total loss: 0.409615
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.8703e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.200808
Average KL loss: 0.212233
Average total loss: 0.413041
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.4471e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.200853
Average KL loss: 0.212222
Average total loss: 0.413075
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.7260e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.206843
Average KL loss: 0.212212
Average total loss: 0.419055
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(3.1727e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.206310
Average KL loss: 0.212202
Average total loss: 0.418512
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.5907e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.204470
Average KL loss: 0.212192
Average total loss: 0.416662
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.0390e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.194673
Average KL loss: 0.212181
Average total loss: 0.406854
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.5819e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.201465
Average KL loss: 0.212170
Average total loss: 0.413635
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.5954e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.207618
Average KL loss: 0.212160
Average total loss: 0.419778
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.4838e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.203726
Average KL loss: 0.212151
Average total loss: 0.415877
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.9858e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.199919
Average KL loss: 0.212141
Average total loss: 0.412060
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.2587e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.198411
Average KL loss: 0.212130
Average total loss: 0.410541
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.3413e-12, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.199002
Average KL loss: 0.212120
Average total loss: 0.411122
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.0065e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.205811
Average KL loss: 0.212109
Average total loss: 0.417921
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.7068e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.198097
Average KL loss: 0.212100
Average total loss: 0.410197
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(2.0568e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.201521
Average KL loss: 0.212090
Average total loss: 0.413611
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.7538e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.204179
Average KL loss: 0.212080
Average total loss: 0.416259
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.9100e-09, device='cuda:0')
 Percentile value: 0.023410207778215408
Non-zero model percentage: 9.000003814697266%, Non-zero mask percentage: 9.000003814697266%

--- Pruning Level [2/8]: ---
conv1.weight         | nonzeros =    1069 /    1728             ( 61.86%) | total_pruned =     659 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    9215 /   36864             ( 25.00%) | total_pruned =   27649 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    9950 /   36864             ( 26.99%) | total_pruned =   26914 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    9370 /   36864             ( 25.42%) | total_pruned =   27494 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    9172 /   36864             ( 24.88%) | total_pruned =   27692 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   17861 /   73728             ( 24.23%) | total_pruned =   55867 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   32794 /  147456             ( 22.24%) | total_pruned =  114662 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3523 /    8192             ( 43.01%) | total_pruned =    4669 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   25414 /  147456             ( 17.23%) | total_pruned =  122042 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   26130 /  147456             ( 17.72%) | total_pruned =  121326 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   62080 /  294912             ( 21.05%) | total_pruned =  232832 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  110864 /  589824             ( 18.80%) | total_pruned =  478960 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   11164 /   32768             ( 34.07%) | total_pruned =   21604 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     204 /     256             ( 79.69%) | total_pruned =      52 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   62899 /  589824             ( 10.66%) | total_pruned =  526925 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     210 /     256             ( 82.03%) | total_pruned =      46 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     154 /     256             ( 60.16%) | total_pruned =     102 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   63568 /  589824             ( 10.78%) | total_pruned =  526256 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  180337 / 1179648             ( 15.29%) | total_pruned =  999311 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     386 /     512             ( 75.39%) | total_pruned =     126 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  194390 / 2359296             (  8.24%) | total_pruned = 2164906 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     349 /     512             ( 68.16%) | total_pruned =     163 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   26583 /  131072             ( 20.28%) | total_pruned =  104489 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     479 /     512             ( 93.55%) | total_pruned =      33 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     364 /     512             ( 71.09%) | total_pruned =     148 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   90424 / 2359296             (  3.83%) | total_pruned = 2268872 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     407 /     512             ( 79.49%) | total_pruned =     105 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     227 /     512             ( 44.34%) | total_pruned =     285 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   48306 / 2359296             (  2.05%) | total_pruned = 2310990 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      84 /     512             ( 16.41%) | total_pruned =     428 | shape = torch.Size([512])
linear.weight        | nonzeros =    3483 /    5120             ( 68.03%) | total_pruned =    1637 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1006089, pruned : 10172673, total: 11178762, Compression rate :      11.11x  ( 91.00% pruned)
Train Epoch: 32/100 Loss: 0.000176 Accuracy: 86.84 100.00 % Best test Accuracy: 86.92%
tensor(0.0021, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.5156e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.502207
Average KL loss: 0.220599
Average total loss: 0.722806
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.2316e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.448764
Average KL loss: 0.249178
Average total loss: 0.697942
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.6907e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.417055
Average KL loss: 0.264909
Average total loss: 0.681964
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.5431e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.418603
Average KL loss: 0.275085
Average total loss: 0.693687
tensor(0.0026, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-9.5859e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.400009
Average KL loss: 0.282668
Average total loss: 0.682677
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.5083e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.398790
Average KL loss: 0.286715
Average total loss: 0.685506
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.0903e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.385439
Average KL loss: 0.291755
Average total loss: 0.677194
tensor(0.0026, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2146e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.375625
Average KL loss: 0.293874
Average total loss: 0.669499
tensor(0.0026, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.7226e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.378120
Average KL loss: 0.295341
Average total loss: 0.673462
tensor(0.0026, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(4.2907e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.378108
Average KL loss: 0.296909
Average total loss: 0.675017
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.1981e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.368416
Average KL loss: 0.299710
Average total loss: 0.668126
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.0230e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.374432
Average KL loss: 0.300552
Average total loss: 0.674983
tensor(0.0027, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-9.2813e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.371416
Average KL loss: 0.303044
Average total loss: 0.674460
tensor(0.0027, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(3.6305e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.362878
Average KL loss: 0.304548
Average total loss: 0.667426
tensor(0.0027, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.1857e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.358287
Average KL loss: 0.303795
Average total loss: 0.662081
tensor(0.0027, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.6577e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.362411
Average KL loss: 0.305468
Average total loss: 0.667879
tensor(0.0027, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.1447e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.361727
Average KL loss: 0.307303
Average total loss: 0.669030
tensor(0.0027, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-7.7136e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.361985
Average KL loss: 0.307409
Average total loss: 0.669394
tensor(0.0027, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.1472e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.355020
Average KL loss: 0.309319
Average total loss: 0.664339
tensor(0.0027, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.8403e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.353640
Average KL loss: 0.309913
Average total loss: 0.663553
tensor(0.0027, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.9002e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.350563
Average KL loss: 0.310001
Average total loss: 0.660564
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.9688e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.354575
Average KL loss: 0.310755
Average total loss: 0.665330
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.0493e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.347227
Average KL loss: 0.310596
Average total loss: 0.657823
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.1402e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.335603
Average KL loss: 0.310980
Average total loss: 0.646584
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(3.9942e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.352585
Average KL loss: 0.311023
Average total loss: 0.663608
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.8057e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.346389
Average KL loss: 0.312045
Average total loss: 0.658434
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.0311e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.361677
Average KL loss: 0.313175
Average total loss: 0.674852
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(7.2498e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.349199
Average KL loss: 0.316018
Average total loss: 0.665217
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(4.4602e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.350144
Average KL loss: 0.316261
Average total loss: 0.666405
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(1.8924e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.350323
Average KL loss: 0.315997
Average total loss: 0.666320
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(1.5092e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.344491
Average KL loss: 0.317355
Average total loss: 0.661846
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.5465e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.347406
Average KL loss: 0.317663
Average total loss: 0.665069
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(1.3277e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.329349
Average KL loss: 0.317205
Average total loss: 0.646555
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.4771e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.339803
Average KL loss: 0.315886
Average total loss: 0.655689
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-5.7750e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.343625
Average KL loss: 0.316963
Average total loss: 0.660588
tensor(0.0027, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(3.9488e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.341417
Average KL loss: 0.316457
Average total loss: 0.657874
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(2.9844e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.334859
Average KL loss: 0.312344
Average total loss: 0.647202
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(3.6811e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.317432
Average KL loss: 0.308625
Average total loss: 0.626056
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.5800e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.330477
Average KL loss: 0.305316
Average total loss: 0.635793
tensor(0.0027, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(3.5417e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.328795
Average KL loss: 0.302442
Average total loss: 0.631238
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.5838e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.328713
Average KL loss: 0.299873
Average total loss: 0.628586
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(1.1507e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.337695
Average KL loss: 0.297546
Average total loss: 0.635240
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.4776e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.342249
Average KL loss: 0.295514
Average total loss: 0.637763
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.0052e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.323886
Average KL loss: 0.293629
Average total loss: 0.617515
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(3.4507e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.329818
Average KL loss: 0.291803
Average total loss: 0.621621
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(1.1771e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.322167
Average KL loss: 0.290164
Average total loss: 0.612330
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.4085e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.335355
Average KL loss: 0.288535
Average total loss: 0.623890
tensor(0.0027, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(5.7700e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.328453
Average KL loss: 0.287087
Average total loss: 0.615539
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4529e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.336156
Average KL loss: 0.285722
Average total loss: 0.621879
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(4.9134e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.328256
Average KL loss: 0.284526
Average total loss: 0.612782
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.8603e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.330691
Average KL loss: 0.283394
Average total loss: 0.614085
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.3065e-10, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.326954
Average KL loss: 0.282305
Average total loss: 0.609259
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-9.5581e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.328114
Average KL loss: 0.281297
Average total loss: 0.609411
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.5416e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.343046
Average KL loss: 0.280365
Average total loss: 0.623411
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(1.4983e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.333566
Average KL loss: 0.279531
Average total loss: 0.613097
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(7.6168e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.318320
Average KL loss: 0.278651
Average total loss: 0.596972
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.0772e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.330168
Average KL loss: 0.277777
Average total loss: 0.607944
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(2.9681e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.331808
Average KL loss: 0.277036
Average total loss: 0.608843
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(1.4750e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.330030
Average KL loss: 0.276351
Average total loss: 0.606382
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.0532e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.330925
Average KL loss: 0.275669
Average total loss: 0.606594
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.3108e-10, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.326902
Average KL loss: 0.275071
Average total loss: 0.601973
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0270e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.327794
Average KL loss: 0.274431
Average total loss: 0.602226
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.3877e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.329866
Average KL loss: 0.273902
Average total loss: 0.603768
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(1.5821e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.331584
Average KL loss: 0.273394
Average total loss: 0.604979
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(2.3159e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.329427
Average KL loss: 0.272843
Average total loss: 0.602270
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(6.1953e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.333119
Average KL loss: 0.272434
Average total loss: 0.605553
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(3.0100e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.323787
Average KL loss: 0.271997
Average total loss: 0.595784
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.4810e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.327184
Average KL loss: 0.271476
Average total loss: 0.598660
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4122e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.340781
Average KL loss: 0.271088
Average total loss: 0.611868
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.2058e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.328323
Average KL loss: 0.270757
Average total loss: 0.599080
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.0934e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.329800
Average KL loss: 0.270446
Average total loss: 0.600246
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(3.8563e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.328632
Average KL loss: 0.270134
Average total loss: 0.598766
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.3620e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.338502
Average KL loss: 0.269815
Average total loss: 0.608317
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0830e-10, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.334069
Average KL loss: 0.269522
Average total loss: 0.603592
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(3.7480e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.329234
Average KL loss: 0.269251
Average total loss: 0.598485
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.2656e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.336817
Average KL loss: 0.268889
Average total loss: 0.605706
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(3.8858e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.329452
Average KL loss: 0.268597
Average total loss: 0.598049
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(3.9028e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.331016
Average KL loss: 0.268282
Average total loss: 0.599298
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.3439e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.326212
Average KL loss: 0.268124
Average total loss: 0.594336
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4781e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.329757
Average KL loss: 0.268050
Average total loss: 0.597807
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.2586e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.333861
Average KL loss: 0.267973
Average total loss: 0.601835
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(8.4893e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.332027
Average KL loss: 0.267899
Average total loss: 0.599927
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.1890e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.336504
Average KL loss: 0.267830
Average total loss: 0.604334
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.5083e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.327767
Average KL loss: 0.267758
Average total loss: 0.595525
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0323e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.323890
Average KL loss: 0.267687
Average total loss: 0.591577
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.0885e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.333564
Average KL loss: 0.267622
Average total loss: 0.601186
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(4.7656e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.326348
Average KL loss: 0.267550
Average total loss: 0.593898
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.6738e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.334785
Average KL loss: 0.267489
Average total loss: 0.602274
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(4.9090e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.328644
Average KL loss: 0.267428
Average total loss: 0.596072
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(6.4998e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.329022
Average KL loss: 0.267357
Average total loss: 0.596379
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.3348e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.323498
Average KL loss: 0.267292
Average total loss: 0.590789
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(3.3006e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.330285
Average KL loss: 0.267221
Average total loss: 0.597507
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(5.1828e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.330233
Average KL loss: 0.267153
Average total loss: 0.597385
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.4394e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.327747
Average KL loss: 0.267088
Average total loss: 0.594835
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(8.6042e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.330206
Average KL loss: 0.267027
Average total loss: 0.597232
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.4137e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.329927
Average KL loss: 0.266969
Average total loss: 0.596896
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.6310e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.337504
Average KL loss: 0.266906
Average total loss: 0.604410
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(8.7095e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.330006
Average KL loss: 0.266846
Average total loss: 0.596851
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(8.8949e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.327243
Average KL loss: 0.266783
Average total loss: 0.594027
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.9639e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.334946
Average KL loss: 0.266730
Average total loss: 0.601677
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(4.4316e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.329025
Average KL loss: 0.266669
Average total loss: 0.595694
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.3924e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.334511
Average KL loss: 0.266609
Average total loss: 0.601120
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(8.6652e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.316742
Average KL loss: 0.266577
Average total loss: 0.583319
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.3977e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.336757
Average KL loss: 0.266570
Average total loss: 0.603327
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(1.1444e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.336676
Average KL loss: 0.266564
Average total loss: 0.603240
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.9512e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.328628
Average KL loss: 0.266558
Average total loss: 0.595186
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.4550e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.334391
Average KL loss: 0.266552
Average total loss: 0.600943
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.0436e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.323695
Average KL loss: 0.266545
Average total loss: 0.590240
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.1956e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.324062
Average KL loss: 0.266539
Average total loss: 0.590600
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(1.0474e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.330925
Average KL loss: 0.266532
Average total loss: 0.597456
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(1.2668e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.334872
Average KL loss: 0.266527
Average total loss: 0.601399
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.8390e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.325925
Average KL loss: 0.266521
Average total loss: 0.592446
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(5.3178e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.330572
Average KL loss: 0.266514
Average total loss: 0.597085
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.5878e-09, device='cuda:0')
 Percentile value: 0.09010935127735135
Non-zero model percentage: 2.7000038623809814%, Non-zero mask percentage: 2.7000038623809814%

--- Pruning Level [3/8]: ---
conv1.weight         | nonzeros =     909 /    1728             ( 52.60%) | total_pruned =     819 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    4281 /   36864             ( 11.61%) | total_pruned =   32583 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4837 /   36864             ( 13.12%) | total_pruned =   32027 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    4346 /   36864             ( 11.79%) | total_pruned =   32518 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4346 /   36864             ( 11.79%) | total_pruned =   32518 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    8023 /   73728             ( 10.88%) | total_pruned =   65705 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   13370 /  147456             (  9.07%) | total_pruned =  134086 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2349 /    8192             ( 28.67%) | total_pruned =    5843 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      67 /     128             ( 52.34%) | total_pruned =      61 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8427 /  147456             (  5.71%) | total_pruned =  139029 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    8906 /  147456             (  6.04%) | total_pruned =  138550 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   23899 /  294912             (  8.10%) | total_pruned =  271013 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     172 /     256             ( 67.19%) | total_pruned =      84 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   37340 /  589824             (  6.33%) | total_pruned =  552484 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6237 /   32768             ( 19.03%) | total_pruned =   26531 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     159 /     256             ( 62.11%) | total_pruned =      97 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   16888 /  589824             (  2.86%) | total_pruned =  572936 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      97 /     256             ( 37.89%) | total_pruned =     159 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   17108 /  589824             (  2.90%) | total_pruned =  572716 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     109 /     256             ( 42.58%) | total_pruned =     147 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   51576 / 1179648             (  4.37%) | total_pruned = 1128072 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     504 /     512             ( 98.44%) | total_pruned =       8 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     301 /     512             ( 58.79%) | total_pruned =     211 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   41955 / 2359296             (  1.78%) | total_pruned = 2317341 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     299 /     512             ( 58.40%) | total_pruned =     213 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    9197 /  131072             (  7.02%) | total_pruned =  121875 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     440 /     512             ( 85.94%) | total_pruned =      72 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     329 /     512             ( 64.26%) | total_pruned =     183 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   18941 / 2359296             (  0.80%) | total_pruned = 2340355 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     389 /     512             ( 75.98%) | total_pruned =     123 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     146 /     512             ( 28.52%) | total_pruned =     366 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    9497 / 2359296             (  0.40%) | total_pruned = 2349799 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     496 /     512             ( 96.88%) | total_pruned =      16 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      56 /     512             ( 10.94%) | total_pruned =     456 | shape = torch.Size([512])
linear.weight        | nonzeros =    2631 /    5120             ( 51.39%) | total_pruned =    2489 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 301827, pruned : 10876935, total: 11178762, Compression rate :      37.04x  ( 97.30% pruned)
Train Epoch: 31/100 Loss: 0.000061 Accuracy: 86.12 100.00 % Best test Accuracy: 86.72%
tensor(0.0027, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-9.4814e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.934497
Average KL loss: 0.255503
Average total loss: 1.190000
tensor(0.0031, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-5.7108e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.815817
Average KL loss: 0.274104
Average total loss: 1.089922
tensor(0.0032, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.0088e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.765544
Average KL loss: 0.291545
Average total loss: 1.057088
tensor(0.0032, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.7072e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.754055
Average KL loss: 0.305752
Average total loss: 1.059807
tensor(0.0033, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.3649e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.729100
Average KL loss: 0.318190
Average total loss: 1.047290
tensor(0.0033, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.0845e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.703451
Average KL loss: 0.328600
Average total loss: 1.032051
tensor(0.0033, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.0517e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.673323
Average KL loss: 0.335538
Average total loss: 1.008861
tensor(0.0033, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.5286e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.666671
Average KL loss: 0.341699
Average total loss: 1.008369
tensor(0.0033, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(1.0639e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.671557
Average KL loss: 0.347226
Average total loss: 1.018783
tensor(0.0033, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.2340e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.667788
Average KL loss: 0.352966
Average total loss: 1.020754
tensor(0.0033, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-7.2257e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.658293
Average KL loss: 0.357709
Average total loss: 1.016002
tensor(0.0033, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.6862e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.666293
Average KL loss: 0.362031
Average total loss: 1.028324
tensor(0.0033, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-6.3143e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.651392
Average KL loss: 0.366278
Average total loss: 1.017670
tensor(0.0033, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.7586e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.639104
Average KL loss: 0.368747
Average total loss: 1.007850
tensor(0.0033, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(9.1407e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.623649
Average KL loss: 0.370486
Average total loss: 0.994135
tensor(0.0033, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.0629e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.630864
Average KL loss: 0.372496
Average total loss: 1.003360
tensor(0.0033, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.3779e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.632691
Average KL loss: 0.375150
Average total loss: 1.007841
tensor(0.0033, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(1.8840e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.611396
Average KL loss: 0.377552
Average total loss: 0.988948
tensor(0.0033, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.8052e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.609759
Average KL loss: 0.377892
Average total loss: 0.987651
tensor(0.0033, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(1.2694e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.617770
Average KL loss: 0.379259
Average total loss: 0.997029
tensor(0.0033, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(1.8255e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.598541
Average KL loss: 0.380379
Average total loss: 0.978919
tensor(0.0033, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(5.3461e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.602647
Average KL loss: 0.382075
Average total loss: 0.984723
tensor(0.0033, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-3.7477e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.607903
Average KL loss: 0.383631
Average total loss: 0.991533
tensor(0.0033, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(2.7502e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.590144
Average KL loss: 0.384860
Average total loss: 0.975004
tensor(0.0033, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-2.9448e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.593895
Average KL loss: 0.385293
Average total loss: 0.979188
tensor(0.0033, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(1.5591e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.591472
Average KL loss: 0.385053
Average total loss: 0.976526
tensor(0.0033, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-9.3494e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.588986
Average KL loss: 0.386114
Average total loss: 0.975101
tensor(0.0033, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0450e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.590232
Average KL loss: 0.387073
Average total loss: 0.977305
tensor(0.0033, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(3.0927e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.588728
Average KL loss: 0.388445
Average total loss: 0.977173
tensor(0.0033, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.5148e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.603103
Average KL loss: 0.389416
Average total loss: 0.992519
tensor(0.0033, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-9.4381e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.582158
Average KL loss: 0.390457
Average total loss: 0.972614
tensor(0.0033, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-8.6385e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.587271
Average KL loss: 0.390369
Average total loss: 0.977641
tensor(0.0033, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.3382e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.589936
Average KL loss: 0.391707
Average total loss: 0.981643
tensor(0.0033, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-4.1595e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.596801
Average KL loss: 0.392636
Average total loss: 0.989437
tensor(0.0033, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(1.4309e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.580535
Average KL loss: 0.393814
Average total loss: 0.974349
tensor(0.0033, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.1067e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.577443
Average KL loss: 0.394224
Average total loss: 0.971667
tensor(0.0033, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.1409e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.570325
Average KL loss: 0.393842
Average total loss: 0.964167
tensor(0.0033, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(2.7716e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.568255
Average KL loss: 0.393734
Average total loss: 0.961989
tensor(0.0033, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.6000e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.549360
Average KL loss: 0.393729
Average total loss: 0.943090
tensor(0.0033, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-9.2431e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.573851
Average KL loss: 0.393426
Average total loss: 0.967277
tensor(0.0033, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(3.2241e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.592688
Average KL loss: 0.394581
Average total loss: 0.987269
tensor(0.0033, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(3.2665e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.577837
Average KL loss: 0.396628
Average total loss: 0.974465
tensor(0.0033, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(4.6616e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.575319
Average KL loss: 0.396700
Average total loss: 0.972019
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.3098e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.547845
Average KL loss: 0.396638
Average total loss: 0.944482
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.4607e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.574966
Average KL loss: 0.395878
Average total loss: 0.970845
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(6.9196e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.563045
Average KL loss: 0.396827
Average total loss: 0.959872
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.3779e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.557303
Average KL loss: 0.397480
Average total loss: 0.954783
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.0705e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.563720
Average KL loss: 0.398517
Average total loss: 0.962238
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(1.7203e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.566652
Average KL loss: 0.398289
Average total loss: 0.964942
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-5.6194e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.564257
Average KL loss: 0.399043
Average total loss: 0.963300
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-6.5567e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.566644
Average KL loss: 0.399324
Average total loss: 0.965968
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(6.0911e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.567524
Average KL loss: 0.398148
Average total loss: 0.965672
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(5.5209e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.566387
Average KL loss: 0.396863
Average total loss: 0.963250
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.9521e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.569978
Average KL loss: 0.395755
Average total loss: 0.965733
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(2.0485e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.537753
Average KL loss: 0.394623
Average total loss: 0.932376
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.7284e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.556092
Average KL loss: 0.393443
Average total loss: 0.949535
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(5.3017e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.564821
Average KL loss: 0.392377
Average total loss: 0.957199
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(1.4548e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.561880
Average KL loss: 0.391519
Average total loss: 0.953400
tensor(0.0033, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.6681e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.560535
Average KL loss: 0.390544
Average total loss: 0.951079
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-4.4194e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.574287
Average KL loss: 0.389647
Average total loss: 0.963934
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(7.9881e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.549588
Average KL loss: 0.388804
Average total loss: 0.938392
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.1983e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.568735
Average KL loss: 0.387936
Average total loss: 0.956671
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.7420e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.563263
Average KL loss: 0.387233
Average total loss: 0.950495
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(9.0148e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.568628
Average KL loss: 0.386472
Average total loss: 0.955099
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.9054e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.550613
Average KL loss: 0.385741
Average total loss: 0.936354
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.5994e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.550626
Average KL loss: 0.385005
Average total loss: 0.935631
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.4330e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.569652
Average KL loss: 0.384561
Average total loss: 0.954212
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.4945e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.577671
Average KL loss: 0.384479
Average total loss: 0.962150
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.2226e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.566884
Average KL loss: 0.384401
Average total loss: 0.951285
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.0756e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.560628
Average KL loss: 0.384325
Average total loss: 0.944953
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(6.7530e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.557660
Average KL loss: 0.384236
Average total loss: 0.941897
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(4.1456e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.564511
Average KL loss: 0.384153
Average total loss: 0.948665
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.2351e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.565320
Average KL loss: 0.384069
Average total loss: 0.949390
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.1218e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.553870
Average KL loss: 0.383981
Average total loss: 0.937852
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.8282e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.568829
Average KL loss: 0.383897
Average total loss: 0.952726
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.4407e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.545164
Average KL loss: 0.383803
Average total loss: 0.928967
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.7795e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.561142
Average KL loss: 0.383713
Average total loss: 0.944855
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.2739e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.575393
Average KL loss: 0.383631
Average total loss: 0.959024
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(8.0760e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.550485
Average KL loss: 0.383547
Average total loss: 0.934031
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.1065e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.556339
Average KL loss: 0.383458
Average total loss: 0.939797
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-9.9787e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.560835
Average KL loss: 0.383373
Average total loss: 0.944208
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(4.2064e-10, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.563821
Average KL loss: 0.383291
Average total loss: 0.947113
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.4101e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.557730
Average KL loss: 0.383205
Average total loss: 0.940935
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(8.2950e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.560193
Average KL loss: 0.383126
Average total loss: 0.943319
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(5.2213e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.558984
Average KL loss: 0.383042
Average total loss: 0.942027
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.0494e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.552433
Average KL loss: 0.382953
Average total loss: 0.935386
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.1648e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.550814
Average KL loss: 0.382872
Average total loss: 0.933685
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.1889e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.543493
Average KL loss: 0.382823
Average total loss: 0.926316
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-8.8829e-10, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.557545
Average KL loss: 0.382815
Average total loss: 0.940359
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.7449e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.552602
Average KL loss: 0.382806
Average total loss: 0.935407
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.4562e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.564420
Average KL loss: 0.382797
Average total loss: 0.947218
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(4.0588e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.544156
Average KL loss: 0.382788
Average total loss: 0.926944
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(8.4527e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.557100
Average KL loss: 0.382779
Average total loss: 0.939879
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.1025e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.574623
Average KL loss: 0.382770
Average total loss: 0.957393
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.5937e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.547177
Average KL loss: 0.382762
Average total loss: 0.929939
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.7646e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.539573
Average KL loss: 0.382754
Average total loss: 0.922326
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-2.7500e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.565209
Average KL loss: 0.382745
Average total loss: 0.947954
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-4.5523e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.548657
Average KL loss: 0.382736
Average total loss: 0.931393
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-1.5086e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.545414
Average KL loss: 0.382727
Average total loss: 0.928141
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.3621e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.563104
Average KL loss: 0.382718
Average total loss: 0.945821
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(2.0277e-11, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.564050
Average KL loss: 0.382709
Average total loss: 0.946759
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-7.8006e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.542513
Average KL loss: 0.382701
Average total loss: 0.925214
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.5712e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.544859
Average KL loss: 0.382693
Average total loss: 0.927552
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-5.4529e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.557775
Average KL loss: 0.382684
Average total loss: 0.940459
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-7.7674e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.557807
Average KL loss: 0.382676
Average total loss: 0.940482
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(1.6844e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.547903
Average KL loss: 0.382667
Average total loss: 0.930570
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-6.7152e-09, device='cuda:0')
 Percentile value: 0.3669720649719238
Non-zero model percentage: 0.8100091218948364%, Non-zero mask percentage: 0.8100091218948364%

--- Pruning Level [4/8]: ---
conv1.weight         | nonzeros =     807 /    1728             ( 46.70%) | total_pruned =     921 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1787 /   36864             (  4.85%) | total_pruned =   35077 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2178 /   36864             (  5.91%) | total_pruned =   34686 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1963 /   36864             (  5.32%) | total_pruned =   34901 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1885 /   36864             (  5.11%) | total_pruned =   34979 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3287 /   73728             (  4.46%) | total_pruned =   70441 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4841 /  147456             (  3.28%) | total_pruned =  142615 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1473 /    8192             ( 17.98%) | total_pruned =    6719 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2595 /  147456             (  1.76%) | total_pruned =  144861 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2633 /  147456             (  1.79%) | total_pruned =  144823 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7924 /  294912             (  2.69%) | total_pruned =  286988 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   10499 /  589824             (  1.78%) | total_pruned =  579325 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2883 /   32768             (  8.80%) | total_pruned =   29885 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3877 /  589824             (  0.66%) | total_pruned =  585947 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     204 /     256             ( 79.69%) | total_pruned =      52 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      55 /     256             ( 21.48%) | total_pruned =     201 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3835 /  589824             (  0.65%) | total_pruned =  585989 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      53 /     256             ( 20.70%) | total_pruned =     203 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   12123 / 1179648             (  1.03%) | total_pruned = 1167525 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     186 /     512             ( 36.33%) | total_pruned =     326 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    9191 / 2359296             (  0.39%) | total_pruned = 2350105 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     464 /     512             ( 90.62%) | total_pruned =      48 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     250 /     512             ( 48.83%) | total_pruned =     262 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2598 /  131072             (  1.98%) | total_pruned =  128474 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     333 /     512             ( 65.04%) | total_pruned =     179 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     265 /     512             ( 51.76%) | total_pruned =     247 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    4381 / 2359296             (  0.19%) | total_pruned = 2354915 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     306 /     512             ( 59.77%) | total_pruned =     206 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      58 /     512             ( 11.33%) | total_pruned =     454 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    2354 / 2359296             (  0.10%) | total_pruned = 2356942 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     392 /     512             ( 76.56%) | total_pruned =     120 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
linear.weight        | nonzeros =    1764 /    5120             ( 34.45%) | total_pruned =    3356 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 90549, pruned : 11088213, total: 11178762, Compression rate :     123.46x  ( 99.19% pruned)
Train Epoch: 35/100 Loss: 0.000825 Accuracy: 84.41 100.00 % Best test Accuracy: 85.29%
tensor(0.0033, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-9.1428e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.913812
Average KL loss: 0.348313
Average total loss: 2.262125
tensor(0.0035, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-5.5754e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.689011
Average KL loss: 0.349437
Average total loss: 2.038447
tensor(0.0035, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-8.2481e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.602871
Average KL loss: 0.361446
Average total loss: 1.964317
tensor(0.0035, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-8.0633e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.531602
Average KL loss: 0.374032
Average total loss: 1.905634
tensor(0.0036, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-8.9298e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.472596
Average KL loss: 0.385679
Average total loss: 1.858275
tensor(0.0036, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-5.4495e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.395220
Average KL loss: 0.396692
Average total loss: 1.791913
tensor(0.0036, device='cuda:0') tensor(0.0055, device='cuda:0') tensor(-4.0277e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.395603
Average KL loss: 0.406471
Average total loss: 1.802074
tensor(0.0036, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-3.6543e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.269136
Average KL loss: 0.415959
Average total loss: 1.685096
tensor(0.0037, device='cuda:0') tensor(0.0057, device='cuda:0') tensor(-1.8077e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.278360
Average KL loss: 0.423514
Average total loss: 1.701873
tensor(0.0037, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-2.1268e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.272536
Average KL loss: 0.431764
Average total loss: 1.704300
tensor(0.0037, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(1.3151e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.209175
Average KL loss: 0.438922
Average total loss: 1.648097
tensor(0.0037, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-3.3008e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.269244
Average KL loss: 0.445421
Average total loss: 1.714666
tensor(0.0037, device='cuda:0') tensor(0.0060, device='cuda:0') tensor(-4.5299e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.210886
Average KL loss: 0.453056
Average total loss: 1.663941
tensor(0.0037, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-3.0010e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.184550
Average KL loss: 0.459633
Average total loss: 1.644183
tensor(0.0037, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-4.7915e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.179453
Average KL loss: 0.465436
Average total loss: 1.644889
tensor(0.0037, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-7.2847e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.156367
Average KL loss: 0.470388
Average total loss: 1.626755
tensor(0.0037, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-9.1061e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.140979
Average KL loss: 0.475351
Average total loss: 1.616330
tensor(0.0037, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(8.0981e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.161637
Average KL loss: 0.480407
Average total loss: 1.642044
tensor(0.0038, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(9.2866e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.059192
Average KL loss: 0.484721
Average total loss: 1.543913
tensor(0.0038, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(1.2250e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.081263
Average KL loss: 0.487602
Average total loss: 1.568866
tensor(0.0038, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-1.4853e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.121499
Average KL loss: 0.491478
Average total loss: 1.612978
tensor(0.0038, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-5.7206e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.039787
Average KL loss: 0.495473
Average total loss: 1.535261
tensor(0.0038, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-4.5904e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.059591
Average KL loss: 0.498544
Average total loss: 1.558135
tensor(0.0038, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-1.2830e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.008971
Average KL loss: 0.501421
Average total loss: 1.510392
tensor(0.0038, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-3.4881e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.063899
Average KL loss: 0.503644
Average total loss: 1.567543
tensor(0.0038, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-8.0138e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.034019
Average KL loss: 0.506197
Average total loss: 1.540216
tensor(0.0038, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-3.2612e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.002621
Average KL loss: 0.508396
Average total loss: 1.511017
tensor(0.0038, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.3953e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.004206
Average KL loss: 0.510584
Average total loss: 1.514790
tensor(0.0038, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-1.9085e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.019597
Average KL loss: 0.512877
Average total loss: 1.532474
tensor(0.0038, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(1.0749e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.991293
Average KL loss: 0.515246
Average total loss: 1.506539
tensor(0.0038, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-2.8599e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.032576
Average KL loss: 0.517710
Average total loss: 1.550287
tensor(0.0038, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(2.9486e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.040095
Average KL loss: 0.520690
Average total loss: 1.560785
tensor(0.0038, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-3.8501e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.989136
Average KL loss: 0.523582
Average total loss: 1.512718
tensor(0.0038, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.7560e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.946683
Average KL loss: 0.524780
Average total loss: 1.471463
tensor(0.0038, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.4969e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.964151
Average KL loss: 0.525556
Average total loss: 1.489708
tensor(0.0038, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(1.1760e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.957536
Average KL loss: 0.526417
Average total loss: 1.483953
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.2898e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.962254
Average KL loss: 0.527613
Average total loss: 1.489867
tensor(0.0037, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(2.3719e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.964547
Average KL loss: 0.529570
Average total loss: 1.494117
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.0372e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.982790
Average KL loss: 0.530770
Average total loss: 1.513560
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-2.9999e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.953759
Average KL loss: 0.531608
Average total loss: 1.485367
tensor(0.0037, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-1.3502e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.943390
Average KL loss: 0.532786
Average total loss: 1.476176
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(2.3735e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.941106
Average KL loss: 0.533987
Average total loss: 1.475093
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.9666e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.934095
Average KL loss: 0.535123
Average total loss: 1.469217
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(5.5313e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.969177
Average KL loss: 0.536372
Average total loss: 1.505549
tensor(0.0037, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(1.0606e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.950824
Average KL loss: 0.538203
Average total loss: 1.489027
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-5.9155e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.952260
Average KL loss: 0.540016
Average total loss: 1.492277
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.2724e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.936878
Average KL loss: 0.541423
Average total loss: 1.478301
tensor(0.0037, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.7570e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.941765
Average KL loss: 0.541999
Average total loss: 1.483764
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.5561e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.922254
Average KL loss: 0.543209
Average total loss: 1.465462
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(2.0108e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.900105
Average KL loss: 0.544205
Average total loss: 1.444310
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.3434e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.926494
Average KL loss: 0.545258
Average total loss: 1.471751
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.2231e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.920544
Average KL loss: 0.546505
Average total loss: 1.467049
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(6.1478e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.924990
Average KL loss: 0.548142
Average total loss: 1.473132
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.7780e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.885211
Average KL loss: 0.548863
Average total loss: 1.434074
tensor(0.0037, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(9.0372e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.911841
Average KL loss: 0.548766
Average total loss: 1.460607
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.6066e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.877205
Average KL loss: 0.549082
Average total loss: 1.426287
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.6970e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.901095
Average KL loss: 0.548983
Average total loss: 1.450078
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.0373e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.917773
Average KL loss: 0.549941
Average total loss: 1.467714
tensor(0.0037, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.8477e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.902863
Average KL loss: 0.551228
Average total loss: 1.454091
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.5191e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.871696
Average KL loss: 0.551428
Average total loss: 1.423124
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(5.3247e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.883405
Average KL loss: 0.551490
Average total loss: 1.434895
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.4255e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.882070
Average KL loss: 0.551538
Average total loss: 1.433608
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.3460e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.886331
Average KL loss: 0.552438
Average total loss: 1.438769
tensor(0.0037, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(2.8435e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.886496
Average KL loss: 0.553552
Average total loss: 1.440048
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.2652e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.866260
Average KL loss: 0.553849
Average total loss: 1.420108
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(7.2365e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.883168
Average KL loss: 0.554089
Average total loss: 1.437258
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.8794e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.869410
Average KL loss: 0.554922
Average total loss: 1.424332
tensor(0.0037, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(8.7071e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.896719
Average KL loss: 0.555579
Average total loss: 1.452298
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(4.0986e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.875421
Average KL loss: 0.556959
Average total loss: 1.432380
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(2.4760e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.870556
Average KL loss: 0.557269
Average total loss: 1.427825
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(7.5557e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.850741
Average KL loss: 0.557333
Average total loss: 1.408073
tensor(0.0037, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.7433e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.876935
Average KL loss: 0.557738
Average total loss: 1.434672
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.9994e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.866733
Average KL loss: 0.558388
Average total loss: 1.425121
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.2812e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.849833
Average KL loss: 0.558802
Average total loss: 1.408635
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(8.3094e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.881785
Average KL loss: 0.558650
Average total loss: 1.440436
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.1678e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.853561
Average KL loss: 0.558720
Average total loss: 1.412281
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-1.5409e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.836210
Average KL loss: 0.558818
Average total loss: 1.395028
tensor(0.0037, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(9.9624e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.866575
Average KL loss: 0.558802
Average total loss: 1.425377
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.2085e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.847216
Average KL loss: 0.559663
Average total loss: 1.406879
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(2.2558e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.840535
Average KL loss: 0.559952
Average total loss: 1.400487
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.5870e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.840042
Average KL loss: 0.559670
Average total loss: 1.399712
tensor(0.0037, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.6137e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.854619
Average KL loss: 0.560018
Average total loss: 1.414637
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.4126e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.831867
Average KL loss: 0.559935
Average total loss: 1.391802
tensor(0.0036, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(1.1153e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.847423
Average KL loss: 0.559399
Average total loss: 1.406822
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.1131e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.812512
Average KL loss: 0.559553
Average total loss: 1.372064
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.6166e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.858327
Average KL loss: 0.559456
Average total loss: 1.417784
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.6467e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.822558
Average KL loss: 0.559934
Average total loss: 1.382492
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(1.8959e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.820586
Average KL loss: 0.560133
Average total loss: 1.380720
tensor(0.0036, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(2.5585e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.858404
Average KL loss: 0.560288
Average total loss: 1.418692
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.0345e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.815822
Average KL loss: 0.560549
Average total loss: 1.376371
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(1.2794e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.817600
Average KL loss: 0.560587
Average total loss: 1.378187
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(4.4383e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.844824
Average KL loss: 0.560819
Average total loss: 1.405643
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(5.3162e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.833880
Average KL loss: 0.560881
Average total loss: 1.394762
tensor(0.0036, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.5165e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.837930
Average KL loss: 0.560990
Average total loss: 1.398920
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.2578e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.854235
Average KL loss: 0.561938
Average total loss: 1.416173
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(5.2642e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.821295
Average KL loss: 0.562556
Average total loss: 1.383851
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(9.7314e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.814510
Average KL loss: 0.562346
Average total loss: 1.376856
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.3329e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.810792
Average KL loss: 0.562009
Average total loss: 1.372801
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.4852e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.803310
Average KL loss: 0.561647
Average total loss: 1.364958
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.1154e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.816775
Average KL loss: 0.561323
Average total loss: 1.378097
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.5184e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.831931
Average KL loss: 0.560994
Average total loss: 1.392926
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-7.5153e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.841259
Average KL loss: 0.560742
Average total loss: 1.402001
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.8569e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.839374
Average KL loss: 0.560508
Average total loss: 1.399883
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.1774e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.835643
Average KL loss: 0.560297
Average total loss: 1.395940
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.1639e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.796744
Average KL loss: 0.560009
Average total loss: 1.356752
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.0164e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.825285
Average KL loss: 0.559703
Average total loss: 1.384988
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(9.6832e-11, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.793171
Average KL loss: 0.559447
Average total loss: 1.352618
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.1430e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.810555
Average KL loss: 0.559113
Average total loss: 1.369668
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.4879e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.810615
Average KL loss: 0.558824
Average total loss: 1.369439
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.1862e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.806548
Average KL loss: 0.558582
Average total loss: 1.365130
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.1617e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.817969
Average KL loss: 0.558305
Average total loss: 1.376273
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.1480e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.823409
Average KL loss: 0.558070
Average total loss: 1.381479
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(7.5062e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.831852
Average KL loss: 0.557867
Average total loss: 1.389720
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.2385e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.815555
Average KL loss: 0.557527
Average total loss: 1.373082
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(4.0396e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.817368
Average KL loss: 0.557216
Average total loss: 1.374583
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.1240e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.824384
Average KL loss: 0.556942
Average total loss: 1.381327
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(7.8958e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.813793
Average KL loss: 0.556714
Average total loss: 1.370508
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(9.5035e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.809747
Average KL loss: 0.556444
Average total loss: 1.366191
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.2086e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.813479
Average KL loss: 0.556310
Average total loss: 1.369789
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.2745e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.816282
Average KL loss: 0.556280
Average total loss: 1.372562
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.2590e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.824737
Average KL loss: 0.556247
Average total loss: 1.380984
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.4002e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.823539
Average KL loss: 0.556220
Average total loss: 1.379759
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.0631e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.799520
Average KL loss: 0.556192
Average total loss: 1.355712
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(9.2717e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.811212
Average KL loss: 0.556164
Average total loss: 1.367376
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-5.8879e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.816908
Average KL loss: 0.556138
Average total loss: 1.373047
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.6278e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.808624
Average KL loss: 0.556111
Average total loss: 1.364735
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.0106e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.807619
Average KL loss: 0.556082
Average total loss: 1.363701
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(9.2476e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.827313
Average KL loss: 0.556050
Average total loss: 1.383363
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.1819e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.808485
Average KL loss: 0.556023
Average total loss: 1.364508
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(9.2636e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.814656
Average KL loss: 0.556008
Average total loss: 1.370663
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-9.6016e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.827389
Average KL loss: 0.556005
Average total loss: 1.383393
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.2353e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.809958
Average KL loss: 0.556002
Average total loss: 1.365960
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(3.1249e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.814084
Average KL loss: 0.556000
Average total loss: 1.370083
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-8.4138e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.802213
Average KL loss: 0.555997
Average total loss: 1.358210
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(8.3229e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.827382
Average KL loss: 0.555994
Average total loss: 1.383376
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(2.3618e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.810058
Average KL loss: 0.555991
Average total loss: 1.366049
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.4751e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.805927
Average KL loss: 0.555988
Average total loss: 1.361915
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.5088e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.808544
Average KL loss: 0.555985
Average total loss: 1.364529
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.3767e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.810684
Average KL loss: 0.555982
Average total loss: 1.366666
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-6.8959e-09, device='cuda:0')
 Percentile value: 1.3421180248260496
Non-zero model percentage: 0.2430054396390915%, Non-zero mask percentage: 0.2430054396390915%

--- Pruning Level [5/8]: ---
conv1.weight         | nonzeros =     655 /    1728             ( 37.91%) | total_pruned =    1073 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     709 /   36864             (  1.92%) | total_pruned =   36155 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     892 /   36864             (  2.42%) | total_pruned =   35972 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     753 /   36864             (  2.04%) | total_pruned =   36111 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     752 /   36864             (  2.04%) | total_pruned =   36112 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1193 /   73728             (  1.62%) | total_pruned =   72535 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     126 /     128             ( 98.44%) | total_pruned =       2 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1536 /  147456             (  1.04%) | total_pruned =  145920 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     744 /    8192             (  9.08%) | total_pruned =    7448 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      13 /     128             ( 10.16%) | total_pruned =     115 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     780 /  147456             (  0.53%) | total_pruned =  146676 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     106 /     128             ( 82.81%) | total_pruned =      22 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     732 /  147456             (  0.50%) | total_pruned =  146724 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2172 /  294912             (  0.74%) | total_pruned =  292740 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      60 /     256             ( 23.44%) | total_pruned =     196 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    2497 /  589824             (  0.42%) | total_pruned =  587327 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     937 /   32768             (  2.86%) | total_pruned =   31831 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      38 /     256             ( 14.84%) | total_pruned =     218 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     862 /  589824             (  0.15%) | total_pruned =  588962 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     165 /     256             ( 64.45%) | total_pruned =      91 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     842 /  589824             (  0.14%) | total_pruned =  588982 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     219 /     256             ( 85.55%) | total_pruned =      37 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    2459 / 1179648             (  0.21%) | total_pruned = 1177189 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     427 /     512             ( 83.40%) | total_pruned =      85 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      71 /     512             ( 13.87%) | total_pruned =     441 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1888 / 2359296             (  0.08%) | total_pruned = 2357408 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     339 /     512             ( 66.21%) | total_pruned =     173 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     156 /     512             ( 30.47%) | total_pruned =     356 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     563 /  131072             (  0.43%) | total_pruned =  130509 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     194 /     512             ( 37.89%) | total_pruned =     318 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     155 /     512             ( 30.27%) | total_pruned =     357 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     882 / 2359296             (  0.04%) | total_pruned = 2358414 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     178 /     512             ( 34.77%) | total_pruned =     334 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      25 /     512             (  4.88%) | total_pruned =     487 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     431 / 2359296             (  0.02%) | total_pruned = 2358865 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     128 /     512             ( 25.00%) | total_pruned =     384 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
linear.weight        | nonzeros =     860 /    5120             ( 16.80%) | total_pruned =    4260 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 27165, pruned : 11151597, total: 11178762, Compression rate :     411.51x  ( 99.76% pruned)
Train Epoch: 99/100 Loss: 0.093015 Accuracy: 79.10 99.35 % Best test Accuracy: 82.29%
tensor(0.0036, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.6919e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 3.614082
Average KL loss: 0.501565
Average total loss: 4.115647
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.4974e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 3.338335
Average KL loss: 0.473526
Average total loss: 3.811861
tensor(0.0032, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.2789e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 3.041218
Average KL loss: 0.471500
Average total loss: 3.512719
tensor(0.0032, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-1.5787e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.881584
Average KL loss: 0.474071
Average total loss: 3.355654
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-1.3658e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.771841
Average KL loss: 0.478036
Average total loss: 3.249877
tensor(0.0032, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.7664e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.720999
Average KL loss: 0.482486
Average total loss: 3.203485
tensor(0.0033, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.7166e-07, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.624348
Average KL loss: 0.487314
Average total loss: 3.111662
tensor(0.0033, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.1197e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.622262
Average KL loss: 0.492166
Average total loss: 3.114427
tensor(0.0033, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-9.9700e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.466545
Average KL loss: 0.496978
Average total loss: 2.963523
tensor(0.0033, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-9.2819e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.436706
Average KL loss: 0.501793
Average total loss: 2.938499
tensor(0.0033, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.5982e-07, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.389037
Average KL loss: 0.506234
Average total loss: 2.895271
tensor(0.0033, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.7462e-07, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.351606
Average KL loss: 0.510697
Average total loss: 2.862303
tensor(0.0033, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.1751e-07, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.277070
Average KL loss: 0.515204
Average total loss: 2.792274
tensor(0.0033, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.4396e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.321832
Average KL loss: 0.519665
Average total loss: 2.841497
tensor(0.0034, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.2115e-07, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.260431
Average KL loss: 0.524123
Average total loss: 2.784554
tensor(0.0034, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.5593e-07, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.217180
Average KL loss: 0.528272
Average total loss: 2.745452
tensor(0.0034, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.5172e-07, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.123340
Average KL loss: 0.532034
Average total loss: 2.655374
tensor(0.0034, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.1335e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.081848
Average KL loss: 0.535878
Average total loss: 2.617727
tensor(0.0034, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-9.0393e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.102424
Average KL loss: 0.539846
Average total loss: 2.642270
tensor(0.0034, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-7.1108e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.059932
Average KL loss: 0.543825
Average total loss: 2.603757
tensor(0.0034, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-9.3412e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.932248
Average KL loss: 0.547327
Average total loss: 2.479575
tensor(0.0034, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.0621e-07, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.060001
Average KL loss: 0.550830
Average total loss: 2.610831
tensor(0.0034, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.4669e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.980613
Average KL loss: 0.554556
Average total loss: 2.535168
tensor(0.0035, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-5.9267e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.909093
Average KL loss: 0.557989
Average total loss: 2.467082
tensor(0.0035, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.5911e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 1.920109
Average KL loss: 0.561018
Average total loss: 2.481127
tensor(0.0035, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-4.2728e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 1.880319
Average KL loss: 0.564114
Average total loss: 2.444434
tensor(0.0035, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.1704e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 1.812523
Average KL loss: 0.567100
Average total loss: 2.379623
tensor(0.0035, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-4.6204e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 1.821956
Average KL loss: 0.570242
Average total loss: 2.392198
tensor(0.0035, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(1.1423e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 1.789616
Average KL loss: 0.573383
Average total loss: 2.362999
tensor(0.0035, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-4.9743e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 1.787103
Average KL loss: 0.576048
Average total loss: 2.363152
tensor(0.0035, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-3.0164e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 1.753676
Average KL loss: 0.579004
Average total loss: 2.332680
tensor(0.0035, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-2.5996e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.826434
Average KL loss: 0.581929
Average total loss: 2.408363
tensor(0.0035, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(1.3155e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.744225
Average KL loss: 0.584809
Average total loss: 2.329035
tensor(0.0035, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.2641e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.726724
Average KL loss: 0.587495
Average total loss: 2.314219
tensor(0.0036, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-2.9516e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.761215
Average KL loss: 0.590114
Average total loss: 2.351328
tensor(0.0036, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-4.9127e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.655010
Average KL loss: 0.592891
Average total loss: 2.247902
tensor(0.0036, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.7510e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.651961
Average KL loss: 0.595328
Average total loss: 2.247289
tensor(0.0036, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.3826e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.699624
Average KL loss: 0.597543
Average total loss: 2.297168
tensor(0.0036, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-7.7117e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.668765
Average KL loss: 0.600258
Average total loss: 2.269024
tensor(0.0036, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-8.1757e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.622933
Average KL loss: 0.602703
Average total loss: 2.225636
tensor(0.0036, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-3.5242e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.641734
Average KL loss: 0.605052
Average total loss: 2.246786
tensor(0.0036, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.8714e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.636071
Average KL loss: 0.607481
Average total loss: 2.243552
tensor(0.0036, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-9.6190e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.633356
Average KL loss: 0.609878
Average total loss: 2.243234
tensor(0.0036, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-5.3948e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.574237
Average KL loss: 0.612365
Average total loss: 2.186603
tensor(0.0036, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-2.2167e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.507516
Average KL loss: 0.614527
Average total loss: 2.122044
tensor(0.0036, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-5.7213e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.600135
Average KL loss: 0.616559
Average total loss: 2.216693
tensor(0.0036, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-5.0229e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.594393
Average KL loss: 0.618858
Average total loss: 2.213251
tensor(0.0036, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-4.9001e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.581859
Average KL loss: 0.621109
Average total loss: 2.202968
tensor(0.0037, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(4.5664e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.526939
Average KL loss: 0.623396
Average total loss: 2.150335
tensor(0.0037, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.5350e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.535194
Average KL loss: 0.625335
Average total loss: 2.160529
tensor(0.0037, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-3.0325e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.511255
Average KL loss: 0.627491
Average total loss: 2.138746
tensor(0.0037, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-4.9747e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.525024
Average KL loss: 0.629422
Average total loss: 2.154445
tensor(0.0037, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.2301e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.436228
Average KL loss: 0.631287
Average total loss: 2.067515
tensor(0.0037, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-5.3084e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.481337
Average KL loss: 0.633073
Average total loss: 2.114409
tensor(0.0037, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-4.6787e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.410348
Average KL loss: 0.634857
Average total loss: 2.045205
tensor(0.0037, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-4.3767e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.496802
Average KL loss: 0.636378
Average total loss: 2.133180
tensor(0.0037, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-3.0527e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.421622
Average KL loss: 0.637993
Average total loss: 2.059615
tensor(0.0037, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-2.8299e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.426974
Average KL loss: 0.639633
Average total loss: 2.066607
tensor(0.0037, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-8.4982e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.441238
Average KL loss: 0.641360
Average total loss: 2.082597
tensor(0.0037, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.2375e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.388512
Average KL loss: 0.642992
Average total loss: 2.031503
tensor(0.0037, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(1.8370e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.395326
Average KL loss: 0.644439
Average total loss: 2.039765
tensor(0.0037, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-5.0893e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.377766
Average KL loss: 0.645924
Average total loss: 2.023691
tensor(0.0037, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.8530e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.361314
Average KL loss: 0.647378
Average total loss: 2.008691
tensor(0.0037, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-3.9651e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.367766
Average KL loss: 0.648828
Average total loss: 2.016595
tensor(0.0037, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-4.1785e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.361246
Average KL loss: 0.650242
Average total loss: 2.011488
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-8.5011e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.337887
Average KL loss: 0.651536
Average total loss: 1.989423
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.2015e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.372508
Average KL loss: 0.652802
Average total loss: 2.025310
tensor(0.0038, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.8176e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.330404
Average KL loss: 0.654340
Average total loss: 1.984743
tensor(0.0038, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.5476e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.396470
Average KL loss: 0.655980
Average total loss: 2.052450
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.9524e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.326594
Average KL loss: 0.657611
Average total loss: 1.984206
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.3952e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.346575
Average KL loss: 0.659168
Average total loss: 2.005743
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.7894e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.307393
Average KL loss: 0.660735
Average total loss: 1.968128
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-6.7630e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.331212
Average KL loss: 0.661703
Average total loss: 1.992915
tensor(0.0038, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.9087e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.299173
Average KL loss: 0.663059
Average total loss: 1.962232
tensor(0.0038, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.4390e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.331680
Average KL loss: 0.664447
Average total loss: 1.996126
tensor(0.0038, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-7.4770e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.302379
Average KL loss: 0.665894
Average total loss: 1.968273
tensor(0.0038, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.8462e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.275486
Average KL loss: 0.667120
Average total loss: 1.942606
tensor(0.0038, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-9.3579e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.291087
Average KL loss: 0.668257
Average total loss: 1.959344
tensor(0.0038, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.1309e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.236769
Average KL loss: 0.669158
Average total loss: 1.905926
tensor(0.0038, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(4.9453e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.289421
Average KL loss: 0.670503
Average total loss: 1.959924
tensor(0.0038, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.0294e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.239184
Average KL loss: 0.671815
Average total loss: 1.910998
tensor(0.0038, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-7.3347e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.267687
Average KL loss: 0.672879
Average total loss: 1.940566
tensor(0.0038, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.8503e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.228636
Average KL loss: 0.673919
Average total loss: 1.902556
tensor(0.0038, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-7.4247e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.281774
Average KL loss: 0.674934
Average total loss: 1.956708
tensor(0.0039, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.5593e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.200246
Average KL loss: 0.676219
Average total loss: 1.876465
tensor(0.0039, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(6.5619e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.235248
Average KL loss: 0.677209
Average total loss: 1.912457
tensor(0.0039, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-4.0404e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.193669
Average KL loss: 0.678337
Average total loss: 1.872006
tensor(0.0039, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.5304e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.207122
Average KL loss: 0.679025
Average total loss: 1.886147
tensor(0.0039, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-2.1619e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.179327
Average KL loss: 0.679868
Average total loss: 1.859195
tensor(0.0039, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.5912e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.236634
Average KL loss: 0.680952
Average total loss: 1.917586
tensor(0.0039, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.0743e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.185339
Average KL loss: 0.682283
Average total loss: 1.867622
tensor(0.0039, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.1238e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.169019
Average KL loss: 0.683156
Average total loss: 1.852175
tensor(0.0039, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.4501e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.163952
Average KL loss: 0.683771
Average total loss: 1.847723
tensor(0.0039, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.5715e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.222279
Average KL loss: 0.684582
Average total loss: 1.906861
tensor(0.0039, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.9938e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.188501
Average KL loss: 0.685938
Average total loss: 1.874439
tensor(0.0039, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-8.6715e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.142321
Average KL loss: 0.687008
Average total loss: 1.829329
tensor(0.0039, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(2.7243e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.145324
Average KL loss: 0.687675
Average total loss: 1.832998
tensor(0.0039, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-3.2043e-10, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.135830
Average KL loss: 0.688552
Average total loss: 1.824382
tensor(0.0039, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-5.6521e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.133780
Average KL loss: 0.689434
Average total loss: 1.823214
tensor(0.0039, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(6.0178e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.167792
Average KL loss: 0.690266
Average total loss: 1.858058
tensor(0.0039, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-5.0767e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.153406
Average KL loss: 0.691243
Average total loss: 1.844650
tensor(0.0039, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.4988e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.102425
Average KL loss: 0.692297
Average total loss: 1.794722
tensor(0.0039, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.1140e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.148135
Average KL loss: 0.693181
Average total loss: 1.841317
tensor(0.0039, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(2.7982e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.115539
Average KL loss: 0.693936
Average total loss: 1.809475
tensor(0.0039, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.0877e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.113521
Average KL loss: 0.694334
Average total loss: 1.807854
tensor(0.0039, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.0419e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.110980
Average KL loss: 0.695072
Average total loss: 1.806052
tensor(0.0039, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.1356e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.123057
Average KL loss: 0.696005
Average total loss: 1.819062
tensor(0.0039, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-3.2694e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.109334
Average KL loss: 0.697084
Average total loss: 1.806418
tensor(0.0040, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.7423e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.092437
Average KL loss: 0.697836
Average total loss: 1.790272
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.8170e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.077774
Average KL loss: 0.698384
Average total loss: 1.776158
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.9823e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.078035
Average KL loss: 0.698822
Average total loss: 1.776857
tensor(0.0040, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.6393e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.065917
Average KL loss: 0.699410
Average total loss: 1.765327
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.4886e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.093573
Average KL loss: 0.700011
Average total loss: 1.793584
tensor(0.0040, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-6.7082e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.074925
Average KL loss: 0.700503
Average total loss: 1.775428
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.5879e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.086823
Average KL loss: 0.701199
Average total loss: 1.788022
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.0069e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.057934
Average KL loss: 0.701747
Average total loss: 1.759681
tensor(0.0040, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(6.5627e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.065061
Average KL loss: 0.702216
Average total loss: 1.767276
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.0010e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.076224
Average KL loss: 0.702570
Average total loss: 1.778794
tensor(0.0040, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-6.8187e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.074495
Average KL loss: 0.703293
Average total loss: 1.777787
tensor(0.0040, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.0566e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.046633
Average KL loss: 0.703875
Average total loss: 1.750508
tensor(0.0040, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-6.3355e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.037843
Average KL loss: 0.704517
Average total loss: 1.742361
tensor(0.0040, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(8.4856e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.071768
Average KL loss: 0.705012
Average total loss: 1.776780
tensor(0.0040, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.2964e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.033570
Average KL loss: 0.705874
Average total loss: 1.739445
tensor(0.0040, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(9.9039e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.044908
Average KL loss: 0.706429
Average total loss: 1.751337
tensor(0.0040, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.3552e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.032181
Average KL loss: 0.707242
Average total loss: 1.739422
tensor(0.0040, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-3.7153e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.030705
Average KL loss: 0.707953
Average total loss: 1.738658
tensor(0.0040, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.9048e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.026249
Average KL loss: 0.708510
Average total loss: 1.734759
tensor(0.0040, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.5772e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.996558
Average KL loss: 0.708877
Average total loss: 1.705435
tensor(0.0040, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-8.0360e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.043286
Average KL loss: 0.709318
Average total loss: 1.752603
tensor(0.0040, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(2.8446e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.003987
Average KL loss: 0.710021
Average total loss: 1.714008
tensor(0.0040, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-5.4778e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.000972
Average KL loss: 0.710502
Average total loss: 1.711474
tensor(0.0040, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-3.5154e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.994707
Average KL loss: 0.710890
Average total loss: 1.705596
tensor(0.0040, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.4789e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.020340
Average KL loss: 0.711468
Average total loss: 1.731808
tensor(0.0040, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-7.0365e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.979799
Average KL loss: 0.711826
Average total loss: 1.691624
tensor(0.0040, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.1812e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.010681
Average KL loss: 0.712199
Average total loss: 1.722879
tensor(0.0041, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.4718e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.009844
Average KL loss: 0.712827
Average total loss: 1.722671
tensor(0.0041, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-5.0826e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.983530
Average KL loss: 0.713445
Average total loss: 1.696974
tensor(0.0041, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.3688e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.026844
Average KL loss: 0.714016
Average total loss: 1.740861
tensor(0.0041, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.1146e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.984228
Average KL loss: 0.714638
Average total loss: 1.698866
tensor(0.0041, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-8.9724e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.991461
Average KL loss: 0.715267
Average total loss: 1.706729
tensor(0.0041, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-6.0969e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.989535
Average KL loss: 0.715906
Average total loss: 1.705441
tensor(0.0041, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.4620e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.979074
Average KL loss: 0.716301
Average total loss: 1.695375
tensor(0.0041, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-5.1768e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.998694
Average KL loss: 0.716478
Average total loss: 1.715172
tensor(0.0041, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-3.3990e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.996472
Average KL loss: 0.717025
Average total loss: 1.713497
tensor(0.0041, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.4210e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.960423
Average KL loss: 0.717578
Average total loss: 1.678001
tensor(0.0041, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.4119e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.982116
Average KL loss: 0.718097
Average total loss: 1.700213
tensor(0.0041, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.1392e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.974108
Average KL loss: 0.718724
Average total loss: 1.692833
tensor(0.0041, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-8.1870e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.937364
Average KL loss: 0.719089
Average total loss: 1.656454
tensor(0.0041, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(1.1887e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.975292
Average KL loss: 0.719702
Average total loss: 1.694994
tensor(0.0041, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-1.4308e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.953707
Average KL loss: 0.720410
Average total loss: 1.674117
tensor(0.0041, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-3.5903e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.961652
Average KL loss: 0.720905
Average total loss: 1.682556
tensor(0.0041, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(7.5929e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.962425
Average KL loss: 0.721507
Average total loss: 1.683932
tensor(0.0041, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-4.1530e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.954205
Average KL loss: 0.722074
Average total loss: 1.676278
tensor(0.0041, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(2.9382e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.944020
Average KL loss: 0.722315
Average total loss: 1.666336
tensor(0.0041, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(5.3123e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.951942
Average KL loss: 0.722584
Average total loss: 1.674526
tensor(0.0041, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(5.8353e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.970411
Average KL loss: 0.722900
Average total loss: 1.693311
tensor(0.0041, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.2136e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.920056
Average KL loss: 0.723298
Average total loss: 1.643354
tensor(0.0041, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-4.7757e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.950594
Average KL loss: 0.723445
Average total loss: 1.674040
tensor(0.0041, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-1.2530e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.933360
Average KL loss: 0.723923
Average total loss: 1.657283
tensor(0.0041, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(2.5596e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.907505
Average KL loss: 0.724209
Average total loss: 1.631714
tensor(0.0041, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(7.1322e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.926940
Average KL loss: 0.724322
Average total loss: 1.651262
tensor(0.0041, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(5.7771e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.920044
Average KL loss: 0.724590
Average total loss: 1.644634
tensor(0.0041, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-5.4140e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.952577
Average KL loss: 0.724956
Average total loss: 1.677533
tensor(0.0041, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-3.0649e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.953947
Average KL loss: 0.725604
Average total loss: 1.679551
tensor(0.0041, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-5.1053e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.911223
Average KL loss: 0.726020
Average total loss: 1.637243
tensor(0.0041, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-1.9595e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.905555
Average KL loss: 0.726152
Average total loss: 1.631707
tensor(0.0042, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-6.8203e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.904741
Average KL loss: 0.726321
Average total loss: 1.631062
tensor(0.0042, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-2.3204e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.915484
Average KL loss: 0.726481
Average total loss: 1.641965
tensor(0.0042, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(3.5668e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.889386
Average KL loss: 0.726677
Average total loss: 1.616063
tensor(0.0042, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(9.1904e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.905568
Average KL loss: 0.726651
Average total loss: 1.632219
tensor(0.0042, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-7.7539e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.906759
Average KL loss: 0.726892
Average total loss: 1.633652
tensor(0.0042, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-5.5472e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.897816
Average KL loss: 0.727263
Average total loss: 1.625080
tensor(0.0042, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-2.1765e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.887990
Average KL loss: 0.727512
Average total loss: 1.615501
tensor(0.0042, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-1.0532e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.902404
Average KL loss: 0.727806
Average total loss: 1.630210
tensor(0.0042, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-7.6930e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.888976
Average KL loss: 0.728163
Average total loss: 1.617140
tensor(0.0042, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(1.0519e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.892255
Average KL loss: 0.728389
Average total loss: 1.620644
tensor(0.0042, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-1.5165e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.901332
Average KL loss: 0.728632
Average total loss: 1.629964
tensor(0.0042, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-1.5397e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.885163
Average KL loss: 0.728943
Average total loss: 1.614106
tensor(0.0042, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-1.4370e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.882148
Average KL loss: 0.729477
Average total loss: 1.611625
tensor(0.0042, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-7.4939e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.898402
Average KL loss: 0.729964
Average total loss: 1.628367
tensor(0.0042, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-6.1177e-10, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.861731
Average KL loss: 0.730386
Average total loss: 1.592117
tensor(0.0042, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(1.8181e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.869324
Average KL loss: 0.730441
Average total loss: 1.599765
tensor(0.0042, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-1.1886e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.849911
Average KL loss: 0.730582
Average total loss: 1.580493
tensor(0.0042, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-1.2588e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.885993
Average KL loss: 0.730792
Average total loss: 1.616785
tensor(0.0042, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-9.8123e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.867034
Average KL loss: 0.731215
Average total loss: 1.598250
tensor(0.0042, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-1.7152e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.865763
Average KL loss: 0.731635
Average total loss: 1.597398
tensor(0.0042, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-6.2728e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.879535
Average KL loss: 0.731969
Average total loss: 1.611504
tensor(0.0042, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(2.1292e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.883771
Average KL loss: 0.732280
Average total loss: 1.616051
tensor(0.0042, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(-1.6739e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.853285
Average KL loss: 0.732702
Average total loss: 1.585987
tensor(0.0042, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-1.0181e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.868632
Average KL loss: 0.733147
Average total loss: 1.601779
tensor(0.0042, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-2.9126e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.850860
Average KL loss: 0.733457
Average total loss: 1.584317
tensor(0.0042, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-1.4626e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.858412
Average KL loss: 0.733654
Average total loss: 1.592066
tensor(0.0042, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(2.4628e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.878775
Average KL loss: 0.734105
Average total loss: 1.612880
tensor(0.0042, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(5.1875e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.860173
Average KL loss: 0.734439
Average total loss: 1.594612
tensor(0.0042, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(-8.6424e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.845104
Average KL loss: 0.734514
Average total loss: 1.579619
tensor(0.0042, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(1.8172e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.849703
Average KL loss: 0.734511
Average total loss: 1.584214
tensor(0.0042, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(4.0284e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.860438
Average KL loss: 0.734505
Average total loss: 1.594943
tensor(0.0042, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.9226e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.874100
Average KL loss: 0.734507
Average total loss: 1.608606
tensor(0.0042, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(1.1967e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.847663
Average KL loss: 0.734523
Average total loss: 1.582186
tensor(0.0042, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-2.3100e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.845150
Average KL loss: 0.734496
Average total loss: 1.579646
 Percentile value: 4.656320476531982
Non-zero model percentage: 0.07290609925985336%, Non-zero mask percentage: 0.07290609925985336%

--- Pruning Level [6/8]: ---
conv1.weight         | nonzeros =     507 /    1728             ( 29.34%) | total_pruned =    1221 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     275 /   36864             (  0.75%) | total_pruned =   36589 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     288 /   36864             (  0.78%) | total_pruned =   36576 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     243 /   36864             (  0.66%) | total_pruned =   36621 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     220 /   36864             (  0.60%) | total_pruned =   36644 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     325 /   73728             (  0.44%) | total_pruned =   73403 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     404 /  147456             (  0.27%) | total_pruned =  147052 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     221 /    8192             (  2.70%) | total_pruned =    7971 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     212 /  147456             (  0.14%) | total_pruned =  147244 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     213 /  147456             (  0.14%) | total_pruned =  147243 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     433 /  294912             (  0.15%) | total_pruned =  294479 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     222 /     256             ( 86.72%) | total_pruned =      34 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     477 /  589824             (  0.08%) | total_pruned =  589347 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     165 /   32768             (  0.50%) | total_pruned =   32603 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     137 /     256             ( 53.52%) | total_pruned =     119 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     190 /  589824             (  0.03%) | total_pruned =  589634 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      95 /     256             ( 37.11%) | total_pruned =     161 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     181 /  589824             (  0.03%) | total_pruned =  589643 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     113 /     256             ( 44.14%) | total_pruned =     143 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     464 / 1179648             (  0.04%) | total_pruned = 1179184 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     261 /     512             ( 50.98%) | total_pruned =     251 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     377 / 2359296             (  0.02%) | total_pruned = 2358919 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     183 /     512             ( 35.74%) | total_pruned =     329 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      89 /  131072             (  0.07%) | total_pruned =  130983 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      69 /     512             ( 13.48%) | total_pruned =     443 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     123 / 2359296             (  0.01%) | total_pruned = 2359173 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      65 /     512             ( 12.70%) | total_pruned =     447 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =      59 / 2359296             (  0.00%) | total_pruned = 2359237 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     308 /    5120             (  6.02%) | total_pruned =    4812 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 8150, pruned : 11170612, total: 11178762, Compression rate :    1371.63x  ( 99.93% pruned)
Train Epoch: 99/100 Loss: 0.626156 Accuracy: 72.39 78.35 % Best test Accuracy: 72.51%
tensor(0.0042, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(3.8482e-10, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.917429
Average KL loss: 0.672045
Average total loss: 1.589474
tensor(0.0037, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(3.4670e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.949581
Average KL loss: 0.571285
Average total loss: 1.520866
tensor(0.0032, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.2685e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.955157
Average KL loss: 0.498140
Average total loss: 1.453297
tensor(0.0029, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-9.8225e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.973612
Average KL loss: 0.448443
Average total loss: 1.422055
tensor(0.0027, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-7.3617e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.958405
Average KL loss: 0.418437
Average total loss: 1.376842
tensor(0.0025, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-4.1539e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.966727
Average KL loss: 0.402335
Average total loss: 1.369062
tensor(0.0024, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.1847e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.939003
Average KL loss: 0.395035
Average total loss: 1.334038
tensor(0.0024, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-2.4141e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.948738
Average KL loss: 0.392244
Average total loss: 1.340983
tensor(0.0024, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.2890e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.938410
Average KL loss: 0.391006
Average total loss: 1.329416
tensor(0.0024, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-2.6480e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.929836
Average KL loss: 0.390160
Average total loss: 1.319996
tensor(0.0024, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-3.5619e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.920820
Average KL loss: 0.389321
Average total loss: 1.310142
tensor(0.0024, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-4.3058e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.921580
Average KL loss: 0.388545
Average total loss: 1.310124
tensor(0.0024, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.4226e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.902256
Average KL loss: 0.387871
Average total loss: 1.290126
tensor(0.0024, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.7508e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.926795
Average KL loss: 0.387204
Average total loss: 1.313999
tensor(0.0024, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.5965e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.901685
Average KL loss: 0.386619
Average total loss: 1.288304
tensor(0.0024, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-2.2111e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.908344
Average KL loss: 0.386042
Average total loss: 1.294386
tensor(0.0024, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.2725e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.878650
Average KL loss: 0.385412
Average total loss: 1.264063
tensor(0.0024, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-2.3722e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.882227
Average KL loss: 0.384935
Average total loss: 1.267162
tensor(0.0024, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.4646e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.875854
Average KL loss: 0.384411
Average total loss: 1.260266
tensor(0.0024, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.9834e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.869686
Average KL loss: 0.383908
Average total loss: 1.253593
tensor(0.0024, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-3.0322e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.890096
Average KL loss: 0.383429
Average total loss: 1.273525
tensor(0.0024, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.3568e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.871945
Average KL loss: 0.382998
Average total loss: 1.254943
tensor(0.0024, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-3.0075e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.873437
Average KL loss: 0.382569
Average total loss: 1.256006
tensor(0.0024, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.9759e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.876307
Average KL loss: 0.382248
Average total loss: 1.258555
tensor(0.0024, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-6.8132e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.865545
Average KL loss: 0.381907
Average total loss: 1.247451
tensor(0.0024, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.1458e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.865890
Average KL loss: 0.381526
Average total loss: 1.247416
tensor(0.0024, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-3.4797e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.844820
Average KL loss: 0.381213
Average total loss: 1.226033
tensor(0.0024, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-4.7225e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.833305
Average KL loss: 0.380951
Average total loss: 1.214257
tensor(0.0024, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-2.0443e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.843199
Average KL loss: 0.380639
Average total loss: 1.223838
tensor(0.0024, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.8894e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.836461
Average KL loss: 0.380280
Average total loss: 1.216741
tensor(0.0024, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-6.5859e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.836895
Average KL loss: 0.379939
Average total loss: 1.216834
tensor(0.0024, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-3.0494e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.846960
Average KL loss: 0.379652
Average total loss: 1.226612
tensor(0.0024, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-6.1480e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.843635
Average KL loss: 0.379445
Average total loss: 1.223080
tensor(0.0024, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-7.8603e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.833973
Average KL loss: 0.379261
Average total loss: 1.213234
tensor(0.0024, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-9.8200e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.834042
Average KL loss: 0.379106
Average total loss: 1.213147
tensor(0.0024, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-4.2768e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.815856
Average KL loss: 0.378998
Average total loss: 1.194854
tensor(0.0024, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.2407e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.797611
Average KL loss: 0.378784
Average total loss: 1.176395
tensor(0.0024, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.5633e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.827662
Average KL loss: 0.378683
Average total loss: 1.206345
tensor(0.0024, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-8.4392e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.813116
Average KL loss: 0.378445
Average total loss: 1.191561
tensor(0.0024, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-8.6260e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.807078
Average KL loss: 0.378253
Average total loss: 1.185331
tensor(0.0024, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.6623e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.804697
Average KL loss: 0.378085
Average total loss: 1.182782
tensor(0.0024, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.2362e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.804167
Average KL loss: 0.377883
Average total loss: 1.182050
tensor(0.0024, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-8.5803e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.810599
Average KL loss: 0.377716
Average total loss: 1.188315
tensor(0.0024, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.4869e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.808357
Average KL loss: 0.377537
Average total loss: 1.185894
tensor(0.0024, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-6.6173e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.797136
Average KL loss: 0.377374
Average total loss: 1.174509
tensor(0.0024, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.3315e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.819159
Average KL loss: 0.377258
Average total loss: 1.196417
tensor(0.0024, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.1281e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.789712
Average KL loss: 0.377181
Average total loss: 1.166893
tensor(0.0024, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-9.8768e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.792949
Average KL loss: 0.377001
Average total loss: 1.169950
tensor(0.0024, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-6.4198e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.798395
Average KL loss: 0.376797
Average total loss: 1.175192
tensor(0.0024, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.1113e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.809435
Average KL loss: 0.376650
Average total loss: 1.186086
tensor(0.0025, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-6.6541e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.792580
Average KL loss: 0.376503
Average total loss: 1.169083
tensor(0.0025, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-4.5566e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.801472
Average KL loss: 0.376314
Average total loss: 1.177786
tensor(0.0025, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-3.9274e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.788583
Average KL loss: 0.376077
Average total loss: 1.164661
tensor(0.0025, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-5.9838e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.785225
Average KL loss: 0.375918
Average total loss: 1.161143
tensor(0.0025, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.9508e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.789728
Average KL loss: 0.375790
Average total loss: 1.165519
tensor(0.0025, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-5.9819e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.783690
Average KL loss: 0.375670
Average total loss: 1.159360
tensor(0.0025, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-8.0413e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.780967
Average KL loss: 0.375562
Average total loss: 1.156529
tensor(0.0025, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.8579e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.788975
Average KL loss: 0.375385
Average total loss: 1.164359
tensor(0.0025, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.0883e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.783550
Average KL loss: 0.375223
Average total loss: 1.158774
tensor(0.0025, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.0472e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.783284
Average KL loss: 0.375050
Average total loss: 1.158334
tensor(0.0025, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.6171e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.774476
Average KL loss: 0.374957
Average total loss: 1.149433
tensor(0.0025, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.0339e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.777589
Average KL loss: 0.374886
Average total loss: 1.152475
tensor(0.0025, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.5385e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.791898
Average KL loss: 0.374816
Average total loss: 1.166713
tensor(0.0025, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-5.5066e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.775722
Average KL loss: 0.374686
Average total loss: 1.150409
tensor(0.0025, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.2454e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.761133
Average KL loss: 0.374603
Average total loss: 1.135736
tensor(0.0025, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.4222e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.767972
Average KL loss: 0.374504
Average total loss: 1.142476
tensor(0.0025, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.0873e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.776272
Average KL loss: 0.374332
Average total loss: 1.150604
tensor(0.0025, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-4.0676e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.768917
Average KL loss: 0.374245
Average total loss: 1.143161
tensor(0.0025, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-8.7960e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.762336
Average KL loss: 0.374212
Average total loss: 1.136548
tensor(0.0025, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-4.4879e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.773606
Average KL loss: 0.374205
Average total loss: 1.147810
tensor(0.0025, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-6.7667e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.760641
Average KL loss: 0.374174
Average total loss: 1.134814
tensor(0.0025, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-4.8016e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.769839
Average KL loss: 0.374099
Average total loss: 1.143938
tensor(0.0025, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.9468e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.763599
Average KL loss: 0.373982
Average total loss: 1.137581
tensor(0.0025, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.4438e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.755709
Average KL loss: 0.373915
Average total loss: 1.129624
tensor(0.0025, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-8.9844e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.757496
Average KL loss: 0.373798
Average total loss: 1.131293
tensor(0.0025, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.0456e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.759199
Average KL loss: 0.373798
Average total loss: 1.132997
tensor(0.0025, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.2723e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.766301
Average KL loss: 0.373776
Average total loss: 1.140077
tensor(0.0025, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-9.4080e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.755349
Average KL loss: 0.373715
Average total loss: 1.129064
tensor(0.0025, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-5.2712e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.761767
Average KL loss: 0.373660
Average total loss: 1.135427
tensor(0.0025, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-3.9972e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.753199
Average KL loss: 0.373616
Average total loss: 1.126815
tensor(0.0025, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.9253e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.765539
Average KL loss: 0.373576
Average total loss: 1.139115
tensor(0.0025, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.0723e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.756717
Average KL loss: 0.373533
Average total loss: 1.130251
tensor(0.0025, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-6.2620e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.753862
Average KL loss: 0.373515
Average total loss: 1.127376
tensor(0.0025, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(7.9318e-11, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.757429
Average KL loss: 0.373456
Average total loss: 1.130885
tensor(0.0026, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.4905e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.755453
Average KL loss: 0.373474
Average total loss: 1.128927
tensor(0.0026, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-4.9109e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.757355
Average KL loss: 0.373457
Average total loss: 1.130812
tensor(0.0026, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-6.9355e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.739643
Average KL loss: 0.373427
Average total loss: 1.113070
tensor(0.0026, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-2.2075e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.741990
Average KL loss: 0.373314
Average total loss: 1.115304
tensor(0.0026, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-9.8058e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.749461
Average KL loss: 0.373324
Average total loss: 1.122785
tensor(0.0026, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-3.3059e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.751048
Average KL loss: 0.373306
Average total loss: 1.124354
tensor(0.0026, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.9057e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.747846
Average KL loss: 0.373324
Average total loss: 1.121169
tensor(0.0026, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-5.8859e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.749839
Average KL loss: 0.373373
Average total loss: 1.123213
tensor(0.0026, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.3111e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.741447
Average KL loss: 0.373349
Average total loss: 1.114796
tensor(0.0026, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-3.7016e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.743349
Average KL loss: 0.373308
Average total loss: 1.116656
tensor(0.0026, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-6.0050e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.742934
Average KL loss: 0.373281
Average total loss: 1.116215
tensor(0.0026, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.8063e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.746190
Average KL loss: 0.373231
Average total loss: 1.119421
tensor(0.0026, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-8.5682e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.747624
Average KL loss: 0.373254
Average total loss: 1.120878
tensor(0.0026, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-3.1026e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.738285
Average KL loss: 0.373246
Average total loss: 1.111531
tensor(0.0026, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-6.4413e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.737579
Average KL loss: 0.373273
Average total loss: 1.110853
tensor(0.0026, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.0244e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.741335
Average KL loss: 0.373238
Average total loss: 1.114573
tensor(0.0026, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-4.7074e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.736604
Average KL loss: 0.373265
Average total loss: 1.109869
tensor(0.0026, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.7149e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.743922
Average KL loss: 0.373230
Average total loss: 1.117151
tensor(0.0026, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-4.8552e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.741229
Average KL loss: 0.373214
Average total loss: 1.114443
tensor(0.0026, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-5.8216e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.735463
Average KL loss: 0.373240
Average total loss: 1.108703
tensor(0.0026, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.8064e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.748885
Average KL loss: 0.373239
Average total loss: 1.122123
tensor(0.0026, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-6.4291e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.741383
Average KL loss: 0.373227
Average total loss: 1.114610
tensor(0.0026, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.5713e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.727623
Average KL loss: 0.373212
Average total loss: 1.100835
tensor(0.0026, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-8.2788e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.731035
Average KL loss: 0.373218
Average total loss: 1.104253
tensor(0.0026, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-6.2124e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.733665
Average KL loss: 0.373196
Average total loss: 1.106861
tensor(0.0026, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.3163e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.740156
Average KL loss: 0.373199
Average total loss: 1.113355
tensor(0.0026, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.7695e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.737425
Average KL loss: 0.373184
Average total loss: 1.110609
tensor(0.0026, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-4.1462e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.734042
Average KL loss: 0.373175
Average total loss: 1.107217
tensor(0.0026, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.0715e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.733200
Average KL loss: 0.373195
Average total loss: 1.106395
tensor(0.0026, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.0732e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.731190
Average KL loss: 0.373222
Average total loss: 1.104412
tensor(0.0026, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(2.7446e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.724353
Average KL loss: 0.373275
Average total loss: 1.097627
tensor(0.0026, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.4597e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.738861
Average KL loss: 0.373305
Average total loss: 1.112166
tensor(0.0026, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.1080e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.725357
Average KL loss: 0.373328
Average total loss: 1.098685
tensor(0.0027, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.1612e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.730669
Average KL loss: 0.373292
Average total loss: 1.103961
tensor(0.0027, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(1.7066e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.729783
Average KL loss: 0.373325
Average total loss: 1.103108
tensor(0.0027, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-8.2585e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.725469
Average KL loss: 0.373327
Average total loss: 1.098797
tensor(0.0027, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(4.2818e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.725849
Average KL loss: 0.373344
Average total loss: 1.099194
tensor(0.0027, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-4.0528e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.722421
Average KL loss: 0.373371
Average total loss: 1.095793
tensor(0.0027, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.3857e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.725231
Average KL loss: 0.373376
Average total loss: 1.098607
tensor(0.0027, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-5.0150e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.727248
Average KL loss: 0.373396
Average total loss: 1.100645
tensor(0.0027, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.6434e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.727912
Average KL loss: 0.373377
Average total loss: 1.101288
tensor(0.0027, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-4.9782e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.724634
Average KL loss: 0.373302
Average total loss: 1.097936
tensor(0.0027, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-4.7647e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.726954
Average KL loss: 0.373299
Average total loss: 1.100253
tensor(0.0027, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(3.3484e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.721506
Average KL loss: 0.373295
Average total loss: 1.094801
tensor(0.0027, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.9983e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.723606
Average KL loss: 0.373319
Average total loss: 1.096925
tensor(0.0027, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-5.5663e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.738304
Average KL loss: 0.373326
Average total loss: 1.111630
tensor(0.0027, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-3.5735e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.717270
Average KL loss: 0.373298
Average total loss: 1.090568
tensor(0.0027, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.1581e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.718009
Average KL loss: 0.373311
Average total loss: 1.091320
tensor(0.0027, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-5.1803e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.722533
Average KL loss: 0.373269
Average total loss: 1.095802
tensor(0.0027, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.6344e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.722563
Average KL loss: 0.373257
Average total loss: 1.095821
tensor(0.0027, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.0639e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.735950
Average KL loss: 0.373305
Average total loss: 1.109255
tensor(0.0027, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.1420e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.721362
Average KL loss: 0.373383
Average total loss: 1.094745
tensor(0.0027, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-5.5864e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.720830
Average KL loss: 0.373420
Average total loss: 1.094250
tensor(0.0027, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-5.3601e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.721891
Average KL loss: 0.373428
Average total loss: 1.095320
tensor(0.0027, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-5.0453e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.728743
Average KL loss: 0.373436
Average total loss: 1.102179
tensor(0.0027, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(5.9072e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.729278
Average KL loss: 0.373449
Average total loss: 1.102728
tensor(0.0027, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-3.9593e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.714778
Average KL loss: 0.373449
Average total loss: 1.088228
tensor(0.0027, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.1475e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.723816
Average KL loss: 0.373425
Average total loss: 1.097241
tensor(0.0027, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.9095e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.715966
Average KL loss: 0.373495
Average total loss: 1.089460
tensor(0.0027, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.0749e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.722866
Average KL loss: 0.373556
Average total loss: 1.096422
tensor(0.0027, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-7.7587e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.719506
Average KL loss: 0.373634
Average total loss: 1.093139
tensor(0.0027, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.1982e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.714698
Average KL loss: 0.373740
Average total loss: 1.088437
tensor(0.0027, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-3.8711e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.712762
Average KL loss: 0.373716
Average total loss: 1.086477
tensor(0.0027, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-3.2751e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.720761
Average KL loss: 0.373751
Average total loss: 1.094512
tensor(0.0027, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-3.2286e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.717360
Average KL loss: 0.373798
Average total loss: 1.091158
tensor(0.0027, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-7.3501e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.716130
Average KL loss: 0.373849
Average total loss: 1.089979
tensor(0.0028, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-3.7050e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.718364
Average KL loss: 0.373858
Average total loss: 1.092222
tensor(0.0028, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-2.8395e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.714548
Average KL loss: 0.373931
Average total loss: 1.088479
tensor(0.0028, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-5.9971e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.709461
Average KL loss: 0.374004
Average total loss: 1.083466
tensor(0.0028, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-2.0752e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.710090
Average KL loss: 0.373949
Average total loss: 1.084039
tensor(0.0028, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-2.0548e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.714848
Average KL loss: 0.373981
Average total loss: 1.088830
tensor(0.0028, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-3.4903e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.713073
Average KL loss: 0.374020
Average total loss: 1.087094
tensor(0.0028, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-2.7068e-10, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.713840
Average KL loss: 0.374004
Average total loss: 1.087844
tensor(0.0028, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-6.9019e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.710517
Average KL loss: 0.373937
Average total loss: 1.084454
tensor(0.0028, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-5.2523e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.713837
Average KL loss: 0.373967
Average total loss: 1.087804
tensor(0.0028, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(1.3096e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.712772
Average KL loss: 0.373991
Average total loss: 1.086763
tensor(0.0028, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.6933e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.715767
Average KL loss: 0.374022
Average total loss: 1.089788
tensor(0.0028, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-3.9111e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.709517
Average KL loss: 0.374083
Average total loss: 1.083601
tensor(0.0028, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-2.8897e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.709905
Average KL loss: 0.374079
Average total loss: 1.083984
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-1.4371e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.717526
Average KL loss: 0.374079
Average total loss: 1.091604
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-2.7371e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.711929
Average KL loss: 0.374098
Average total loss: 1.086027
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-2.1875e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.706278
Average KL loss: 0.374102
Average total loss: 1.080380
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(4.5031e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.708128
Average KL loss: 0.374106
Average total loss: 1.082234
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-1.5485e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.704593
Average KL loss: 0.374111
Average total loss: 1.078704
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-1.1598e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.707710
Average KL loss: 0.374115
Average total loss: 1.081825
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-1.0403e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.710456
Average KL loss: 0.374117
Average total loss: 1.084574
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-2.1536e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.713604
Average KL loss: 0.374122
Average total loss: 1.087726
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-9.5164e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.719929
Average KL loss: 0.374120
Average total loss: 1.094049
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-6.6856e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.710009
Average KL loss: 0.374116
Average total loss: 1.084125
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-1.6441e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.713530
Average KL loss: 0.374111
Average total loss: 1.087641
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-3.4372e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.709532
Average KL loss: 0.374111
Average total loss: 1.083643
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-3.3355e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.705424
Average KL loss: 0.374111
Average total loss: 1.079535
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-3.2614e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.715848
Average KL loss: 0.374107
Average total loss: 1.089955
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-6.0356e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.713454
Average KL loss: 0.374114
Average total loss: 1.087568
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-4.8067e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.708417
Average KL loss: 0.374112
Average total loss: 1.082529
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-6.3112e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.705985
Average KL loss: 0.374113
Average total loss: 1.080098
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-3.7939e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.710216
Average KL loss: 0.374113
Average total loss: 1.084329
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-4.0963e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.711370
Average KL loss: 0.374113
Average total loss: 1.085483
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-5.9700e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.705586
Average KL loss: 0.374113
Average total loss: 1.079699
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-5.8281e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.705280
Average KL loss: 0.374112
Average total loss: 1.079392
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-5.2341e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.715630
Average KL loss: 0.374113
Average total loss: 1.089742
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(8.5859e-11, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.712232
Average KL loss: 0.374113
Average total loss: 1.086345
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-4.0547e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.718480
Average KL loss: 0.374113
Average total loss: 1.092593
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-4.6462e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.710242
Average KL loss: 0.374113
Average total loss: 1.084355
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-1.5411e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.706350
Average KL loss: 0.374112
Average total loss: 1.080463
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(1.6087e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.712970
Average KL loss: 0.374112
Average total loss: 1.087083
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-1.3448e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.705716
Average KL loss: 0.374112
Average total loss: 1.079828
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-2.7645e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.707190
Average KL loss: 0.374112
Average total loss: 1.081302
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-3.3752e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.711681
Average KL loss: 0.374112
Average total loss: 1.085793
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-8.6617e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.713427
Average KL loss: 0.374112
Average total loss: 1.087539
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-4.7092e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.709595
Average KL loss: 0.374112
Average total loss: 1.083707
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-3.4871e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.715042
Average KL loss: 0.374112
Average total loss: 1.089154
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-6.6875e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.714491
Average KL loss: 0.374112
Average total loss: 1.088604
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-8.0157e-10, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.709729
Average KL loss: 0.374112
Average total loss: 1.083841
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-2.2169e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.705512
Average KL loss: 0.374112
Average total loss: 1.079625
tensor(0.0028, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-3.0662e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.713999
Average KL loss: 0.374112
Average total loss: 1.088111
 Percentile value: 6.849361324310303
Non-zero model percentage: 0.02187183126807213%, Non-zero mask percentage: 0.02187183126807213%

--- Pruning Level [7/8]: ---
conv1.weight         | nonzeros =     329 /    1728             ( 19.04%) | total_pruned =    1399 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
bn1.bias             | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      83 /   36864             (  0.23%) | total_pruned =   36781 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      76 /   36864             (  0.21%) | total_pruned =   36788 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      67 /   36864             (  0.18%) | total_pruned =   36797 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =      53 /   36864             (  0.14%) | total_pruned =   36811 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =      63 /   73728             (  0.09%) | total_pruned =   73665 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =      89 /  147456             (  0.06%) | total_pruned =  147367 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      31 /    8192             (  0.38%) | total_pruned =    8161 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =      47 /  147456             (  0.03%) | total_pruned =  147409 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =      37 /  147456             (  0.03%) | total_pruned =  147419 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =      60 /  294912             (  0.02%) | total_pruned =  294852 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =      93 /     256             ( 36.33%) | total_pruned =     163 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =      77 /  589824             (  0.01%) | total_pruned =  589747 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =      77 /     256             ( 30.08%) | total_pruned =     179 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      14 /   32768             (  0.04%) | total_pruned =   32754 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =      38 /  589824             (  0.01%) | total_pruned =  589786 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      34 /     256             ( 13.28%) | total_pruned =     222 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =      33 /  589824             (  0.01%) | total_pruned =  589791 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =      52 / 1179648             (  0.00%) | total_pruned = 1179596 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      81 /     512             ( 15.82%) | total_pruned =     431 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =      69 / 2359296             (  0.00%) | total_pruned = 2359227 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      86 /     512             ( 16.80%) | total_pruned =     426 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      14 /  131072             (  0.01%) | total_pruned =  131058 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      25 /     512             (  4.88%) | total_pruned =     487 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =      18 / 2359296             (  0.00%) | total_pruned = 2359278 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =      11 / 2359296             (  0.00%) | total_pruned = 2359285 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      23 /     512             (  4.49%) | total_pruned =     489 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     141 /    5120             (  2.75%) | total_pruned =    4979 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 2445, pruned : 11176317, total: 11178762, Compression rate :    4572.09x  ( 99.98% pruned)
Train Epoch: 99/100 Loss: 1.530620 Accuracy: 37.79 38.39 % Best test Accuracy: 37.79%
