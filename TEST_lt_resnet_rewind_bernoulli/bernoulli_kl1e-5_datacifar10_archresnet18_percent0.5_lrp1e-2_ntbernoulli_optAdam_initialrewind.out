Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 61/100 Loss: 0.000080 Accuracy: 86.83 100.00 % Best test Accuracy: 86.83%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-2.1415e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.781581
Average KL loss: 0.022915
Average total loss: 1.804496
tensor(0.0006, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.1547e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.479979
Average KL loss: 0.058272
Average total loss: 1.538250
tensor(0.0007, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.5852e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.272481
Average KL loss: 0.076328
Average total loss: 1.348809
tensor(0.0008, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-1.5496e-07, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.138971
Average KL loss: 0.085166
Average total loss: 1.224137
tensor(0.0009, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-1.1944e-07, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.051031
Average KL loss: 0.091656
Average total loss: 1.142688
tensor(0.0012, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.5875e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.969904
Average KL loss: 0.095247
Average total loss: 1.065151
tensor(0.0013, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-9.8225e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.903427
Average KL loss: 0.097790
Average total loss: 1.001218
tensor(0.0016, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-1.0753e-07, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.849244
Average KL loss: 0.100548
Average total loss: 0.949792
tensor(0.0017, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-8.4542e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.777373
Average KL loss: 0.102282
Average total loss: 0.879656
tensor(0.0019, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-8.8526e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.748213
Average KL loss: 0.102905
Average total loss: 0.851118
tensor(0.0021, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-7.4957e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.712748
Average KL loss: 0.103284
Average total loss: 0.816031
tensor(0.0022, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-6.9964e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.671457
Average KL loss: 0.104221
Average total loss: 0.775679
tensor(0.0023, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-7.9778e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.630842
Average KL loss: 0.104695
Average total loss: 0.735537
tensor(0.0025, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.1762e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.616385
Average KL loss: 0.105258
Average total loss: 0.721643
tensor(0.0026, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-7.4231e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.584807
Average KL loss: 0.105320
Average total loss: 0.690127
tensor(0.0027, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.3865e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.548047
Average KL loss: 0.105806
Average total loss: 0.653853
tensor(0.0028, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.6530e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.513818
Average KL loss: 0.104849
Average total loss: 0.618667
tensor(0.0029, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.6244e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.504959
Average KL loss: 0.104445
Average total loss: 0.609404
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-5.8013e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.482208
Average KL loss: 0.104828
Average total loss: 0.587036
tensor(0.0031, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.4251e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.467576
Average KL loss: 0.105407
Average total loss: 0.572983
tensor(0.0032, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.8204e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.444845
Average KL loss: 0.105237
Average total loss: 0.550082
tensor(0.0033, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-6.2903e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.423391
Average KL loss: 0.105376
Average total loss: 0.528767
tensor(0.0034, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-6.9380e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.409753
Average KL loss: 0.104885
Average total loss: 0.514638
tensor(0.0035, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.0351e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.394528
Average KL loss: 0.105057
Average total loss: 0.499585
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.8894e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.377975
Average KL loss: 0.104943
Average total loss: 0.482918
tensor(0.0036, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.6020e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.358811
Average KL loss: 0.104575
Average total loss: 0.463386
tensor(0.0037, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.6157e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.351345
Average KL loss: 0.104555
Average total loss: 0.455900
tensor(0.0038, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.2522e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.336375
Average KL loss: 0.104652
Average total loss: 0.441027
tensor(0.0039, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.7072e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.326326
Average KL loss: 0.104912
Average total loss: 0.431239
tensor(0.0039, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-4.0123e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.311376
Average KL loss: 0.104743
Average total loss: 0.416119
tensor(0.0039, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.7136e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.311340
Average KL loss: 0.104169
Average total loss: 0.415509
tensor(0.0040, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.6583e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.292288
Average KL loss: 0.104393
Average total loss: 0.396681
tensor(0.0040, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.3398e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.277253
Average KL loss: 0.103879
Average total loss: 0.381131
tensor(0.0041, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.8263e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.274874
Average KL loss: 0.103563
Average total loss: 0.378437
tensor(0.0042, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.7256e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.272781
Average KL loss: 0.103917
Average total loss: 0.376698
tensor(0.0042, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.9162e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.257492
Average KL loss: 0.104074
Average total loss: 0.361566
tensor(0.0042, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.8884e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.255833
Average KL loss: 0.104825
Average total loss: 0.360657
tensor(0.0043, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.6402e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.246381
Average KL loss: 0.105121
Average total loss: 0.351502
tensor(0.0043, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.6849e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.237651
Average KL loss: 0.105181
Average total loss: 0.342831
tensor(0.0043, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.8439e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.222925
Average KL loss: 0.104162
Average total loss: 0.327087
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.2318e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.217473
Average KL loss: 0.103188
Average total loss: 0.320661
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.0235e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.212115
Average KL loss: 0.103340
Average total loss: 0.315454
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.4346e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.201699
Average KL loss: 0.102807
Average total loss: 0.304506
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.3994e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.210353
Average KL loss: 0.103091
Average total loss: 0.313444
tensor(0.0045, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.9570e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.196199
Average KL loss: 0.103497
Average total loss: 0.299696
tensor(0.0045, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.8627e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.187141
Average KL loss: 0.102746
Average total loss: 0.289887
tensor(0.0045, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.6980e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.193485
Average KL loss: 0.102552
Average total loss: 0.296037
tensor(0.0045, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.7766e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.180178
Average KL loss: 0.103224
Average total loss: 0.283402
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.6197e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.165564
Average KL loss: 0.102694
Average total loss: 0.268258
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.0271e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.170761
Average KL loss: 0.102141
Average total loss: 0.272901
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.4624e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.165021
Average KL loss: 0.102143
Average total loss: 0.267164
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.7684e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.158368
Average KL loss: 0.102216
Average total loss: 0.260584
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.8231e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.155569
Average KL loss: 0.101831
Average total loss: 0.257400
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.4833e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.153638
Average KL loss: 0.101074
Average total loss: 0.254712
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.2993e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.148839
Average KL loss: 0.101029
Average total loss: 0.249868
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5768e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.145185
Average KL loss: 0.100715
Average total loss: 0.245901
tensor(0.0046, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5557e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.140930
Average KL loss: 0.100427
Average total loss: 0.241357
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5318e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.140946
Average KL loss: 0.100946
Average total loss: 0.241892
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.7981e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.135439
Average KL loss: 0.100745
Average total loss: 0.236184
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5378e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.127886
Average KL loss: 0.100556
Average total loss: 0.228442
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.7945e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.124548
Average KL loss: 0.099436
Average total loss: 0.223984
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.0687e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.122970
Average KL loss: 0.098844
Average total loss: 0.221815
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.3015e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.125966
Average KL loss: 0.099451
Average total loss: 0.225417
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.6158e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.116570
Average KL loss: 0.099011
Average total loss: 0.215582
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.4844e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.113034
Average KL loss: 0.098034
Average total loss: 0.211068
tensor(0.0047, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.1456e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.120709
Average KL loss: 0.097709
Average total loss: 0.218418
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.3005e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.108732
Average KL loss: 0.098420
Average total loss: 0.207151
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.5837e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.111783
Average KL loss: 0.098414
Average total loss: 0.210197
tensor(0.0047, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-6.9634e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.113613
Average KL loss: 0.098283
Average total loss: 0.211896
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.6512e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.108252
Average KL loss: 0.098988
Average total loss: 0.207240
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.0617e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.104926
Average KL loss: 0.098901
Average total loss: 0.203827
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.5565e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.101908
Average KL loss: 0.098127
Average total loss: 0.200035
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.9785e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.096727
Average KL loss: 0.097325
Average total loss: 0.194052
tensor(0.0048, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-7.5567e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.101155
Average KL loss: 0.097302
Average total loss: 0.198458
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-8.1604e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.092656
Average KL loss: 0.097257
Average total loss: 0.189914
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-7.8732e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.098571
Average KL loss: 0.097537
Average total loss: 0.196107
tensor(0.0048, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.9620e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.094356
Average KL loss: 0.098037
Average total loss: 0.192393
tensor(0.0048, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.8142e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.092114
Average KL loss: 0.097569
Average total loss: 0.189683
tensor(0.0048, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.6523e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.089041
Average KL loss: 0.097587
Average total loss: 0.186628
tensor(0.0048, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.9336e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.087515
Average KL loss: 0.096662
Average total loss: 0.184176
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-5.6550e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.081658
Average KL loss: 0.095857
Average total loss: 0.177515
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-6.0571e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.085028
Average KL loss: 0.095018
Average total loss: 0.180046
tensor(0.0048, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.2132e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.081676
Average KL loss: 0.094469
Average total loss: 0.176146
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.0701e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.082045
Average KL loss: 0.095047
Average total loss: 0.177092
tensor(0.0047, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.9775e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.081214
Average KL loss: 0.095063
Average total loss: 0.176278
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.6232e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.082661
Average KL loss: 0.095654
Average total loss: 0.178316
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.8928e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.078849
Average KL loss: 0.095893
Average total loss: 0.174741
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-9.6612e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.073816
Average KL loss: 0.095176
Average total loss: 0.168992
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-7.4495e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.073589
Average KL loss: 0.093897
Average total loss: 0.167486
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-8.3313e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.074293
Average KL loss: 0.094082
Average total loss: 0.168376
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.4775e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.071842
Average KL loss: 0.093958
Average total loss: 0.165800
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.0131e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.070900
Average KL loss: 0.094063
Average total loss: 0.164963
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-6.0265e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.071145
Average KL loss: 0.093464
Average total loss: 0.164609
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-4.7075e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.065632
Average KL loss: 0.093602
Average total loss: 0.159234
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.8177e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.069612
Average KL loss: 0.093171
Average total loss: 0.162784
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-5.9970e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.066480
Average KL loss: 0.093743
Average total loss: 0.160223
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2373e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.063725
Average KL loss: 0.092671
Average total loss: 0.156395
tensor(0.0047, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.3134e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.066125
Average KL loss: 0.092557
Average total loss: 0.158682
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.5158e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.062936
Average KL loss: 0.092801
Average total loss: 0.155737
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.9893e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.065525
Average KL loss: 0.092323
Average total loss: 0.157848
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.4077e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.060252
Average KL loss: 0.092750
Average total loss: 0.153002
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.4921e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.062894
Average KL loss: 0.091779
Average total loss: 0.154673
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.5107e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.059602
Average KL loss: 0.092448
Average total loss: 0.152049
tensor(0.0046, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-9.7977e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.059708
Average KL loss: 0.091818
Average total loss: 0.151526
tensor(0.0047, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-8.3837e-10, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.058585
Average KL loss: 0.091326
Average total loss: 0.149911
tensor(0.0046, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-7.4487e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.056023
Average KL loss: 0.090879
Average total loss: 0.146902
tensor(0.0046, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2990e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.057102
Average KL loss: 0.090827
Average total loss: 0.147930
tensor(0.0046, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.7662e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.057153
Average KL loss: 0.091195
Average total loss: 0.148348
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.2678e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.055326
Average KL loss: 0.090385
Average total loss: 0.145711
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.4728e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.056119
Average KL loss: 0.090345
Average total loss: 0.146465
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-4.5202e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.057698
Average KL loss: 0.091418
Average total loss: 0.149115
tensor(0.0046, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.6245e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.052311
Average KL loss: 0.091136
Average total loss: 0.143447
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-6.5827e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.052438
Average KL loss: 0.089820
Average total loss: 0.142259
tensor(0.0046, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.1456e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.054580
Average KL loss: 0.090505
Average total loss: 0.145085
tensor(0.0046, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.5763e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.052857
Average KL loss: 0.090166
Average total loss: 0.143023
tensor(0.0046, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.1179e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.053456
Average KL loss: 0.090487
Average total loss: 0.143943
tensor(0.0046, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.8786e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.052757
Average KL loss: 0.090816
Average total loss: 0.143573
tensor(0.0046, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-5.6519e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.053488
Average KL loss: 0.091435
Average total loss: 0.144922
tensor(0.0046, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.9328e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.050291
Average KL loss: 0.091249
Average total loss: 0.141540
tensor(0.0046, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.0470e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.049077
Average KL loss: 0.090464
Average total loss: 0.139540
tensor(0.0046, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.1736e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.046923
Average KL loss: 0.089705
Average total loss: 0.136628
tensor(0.0046, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.1624e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.049107
Average KL loss: 0.089156
Average total loss: 0.138263
tensor(0.0046, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-6.5521e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.047763
Average KL loss: 0.089396
Average total loss: 0.137159
tensor(0.0045, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.8167e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.048201
Average KL loss: 0.089247
Average total loss: 0.137447
tensor(0.0045, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.0370e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.046576
Average KL loss: 0.088985
Average total loss: 0.135561
tensor(0.0045, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.3068e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.048412
Average KL loss: 0.089484
Average total loss: 0.137896
tensor(0.0045, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.9681e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.047136
Average KL loss: 0.089814
Average total loss: 0.136950
tensor(0.0045, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-5.2743e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.049656
Average KL loss: 0.090647
Average total loss: 0.140304
tensor(0.0046, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.0727e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.045735
Average KL loss: 0.090068
Average total loss: 0.135803
tensor(0.0045, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.6646e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.046527
Average KL loss: 0.089819
Average total loss: 0.136345
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.8894e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.047779
Average KL loss: 0.090378
Average total loss: 0.138156
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-3.7242e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.047264
Average KL loss: 0.090736
Average total loss: 0.138000
tensor(0.0045, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.7832e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.041933
Average KL loss: 0.090234
Average total loss: 0.132167
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.9440e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.043738
Average KL loss: 0.088916
Average total loss: 0.132654
tensor(0.0045, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.6805e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.043254
Average KL loss: 0.088537
Average total loss: 0.131791
tensor(0.0045, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.1088e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.044819
Average KL loss: 0.089170
Average total loss: 0.133989
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-4.3789e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.041414
Average KL loss: 0.089241
Average total loss: 0.130654
tensor(0.0045, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(1.2013e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.042764
Average KL loss: 0.087902
Average total loss: 0.130666
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(1.1491e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.041680
Average KL loss: 0.088009
Average total loss: 0.129689
tensor(0.0045, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-7.1874e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.043757
Average KL loss: 0.088383
Average total loss: 0.132140
tensor(0.0045, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(2.8715e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.042742
Average KL loss: 0.088940
Average total loss: 0.131682
tensor(0.0045, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.4149e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.044301
Average KL loss: 0.089883
Average total loss: 0.134184
tensor(0.0045, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.8524e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.040750
Average KL loss: 0.089466
Average total loss: 0.130216
tensor(0.0045, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(4.6232e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.039786
Average KL loss: 0.088334
Average total loss: 0.128120
tensor(0.0045, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.7855e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.041448
Average KL loss: 0.088480
Average total loss: 0.129928
tensor(0.0045, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.5424e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.043358
Average KL loss: 0.089325
Average total loss: 0.132682
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.2629e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.040836
Average KL loss: 0.089177
Average total loss: 0.130013
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.8643e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.039042
Average KL loss: 0.089081
Average total loss: 0.128123
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-5.9492e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.038748
Average KL loss: 0.088687
Average total loss: 0.127435
tensor(0.0045, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-3.9755e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.041376
Average KL loss: 0.088984
Average total loss: 0.130360
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.8205e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.040140
Average KL loss: 0.088582
Average total loss: 0.128722
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-2.0065e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.040259
Average KL loss: 0.088583
Average total loss: 0.128842
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.0140e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.038836
Average KL loss: 0.088600
Average total loss: 0.127435
tensor(0.0045, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.3856e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.039882
Average KL loss: 0.089406
Average total loss: 0.129288
tensor(0.0045, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.7375e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.038408
Average KL loss: 0.088766
Average total loss: 0.127175
tensor(0.0045, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-3.7966e-11, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.032984
Average KL loss: 0.087530
Average total loss: 0.120513
tensor(0.0045, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.2096e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.036259
Average KL loss: 0.085906
Average total loss: 0.122165
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(1.2021e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.035665
Average KL loss: 0.086317
Average total loss: 0.121982
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-4.4226e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.036045
Average KL loss: 0.086438
Average total loss: 0.122483
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-3.9945e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.035302
Average KL loss: 0.085956
Average total loss: 0.121258
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.8041e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.034719
Average KL loss: 0.085262
Average total loss: 0.119982
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-9.3639e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.037679
Average KL loss: 0.086229
Average total loss: 0.123907
tensor(0.0044, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-2.3571e-11, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.036059
Average KL loss: 0.086865
Average total loss: 0.122924
tensor(0.0044, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-2.3867e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.035157
Average KL loss: 0.085882
Average total loss: 0.121038
tensor(0.0044, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-3.5324e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.037641
Average KL loss: 0.086798
Average total loss: 0.124439
tensor(0.0045, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(3.0664e-10, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.035381
Average KL loss: 0.087355
Average total loss: 0.122736
tensor(0.0044, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-3.4048e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.037332
Average KL loss: 0.086788
Average total loss: 0.124120
tensor(0.0044, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(9.4284e-10, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.034512
Average KL loss: 0.087080
Average total loss: 0.121592
tensor(0.0044, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-3.2373e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.035520
Average KL loss: 0.086905
Average total loss: 0.122426
tensor(0.0044, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-2.2830e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.036134
Average KL loss: 0.086511
Average total loss: 0.122645
tensor(0.0044, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(3.8677e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.036416
Average KL loss: 0.087141
Average total loss: 0.123557
tensor(0.0044, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-5.7775e-11, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.035434
Average KL loss: 0.087543
Average total loss: 0.122977
tensor(0.0044, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(5.1394e-11, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.033761
Average KL loss: 0.086280
Average total loss: 0.120041
tensor(0.0044, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-3.9168e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.033557
Average KL loss: 0.083246
Average total loss: 0.116802
tensor(0.0044, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(8.2886e-10, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.031424
Average KL loss: 0.080896
Average total loss: 0.112320
tensor(0.0044, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.8207e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.033323
Average KL loss: 0.079004
Average total loss: 0.112326
tensor(0.0044, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-4.4673e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.034102
Average KL loss: 0.077424
Average total loss: 0.111526
tensor(0.0044, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-6.5342e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.032729
Average KL loss: 0.076047
Average total loss: 0.108776
tensor(0.0044, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.3489e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.033317
Average KL loss: 0.074836
Average total loss: 0.108153
tensor(0.0044, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.6407e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.032364
Average KL loss: 0.073755
Average total loss: 0.106118
tensor(0.0044, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.8960e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.034329
Average KL loss: 0.072766
Average total loss: 0.107095
tensor(0.0044, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-3.7675e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.033883
Average KL loss: 0.071885
Average total loss: 0.105768
tensor(0.0044, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-8.7903e-10, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.031774
Average KL loss: 0.071040
Average total loss: 0.102814
tensor(0.0044, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-7.9508e-10, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.031828
Average KL loss: 0.070265
Average total loss: 0.102093
tensor(0.0044, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(1.9237e-10, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.032551
Average KL loss: 0.069531
Average total loss: 0.102082
tensor(0.0044, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-3.5946e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.033539
Average KL loss: 0.068879
Average total loss: 0.102418
tensor(0.0044, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-1.2749e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.031630
Average KL loss: 0.068257
Average total loss: 0.099887
tensor(0.0044, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.0416e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.030774
Average KL loss: 0.067615
Average total loss: 0.098389
tensor(0.0044, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.3234e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.031561
Average KL loss: 0.067028
Average total loss: 0.098589
tensor(0.0044, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-1.1571e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.032840
Average KL loss: 0.066525
Average total loss: 0.099365
tensor(0.0044, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-4.2323e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.029156
Average KL loss: 0.066016
Average total loss: 0.095172
tensor(0.0044, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(4.5949e-10, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.032747
Average KL loss: 0.065535
Average total loss: 0.098282
tensor(0.0044, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(8.8404e-10, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.031068
Average KL loss: 0.065124
Average total loss: 0.096192
tensor(0.0044, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-5.1214e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.031571
Average KL loss: 0.064700
Average total loss: 0.096270
tensor(0.0044, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(4.4386e-10, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.032889
Average KL loss: 0.064316
Average total loss: 0.097205
tensor(0.0044, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(7.7628e-10, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.033784
Average KL loss: 0.063977
Average total loss: 0.097761
tensor(0.0044, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(1.0554e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.031319
Average KL loss: 0.063638
Average total loss: 0.094957
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(1.3839e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.031455
Average KL loss: 0.063284
Average total loss: 0.094739
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.4471e-10, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.030939
Average KL loss: 0.062966
Average total loss: 0.093904
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(3.6683e-10, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.032241
Average KL loss: 0.062652
Average total loss: 0.094893
 Percentile value: 0.006108797620981932
Non-zero model percentage: 49.999996185302734%, Non-zero mask percentage: 49.999996185302734%

--- Pruning Level [1/12]: ---
conv1.weight         | nonzeros =    1325 /    1728             ( 76.68%) | total_pruned =     403 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   20151 /   36864             ( 54.66%) | total_pruned =   16713 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   20654 /   36864             ( 56.03%) | total_pruned =   16210 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   20353 /   36864             ( 55.21%) | total_pruned =   16511 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   20400 /   36864             ( 55.34%) | total_pruned =   16464 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   39891 /   73728             ( 54.11%) | total_pruned =   33837 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      88 /     128             ( 68.75%) | total_pruned =      40 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   79023 /  147456             ( 53.59%) | total_pruned =   68433 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    5497 /    8192             ( 67.10%) | total_pruned =    2695 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   76674 /  147456             ( 52.00%) | total_pruned =   70782 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   76096 /  147456             ( 51.61%) | total_pruned =   71360 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      90 /     128             ( 70.31%) | total_pruned =      38 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  155986 /  294912             ( 52.89%) | total_pruned =  138926 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  308581 /  589824             ( 52.32%) | total_pruned =  281243 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     251 /     256             ( 98.05%) | total_pruned =       5 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   19943 /   32768             ( 60.86%) | total_pruned =   12825 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  299421 /  589824             ( 50.76%) | total_pruned =  290403 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     250 /     256             ( 97.66%) | total_pruned =       6 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  295855 /  589824             ( 50.16%) | total_pruned =  293969 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  606811 / 1179648             ( 51.44%) | total_pruned =  572837 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1180406 / 2359296             ( 50.03%) | total_pruned = 1178890 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     456 /     512             ( 89.06%) | total_pruned =      56 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   69948 /  131072             ( 53.37%) | total_pruned =   61124 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     449 /     512             ( 87.70%) | total_pruned =      63 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1154587 / 2359296             ( 48.94%) | total_pruned = 1204709 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     416 /     512             ( 81.25%) | total_pruned =      96 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     400 /     512             ( 78.12%) | total_pruned =     112 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1124857 / 2359296             ( 47.68%) | total_pruned = 1234439 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     133 /     512             ( 25.98%) | total_pruned =     379 | shape = torch.Size([512])
linear.weight        | nonzeros =    4367 /    5120             ( 85.29%) | total_pruned =     753 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       8 /      10             ( 80.00%) | total_pruned =       2 | shape = torch.Size([10])
alive: 5589381, pruned : 5589381, total: 11178762, Compression rate :       2.00x  ( 50.00% pruned)
Train Epoch: 33/100 Loss: 0.000009 Accuracy: 86.79 100.00 % Best test Accuracy: 86.79%
tensor(0.0044, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.7016e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.122755
Average KL loss: 0.062968
Average total loss: 0.185723
tensor(0.0086, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.2803e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.100896
Average KL loss: 0.073846
Average total loss: 0.174742
tensor(0.0083, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-6.6826e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.091820
Average KL loss: 0.080837
Average total loss: 0.172657
tensor(0.0082, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.9952e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.086817
Average KL loss: 0.085060
Average total loss: 0.171877
tensor(0.0080, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(2.2043e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.081238
Average KL loss: 0.088858
Average total loss: 0.170096
tensor(0.0079, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.8539e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.077545
Average KL loss: 0.091363
Average total loss: 0.168908
tensor(0.0078, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(1.3063e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.075468
Average KL loss: 0.093282
Average total loss: 0.168751
tensor(0.0077, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-5.4034e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.071859
Average KL loss: 0.094904
Average total loss: 0.166764
tensor(0.0076, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(1.8232e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.068962
Average KL loss: 0.095552
Average total loss: 0.164514
tensor(0.0075, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.0563e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.071920
Average KL loss: 0.097130
Average total loss: 0.169050
tensor(0.0075, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-2.0725e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.068054
Average KL loss: 0.098221
Average total loss: 0.166274
tensor(0.0074, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-3.9358e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.067153
Average KL loss: 0.098964
Average total loss: 0.166116
tensor(0.0074, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(1.9419e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.060871
Average KL loss: 0.099598
Average total loss: 0.160469
tensor(0.0073, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-3.9389e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.060962
Average KL loss: 0.099422
Average total loss: 0.160384
tensor(0.0072, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(2.9915e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.061651
Average KL loss: 0.099607
Average total loss: 0.161257
tensor(0.0072, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.8778e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.058245
Average KL loss: 0.099993
Average total loss: 0.158238
tensor(0.0071, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(7.4446e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.058824
Average KL loss: 0.100188
Average total loss: 0.159012
tensor(0.0070, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(1.9386e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.057449
Average KL loss: 0.100288
Average total loss: 0.157737
tensor(0.0070, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.9745e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.059614
Average KL loss: 0.100625
Average total loss: 0.160239
tensor(0.0069, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(2.3279e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.058241
Average KL loss: 0.101017
Average total loss: 0.159258
tensor(0.0069, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-3.9259e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.054355
Average KL loss: 0.101208
Average total loss: 0.155564
tensor(0.0069, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(2.4007e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.056411
Average KL loss: 0.101187
Average total loss: 0.157599
tensor(0.0068, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(1.2387e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.056783
Average KL loss: 0.101592
Average total loss: 0.158376
tensor(0.0068, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.5928e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.052385
Average KL loss: 0.101850
Average total loss: 0.154235
tensor(0.0068, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(2.8178e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.054324
Average KL loss: 0.101613
Average total loss: 0.155937
tensor(0.0067, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(7.2557e-10, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.053345
Average KL loss: 0.101620
Average total loss: 0.154965
tensor(0.0067, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.5992e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.050356
Average KL loss: 0.101467
Average total loss: 0.151822
tensor(0.0067, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.2230e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.053490
Average KL loss: 0.101368
Average total loss: 0.154858
tensor(0.0066, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-5.8649e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.051696
Average KL loss: 0.102147
Average total loss: 0.153842
tensor(0.0066, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-2.1952e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.050977
Average KL loss: 0.101729
Average total loss: 0.152706
tensor(0.0066, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(2.0187e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.052017
Average KL loss: 0.102061
Average total loss: 0.154077
tensor(0.0066, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(4.4960e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.049355
Average KL loss: 0.101999
Average total loss: 0.151353
tensor(0.0065, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(3.5878e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.051132
Average KL loss: 0.101785
Average total loss: 0.152916
tensor(0.0065, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.8269e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.048761
Average KL loss: 0.102167
Average total loss: 0.150929
tensor(0.0065, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.7832e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.050301
Average KL loss: 0.102080
Average total loss: 0.152382
tensor(0.0065, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-4.4477e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.049080
Average KL loss: 0.102181
Average total loss: 0.151261
tensor(0.0065, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.8459e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.045447
Average KL loss: 0.102169
Average total loss: 0.147616
tensor(0.0064, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(2.0940e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.047786
Average KL loss: 0.101574
Average total loss: 0.149360
tensor(0.0064, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-6.0271e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.049042
Average KL loss: 0.102087
Average total loss: 0.151129
tensor(0.0064, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.1931e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.049047
Average KL loss: 0.102602
Average total loss: 0.151649
tensor(0.0064, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.9835e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.046421
Average KL loss: 0.102935
Average total loss: 0.149357
tensor(0.0064, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-6.9186e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.049715
Average KL loss: 0.102626
Average total loss: 0.152341
tensor(0.0064, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.5800e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.046711
Average KL loss: 0.102739
Average total loss: 0.149450
tensor(0.0063, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.2913e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.047280
Average KL loss: 0.102815
Average total loss: 0.150095
tensor(0.0063, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.4218e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.048011
Average KL loss: 0.102849
Average total loss: 0.150860
tensor(0.0063, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.1486e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.048281
Average KL loss: 0.103122
Average total loss: 0.151404
tensor(0.0063, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-5.5250e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.044379
Average KL loss: 0.103471
Average total loss: 0.147850
tensor(0.0063, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(1.1754e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.044655
Average KL loss: 0.102720
Average total loss: 0.147375
tensor(0.0063, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(1.5400e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.046308
Average KL loss: 0.102414
Average total loss: 0.148723
tensor(0.0063, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-7.4642e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.045354
Average KL loss: 0.102521
Average total loss: 0.147874
tensor(0.0063, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.3940e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.045756
Average KL loss: 0.102671
Average total loss: 0.148427
tensor(0.0063, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.6783e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.045568
Average KL loss: 0.103083
Average total loss: 0.148651
tensor(0.0063, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.7110e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.044155
Average KL loss: 0.102428
Average total loss: 0.146583
tensor(0.0062, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(3.0653e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.043257
Average KL loss: 0.101927
Average total loss: 0.145184
tensor(0.0062, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.9906e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.044769
Average KL loss: 0.102090
Average total loss: 0.146860
tensor(0.0062, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.9798e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.045762
Average KL loss: 0.102495
Average total loss: 0.148257
tensor(0.0062, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.3522e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.047460
Average KL loss: 0.103341
Average total loss: 0.150801
tensor(0.0062, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.6970e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.044794
Average KL loss: 0.103980
Average total loss: 0.148774
tensor(0.0062, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.9804e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.045005
Average KL loss: 0.103183
Average total loss: 0.148188
tensor(0.0062, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-6.7072e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.043224
Average KL loss: 0.103209
Average total loss: 0.146433
tensor(0.0062, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(1.5428e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.041743
Average KL loss: 0.102585
Average total loss: 0.144328
tensor(0.0062, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-7.8035e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.042953
Average KL loss: 0.102783
Average total loss: 0.145736
tensor(0.0062, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.7853e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.042933
Average KL loss: 0.102405
Average total loss: 0.145338
tensor(0.0062, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.2624e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.044426
Average KL loss: 0.102944
Average total loss: 0.147369
tensor(0.0062, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.1803e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.040783
Average KL loss: 0.102800
Average total loss: 0.143584
tensor(0.0061, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.7914e-10, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.040944
Average KL loss: 0.101760
Average total loss: 0.142704
tensor(0.0061, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(9.9781e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.041219
Average KL loss: 0.101468
Average total loss: 0.142687
tensor(0.0061, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.8825e-10, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.041543
Average KL loss: 0.101316
Average total loss: 0.142858
tensor(0.0061, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(2.5392e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.042973
Average KL loss: 0.101699
Average total loss: 0.144672
tensor(0.0061, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(1.2251e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.040384
Average KL loss: 0.102358
Average total loss: 0.142742
tensor(0.0061, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.0918e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.042537
Average KL loss: 0.101941
Average total loss: 0.144478
tensor(0.0061, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(3.3804e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.041297
Average KL loss: 0.101835
Average total loss: 0.143132
tensor(0.0061, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-2.5952e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.042186
Average KL loss: 0.102131
Average total loss: 0.144317
tensor(0.0061, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(1.2988e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.043034
Average KL loss: 0.102142
Average total loss: 0.145176
tensor(0.0061, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(1.0452e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.041476
Average KL loss: 0.102650
Average total loss: 0.144127
tensor(0.0061, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.3484e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.042001
Average KL loss: 0.102783
Average total loss: 0.144783
tensor(0.0061, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.3970e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.040991
Average KL loss: 0.102777
Average total loss: 0.143768
tensor(0.0061, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-5.4166e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.043137
Average KL loss: 0.103159
Average total loss: 0.146295
tensor(0.0061, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.4277e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.040439
Average KL loss: 0.102464
Average total loss: 0.142903
tensor(0.0061, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-6.8286e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.040411
Average KL loss: 0.100554
Average total loss: 0.140965
tensor(0.0061, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-7.2965e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.040987
Average KL loss: 0.098922
Average total loss: 0.139909
tensor(0.0061, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.4073e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.039086
Average KL loss: 0.097489
Average total loss: 0.136575
tensor(0.0061, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.4986e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.039586
Average KL loss: 0.096198
Average total loss: 0.135783
tensor(0.0061, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(3.0516e-10, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.038943
Average KL loss: 0.095043
Average total loss: 0.133986
tensor(0.0061, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(2.1591e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.041174
Average KL loss: 0.093987
Average total loss: 0.135161
tensor(0.0061, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(8.3922e-10, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.038334
Average KL loss: 0.093012
Average total loss: 0.131346
tensor(0.0061, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-5.2572e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.040260
Average KL loss: 0.092091
Average total loss: 0.132351
tensor(0.0061, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-5.0892e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.038831
Average KL loss: 0.091238
Average total loss: 0.130069
tensor(0.0061, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.2641e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.038569
Average KL loss: 0.090430
Average total loss: 0.128999
tensor(0.0061, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(2.4566e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.038346
Average KL loss: 0.089664
Average total loss: 0.128010
tensor(0.0061, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(2.0246e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.038743
Average KL loss: 0.088936
Average total loss: 0.127679
tensor(0.0061, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(3.8080e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.040542
Average KL loss: 0.088248
Average total loss: 0.128790
tensor(0.0061, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(5.3294e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.041396
Average KL loss: 0.087623
Average total loss: 0.129019
tensor(0.0061, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(3.1848e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.036774
Average KL loss: 0.087025
Average total loss: 0.123799
tensor(0.0061, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.2512e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.036840
Average KL loss: 0.086428
Average total loss: 0.123269
tensor(0.0061, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-6.5126e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.041670
Average KL loss: 0.085872
Average total loss: 0.127542
tensor(0.0061, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(4.1964e-11, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.039220
Average KL loss: 0.085362
Average total loss: 0.124582
tensor(0.0061, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(1.4877e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.038622
Average KL loss: 0.084861
Average total loss: 0.123483
tensor(0.0061, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(3.8167e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.038447
Average KL loss: 0.084350
Average total loss: 0.122796
tensor(0.0061, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(2.9604e-10, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.037786
Average KL loss: 0.083870
Average total loss: 0.121656
tensor(0.0061, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(1.3288e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.038952
Average KL loss: 0.083411
Average total loss: 0.122363
tensor(0.0061, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-3.3198e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.040319
Average KL loss: 0.082974
Average total loss: 0.123292
tensor(0.0061, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(2.2896e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.039397
Average KL loss: 0.082571
Average total loss: 0.121968
tensor(0.0061, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(7.0187e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.038645
Average KL loss: 0.082163
Average total loss: 0.120809
tensor(0.0061, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.5020e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.037792
Average KL loss: 0.081789
Average total loss: 0.119581
tensor(0.0061, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.9925e-10, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.039429
Average KL loss: 0.081417
Average total loss: 0.120846
tensor(0.0061, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(4.1949e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.039993
Average KL loss: 0.081071
Average total loss: 0.121064
tensor(0.0061, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.0410e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.039919
Average KL loss: 0.080735
Average total loss: 0.120655
tensor(0.0061, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(1.7123e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.038106
Average KL loss: 0.080399
Average total loss: 0.118505
tensor(0.0061, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(1.6914e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.038822
Average KL loss: 0.080076
Average total loss: 0.118898
tensor(0.0061, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-2.6359e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.039003
Average KL loss: 0.079755
Average total loss: 0.118757
tensor(0.0061, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(4.2290e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.037883
Average KL loss: 0.079447
Average total loss: 0.117329
tensor(0.0061, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(4.3603e-10, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.037865
Average KL loss: 0.079138
Average total loss: 0.117003
tensor(0.0061, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(3.0868e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.038089
Average KL loss: 0.078840
Average total loss: 0.116929
tensor(0.0060, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(4.7175e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.037888
Average KL loss: 0.078560
Average total loss: 0.116448
tensor(0.0060, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(3.7325e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.040422
Average KL loss: 0.078294
Average total loss: 0.118716
tensor(0.0060, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.4643e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.039187
Average KL loss: 0.078069
Average total loss: 0.117256
tensor(0.0060, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-7.6859e-10, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.040529
Average KL loss: 0.077817
Average total loss: 0.118347
tensor(0.0060, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-5.5418e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.038785
Average KL loss: 0.077576
Average total loss: 0.116361
tensor(0.0060, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-3.2054e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.037700
Average KL loss: 0.077325
Average total loss: 0.115025
tensor(0.0060, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(3.4814e-10, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.039997
Average KL loss: 0.077078
Average total loss: 0.117075
tensor(0.0060, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(3.1942e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.040880
Average KL loss: 0.076869
Average total loss: 0.117749
tensor(0.0060, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(2.6563e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.038070
Average KL loss: 0.076653
Average total loss: 0.114724
tensor(0.0060, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-4.2891e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.038846
Average KL loss: 0.076427
Average total loss: 0.115272
tensor(0.0060, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-7.4956e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.038494
Average KL loss: 0.076216
Average total loss: 0.114710
tensor(0.0060, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-2.0215e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.039319
Average KL loss: 0.076013
Average total loss: 0.115332
tensor(0.0060, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.5788e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.038209
Average KL loss: 0.075825
Average total loss: 0.114034
tensor(0.0060, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(3.0474e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.038117
Average KL loss: 0.075613
Average total loss: 0.113730
tensor(0.0060, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.0089e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.041304
Average KL loss: 0.075428
Average total loss: 0.116733
tensor(0.0060, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(3.1986e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.037932
Average KL loss: 0.075233
Average total loss: 0.113164
tensor(0.0060, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-3.7176e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.037794
Average KL loss: 0.075037
Average total loss: 0.112831
tensor(0.0060, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(8.5846e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.036271
Average KL loss: 0.074864
Average total loss: 0.111135
tensor(0.0060, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(3.8400e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.037291
Average KL loss: 0.074671
Average total loss: 0.111962
tensor(0.0060, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-6.2347e-11, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.038298
Average KL loss: 0.074507
Average total loss: 0.112805
tensor(0.0060, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(2.9519e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.036602
Average KL loss: 0.074347
Average total loss: 0.110949
tensor(0.0060, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.2345e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.038136
Average KL loss: 0.074195
Average total loss: 0.112331
tensor(0.0060, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(2.7952e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.038334
Average KL loss: 0.074034
Average total loss: 0.112368
tensor(0.0060, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(1.2564e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.036439
Average KL loss: 0.073871
Average total loss: 0.110310
tensor(0.0060, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.1059e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.037624
Average KL loss: 0.073699
Average total loss: 0.111323
tensor(0.0060, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.6145e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.037961
Average KL loss: 0.073551
Average total loss: 0.111512
tensor(0.0060, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(1.5255e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.034601
Average KL loss: 0.073392
Average total loss: 0.107992
tensor(0.0060, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(1.3270e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.036719
Average KL loss: 0.073224
Average total loss: 0.109943
tensor(0.0060, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(3.4761e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.039576
Average KL loss: 0.073087
Average total loss: 0.112663
tensor(0.0060, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-3.6230e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.037937
Average KL loss: 0.072990
Average total loss: 0.110926
tensor(0.0060, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(1.6187e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.039713
Average KL loss: 0.072858
Average total loss: 0.112572
tensor(0.0060, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.4206e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.037708
Average KL loss: 0.072741
Average total loss: 0.110448
tensor(0.0060, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(1.8558e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.039622
Average KL loss: 0.072601
Average total loss: 0.112223
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(1.7528e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.038521
Average KL loss: 0.072482
Average total loss: 0.111003
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-8.7239e-10, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.038625
Average KL loss: 0.072368
Average total loss: 0.110993
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-6.1024e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.038994
Average KL loss: 0.072255
Average total loss: 0.111248
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-3.2612e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.038721
Average KL loss: 0.072129
Average total loss: 0.110850
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(1.0910e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.038459
Average KL loss: 0.072015
Average total loss: 0.110474
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.2898e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.036737
Average KL loss: 0.071945
Average total loss: 0.108682
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.2432e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.039193
Average KL loss: 0.071910
Average total loss: 0.111102
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(3.3985e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.040225
Average KL loss: 0.071875
Average total loss: 0.112100
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(1.1595e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.038303
Average KL loss: 0.071842
Average total loss: 0.110144
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(2.5135e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.038775
Average KL loss: 0.071808
Average total loss: 0.110583
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(2.5080e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.038142
Average KL loss: 0.071776
Average total loss: 0.109918
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-4.2707e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.037225
Average KL loss: 0.071743
Average total loss: 0.108969
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-3.4099e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.037331
Average KL loss: 0.071710
Average total loss: 0.109041
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(3.8564e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.036365
Average KL loss: 0.071679
Average total loss: 0.108044
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(2.2494e-10, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.037527
Average KL loss: 0.071648
Average total loss: 0.109176
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.0487e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.037486
Average KL loss: 0.071619
Average total loss: 0.109106
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(1.4955e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.040322
Average KL loss: 0.071603
Average total loss: 0.111925
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-7.0745e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.036339
Average KL loss: 0.071600
Average total loss: 0.107939
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(2.2072e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.037399
Average KL loss: 0.071597
Average total loss: 0.108996
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(3.7815e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.037503
Average KL loss: 0.071594
Average total loss: 0.109097
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.3971e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.036956
Average KL loss: 0.071590
Average total loss: 0.108546
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.8586e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.039579
Average KL loss: 0.071587
Average total loss: 0.111166
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(1.2475e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.037847
Average KL loss: 0.071584
Average total loss: 0.109431
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(6.9926e-10, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.039890
Average KL loss: 0.071581
Average total loss: 0.111471
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(2.5195e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.038695
Average KL loss: 0.071578
Average total loss: 0.110273
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(2.4258e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.039080
Average KL loss: 0.071575
Average total loss: 0.110655
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.5827e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.039017
Average KL loss: 0.071572
Average total loss: 0.110589
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(2.1424e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.039868
Average KL loss: 0.071569
Average total loss: 0.111437
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(2.4361e-09, device='cuda:0')
 Percentile value: 0.010711495764553547
Non-zero model percentage: 25.000003814697266%, Non-zero mask percentage: 25.000003814697266%

--- Pruning Level [2/12]: ---
conv1.weight         | nonzeros =    1197 /    1728             ( 69.27%) | total_pruned =     531 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   12170 /   36864             ( 33.01%) | total_pruned =   24694 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   12766 /   36864             ( 34.63%) | total_pruned =   24098 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   12348 /   36864             ( 33.50%) | total_pruned =   24516 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      51 /      64             ( 79.69%) | total_pruned =      13 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   12387 /   36864             ( 33.60%) | total_pruned =   24477 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   23521 /   73728             ( 31.90%) | total_pruned =   50207 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   45380 /  147456             ( 30.78%) | total_pruned =  102076 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4091 /    8192             ( 49.94%) | total_pruned =    4101 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   41414 /  147456             ( 28.09%) | total_pruned =  106042 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   41196 /  147456             ( 27.94%) | total_pruned =  106260 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   88597 /  294912             ( 30.04%) | total_pruned =  206315 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  171126 /  589824             ( 29.01%) | total_pruned =  418698 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     237 /     256             ( 92.58%) | total_pruned =      19 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   13395 /   32768             ( 40.88%) | total_pruned =   19373 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  150941 /  589824             ( 25.59%) | total_pruned =  438883 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  147754 /  589824             ( 25.05%) | total_pruned =  442070 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     220 /     256             ( 85.94%) | total_pruned =      36 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  327188 / 1179648             ( 27.74%) | total_pruned =  852460 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     496 /     512             ( 96.88%) | total_pruned =      16 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  610354 / 2359296             ( 25.87%) | total_pruned = 1748942 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     419 /     512             ( 81.84%) | total_pruned =      93 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   38857 /  131072             ( 29.65%) | total_pruned =   92215 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     498 /     512             ( 97.27%) | total_pruned =      14 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     418 /     512             ( 81.64%) | total_pruned =      94 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  520538 / 2359296             ( 22.06%) | total_pruned = 1838758 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     404 /     512             ( 78.91%) | total_pruned =     108 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     284 /     512             ( 55.47%) | total_pruned =     228 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  507530 / 2359296             ( 21.51%) | total_pruned = 1851766 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      70 /     512             ( 13.67%) | total_pruned =     442 | shape = torch.Size([512])
linear.weight        | nonzeros =    3814 /    5120             ( 74.49%) | total_pruned =    1306 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 2794691, pruned : 8384071, total: 11178762, Compression rate :       4.00x  ( 75.00% pruned)
Train Epoch: 30/100 Loss: 0.000023 Accuracy: 87.06 100.00 % Best test Accuracy: 87.20%
tensor(0.0060, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.9179e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.143846
Average KL loss: 0.069615
Average total loss: 0.213461
tensor(0.0092, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-9.0483e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.125288
Average KL loss: 0.077426
Average total loss: 0.202714
tensor(0.0091, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-8.0104e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.108743
Average KL loss: 0.083566
Average total loss: 0.192309
tensor(0.0091, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-2.6062e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.106402
Average KL loss: 0.087991
Average total loss: 0.194393
tensor(0.0090, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-7.6934e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.098906
Average KL loss: 0.091735
Average total loss: 0.190641
tensor(0.0090, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-4.4761e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.100760
Average KL loss: 0.094346
Average total loss: 0.195106
tensor(0.0090, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-5.7339e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.092885
Average KL loss: 0.097040
Average total loss: 0.189925
tensor(0.0089, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-7.9414e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.090294
Average KL loss: 0.099018
Average total loss: 0.189311
tensor(0.0089, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-4.1455e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.086730
Average KL loss: 0.100691
Average total loss: 0.187421
tensor(0.0088, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-6.5147e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.081056
Average KL loss: 0.102167
Average total loss: 0.183223
tensor(0.0088, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(4.8242e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.081173
Average KL loss: 0.103059
Average total loss: 0.184232
tensor(0.0087, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(2.2895e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.079442
Average KL loss: 0.104332
Average total loss: 0.183774
tensor(0.0087, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(3.3599e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.079911
Average KL loss: 0.105174
Average total loss: 0.185086
tensor(0.0087, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-9.7016e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.078312
Average KL loss: 0.106111
Average total loss: 0.184423
tensor(0.0087, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(3.3195e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.077103
Average KL loss: 0.107022
Average total loss: 0.184125
tensor(0.0086, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-2.3005e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.076552
Average KL loss: 0.108044
Average total loss: 0.184595
tensor(0.0086, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(4.6365e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.071274
Average KL loss: 0.108567
Average total loss: 0.179841
tensor(0.0086, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-2.1243e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.077294
Average KL loss: 0.109205
Average total loss: 0.186499
tensor(0.0085, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.5973e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.069015
Average KL loss: 0.109529
Average total loss: 0.178544
tensor(0.0085, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(1.5539e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.072978
Average KL loss: 0.109863
Average total loss: 0.182840
tensor(0.0085, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(2.4491e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.071607
Average KL loss: 0.110617
Average total loss: 0.182224
tensor(0.0085, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.2594e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.066509
Average KL loss: 0.110927
Average total loss: 0.177436
tensor(0.0084, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(2.6018e-11, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.066735
Average KL loss: 0.110785
Average total loss: 0.177520
tensor(0.0084, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-5.9301e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.066682
Average KL loss: 0.110828
Average total loss: 0.177510
tensor(0.0084, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(9.7630e-11, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.066340
Average KL loss: 0.110938
Average total loss: 0.177278
tensor(0.0084, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.7486e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.064331
Average KL loss: 0.111063
Average total loss: 0.175394
tensor(0.0083, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.4892e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.061331
Average KL loss: 0.111235
Average total loss: 0.172566
tensor(0.0083, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.9175e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.065683
Average KL loss: 0.111134
Average total loss: 0.176817
tensor(0.0083, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.3035e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.063616
Average KL loss: 0.111516
Average total loss: 0.175132
tensor(0.0083, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(1.6105e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.064127
Average KL loss: 0.112136
Average total loss: 0.176263
tensor(0.0083, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(5.3656e-10, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.064613
Average KL loss: 0.112453
Average total loss: 0.177066
tensor(0.0082, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-6.4995e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.065176
Average KL loss: 0.112750
Average total loss: 0.177926
tensor(0.0082, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(1.5595e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.059631
Average KL loss: 0.113141
Average total loss: 0.172773
tensor(0.0082, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(7.4576e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.063270
Average KL loss: 0.112870
Average total loss: 0.176140
tensor(0.0082, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.4594e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.061138
Average KL loss: 0.113572
Average total loss: 0.174710
tensor(0.0082, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.2800e-10, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.061086
Average KL loss: 0.113565
Average total loss: 0.174651
tensor(0.0081, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.1131e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.062047
Average KL loss: 0.113554
Average total loss: 0.175601
tensor(0.0081, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(2.7149e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.057913
Average KL loss: 0.113820
Average total loss: 0.171733
tensor(0.0081, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-7.8709e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.060113
Average KL loss: 0.113590
Average total loss: 0.173703
tensor(0.0081, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(2.5950e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.060617
Average KL loss: 0.113956
Average total loss: 0.174573
tensor(0.0081, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-5.8021e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.059209
Average KL loss: 0.114073
Average total loss: 0.173282
tensor(0.0081, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-4.1754e-11, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.061045
Average KL loss: 0.114359
Average total loss: 0.175404
tensor(0.0081, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-3.5745e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.056000
Average KL loss: 0.114292
Average total loss: 0.170292
tensor(0.0080, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-5.8555e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.062720
Average KL loss: 0.114387
Average total loss: 0.177107
tensor(0.0080, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(3.6210e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.058026
Average KL loss: 0.114677
Average total loss: 0.172703
tensor(0.0080, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.8237e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.059844
Average KL loss: 0.114913
Average total loss: 0.174757
tensor(0.0080, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.9416e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.062212
Average KL loss: 0.115163
Average total loss: 0.177375
tensor(0.0080, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-5.7823e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.057232
Average KL loss: 0.115363
Average total loss: 0.172596
tensor(0.0080, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-6.4399e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.058882
Average KL loss: 0.115311
Average total loss: 0.174193
tensor(0.0080, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(1.3245e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.057472
Average KL loss: 0.115407
Average total loss: 0.172878
tensor(0.0080, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.9814e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.056016
Average KL loss: 0.115363
Average total loss: 0.171379
tensor(0.0080, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(2.8624e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.057819
Average KL loss: 0.115415
Average total loss: 0.173233
tensor(0.0080, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-3.7213e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.056210
Average KL loss: 0.115465
Average total loss: 0.171674
tensor(0.0080, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-1.0446e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.057412
Average KL loss: 0.115679
Average total loss: 0.173091
tensor(0.0080, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-3.6006e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.056075
Average KL loss: 0.115345
Average total loss: 0.171419
tensor(0.0080, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(9.1619e-10, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.057241
Average KL loss: 0.114287
Average total loss: 0.171528
tensor(0.0080, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(2.1264e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.055044
Average KL loss: 0.113307
Average total loss: 0.168351
tensor(0.0080, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(2.8384e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.057632
Average KL loss: 0.112403
Average total loss: 0.170035
tensor(0.0080, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(1.2243e-10, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.055385
Average KL loss: 0.111577
Average total loss: 0.166963
tensor(0.0079, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(2.6126e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.055050
Average KL loss: 0.110805
Average total loss: 0.165855
tensor(0.0079, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-3.7504e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.055160
Average KL loss: 0.110066
Average total loss: 0.165226
tensor(0.0079, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(4.4984e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.054439
Average KL loss: 0.109372
Average total loss: 0.163811
tensor(0.0079, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(5.1166e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.054770
Average KL loss: 0.108709
Average total loss: 0.163479
tensor(0.0079, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(1.8196e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.056892
Average KL loss: 0.108088
Average total loss: 0.164980
tensor(0.0079, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(4.0335e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.051714
Average KL loss: 0.107488
Average total loss: 0.159203
tensor(0.0079, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(1.5773e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.053774
Average KL loss: 0.106911
Average total loss: 0.160685
tensor(0.0079, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.9531e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.054700
Average KL loss: 0.106363
Average total loss: 0.161063
tensor(0.0079, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.3920e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.055096
Average KL loss: 0.105838
Average total loss: 0.160934
tensor(0.0079, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.4932e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.056687
Average KL loss: 0.105324
Average total loss: 0.162011
tensor(0.0079, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(2.6813e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.052236
Average KL loss: 0.104849
Average total loss: 0.157085
tensor(0.0079, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-4.7733e-10, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.053312
Average KL loss: 0.104364
Average total loss: 0.157677
tensor(0.0079, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-3.2274e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.055710
Average KL loss: 0.103897
Average total loss: 0.159607
tensor(0.0079, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(2.0885e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.049827
Average KL loss: 0.103437
Average total loss: 0.153264
tensor(0.0079, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(1.5337e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.055956
Average KL loss: 0.103001
Average total loss: 0.158957
tensor(0.0079, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(2.2308e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.054160
Average KL loss: 0.102582
Average total loss: 0.156742
tensor(0.0079, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(1.7357e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.054406
Average KL loss: 0.102166
Average total loss: 0.156572
tensor(0.0079, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(2.5719e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.056696
Average KL loss: 0.101778
Average total loss: 0.158475
tensor(0.0079, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(5.9568e-10, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.053735
Average KL loss: 0.101409
Average total loss: 0.155144
tensor(0.0079, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(4.0559e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.054262
Average KL loss: 0.101033
Average total loss: 0.155295
tensor(0.0079, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(2.2904e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.051717
Average KL loss: 0.100661
Average total loss: 0.152379
tensor(0.0079, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(3.6743e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.054741
Average KL loss: 0.100302
Average total loss: 0.155043
tensor(0.0079, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(4.3253e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.052989
Average KL loss: 0.099973
Average total loss: 0.152962
tensor(0.0079, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-7.8148e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.054517
Average KL loss: 0.099626
Average total loss: 0.154143
tensor(0.0079, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.3999e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.054103
Average KL loss: 0.099297
Average total loss: 0.153400
tensor(0.0079, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.1180e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.052776
Average KL loss: 0.098974
Average total loss: 0.151749
tensor(0.0079, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(2.5283e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.055105
Average KL loss: 0.098671
Average total loss: 0.153775
tensor(0.0079, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(3.3838e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.051719
Average KL loss: 0.098379
Average total loss: 0.150097
tensor(0.0079, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-7.3023e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.055547
Average KL loss: 0.098074
Average total loss: 0.153621
tensor(0.0079, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.2078e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.055985
Average KL loss: 0.097804
Average total loss: 0.153789
tensor(0.0079, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-8.2378e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.051046
Average KL loss: 0.097523
Average total loss: 0.148569
tensor(0.0079, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(2.4552e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.052213
Average KL loss: 0.097229
Average total loss: 0.149442
tensor(0.0079, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(4.0820e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.052684
Average KL loss: 0.096963
Average total loss: 0.149647
tensor(0.0079, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.4368e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.053267
Average KL loss: 0.096701
Average total loss: 0.149969
tensor(0.0079, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-5.4983e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.053454
Average KL loss: 0.096449
Average total loss: 0.149903
tensor(0.0079, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.3273e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.052780
Average KL loss: 0.096195
Average total loss: 0.148976
tensor(0.0079, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(1.5190e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.055665
Average KL loss: 0.095944
Average total loss: 0.151609
tensor(0.0079, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-4.0600e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.053787
Average KL loss: 0.095715
Average total loss: 0.149502
tensor(0.0079, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(3.5419e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.052149
Average KL loss: 0.095477
Average total loss: 0.147627
tensor(0.0079, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(5.0528e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.052798
Average KL loss: 0.095231
Average total loss: 0.148029
tensor(0.0079, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.7562e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.055168
Average KL loss: 0.095014
Average total loss: 0.150182
tensor(0.0079, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-6.6547e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.054808
Average KL loss: 0.094813
Average total loss: 0.149620
tensor(0.0079, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(4.7291e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.051972
Average KL loss: 0.094592
Average total loss: 0.146564
tensor(0.0079, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(5.5111e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.052147
Average KL loss: 0.094368
Average total loss: 0.146515
tensor(0.0079, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-7.4050e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.052131
Average KL loss: 0.094164
Average total loss: 0.146295
tensor(0.0079, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.2557e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.055492
Average KL loss: 0.093962
Average total loss: 0.149454
tensor(0.0079, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(1.2138e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.052269
Average KL loss: 0.093769
Average total loss: 0.146038
tensor(0.0079, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-9.5760e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.054700
Average KL loss: 0.093586
Average total loss: 0.148286
tensor(0.0079, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-4.3896e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.051780
Average KL loss: 0.093405
Average total loss: 0.145184
tensor(0.0078, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.9313e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.049192
Average KL loss: 0.093210
Average total loss: 0.142402
tensor(0.0078, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-8.6509e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.052916
Average KL loss: 0.093001
Average total loss: 0.145917
tensor(0.0078, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(2.6125e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.052865
Average KL loss: 0.092822
Average total loss: 0.145687
tensor(0.0078, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-9.6416e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.053440
Average KL loss: 0.092648
Average total loss: 0.146088
tensor(0.0078, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.9762e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.054302
Average KL loss: 0.092487
Average total loss: 0.146789
tensor(0.0078, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(6.0144e-11, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.051579
Average KL loss: 0.092330
Average total loss: 0.143909
tensor(0.0078, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(4.3279e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.052390
Average KL loss: 0.092151
Average total loss: 0.144541
tensor(0.0078, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-6.2063e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.054541
Average KL loss: 0.091978
Average total loss: 0.146520
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-3.6390e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.051224
Average KL loss: 0.091822
Average total loss: 0.143046
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(3.2389e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.052550
Average KL loss: 0.091655
Average total loss: 0.144205
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(2.6728e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.050901
Average KL loss: 0.091502
Average total loss: 0.142404
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(8.5693e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.052242
Average KL loss: 0.091341
Average total loss: 0.143584
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(2.7554e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.049656
Average KL loss: 0.091250
Average total loss: 0.140906
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(4.3493e-10, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.052857
Average KL loss: 0.091221
Average total loss: 0.144078
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.2628e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.054489
Average KL loss: 0.091193
Average total loss: 0.145681
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-7.2063e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.053325
Average KL loss: 0.091166
Average total loss: 0.144491
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.6324e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.052436
Average KL loss: 0.091139
Average total loss: 0.143575
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.0227e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.053560
Average KL loss: 0.091112
Average total loss: 0.144673
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.7290e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.055358
Average KL loss: 0.091086
Average total loss: 0.146444
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(1.6321e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.053621
Average KL loss: 0.091060
Average total loss: 0.144681
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.3368e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.053893
Average KL loss: 0.091033
Average total loss: 0.144927
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-4.1746e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.053893
Average KL loss: 0.091008
Average total loss: 0.144901
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(2.8937e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.053503
Average KL loss: 0.090982
Average total loss: 0.144485
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(3.8513e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.053009
Average KL loss: 0.090957
Average total loss: 0.143967
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(2.9554e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.052464
Average KL loss: 0.090943
Average total loss: 0.143407
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-9.5799e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.051943
Average KL loss: 0.090940
Average total loss: 0.142883
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(5.6862e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.050230
Average KL loss: 0.090937
Average total loss: 0.141167
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.6338e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.054179
Average KL loss: 0.090935
Average total loss: 0.145114
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-3.4155e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.052850
Average KL loss: 0.090932
Average total loss: 0.143782
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(6.0155e-10, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.055601
Average KL loss: 0.090929
Average total loss: 0.146530
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(1.4839e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.052621
Average KL loss: 0.090927
Average total loss: 0.143547
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(1.5518e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.052818
Average KL loss: 0.090924
Average total loss: 0.143742
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-4.7064e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.056601
Average KL loss: 0.090921
Average total loss: 0.147522
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.0065e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.052896
Average KL loss: 0.090919
Average total loss: 0.143815
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(6.5146e-10, device='cuda:0')
 Percentile value: 0.027312133461236954
Non-zero model percentage: 12.500005722045898%, Non-zero mask percentage: 12.500005722045898%

--- Pruning Level [3/12]: ---
conv1.weight         | nonzeros =    1114 /    1728             ( 64.47%) | total_pruned =     614 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    7900 /   36864             ( 21.43%) | total_pruned =   28964 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    8489 /   36864             ( 23.03%) | total_pruned =   28375 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    8003 /   36864             ( 21.71%) | total_pruned =   28861 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    8076 /   36864             ( 21.91%) | total_pruned =   28788 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   14922 /   73728             ( 20.24%) | total_pruned =   58806 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   27891 /  147456             ( 18.91%) | total_pruned =  119565 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      83 /     128             ( 64.84%) | total_pruned =      45 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3326 /    8192             ( 40.60%) | total_pruned =    4866 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   23682 /  147456             ( 16.06%) | total_pruned =  123774 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      94 /     128             ( 73.44%) | total_pruned =      34 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   23772 /  147456             ( 16.12%) | total_pruned =  123684 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   53457 /  294912             ( 18.13%) | total_pruned =  241455 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   99692 /  589824             ( 16.90%) | total_pruned =  490132 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    9880 /   32768             ( 30.15%) | total_pruned =   22888 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   77751 /  589824             ( 13.18%) | total_pruned =  512073 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     214 /     256             ( 83.59%) | total_pruned =      42 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   76353 /  589824             ( 12.95%) | total_pruned =  513471 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     204 /     256             ( 79.69%) | total_pruned =      52 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  182043 / 1179648             ( 15.43%) | total_pruned =  997605 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     494 /     512             ( 96.48%) | total_pruned =      18 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  311465 / 2359296             ( 13.20%) | total_pruned = 2047831 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     402 /     512             ( 78.52%) | total_pruned =     110 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   23041 /  131072             ( 17.58%) | total_pruned =  108031 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     497 /     512             ( 97.07%) | total_pruned =      15 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     402 /     512             ( 78.52%) | total_pruned =     110 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  224778 / 2359296             (  9.53%) | total_pruned = 2134518 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     228 /     512             ( 44.53%) | total_pruned =     284 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  200471 / 2359296             (  8.50%) | total_pruned = 2158825 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      63 /     512             ( 12.30%) | total_pruned =     449 | shape = torch.Size([512])
linear.weight        | nonzeros =    3348 /    5120             ( 65.39%) | total_pruned =    1772 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 1397346, pruned : 9781416, total: 11178762, Compression rate :       8.00x  ( 87.50% pruned)
Train Epoch: 27/100 Loss: 0.000134 Accuracy: 86.79 100.00 % Best test Accuracy: 87.61%
tensor(0.0078, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-3.5945e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.175644
Average KL loss: 0.085054
Average total loss: 0.260698
tensor(0.0108, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-9.4098e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.148722
Average KL loss: 0.089160
Average total loss: 0.237882
tensor(0.0107, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-5.0663e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.136981
Average KL loss: 0.093724
Average total loss: 0.230705
tensor(0.0107, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-5.4897e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.133007
Average KL loss: 0.097495
Average total loss: 0.230502
tensor(0.0107, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-5.7621e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.130319
Average KL loss: 0.100851
Average total loss: 0.231170
tensor(0.0106, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-9.7456e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.124764
Average KL loss: 0.103838
Average total loss: 0.228602
tensor(0.0106, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.2705e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.126074
Average KL loss: 0.106440
Average total loss: 0.232514
tensor(0.0106, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(9.3696e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.114175
Average KL loss: 0.108934
Average total loss: 0.223108
tensor(0.0106, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-6.2858e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.112793
Average KL loss: 0.110393
Average total loss: 0.223186
tensor(0.0105, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.6708e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.110594
Average KL loss: 0.111889
Average total loss: 0.222482
tensor(0.0105, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-7.7163e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.106270
Average KL loss: 0.113451
Average total loss: 0.219721
tensor(0.0105, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.1229e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.101968
Average KL loss: 0.114626
Average total loss: 0.216593
tensor(0.0105, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-3.9033e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.104096
Average KL loss: 0.115665
Average total loss: 0.219761
tensor(0.0104, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.4756e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.102612
Average KL loss: 0.117044
Average total loss: 0.219656
tensor(0.0104, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(3.7476e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.097997
Average KL loss: 0.118115
Average total loss: 0.216111
tensor(0.0104, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-2.5332e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.094083
Average KL loss: 0.118909
Average total loss: 0.212993
tensor(0.0104, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-1.4923e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.095705
Average KL loss: 0.119477
Average total loss: 0.215182
tensor(0.0104, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(2.7235e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.094106
Average KL loss: 0.120398
Average total loss: 0.214504
tensor(0.0103, device='cuda:0') tensor(0.0152, device='cuda:0') tensor(-6.9255e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.095418
Average KL loss: 0.120937
Average total loss: 0.216355
tensor(0.0103, device='cuda:0') tensor(0.0153, device='cuda:0') tensor(-4.9097e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.093836
Average KL loss: 0.121563
Average total loss: 0.215399
tensor(0.0103, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(5.4691e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.089819
Average KL loss: 0.122086
Average total loss: 0.211905
tensor(0.0103, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(1.0828e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.087952
Average KL loss: 0.122511
Average total loss: 0.210463
tensor(0.0102, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-3.6505e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.088721
Average KL loss: 0.123087
Average total loss: 0.211807
tensor(0.0102, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-3.6566e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.090940
Average KL loss: 0.123595
Average total loss: 0.214535
tensor(0.0102, device='cuda:0') tensor(0.0157, device='cuda:0') tensor(-3.8841e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.090203
Average KL loss: 0.124296
Average total loss: 0.214499
tensor(0.0102, device='cuda:0') tensor(0.0158, device='cuda:0') tensor(-2.1557e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.088649
Average KL loss: 0.125008
Average total loss: 0.213658
tensor(0.0102, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-2.9156e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.084535
Average KL loss: 0.125402
Average total loss: 0.209937
tensor(0.0102, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(3.7287e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.081122
Average KL loss: 0.125657
Average total loss: 0.206778
tensor(0.0101, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(4.4837e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.084344
Average KL loss: 0.125650
Average total loss: 0.209994
tensor(0.0101, device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-5.3590e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.082133
Average KL loss: 0.125911
Average total loss: 0.208044
tensor(0.0101, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-2.9704e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.082798
Average KL loss: 0.126183
Average total loss: 0.208981
tensor(0.0101, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-2.5729e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.079103
Average KL loss: 0.126488
Average total loss: 0.205591
tensor(0.0101, device='cuda:0') tensor(0.0162, device='cuda:0') tensor(-5.4381e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.083067
Average KL loss: 0.126916
Average total loss: 0.209983
tensor(0.0100, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-2.5016e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.079955
Average KL loss: 0.127322
Average total loss: 0.207277
tensor(0.0100, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(2.9385e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.081733
Average KL loss: 0.127425
Average total loss: 0.209158
tensor(0.0100, device='cuda:0') tensor(0.0164, device='cuda:0') tensor(2.1496e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.077478
Average KL loss: 0.127768
Average total loss: 0.205247
tensor(0.0100, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(2.0767e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.081314
Average KL loss: 0.128015
Average total loss: 0.209329
tensor(0.0099, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-6.3137e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.083889
Average KL loss: 0.128588
Average total loss: 0.212477
tensor(0.0099, device='cuda:0') tensor(0.0166, device='cuda:0') tensor(1.8126e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.081054
Average KL loss: 0.128856
Average total loss: 0.209910
tensor(0.0099, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(1.4698e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.076247
Average KL loss: 0.129117
Average total loss: 0.205364
tensor(0.0099, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-1.5470e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.075596
Average KL loss: 0.129122
Average total loss: 0.204718
tensor(0.0099, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(1.7765e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.074195
Average KL loss: 0.128928
Average total loss: 0.203123
tensor(0.0099, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-5.0113e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.081221
Average KL loss: 0.128997
Average total loss: 0.210218
tensor(0.0099, device='cuda:0') tensor(0.0168, device='cuda:0') tensor(-2.1022e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.077261
Average KL loss: 0.129596
Average total loss: 0.206857
tensor(0.0098, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-6.5352e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.076914
Average KL loss: 0.129618
Average total loss: 0.206532
tensor(0.0098, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(5.4210e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.076946
Average KL loss: 0.129717
Average total loss: 0.206663
tensor(0.0098, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.3788e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.079261
Average KL loss: 0.129934
Average total loss: 0.209195
tensor(0.0098, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-6.6022e-10, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.076700
Average KL loss: 0.130196
Average total loss: 0.206895
tensor(0.0098, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-3.2339e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.074546
Average KL loss: 0.130382
Average total loss: 0.204928
tensor(0.0098, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-4.1192e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.073796
Average KL loss: 0.130479
Average total loss: 0.204276
tensor(0.0098, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-8.5008e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.075509
Average KL loss: 0.130453
Average total loss: 0.205962
tensor(0.0098, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(2.9209e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.074217
Average KL loss: 0.130558
Average total loss: 0.204775
tensor(0.0098, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-1.2270e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.071279
Average KL loss: 0.130835
Average total loss: 0.202114
tensor(0.0097, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(6.6728e-10, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.077700
Average KL loss: 0.130757
Average total loss: 0.208457
tensor(0.0097, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-6.1510e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.071925
Average KL loss: 0.131075
Average total loss: 0.203000
tensor(0.0097, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(1.8197e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.070639
Average KL loss: 0.130869
Average total loss: 0.201508
tensor(0.0097, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-7.6670e-10, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.074414
Average KL loss: 0.130817
Average total loss: 0.205230
tensor(0.0097, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(7.8437e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.073287
Average KL loss: 0.131159
Average total loss: 0.204447
tensor(0.0097, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-1.4565e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.071703
Average KL loss: 0.131375
Average total loss: 0.203078
tensor(0.0097, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-2.0990e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.072787
Average KL loss: 0.131313
Average total loss: 0.204101
tensor(0.0097, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(2.0833e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.071741
Average KL loss: 0.131636
Average total loss: 0.203376
tensor(0.0097, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-1.7190e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.072411
Average KL loss: 0.131689
Average total loss: 0.204100
tensor(0.0097, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(4.3867e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.071011
Average KL loss: 0.131895
Average total loss: 0.202906
tensor(0.0097, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-2.8118e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.068983
Average KL loss: 0.131834
Average total loss: 0.200816
tensor(0.0097, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-4.0302e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.070758
Average KL loss: 0.131663
Average total loss: 0.202421
tensor(0.0096, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(4.2140e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.069302
Average KL loss: 0.131594
Average total loss: 0.200896
tensor(0.0096, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-8.5337e-10, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.070319
Average KL loss: 0.131598
Average total loss: 0.201917
tensor(0.0096, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(1.8444e-11, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.073377
Average KL loss: 0.131862
Average total loss: 0.205240
tensor(0.0097, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(1.9793e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.073894
Average KL loss: 0.132309
Average total loss: 0.206203
tensor(0.0097, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-3.6404e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.070774
Average KL loss: 0.132392
Average total loss: 0.203166
tensor(0.0097, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-4.3129e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.070009
Average KL loss: 0.132439
Average total loss: 0.202448
tensor(0.0096, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(2.0980e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.071982
Average KL loss: 0.132547
Average total loss: 0.204529
tensor(0.0096, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(1.4163e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.069363
Average KL loss: 0.132802
Average total loss: 0.202165
tensor(0.0096, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-2.4741e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.069498
Average KL loss: 0.132849
Average total loss: 0.202347
tensor(0.0096, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(3.6671e-10, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.070482
Average KL loss: 0.132795
Average total loss: 0.203276
tensor(0.0096, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.8676e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.068307
Average KL loss: 0.132728
Average total loss: 0.201035
tensor(0.0096, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-3.6268e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.068456
Average KL loss: 0.132135
Average total loss: 0.200591
tensor(0.0096, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-2.1080e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.066883
Average KL loss: 0.131552
Average total loss: 0.198434
tensor(0.0096, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-5.6659e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.066701
Average KL loss: 0.130992
Average total loss: 0.197693
tensor(0.0096, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-2.2435e-10, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.070398
Average KL loss: 0.130467
Average total loss: 0.200865
tensor(0.0096, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(6.5934e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.067828
Average KL loss: 0.129988
Average total loss: 0.197816
tensor(0.0096, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-2.4651e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.068963
Average KL loss: 0.129510
Average total loss: 0.198473
tensor(0.0096, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-1.2215e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.068392
Average KL loss: 0.129048
Average total loss: 0.197440
tensor(0.0096, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(1.6597e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.068068
Average KL loss: 0.128603
Average total loss: 0.196672
tensor(0.0096, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-9.1472e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.065818
Average KL loss: 0.128165
Average total loss: 0.193983
tensor(0.0096, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(4.6637e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.069033
Average KL loss: 0.127733
Average total loss: 0.196766
tensor(0.0096, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-8.6961e-11, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.066270
Average KL loss: 0.127325
Average total loss: 0.193595
tensor(0.0096, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(5.9569e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.067778
Average KL loss: 0.126931
Average total loss: 0.194709
tensor(0.0096, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-5.7972e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.068772
Average KL loss: 0.126549
Average total loss: 0.195321
tensor(0.0096, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-1.0360e-10, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.065942
Average KL loss: 0.126174
Average total loss: 0.192115
tensor(0.0096, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-2.3475e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.068466
Average KL loss: 0.125806
Average total loss: 0.194272
tensor(0.0096, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-2.2477e-10, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.066758
Average KL loss: 0.125456
Average total loss: 0.192214
tensor(0.0096, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(1.8656e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.068046
Average KL loss: 0.125111
Average total loss: 0.193157
tensor(0.0096, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(5.4548e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.069514
Average KL loss: 0.124768
Average total loss: 0.194282
tensor(0.0096, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-2.7718e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.067429
Average KL loss: 0.124435
Average total loss: 0.191864
tensor(0.0096, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-2.5784e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.067015
Average KL loss: 0.124119
Average total loss: 0.191133
tensor(0.0096, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(3.4738e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.067590
Average KL loss: 0.123804
Average total loss: 0.191394
tensor(0.0096, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(1.7317e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.067519
Average KL loss: 0.123514
Average total loss: 0.191032
tensor(0.0096, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(4.4864e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.064347
Average KL loss: 0.123215
Average total loss: 0.187563
tensor(0.0096, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(2.2416e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.063922
Average KL loss: 0.122904
Average total loss: 0.186826
tensor(0.0096, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-3.7799e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.066157
Average KL loss: 0.122617
Average total loss: 0.188774
tensor(0.0096, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(3.0058e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.064041
Average KL loss: 0.122329
Average total loss: 0.186370
tensor(0.0096, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(5.2804e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.069783
Average KL loss: 0.122042
Average total loss: 0.191825
tensor(0.0096, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-4.0265e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.067581
Average KL loss: 0.121792
Average total loss: 0.189373
tensor(0.0096, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(1.8238e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.065869
Average KL loss: 0.121531
Average total loss: 0.187399
tensor(0.0096, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(2.1594e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.067275
Average KL loss: 0.121263
Average total loss: 0.188538
tensor(0.0096, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-3.6586e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.066730
Average KL loss: 0.121016
Average total loss: 0.187746
tensor(0.0096, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-1.6780e-10, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.065382
Average KL loss: 0.120756
Average total loss: 0.186137
tensor(0.0096, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(1.4807e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.064252
Average KL loss: 0.120499
Average total loss: 0.184751
tensor(0.0096, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-2.8609e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.070295
Average KL loss: 0.120248
Average total loss: 0.190543
tensor(0.0096, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(1.0391e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.065895
Average KL loss: 0.120012
Average total loss: 0.185907
tensor(0.0096, device='cuda:0') tensor(0.0174, device='cuda:0') tensor(-7.5807e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.068410
Average KL loss: 0.119781
Average total loss: 0.188191
tensor(0.0096, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-4.0442e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.066636
Average KL loss: 0.119556
Average total loss: 0.186192
tensor(0.0096, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(3.4551e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.065183
Average KL loss: 0.119322
Average total loss: 0.184505
tensor(0.0096, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(2.1433e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.068485
Average KL loss: 0.119102
Average total loss: 0.187587
tensor(0.0096, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(7.8451e-11, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.065531
Average KL loss: 0.118886
Average total loss: 0.184417
tensor(0.0096, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-2.2958e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.068187
Average KL loss: 0.118673
Average total loss: 0.186860
tensor(0.0096, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-3.4843e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.066924
Average KL loss: 0.118467
Average total loss: 0.185391
tensor(0.0096, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(-4.0492e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.066968
Average KL loss: 0.118257
Average total loss: 0.185224
tensor(0.0096, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(3.1594e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.066276
Average KL loss: 0.118039
Average total loss: 0.184315
tensor(0.0096, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(3.2950e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.065434
Average KL loss: 0.117840
Average total loss: 0.183274
tensor(0.0096, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-4.5559e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.068308
Average KL loss: 0.117646
Average total loss: 0.185953
tensor(0.0096, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-3.9682e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.069468
Average KL loss: 0.117460
Average total loss: 0.186928
tensor(0.0096, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-1.0302e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.067778
Average KL loss: 0.117283
Average total loss: 0.185062
tensor(0.0096, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-3.2352e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.063591
Average KL loss: 0.117092
Average total loss: 0.180683
tensor(0.0096, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-5.0089e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.067337
Average KL loss: 0.116912
Average total loss: 0.184248
tensor(0.0096, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-5.0736e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.065658
Average KL loss: 0.116732
Average total loss: 0.182390
tensor(0.0096, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-1.2543e-11, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.067011
Average KL loss: 0.116558
Average total loss: 0.183569
tensor(0.0096, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(3.3120e-10, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.065290
Average KL loss: 0.116393
Average total loss: 0.181682
tensor(0.0096, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-1.2813e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.070757
Average KL loss: 0.116227
Average total loss: 0.186985
tensor(0.0096, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-1.1873e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.065572
Average KL loss: 0.116064
Average total loss: 0.181636
tensor(0.0096, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(1.5989e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.064892
Average KL loss: 0.115880
Average total loss: 0.180772
tensor(0.0096, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(1.1867e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.064284
Average KL loss: 0.115707
Average total loss: 0.179991
tensor(0.0096, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-1.3354e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.062424
Average KL loss: 0.115550
Average total loss: 0.177975
tensor(0.0096, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-9.0819e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.067906
Average KL loss: 0.115391
Average total loss: 0.183298
tensor(0.0096, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(2.8141e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.063341
Average KL loss: 0.115233
Average total loss: 0.178575
tensor(0.0096, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(-2.8992e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.067298
Average KL loss: 0.115074
Average total loss: 0.182373
tensor(0.0096, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(2.2986e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.066748
Average KL loss: 0.114922
Average total loss: 0.181670
tensor(0.0095, device='cuda:0') tensor(0.0171, device='cuda:0') tensor(5.1788e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.066468
Average KL loss: 0.114777
Average total loss: 0.181245
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(3.4582e-10, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.065770
Average KL loss: 0.114630
Average total loss: 0.180400
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-7.6564e-10, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.071516
Average KL loss: 0.114491
Average total loss: 0.186007
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.8617e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.066544
Average KL loss: 0.114348
Average total loss: 0.180892
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.6715e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.065330
Average KL loss: 0.114203
Average total loss: 0.179533
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-5.8968e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.066369
Average KL loss: 0.114059
Average total loss: 0.180428
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(3.7507e-10, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.066495
Average KL loss: 0.113920
Average total loss: 0.180415
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(1.0432e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.064632
Average KL loss: 0.113843
Average total loss: 0.178475
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(4.2197e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.065206
Average KL loss: 0.113823
Average total loss: 0.179029
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.3749e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.065509
Average KL loss: 0.113802
Average total loss: 0.179311
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(4.1530e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.067179
Average KL loss: 0.113781
Average total loss: 0.180960
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-9.1255e-10, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.064575
Average KL loss: 0.113761
Average total loss: 0.178336
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.8523e-10, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.063858
Average KL loss: 0.113740
Average total loss: 0.177598
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(4.3057e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.064721
Average KL loss: 0.113718
Average total loss: 0.178439
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(1.4913e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.067879
Average KL loss: 0.113697
Average total loss: 0.181575
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.6317e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.067270
Average KL loss: 0.113676
Average total loss: 0.180946
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(3.0576e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.066222
Average KL loss: 0.113656
Average total loss: 0.179878
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-6.4432e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.066113
Average KL loss: 0.113636
Average total loss: 0.179749
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(6.4028e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.068920
Average KL loss: 0.113615
Average total loss: 0.182535
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(1.0062e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.066227
Average KL loss: 0.113594
Average total loss: 0.179821
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-6.2925e-10, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.063113
Average KL loss: 0.113574
Average total loss: 0.176687
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.3248e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.063842
Average KL loss: 0.113555
Average total loss: 0.177396
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(3.5919e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.063807
Average KL loss: 0.113535
Average total loss: 0.177342
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.9930e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.065676
Average KL loss: 0.113515
Average total loss: 0.179191
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(1.1331e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.065787
Average KL loss: 0.113495
Average total loss: 0.179283
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(3.1985e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.066037
Average KL loss: 0.113476
Average total loss: 0.179514
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(7.1262e-10, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.065409
Average KL loss: 0.113456
Average total loss: 0.178864
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(2.6604e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.065315
Average KL loss: 0.113436
Average total loss: 0.178751
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-6.2977e-10, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.067287
Average KL loss: 0.113416
Average total loss: 0.180704
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.5981e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.065013
Average KL loss: 0.113397
Average total loss: 0.178410
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(7.6037e-10, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.067327
Average KL loss: 0.113377
Average total loss: 0.180704
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(5.2441e-10, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.070969
Average KL loss: 0.113358
Average total loss: 0.184327
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.6612e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.065042
Average KL loss: 0.113348
Average total loss: 0.178390
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-8.0825e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.066367
Average KL loss: 0.113346
Average total loss: 0.179714
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-1.6453e-10, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.066305
Average KL loss: 0.113344
Average total loss: 0.179650
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.8133e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.067339
Average KL loss: 0.113342
Average total loss: 0.180682
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.4396e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.066332
Average KL loss: 0.113340
Average total loss: 0.179672
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(1.8890e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.065437
Average KL loss: 0.113338
Average total loss: 0.178775
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-3.4189e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.067905
Average KL loss: 0.113336
Average total loss: 0.181241
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(3.6755e-10, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.068550
Average KL loss: 0.113334
Average total loss: 0.181885
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(8.2907e-10, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.066854
Average KL loss: 0.113332
Average total loss: 0.180186
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(2.2075e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.068037
Average KL loss: 0.113330
Average total loss: 0.181368
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(5.1509e-10, device='cuda:0')
 Percentile value: 0.07571613788604736
Non-zero model percentage: 6.250002861022949%, Non-zero mask percentage: 6.250002861022949%

--- Pruning Level [4/12]: ---
conv1.weight         | nonzeros =    1050 /    1728             ( 60.76%) | total_pruned =     678 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    5370 /   36864             ( 14.57%) | total_pruned =   31494 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    5898 /   36864             ( 16.00%) | total_pruned =   30966 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    5473 /   36864             ( 14.85%) | total_pruned =   31391 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    5604 /   36864             ( 15.20%) | total_pruned =   31260 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   10118 /   73728             ( 13.72%) | total_pruned =   63610 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      58 /     128             ( 45.31%) | total_pruned =      70 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   17857 /  147456             ( 12.11%) | total_pruned =  129599 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2779 /    8192             ( 33.92%) | total_pruned =    5413 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   14027 /  147456             (  9.51%) | total_pruned =  133429 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   14132 /  147456             (  9.58%) | total_pruned =  133324 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   33855 /  294912             ( 11.48%) | total_pruned =  261057 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   59494 /  589824             ( 10.09%) | total_pruned =  530330 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    7671 /   32768             ( 23.41%) | total_pruned =   25097 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     203 /     256             ( 79.30%) | total_pruned =      53 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   41287 /  589824             (  7.00%) | total_pruned =  548537 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   40333 /  589824             (  6.84%) | total_pruned =  549491 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     182 /     256             ( 71.09%) | total_pruned =      74 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  102141 / 1179648             (  8.66%) | total_pruned = 1077507 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     490 /     512             ( 95.70%) | total_pruned =      22 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  146374 / 2359296             (  6.20%) | total_pruned = 2212922 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     390 /     512             ( 76.17%) | total_pruned =     122 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   14264 /  131072             ( 10.88%) | total_pruned =  116808 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     495 /     512             ( 96.68%) | total_pruned =      17 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     388 /     512             ( 75.78%) | total_pruned =     124 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   93985 / 2359296             (  3.98%) | total_pruned = 2265311 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     201 /     512             ( 39.26%) | total_pruned =     311 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   66350 / 2359296             (  2.81%) | total_pruned = 2292946 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      58 /     512             ( 11.33%) | total_pruned =     454 | shape = torch.Size([512])
linear.weight        | nonzeros =    2932 /    5120             ( 57.27%) | total_pruned =    2188 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 698673, pruned : 10480089, total: 11178762, Compression rate :      16.00x  ( 93.75% pruned)
Train Epoch: 23/100 Loss: 0.000326 Accuracy: 86.84 100.00 % Best test Accuracy: 87.45%
tensor(0.0095, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-2.9972e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.200008
Average KL loss: 0.105683
Average total loss: 0.305691
tensor(0.0118, device='cuda:0') tensor(0.0154, device='cuda:0') tensor(-1.3048e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.187488
Average KL loss: 0.107209
Average total loss: 0.294697
tensor(0.0118, device='cuda:0') tensor(0.0155, device='cuda:0') tensor(-6.9187e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.169213
Average KL loss: 0.110544
Average total loss: 0.279757
tensor(0.0118, device='cuda:0') tensor(0.0156, device='cuda:0') tensor(-2.0117e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.167130
Average KL loss: 0.113596
Average total loss: 0.280726
tensor(0.0119, device='cuda:0') tensor(0.0159, device='cuda:0') tensor(-5.3259e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.154936
Average KL loss: 0.116438
Average total loss: 0.271374
tensor(0.0119, device='cuda:0') tensor(0.0161, device='cuda:0') tensor(-9.5506e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.145547
Average KL loss: 0.118961
Average total loss: 0.264508
tensor(0.0119, device='cuda:0') tensor(0.0163, device='cuda:0') tensor(-6.3239e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.140208
Average KL loss: 0.121006
Average total loss: 0.261214
tensor(0.0119, device='cuda:0') tensor(0.0165, device='cuda:0') tensor(-1.2963e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.134827
Average KL loss: 0.122832
Average total loss: 0.257659
tensor(0.0119, device='cuda:0') tensor(0.0167, device='cuda:0') tensor(-3.6028e-09, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.134884
Average KL loss: 0.124451
Average total loss: 0.259336
tensor(0.0119, device='cuda:0') tensor(0.0169, device='cuda:0') tensor(-5.2343e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.129463
Average KL loss: 0.126101
Average total loss: 0.255564
tensor(0.0119, device='cuda:0') tensor(0.0170, device='cuda:0') tensor(-5.2536e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.131819
Average KL loss: 0.127493
Average total loss: 0.259312
tensor(0.0119, device='cuda:0') tensor(0.0172, device='cuda:0') tensor(-1.2822e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.125513
Average KL loss: 0.128967
Average total loss: 0.254480
tensor(0.0119, device='cuda:0') tensor(0.0173, device='cuda:0') tensor(1.2446e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.124042
Average KL loss: 0.130162
Average total loss: 0.254204
tensor(0.0119, device='cuda:0') tensor(0.0175, device='cuda:0') tensor(-2.8898e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.125768
Average KL loss: 0.131336
Average total loss: 0.257104
tensor(0.0119, device='cuda:0') tensor(0.0176, device='cuda:0') tensor(-4.6953e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.118541
Average KL loss: 0.132619
Average total loss: 0.251160
tensor(0.0119, device='cuda:0') tensor(0.0178, device='cuda:0') tensor(-4.5834e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.117741
Average KL loss: 0.133445
Average total loss: 0.251186
tensor(0.0119, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-1.6790e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.119766
Average KL loss: 0.134309
Average total loss: 0.254075
tensor(0.0119, device='cuda:0') tensor(0.0180, device='cuda:0') tensor(-7.3781e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.115215
Average KL loss: 0.135373
Average total loss: 0.250587
tensor(0.0119, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-5.5812e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.115655
Average KL loss: 0.136222
Average total loss: 0.251877
tensor(0.0119, device='cuda:0') tensor(0.0182, device='cuda:0') tensor(-8.4811e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.109924
Average KL loss: 0.136925
Average total loss: 0.246849
tensor(0.0118, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-3.7106e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.111771
Average KL loss: 0.137471
Average total loss: 0.249241
tensor(0.0118, device='cuda:0') tensor(0.0184, device='cuda:0') tensor(-7.3813e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.109987
Average KL loss: 0.138111
Average total loss: 0.248098
tensor(0.0118, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-7.9715e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.107027
Average KL loss: 0.138669
Average total loss: 0.245696
tensor(0.0118, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(5.7230e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.107062
Average KL loss: 0.139149
Average total loss: 0.246211
tensor(0.0118, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(2.8350e-10, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.102993
Average KL loss: 0.139596
Average total loss: 0.242588
tensor(0.0118, device='cuda:0') tensor(0.0187, device='cuda:0') tensor(-2.0423e-11, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.106013
Average KL loss: 0.140134
Average total loss: 0.246147
tensor(0.0118, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-2.5410e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.103599
Average KL loss: 0.140631
Average total loss: 0.244231
tensor(0.0117, device='cuda:0') tensor(0.0189, device='cuda:0') tensor(-2.8414e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.102406
Average KL loss: 0.140970
Average total loss: 0.243375
tensor(0.0117, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(1.3476e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.101926
Average KL loss: 0.141420
Average total loss: 0.243346
tensor(0.0117, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-4.4600e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.100001
Average KL loss: 0.141898
Average total loss: 0.241899
tensor(0.0117, device='cuda:0') tensor(0.0191, device='cuda:0') tensor(-1.4067e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.095743
Average KL loss: 0.142083
Average total loss: 0.237826
tensor(0.0117, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-1.3737e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.101328
Average KL loss: 0.142456
Average total loss: 0.243784
tensor(0.0117, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(1.7365e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.102590
Average KL loss: 0.142905
Average total loss: 0.245495
tensor(0.0117, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(2.2262e-11, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.098618
Average KL loss: 0.143367
Average total loss: 0.241985
tensor(0.0117, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(2.9754e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.096863
Average KL loss: 0.143697
Average total loss: 0.240561
tensor(0.0116, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(2.5715e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.101864
Average KL loss: 0.143980
Average total loss: 0.245844
tensor(0.0116, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-2.2471e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.093998
Average KL loss: 0.144397
Average total loss: 0.238395
tensor(0.0116, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-3.8076e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.095171
Average KL loss: 0.144684
Average total loss: 0.239855
tensor(0.0116, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(1.3455e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.093118
Average KL loss: 0.144892
Average total loss: 0.238010
tensor(0.0116, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-1.8631e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.093531
Average KL loss: 0.144941
Average total loss: 0.238471
tensor(0.0116, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-8.1701e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.096339
Average KL loss: 0.145156
Average total loss: 0.241495
tensor(0.0116, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-2.1442e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.096801
Average KL loss: 0.145428
Average total loss: 0.242229
tensor(0.0116, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(3.3763e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.091534
Average KL loss: 0.145461
Average total loss: 0.236994
tensor(0.0116, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(1.4472e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.095792
Average KL loss: 0.145210
Average total loss: 0.241002
tensor(0.0116, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-1.2391e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.092579
Average KL loss: 0.144962
Average total loss: 0.237541
tensor(0.0116, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-1.8995e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.090578
Average KL loss: 0.144716
Average total loss: 0.235293
tensor(0.0116, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(1.0938e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.090177
Average KL loss: 0.144471
Average total loss: 0.234648
tensor(0.0116, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(2.0438e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.093301
Average KL loss: 0.144235
Average total loss: 0.237536
tensor(0.0116, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-3.7145e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.096078
Average KL loss: 0.144003
Average total loss: 0.240081
tensor(0.0116, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-8.0019e-10, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.091454
Average KL loss: 0.143782
Average total loss: 0.235236
tensor(0.0116, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(4.6154e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.091974
Average KL loss: 0.143555
Average total loss: 0.235528
tensor(0.0116, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-3.0360e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.092161
Average KL loss: 0.143333
Average total loss: 0.235495
tensor(0.0116, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(2.3063e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.089114
Average KL loss: 0.143108
Average total loss: 0.232221
tensor(0.0116, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-2.2912e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.092349
Average KL loss: 0.142891
Average total loss: 0.235240
tensor(0.0116, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(7.6652e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.092783
Average KL loss: 0.142686
Average total loss: 0.235469
tensor(0.0115, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(1.6639e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.092274
Average KL loss: 0.142481
Average total loss: 0.234755
tensor(0.0115, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-6.5569e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.092209
Average KL loss: 0.142281
Average total loss: 0.234490
tensor(0.0115, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(3.8570e-10, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.088399
Average KL loss: 0.142078
Average total loss: 0.230478
tensor(0.0115, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(5.2110e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.091867
Average KL loss: 0.141889
Average total loss: 0.233756
tensor(0.0115, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-2.1435e-10, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.090354
Average KL loss: 0.141698
Average total loss: 0.232052
tensor(0.0115, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-3.7358e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.094459
Average KL loss: 0.141512
Average total loss: 0.235972
tensor(0.0115, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(1.0398e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.093083
Average KL loss: 0.141330
Average total loss: 0.234413
tensor(0.0115, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(2.5858e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.089159
Average KL loss: 0.141151
Average total loss: 0.230310
tensor(0.0115, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-2.6936e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.089371
Average KL loss: 0.140968
Average total loss: 0.230339
tensor(0.0115, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(3.3878e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.088759
Average KL loss: 0.140793
Average total loss: 0.229551
tensor(0.0115, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-4.1669e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.092665
Average KL loss: 0.140630
Average total loss: 0.233296
tensor(0.0115, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(1.1397e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.094123
Average KL loss: 0.140467
Average total loss: 0.234590
tensor(0.0115, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-2.6546e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.092301
Average KL loss: 0.140305
Average total loss: 0.232606
tensor(0.0115, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-1.3995e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.087015
Average KL loss: 0.140128
Average total loss: 0.227143
tensor(0.0115, device='cuda:0') tensor(0.0196, device='cuda:0') tensor(-6.1015e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.090756
Average KL loss: 0.139959
Average total loss: 0.230715
tensor(0.0115, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-3.9157e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.092137
Average KL loss: 0.139787
Average total loss: 0.231924
tensor(0.0115, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(1.7020e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.092387
Average KL loss: 0.139627
Average total loss: 0.232015
tensor(0.0115, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-3.3624e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.087962
Average KL loss: 0.139481
Average total loss: 0.227442
tensor(0.0115, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(2.7878e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.089030
Average KL loss: 0.139318
Average total loss: 0.228348
tensor(0.0115, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(1.9580e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.096576
Average KL loss: 0.139162
Average total loss: 0.235738
tensor(0.0115, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(2.7119e-10, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.085376
Average KL loss: 0.139017
Average total loss: 0.224393
tensor(0.0115, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(2.0970e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.090121
Average KL loss: 0.138858
Average total loss: 0.228980
tensor(0.0115, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-1.0537e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.091788
Average KL loss: 0.138712
Average total loss: 0.230500
tensor(0.0115, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-4.3752e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.087537
Average KL loss: 0.138561
Average total loss: 0.226098
tensor(0.0115, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-3.0181e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.092396
Average KL loss: 0.138411
Average total loss: 0.230807
tensor(0.0115, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-5.5767e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.094420
Average KL loss: 0.138266
Average total loss: 0.232686
tensor(0.0115, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(3.0470e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.091008
Average KL loss: 0.138130
Average total loss: 0.229139
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(9.7239e-10, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.089152
Average KL loss: 0.138005
Average total loss: 0.227157
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.1011e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.090367
Average KL loss: 0.137871
Average total loss: 0.228238
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(3.3308e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.088816
Average KL loss: 0.137732
Average total loss: 0.226548
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.6957e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.086987
Average KL loss: 0.137591
Average total loss: 0.224578
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(2.0344e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.089812
Average KL loss: 0.137452
Average total loss: 0.227264
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-5.2241e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.087784
Average KL loss: 0.137376
Average total loss: 0.225159
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(2.7675e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.090457
Average KL loss: 0.137359
Average total loss: 0.227816
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-2.3020e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.086393
Average KL loss: 0.137342
Average total loss: 0.223736
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-2.1424e-10, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.089209
Average KL loss: 0.137324
Average total loss: 0.226533
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.1093e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.087287
Average KL loss: 0.137306
Average total loss: 0.224593
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-3.0465e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.088453
Average KL loss: 0.137290
Average total loss: 0.225743
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(7.1138e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.087548
Average KL loss: 0.137272
Average total loss: 0.224820
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(3.6428e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.086315
Average KL loss: 0.137255
Average total loss: 0.223570
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-7.2067e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.089992
Average KL loss: 0.137238
Average total loss: 0.227230
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-3.1265e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.087670
Average KL loss: 0.137223
Average total loss: 0.224892
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-3.9932e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.087024
Average KL loss: 0.137207
Average total loss: 0.224231
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-2.3425e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.089302
Average KL loss: 0.137190
Average total loss: 0.226492
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-5.6062e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.089878
Average KL loss: 0.137175
Average total loss: 0.227053
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(5.3525e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.092196
Average KL loss: 0.137158
Average total loss: 0.229355
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-5.2976e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.089242
Average KL loss: 0.137142
Average total loss: 0.226383
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-5.0613e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.090065
Average KL loss: 0.137125
Average total loss: 0.227190
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(6.1761e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.086522
Average KL loss: 0.137107
Average total loss: 0.223629
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-5.5743e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.090426
Average KL loss: 0.137091
Average total loss: 0.227517
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.5708e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.088429
Average KL loss: 0.137075
Average total loss: 0.225504
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.5739e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.089231
Average KL loss: 0.137065
Average total loss: 0.226296
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-4.3494e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.088742
Average KL loss: 0.137064
Average total loss: 0.225806
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.0625e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.088535
Average KL loss: 0.137062
Average total loss: 0.225598
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(2.5864e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.091133
Average KL loss: 0.137061
Average total loss: 0.228194
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(3.8610e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.085497
Average KL loss: 0.137059
Average total loss: 0.222556
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(4.5129e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.090634
Average KL loss: 0.137057
Average total loss: 0.227691
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-7.4297e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.087393
Average KL loss: 0.137056
Average total loss: 0.224449
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(1.5857e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.088733
Average KL loss: 0.137054
Average total loss: 0.225787
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-2.1322e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.089271
Average KL loss: 0.137052
Average total loss: 0.226324
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.6883e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.092055
Average KL loss: 0.137051
Average total loss: 0.229106
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-6.1413e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.085681
Average KL loss: 0.137049
Average total loss: 0.222730
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-3.7439e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.090730
Average KL loss: 0.137048
Average total loss: 0.227778
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-5.4038e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.087497
Average KL loss: 0.137046
Average total loss: 0.224543
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-2.7983e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.091813
Average KL loss: 0.137044
Average total loss: 0.228857
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(1.6870e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.089298
Average KL loss: 0.137043
Average total loss: 0.226341
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.6010e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.084921
Average KL loss: 0.137041
Average total loss: 0.221962
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.9615e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.086240
Average KL loss: 0.137039
Average total loss: 0.223279
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-8.7478e-10, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.086590
Average KL loss: 0.137037
Average total loss: 0.223628
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-4.9809e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.089634
Average KL loss: 0.137036
Average total loss: 0.226669
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-3.7685e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.090373
Average KL loss: 0.137034
Average total loss: 0.227407
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.3117e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.087958
Average KL loss: 0.137032
Average total loss: 0.224991
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-2.1190e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.092205
Average KL loss: 0.137031
Average total loss: 0.229236
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(1.3481e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.092370
Average KL loss: 0.137029
Average total loss: 0.229399
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(2.8535e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.088313
Average KL loss: 0.137028
Average total loss: 0.225341
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-5.6616e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.087464
Average KL loss: 0.137026
Average total loss: 0.224490
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-4.1622e-10, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.086959
Average KL loss: 0.137024
Average total loss: 0.223984
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-1.4925e-09, device='cuda:0')
 Percentile value: 0.23937371373176575
Non-zero model percentage: 3.1250059604644775%, Non-zero mask percentage: 3.1250059604644775%

--- Pruning Level [5/12]: ---
conv1.weight         | nonzeros =    1006 /    1728             ( 58.22%) | total_pruned =     722 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    3777 /   36864             ( 10.25%) | total_pruned =   33087 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    4355 /   36864             ( 11.81%) | total_pruned =   32509 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    3926 /   36864             ( 10.65%) | total_pruned =   32938 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4025 /   36864             ( 10.92%) | total_pruned =   32839 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    7105 /   73728             (  9.64%) | total_pruned =   66623 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      51 /     128             ( 39.84%) | total_pruned =      77 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   11913 /  147456             (  8.08%) | total_pruned =  135543 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2422 /    8192             ( 29.57%) | total_pruned =    5770 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8432 /  147456             (  5.72%) | total_pruned =  139024 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    8491 /  147456             (  5.76%) | total_pruned =  138965 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      39 /     128             ( 30.47%) | total_pruned =      89 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   21848 /  294912             (  7.41%) | total_pruned =  273064 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   35608 /  589824             (  6.04%) | total_pruned =  554216 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6233 /   32768             ( 19.02%) | total_pruned =   26535 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     185 /     256             ( 72.27%) | total_pruned =      71 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   20721 /  589824             (  3.51%) | total_pruned =  569103 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     183 /     256             ( 71.48%) | total_pruned =      73 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   20069 /  589824             (  3.40%) | total_pruned =  569755 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     158 /     256             ( 61.72%) | total_pruned =      98 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   56491 / 1179648             (  4.79%) | total_pruned = 1123157 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     483 /     512             ( 94.34%) | total_pruned =      29 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   61479 / 2359296             (  2.61%) | total_pruned = 2297817 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    9082 /  131072             (  6.93%) | total_pruned =  121990 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     375 /     512             ( 73.24%) | total_pruned =     137 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   34492 / 2359296             (  1.46%) | total_pruned = 2324804 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     403 /     512             ( 78.71%) | total_pruned =     109 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     173 /     512             ( 33.79%) | total_pruned =     339 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   17755 / 2359296             (  0.75%) | total_pruned = 2341541 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     507 /     512             ( 99.02%) | total_pruned =       5 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
linear.weight        | nonzeros =    2628 /    5120             ( 51.33%) | total_pruned =    2492 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 349337, pruned : 10829425, total: 11178762, Compression rate :      32.00x  ( 96.87% pruned)
Train Epoch: 21/100 Loss: 0.000117 Accuracy: 86.49 100.00 % Best test Accuracy: 87.54%
tensor(0.0115, device='cuda:0') tensor(0.0194, device='cuda:0') tensor(-2.9010e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.248415
Average KL loss: 0.128944
Average total loss: 0.377359
tensor(0.0128, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-1.4737e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.232601
Average KL loss: 0.128959
Average total loss: 0.361561
tensor(0.0128, device='cuda:0') tensor(0.0177, device='cuda:0') tensor(-1.7294e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.207799
Average KL loss: 0.131182
Average total loss: 0.338981
tensor(0.0129, device='cuda:0') tensor(0.0179, device='cuda:0') tensor(-3.8262e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.202464
Average KL loss: 0.133256
Average total loss: 0.335719
tensor(0.0129, device='cuda:0') tensor(0.0181, device='cuda:0') tensor(-1.2650e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.200028
Average KL loss: 0.135273
Average total loss: 0.335301
tensor(0.0129, device='cuda:0') tensor(0.0183, device='cuda:0') tensor(-1.3231e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.196290
Average KL loss: 0.137254
Average total loss: 0.333543
tensor(0.0130, device='cuda:0') tensor(0.0185, device='cuda:0') tensor(-1.1268e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.187436
Average KL loss: 0.138959
Average total loss: 0.326395
tensor(0.0130, device='cuda:0') tensor(0.0186, device='cuda:0') tensor(-1.0404e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.180077
Average KL loss: 0.140632
Average total loss: 0.320709
tensor(0.0130, device='cuda:0') tensor(0.0188, device='cuda:0') tensor(-1.0962e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.175016
Average KL loss: 0.142223
Average total loss: 0.317239
tensor(0.0130, device='cuda:0') tensor(0.0190, device='cuda:0') tensor(-5.8690e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.172158
Average KL loss: 0.143607
Average total loss: 0.315764
tensor(0.0131, device='cuda:0') tensor(0.0192, device='cuda:0') tensor(-1.0580e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.168260
Average KL loss: 0.144969
Average total loss: 0.313229
tensor(0.0131, device='cuda:0') tensor(0.0193, device='cuda:0') tensor(4.4932e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.164437
Average KL loss: 0.146110
Average total loss: 0.310547
tensor(0.0131, device='cuda:0') tensor(0.0195, device='cuda:0') tensor(-4.3011e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.165253
Average KL loss: 0.147375
Average total loss: 0.312628
tensor(0.0131, device='cuda:0') tensor(0.0197, device='cuda:0') tensor(-5.5846e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.158810
Average KL loss: 0.148605
Average total loss: 0.307414
tensor(0.0131, device='cuda:0') tensor(0.0198, device='cuda:0') tensor(-6.7780e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.162268
Average KL loss: 0.149568
Average total loss: 0.311836
tensor(0.0131, device='cuda:0') tensor(0.0199, device='cuda:0') tensor(-9.1774e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.155586
Average KL loss: 0.150593
Average total loss: 0.306178
tensor(0.0131, device='cuda:0') tensor(0.0201, device='cuda:0') tensor(-7.6208e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.158978
Average KL loss: 0.151689
Average total loss: 0.310667
tensor(0.0131, device='cuda:0') tensor(0.0202, device='cuda:0') tensor(-6.2154e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.149402
Average KL loss: 0.152571
Average total loss: 0.301973
tensor(0.0131, device='cuda:0') tensor(0.0203, device='cuda:0') tensor(1.5155e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.149935
Average KL loss: 0.153397
Average total loss: 0.303332
tensor(0.0131, device='cuda:0') tensor(0.0205, device='cuda:0') tensor(-5.9666e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.144953
Average KL loss: 0.154249
Average total loss: 0.299203
tensor(0.0131, device='cuda:0') tensor(0.0206, device='cuda:0') tensor(6.4734e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.147230
Average KL loss: 0.154947
Average total loss: 0.302178
tensor(0.0131, device='cuda:0') tensor(0.0207, device='cuda:0') tensor(-1.0237e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.148252
Average KL loss: 0.155652
Average total loss: 0.303905
tensor(0.0131, device='cuda:0') tensor(0.0208, device='cuda:0') tensor(-7.6070e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.143597
Average KL loss: 0.156481
Average total loss: 0.300078
tensor(0.0131, device='cuda:0') tensor(0.0209, device='cuda:0') tensor(3.3035e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.143099
Average KL loss: 0.157247
Average total loss: 0.300346
tensor(0.0131, device='cuda:0') tensor(0.0210, device='cuda:0') tensor(-9.4607e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.148010
Average KL loss: 0.157970
Average total loss: 0.305980
tensor(0.0131, device='cuda:0') tensor(0.0211, device='cuda:0') tensor(-4.3803e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.137422
Average KL loss: 0.158657
Average total loss: 0.296079
tensor(0.0131, device='cuda:0') tensor(0.0212, device='cuda:0') tensor(-2.1746e-10, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.135245
Average KL loss: 0.159203
Average total loss: 0.294447
tensor(0.0131, device='cuda:0') tensor(0.0213, device='cuda:0') tensor(-9.5536e-11, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.140207
Average KL loss: 0.159697
Average total loss: 0.299904
tensor(0.0131, device='cuda:0') tensor(0.0214, device='cuda:0') tensor(-3.0935e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.135849
Average KL loss: 0.160244
Average total loss: 0.296093
tensor(0.0131, device='cuda:0') tensor(0.0215, device='cuda:0') tensor(-8.2351e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.131039
Average KL loss: 0.160788
Average total loss: 0.291827
tensor(0.0131, device='cuda:0') tensor(0.0216, device='cuda:0') tensor(3.6650e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.129665
Average KL loss: 0.161330
Average total loss: 0.290995
tensor(0.0131, device='cuda:0') tensor(0.0217, device='cuda:0') tensor(1.6379e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.135265
Average KL loss: 0.161819
Average total loss: 0.297084
tensor(0.0131, device='cuda:0') tensor(0.0218, device='cuda:0') tensor(-9.9596e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.136783
Average KL loss: 0.162383
Average total loss: 0.299165
tensor(0.0131, device='cuda:0') tensor(0.0219, device='cuda:0') tensor(-7.6311e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.132389
Average KL loss: 0.162839
Average total loss: 0.295227
tensor(0.0131, device='cuda:0') tensor(0.0220, device='cuda:0') tensor(4.7287e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.129618
Average KL loss: 0.163236
Average total loss: 0.292854
tensor(0.0131, device='cuda:0') tensor(0.0221, device='cuda:0') tensor(4.1742e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.126733
Average KL loss: 0.163692
Average total loss: 0.290425
tensor(0.0131, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-4.0282e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.128089
Average KL loss: 0.163982
Average total loss: 0.292070
tensor(0.0131, device='cuda:0') tensor(0.0222, device='cuda:0') tensor(-9.3914e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.125694
Average KL loss: 0.164359
Average total loss: 0.290053
tensor(0.0131, device='cuda:0') tensor(0.0223, device='cuda:0') tensor(-2.2141e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.120989
Average KL loss: 0.164616
Average total loss: 0.285605
tensor(0.0131, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(-3.7879e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.120827
Average KL loss: 0.164823
Average total loss: 0.285650
tensor(0.0130, device='cuda:0') tensor(0.0224, device='cuda:0') tensor(6.4237e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.129576
Average KL loss: 0.164997
Average total loss: 0.294573
tensor(0.0130, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-4.3740e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.121606
Average KL loss: 0.165423
Average total loss: 0.287029
tensor(0.0130, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-2.2779e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.123200
Average KL loss: 0.165830
Average total loss: 0.289029
tensor(0.0130, device='cuda:0') tensor(0.0227, device='cuda:0') tensor(-1.1089e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.124593
Average KL loss: 0.166158
Average total loss: 0.290751
tensor(0.0130, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-8.1808e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.118499
Average KL loss: 0.166480
Average total loss: 0.284979
tensor(0.0130, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-2.8726e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.119972
Average KL loss: 0.166747
Average total loss: 0.286718
tensor(0.0130, device='cuda:0') tensor(0.0229, device='cuda:0') tensor(-6.9199e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.121497
Average KL loss: 0.167033
Average total loss: 0.288530
tensor(0.0130, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(1.0839e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.120920
Average KL loss: 0.167336
Average total loss: 0.288257
tensor(0.0130, device='cuda:0') tensor(0.0231, device='cuda:0') tensor(6.3974e-10, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.118268
Average KL loss: 0.167697
Average total loss: 0.285965
tensor(0.0130, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-2.5414e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.118268
Average KL loss: 0.167961
Average total loss: 0.286230
tensor(0.0130, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-2.1784e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.117524
Average KL loss: 0.168253
Average total loss: 0.285777
tensor(0.0130, device='cuda:0') tensor(0.0233, device='cuda:0') tensor(-1.2994e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.118892
Average KL loss: 0.168591
Average total loss: 0.287483
tensor(0.0130, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.7542e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.117476
Average KL loss: 0.168862
Average total loss: 0.286338
tensor(0.0130, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-3.4339e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.118654
Average KL loss: 0.169176
Average total loss: 0.287830
tensor(0.0130, device='cuda:0') tensor(0.0235, device='cuda:0') tensor(-2.8240e-10, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.117675
Average KL loss: 0.169487
Average total loss: 0.287162
tensor(0.0130, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-5.9774e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.113822
Average KL loss: 0.169646
Average total loss: 0.283468
tensor(0.0130, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.6003e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.114747
Average KL loss: 0.169848
Average total loss: 0.284595
tensor(0.0130, device='cuda:0') tensor(0.0237, device='cuda:0') tensor(-5.0141e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.112059
Average KL loss: 0.170137
Average total loss: 0.282195
tensor(0.0130, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-8.9322e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.114395
Average KL loss: 0.170236
Average total loss: 0.284631
tensor(0.0130, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-2.1571e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.112995
Average KL loss: 0.170398
Average total loss: 0.283393
tensor(0.0130, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(-8.9373e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.113763
Average KL loss: 0.170638
Average total loss: 0.284401
tensor(0.0130, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-2.8034e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.113359
Average KL loss: 0.170902
Average total loss: 0.284261
tensor(0.0129, device='cuda:0') tensor(0.0240, device='cuda:0') tensor(-1.4080e-10, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.107259
Average KL loss: 0.170972
Average total loss: 0.278231
tensor(0.0129, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-4.5927e-11, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.110429
Average KL loss: 0.170982
Average total loss: 0.281411
tensor(0.0129, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-7.8539e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.110002
Average KL loss: 0.171160
Average total loss: 0.281162
tensor(0.0129, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(3.7479e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.107819
Average KL loss: 0.171292
Average total loss: 0.279111
tensor(0.0129, device='cuda:0') tensor(0.0242, device='cuda:0') tensor(-1.5401e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.108126
Average KL loss: 0.171449
Average total loss: 0.279576
tensor(0.0129, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(2.4929e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.110749
Average KL loss: 0.171640
Average total loss: 0.282389
tensor(0.0129, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-7.0681e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.106680
Average KL loss: 0.171830
Average total loss: 0.278509
tensor(0.0129, device='cuda:0') tensor(0.0244, device='cuda:0') tensor(-1.4979e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.109441
Average KL loss: 0.171936
Average total loss: 0.281377
tensor(0.0129, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-1.0201e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.107834
Average KL loss: 0.172150
Average total loss: 0.279984
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-5.9266e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.109485
Average KL loss: 0.172167
Average total loss: 0.281652
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(3.1998e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.108497
Average KL loss: 0.172348
Average total loss: 0.280845
tensor(0.0129, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(6.2425e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.107289
Average KL loss: 0.172484
Average total loss: 0.279773
tensor(0.0129, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-2.7055e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.108172
Average KL loss: 0.172502
Average total loss: 0.280674
tensor(0.0129, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(2.8530e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.109752
Average KL loss: 0.172385
Average total loss: 0.282137
tensor(0.0129, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-4.0203e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.108739
Average KL loss: 0.172265
Average total loss: 0.281004
tensor(0.0129, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(2.7329e-11, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.108642
Average KL loss: 0.172152
Average total loss: 0.280793
tensor(0.0129, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(2.9252e-10, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.105029
Average KL loss: 0.172042
Average total loss: 0.277071
tensor(0.0129, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-3.6839e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.110689
Average KL loss: 0.171929
Average total loss: 0.282619
tensor(0.0129, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(4.3374e-10, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.104483
Average KL loss: 0.171818
Average total loss: 0.276301
tensor(0.0129, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-2.2962e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.105479
Average KL loss: 0.171692
Average total loss: 0.277171
tensor(0.0129, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(2.0916e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.106075
Average KL loss: 0.171571
Average total loss: 0.277646
tensor(0.0129, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-1.9172e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.106618
Average KL loss: 0.171463
Average total loss: 0.278081
tensor(0.0129, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(3.5618e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.108398
Average KL loss: 0.171349
Average total loss: 0.279747
tensor(0.0129, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(2.0915e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.101409
Average KL loss: 0.171241
Average total loss: 0.272649
tensor(0.0129, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(-4.3722e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.109160
Average KL loss: 0.171131
Average total loss: 0.280291
tensor(0.0129, device='cuda:0') tensor(0.0247, device='cuda:0') tensor(5.3260e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.104492
Average KL loss: 0.171028
Average total loss: 0.275520
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-1.5102e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.108539
Average KL loss: 0.170925
Average total loss: 0.279464
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-3.9540e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.101426
Average KL loss: 0.170823
Average total loss: 0.272249
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(2.9637e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.102273
Average KL loss: 0.170706
Average total loss: 0.272979
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-1.8695e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.101948
Average KL loss: 0.170590
Average total loss: 0.272538
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-5.3461e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.105665
Average KL loss: 0.170478
Average total loss: 0.276143
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-3.3879e-10, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.104623
Average KL loss: 0.170375
Average total loss: 0.274998
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-8.5954e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.106744
Average KL loss: 0.170270
Average total loss: 0.277014
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-6.0556e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.108369
Average KL loss: 0.170166
Average total loss: 0.278535
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-6.6187e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.106573
Average KL loss: 0.170069
Average total loss: 0.276642
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-5.4746e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.108422
Average KL loss: 0.169977
Average total loss: 0.278399
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(1.2664e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.101226
Average KL loss: 0.169883
Average total loss: 0.271109
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(1.3065e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.102484
Average KL loss: 0.169788
Average total loss: 0.272272
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(9.6362e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.103040
Average KL loss: 0.169690
Average total loss: 0.272730
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-6.0943e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.105129
Average KL loss: 0.169579
Average total loss: 0.274708
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(4.5796e-10, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.103537
Average KL loss: 0.169477
Average total loss: 0.273014
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-2.6518e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.103990
Average KL loss: 0.169372
Average total loss: 0.273362
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(2.2718e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.104170
Average KL loss: 0.169266
Average total loss: 0.273436
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-1.7529e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.107499
Average KL loss: 0.169170
Average total loss: 0.276669
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-1.1251e-10, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.107254
Average KL loss: 0.169081
Average total loss: 0.276335
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(4.0256e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.102806
Average KL loss: 0.168997
Average total loss: 0.271803
tensor(0.0129, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-5.2319e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.106659
Average KL loss: 0.168902
Average total loss: 0.275562
tensor(0.0128, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(2.2059e-10, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.103215
Average KL loss: 0.168814
Average total loss: 0.272030
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-3.4023e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.105651
Average KL loss: 0.168759
Average total loss: 0.274410
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(2.2601e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.098658
Average KL loss: 0.168748
Average total loss: 0.267407
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(1.2419e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.102975
Average KL loss: 0.168736
Average total loss: 0.271712
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-3.8545e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.105312
Average KL loss: 0.168726
Average total loss: 0.274038
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-4.4157e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.105821
Average KL loss: 0.168716
Average total loss: 0.274537
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(4.7136e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.102361
Average KL loss: 0.168705
Average total loss: 0.271066
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-4.2859e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.106513
Average KL loss: 0.168694
Average total loss: 0.275207
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-5.2467e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.102547
Average KL loss: 0.168684
Average total loss: 0.271231
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-4.6130e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.106093
Average KL loss: 0.168674
Average total loss: 0.274767
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-3.2607e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.101652
Average KL loss: 0.168663
Average total loss: 0.270315
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(4.2040e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.106781
Average KL loss: 0.168652
Average total loss: 0.275433
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(1.6393e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.109630
Average KL loss: 0.168642
Average total loss: 0.278273
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-5.3501e-10, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.104727
Average KL loss: 0.168633
Average total loss: 0.273360
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-1.2546e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.106986
Average KL loss: 0.168627
Average total loss: 0.275613
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(4.6461e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.100971
Average KL loss: 0.168626
Average total loss: 0.269597
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-2.6375e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.105580
Average KL loss: 0.168625
Average total loss: 0.274205
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(3.6005e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.103668
Average KL loss: 0.168624
Average total loss: 0.272291
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-4.7552e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.103085
Average KL loss: 0.168623
Average total loss: 0.271707
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(7.5370e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.104590
Average KL loss: 0.168622
Average total loss: 0.273212
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-2.3170e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.100832
Average KL loss: 0.168620
Average total loss: 0.269453
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(3.8521e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.104014
Average KL loss: 0.168619
Average total loss: 0.272633
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(3.1724e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.104572
Average KL loss: 0.168618
Average total loss: 0.273190
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(7.8481e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.104752
Average KL loss: 0.168617
Average total loss: 0.273369
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-5.0831e-09, device='cuda:0')
 Percentile value: 0.5559160113334656
Non-zero model percentage: 1.5625073909759521%, Non-zero mask percentage: 1.5625073909759521%

--- Pruning Level [6/12]: ---
conv1.weight         | nonzeros =     970 /    1728             ( 56.13%) | total_pruned =     758 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2531 /   36864             (  6.87%) | total_pruned =   34333 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    3008 /   36864             (  8.16%) | total_pruned =   33856 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2652 /   36864             (  7.19%) | total_pruned =   34212 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2785 /   36864             (  7.55%) | total_pruned =   34079 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4746 /   73728             (  6.44%) | total_pruned =   68982 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    7438 /  147456             (  5.04%) | total_pruned =  140018 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      52 /     128             ( 40.62%) | total_pruned =      76 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2061 /    8192             ( 25.16%) | total_pruned =    6131 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4716 /  147456             (  3.20%) | total_pruned =  142740 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    4521 /  147456             (  3.07%) | total_pruned =  142935 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      33 /     128             ( 25.78%) | total_pruned =      95 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   13172 /  294912             (  4.47%) | total_pruned =  281740 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   19582 /  589824             (  3.32%) | total_pruned =  570242 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     176 /     256             ( 68.75%) | total_pruned =      80 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4797 /   32768             ( 14.64%) | total_pruned =   27971 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     162 /     256             ( 63.28%) | total_pruned =      94 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    9201 /  589824             (  1.56%) | total_pruned =  580623 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     158 /     256             ( 61.72%) | total_pruned =      98 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    8763 /  589824             (  1.49%) | total_pruned =  581061 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   27939 / 1179648             (  2.37%) | total_pruned = 1151709 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     471 /     512             ( 91.99%) | total_pruned =      41 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   23289 / 2359296             (  0.99%) | total_pruned = 2336007 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     352 /     512             ( 68.75%) | total_pruned =     160 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    5377 /  131072             (  4.10%) | total_pruned =  125695 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     486 /     512             ( 94.92%) | total_pruned =      26 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     353 /     512             ( 68.95%) | total_pruned =     159 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   11939 / 2359296             (  0.51%) | total_pruned = 2347357 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     402 /     512             ( 78.52%) | total_pruned =     110 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     125 /     512             ( 24.41%) | total_pruned =     387 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    5712 / 2359296             (  0.24%) | total_pruned = 2353584 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     490 /     512             ( 95.70%) | total_pruned =      22 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      31 /     512             (  6.05%) | total_pruned =     481 | shape = torch.Size([512])
linear.weight        | nonzeros =    2285 /    5120             ( 44.63%) | total_pruned =    2835 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 174669, pruned : 11004093, total: 11178762, Compression rate :      64.00x  ( 98.44% pruned)
Train Epoch: 21/100 Loss: 0.000114 Accuracy: 86.52 100.00 % Best test Accuracy: 86.99%
tensor(0.0128, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-2.6839e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.289988
Average KL loss: 0.160320
Average total loss: 0.450308
tensor(0.0128, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-2.9829e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.278573
Average KL loss: 0.159320
Average total loss: 0.437894
tensor(0.0129, device='cuda:0') tensor(0.0225, device='cuda:0') tensor(-1.8444e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.266292
Average KL loss: 0.160992
Average total loss: 0.427284
tensor(0.0130, device='cuda:0') tensor(0.0226, device='cuda:0') tensor(-1.2826e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.257222
Average KL loss: 0.162804
Average total loss: 0.420025
tensor(0.0131, device='cuda:0') tensor(0.0228, device='cuda:0') tensor(-1.4032e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.248424
Average KL loss: 0.164510
Average total loss: 0.412934
tensor(0.0131, device='cuda:0') tensor(0.0230, device='cuda:0') tensor(-1.2464e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.247975
Average KL loss: 0.166158
Average total loss: 0.414133
tensor(0.0132, device='cuda:0') tensor(0.0232, device='cuda:0') tensor(-1.2522e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.241262
Average KL loss: 0.167744
Average total loss: 0.409007
tensor(0.0132, device='cuda:0') tensor(0.0234, device='cuda:0') tensor(-1.7701e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.226057
Average KL loss: 0.169218
Average total loss: 0.395274
tensor(0.0133, device='cuda:0') tensor(0.0236, device='cuda:0') tensor(-1.2217e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.220841
Average KL loss: 0.170591
Average total loss: 0.391432
tensor(0.0133, device='cuda:0') tensor(0.0238, device='cuda:0') tensor(-3.1612e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.222873
Average KL loss: 0.171885
Average total loss: 0.394758
tensor(0.0134, device='cuda:0') tensor(0.0239, device='cuda:0') tensor(5.9067e-10, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.224061
Average KL loss: 0.173147
Average total loss: 0.397207
tensor(0.0134, device='cuda:0') tensor(0.0241, device='cuda:0') tensor(-2.0261e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.208310
Average KL loss: 0.174347
Average total loss: 0.382657
tensor(0.0134, device='cuda:0') tensor(0.0243, device='cuda:0') tensor(-5.5157e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.209431
Average KL loss: 0.175470
Average total loss: 0.384901
tensor(0.0135, device='cuda:0') tensor(0.0245, device='cuda:0') tensor(-1.2903e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.208576
Average KL loss: 0.176534
Average total loss: 0.385110
tensor(0.0135, device='cuda:0') tensor(0.0246, device='cuda:0') tensor(-6.2167e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.205241
Average KL loss: 0.177525
Average total loss: 0.382766
tensor(0.0135, device='cuda:0') tensor(0.0248, device='cuda:0') tensor(-8.0183e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.197452
Average KL loss: 0.178432
Average total loss: 0.375884
tensor(0.0135, device='cuda:0') tensor(0.0249, device='cuda:0') tensor(-7.8354e-09, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.196289
Average KL loss: 0.179396
Average total loss: 0.375685
tensor(0.0136, device='cuda:0') tensor(0.0251, device='cuda:0') tensor(-3.9103e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.194987
Average KL loss: 0.180378
Average total loss: 0.375364
tensor(0.0136, device='cuda:0') tensor(0.0252, device='cuda:0') tensor(-1.5022e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.193166
Average KL loss: 0.181325
Average total loss: 0.374492
tensor(0.0136, device='cuda:0') tensor(0.0254, device='cuda:0') tensor(-8.2194e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.185782
Average KL loss: 0.182207
Average total loss: 0.367989
tensor(0.0136, device='cuda:0') tensor(0.0255, device='cuda:0') tensor(-2.1008e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.185398
Average KL loss: 0.183072
Average total loss: 0.368469
tensor(0.0137, device='cuda:0') tensor(0.0257, device='cuda:0') tensor(-4.5410e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.180876
Average KL loss: 0.183820
Average total loss: 0.364695
tensor(0.0137, device='cuda:0') tensor(0.0258, device='cuda:0') tensor(-9.9139e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.182322
Average KL loss: 0.184587
Average total loss: 0.366909
tensor(0.0137, device='cuda:0') tensor(0.0259, device='cuda:0') tensor(-1.2865e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.180771
Average KL loss: 0.185361
Average total loss: 0.366132
tensor(0.0137, device='cuda:0') tensor(0.0261, device='cuda:0') tensor(-1.3383e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.179848
Average KL loss: 0.186076
Average total loss: 0.365924
tensor(0.0137, device='cuda:0') tensor(0.0262, device='cuda:0') tensor(-6.8375e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.173344
Average KL loss: 0.186717
Average total loss: 0.360062
tensor(0.0138, device='cuda:0') tensor(0.0263, device='cuda:0') tensor(-5.7067e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.169081
Average KL loss: 0.187353
Average total loss: 0.356434
tensor(0.0138, device='cuda:0') tensor(0.0264, device='cuda:0') tensor(-4.4703e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.172091
Average KL loss: 0.188028
Average total loss: 0.360120
tensor(0.0138, device='cuda:0') tensor(0.0266, device='cuda:0') tensor(-1.5037e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.168200
Average KL loss: 0.188663
Average total loss: 0.356863
tensor(0.0138, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-6.4935e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.165971
Average KL loss: 0.189224
Average total loss: 0.355195
tensor(0.0138, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-6.5405e-09, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.171210
Average KL loss: 0.189821
Average total loss: 0.361031
tensor(0.0138, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-1.4817e-11, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.168334
Average KL loss: 0.190468
Average total loss: 0.358802
tensor(0.0138, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-2.0865e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.167255
Average KL loss: 0.191009
Average total loss: 0.358263
tensor(0.0139, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-1.2654e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.162689
Average KL loss: 0.191647
Average total loss: 0.354336
tensor(0.0139, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-3.0820e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.166452
Average KL loss: 0.192255
Average total loss: 0.358707
tensor(0.0139, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-7.4891e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.160120
Average KL loss: 0.192798
Average total loss: 0.352918
tensor(0.0139, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-1.2273e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.159869
Average KL loss: 0.193296
Average total loss: 0.353165
tensor(0.0139, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-3.9419e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.158984
Average KL loss: 0.193841
Average total loss: 0.352825
tensor(0.0139, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-1.6435e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.152888
Average KL loss: 0.194402
Average total loss: 0.347290
tensor(0.0139, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-1.3371e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.159148
Average KL loss: 0.194949
Average total loss: 0.354096
tensor(0.0139, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(3.0466e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.152668
Average KL loss: 0.195399
Average total loss: 0.348067
tensor(0.0140, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-9.9136e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.152787
Average KL loss: 0.195791
Average total loss: 0.348579
tensor(0.0140, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-6.0704e-10, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.148185
Average KL loss: 0.196229
Average total loss: 0.344414
tensor(0.0140, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-4.7509e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.147661
Average KL loss: 0.196654
Average total loss: 0.344315
tensor(0.0140, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-1.4494e-10, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.150253
Average KL loss: 0.197054
Average total loss: 0.347307
tensor(0.0140, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-1.5814e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.142030
Average KL loss: 0.197427
Average total loss: 0.339456
tensor(0.0140, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-2.4054e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.148319
Average KL loss: 0.197797
Average total loss: 0.346116
tensor(0.0140, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-5.9570e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.148176
Average KL loss: 0.198213
Average total loss: 0.346389
tensor(0.0140, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-5.9812e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.148527
Average KL loss: 0.198675
Average total loss: 0.347202
tensor(0.0140, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-3.1971e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.143690
Average KL loss: 0.199084
Average total loss: 0.342774
tensor(0.0140, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-8.1473e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.142930
Average KL loss: 0.199438
Average total loss: 0.342368
tensor(0.0140, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-4.8215e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.143499
Average KL loss: 0.199785
Average total loss: 0.343284
tensor(0.0140, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(1.6899e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.138799
Average KL loss: 0.200137
Average total loss: 0.338935
tensor(0.0140, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-1.1976e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.138864
Average KL loss: 0.200437
Average total loss: 0.339301
tensor(0.0140, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-7.7586e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.140119
Average KL loss: 0.200815
Average total loss: 0.340935
tensor(0.0141, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-2.4518e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.143298
Average KL loss: 0.201199
Average total loss: 0.344497
tensor(0.0141, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(2.8086e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.141467
Average KL loss: 0.201542
Average total loss: 0.343010
tensor(0.0141, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-2.3721e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.141238
Average KL loss: 0.201938
Average total loss: 0.343177
tensor(0.0141, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-4.2734e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.136410
Average KL loss: 0.202348
Average total loss: 0.338757
tensor(0.0141, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-6.2485e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.138420
Average KL loss: 0.202636
Average total loss: 0.341056
tensor(0.0141, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-3.2701e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.137530
Average KL loss: 0.202889
Average total loss: 0.340420
tensor(0.0141, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-3.3354e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.135531
Average KL loss: 0.203228
Average total loss: 0.338759
tensor(0.0141, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-6.1357e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.127945
Average KL loss: 0.203468
Average total loss: 0.331414
tensor(0.0141, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-2.7194e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.131812
Average KL loss: 0.203607
Average total loss: 0.335419
tensor(0.0141, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-8.9613e-11, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.133304
Average KL loss: 0.203866
Average total loss: 0.337171
tensor(0.0141, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-1.1936e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.136985
Average KL loss: 0.204135
Average total loss: 0.341120
tensor(0.0141, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(1.6814e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.133007
Average KL loss: 0.204453
Average total loss: 0.337459
tensor(0.0141, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-2.4476e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.130761
Average KL loss: 0.204657
Average total loss: 0.335418
tensor(0.0141, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-3.2576e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.131263
Average KL loss: 0.204923
Average total loss: 0.336186
tensor(0.0141, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(8.1084e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.128284
Average KL loss: 0.205109
Average total loss: 0.333393
tensor(0.0141, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-7.8924e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.129034
Average KL loss: 0.205329
Average total loss: 0.334363
tensor(0.0141, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-2.0955e-10, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.125534
Average KL loss: 0.205565
Average total loss: 0.331099
tensor(0.0141, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-5.2352e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.131231
Average KL loss: 0.205750
Average total loss: 0.336982
tensor(0.0141, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-9.3893e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.122416
Average KL loss: 0.205964
Average total loss: 0.328380
tensor(0.0141, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-4.8117e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.129498
Average KL loss: 0.206190
Average total loss: 0.335688
tensor(0.0141, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-4.8155e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.130819
Average KL loss: 0.206464
Average total loss: 0.337283
tensor(0.0141, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(1.1108e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.128942
Average KL loss: 0.206731
Average total loss: 0.335673
tensor(0.0141, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-5.9002e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.126071
Average KL loss: 0.206945
Average total loss: 0.333016
tensor(0.0141, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-2.2459e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.128265
Average KL loss: 0.207150
Average total loss: 0.335415
tensor(0.0142, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-1.0349e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.127733
Average KL loss: 0.207378
Average total loss: 0.335111
tensor(0.0142, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-4.3809e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.123354
Average KL loss: 0.207592
Average total loss: 0.330946
tensor(0.0142, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-4.7691e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.118342
Average KL loss: 0.207837
Average total loss: 0.326179
tensor(0.0142, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(4.5216e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.122641
Average KL loss: 0.208020
Average total loss: 0.330662
tensor(0.0142, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-2.4539e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.122152
Average KL loss: 0.208127
Average total loss: 0.330279
tensor(0.0142, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-3.3531e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.116114
Average KL loss: 0.208288
Average total loss: 0.324402
tensor(0.0142, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-1.8613e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.114197
Average KL loss: 0.208352
Average total loss: 0.322549
tensor(0.0142, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-4.2618e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.118892
Average KL loss: 0.208436
Average total loss: 0.327327
tensor(0.0142, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(8.6029e-10, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.117518
Average KL loss: 0.208564
Average total loss: 0.326082
tensor(0.0142, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.6022e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.118210
Average KL loss: 0.208734
Average total loss: 0.326944
tensor(0.0142, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-6.2166e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.120521
Average KL loss: 0.208896
Average total loss: 0.329417
tensor(0.0142, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-1.3413e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.125059
Average KL loss: 0.209065
Average total loss: 0.334124
tensor(0.0142, device='cuda:0') tensor(0.0322, device='cuda:0') tensor(-2.6697e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.117253
Average KL loss: 0.209248
Average total loss: 0.326502
tensor(0.0142, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(3.1889e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.119477
Average KL loss: 0.209409
Average total loss: 0.328886
tensor(0.0142, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(-4.8685e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.117464
Average KL loss: 0.209580
Average total loss: 0.327044
tensor(0.0142, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-6.2050e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.113514
Average KL loss: 0.209664
Average total loss: 0.323178
tensor(0.0142, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-6.4773e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.116262
Average KL loss: 0.209692
Average total loss: 0.325953
tensor(0.0142, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(8.4058e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.121032
Average KL loss: 0.209795
Average total loss: 0.330828
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.4422e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.116140
Average KL loss: 0.209873
Average total loss: 0.326012
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-7.3617e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.115877
Average KL loss: 0.209843
Average total loss: 0.325720
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-5.2879e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.116776
Average KL loss: 0.209816
Average total loss: 0.326592
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-2.0920e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.117228
Average KL loss: 0.209783
Average total loss: 0.327011
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-4.4152e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.117881
Average KL loss: 0.209746
Average total loss: 0.327628
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.1362e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.114742
Average KL loss: 0.209710
Average total loss: 0.324452
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.0472e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.113814
Average KL loss: 0.209674
Average total loss: 0.323487
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.9957e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.114387
Average KL loss: 0.209638
Average total loss: 0.324025
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-2.4177e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.117336
Average KL loss: 0.209613
Average total loss: 0.326949
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-4.7799e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.116422
Average KL loss: 0.209574
Average total loss: 0.325995
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(8.0276e-11, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.116379
Average KL loss: 0.209544
Average total loss: 0.325923
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-8.9097e-11, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.112450
Average KL loss: 0.209525
Average total loss: 0.321975
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-2.6590e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.116622
Average KL loss: 0.209521
Average total loss: 0.326143
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(2.1784e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.111243
Average KL loss: 0.209517
Average total loss: 0.320759
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-8.3024e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.117727
Average KL loss: 0.209513
Average total loss: 0.327240
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.7456e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.115799
Average KL loss: 0.209510
Average total loss: 0.325308
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-4.1122e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.119264
Average KL loss: 0.209507
Average total loss: 0.328771
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-7.5648e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.110095
Average KL loss: 0.209503
Average total loss: 0.319597
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-3.4195e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.110559
Average KL loss: 0.209498
Average total loss: 0.320057
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(6.3982e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.109034
Average KL loss: 0.209494
Average total loss: 0.318528
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-9.4670e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.115346
Average KL loss: 0.209489
Average total loss: 0.324836
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(1.1159e-10, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.112814
Average KL loss: 0.209485
Average total loss: 0.322299
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(5.0691e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.111863
Average KL loss: 0.209480
Average total loss: 0.321344
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-6.1269e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.117763
Average KL loss: 0.209476
Average total loss: 0.327239
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-5.2592e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.114847
Average KL loss: 0.209472
Average total loss: 0.324320
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-5.6720e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.116195
Average KL loss: 0.209469
Average total loss: 0.325664
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-2.8169e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.111530
Average KL loss: 0.209465
Average total loss: 0.320994
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(4.0173e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.116152
Average KL loss: 0.209460
Average total loss: 0.325612
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(6.2997e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.111697
Average KL loss: 0.209455
Average total loss: 0.321153
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(1.1597e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.111698
Average KL loss: 0.209450
Average total loss: 0.321148
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-4.5416e-10, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.112052
Average KL loss: 0.209446
Average total loss: 0.321498
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-7.3642e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.116165
Average KL loss: 0.209444
Average total loss: 0.325609
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-8.3761e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.114379
Average KL loss: 0.209443
Average total loss: 0.323823
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-4.5944e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.113553
Average KL loss: 0.209443
Average total loss: 0.322996
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-2.9538e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.120403
Average KL loss: 0.209442
Average total loss: 0.329845
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(5.1533e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.118650
Average KL loss: 0.209442
Average total loss: 0.328092
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.1997e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.113576
Average KL loss: 0.209442
Average total loss: 0.323018
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-5.0807e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.121641
Average KL loss: 0.209441
Average total loss: 0.331082
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.3506e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.114403
Average KL loss: 0.209441
Average total loss: 0.323844
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(8.1030e-10, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.113602
Average KL loss: 0.209440
Average total loss: 0.323042
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-2.3658e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.115846
Average KL loss: 0.209440
Average total loss: 0.325286
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(9.0968e-09, device='cuda:0')
 Percentile value: 1.2536965608596802
Non-zero model percentage: 0.781258225440979%, Non-zero mask percentage: 0.781258225440979%

--- Pruning Level [7/12]: ---
conv1.weight         | nonzeros =     921 /    1728             ( 53.30%) | total_pruned =     807 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1595 /   36864             (  4.33%) | total_pruned =   35269 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2004 /   36864             (  5.44%) | total_pruned =   34860 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1669 /   36864             (  4.53%) | total_pruned =   35195 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1769 /   36864             (  4.80%) | total_pruned =   35095 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2937 /   73728             (  3.98%) | total_pruned =   70791 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      44 /     128             ( 34.38%) | total_pruned =      84 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4305 /  147456             (  2.92%) | total_pruned =  143151 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1667 /    8192             ( 20.35%) | total_pruned =    6525 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2385 /  147456             (  1.62%) | total_pruned =  145071 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2281 /  147456             (  1.55%) | total_pruned =  145175 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    7393 /  294912             (  2.51%) | total_pruned =  287519 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     222 /     256             ( 86.72%) | total_pruned =      34 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    9806 /  589824             (  1.66%) | total_pruned =  580018 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =     151 /     256             ( 58.98%) | total_pruned =     105 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    3396 /   32768             ( 10.36%) | total_pruned =   29372 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =     130 /     256             ( 50.78%) | total_pruned =     126 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    3706 /  589824             (  0.63%) | total_pruned =  586118 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     232 /     256             ( 90.62%) | total_pruned =      24 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     115 /     256             ( 44.92%) | total_pruned =     141 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3553 /  589824             (  0.60%) | total_pruned =  586271 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =     100 /     256             ( 39.06%) | total_pruned =     156 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   12067 / 1179648             (  1.02%) | total_pruned = 1167581 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     511 /     512             ( 99.80%) | total_pruned =       1 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     441 /     512             ( 86.13%) | total_pruned =      71 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    8376 / 2359296             (  0.36%) | total_pruned = 2350920 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     274 /     512             ( 53.52%) | total_pruned =     238 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2843 /  131072             (  2.17%) | total_pruned =  128229 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     468 /     512             ( 91.41%) | total_pruned =      44 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     281 /     512             ( 54.88%) | total_pruned =     231 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    4166 / 2359296             (  0.18%) | total_pruned = 2355130 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     381 /     512             ( 74.41%) | total_pruned =     131 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      61 /     512             ( 11.91%) | total_pruned =     451 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1901 / 2359296             (  0.08%) | total_pruned = 2357395 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     447 /     512             ( 87.30%) | total_pruned =      65 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
linear.weight        | nonzeros =    1963 /    5120             ( 38.34%) | total_pruned =    3157 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 87335, pruned : 11091427, total: 11178762, Compression rate :     128.00x  ( 99.22% pruned)
Train Epoch: 23/100 Loss: 0.001768 Accuracy: 85.16 100.00 % Best test Accuracy: 85.48%
tensor(0.0142, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-2.2866e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.338620
Average KL loss: 0.197881
Average total loss: 0.536501
tensor(0.0127, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-1.8549e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.309356
Average KL loss: 0.193656
Average total loss: 0.503012
tensor(0.0126, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-2.5416e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.304326
Average KL loss: 0.194500
Average total loss: 0.498826
tensor(0.0126, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-2.7467e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.305187
Average KL loss: 0.195669
Average total loss: 0.500856
tensor(0.0126, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-2.7970e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.291188
Average KL loss: 0.196813
Average total loss: 0.488002
tensor(0.0127, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-2.6839e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.288611
Average KL loss: 0.198013
Average total loss: 0.486624
tensor(0.0127, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-2.3455e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.291149
Average KL loss: 0.199198
Average total loss: 0.490346
tensor(0.0128, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-2.4061e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.281485
Average KL loss: 0.200333
Average total loss: 0.481817
tensor(0.0128, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-2.4094e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.265620
Average KL loss: 0.201397
Average total loss: 0.467016
tensor(0.0129, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-4.3789e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.269859
Average KL loss: 0.202476
Average total loss: 0.472335
tensor(0.0129, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-2.7766e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.258070
Average KL loss: 0.203553
Average total loss: 0.461623
tensor(0.0130, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-2.8959e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.247964
Average KL loss: 0.204525
Average total loss: 0.452488
tensor(0.0130, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-2.4235e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.245175
Average KL loss: 0.205438
Average total loss: 0.450612
tensor(0.0131, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-1.6293e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.241670
Average KL loss: 0.206347
Average total loss: 0.448016
tensor(0.0131, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-1.3073e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.245485
Average KL loss: 0.207301
Average total loss: 0.452786
tensor(0.0131, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-2.2973e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.233774
Average KL loss: 0.208216
Average total loss: 0.441990
tensor(0.0132, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-1.9255e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.234801
Average KL loss: 0.209017
Average total loss: 0.443817
tensor(0.0132, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(-2.4842e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.231382
Average KL loss: 0.209917
Average total loss: 0.441299
tensor(0.0133, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-2.3535e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.218552
Average KL loss: 0.210761
Average total loss: 0.429313
tensor(0.0133, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-1.4038e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.224485
Average KL loss: 0.211503
Average total loss: 0.435989
tensor(0.0133, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-9.0793e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.216427
Average KL loss: 0.212263
Average total loss: 0.428690
tensor(0.0134, device='cuda:0') tensor(0.0330, device='cuda:0') tensor(-1.6291e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.217496
Average KL loss: 0.213023
Average total loss: 0.430519
tensor(0.0134, device='cuda:0') tensor(0.0332, device='cuda:0') tensor(-1.0206e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.211441
Average KL loss: 0.213757
Average total loss: 0.425198
tensor(0.0134, device='cuda:0') tensor(0.0333, device='cuda:0') tensor(-1.2052e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.207659
Average KL loss: 0.214497
Average total loss: 0.422157
tensor(0.0135, device='cuda:0') tensor(0.0335, device='cuda:0') tensor(-1.5392e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.205063
Average KL loss: 0.215217
Average total loss: 0.420280
tensor(0.0135, device='cuda:0') tensor(0.0337, device='cuda:0') tensor(-1.2446e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.202150
Average KL loss: 0.215892
Average total loss: 0.418042
tensor(0.0135, device='cuda:0') tensor(0.0338, device='cuda:0') tensor(-6.8045e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.203229
Average KL loss: 0.216529
Average total loss: 0.419758
tensor(0.0135, device='cuda:0') tensor(0.0340, device='cuda:0') tensor(-1.6049e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.198634
Average KL loss: 0.217215
Average total loss: 0.415849
tensor(0.0136, device='cuda:0') tensor(0.0342, device='cuda:0') tensor(-1.4699e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.202087
Average KL loss: 0.217910
Average total loss: 0.419996
tensor(0.0136, device='cuda:0') tensor(0.0343, device='cuda:0') tensor(-1.0180e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.204881
Average KL loss: 0.218553
Average total loss: 0.423434
tensor(0.0136, device='cuda:0') tensor(0.0345, device='cuda:0') tensor(-1.7073e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.190381
Average KL loss: 0.219146
Average total loss: 0.409527
tensor(0.0137, device='cuda:0') tensor(0.0347, device='cuda:0') tensor(-1.1814e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.199874
Average KL loss: 0.219759
Average total loss: 0.419633
tensor(0.0137, device='cuda:0') tensor(0.0348, device='cuda:0') tensor(-2.0750e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.185860
Average KL loss: 0.220383
Average total loss: 0.406242
tensor(0.0137, device='cuda:0') tensor(0.0350, device='cuda:0') tensor(-9.7037e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.189653
Average KL loss: 0.220947
Average total loss: 0.410599
tensor(0.0137, device='cuda:0') tensor(0.0352, device='cuda:0') tensor(-9.0460e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.186976
Average KL loss: 0.221516
Average total loss: 0.408493
tensor(0.0138, device='cuda:0') tensor(0.0353, device='cuda:0') tensor(-1.3489e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.189588
Average KL loss: 0.222092
Average total loss: 0.411680
tensor(0.0138, device='cuda:0') tensor(0.0354, device='cuda:0') tensor(-1.1737e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.180771
Average KL loss: 0.222629
Average total loss: 0.403400
tensor(0.0138, device='cuda:0') tensor(0.0356, device='cuda:0') tensor(-1.1770e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.181528
Average KL loss: 0.223128
Average total loss: 0.404656
tensor(0.0138, device='cuda:0') tensor(0.0358, device='cuda:0') tensor(-9.7092e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.177350
Average KL loss: 0.223640
Average total loss: 0.400990
tensor(0.0139, device='cuda:0') tensor(0.0359, device='cuda:0') tensor(-1.4136e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.185337
Average KL loss: 0.224211
Average total loss: 0.409547
tensor(0.0139, device='cuda:0') tensor(0.0361, device='cuda:0') tensor(-1.7339e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.167964
Average KL loss: 0.224747
Average total loss: 0.392710
tensor(0.0139, device='cuda:0') tensor(0.0362, device='cuda:0') tensor(-6.8501e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.171074
Average KL loss: 0.225196
Average total loss: 0.396270
tensor(0.0139, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-1.4173e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.178964
Average KL loss: 0.225680
Average total loss: 0.404644
tensor(0.0140, device='cuda:0') tensor(0.0365, device='cuda:0') tensor(-1.6455e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.171231
Average KL loss: 0.226186
Average total loss: 0.397417
tensor(0.0140, device='cuda:0') tensor(0.0366, device='cuda:0') tensor(-9.6411e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.169167
Average KL loss: 0.226659
Average total loss: 0.395826
tensor(0.0140, device='cuda:0') tensor(0.0368, device='cuda:0') tensor(-1.2669e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.166713
Average KL loss: 0.227114
Average total loss: 0.393828
tensor(0.0140, device='cuda:0') tensor(0.0369, device='cuda:0') tensor(-1.9661e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.163121
Average KL loss: 0.227550
Average total loss: 0.390671
tensor(0.0140, device='cuda:0') tensor(0.0371, device='cuda:0') tensor(-1.1023e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.166325
Average KL loss: 0.228015
Average total loss: 0.394339
tensor(0.0141, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(-1.1750e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.163587
Average KL loss: 0.228455
Average total loss: 0.392042
tensor(0.0141, device='cuda:0') tensor(0.0373, device='cuda:0') tensor(-4.5974e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.163169
Average KL loss: 0.228893
Average total loss: 0.392062
tensor(0.0141, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(4.8565e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.159671
Average KL loss: 0.229319
Average total loss: 0.388990
tensor(0.0141, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-1.7100e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.150351
Average KL loss: 0.229670
Average total loss: 0.380021
tensor(0.0141, device='cuda:0') tensor(0.0377, device='cuda:0') tensor(-1.2955e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.156085
Average KL loss: 0.230022
Average total loss: 0.386107
tensor(0.0142, device='cuda:0') tensor(0.0379, device='cuda:0') tensor(-7.0694e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.155589
Average KL loss: 0.230446
Average total loss: 0.386035
tensor(0.0142, device='cuda:0') tensor(0.0380, device='cuda:0') tensor(-1.2344e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.162172
Average KL loss: 0.230902
Average total loss: 0.393074
tensor(0.0142, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-3.2903e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.154912
Average KL loss: 0.231339
Average total loss: 0.386252
tensor(0.0142, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-8.6735e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.146103
Average KL loss: 0.231737
Average total loss: 0.377840
tensor(0.0142, device='cuda:0') tensor(0.0384, device='cuda:0') tensor(-2.2754e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.152783
Average KL loss: 0.232078
Average total loss: 0.384860
tensor(0.0143, device='cuda:0') tensor(0.0385, device='cuda:0') tensor(-3.3566e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.145664
Average KL loss: 0.232394
Average total loss: 0.378058
tensor(0.0143, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-7.2279e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.150163
Average KL loss: 0.232694
Average total loss: 0.382857
tensor(0.0143, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-6.2549e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.147301
Average KL loss: 0.233074
Average total loss: 0.380375
tensor(0.0143, device='cuda:0') tensor(0.0389, device='cuda:0') tensor(-7.7145e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.143863
Average KL loss: 0.233415
Average total loss: 0.377278
tensor(0.0143, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-6.8156e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.147137
Average KL loss: 0.233805
Average total loss: 0.380942
tensor(0.0143, device='cuda:0') tensor(0.0392, device='cuda:0') tensor(-7.3975e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.144167
Average KL loss: 0.234165
Average total loss: 0.378332
tensor(0.0144, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-5.0220e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.142492
Average KL loss: 0.234507
Average total loss: 0.376999
tensor(0.0144, device='cuda:0') tensor(0.0394, device='cuda:0') tensor(-4.5909e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.142493
Average KL loss: 0.234829
Average total loss: 0.377323
tensor(0.0144, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-9.9699e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.134716
Average KL loss: 0.235100
Average total loss: 0.369815
tensor(0.0144, device='cuda:0') tensor(0.0396, device='cuda:0') tensor(-7.9644e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.140934
Average KL loss: 0.235398
Average total loss: 0.376333
tensor(0.0144, device='cuda:0') tensor(0.0398, device='cuda:0') tensor(-6.8928e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.136661
Average KL loss: 0.235694
Average total loss: 0.372354
tensor(0.0144, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-3.0149e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.132929
Average KL loss: 0.235992
Average total loss: 0.368921
tensor(0.0145, device='cuda:0') tensor(0.0400, device='cuda:0') tensor(-1.0457e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.137498
Average KL loss: 0.236334
Average total loss: 0.373832
tensor(0.0145, device='cuda:0') tensor(0.0401, device='cuda:0') tensor(-9.8176e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.135049
Average KL loss: 0.236661
Average total loss: 0.371710
tensor(0.0145, device='cuda:0') tensor(0.0403, device='cuda:0') tensor(2.2734e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.133572
Average KL loss: 0.236915
Average total loss: 0.370487
tensor(0.0145, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-6.9692e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.134063
Average KL loss: 0.237198
Average total loss: 0.371260
tensor(0.0145, device='cuda:0') tensor(0.0405, device='cuda:0') tensor(-4.5768e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.129888
Average KL loss: 0.237516
Average total loss: 0.367404
tensor(0.0145, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-3.8511e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.127938
Average KL loss: 0.237769
Average total loss: 0.365707
tensor(0.0145, device='cuda:0') tensor(0.0407, device='cuda:0') tensor(-1.6118e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.130884
Average KL loss: 0.237984
Average total loss: 0.368869
tensor(0.0146, device='cuda:0') tensor(0.0408, device='cuda:0') tensor(-4.6734e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.128838
Average KL loss: 0.238269
Average total loss: 0.367108
tensor(0.0146, device='cuda:0') tensor(0.0409, device='cuda:0') tensor(-2.3301e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.127561
Average KL loss: 0.238498
Average total loss: 0.366059
tensor(0.0146, device='cuda:0') tensor(0.0410, device='cuda:0') tensor(-4.7788e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.124075
Average KL loss: 0.238725
Average total loss: 0.362800
tensor(0.0146, device='cuda:0') tensor(0.0411, device='cuda:0') tensor(-9.4747e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.127280
Average KL loss: 0.238990
Average total loss: 0.366270
tensor(0.0146, device='cuda:0') tensor(0.0413, device='cuda:0') tensor(-3.7538e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.127294
Average KL loss: 0.239259
Average total loss: 0.366553
tensor(0.0146, device='cuda:0') tensor(0.0414, device='cuda:0') tensor(-9.0611e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.127711
Average KL loss: 0.239503
Average total loss: 0.367214
tensor(0.0146, device='cuda:0') tensor(0.0415, device='cuda:0') tensor(-1.0151e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.121073
Average KL loss: 0.239725
Average total loss: 0.360798
tensor(0.0146, device='cuda:0') tensor(0.0416, device='cuda:0') tensor(1.5714e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.132204
Average KL loss: 0.239940
Average total loss: 0.372145
tensor(0.0147, device='cuda:0') tensor(0.0417, device='cuda:0') tensor(-2.7452e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.124751
Average KL loss: 0.240195
Average total loss: 0.364946
tensor(0.0147, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-9.0811e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.124669
Average KL loss: 0.240447
Average total loss: 0.365115
tensor(0.0147, device='cuda:0') tensor(0.0419, device='cuda:0') tensor(-6.2888e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.121760
Average KL loss: 0.240627
Average total loss: 0.362387
tensor(0.0147, device='cuda:0') tensor(0.0420, device='cuda:0') tensor(-3.4254e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.119420
Average KL loss: 0.240769
Average total loss: 0.360189
tensor(0.0147, device='cuda:0') tensor(0.0421, device='cuda:0') tensor(-4.5946e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.120374
Average KL loss: 0.240913
Average total loss: 0.361286
tensor(0.0147, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(-8.9861e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.119503
Average KL loss: 0.241083
Average total loss: 0.360587
tensor(0.0147, device='cuda:0') tensor(0.0423, device='cuda:0') tensor(-1.4651e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.116759
Average KL loss: 0.241256
Average total loss: 0.358014
tensor(0.0147, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-1.0230e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.114179
Average KL loss: 0.241442
Average total loss: 0.355621
tensor(0.0147, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-7.1178e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.120557
Average KL loss: 0.241603
Average total loss: 0.362160
tensor(0.0148, device='cuda:0') tensor(0.0426, device='cuda:0') tensor(-1.6502e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.118449
Average KL loss: 0.241782
Average total loss: 0.360231
tensor(0.0148, device='cuda:0') tensor(0.0427, device='cuda:0') tensor(-8.2835e-10, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.114900
Average KL loss: 0.241993
Average total loss: 0.356893
tensor(0.0148, device='cuda:0') tensor(0.0428, device='cuda:0') tensor(-1.3344e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.120523
Average KL loss: 0.242141
Average total loss: 0.362664
tensor(0.0148, device='cuda:0') tensor(0.0429, device='cuda:0') tensor(-2.7941e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.110519
Average KL loss: 0.242347
Average total loss: 0.352866
tensor(0.0148, device='cuda:0') tensor(0.0430, device='cuda:0') tensor(6.0466e-10, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.117025
Average KL loss: 0.242464
Average total loss: 0.359489
tensor(0.0148, device='cuda:0') tensor(0.0431, device='cuda:0') tensor(-6.4883e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.117414
Average KL loss: 0.242671
Average total loss: 0.360085
tensor(0.0148, device='cuda:0') tensor(0.0432, device='cuda:0') tensor(-6.7842e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.113130
Average KL loss: 0.242806
Average total loss: 0.355935
tensor(0.0148, device='cuda:0') tensor(0.0433, device='cuda:0') tensor(-1.0048e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.115212
Average KL loss: 0.242956
Average total loss: 0.358168
tensor(0.0148, device='cuda:0') tensor(0.0434, device='cuda:0') tensor(-8.7910e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.111323
Average KL loss: 0.243139
Average total loss: 0.354462
tensor(0.0148, device='cuda:0') tensor(0.0435, device='cuda:0') tensor(-1.0983e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.109925
Average KL loss: 0.243275
Average total loss: 0.353201
tensor(0.0149, device='cuda:0') tensor(0.0436, device='cuda:0') tensor(-2.7302e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.110102
Average KL loss: 0.243361
Average total loss: 0.353464
tensor(0.0149, device='cuda:0') tensor(0.0437, device='cuda:0') tensor(-3.3725e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.111695
Average KL loss: 0.243507
Average total loss: 0.355202
tensor(0.0149, device='cuda:0') tensor(0.0438, device='cuda:0') tensor(-5.1577e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.112758
Average KL loss: 0.243724
Average total loss: 0.356482
tensor(0.0149, device='cuda:0') tensor(0.0439, device='cuda:0') tensor(2.4341e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.109621
Average KL loss: 0.243883
Average total loss: 0.353504
tensor(0.0149, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-4.9937e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.117263
Average KL loss: 0.244032
Average total loss: 0.361294
tensor(0.0149, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(-5.5826e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.108175
Average KL loss: 0.244153
Average total loss: 0.352328
tensor(0.0149, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(-2.3834e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.115766
Average KL loss: 0.244161
Average total loss: 0.359927
tensor(0.0149, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(-5.8640e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.113024
Average KL loss: 0.244177
Average total loss: 0.357201
tensor(0.0149, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(3.4357e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.105475
Average KL loss: 0.244188
Average total loss: 0.349663
tensor(0.0149, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(-7.8276e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.108503
Average KL loss: 0.244193
Average total loss: 0.352695
tensor(0.0149, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(-5.4069e-10, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.105438
Average KL loss: 0.244199
Average total loss: 0.349637
tensor(0.0149, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(-1.1280e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.108527
Average KL loss: 0.244199
Average total loss: 0.352726
tensor(0.0149, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-4.1157e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.112589
Average KL loss: 0.244198
Average total loss: 0.356787
tensor(0.0149, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-2.9184e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.105346
Average KL loss: 0.244203
Average total loss: 0.349549
tensor(0.0149, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-8.4388e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.111801
Average KL loss: 0.244213
Average total loss: 0.356013
tensor(0.0149, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-8.0029e-10, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.112859
Average KL loss: 0.244224
Average total loss: 0.357083
tensor(0.0149, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-6.5182e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.110247
Average KL loss: 0.244233
Average total loss: 0.354480
tensor(0.0149, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-1.1817e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.109560
Average KL loss: 0.244244
Average total loss: 0.353803
tensor(0.0149, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-4.4625e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.103895
Average KL loss: 0.244251
Average total loss: 0.348146
tensor(0.0149, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-9.9753e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.107456
Average KL loss: 0.244254
Average total loss: 0.351710
tensor(0.0149, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-3.9549e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.113091
Average KL loss: 0.244265
Average total loss: 0.357356
tensor(0.0149, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-5.1211e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.110651
Average KL loss: 0.244280
Average total loss: 0.354931
tensor(0.0149, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(4.9602e-11, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.110099
Average KL loss: 0.244289
Average total loss: 0.354389
tensor(0.0149, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-3.9428e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.110266
Average KL loss: 0.244303
Average total loss: 0.354569
tensor(0.0149, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-1.1168e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.104294
Average KL loss: 0.244317
Average total loss: 0.348611
tensor(0.0149, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-5.4004e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.107858
Average KL loss: 0.244324
Average total loss: 0.352181
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-2.1511e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.107631
Average KL loss: 0.244329
Average total loss: 0.351961
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-4.8158e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.110873
Average KL loss: 0.244338
Average total loss: 0.355210
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-4.8659e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.109893
Average KL loss: 0.244349
Average total loss: 0.354241
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-4.1663e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.108069
Average KL loss: 0.244363
Average total loss: 0.352432
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-3.5147e-11, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.108795
Average KL loss: 0.244369
Average total loss: 0.353164
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-5.9014e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.108863
Average KL loss: 0.244370
Average total loss: 0.353234
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-1.5963e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.105808
Average KL loss: 0.244371
Average total loss: 0.350178
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-3.0478e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.108010
Average KL loss: 0.244371
Average total loss: 0.352381
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-7.3088e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.110831
Average KL loss: 0.244372
Average total loss: 0.355203
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-2.3590e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.107864
Average KL loss: 0.244372
Average total loss: 0.352237
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-3.1592e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.102311
Average KL loss: 0.244373
Average total loss: 0.346684
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-6.2356e-10, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.109406
Average KL loss: 0.244374
Average total loss: 0.353781
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-4.7601e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.105457
Average KL loss: 0.244375
Average total loss: 0.349832
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-1.1304e-10, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.107125
Average KL loss: 0.244376
Average total loss: 0.351501
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-6.5993e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.105804
Average KL loss: 0.244376
Average total loss: 0.350180
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-5.2957e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.107306
Average KL loss: 0.244377
Average total loss: 0.351683
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(4.1043e-10, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.105289
Average KL loss: 0.244378
Average total loss: 0.349666
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-4.9995e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.109288
Average KL loss: 0.244378
Average total loss: 0.353667
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-7.8546e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.105322
Average KL loss: 0.244379
Average total loss: 0.349701
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-1.1384e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.110086
Average KL loss: 0.244380
Average total loss: 0.354465
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-3.5029e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.106810
Average KL loss: 0.244380
Average total loss: 0.351191
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-6.8596e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.101962
Average KL loss: 0.244381
Average total loss: 0.346343
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-2.1731e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.103672
Average KL loss: 0.244381
Average total loss: 0.348053
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-3.3614e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.106238
Average KL loss: 0.244382
Average total loss: 0.350620
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-4.9260e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.104868
Average KL loss: 0.244383
Average total loss: 0.349250
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-3.8005e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.100915
Average KL loss: 0.244382
Average total loss: 0.345298
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-7.6495e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.107694
Average KL loss: 0.244383
Average total loss: 0.352077
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-5.3224e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.102555
Average KL loss: 0.244383
Average total loss: 0.346938
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-3.5314e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.106075
Average KL loss: 0.244384
Average total loss: 0.350458
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-6.0432e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.108552
Average KL loss: 0.244384
Average total loss: 0.352937
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(1.3449e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.107049
Average KL loss: 0.244385
Average total loss: 0.351434
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-2.3431e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.106952
Average KL loss: 0.244386
Average total loss: 0.351338
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-3.8027e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.109596
Average KL loss: 0.244387
Average total loss: 0.353983
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-6.8826e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.108518
Average KL loss: 0.244388
Average total loss: 0.352906
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-2.6294e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.108475
Average KL loss: 0.244388
Average total loss: 0.352863
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-2.4546e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.104497
Average KL loss: 0.244389
Average total loss: 0.348886
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-3.7955e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.102389
Average KL loss: 0.244389
Average total loss: 0.346778
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-8.4189e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.110727
Average KL loss: 0.244389
Average total loss: 0.355116
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-1.3537e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.109061
Average KL loss: 0.244390
Average total loss: 0.353450
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-8.3911e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.102749
Average KL loss: 0.244390
Average total loss: 0.347138
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-7.3109e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.104232
Average KL loss: 0.244390
Average total loss: 0.348622
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(2.7318e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.103390
Average KL loss: 0.244390
Average total loss: 0.347780
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-2.2420e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.106327
Average KL loss: 0.244390
Average total loss: 0.350717
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-4.0844e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.108362
Average KL loss: 0.244390
Average total loss: 0.352752
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-5.7149e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.106928
Average KL loss: 0.244390
Average total loss: 0.351318
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(9.3407e-10, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.104116
Average KL loss: 0.244390
Average total loss: 0.348506
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(2.8006e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.105992
Average KL loss: 0.244390
Average total loss: 0.350382
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(8.2622e-10, device='cuda:0')
 Percentile value: 2.5984307527542114
Non-zero model percentage: 0.39063358306884766%, Non-zero mask percentage: 0.39063358306884766%

--- Pruning Level [8/12]: ---
conv1.weight         | nonzeros =     858 /    1728             ( 49.65%) | total_pruned =     870 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1005 /   36864             (  2.73%) | total_pruned =   35859 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1240 /   36864             (  3.36%) | total_pruned =   35624 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     982 /   36864             (  2.66%) | total_pruned =   35882 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1089 /   36864             (  2.95%) | total_pruned =   35775 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1646 /   73728             (  2.23%) | total_pruned =   72082 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      36 /     128             ( 28.12%) | total_pruned =      92 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2251 /  147456             (  1.53%) | total_pruned =  145205 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      20 /     128             ( 15.62%) | total_pruned =     108 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1282 /    8192             ( 15.65%) | total_pruned =    6910 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1155 /  147456             (  0.78%) | total_pruned =  146301 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1098 /  147456             (  0.74%) | total_pruned =  146358 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3644 /  294912             (  1.24%) | total_pruned =  291268 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     201 /     256             ( 78.52%) | total_pruned =      55 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    4229 /  589824             (  0.72%) | total_pruned =  585595 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      79 /     256             ( 30.86%) | total_pruned =     177 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2064 /   32768             (  6.30%) | total_pruned =   30704 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      80 /     256             ( 31.25%) | total_pruned =     176 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1447 /  589824             (  0.25%) | total_pruned =  588377 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1403 /  589824             (  0.24%) | total_pruned =  588421 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     253 /     256             ( 98.83%) | total_pruned =       3 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      64 /     256             ( 25.00%) | total_pruned =     192 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    4525 / 1179648             (  0.38%) | total_pruned = 1175123 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     510 /     512             ( 99.61%) | total_pruned =       2 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     379 /     512             ( 74.02%) | total_pruned =     133 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    3002 / 2359296             (  0.13%) | total_pruned = 2356294 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     504 /     512             ( 98.44%) | total_pruned =       8 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     117 /     512             ( 22.85%) | total_pruned =     395 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1238 /  131072             (  0.94%) | total_pruned =  129834 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     433 /     512             ( 84.57%) | total_pruned =      79 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     124 /     512             ( 24.22%) | total_pruned =     388 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1445 / 2359296             (  0.06%) | total_pruned = 2357851 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     319 /     512             ( 62.30%) | total_pruned =     193 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     695 / 2359296             (  0.03%) | total_pruned = 2358601 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     376 /     512             ( 73.44%) | total_pruned =     136 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    1640 /    5120             ( 32.03%) | total_pruned =    3480 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 43668, pruned : 11135094, total: 11178762, Compression rate :     255.99x  ( 99.61% pruned)
Train Epoch: 40/100 Loss: 0.003387 Accuracy: 81.99 100.00 % Best test Accuracy: 82.16%
tensor(0.0149, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-2.0131e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.337416
Average KL loss: 0.227169
Average total loss: 0.564585
tensor(0.0131, device='cuda:0') tensor(0.0391, device='cuda:0') tensor(-3.3794e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.360263
Average KL loss: 0.206541
Average total loss: 0.566804
tensor(0.0121, device='cuda:0') tensor(0.0375, device='cuda:0') tensor(-3.4817e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.348508
Average KL loss: 0.198090
Average total loss: 0.546598
tensor(0.0116, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-2.0833e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.344658
Average KL loss: 0.195666
Average total loss: 0.540324
tensor(0.0114, device='cuda:0') tensor(0.0370, device='cuda:0') tensor(-1.9823e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.328410
Average KL loss: 0.195384
Average total loss: 0.523794
tensor(0.0113, device='cuda:0') tensor(0.0372, device='cuda:0') tensor(-2.3892e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.316759
Average KL loss: 0.195657
Average total loss: 0.512417
tensor(0.0113, device='cuda:0') tensor(0.0374, device='cuda:0') tensor(-3.8232e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.320191
Average KL loss: 0.196092
Average total loss: 0.516283
tensor(0.0113, device='cuda:0') tensor(0.0376, device='cuda:0') tensor(-3.1305e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.308486
Average KL loss: 0.196610
Average total loss: 0.505096
tensor(0.0114, device='cuda:0') tensor(0.0378, device='cuda:0') tensor(-3.8810e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.321618
Average KL loss: 0.197157
Average total loss: 0.518775
tensor(0.0114, device='cuda:0') tensor(0.0381, device='cuda:0') tensor(-2.6501e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.304514
Average KL loss: 0.197724
Average total loss: 0.502238
tensor(0.0114, device='cuda:0') tensor(0.0383, device='cuda:0') tensor(-4.1169e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.293238
Average KL loss: 0.198261
Average total loss: 0.491499
tensor(0.0115, device='cuda:0') tensor(0.0386, device='cuda:0') tensor(-2.8760e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.288304
Average KL loss: 0.198750
Average total loss: 0.487054
tensor(0.0115, device='cuda:0') tensor(0.0388, device='cuda:0') tensor(-2.3907e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.283660
Average KL loss: 0.199245
Average total loss: 0.482905
tensor(0.0115, device='cuda:0') tensor(0.0390, device='cuda:0') tensor(-3.0069e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.278356
Average KL loss: 0.199746
Average total loss: 0.478102
tensor(0.0116, device='cuda:0') tensor(0.0393, device='cuda:0') tensor(-4.0878e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.266198
Average KL loss: 0.200246
Average total loss: 0.466444
tensor(0.0116, device='cuda:0') tensor(0.0395, device='cuda:0') tensor(-2.3148e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.278252
Average KL loss: 0.200710
Average total loss: 0.478963
tensor(0.0116, device='cuda:0') tensor(0.0397, device='cuda:0') tensor(-1.8032e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.264496
Average KL loss: 0.201159
Average total loss: 0.465655
tensor(0.0117, device='cuda:0') tensor(0.0399, device='cuda:0') tensor(-2.9078e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.259265
Average KL loss: 0.201633
Average total loss: 0.460898
tensor(0.0117, device='cuda:0') tensor(0.0402, device='cuda:0') tensor(-1.7055e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.260984
Average KL loss: 0.202086
Average total loss: 0.463070
tensor(0.0117, device='cuda:0') tensor(0.0404, device='cuda:0') tensor(-1.8320e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.248213
Average KL loss: 0.202534
Average total loss: 0.450747
tensor(0.0118, device='cuda:0') tensor(0.0406, device='cuda:0') tensor(-2.3494e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.256892
Average KL loss: 0.202971
Average total loss: 0.459862
tensor(0.0118, device='cuda:0') tensor(0.0409, device='cuda:0') tensor(-2.0509e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.236410
Average KL loss: 0.203426
Average total loss: 0.439836
tensor(0.0118, device='cuda:0') tensor(0.0411, device='cuda:0') tensor(-2.8094e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.234054
Average KL loss: 0.203855
Average total loss: 0.437909
tensor(0.0119, device='cuda:0') tensor(0.0413, device='cuda:0') tensor(-2.9922e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.239630
Average KL loss: 0.204294
Average total loss: 0.443924
tensor(0.0119, device='cuda:0') tensor(0.0415, device='cuda:0') tensor(-1.4569e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.232546
Average KL loss: 0.204730
Average total loss: 0.437276
tensor(0.0119, device='cuda:0') tensor(0.0418, device='cuda:0') tensor(-2.1955e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.227395
Average KL loss: 0.205154
Average total loss: 0.432549
tensor(0.0120, device='cuda:0') tensor(0.0420, device='cuda:0') tensor(-9.8296e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.234952
Average KL loss: 0.205552
Average total loss: 0.440504
tensor(0.0120, device='cuda:0') tensor(0.0422, device='cuda:0') tensor(-1.9153e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.228334
Average KL loss: 0.205974
Average total loss: 0.434307
tensor(0.0120, device='cuda:0') tensor(0.0424, device='cuda:0') tensor(-3.9017e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.223808
Average KL loss: 0.206404
Average total loss: 0.430212
tensor(0.0121, device='cuda:0') tensor(0.0427, device='cuda:0') tensor(-2.6010e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.215089
Average KL loss: 0.206793
Average total loss: 0.421882
tensor(0.0121, device='cuda:0') tensor(0.0429, device='cuda:0') tensor(-1.2950e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.212729
Average KL loss: 0.207198
Average total loss: 0.419927
tensor(0.0121, device='cuda:0') tensor(0.0431, device='cuda:0') tensor(-1.9232e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.204272
Average KL loss: 0.207585
Average total loss: 0.411856
tensor(0.0121, device='cuda:0') tensor(0.0433, device='cuda:0') tensor(-1.9837e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.204757
Average KL loss: 0.207953
Average total loss: 0.412710
tensor(0.0122, device='cuda:0') tensor(0.0435, device='cuda:0') tensor(-2.2598e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.209629
Average KL loss: 0.208318
Average total loss: 0.417947
tensor(0.0122, device='cuda:0') tensor(0.0437, device='cuda:0') tensor(-1.5010e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.197363
Average KL loss: 0.208716
Average total loss: 0.406079
tensor(0.0122, device='cuda:0') tensor(0.0440, device='cuda:0') tensor(-2.3486e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.195007
Average KL loss: 0.209073
Average total loss: 0.404080
tensor(0.0123, device='cuda:0') tensor(0.0442, device='cuda:0') tensor(-1.9777e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.191460
Average KL loss: 0.209413
Average total loss: 0.400873
tensor(0.0123, device='cuda:0') tensor(0.0444, device='cuda:0') tensor(-2.0106e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.191154
Average KL loss: 0.209764
Average total loss: 0.400918
tensor(0.0123, device='cuda:0') tensor(0.0446, device='cuda:0') tensor(-1.4316e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.187181
Average KL loss: 0.210097
Average total loss: 0.397278
tensor(0.0124, device='cuda:0') tensor(0.0448, device='cuda:0') tensor(-2.0859e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.186261
Average KL loss: 0.210432
Average total loss: 0.396693
tensor(0.0124, device='cuda:0') tensor(0.0450, device='cuda:0') tensor(-1.4528e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.193287
Average KL loss: 0.210770
Average total loss: 0.404057
tensor(0.0124, device='cuda:0') tensor(0.0452, device='cuda:0') tensor(-2.0037e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.187797
Average KL loss: 0.211134
Average total loss: 0.398932
tensor(0.0124, device='cuda:0') tensor(0.0454, device='cuda:0') tensor(-1.6486e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.176964
Average KL loss: 0.211460
Average total loss: 0.388424
tensor(0.0125, device='cuda:0') tensor(0.0456, device='cuda:0') tensor(-1.6177e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.174615
Average KL loss: 0.211792
Average total loss: 0.386407
tensor(0.0125, device='cuda:0') tensor(0.0458, device='cuda:0') tensor(-1.1293e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.170220
Average KL loss: 0.212089
Average total loss: 0.382309
tensor(0.0125, device='cuda:0') tensor(0.0460, device='cuda:0') tensor(-1.1525e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.166809
Average KL loss: 0.212401
Average total loss: 0.379210
tensor(0.0125, device='cuda:0') tensor(0.0462, device='cuda:0') tensor(-1.5325e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.166546
Average KL loss: 0.212704
Average total loss: 0.379250
tensor(0.0126, device='cuda:0') tensor(0.0464, device='cuda:0') tensor(-1.4830e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.167274
Average KL loss: 0.213014
Average total loss: 0.380288
tensor(0.0126, device='cuda:0') tensor(0.0466, device='cuda:0') tensor(-1.3761e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.164938
Average KL loss: 0.213343
Average total loss: 0.378281
tensor(0.0126, device='cuda:0') tensor(0.0468, device='cuda:0') tensor(-1.4612e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.161458
Average KL loss: 0.213663
Average total loss: 0.375120
tensor(0.0127, device='cuda:0') tensor(0.0470, device='cuda:0') tensor(-1.0847e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.155824
Average KL loss: 0.213957
Average total loss: 0.369781
tensor(0.0127, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-2.2965e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.156377
Average KL loss: 0.214254
Average total loss: 0.370631
tensor(0.0127, device='cuda:0') tensor(0.0475, device='cuda:0') tensor(-1.4361e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.156303
Average KL loss: 0.214564
Average total loss: 0.370866
tensor(0.0127, device='cuda:0') tensor(0.0477, device='cuda:0') tensor(-1.8051e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.149428
Average KL loss: 0.214864
Average total loss: 0.364291
tensor(0.0128, device='cuda:0') tensor(0.0479, device='cuda:0') tensor(-1.3507e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.146050
Average KL loss: 0.215120
Average total loss: 0.361169
tensor(0.0128, device='cuda:0') tensor(0.0481, device='cuda:0') tensor(-1.3219e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.150668
Average KL loss: 0.215393
Average total loss: 0.366061
tensor(0.0128, device='cuda:0') tensor(0.0483, device='cuda:0') tensor(-2.1693e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.146921
Average KL loss: 0.215678
Average total loss: 0.362599
tensor(0.0128, device='cuda:0') tensor(0.0485, device='cuda:0') tensor(-1.4032e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.146469
Average KL loss: 0.215963
Average total loss: 0.362432
tensor(0.0129, device='cuda:0') tensor(0.0487, device='cuda:0') tensor(-2.0065e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.141648
Average KL loss: 0.216254
Average total loss: 0.357902
tensor(0.0129, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-1.2876e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.142682
Average KL loss: 0.216529
Average total loss: 0.359211
tensor(0.0129, device='cuda:0') tensor(0.0491, device='cuda:0') tensor(-1.1545e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.140694
Average KL loss: 0.216807
Average total loss: 0.357502
tensor(0.0129, device='cuda:0') tensor(0.0493, device='cuda:0') tensor(-9.5410e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.134895
Average KL loss: 0.217077
Average total loss: 0.351972
tensor(0.0130, device='cuda:0') tensor(0.0495, device='cuda:0') tensor(-1.5118e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.140758
Average KL loss: 0.217354
Average total loss: 0.358111
tensor(0.0130, device='cuda:0') tensor(0.0497, device='cuda:0') tensor(-1.4627e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.136285
Average KL loss: 0.217622
Average total loss: 0.353907
tensor(0.0130, device='cuda:0') tensor(0.0499, device='cuda:0') tensor(-5.6671e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.128121
Average KL loss: 0.217868
Average total loss: 0.345989
tensor(0.0130, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(-9.6621e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.128077
Average KL loss: 0.218102
Average total loss: 0.346178
tensor(0.0131, device='cuda:0') tensor(0.0503, device='cuda:0') tensor(-1.8223e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.127938
Average KL loss: 0.218350
Average total loss: 0.346288
tensor(0.0131, device='cuda:0') tensor(0.0505, device='cuda:0') tensor(-1.0961e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.127609
Average KL loss: 0.218593
Average total loss: 0.346201
tensor(0.0131, device='cuda:0') tensor(0.0507, device='cuda:0') tensor(-1.5024e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.125243
Average KL loss: 0.218850
Average total loss: 0.344093
tensor(0.0131, device='cuda:0') tensor(0.0509, device='cuda:0') tensor(-1.5674e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.123262
Average KL loss: 0.219099
Average total loss: 0.342361
tensor(0.0132, device='cuda:0') tensor(0.0511, device='cuda:0') tensor(-1.0578e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.117194
Average KL loss: 0.219357
Average total loss: 0.336551
tensor(0.0132, device='cuda:0') tensor(0.0512, device='cuda:0') tensor(-1.2636e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.121255
Average KL loss: 0.219587
Average total loss: 0.340842
tensor(0.0132, device='cuda:0') tensor(0.0514, device='cuda:0') tensor(-1.2767e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.119031
Average KL loss: 0.219804
Average total loss: 0.338835
tensor(0.0132, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(-1.6024e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.115352
Average KL loss: 0.220016
Average total loss: 0.335367
tensor(0.0133, device='cuda:0') tensor(0.0518, device='cuda:0') tensor(-8.7747e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.114851
Average KL loss: 0.220224
Average total loss: 0.335075
tensor(0.0133, device='cuda:0') tensor(0.0520, device='cuda:0') tensor(-1.2558e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.116456
Average KL loss: 0.220430
Average total loss: 0.336887
tensor(0.0133, device='cuda:0') tensor(0.0522, device='cuda:0') tensor(-1.0815e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.115995
Average KL loss: 0.220650
Average total loss: 0.336645
tensor(0.0133, device='cuda:0') tensor(0.0524, device='cuda:0') tensor(-7.0953e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.108205
Average KL loss: 0.220867
Average total loss: 0.329072
tensor(0.0134, device='cuda:0') tensor(0.0526, device='cuda:0') tensor(-7.3856e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.106513
Average KL loss: 0.221059
Average total loss: 0.327572
tensor(0.0134, device='cuda:0') tensor(0.0527, device='cuda:0') tensor(-9.3501e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.106700
Average KL loss: 0.221245
Average total loss: 0.327945
tensor(0.0134, device='cuda:0') tensor(0.0529, device='cuda:0') tensor(-9.1136e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.102134
Average KL loss: 0.221437
Average total loss: 0.323572
tensor(0.0134, device='cuda:0') tensor(0.0531, device='cuda:0') tensor(-1.1406e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.109277
Average KL loss: 0.221642
Average total loss: 0.330920
tensor(0.0134, device='cuda:0') tensor(0.0533, device='cuda:0') tensor(-1.0441e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.105290
Average KL loss: 0.221856
Average total loss: 0.327146
tensor(0.0135, device='cuda:0') tensor(0.0535, device='cuda:0') tensor(-1.1721e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.100471
Average KL loss: 0.222067
Average total loss: 0.322538
tensor(0.0135, device='cuda:0') tensor(0.0537, device='cuda:0') tensor(-1.0095e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.098918
Average KL loss: 0.222254
Average total loss: 0.321172
tensor(0.0135, device='cuda:0') tensor(0.0538, device='cuda:0') tensor(-9.9601e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.104806
Average KL loss: 0.222435
Average total loss: 0.327240
tensor(0.0135, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(-8.5222e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.102312
Average KL loss: 0.222613
Average total loss: 0.324925
tensor(0.0135, device='cuda:0') tensor(0.0542, device='cuda:0') tensor(-1.0687e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.103520
Average KL loss: 0.222799
Average total loss: 0.326319
tensor(0.0136, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-6.4031e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.097129
Average KL loss: 0.222983
Average total loss: 0.320112
tensor(0.0136, device='cuda:0') tensor(0.0546, device='cuda:0') tensor(-8.4296e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.094109
Average KL loss: 0.223164
Average total loss: 0.317273
tensor(0.0136, device='cuda:0') tensor(0.0548, device='cuda:0') tensor(-9.2518e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.100935
Average KL loss: 0.223337
Average total loss: 0.324272
tensor(0.0136, device='cuda:0') tensor(0.0550, device='cuda:0') tensor(-5.0945e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.097671
Average KL loss: 0.223516
Average total loss: 0.321187
tensor(0.0137, device='cuda:0') tensor(0.0552, device='cuda:0') tensor(-9.7326e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.097860
Average KL loss: 0.223712
Average total loss: 0.321572
tensor(0.0137, device='cuda:0') tensor(0.0553, device='cuda:0') tensor(-1.1126e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.095901
Average KL loss: 0.223912
Average total loss: 0.319813
tensor(0.0137, device='cuda:0') tensor(0.0555, device='cuda:0') tensor(-6.1950e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.092828
Average KL loss: 0.224098
Average total loss: 0.316926
tensor(0.0137, device='cuda:0') tensor(0.0557, device='cuda:0') tensor(-7.4174e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.091649
Average KL loss: 0.224260
Average total loss: 0.315910
tensor(0.0137, device='cuda:0') tensor(0.0559, device='cuda:0') tensor(-1.1190e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.088215
Average KL loss: 0.224438
Average total loss: 0.312653
tensor(0.0138, device='cuda:0') tensor(0.0561, device='cuda:0') tensor(-6.4548e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.081936
Average KL loss: 0.224588
Average total loss: 0.306525
tensor(0.0138, device='cuda:0') tensor(0.0562, device='cuda:0') tensor(-9.6502e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.086932
Average KL loss: 0.224714
Average total loss: 0.311646
tensor(0.0138, device='cuda:0') tensor(0.0564, device='cuda:0') tensor(-3.7725e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.091492
Average KL loss: 0.224865
Average total loss: 0.316357
tensor(0.0138, device='cuda:0') tensor(0.0566, device='cuda:0') tensor(-7.5667e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.087178
Average KL loss: 0.225003
Average total loss: 0.312181
tensor(0.0138, device='cuda:0') tensor(0.0568, device='cuda:0') tensor(-8.2255e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.086899
Average KL loss: 0.225138
Average total loss: 0.312037
tensor(0.0139, device='cuda:0') tensor(0.0569, device='cuda:0') tensor(-6.8638e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.087590
Average KL loss: 0.225283
Average total loss: 0.312874
tensor(0.0139, device='cuda:0') tensor(0.0571, device='cuda:0') tensor(-7.6454e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.084204
Average KL loss: 0.225440
Average total loss: 0.309645
tensor(0.0139, device='cuda:0') tensor(0.0573, device='cuda:0') tensor(-7.0816e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.081546
Average KL loss: 0.225562
Average total loss: 0.307108
tensor(0.0139, device='cuda:0') tensor(0.0575, device='cuda:0') tensor(-1.0837e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.084132
Average KL loss: 0.225712
Average total loss: 0.309844
tensor(0.0139, device='cuda:0') tensor(0.0576, device='cuda:0') tensor(-9.7571e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.077923
Average KL loss: 0.225847
Average total loss: 0.303769
tensor(0.0140, device='cuda:0') tensor(0.0578, device='cuda:0') tensor(-1.1207e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.079349
Average KL loss: 0.225980
Average total loss: 0.305329
tensor(0.0140, device='cuda:0') tensor(0.0580, device='cuda:0') tensor(-8.4589e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.078283
Average KL loss: 0.226118
Average total loss: 0.304401
tensor(0.0140, device='cuda:0') tensor(0.0581, device='cuda:0') tensor(-6.6196e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.078303
Average KL loss: 0.226238
Average total loss: 0.304541
tensor(0.0140, device='cuda:0') tensor(0.0583, device='cuda:0') tensor(-6.8201e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.078961
Average KL loss: 0.226373
Average total loss: 0.305334
tensor(0.0140, device='cuda:0') tensor(0.0585, device='cuda:0') tensor(-6.7591e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.075318
Average KL loss: 0.226497
Average total loss: 0.301815
tensor(0.0141, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-3.2435e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.072338
Average KL loss: 0.226611
Average total loss: 0.298949
tensor(0.0141, device='cuda:0') tensor(0.0588, device='cuda:0') tensor(-9.2902e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.074422
Average KL loss: 0.226724
Average total loss: 0.301146
tensor(0.0141, device='cuda:0') tensor(0.0590, device='cuda:0') tensor(-2.7777e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.076546
Average KL loss: 0.226842
Average total loss: 0.303388
tensor(0.0141, device='cuda:0') tensor(0.0592, device='cuda:0') tensor(-1.7971e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.073996
Average KL loss: 0.226956
Average total loss: 0.300951
tensor(0.0141, device='cuda:0') tensor(0.0593, device='cuda:0') tensor(-6.5163e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.075896
Average KL loss: 0.227081
Average total loss: 0.302977
tensor(0.0141, device='cuda:0') tensor(0.0595, device='cuda:0') tensor(-3.2848e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.074625
Average KL loss: 0.227236
Average total loss: 0.301861
tensor(0.0142, device='cuda:0') tensor(0.0597, device='cuda:0') tensor(-6.4626e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.073477
Average KL loss: 0.227371
Average total loss: 0.300849
tensor(0.0142, device='cuda:0') tensor(0.0598, device='cuda:0') tensor(-3.9208e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.070503
Average KL loss: 0.227491
Average total loss: 0.297994
tensor(0.0142, device='cuda:0') tensor(0.0600, device='cuda:0') tensor(-5.1864e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.071831
Average KL loss: 0.227609
Average total loss: 0.299440
tensor(0.0142, device='cuda:0') tensor(0.0602, device='cuda:0') tensor(-5.7028e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.069677
Average KL loss: 0.227694
Average total loss: 0.297371
tensor(0.0142, device='cuda:0') tensor(0.0603, device='cuda:0') tensor(-8.7833e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.070836
Average KL loss: 0.227804
Average total loss: 0.298640
tensor(0.0143, device='cuda:0') tensor(0.0605, device='cuda:0') tensor(-3.2377e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.069781
Average KL loss: 0.227902
Average total loss: 0.297683
tensor(0.0143, device='cuda:0') tensor(0.0607, device='cuda:0') tensor(-5.0473e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.067565
Average KL loss: 0.228013
Average total loss: 0.295578
tensor(0.0143, device='cuda:0') tensor(0.0608, device='cuda:0') tensor(-2.2603e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.066931
Average KL loss: 0.228111
Average total loss: 0.295042
tensor(0.0143, device='cuda:0') tensor(0.0610, device='cuda:0') tensor(-4.5665e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.062946
Average KL loss: 0.228231
Average total loss: 0.291177
tensor(0.0143, device='cuda:0') tensor(0.0612, device='cuda:0') tensor(-9.0371e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.066060
Average KL loss: 0.228339
Average total loss: 0.294399
tensor(0.0143, device='cuda:0') tensor(0.0613, device='cuda:0') tensor(-6.0133e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.063041
Average KL loss: 0.228424
Average total loss: 0.291465
tensor(0.0144, device='cuda:0') tensor(0.0615, device='cuda:0') tensor(-5.5236e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.066172
Average KL loss: 0.228519
Average total loss: 0.294690
tensor(0.0144, device='cuda:0') tensor(0.0616, device='cuda:0') tensor(-8.9529e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.063085
Average KL loss: 0.228618
Average total loss: 0.291703
tensor(0.0144, device='cuda:0') tensor(0.0618, device='cuda:0') tensor(-6.8383e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.062834
Average KL loss: 0.228712
Average total loss: 0.291546
tensor(0.0144, device='cuda:0') tensor(0.0620, device='cuda:0') tensor(-4.0227e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.060660
Average KL loss: 0.228822
Average total loss: 0.289482
tensor(0.0144, device='cuda:0') tensor(0.0621, device='cuda:0') tensor(-5.4500e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.063950
Average KL loss: 0.228913
Average total loss: 0.292863
tensor(0.0144, device='cuda:0') tensor(0.0623, device='cuda:0') tensor(-2.8546e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.064165
Average KL loss: 0.229016
Average total loss: 0.293181
tensor(0.0145, device='cuda:0') tensor(0.0624, device='cuda:0') tensor(-5.9080e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.062450
Average KL loss: 0.229124
Average total loss: 0.291575
tensor(0.0145, device='cuda:0') tensor(0.0626, device='cuda:0') tensor(-4.4215e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.063530
Average KL loss: 0.229217
Average total loss: 0.292747
tensor(0.0145, device='cuda:0') tensor(0.0628, device='cuda:0') tensor(-2.1505e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.061521
Average KL loss: 0.229309
Average total loss: 0.290830
tensor(0.0145, device='cuda:0') tensor(0.0629, device='cuda:0') tensor(-5.1790e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.060707
Average KL loss: 0.229382
Average total loss: 0.290090
tensor(0.0145, device='cuda:0') tensor(0.0631, device='cuda:0') tensor(-5.7343e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.061066
Average KL loss: 0.229472
Average total loss: 0.290538
tensor(0.0145, device='cuda:0') tensor(0.0632, device='cuda:0') tensor(-8.3624e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.057703
Average KL loss: 0.229565
Average total loss: 0.287268
tensor(0.0146, device='cuda:0') tensor(0.0634, device='cuda:0') tensor(-3.2349e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.058385
Average KL loss: 0.229624
Average total loss: 0.288009
tensor(0.0146, device='cuda:0') tensor(0.0635, device='cuda:0') tensor(-5.7328e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.060585
Average KL loss: 0.229693
Average total loss: 0.290278
tensor(0.0146, device='cuda:0') tensor(0.0637, device='cuda:0') tensor(-3.3121e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.058501
Average KL loss: 0.229777
Average total loss: 0.288278
tensor(0.0146, device='cuda:0') tensor(0.0638, device='cuda:0') tensor(-5.7818e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.058575
Average KL loss: 0.229851
Average total loss: 0.288426
tensor(0.0146, device='cuda:0') tensor(0.0640, device='cuda:0') tensor(-4.2154e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.056606
Average KL loss: 0.229937
Average total loss: 0.286543
tensor(0.0146, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-7.2681e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.056444
Average KL loss: 0.230009
Average total loss: 0.286453
tensor(0.0147, device='cuda:0') tensor(0.0643, device='cuda:0') tensor(-6.3291e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.056585
Average KL loss: 0.230085
Average total loss: 0.286671
tensor(0.0147, device='cuda:0') tensor(0.0645, device='cuda:0') tensor(-4.2110e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.054507
Average KL loss: 0.230163
Average total loss: 0.284670
tensor(0.0147, device='cuda:0') tensor(0.0646, device='cuda:0') tensor(-1.9335e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.056552
Average KL loss: 0.230234
Average total loss: 0.286786
tensor(0.0147, device='cuda:0') tensor(0.0648, device='cuda:0') tensor(-3.5060e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.056160
Average KL loss: 0.230307
Average total loss: 0.286466
tensor(0.0147, device='cuda:0') tensor(0.0650, device='cuda:0') tensor(-1.3666e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.055833
Average KL loss: 0.230399
Average total loss: 0.286232
tensor(0.0147, device='cuda:0') tensor(0.0651, device='cuda:0') tensor(-2.6871e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.055466
Average KL loss: 0.230489
Average total loss: 0.285955
tensor(0.0147, device='cuda:0') tensor(0.0653, device='cuda:0') tensor(-8.9465e-10, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.051373
Average KL loss: 0.230568
Average total loss: 0.281941
tensor(0.0148, device='cuda:0') tensor(0.0654, device='cuda:0') tensor(-3.8803e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.053901
Average KL loss: 0.230649
Average total loss: 0.284550
tensor(0.0148, device='cuda:0') tensor(0.0656, device='cuda:0') tensor(-2.9223e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.052781
Average KL loss: 0.230709
Average total loss: 0.283491
tensor(0.0148, device='cuda:0') tensor(0.0657, device='cuda:0') tensor(-4.2462e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.050450
Average KL loss: 0.230772
Average total loss: 0.281223
tensor(0.0148, device='cuda:0') tensor(0.0659, device='cuda:0') tensor(-1.9388e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.052652
Average KL loss: 0.230833
Average total loss: 0.283485
tensor(0.0148, device='cuda:0') tensor(0.0660, device='cuda:0') tensor(-3.2793e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.050622
Average KL loss: 0.230897
Average total loss: 0.281519
tensor(0.0148, device='cuda:0') tensor(0.0662, device='cuda:0') tensor(-2.1421e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.050952
Average KL loss: 0.230951
Average total loss: 0.281903
tensor(0.0149, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-2.0150e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.051705
Average KL loss: 0.231005
Average total loss: 0.282711
tensor(0.0149, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-4.3114e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.047214
Average KL loss: 0.231068
Average total loss: 0.278281
tensor(0.0149, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-9.2830e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.051499
Average KL loss: 0.231116
Average total loss: 0.282615
tensor(0.0149, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-1.1649e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.050019
Average KL loss: 0.231175
Average total loss: 0.281194
tensor(0.0149, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-4.7138e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.050301
Average KL loss: 0.231229
Average total loss: 0.281530
tensor(0.0149, device='cuda:0') tensor(0.0671, device='cuda:0') tensor(-4.6995e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.049072
Average KL loss: 0.231290
Average total loss: 0.280362
tensor(0.0149, device='cuda:0') tensor(0.0672, device='cuda:0') tensor(-3.6884e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.048636
Average KL loss: 0.231354
Average total loss: 0.279990
tensor(0.0150, device='cuda:0') tensor(0.0674, device='cuda:0') tensor(-2.9724e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.047049
Average KL loss: 0.231407
Average total loss: 0.278455
tensor(0.0150, device='cuda:0') tensor(0.0675, device='cuda:0') tensor(-2.2699e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.050506
Average KL loss: 0.231456
Average total loss: 0.281962
tensor(0.0150, device='cuda:0') tensor(0.0677, device='cuda:0') tensor(-3.4453e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.048624
Average KL loss: 0.231522
Average total loss: 0.280146
tensor(0.0150, device='cuda:0') tensor(0.0678, device='cuda:0') tensor(-1.5887e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.047113
Average KL loss: 0.231594
Average total loss: 0.278707
tensor(0.0150, device='cuda:0') tensor(0.0680, device='cuda:0') tensor(-5.7430e-10, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.047412
Average KL loss: 0.231646
Average total loss: 0.279058
tensor(0.0150, device='cuda:0') tensor(0.0681, device='cuda:0') tensor(-3.6470e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.047542
Average KL loss: 0.231713
Average total loss: 0.279255
tensor(0.0150, device='cuda:0') tensor(0.0683, device='cuda:0') tensor(-2.2032e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.047536
Average KL loss: 0.231743
Average total loss: 0.279279
tensor(0.0150, device='cuda:0') tensor(0.0683, device='cuda:0') tensor(-3.2950e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.045970
Average KL loss: 0.231751
Average total loss: 0.277721
tensor(0.0150, device='cuda:0') tensor(0.0683, device='cuda:0') tensor(-2.8883e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.046744
Average KL loss: 0.231757
Average total loss: 0.278501
tensor(0.0150, device='cuda:0') tensor(0.0683, device='cuda:0') tensor(-3.1249e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.049240
Average KL loss: 0.231762
Average total loss: 0.281002
tensor(0.0150, device='cuda:0') tensor(0.0683, device='cuda:0') tensor(-4.2089e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.048644
Average KL loss: 0.231770
Average total loss: 0.280414
tensor(0.0150, device='cuda:0') tensor(0.0683, device='cuda:0') tensor(-1.7605e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.048036
Average KL loss: 0.231776
Average total loss: 0.279811
tensor(0.0150, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(-4.0015e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.045680
Average KL loss: 0.231779
Average total loss: 0.277460
tensor(0.0151, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(-3.3664e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.043888
Average KL loss: 0.231783
Average total loss: 0.275671
tensor(0.0151, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(-4.0280e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.045466
Average KL loss: 0.231787
Average total loss: 0.277253
tensor(0.0151, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(-1.6046e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.045787
Average KL loss: 0.231791
Average total loss: 0.277578
tensor(0.0151, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(-2.2852e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.047462
Average KL loss: 0.231798
Average total loss: 0.279260
tensor(0.0151, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(-2.9409e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.046437
Average KL loss: 0.231806
Average total loss: 0.278243
tensor(0.0151, device='cuda:0') tensor(0.0684, device='cuda:0') tensor(-2.7331e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.047218
Average KL loss: 0.231813
Average total loss: 0.279031
tensor(0.0151, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-2.9912e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.051219
Average KL loss: 0.231821
Average total loss: 0.283039
tensor(0.0151, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-5.5171e-10, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.046247
Average KL loss: 0.231828
Average total loss: 0.278076
tensor(0.0151, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-2.7493e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.048505
Average KL loss: 0.231834
Average total loss: 0.280340
tensor(0.0151, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-2.7886e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.049702
Average KL loss: 0.231840
Average total loss: 0.281543
tensor(0.0151, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-6.5961e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.049178
Average KL loss: 0.231847
Average total loss: 0.281025
tensor(0.0151, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-2.8590e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.047265
Average KL loss: 0.231854
Average total loss: 0.279119
tensor(0.0151, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-1.9964e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.047400
Average KL loss: 0.231857
Average total loss: 0.279257
tensor(0.0151, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-3.5233e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.048092
Average KL loss: 0.231858
Average total loss: 0.279950
tensor(0.0151, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-1.1315e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.043472
Average KL loss: 0.231858
Average total loss: 0.275331
tensor(0.0151, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-2.0678e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.046575
Average KL loss: 0.231859
Average total loss: 0.278434
tensor(0.0151, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-1.6926e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.045432
Average KL loss: 0.231859
Average total loss: 0.277291
tensor(0.0151, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-4.6754e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.046034
Average KL loss: 0.231860
Average total loss: 0.277894
tensor(0.0151, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-2.5335e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.045305
Average KL loss: 0.231860
Average total loss: 0.277166
tensor(0.0151, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-4.8184e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.046922
Average KL loss: 0.231861
Average total loss: 0.278783
 Percentile value: 4.879164457321167
Non-zero model percentage: 0.19531679153442383%, Non-zero mask percentage: 0.19531679153442383%

--- Pruning Level [9/12]: ---
conv1.weight         | nonzeros =     793 /    1728             ( 45.89%) | total_pruned =     935 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
bn1.bias             | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     616 /   36864             (  1.67%) | total_pruned =   36248 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     735 /   36864             (  1.99%) | total_pruned =   36129 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     552 /   36864             (  1.50%) | total_pruned =   36312 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     616 /   36864             (  1.67%) | total_pruned =   36248 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     887 /   73728             (  1.20%) | total_pruned =   72841 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      19 /     128             ( 14.84%) | total_pruned =     109 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1071 /  147456             (  0.73%) | total_pruned =  146385 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     856 /    8192             ( 10.45%) | total_pruned =    7336 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     601 /  147456             (  0.41%) | total_pruned =  146855 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     117 /     128             ( 91.41%) | total_pruned =      11 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     517 /  147456             (  0.35%) | total_pruned =  146939 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1526 /  294912             (  0.52%) | total_pruned =  293386 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1591 /  589824             (  0.27%) | total_pruned =  588233 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      28 /     256             ( 10.94%) | total_pruned =     228 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1017 /   32768             (  3.10%) | total_pruned =   31751 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     542 /  589824             (  0.09%) | total_pruned =  589282 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     190 /     256             ( 74.22%) | total_pruned =      66 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      33 /     256             ( 12.89%) | total_pruned =     223 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     518 /  589824             (  0.09%) | total_pruned =  589306 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      24 /     256             (  9.38%) | total_pruned =     232 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    1523 / 1179648             (  0.13%) | total_pruned = 1178125 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     466 /     512             ( 91.02%) | total_pruned =      46 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     200 /     512             ( 39.06%) | total_pruned =     312 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     945 / 2359296             (  0.04%) | total_pruned = 2358351 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     447 /     512             ( 87.30%) | total_pruned =      65 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     446 /  131072             (  0.34%) | total_pruned =  130626 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     315 /     512             ( 61.52%) | total_pruned =     197 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     533 / 2359296             (  0.02%) | total_pruned = 2358763 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     222 /     512             ( 43.36%) | total_pruned =     290 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     256 / 2359296             (  0.01%) | total_pruned = 2359040 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     288 /     512             ( 56.25%) | total_pruned =     224 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    1140 /    5120             ( 22.27%) | total_pruned =    3980 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 21834, pruned : 11156928, total: 11178762, Compression rate :     511.99x  ( 99.80% pruned)
Train Epoch: 99/100 Loss: 0.254979 Accuracy: 76.15 95.77 % Best test Accuracy: 76.84%
tensor(0.0151, device='cuda:0') tensor(0.0685, device='cuda:0') tensor(-1.9094e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.316434
Average KL loss: 0.223568
Average total loss: 0.540002
tensor(0.0137, device='cuda:0') tensor(0.0586, device='cuda:0') tensor(-1.5098e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.344969
Average KL loss: 0.205861
Average total loss: 0.550829
tensor(0.0125, device='cuda:0') tensor(0.0521, device='cuda:0') tensor(-9.6553e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.355145
Average KL loss: 0.185826
Average total loss: 0.540972
tensor(0.0114, device='cuda:0') tensor(0.0476, device='cuda:0') tensor(-1.4072e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.361168
Average KL loss: 0.164907
Average total loss: 0.526075
tensor(0.0105, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-2.1833e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.375399
Average KL loss: 0.147419
Average total loss: 0.522817
tensor(0.0097, device='cuda:0') tensor(0.0432, device='cuda:0') tensor(-1.6676e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.383026
Average KL loss: 0.137007
Average total loss: 0.520033
tensor(0.0092, device='cuda:0') tensor(0.0427, device='cuda:0') tensor(-1.0709e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.365855
Average KL loss: 0.132751
Average total loss: 0.498605
tensor(0.0090, device='cuda:0') tensor(0.0426, device='cuda:0') tensor(-1.8625e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.367810
Average KL loss: 0.131530
Average total loss: 0.499341
tensor(0.0088, device='cuda:0') tensor(0.0427, device='cuda:0') tensor(-1.2407e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.364337
Average KL loss: 0.131303
Average total loss: 0.495640
tensor(0.0088, device='cuda:0') tensor(0.0429, device='cuda:0') tensor(-1.9089e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.358439
Average KL loss: 0.131300
Average total loss: 0.489739
tensor(0.0088, device='cuda:0') tensor(0.0430, device='cuda:0') tensor(-1.9338e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.350107
Average KL loss: 0.131327
Average total loss: 0.481434
tensor(0.0088, device='cuda:0') tensor(0.0432, device='cuda:0') tensor(-1.3362e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.346471
Average KL loss: 0.131354
Average total loss: 0.477826
tensor(0.0088, device='cuda:0') tensor(0.0434, device='cuda:0') tensor(-1.5162e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.351169
Average KL loss: 0.131383
Average total loss: 0.482551
tensor(0.0089, device='cuda:0') tensor(0.0436, device='cuda:0') tensor(-9.7690e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.345522
Average KL loss: 0.131423
Average total loss: 0.476945
tensor(0.0089, device='cuda:0') tensor(0.0438, device='cuda:0') tensor(-2.0366e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.334373
Average KL loss: 0.131467
Average total loss: 0.465840
tensor(0.0089, device='cuda:0') tensor(0.0439, device='cuda:0') tensor(-1.8564e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.350561
Average KL loss: 0.131506
Average total loss: 0.482067
tensor(0.0089, device='cuda:0') tensor(0.0441, device='cuda:0') tensor(-1.3751e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.337009
Average KL loss: 0.131550
Average total loss: 0.468560
tensor(0.0089, device='cuda:0') tensor(0.0443, device='cuda:0') tensor(-1.0690e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.321864
Average KL loss: 0.131590
Average total loss: 0.453454
tensor(0.0089, device='cuda:0') tensor(0.0445, device='cuda:0') tensor(-1.7218e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.334612
Average KL loss: 0.131629
Average total loss: 0.466241
tensor(0.0090, device='cuda:0') tensor(0.0447, device='cuda:0') tensor(-1.7577e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.325725
Average KL loss: 0.131657
Average total loss: 0.457381
tensor(0.0090, device='cuda:0') tensor(0.0449, device='cuda:0') tensor(-1.4282e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.326010
Average KL loss: 0.131682
Average total loss: 0.457692
tensor(0.0090, device='cuda:0') tensor(0.0450, device='cuda:0') tensor(-1.4280e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.317444
Average KL loss: 0.131717
Average total loss: 0.449161
tensor(0.0090, device='cuda:0') tensor(0.0452, device='cuda:0') tensor(-6.4448e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.333593
Average KL loss: 0.131747
Average total loss: 0.465341
tensor(0.0090, device='cuda:0') tensor(0.0454, device='cuda:0') tensor(-1.6377e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.316059
Average KL loss: 0.131776
Average total loss: 0.447835
tensor(0.0090, device='cuda:0') tensor(0.0456, device='cuda:0') tensor(-1.2230e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.311536
Average KL loss: 0.131797
Average total loss: 0.443334
tensor(0.0091, device='cuda:0') tensor(0.0458, device='cuda:0') tensor(-1.5527e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.296842
Average KL loss: 0.131827
Average total loss: 0.428669
tensor(0.0091, device='cuda:0') tensor(0.0459, device='cuda:0') tensor(-8.3216e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.296952
Average KL loss: 0.131855
Average total loss: 0.428807
tensor(0.0091, device='cuda:0') tensor(0.0461, device='cuda:0') tensor(-1.3462e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.312637
Average KL loss: 0.131874
Average total loss: 0.444511
tensor(0.0091, device='cuda:0') tensor(0.0463, device='cuda:0') tensor(-1.3381e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.301951
Average KL loss: 0.131909
Average total loss: 0.433860
tensor(0.0091, device='cuda:0') tensor(0.0465, device='cuda:0') tensor(-1.2801e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.297146
Average KL loss: 0.131938
Average total loss: 0.429084
tensor(0.0091, device='cuda:0') tensor(0.0467, device='cuda:0') tensor(-1.5031e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.300271
Average KL loss: 0.131967
Average total loss: 0.432238
tensor(0.0092, device='cuda:0') tensor(0.0469, device='cuda:0') tensor(-1.6003e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.287729
Average KL loss: 0.131996
Average total loss: 0.419725
tensor(0.0092, device='cuda:0') tensor(0.0471, device='cuda:0') tensor(-1.0632e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.299102
Average KL loss: 0.132020
Average total loss: 0.431122
tensor(0.0092, device='cuda:0') tensor(0.0473, device='cuda:0') tensor(-2.0383e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.295400
Average KL loss: 0.132040
Average total loss: 0.427441
tensor(0.0092, device='cuda:0') tensor(0.0474, device='cuda:0') tensor(-2.1719e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.272831
Average KL loss: 0.132060
Average total loss: 0.404891
tensor(0.0092, device='cuda:0') tensor(0.0476, device='cuda:0') tensor(-1.3219e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.284391
Average KL loss: 0.132081
Average total loss: 0.416473
tensor(0.0092, device='cuda:0') tensor(0.0478, device='cuda:0') tensor(-1.2972e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.279277
Average KL loss: 0.132101
Average total loss: 0.411377
tensor(0.0093, device='cuda:0') tensor(0.0480, device='cuda:0') tensor(-9.0491e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.267924
Average KL loss: 0.132123
Average total loss: 0.400047
tensor(0.0093, device='cuda:0') tensor(0.0482, device='cuda:0') tensor(-1.4478e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.280130
Average KL loss: 0.132138
Average total loss: 0.412267
tensor(0.0093, device='cuda:0') tensor(0.0483, device='cuda:0') tensor(-1.6298e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.265439
Average KL loss: 0.132151
Average total loss: 0.397590
tensor(0.0093, device='cuda:0') tensor(0.0485, device='cuda:0') tensor(-1.0153e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.271746
Average KL loss: 0.132171
Average total loss: 0.403917
tensor(0.0093, device='cuda:0') tensor(0.0487, device='cuda:0') tensor(-1.5136e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.273349
Average KL loss: 0.132186
Average total loss: 0.405535
tensor(0.0093, device='cuda:0') tensor(0.0489, device='cuda:0') tensor(-1.1088e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.269823
Average KL loss: 0.132200
Average total loss: 0.402024
tensor(0.0093, device='cuda:0') tensor(0.0491, device='cuda:0') tensor(-1.2243e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.272238
Average KL loss: 0.132217
Average total loss: 0.404455
tensor(0.0094, device='cuda:0') tensor(0.0492, device='cuda:0') tensor(-2.0793e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.264682
Average KL loss: 0.132234
Average total loss: 0.396916
tensor(0.0094, device='cuda:0') tensor(0.0494, device='cuda:0') tensor(-1.4619e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.260905
Average KL loss: 0.132253
Average total loss: 0.393158
tensor(0.0094, device='cuda:0') tensor(0.0496, device='cuda:0') tensor(-1.2259e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.258750
Average KL loss: 0.132276
Average total loss: 0.391026
tensor(0.0094, device='cuda:0') tensor(0.0498, device='cuda:0') tensor(-1.2695e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.258621
Average KL loss: 0.132298
Average total loss: 0.390919
tensor(0.0094, device='cuda:0') tensor(0.0499, device='cuda:0') tensor(-7.5683e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.258059
Average KL loss: 0.132317
Average total loss: 0.390376
tensor(0.0094, device='cuda:0') tensor(0.0501, device='cuda:0') tensor(-1.0946e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.256433
Average KL loss: 0.132336
Average total loss: 0.388769
tensor(0.0095, device='cuda:0') tensor(0.0503, device='cuda:0') tensor(-5.2880e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.257535
Average KL loss: 0.132357
Average total loss: 0.389892
tensor(0.0095, device='cuda:0') tensor(0.0505, device='cuda:0') tensor(-1.0746e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.259058
Average KL loss: 0.132382
Average total loss: 0.391440
tensor(0.0095, device='cuda:0') tensor(0.0507, device='cuda:0') tensor(-9.6711e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.250618
Average KL loss: 0.132406
Average total loss: 0.383024
tensor(0.0095, device='cuda:0') tensor(0.0509, device='cuda:0') tensor(-1.1455e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.251292
Average KL loss: 0.132425
Average total loss: 0.383717
tensor(0.0095, device='cuda:0') tensor(0.0510, device='cuda:0') tensor(-6.4438e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.243733
Average KL loss: 0.132451
Average total loss: 0.376184
tensor(0.0095, device='cuda:0') tensor(0.0512, device='cuda:0') tensor(-5.2039e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.255716
Average KL loss: 0.132474
Average total loss: 0.388190
tensor(0.0095, device='cuda:0') tensor(0.0514, device='cuda:0') tensor(-8.1800e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.257359
Average KL loss: 0.132496
Average total loss: 0.389856
tensor(0.0096, device='cuda:0') tensor(0.0516, device='cuda:0') tensor(-1.1609e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.247859
Average KL loss: 0.132523
Average total loss: 0.380382
tensor(0.0096, device='cuda:0') tensor(0.0518, device='cuda:0') tensor(-8.8284e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.251006
Average KL loss: 0.132545
Average total loss: 0.383551
tensor(0.0096, device='cuda:0') tensor(0.0519, device='cuda:0') tensor(-1.7025e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.242426
Average KL loss: 0.132565
Average total loss: 0.374992
tensor(0.0096, device='cuda:0') tensor(0.0521, device='cuda:0') tensor(-9.1312e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.240977
Average KL loss: 0.132581
Average total loss: 0.373558
tensor(0.0096, device='cuda:0') tensor(0.0523, device='cuda:0') tensor(-1.8589e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.245785
Average KL loss: 0.132604
Average total loss: 0.378389
tensor(0.0096, device='cuda:0') tensor(0.0525, device='cuda:0') tensor(-8.6940e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.230784
Average KL loss: 0.132617
Average total loss: 0.363401
tensor(0.0097, device='cuda:0') tensor(0.0527, device='cuda:0') tensor(-7.4672e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.237432
Average KL loss: 0.132632
Average total loss: 0.370065
tensor(0.0097, device='cuda:0') tensor(0.0528, device='cuda:0') tensor(-7.6675e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.236912
Average KL loss: 0.132650
Average total loss: 0.369562
tensor(0.0097, device='cuda:0') tensor(0.0530, device='cuda:0') tensor(-9.9962e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.238655
Average KL loss: 0.132662
Average total loss: 0.371317
tensor(0.0097, device='cuda:0') tensor(0.0532, device='cuda:0') tensor(-7.7004e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.242656
Average KL loss: 0.132678
Average total loss: 0.375333
tensor(0.0097, device='cuda:0') tensor(0.0534, device='cuda:0') tensor(-5.9120e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.235085
Average KL loss: 0.132693
Average total loss: 0.367778
tensor(0.0097, device='cuda:0') tensor(0.0535, device='cuda:0') tensor(-1.6585e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.229205
Average KL loss: 0.132712
Average total loss: 0.361917
tensor(0.0097, device='cuda:0') tensor(0.0537, device='cuda:0') tensor(-8.2999e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.230388
Average KL loss: 0.132726
Average total loss: 0.363114
tensor(0.0098, device='cuda:0') tensor(0.0539, device='cuda:0') tensor(-2.7274e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.229749
Average KL loss: 0.132739
Average total loss: 0.362488
tensor(0.0098, device='cuda:0') tensor(0.0540, device='cuda:0') tensor(-8.3370e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.230018
Average KL loss: 0.132755
Average total loss: 0.362773
tensor(0.0098, device='cuda:0') tensor(0.0542, device='cuda:0') tensor(-6.1399e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.222926
Average KL loss: 0.132766
Average total loss: 0.355692
tensor(0.0098, device='cuda:0') tensor(0.0544, device='cuda:0') tensor(-3.4297e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.226809
Average KL loss: 0.132778
Average total loss: 0.359586
tensor(0.0098, device='cuda:0') tensor(0.0546, device='cuda:0') tensor(-3.6005e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.229721
Average KL loss: 0.132788
Average total loss: 0.362509
tensor(0.0098, device='cuda:0') tensor(0.0547, device='cuda:0') tensor(-1.2383e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.233555
Average KL loss: 0.132802
Average total loss: 0.366357
tensor(0.0098, device='cuda:0') tensor(0.0549, device='cuda:0') tensor(-7.1743e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.228013
Average KL loss: 0.132814
Average total loss: 0.360828
tensor(0.0099, device='cuda:0') tensor(0.0551, device='cuda:0') tensor(-3.8880e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.225108
Average KL loss: 0.132826
Average total loss: 0.357935
tensor(0.0099, device='cuda:0') tensor(0.0552, device='cuda:0') tensor(-7.8930e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.222670
Average KL loss: 0.132842
Average total loss: 0.355512
tensor(0.0099, device='cuda:0') tensor(0.0554, device='cuda:0') tensor(-6.8894e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.221341
Average KL loss: 0.132853
Average total loss: 0.354194
tensor(0.0099, device='cuda:0') tensor(0.0556, device='cuda:0') tensor(-6.9843e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.220857
Average KL loss: 0.132860
Average total loss: 0.353717
tensor(0.0099, device='cuda:0') tensor(0.0558, device='cuda:0') tensor(-6.9671e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.214084
Average KL loss: 0.132868
Average total loss: 0.346952
tensor(0.0099, device='cuda:0') tensor(0.0559, device='cuda:0') tensor(-4.4946e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.219160
Average KL loss: 0.132879
Average total loss: 0.352040
tensor(0.0099, device='cuda:0') tensor(0.0561, device='cuda:0') tensor(-9.4279e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.213388
Average KL loss: 0.132889
Average total loss: 0.346277
tensor(0.0099, device='cuda:0') tensor(0.0563, device='cuda:0') tensor(-8.3405e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.213046
Average KL loss: 0.132905
Average total loss: 0.345951
tensor(0.0100, device='cuda:0') tensor(0.0564, device='cuda:0') tensor(-6.1464e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.216552
Average KL loss: 0.132919
Average total loss: 0.349470
tensor(0.0100, device='cuda:0') tensor(0.0566, device='cuda:0') tensor(-1.0790e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.216400
Average KL loss: 0.132928
Average total loss: 0.349329
tensor(0.0100, device='cuda:0') tensor(0.0567, device='cuda:0') tensor(-8.9648e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.210397
Average KL loss: 0.132947
Average total loss: 0.343344
tensor(0.0100, device='cuda:0') tensor(0.0569, device='cuda:0') tensor(-1.5409e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.205958
Average KL loss: 0.132958
Average total loss: 0.338916
tensor(0.0100, device='cuda:0') tensor(0.0571, device='cuda:0') tensor(-3.8664e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.208080
Average KL loss: 0.132967
Average total loss: 0.341047
tensor(0.0100, device='cuda:0') tensor(0.0572, device='cuda:0') tensor(-5.1371e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.214834
Average KL loss: 0.132977
Average total loss: 0.347811
tensor(0.0100, device='cuda:0') tensor(0.0574, device='cuda:0') tensor(-7.6673e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.208666
Average KL loss: 0.132993
Average total loss: 0.341659
tensor(0.0101, device='cuda:0') tensor(0.0576, device='cuda:0') tensor(-7.2236e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.211314
Average KL loss: 0.133006
Average total loss: 0.344320
tensor(0.0101, device='cuda:0') tensor(0.0577, device='cuda:0') tensor(-6.8002e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.210671
Average KL loss: 0.133014
Average total loss: 0.343685
tensor(0.0101, device='cuda:0') tensor(0.0579, device='cuda:0') tensor(-3.5166e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.207693
Average KL loss: 0.133028
Average total loss: 0.340721
tensor(0.0101, device='cuda:0') tensor(0.0581, device='cuda:0') tensor(-8.4477e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.209134
Average KL loss: 0.133043
Average total loss: 0.342177
tensor(0.0101, device='cuda:0') tensor(0.0582, device='cuda:0') tensor(-9.6199e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.207555
Average KL loss: 0.133056
Average total loss: 0.340611
tensor(0.0101, device='cuda:0') tensor(0.0584, device='cuda:0') tensor(-5.1024e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.211181
Average KL loss: 0.133064
Average total loss: 0.344245
tensor(0.0101, device='cuda:0') tensor(0.0586, device='cuda:0') tensor(-3.2202e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.202179
Average KL loss: 0.133076
Average total loss: 0.335255
tensor(0.0101, device='cuda:0') tensor(0.0587, device='cuda:0') tensor(-7.6294e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.208427
Average KL loss: 0.133088
Average total loss: 0.341515
tensor(0.0102, device='cuda:0') tensor(0.0589, device='cuda:0') tensor(-4.0403e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.203551
Average KL loss: 0.133099
Average total loss: 0.336650
tensor(0.0102, device='cuda:0') tensor(0.0591, device='cuda:0') tensor(-4.3368e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.201649
Average KL loss: 0.133106
Average total loss: 0.334754
tensor(0.0102, device='cuda:0') tensor(0.0592, device='cuda:0') tensor(-4.8658e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.206111
Average KL loss: 0.133112
Average total loss: 0.339223
tensor(0.0102, device='cuda:0') tensor(0.0594, device='cuda:0') tensor(-7.4318e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.201285
Average KL loss: 0.133118
Average total loss: 0.334402
tensor(0.0102, device='cuda:0') tensor(0.0595, device='cuda:0') tensor(-5.4266e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.199746
Average KL loss: 0.133122
Average total loss: 0.332868
tensor(0.0102, device='cuda:0') tensor(0.0597, device='cuda:0') tensor(-5.8117e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.199127
Average KL loss: 0.133124
Average total loss: 0.332252
tensor(0.0102, device='cuda:0') tensor(0.0599, device='cuda:0') tensor(-4.4247e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.209026
Average KL loss: 0.133134
Average total loss: 0.342159
tensor(0.0103, device='cuda:0') tensor(0.0600, device='cuda:0') tensor(-9.5976e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.197083
Average KL loss: 0.133146
Average total loss: 0.330228
tensor(0.0103, device='cuda:0') tensor(0.0602, device='cuda:0') tensor(-5.4459e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.196547
Average KL loss: 0.133156
Average total loss: 0.329703
tensor(0.0103, device='cuda:0') tensor(0.0603, device='cuda:0') tensor(-3.9230e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.191359
Average KL loss: 0.133163
Average total loss: 0.324522
tensor(0.0103, device='cuda:0') tensor(0.0605, device='cuda:0') tensor(-5.9504e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.197895
Average KL loss: 0.133175
Average total loss: 0.331070
tensor(0.0103, device='cuda:0') tensor(0.0606, device='cuda:0') tensor(-3.6964e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.201386
Average KL loss: 0.133184
Average total loss: 0.334570
tensor(0.0103, device='cuda:0') tensor(0.0608, device='cuda:0') tensor(-6.7116e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.197169
Average KL loss: 0.133192
Average total loss: 0.330361
tensor(0.0103, device='cuda:0') tensor(0.0610, device='cuda:0') tensor(-2.0869e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.200721
Average KL loss: 0.133196
Average total loss: 0.333918
tensor(0.0103, device='cuda:0') tensor(0.0611, device='cuda:0') tensor(-7.6892e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.192975
Average KL loss: 0.133208
Average total loss: 0.326182
tensor(0.0104, device='cuda:0') tensor(0.0613, device='cuda:0') tensor(-4.6907e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.194346
Average KL loss: 0.133215
Average total loss: 0.327561
tensor(0.0104, device='cuda:0') tensor(0.0614, device='cuda:0') tensor(-4.5958e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.199103
Average KL loss: 0.133221
Average total loss: 0.332324
tensor(0.0104, device='cuda:0') tensor(0.0616, device='cuda:0') tensor(-5.6678e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.198213
Average KL loss: 0.133224
Average total loss: 0.331437
tensor(0.0104, device='cuda:0') tensor(0.0617, device='cuda:0') tensor(-7.9895e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.188807
Average KL loss: 0.133233
Average total loss: 0.322041
tensor(0.0104, device='cuda:0') tensor(0.0619, device='cuda:0') tensor(-4.5799e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.196757
Average KL loss: 0.133243
Average total loss: 0.330001
tensor(0.0104, device='cuda:0') tensor(0.0621, device='cuda:0') tensor(-1.0476e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.195550
Average KL loss: 0.133251
Average total loss: 0.328802
tensor(0.0104, device='cuda:0') tensor(0.0622, device='cuda:0') tensor(-3.4623e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.196067
Average KL loss: 0.133261
Average total loss: 0.329327
tensor(0.0104, device='cuda:0') tensor(0.0624, device='cuda:0') tensor(-1.0540e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.188589
Average KL loss: 0.133266
Average total loss: 0.321855
tensor(0.0104, device='cuda:0') tensor(0.0625, device='cuda:0') tensor(-6.2357e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.189242
Average KL loss: 0.133274
Average total loss: 0.322516
tensor(0.0105, device='cuda:0') tensor(0.0627, device='cuda:0') tensor(-4.8551e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.188411
Average KL loss: 0.133281
Average total loss: 0.321692
tensor(0.0105, device='cuda:0') tensor(0.0628, device='cuda:0') tensor(-5.2845e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.187665
Average KL loss: 0.133287
Average total loss: 0.320952
tensor(0.0105, device='cuda:0') tensor(0.0630, device='cuda:0') tensor(-2.7812e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.184044
Average KL loss: 0.133295
Average total loss: 0.317339
tensor(0.0105, device='cuda:0') tensor(0.0631, device='cuda:0') tensor(-3.8507e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.183590
Average KL loss: 0.133303
Average total loss: 0.316894
tensor(0.0105, device='cuda:0') tensor(0.0633, device='cuda:0') tensor(-4.0846e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.187297
Average KL loss: 0.133312
Average total loss: 0.320609
tensor(0.0105, device='cuda:0') tensor(0.0634, device='cuda:0') tensor(-2.8400e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.190993
Average KL loss: 0.133314
Average total loss: 0.324307
tensor(0.0105, device='cuda:0') tensor(0.0636, device='cuda:0') tensor(-1.8662e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.190584
Average KL loss: 0.133320
Average total loss: 0.323904
tensor(0.0105, device='cuda:0') tensor(0.0637, device='cuda:0') tensor(-6.0878e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.182679
Average KL loss: 0.133331
Average total loss: 0.316010
tensor(0.0106, device='cuda:0') tensor(0.0639, device='cuda:0') tensor(-4.6007e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.182342
Average KL loss: 0.133338
Average total loss: 0.315680
tensor(0.0106, device='cuda:0') tensor(0.0641, device='cuda:0') tensor(-3.6471e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.186168
Average KL loss: 0.133346
Average total loss: 0.319515
tensor(0.0106, device='cuda:0') tensor(0.0642, device='cuda:0') tensor(-2.1148e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.184927
Average KL loss: 0.133353
Average total loss: 0.318280
tensor(0.0106, device='cuda:0') tensor(0.0644, device='cuda:0') tensor(-6.7993e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.185884
Average KL loss: 0.133360
Average total loss: 0.319244
tensor(0.0106, device='cuda:0') tensor(0.0645, device='cuda:0') tensor(-5.3273e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.182841
Average KL loss: 0.133368
Average total loss: 0.316209
tensor(0.0106, device='cuda:0') tensor(0.0647, device='cuda:0') tensor(-5.4238e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.177487
Average KL loss: 0.133373
Average total loss: 0.310860
tensor(0.0106, device='cuda:0') tensor(0.0648, device='cuda:0') tensor(-5.4077e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.179794
Average KL loss: 0.133383
Average total loss: 0.313177
tensor(0.0106, device='cuda:0') tensor(0.0650, device='cuda:0') tensor(-2.7213e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.179361
Average KL loss: 0.133390
Average total loss: 0.312751
tensor(0.0106, device='cuda:0') tensor(0.0651, device='cuda:0') tensor(-1.0606e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.181034
Average KL loss: 0.133396
Average total loss: 0.314430
tensor(0.0107, device='cuda:0') tensor(0.0653, device='cuda:0') tensor(-4.0420e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.180687
Average KL loss: 0.133403
Average total loss: 0.314090
tensor(0.0107, device='cuda:0') tensor(0.0654, device='cuda:0') tensor(-4.0970e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.187939
Average KL loss: 0.133408
Average total loss: 0.321347
tensor(0.0107, device='cuda:0') tensor(0.0655, device='cuda:0') tensor(-4.7732e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.182915
Average KL loss: 0.133414
Average total loss: 0.316329
tensor(0.0107, device='cuda:0') tensor(0.0657, device='cuda:0') tensor(-3.3022e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.183183
Average KL loss: 0.133413
Average total loss: 0.316596
tensor(0.0107, device='cuda:0') tensor(0.0658, device='cuda:0') tensor(-3.8687e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.179038
Average KL loss: 0.133417
Average total loss: 0.312455
tensor(0.0107, device='cuda:0') tensor(0.0660, device='cuda:0') tensor(-3.5734e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.179620
Average KL loss: 0.133420
Average total loss: 0.313039
tensor(0.0107, device='cuda:0') tensor(0.0661, device='cuda:0') tensor(-3.5320e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.179176
Average KL loss: 0.133418
Average total loss: 0.312594
tensor(0.0107, device='cuda:0') tensor(0.0663, device='cuda:0') tensor(-6.9127e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.180316
Average KL loss: 0.133422
Average total loss: 0.313738
tensor(0.0107, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-5.1909e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.177889
Average KL loss: 0.133427
Average total loss: 0.311315
tensor(0.0107, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-2.6491e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.178374
Average KL loss: 0.133429
Average total loss: 0.311802
tensor(0.0107, device='cuda:0') tensor(0.0664, device='cuda:0') tensor(-4.5428e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.175387
Average KL loss: 0.133429
Average total loss: 0.308816
tensor(0.0107, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-2.2002e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.177595
Average KL loss: 0.133430
Average total loss: 0.311025
tensor(0.0107, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-7.3875e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.174362
Average KL loss: 0.133430
Average total loss: 0.307792
tensor(0.0108, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-2.0406e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.176542
Average KL loss: 0.133431
Average total loss: 0.309973
tensor(0.0108, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-3.4502e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.176473
Average KL loss: 0.133432
Average total loss: 0.309905
tensor(0.0108, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-3.7340e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.180060
Average KL loss: 0.133433
Average total loss: 0.313493
tensor(0.0108, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-2.4991e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.180222
Average KL loss: 0.133434
Average total loss: 0.313655
tensor(0.0108, device='cuda:0') tensor(0.0665, device='cuda:0') tensor(-2.4617e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.172337
Average KL loss: 0.133435
Average total loss: 0.305772
tensor(0.0108, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(3.1472e-10, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.177744
Average KL loss: 0.133436
Average total loss: 0.311180
tensor(0.0108, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-4.2252e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.174039
Average KL loss: 0.133437
Average total loss: 0.307476
tensor(0.0108, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-5.6479e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.172201
Average KL loss: 0.133438
Average total loss: 0.305639
tensor(0.0108, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-9.8139e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.173826
Average KL loss: 0.133439
Average total loss: 0.307265
tensor(0.0108, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-2.5222e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.178304
Average KL loss: 0.133441
Average total loss: 0.311745
tensor(0.0108, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-3.6266e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.175651
Average KL loss: 0.133442
Average total loss: 0.309093
tensor(0.0108, device='cuda:0') tensor(0.0666, device='cuda:0') tensor(-2.5399e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.174827
Average KL loss: 0.133443
Average total loss: 0.308270
tensor(0.0108, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-4.5531e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.178123
Average KL loss: 0.133444
Average total loss: 0.311568
tensor(0.0108, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-2.3424e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.174895
Average KL loss: 0.133445
Average total loss: 0.308340
tensor(0.0108, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-5.8211e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.171801
Average KL loss: 0.133446
Average total loss: 0.305246
tensor(0.0108, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-5.1113e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.180620
Average KL loss: 0.133447
Average total loss: 0.314067
tensor(0.0108, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-5.4904e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.180844
Average KL loss: 0.133448
Average total loss: 0.314292
tensor(0.0108, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-2.3890e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.174774
Average KL loss: 0.133449
Average total loss: 0.308223
tensor(0.0108, device='cuda:0') tensor(0.0667, device='cuda:0') tensor(-3.2630e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.176712
Average KL loss: 0.133450
Average total loss: 0.310162
tensor(0.0108, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-4.7873e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.169639
Average KL loss: 0.133451
Average total loss: 0.303090
tensor(0.0108, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-1.4857e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.179370
Average KL loss: 0.133451
Average total loss: 0.312821
tensor(0.0108, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-2.2906e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.180921
Average KL loss: 0.133452
Average total loss: 0.314373
tensor(0.0108, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-2.8814e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.174858
Average KL loss: 0.133453
Average total loss: 0.308311
tensor(0.0108, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-2.9942e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.177375
Average KL loss: 0.133454
Average total loss: 0.310830
tensor(0.0108, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-5.8576e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.172876
Average KL loss: 0.133456
Average total loss: 0.306332
tensor(0.0108, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-3.5182e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.178924
Average KL loss: 0.133457
Average total loss: 0.312382
tensor(0.0108, device='cuda:0') tensor(0.0668, device='cuda:0') tensor(-3.0544e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.179276
Average KL loss: 0.133458
Average total loss: 0.312734
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-2.6168e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.171057
Average KL loss: 0.133458
Average total loss: 0.304516
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-3.1939e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.176444
Average KL loss: 0.133459
Average total loss: 0.309904
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-3.8584e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.176595
Average KL loss: 0.133461
Average total loss: 0.310055
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-2.5818e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.170835
Average KL loss: 0.133462
Average total loss: 0.304297
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-4.2750e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.177234
Average KL loss: 0.133463
Average total loss: 0.310697
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-1.5301e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.179241
Average KL loss: 0.133463
Average total loss: 0.312703
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-1.2535e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.179282
Average KL loss: 0.133463
Average total loss: 0.312744
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-4.6227e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.178835
Average KL loss: 0.133463
Average total loss: 0.312298
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-7.1097e-10, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.172686
Average KL loss: 0.133463
Average total loss: 0.306149
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-7.4383e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.180262
Average KL loss: 0.133463
Average total loss: 0.313725
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-2.4156e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.176447
Average KL loss: 0.133463
Average total loss: 0.309910
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-5.4396e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.176449
Average KL loss: 0.133463
Average total loss: 0.309912
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-6.3645e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.177150
Average KL loss: 0.133463
Average total loss: 0.310613
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-1.5000e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.174584
Average KL loss: 0.133463
Average total loss: 0.308047
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-3.2267e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.173280
Average KL loss: 0.133464
Average total loss: 0.306744
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-3.6227e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.174137
Average KL loss: 0.133464
Average total loss: 0.307600
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-2.8487e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.175453
Average KL loss: 0.133464
Average total loss: 0.308916
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-2.6929e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.181992
Average KL loss: 0.133464
Average total loss: 0.315456
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-2.8750e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.178496
Average KL loss: 0.133464
Average total loss: 0.311959
 Percentile value: 6.669440269470215
Non-zero model percentage: 0.09765839576721191%, Non-zero mask percentage: 0.09765839576721191%

--- Pruning Level [10/12]: ---
conv1.weight         | nonzeros =     663 /    1728             ( 38.37%) | total_pruned =    1065 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
bn1.bias             | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     404 /   36864             (  1.10%) | total_pruned =   36460 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      57 /      64             ( 89.06%) | total_pruned =       7 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     465 /   36864             (  1.26%) | total_pruned =   36399 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      63 /      64             ( 98.44%) | total_pruned =       1 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     378 /   36864             (  1.03%) | total_pruned =   36486 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     377 /   36864             (  1.02%) | total_pruned =   36487 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     498 /   73728             (  0.68%) | total_pruned =   73230 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     533 /  147456             (  0.36%) | total_pruned =  146923 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     430 /    8192             (  5.25%) | total_pruned =    7762 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     125 /     128             ( 97.66%) | total_pruned =       3 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     335 /  147456             (  0.23%) | total_pruned =  147121 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     270 /  147456             (  0.18%) | total_pruned =  147186 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     595 /  294912             (  0.20%) | total_pruned =  294317 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     224 /     256             ( 87.50%) | total_pruned =      32 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      44 /     256             ( 17.19%) | total_pruned =     212 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     575 /  589824             (  0.10%) | total_pruned =  589249 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     367 /   32768             (  1.12%) | total_pruned =   32401 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     218 /     256             ( 85.16%) | total_pruned =      38 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     218 /  589824             (  0.04%) | total_pruned =  589606 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     116 /     256             ( 45.31%) | total_pruned =     140 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     177 /  589824             (  0.03%) | total_pruned =  589647 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     146 /     256             ( 57.03%) | total_pruned =     110 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     461 / 1179648             (  0.04%) | total_pruned = 1179187 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     282 /     512             ( 55.08%) | total_pruned =     230 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      43 /     512             (  8.40%) | total_pruned =     469 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     314 / 2359296             (  0.01%) | total_pruned = 2358982 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     268 /     512             ( 52.34%) | total_pruned =     244 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     102 /  131072             (  0.08%) | total_pruned =  130970 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     134 /     512             ( 26.17%) | total_pruned =     378 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     186 / 2359296             (  0.01%) | total_pruned = 2359110 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      86 /     512             ( 16.80%) | total_pruned =     426 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =      64 / 2359296             (  0.00%) | total_pruned = 2359232 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     136 /     512             ( 26.56%) | total_pruned =     376 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     567 /    5120             ( 11.07%) | total_pruned =    4553 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 10917, pruned : 11167845, total: 11178762, Compression rate :    1023.98x  ( 99.90% pruned)
Train Epoch: 99/100 Loss: 0.626931 Accuracy: 70.54 79.20 % Best test Accuracy: 71.03%
tensor(0.0108, device='cuda:0') tensor(0.0669, device='cuda:0') tensor(-4.0341e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.631586
Average KL loss: 0.132191
Average total loss: 0.763777
tensor(0.0100, device='cuda:0') tensor(0.0580, device='cuda:0') tensor(-1.6751e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.655056
Average KL loss: 0.128973
Average total loss: 0.784029
tensor(0.0092, device='cuda:0') tensor(0.0499, device='cuda:0') tensor(-1.0232e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.665413
Average KL loss: 0.124091
Average total loss: 0.789504
tensor(0.0083, device='cuda:0') tensor(0.0425, device='cuda:0') tensor(-6.0097e-09, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.683402
Average KL loss: 0.116252
Average total loss: 0.799654
tensor(0.0075, device='cuda:0') tensor(0.0363, device='cuda:0') tensor(-6.4177e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.681715
Average KL loss: 0.103902
Average total loss: 0.785617
tensor(0.0066, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-5.0990e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.701831
Average KL loss: 0.087249
Average total loss: 0.789080
tensor(0.0058, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-2.2349e-09, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.701684
Average KL loss: 0.071779
Average total loss: 0.773463
tensor(0.0052, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-7.8033e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.697043
Average KL loss: 0.063733
Average total loss: 0.760776
tensor(0.0048, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-1.5880e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.692431
Average KL loss: 0.061559
Average total loss: 0.753990
tensor(0.0047, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-1.2073e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.696230
Average KL loss: 0.061221
Average total loss: 0.757451
tensor(0.0047, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-4.7338e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.694599
Average KL loss: 0.061175
Average total loss: 0.755774
tensor(0.0046, device='cuda:0') tensor(0.0267, device='cuda:0') tensor(-2.7231e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.691773
Average KL loss: 0.061154
Average total loss: 0.752928
tensor(0.0046, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-1.0838e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.692320
Average KL loss: 0.061139
Average total loss: 0.753459
tensor(0.0046, device='cuda:0') tensor(0.0268, device='cuda:0') tensor(-9.0697e-09, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.692954
Average KL loss: 0.061123
Average total loss: 0.754078
tensor(0.0046, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-8.3906e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.690013
Average KL loss: 0.061106
Average total loss: 0.751118
tensor(0.0047, device='cuda:0') tensor(0.0269, device='cuda:0') tensor(-3.7794e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.689867
Average KL loss: 0.061088
Average total loss: 0.750955
tensor(0.0047, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-1.2246e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.682919
Average KL loss: 0.061069
Average total loss: 0.743988
tensor(0.0047, device='cuda:0') tensor(0.0270, device='cuda:0') tensor(-6.6971e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.685240
Average KL loss: 0.061052
Average total loss: 0.746292
tensor(0.0047, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-8.3251e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.675106
Average KL loss: 0.061035
Average total loss: 0.736141
tensor(0.0047, device='cuda:0') tensor(0.0271, device='cuda:0') tensor(-5.3783e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.680975
Average KL loss: 0.061014
Average total loss: 0.741990
tensor(0.0047, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-9.3831e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.676138
Average KL loss: 0.060997
Average total loss: 0.737136
tensor(0.0047, device='cuda:0') tensor(0.0272, device='cuda:0') tensor(-1.1967e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.676914
Average KL loss: 0.060984
Average total loss: 0.737898
tensor(0.0047, device='cuda:0') tensor(0.0273, device='cuda:0') tensor(-9.3129e-10, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.678964
Average KL loss: 0.060972
Average total loss: 0.739936
tensor(0.0047, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-4.5466e-09, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.675378
Average KL loss: 0.060960
Average total loss: 0.736338
tensor(0.0047, device='cuda:0') tensor(0.0274, device='cuda:0') tensor(-3.6337e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.680737
Average KL loss: 0.060949
Average total loss: 0.741686
tensor(0.0047, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-7.7344e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.676503
Average KL loss: 0.060938
Average total loss: 0.737441
tensor(0.0047, device='cuda:0') tensor(0.0275, device='cuda:0') tensor(-7.6647e-09, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.685364
Average KL loss: 0.060932
Average total loss: 0.746296
tensor(0.0047, device='cuda:0') tensor(0.0276, device='cuda:0') tensor(-6.9841e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.673299
Average KL loss: 0.060923
Average total loss: 0.734223
tensor(0.0047, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-9.8210e-09, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.671866
Average KL loss: 0.060912
Average total loss: 0.732777
tensor(0.0047, device='cuda:0') tensor(0.0277, device='cuda:0') tensor(-9.0744e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.665537
Average KL loss: 0.060904
Average total loss: 0.726441
tensor(0.0047, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-1.1156e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.674470
Average KL loss: 0.060897
Average total loss: 0.735367
tensor(0.0047, device='cuda:0') tensor(0.0278, device='cuda:0') tensor(-4.8314e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.665881
Average KL loss: 0.060888
Average total loss: 0.726769
tensor(0.0047, device='cuda:0') tensor(0.0279, device='cuda:0') tensor(-5.5039e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.665131
Average KL loss: 0.060880
Average total loss: 0.726011
tensor(0.0047, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-6.0557e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.663354
Average KL loss: 0.060872
Average total loss: 0.724225
tensor(0.0047, device='cuda:0') tensor(0.0280, device='cuda:0') tensor(-2.9873e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.666070
Average KL loss: 0.060867
Average total loss: 0.726937
tensor(0.0047, device='cuda:0') tensor(0.0281, device='cuda:0') tensor(-4.8942e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.661543
Average KL loss: 0.060862
Average total loss: 0.722405
tensor(0.0047, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-1.9974e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.663069
Average KL loss: 0.060857
Average total loss: 0.723927
tensor(0.0047, device='cuda:0') tensor(0.0282, device='cuda:0') tensor(-5.0409e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.663038
Average KL loss: 0.060854
Average total loss: 0.723892
tensor(0.0047, device='cuda:0') tensor(0.0283, device='cuda:0') tensor(-2.3023e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.658436
Average KL loss: 0.060852
Average total loss: 0.719288
tensor(0.0048, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-3.8843e-09, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.654554
Average KL loss: 0.060842
Average total loss: 0.715396
tensor(0.0048, device='cuda:0') tensor(0.0284, device='cuda:0') tensor(-8.6769e-09, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.659290
Average KL loss: 0.060834
Average total loss: 0.720124
tensor(0.0048, device='cuda:0') tensor(0.0285, device='cuda:0') tensor(-4.8213e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.661522
Average KL loss: 0.060829
Average total loss: 0.722351
tensor(0.0048, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-6.4029e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.662526
Average KL loss: 0.060819
Average total loss: 0.723344
tensor(0.0048, device='cuda:0') tensor(0.0286, device='cuda:0') tensor(-4.5317e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.655957
Average KL loss: 0.060809
Average total loss: 0.716766
tensor(0.0048, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-3.1327e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.656932
Average KL loss: 0.060800
Average total loss: 0.717731
tensor(0.0048, device='cuda:0') tensor(0.0287, device='cuda:0') tensor(-2.2351e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.652170
Average KL loss: 0.060790
Average total loss: 0.712960
tensor(0.0048, device='cuda:0') tensor(0.0288, device='cuda:0') tensor(-5.0949e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.654686
Average KL loss: 0.060776
Average total loss: 0.715462
tensor(0.0048, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-3.4961e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.659074
Average KL loss: 0.060764
Average total loss: 0.719838
tensor(0.0048, device='cuda:0') tensor(0.0289, device='cuda:0') tensor(-6.0191e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.650882
Average KL loss: 0.060758
Average total loss: 0.711641
tensor(0.0048, device='cuda:0') tensor(0.0290, device='cuda:0') tensor(-2.9042e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.658196
Average KL loss: 0.060755
Average total loss: 0.718950
tensor(0.0048, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-7.1075e-09, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.655343
Average KL loss: 0.060751
Average total loss: 0.716093
tensor(0.0048, device='cuda:0') tensor(0.0291, device='cuda:0') tensor(-5.4133e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.655706
Average KL loss: 0.060745
Average total loss: 0.716451
tensor(0.0048, device='cuda:0') tensor(0.0292, device='cuda:0') tensor(-8.8235e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.651332
Average KL loss: 0.060740
Average total loss: 0.712072
tensor(0.0048, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-5.0179e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.653595
Average KL loss: 0.060736
Average total loss: 0.714331
tensor(0.0048, device='cuda:0') tensor(0.0293, device='cuda:0') tensor(-3.0275e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.646636
Average KL loss: 0.060730
Average total loss: 0.707366
tensor(0.0048, device='cuda:0') tensor(0.0294, device='cuda:0') tensor(-5.6205e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.651370
Average KL loss: 0.060723
Average total loss: 0.712093
tensor(0.0048, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-3.7071e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.652779
Average KL loss: 0.060716
Average total loss: 0.713495
tensor(0.0048, device='cuda:0') tensor(0.0295, device='cuda:0') tensor(-4.7938e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.650750
Average KL loss: 0.060708
Average total loss: 0.711459
tensor(0.0048, device='cuda:0') tensor(0.0296, device='cuda:0') tensor(-3.2232e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.648545
Average KL loss: 0.060701
Average total loss: 0.709246
tensor(0.0048, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-5.5021e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.648193
Average KL loss: 0.060691
Average total loss: 0.708884
tensor(0.0048, device='cuda:0') tensor(0.0297, device='cuda:0') tensor(-1.7830e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.644641
Average KL loss: 0.060683
Average total loss: 0.705324
tensor(0.0049, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-9.0082e-10, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.647638
Average KL loss: 0.060678
Average total loss: 0.708316
tensor(0.0049, device='cuda:0') tensor(0.0298, device='cuda:0') tensor(-3.6209e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.642041
Average KL loss: 0.060677
Average total loss: 0.702718
tensor(0.0049, device='cuda:0') tensor(0.0299, device='cuda:0') tensor(-3.1475e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.647863
Average KL loss: 0.060671
Average total loss: 0.708534
tensor(0.0049, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-9.4073e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.647659
Average KL loss: 0.060665
Average total loss: 0.708323
tensor(0.0049, device='cuda:0') tensor(0.0300, device='cuda:0') tensor(-4.2583e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.648299
Average KL loss: 0.060660
Average total loss: 0.708958
tensor(0.0049, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-5.5496e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.643034
Average KL loss: 0.060657
Average total loss: 0.703691
tensor(0.0049, device='cuda:0') tensor(0.0301, device='cuda:0') tensor(-4.5403e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.648657
Average KL loss: 0.060651
Average total loss: 0.709308
tensor(0.0049, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-1.2506e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.647962
Average KL loss: 0.060644
Average total loss: 0.708606
tensor(0.0049, device='cuda:0') tensor(0.0302, device='cuda:0') tensor(-4.7924e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.643546
Average KL loss: 0.060641
Average total loss: 0.704187
tensor(0.0049, device='cuda:0') tensor(0.0303, device='cuda:0') tensor(-2.3742e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.647842
Average KL loss: 0.060640
Average total loss: 0.708482
tensor(0.0049, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-6.9814e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.643139
Average KL loss: 0.060638
Average total loss: 0.703777
tensor(0.0049, device='cuda:0') tensor(0.0304, device='cuda:0') tensor(-9.5264e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.645295
Average KL loss: 0.060631
Average total loss: 0.705926
tensor(0.0049, device='cuda:0') tensor(0.0305, device='cuda:0') tensor(-1.4102e-11, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.635727
Average KL loss: 0.060626
Average total loss: 0.696353
tensor(0.0049, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-3.3724e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.643612
Average KL loss: 0.060619
Average total loss: 0.704232
tensor(0.0049, device='cuda:0') tensor(0.0306, device='cuda:0') tensor(-6.0627e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.645112
Average KL loss: 0.060614
Average total loss: 0.705726
tensor(0.0049, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-3.6993e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.642705
Average KL loss: 0.060611
Average total loss: 0.703316
tensor(0.0049, device='cuda:0') tensor(0.0307, device='cuda:0') tensor(-2.6345e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.638632
Average KL loss: 0.060608
Average total loss: 0.699241
tensor(0.0049, device='cuda:0') tensor(0.0308, device='cuda:0') tensor(-3.6334e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.640090
Average KL loss: 0.060604
Average total loss: 0.700694
tensor(0.0049, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-2.9012e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.637719
Average KL loss: 0.060601
Average total loss: 0.698320
tensor(0.0049, device='cuda:0') tensor(0.0309, device='cuda:0') tensor(-1.2689e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.641355
Average KL loss: 0.060598
Average total loss: 0.701953
tensor(0.0049, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-9.8258e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.642199
Average KL loss: 0.060592
Average total loss: 0.702791
tensor(0.0049, device='cuda:0') tensor(0.0310, device='cuda:0') tensor(-6.1819e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.633435
Average KL loss: 0.060589
Average total loss: 0.694024
tensor(0.0049, device='cuda:0') tensor(0.0311, device='cuda:0') tensor(-1.9713e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.639492
Average KL loss: 0.060583
Average total loss: 0.700075
tensor(0.0049, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-2.8086e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.643101
Average KL loss: 0.060580
Average total loss: 0.703680
tensor(0.0050, device='cuda:0') tensor(0.0312, device='cuda:0') tensor(-6.3784e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.637585
Average KL loss: 0.060576
Average total loss: 0.698161
tensor(0.0050, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(4.1516e-10, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.642039
Average KL loss: 0.060572
Average total loss: 0.702610
tensor(0.0050, device='cuda:0') tensor(0.0313, device='cuda:0') tensor(-2.0515e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.635905
Average KL loss: 0.060569
Average total loss: 0.696474
tensor(0.0050, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-1.3822e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.638245
Average KL loss: 0.060564
Average total loss: 0.698809
tensor(0.0050, device='cuda:0') tensor(0.0314, device='cuda:0') tensor(-1.9846e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.634568
Average KL loss: 0.060558
Average total loss: 0.695126
tensor(0.0050, device='cuda:0') tensor(0.0315, device='cuda:0') tensor(-2.9509e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.632804
Average KL loss: 0.060554
Average total loss: 0.693357
tensor(0.0050, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-3.1224e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.635539
Average KL loss: 0.060546
Average total loss: 0.696085
tensor(0.0050, device='cuda:0') tensor(0.0316, device='cuda:0') tensor(-6.1073e-10, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.637054
Average KL loss: 0.060541
Average total loss: 0.697594
tensor(0.0050, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-7.4899e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.635270
Average KL loss: 0.060538
Average total loss: 0.695808
tensor(0.0050, device='cuda:0') tensor(0.0317, device='cuda:0') tensor(-5.2557e-10, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.635214
Average KL loss: 0.060538
Average total loss: 0.695751
tensor(0.0050, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-2.8565e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.630058
Average KL loss: 0.060537
Average total loss: 0.690595
tensor(0.0050, device='cuda:0') tensor(0.0318, device='cuda:0') tensor(-8.0199e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.634001
Average KL loss: 0.060532
Average total loss: 0.694533
tensor(0.0050, device='cuda:0') tensor(0.0319, device='cuda:0') tensor(-1.4478e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.636216
Average KL loss: 0.060526
Average total loss: 0.696742
tensor(0.0050, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-1.5039e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.633126
Average KL loss: 0.060522
Average total loss: 0.693648
tensor(0.0050, device='cuda:0') tensor(0.0320, device='cuda:0') tensor(-2.0459e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.639913
Average KL loss: 0.060517
Average total loss: 0.700430
tensor(0.0050, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-5.6275e-10, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.639562
Average KL loss: 0.060513
Average total loss: 0.700075
tensor(0.0050, device='cuda:0') tensor(0.0321, device='cuda:0') tensor(-1.8814e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.632398
Average KL loss: 0.060509
Average total loss: 0.692906
tensor(0.0050, device='cuda:0') tensor(0.0322, device='cuda:0') tensor(-2.0925e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.625251
Average KL loss: 0.060505
Average total loss: 0.685755
tensor(0.0050, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(-1.6195e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.636353
Average KL loss: 0.060500
Average total loss: 0.696853
tensor(0.0050, device='cuda:0') tensor(0.0323, device='cuda:0') tensor(-5.2566e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.635190
Average KL loss: 0.060495
Average total loss: 0.695684
tensor(0.0050, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-3.5573e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.641386
Average KL loss: 0.060491
Average total loss: 0.701878
tensor(0.0050, device='cuda:0') tensor(0.0324, device='cuda:0') tensor(-2.8560e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.635292
Average KL loss: 0.060491
Average total loss: 0.695783
tensor(0.0050, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-1.4714e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.631480
Average KL loss: 0.060488
Average total loss: 0.691968
tensor(0.0050, device='cuda:0') tensor(0.0325, device='cuda:0') tensor(-6.6943e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.633934
Average KL loss: 0.060481
Average total loss: 0.694415
tensor(0.0050, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-2.8880e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.630996
Average KL loss: 0.060478
Average total loss: 0.691474
tensor(0.0051, device='cuda:0') tensor(0.0326, device='cuda:0') tensor(-4.1252e-10, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.628117
Average KL loss: 0.060474
Average total loss: 0.688590
tensor(0.0051, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-1.7612e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.625824
Average KL loss: 0.060471
Average total loss: 0.686296
tensor(0.0051, device='cuda:0') tensor(0.0327, device='cuda:0') tensor(-5.0891e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.628072
Average KL loss: 0.060471
Average total loss: 0.688543
tensor(0.0051, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-1.9149e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.633819
Average KL loss: 0.060470
Average total loss: 0.694289
tensor(0.0051, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-2.9596e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.630266
Average KL loss: 0.060468
Average total loss: 0.690734
tensor(0.0051, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-3.2983e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.623369
Average KL loss: 0.060467
Average total loss: 0.683836
tensor(0.0051, device='cuda:0') tensor(0.0328, device='cuda:0') tensor(-8.6859e-10, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.627297
Average KL loss: 0.060468
Average total loss: 0.687764
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-6.4952e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.625582
Average KL loss: 0.060467
Average total loss: 0.686049
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.3169e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.632362
Average KL loss: 0.060466
Average total loss: 0.692828
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.2957e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.625118
Average KL loss: 0.060466
Average total loss: 0.685584
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.1291e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.628189
Average KL loss: 0.060466
Average total loss: 0.688654
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-3.7896e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.629478
Average KL loss: 0.060466
Average total loss: 0.689943
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-6.2442e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.635352
Average KL loss: 0.060465
Average total loss: 0.695818
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-7.1313e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.628815
Average KL loss: 0.060465
Average total loss: 0.689279
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-2.9049e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.632812
Average KL loss: 0.060464
Average total loss: 0.693276
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-8.9003e-10, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.629679
Average KL loss: 0.060464
Average total loss: 0.690143
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-4.9974e-10, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.631174
Average KL loss: 0.060464
Average total loss: 0.691638
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-2.6326e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.628503
Average KL loss: 0.060464
Average total loss: 0.688967
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-5.0659e-11, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.627324
Average KL loss: 0.060464
Average total loss: 0.687787
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.9671e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.630167
Average KL loss: 0.060464
Average total loss: 0.690631
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(1.8633e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.637139
Average KL loss: 0.060464
Average total loss: 0.697602
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-3.8758e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.632048
Average KL loss: 0.060464
Average total loss: 0.692512
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.7392e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.629896
Average KL loss: 0.060464
Average total loss: 0.690360
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-7.0674e-10, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.632376
Average KL loss: 0.060464
Average total loss: 0.692840
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-4.4098e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.632858
Average KL loss: 0.060463
Average total loss: 0.693322
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-7.8069e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.627472
Average KL loss: 0.060463
Average total loss: 0.687935
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-8.7794e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.626527
Average KL loss: 0.060463
Average total loss: 0.686990
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-2.4724e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.627046
Average KL loss: 0.060463
Average total loss: 0.687509
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-1.3995e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.633258
Average KL loss: 0.060463
Average total loss: 0.693722
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-2.9313e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.634542
Average KL loss: 0.060463
Average total loss: 0.695005
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-2.4983e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.629319
Average KL loss: 0.060463
Average total loss: 0.689782
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-3.2583e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.635297
Average KL loss: 0.060463
Average total loss: 0.695761
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-6.3372e-10, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.631390
Average KL loss: 0.060463
Average total loss: 0.691853
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-2.1009e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.632571
Average KL loss: 0.060463
Average total loss: 0.693035
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-5.4584e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.636541
Average KL loss: 0.060463
Average total loss: 0.697005
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-3.2034e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.626669
Average KL loss: 0.060463
Average total loss: 0.687133
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-3.6830e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.626471
Average KL loss: 0.060463
Average total loss: 0.686934
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(-3.7933e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.637795
Average KL loss: 0.060463
Average total loss: 0.698259
tensor(0.0051, device='cuda:0') tensor(0.0329, device='cuda:0') tensor(5.1487e-10, device='cuda:0')
 Percentile value: 6.925004005432129
Non-zero model percentage: 0.04883367195725441%, Non-zero mask percentage: 0.04883367195725441%

--- Pruning Level [11/12]: ---
conv1.weight         | nonzeros =     509 /    1728             ( 29.46%) | total_pruned =    1219 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
bn1.bias             | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     278 /   36864             (  0.75%) | total_pruned =   36586 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     298 /   36864             (  0.81%) | total_pruned =   36566 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     245 /   36864             (  0.66%) | total_pruned =   36619 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     229 /   36864             (  0.62%) | total_pruned =   36635 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     269 /   73728             (  0.36%) | total_pruned =   73459 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     260 /  147456             (  0.18%) | total_pruned =  147196 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     195 /    8192             (  2.38%) | total_pruned =    7997 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     176 /  147456             (  0.12%) | total_pruned =  147280 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     141 /  147456             (  0.10%) | total_pruned =  147315 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     230 /  294912             (  0.08%) | total_pruned =  294682 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     128 /     256             ( 50.00%) | total_pruned =     128 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     240 /  589824             (  0.04%) | total_pruned =  589584 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     131 /     256             ( 51.17%) | total_pruned =     125 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     107 /   32768             (  0.33%) | total_pruned =   32661 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      88 /     256             ( 34.38%) | total_pruned =     168 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =      81 /  589824             (  0.01%) | total_pruned =  589743 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      47 /     256             ( 18.36%) | total_pruned =     209 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =      74 /  589824             (  0.01%) | total_pruned =  589750 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      63 /     256             ( 24.61%) | total_pruned =     193 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     146 / 1179648             (  0.01%) | total_pruned = 1179502 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =      89 /     512             ( 17.38%) | total_pruned =     423 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =      98 / 2359296             (  0.00%) | total_pruned = 2359198 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     111 /     512             ( 21.68%) | total_pruned =     401 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      24 /  131072             (  0.02%) | total_pruned =  131048 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      45 /     512             (  8.79%) | total_pruned =     467 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =      46 / 2359296             (  0.00%) | total_pruned = 2359250 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =      22 / 2359296             (  0.00%) | total_pruned = 2359274 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      32 /     512             (  6.25%) | total_pruned =     480 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =     237 /    5120             (  4.63%) | total_pruned =    4883 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 5459, pruned : 11173303, total: 11178762, Compression rate :    2047.77x  ( 99.95% pruned)
Train Epoch: 99/100 Loss: 1.132374 Accuracy: 58.41 62.03 % Best test Accuracy: 58.64%
