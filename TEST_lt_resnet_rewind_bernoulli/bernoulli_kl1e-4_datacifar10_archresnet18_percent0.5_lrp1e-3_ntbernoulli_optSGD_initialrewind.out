Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2827e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302788
Average KL loss: 0.002289
Average total loss: 2.305076
tensor(3.8331e-06, device='cuda:0') tensor(2.4506e-07, device='cuda:0') tensor(-1.4051e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.303086
Average KL loss: 0.002306
Average total loss: 2.305392
tensor(4.7465e-06, device='cuda:0') tensor(3.1076e-07, device='cuda:0') tensor(-1.0873e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.302923
Average KL loss: 0.002319
Average total loss: 2.305242
tensor(5.1425e-06, device='cuda:0') tensor(4.3080e-07, device='cuda:0') tensor(-9.4627e-12, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.302902
Average KL loss: 0.002333
Average total loss: 2.305235
tensor(7.1510e-06, device='cuda:0') tensor(5.9269e-07, device='cuda:0') tensor(-1.5588e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.303155
Average KL loss: 0.002347
Average total loss: 2.305502
tensor(5.2883e-06, device='cuda:0') tensor(6.1039e-07, device='cuda:0') tensor(-1.7719e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.302898
Average KL loss: 0.002351
Average total loss: 2.305249
tensor(4.8537e-06, device='cuda:0') tensor(5.9303e-07, device='cuda:0') tensor(2.4821e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.302630
Average KL loss: 0.002361
Average total loss: 2.304991
tensor(7.6529e-06, device='cuda:0') tensor(7.2303e-07, device='cuda:0') tensor(-7.0271e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.302598
Average KL loss: 0.002381
Average total loss: 2.304978
tensor(8.2163e-06, device='cuda:0') tensor(8.4289e-07, device='cuda:0') tensor(1.7615e-10, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.302725
Average KL loss: 0.002392
Average total loss: 2.305117
tensor(9.1444e-06, device='cuda:0') tensor(9.5426e-07, device='cuda:0') tensor(-1.0941e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.302480
Average KL loss: 0.002406
Average total loss: 2.304886
tensor(9.3984e-06, device='cuda:0') tensor(1.0100e-06, device='cuda:0') tensor(2.1252e-11, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.302804
Average KL loss: 0.002415
Average total loss: 2.305219
tensor(1.0144e-05, device='cuda:0') tensor(1.2076e-06, device='cuda:0') tensor(-4.2698e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.302581
Average KL loss: 0.002440
Average total loss: 2.305020
tensor(9.9387e-06, device='cuda:0') tensor(1.2481e-06, device='cuda:0') tensor(-3.3304e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.302411
Average KL loss: 0.002420
Average total loss: 2.304831
tensor(1.1164e-05, device='cuda:0') tensor(1.0115e-06, device='cuda:0') tensor(1.7319e-11, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.302441
Average KL loss: 0.002402
Average total loss: 2.304843
tensor(1.0458e-05, device='cuda:0') tensor(9.5138e-07, device='cuda:0') tensor(2.6798e-10, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.302666
Average KL loss: 0.002397
Average total loss: 2.305062
tensor(1.0508e-05, device='cuda:0') tensor(9.3064e-07, device='cuda:0') tensor(-6.8365e-10, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.302522
Average KL loss: 0.002396
Average total loss: 2.304918
tensor(1.1153e-05, device='cuda:0') tensor(9.3068e-07, device='cuda:0') tensor(4.1745e-11, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.302700
Average KL loss: 0.002394
Average total loss: 2.305095
tensor(1.0751e-05, device='cuda:0') tensor(9.1745e-07, device='cuda:0') tensor(-1.1403e-10, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.302373
Average KL loss: 0.002394
Average total loss: 2.304767
tensor(1.0975e-05, device='cuda:0') tensor(9.2015e-07, device='cuda:0') tensor(1.4711e-10, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.302330
Average KL loss: 0.002394
Average total loss: 2.304724
tensor(1.2140e-05, device='cuda:0') tensor(9.2823e-07, device='cuda:0') tensor(6.1342e-11, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.302549
Average KL loss: 0.002396
Average total loss: 2.304945
tensor(1.1780e-05, device='cuda:0') tensor(9.3498e-07, device='cuda:0') tensor(2.4074e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.302167
Average KL loss: 0.002396
Average total loss: 2.304564
tensor(1.2175e-05, device='cuda:0') tensor(9.4386e-07, device='cuda:0') tensor(-7.2346e-10, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.302636
Average KL loss: 0.002398
Average total loss: 2.305034
tensor(1.1534e-05, device='cuda:0') tensor(9.4156e-07, device='cuda:0') tensor(1.6228e-11, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.302518
Average KL loss: 0.002398
Average total loss: 2.304916
tensor(1.1937e-05, device='cuda:0') tensor(9.4757e-07, device='cuda:0') tensor(-3.2955e-10, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.302741
Average KL loss: 0.002398
Average total loss: 2.305139
tensor(1.1472e-05, device='cuda:0') tensor(9.5102e-07, device='cuda:0') tensor(2.6998e-11, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.302575
Average KL loss: 0.002399
Average total loss: 2.304973
tensor(1.0979e-05, device='cuda:0') tensor(9.4854e-07, device='cuda:0') tensor(-9.1248e-11, device='cuda:0')
Epoch 26
Average batch original loss after noise: 2.302285
Average KL loss: 0.002399
Average total loss: 2.304684
tensor(1.1774e-05, device='cuda:0') tensor(9.5989e-07, device='cuda:0') tensor(-4.7025e-11, device='cuda:0')
Epoch 27
Average batch original loss after noise: 2.302735
Average KL loss: 0.002400
Average total loss: 2.305135
tensor(1.1229e-05, device='cuda:0') tensor(9.5665e-07, device='cuda:0') tensor(-3.6868e-10, device='cuda:0')
Epoch 28
Average batch original loss after noise: 2.302656
Average KL loss: 0.002400
Average total loss: 2.305056
tensor(1.1615e-05, device='cuda:0') tensor(9.6731e-07, device='cuda:0') tensor(3.7486e-10, device='cuda:0')
Epoch 29
Average batch original loss after noise: 2.302488
Average KL loss: 0.002402
Average total loss: 2.304890
tensor(1.1710e-05, device='cuda:0') tensor(9.7571e-07, device='cuda:0') tensor(-4.3704e-10, device='cuda:0')
Epoch 30
Average batch original loss after noise: 2.302759
Average KL loss: 0.002402
Average total loss: 2.305161
tensor(1.1380e-05, device='cuda:0') tensor(9.7513e-07, device='cuda:0') tensor(6.7585e-11, device='cuda:0')
Epoch 31
Average batch original loss after noise: 2.302341
Average KL loss: 0.002403
Average total loss: 2.304744
tensor(1.2238e-05, device='cuda:0') tensor(9.9337e-07, device='cuda:0') tensor(-4.7671e-10, device='cuda:0')
Epoch 32
Average batch original loss after noise: 2.302383
Average KL loss: 0.002405
Average total loss: 2.304787
tensor(1.2105e-05, device='cuda:0') tensor(9.9993e-07, device='cuda:0') tensor(-3.9173e-10, device='cuda:0')
Epoch 33
Average batch original loss after noise: 2.302597
Average KL loss: 0.002405
Average total loss: 2.305002
tensor(1.2229e-05, device='cuda:0') tensor(9.9461e-07, device='cuda:0') tensor(2.0791e-10, device='cuda:0')
Epoch 34
Average batch original loss after noise: 2.302977
Average KL loss: 0.002404
Average total loss: 2.305381
tensor(1.2208e-05, device='cuda:0') tensor(9.8956e-07, device='cuda:0') tensor(-3.5101e-10, device='cuda:0')
Epoch 35
Average batch original loss after noise: 2.302677
Average KL loss: 0.002403
Average total loss: 2.305080
tensor(1.2207e-05, device='cuda:0') tensor(9.8585e-07, device='cuda:0') tensor(8.0108e-11, device='cuda:0')
Epoch 36
Average batch original loss after noise: 2.302596
Average KL loss: 0.002403
Average total loss: 2.304999
tensor(1.2156e-05, device='cuda:0') tensor(9.8301e-07, device='cuda:0') tensor(-1.0182e-10, device='cuda:0')
Epoch 37
Average batch original loss after noise: 2.302462
Average KL loss: 0.002403
Average total loss: 2.304865
tensor(1.2150e-05, device='cuda:0') tensor(9.8114e-07, device='cuda:0') tensor(2.4772e-10, device='cuda:0')
Epoch 38
Average batch original loss after noise: 2.302357
Average KL loss: 0.002402
Average total loss: 2.304760
tensor(1.2164e-05, device='cuda:0') tensor(9.7993e-07, device='cuda:0') tensor(1.1640e-10, device='cuda:0')
Epoch 39
Average batch original loss after noise: 2.302401
Average KL loss: 0.002402
Average total loss: 2.304803
tensor(1.2099e-05, device='cuda:0') tensor(9.7843e-07, device='cuda:0') tensor(-2.5303e-10, device='cuda:0')
Epoch 40
Average batch original loss after noise: 2.302210
Average KL loss: 0.002402
Average total loss: 2.304612
tensor(1.2066e-05, device='cuda:0') tensor(9.7776e-07, device='cuda:0') tensor(1.7733e-10, device='cuda:0')
Epoch 41
Average batch original loss after noise: 2.302471
Average KL loss: 0.002402
Average total loss: 2.304873
tensor(1.1966e-05, device='cuda:0') tensor(9.7650e-07, device='cuda:0') tensor(9.4351e-11, device='cuda:0')
Epoch 42
Average batch original loss after noise: 2.302736
Average KL loss: 0.002402
Average total loss: 2.305138
tensor(1.1994e-05, device='cuda:0') tensor(9.7629e-07, device='cuda:0') tensor(-1.5415e-10, device='cuda:0')
 Percentile value: 8.433191396761686e-06
Non-zero model percentage: 49.999996185302734%, Non-zero mask percentage: 49.999996185302734%

--- Pruning Level [1/12]: ---
conv1.weight         | nonzeros =    1392 /    1728             ( 80.56%) | total_pruned =     336 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      62 /      64             ( 96.88%) | total_pruned =       2 | shape = torch.Size([64])
bn1.bias             | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   30923 /   36864             ( 83.88%) | total_pruned =    5941 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   23421 /   36864             ( 63.53%) | total_pruned =   13443 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   21295 /   36864             ( 57.77%) | total_pruned =   15569 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      60 /      64             ( 93.75%) | total_pruned =       4 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   20391 /   36864             ( 55.31%) | total_pruned =   16473 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      54 /      64             ( 84.38%) | total_pruned =      10 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   42098 /   73728             ( 57.10%) | total_pruned =   31630 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     127 /     128             ( 99.22%) | total_pruned =       1 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      48 /     128             ( 37.50%) | total_pruned =      80 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   81583 /  147456             ( 55.33%) | total_pruned =   65873 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4822 /    8192             ( 58.86%) | total_pruned =    3370 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     118 /     128             ( 92.19%) | total_pruned =      10 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   73677 /  147456             ( 49.97%) | total_pruned =   73779 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   73490 /  147456             ( 49.84%) | total_pruned =   73966 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      75 /     128             ( 58.59%) | total_pruned =      53 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  159083 /  294912             ( 53.94%) | total_pruned =  135829 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     248 /     256             ( 96.88%) | total_pruned =       8 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  309459 /  589824             ( 52.47%) | total_pruned =  280365 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     230 /     256             ( 89.84%) | total_pruned =      26 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   17594 /   32768             ( 53.69%) | total_pruned =   15174 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     193 /     256             ( 75.39%) | total_pruned =      63 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      34 /     256             ( 13.28%) | total_pruned =     222 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  288032 /  589824             ( 48.83%) | total_pruned =  301792 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     145 /     256             ( 56.64%) | total_pruned =     111 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =     111 /     256             ( 43.36%) | total_pruned =     145 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  275646 /  589824             ( 46.73%) | total_pruned =  314178 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     165 /     256             ( 64.45%) | total_pruned =      91 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      37 /     256             ( 14.45%) | total_pruned =     219 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  612735 / 1179648             ( 51.94%) | total_pruned =  566913 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     409 /     512             ( 79.88%) | total_pruned =     103 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =     125 /     512             ( 24.41%) | total_pruned =     387 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1171858 / 2359296             ( 49.67%) | total_pruned = 1187438 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     392 /     512             ( 76.56%) | total_pruned =     120 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     142 /     512             ( 27.73%) | total_pruned =     370 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   66956 /  131072             ( 51.08%) | total_pruned =   64116 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     386 /     512             ( 75.39%) | total_pruned =     126 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     137 /     512             ( 26.76%) | total_pruned =     375 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1130917 / 2359296             ( 47.93%) | total_pruned = 1228379 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     402 /     512             ( 78.52%) | total_pruned =     110 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =     146 /     512             ( 28.52%) | total_pruned =     366 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1171325 / 2359296             ( 49.65%) | total_pruned = 1187971 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     490 /     512             ( 95.70%) | total_pruned =      22 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     222 /     512             ( 43.36%) | total_pruned =     290 | shape = torch.Size([512])
linear.weight        | nonzeros =    2677 /    5120             ( 52.29%) | total_pruned =    2443 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       6 /      10             ( 60.00%) | total_pruned =       4 | shape = torch.Size([10])
alive: 5589381, pruned : 5589381, total: 11178762, Compression rate :       2.00x  ( 50.00% pruned)
Train Epoch: 57/100 Loss: 0.023757 Accuracy: 89.68 100.00 % Best test Accuracy: 89.73%
tensor(1.1924e-05, device='cuda:0') tensor(9.7553e-07, device='cuda:0') tensor(-5.9423e-09, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.294996
Average KL loss: 0.002613
Average total loss: 2.297609
tensor(3.6154e-05, device='cuda:0') tensor(3.9862e-06, device='cuda:0') tensor(1.3235e-09, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.295623
Average KL loss: 0.002991
Average total loss: 2.298614
tensor(4.9752e-05, device='cuda:0') tensor(6.3764e-06, device='cuda:0') tensor(-3.7574e-09, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.293903
Average KL loss: 0.003289
Average total loss: 2.297192
tensor(6.0523e-05, device='cuda:0') tensor(8.3098e-06, device='cuda:0') tensor(6.7775e-10, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.290268
Average KL loss: 0.003568
Average total loss: 2.293836
tensor(6.9966e-05, device='cuda:0') tensor(1.0596e-05, device='cuda:0') tensor(-6.2379e-09, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.294446
Average KL loss: 0.003843
Average total loss: 2.298289
tensor(7.2513e-05, device='cuda:0') tensor(1.2107e-05, device='cuda:0') tensor(-4.1923e-09, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.290264
Average KL loss: 0.004070
Average total loss: 2.294333
tensor(8.0689e-05, device='cuda:0') tensor(1.3678e-05, device='cuda:0') tensor(-1.3279e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.289852
Average KL loss: 0.004359
Average total loss: 2.294211
tensor(9.1937e-05, device='cuda:0') tensor(1.6076e-05, device='cuda:0') tensor(-5.8623e-09, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.285926
Average KL loss: 0.004661
Average total loss: 2.290587
tensor(0.0001, device='cuda:0') tensor(1.8357e-05, device='cuda:0') tensor(-1.0303e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.284451
Average KL loss: 0.005016
Average total loss: 2.289468
tensor(0.0001, device='cuda:0') tensor(2.1439e-05, device='cuda:0') tensor(-4.6533e-09, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.283957
Average KL loss: 0.005451
Average total loss: 2.289408
tensor(0.0001, device='cuda:0') tensor(2.3684e-05, device='cuda:0') tensor(-6.7895e-09, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.286178
Average KL loss: 0.005695
Average total loss: 2.291873
tensor(0.0001, device='cuda:0') tensor(2.5427e-05, device='cuda:0') tensor(-3.8023e-09, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.283471
Average KL loss: 0.005918
Average total loss: 2.289389
tensor(0.0001, device='cuda:0') tensor(2.7265e-05, device='cuda:0') tensor(-5.8776e-09, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.282468
Average KL loss: 0.006221
Average total loss: 2.288688
tensor(0.0001, device='cuda:0') tensor(2.9290e-05, device='cuda:0') tensor(-1.7977e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.276035
Average KL loss: 0.006568
Average total loss: 2.282604
tensor(0.0001, device='cuda:0') tensor(3.2509e-05, device='cuda:0') tensor(-3.9559e-09, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.280582
Average KL loss: 0.006916
Average total loss: 2.287498
tensor(0.0002, device='cuda:0') tensor(3.4457e-05, device='cuda:0') tensor(-1.2925e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.281203
Average KL loss: 0.007289
Average total loss: 2.288492
tensor(0.0002, device='cuda:0') tensor(3.7146e-05, device='cuda:0') tensor(-1.4214e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.266392
Average KL loss: 0.007755
Average total loss: 2.274147
tensor(0.0002, device='cuda:0') tensor(4.1787e-05, device='cuda:0') tensor(-2.2671e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.267062
Average KL loss: 0.008409
Average total loss: 2.275471
tensor(0.0002, device='cuda:0') tensor(4.6434e-05, device='cuda:0') tensor(-2.4140e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.267291
Average KL loss: 0.009033
Average total loss: 2.276323
tensor(0.0002, device='cuda:0') tensor(5.0826e-05, device='cuda:0') tensor(5.4088e-10, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.265064
Average KL loss: 0.009687
Average total loss: 2.274750
tensor(0.0002, device='cuda:0') tensor(5.5791e-05, device='cuda:0') tensor(-2.1119e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.263189
Average KL loss: 0.010323
Average total loss: 2.273512
tensor(0.0002, device='cuda:0') tensor(5.9685e-05, device='cuda:0') tensor(-1.8162e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.258696
Average KL loss: 0.010943
Average total loss: 2.269640
tensor(0.0002, device='cuda:0') tensor(6.5476e-05, device='cuda:0') tensor(-2.3445e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.251158
Average KL loss: 0.011783
Average total loss: 2.262941
tensor(0.0002, device='cuda:0') tensor(7.1227e-05, device='cuda:0') tensor(-2.3585e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.247898
Average KL loss: 0.012771
Average total loss: 2.260668
tensor(0.0003, device='cuda:0') tensor(7.8554e-05, device='cuda:0') tensor(-1.1536e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.243541
Average KL loss: 0.013696
Average total loss: 2.257237
tensor(0.0003, device='cuda:0') tensor(8.5766e-05, device='cuda:0') tensor(-5.4550e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 2.240375
Average KL loss: 0.014620
Average total loss: 2.254994
tensor(0.0003, device='cuda:0') tensor(9.2379e-05, device='cuda:0') tensor(-2.0109e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 2.237187
Average KL loss: 0.015685
Average total loss: 2.252872
tensor(0.0003, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-9.8398e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 2.233013
Average KL loss: 0.016732
Average total loss: 2.249746
tensor(0.0003, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-2.0168e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 2.235068
Average KL loss: 0.017769
Average total loss: 2.252838
tensor(0.0003, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-2.5601e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 2.216933
Average KL loss: 0.018863
Average total loss: 2.235795
tensor(0.0003, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-3.7843e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 2.206082
Average KL loss: 0.020344
Average total loss: 2.226427
tensor(0.0004, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-2.4326e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 2.209884
Average KL loss: 0.021835
Average total loss: 2.231719
tensor(0.0004, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-2.7752e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 2.200499
Average KL loss: 0.023116
Average total loss: 2.223615
tensor(0.0004, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-2.1622e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 2.189034
Average KL loss: 0.024585
Average total loss: 2.213618
tensor(0.0004, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-3.8015e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 2.189104
Average KL loss: 0.026069
Average total loss: 2.215173
tensor(0.0004, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-3.8733e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 2.167944
Average KL loss: 0.027583
Average total loss: 2.195527
tensor(0.0004, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-5.8896e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 2.161435
Average KL loss: 0.029164
Average total loss: 2.190599
tensor(0.0005, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-2.8239e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 2.155130
Average KL loss: 0.030837
Average total loss: 2.185967
tensor(0.0005, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-3.1533e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 2.142375
Average KL loss: 0.032565
Average total loss: 2.174940
tensor(0.0005, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-5.3046e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 2.140620
Average KL loss: 0.034244
Average total loss: 2.174864
tensor(0.0005, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-3.8955e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 2.135590
Average KL loss: 0.036034
Average total loss: 2.171623
tensor(0.0005, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-2.8052e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 2.116497
Average KL loss: 0.037674
Average total loss: 2.154170
tensor(0.0005, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-2.9440e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 2.108065
Average KL loss: 0.039469
Average total loss: 2.147534
tensor(0.0006, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-5.1983e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 2.100688
Average KL loss: 0.041323
Average total loss: 2.142011
tensor(0.0006, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-3.2282e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 2.077711
Average KL loss: 0.042964
Average total loss: 2.120675
tensor(0.0006, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-5.5064e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 2.073454
Average KL loss: 0.044875
Average total loss: 2.118330
tensor(0.0006, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-3.4376e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 2.058392
Average KL loss: 0.046492
Average total loss: 2.104884
tensor(0.0006, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-5.2418e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 2.070566
Average KL loss: 0.048354
Average total loss: 2.118920
tensor(0.0007, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-3.1648e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 2.050896
Average KL loss: 0.049856
Average total loss: 2.100752
tensor(0.0007, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-5.9511e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 2.036438
Average KL loss: 0.051421
Average total loss: 2.087859
tensor(0.0007, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-5.2295e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 2.042984
Average KL loss: 0.053237
Average total loss: 2.096221
tensor(0.0007, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-4.3813e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 2.014323
Average KL loss: 0.054893
Average total loss: 2.069216
tensor(0.0007, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-5.4449e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 2.014909
Average KL loss: 0.056468
Average total loss: 2.071377
tensor(0.0007, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-5.9312e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 2.001537
Average KL loss: 0.058041
Average total loss: 2.059578
tensor(0.0008, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-5.2026e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.974673
Average KL loss: 0.059707
Average total loss: 2.034380
tensor(0.0008, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-5.9591e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.971252
Average KL loss: 0.061539
Average total loss: 2.032792
tensor(0.0008, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-3.5431e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.983687
Average KL loss: 0.063248
Average total loss: 2.046935
tensor(0.0008, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-5.8842e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.932712
Average KL loss: 0.064952
Average total loss: 1.997664
tensor(0.0008, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-6.8289e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 1.943725
Average KL loss: 0.066710
Average total loss: 2.010435
tensor(0.0008, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-4.8162e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 1.932992
Average KL loss: 0.068292
Average total loss: 2.001284
tensor(0.0009, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-5.3035e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 1.901433
Average KL loss: 0.070143
Average total loss: 1.971576
tensor(0.0009, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-4.5383e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 1.912000
Average KL loss: 0.072047
Average total loss: 1.984047
tensor(0.0009, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-3.9891e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 1.888770
Average KL loss: 0.073915
Average total loss: 1.962685
tensor(0.0009, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-5.9198e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 1.883094
Average KL loss: 0.075728
Average total loss: 1.958822
tensor(0.0009, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(-3.8599e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 1.881684
Average KL loss: 0.077358
Average total loss: 1.959043
tensor(0.0009, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-5.7161e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 1.845572
Average KL loss: 0.078973
Average total loss: 1.924545
tensor(0.0010, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-5.5447e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 1.843852
Average KL loss: 0.080712
Average total loss: 1.924564
tensor(0.0010, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-5.4098e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 1.830607
Average KL loss: 0.082323
Average total loss: 1.912930
tensor(0.0010, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-7.3655e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 1.816108
Average KL loss: 0.083965
Average total loss: 1.900073
tensor(0.0010, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-4.7441e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 1.804343
Average KL loss: 0.085375
Average total loss: 1.889718
tensor(0.0010, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-3.9474e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 1.810453
Average KL loss: 0.087105
Average total loss: 1.897558
tensor(0.0010, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-5.0010e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 1.803836
Average KL loss: 0.089016
Average total loss: 1.892852
tensor(0.0011, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-5.1742e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 1.791960
Average KL loss: 0.090640
Average total loss: 1.882600
tensor(0.0011, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-7.8138e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 1.763810
Average KL loss: 0.092136
Average total loss: 1.855946
tensor(0.0011, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-7.3815e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 1.767020
Average KL loss: 0.093370
Average total loss: 1.860390
tensor(0.0011, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-6.6296e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 1.736973
Average KL loss: 0.094811
Average total loss: 1.831784
tensor(0.0011, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-7.6685e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 1.721208
Average KL loss: 0.096412
Average total loss: 1.817619
tensor(0.0011, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-5.1838e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 1.715690
Average KL loss: 0.097995
Average total loss: 1.813686
tensor(0.0011, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-5.5717e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 1.707411
Average KL loss: 0.099709
Average total loss: 1.807120
tensor(0.0012, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-7.0836e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 1.698853
Average KL loss: 0.101023
Average total loss: 1.799877
tensor(0.0012, device='cuda:0') tensor(0.0007, device='cuda:0') tensor(-7.5534e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 1.700057
Average KL loss: 0.102389
Average total loss: 1.802446
tensor(0.0012, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-4.9111e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 1.686566
Average KL loss: 0.103825
Average total loss: 1.790391
tensor(0.0012, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-4.5813e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 1.653923
Average KL loss: 0.105267
Average total loss: 1.759190
tensor(0.0012, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-6.2954e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 1.668342
Average KL loss: 0.106364
Average total loss: 1.774706
tensor(0.0012, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-6.8068e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 1.638206
Average KL loss: 0.107510
Average total loss: 1.745716
tensor(0.0012, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-7.8453e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 1.645428
Average KL loss: 0.108919
Average total loss: 1.754347
tensor(0.0012, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-6.1902e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 1.629195
Average KL loss: 0.110299
Average total loss: 1.739494
tensor(0.0012, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-9.2223e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 1.602119
Average KL loss: 0.111803
Average total loss: 1.713923
tensor(0.0013, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-7.3296e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 1.607458
Average KL loss: 0.113259
Average total loss: 1.720717
tensor(0.0013, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-7.8256e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 1.575741
Average KL loss: 0.114698
Average total loss: 1.690439
tensor(0.0013, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-4.7516e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 1.586561
Average KL loss: 0.115926
Average total loss: 1.702487
tensor(0.0013, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-7.6000e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 1.548951
Average KL loss: 0.117267
Average total loss: 1.666218
tensor(0.0013, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-6.2374e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 1.551114
Average KL loss: 0.118682
Average total loss: 1.669795
tensor(0.0013, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-5.3648e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 1.548100
Average KL loss: 0.119640
Average total loss: 1.667740
tensor(0.0013, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-6.4525e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 1.549695
Average KL loss: 0.120933
Average total loss: 1.670629
tensor(0.0014, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-5.9157e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 1.565209
Average KL loss: 0.122126
Average total loss: 1.687335
tensor(0.0014, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-9.0789e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 1.537908
Average KL loss: 0.123478
Average total loss: 1.661385
tensor(0.0014, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(-7.0988e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 1.520968
Average KL loss: 0.124933
Average total loss: 1.645900
tensor(0.0014, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-7.1245e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 1.513810
Average KL loss: 0.126157
Average total loss: 1.639967
tensor(0.0014, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-6.5928e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 1.479126
Average KL loss: 0.127246
Average total loss: 1.606371
tensor(0.0014, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-9.1754e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 1.478350
Average KL loss: 0.128354
Average total loss: 1.606705
tensor(0.0014, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-5.3173e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 1.487286
Average KL loss: 0.129505
Average total loss: 1.616791
tensor(0.0014, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-6.5785e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 1.457823
Average KL loss: 0.130440
Average total loss: 1.588263
tensor(0.0014, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-5.2980e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 1.465101
Average KL loss: 0.131379
Average total loss: 1.596480
tensor(0.0014, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-5.8732e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 1.474930
Average KL loss: 0.132356
Average total loss: 1.607286
tensor(0.0014, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-5.7859e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 1.456693
Average KL loss: 0.133333
Average total loss: 1.590026
tensor(0.0014, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-7.1630e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 1.433202
Average KL loss: 0.134329
Average total loss: 1.567532
tensor(0.0015, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-6.1244e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 1.433264
Average KL loss: 0.135232
Average total loss: 1.568496
tensor(0.0015, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-5.5305e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 1.411683
Average KL loss: 0.136235
Average total loss: 1.547918
tensor(0.0015, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-6.9052e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 1.431246
Average KL loss: 0.137420
Average total loss: 1.568666
tensor(0.0015, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-8.2795e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 1.411929
Average KL loss: 0.138421
Average total loss: 1.550350
tensor(0.0015, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-5.6990e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 1.401288
Average KL loss: 0.139359
Average total loss: 1.540648
tensor(0.0015, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-6.1606e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 1.380645
Average KL loss: 0.140240
Average total loss: 1.520885
tensor(0.0015, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-8.8375e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 1.383501
Average KL loss: 0.141384
Average total loss: 1.524884
tensor(0.0015, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-8.2860e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 1.363488
Average KL loss: 0.142375
Average total loss: 1.505863
tensor(0.0015, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-6.9118e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 1.385129
Average KL loss: 0.143293
Average total loss: 1.528423
tensor(0.0015, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-5.9037e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 1.356800
Average KL loss: 0.144209
Average total loss: 1.501009
tensor(0.0016, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-6.8636e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 1.349418
Average KL loss: 0.145138
Average total loss: 1.494556
tensor(0.0016, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-5.9796e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 1.361153
Average KL loss: 0.146060
Average total loss: 1.507214
tensor(0.0016, device='cuda:0') tensor(0.0011, device='cuda:0') tensor(-7.7420e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 1.348739
Average KL loss: 0.147278
Average total loss: 1.496018
tensor(0.0016, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-7.6400e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 1.325391
Average KL loss: 0.148262
Average total loss: 1.473653
tensor(0.0016, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-5.6047e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 1.314519
Average KL loss: 0.149360
Average total loss: 1.463879
tensor(0.0016, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-6.2234e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 1.297708
Average KL loss: 0.150368
Average total loss: 1.448075
tensor(0.0016, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-6.7823e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 1.292921
Average KL loss: 0.151278
Average total loss: 1.444199
tensor(0.0016, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-8.5995e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 1.306115
Average KL loss: 0.152200
Average total loss: 1.458315
tensor(0.0016, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-5.3118e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 1.281696
Average KL loss: 0.153190
Average total loss: 1.434885
tensor(0.0016, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-9.9402e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 1.270154
Average KL loss: 0.154084
Average total loss: 1.424238
tensor(0.0016, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-8.1038e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 1.257609
Average KL loss: 0.154946
Average total loss: 1.412556
tensor(0.0016, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-4.9209e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 1.269592
Average KL loss: 0.155650
Average total loss: 1.425242
tensor(0.0017, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-6.2313e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 1.251154
Average KL loss: 0.156517
Average total loss: 1.407672
tensor(0.0017, device='cuda:0') tensor(0.0012, device='cuda:0') tensor(-5.8744e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 1.237502
Average KL loss: 0.157289
Average total loss: 1.394791
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.3122e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 1.253923
Average KL loss: 0.158070
Average total loss: 1.411992
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-8.5190e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 1.239595
Average KL loss: 0.159040
Average total loss: 1.398634
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-5.6757e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 1.230417
Average KL loss: 0.159692
Average total loss: 1.390109
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-3.3108e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 1.217735
Average KL loss: 0.160514
Average total loss: 1.378248
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-8.1793e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 1.204139
Average KL loss: 0.161192
Average total loss: 1.365331
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.8087e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 1.219237
Average KL loss: 0.161921
Average total loss: 1.381158
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-5.3298e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 1.187375
Average KL loss: 0.162425
Average total loss: 1.349800
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-7.8823e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 1.178950
Average KL loss: 0.163004
Average total loss: 1.341955
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.3349e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 1.174537
Average KL loss: 0.163690
Average total loss: 1.338227
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-4.4300e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 1.174552
Average KL loss: 0.164438
Average total loss: 1.338990
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.2363e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 1.174465
Average KL loss: 0.165341
Average total loss: 1.339806
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-3.2606e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 1.150552
Average KL loss: 0.166203
Average total loss: 1.316754
tensor(0.0017, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.6252e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 1.174579
Average KL loss: 0.166907
Average total loss: 1.341486
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-4.8828e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 1.166633
Average KL loss: 0.167871
Average total loss: 1.334505
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-6.1094e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 1.155565
Average KL loss: 0.168742
Average total loss: 1.324307
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-8.2881e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 1.135411
Average KL loss: 0.169423
Average total loss: 1.304834
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-5.2170e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 1.140124
Average KL loss: 0.169981
Average total loss: 1.310105
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-6.5635e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 1.127296
Average KL loss: 0.170552
Average total loss: 1.297848
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-6.1540e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 1.113856
Average KL loss: 0.171110
Average total loss: 1.284966
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-4.5426e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 1.124914
Average KL loss: 0.171862
Average total loss: 1.296776
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-5.6450e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 1.105061
Average KL loss: 0.172563
Average total loss: 1.277624
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-6.9968e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 1.106031
Average KL loss: 0.173297
Average total loss: 1.279328
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-7.2111e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 1.103501
Average KL loss: 0.173975
Average total loss: 1.277476
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-5.2506e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 1.085073
Average KL loss: 0.174703
Average total loss: 1.259776
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-4.7702e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 1.092897
Average KL loss: 0.175340
Average total loss: 1.268237
tensor(0.0018, device='cuda:0') tensor(0.0014, device='cuda:0') tensor(-4.4505e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 1.088562
Average KL loss: 0.176200
Average total loss: 1.264762
tensor(0.0018, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.9702e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 1.068194
Average KL loss: 0.176816
Average total loss: 1.245010
tensor(0.0018, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.9985e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 1.077037
Average KL loss: 0.177337
Average total loss: 1.254374
tensor(0.0018, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.0842e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 1.062657
Average KL loss: 0.177948
Average total loss: 1.240605
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.0997e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 1.061568
Average KL loss: 0.178660
Average total loss: 1.240227
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.5619e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 1.058862
Average KL loss: 0.179241
Average total loss: 1.238102
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.3618e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 1.052034
Average KL loss: 0.179869
Average total loss: 1.231903
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.5076e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 1.038805
Average KL loss: 0.180514
Average total loss: 1.219319
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.2399e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 1.043161
Average KL loss: 0.181103
Average total loss: 1.224264
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.2567e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 1.018286
Average KL loss: 0.181594
Average total loss: 1.199880
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.1215e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 1.013987
Average KL loss: 0.181945
Average total loss: 1.195932
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.8493e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 1.026176
Average KL loss: 0.182344
Average total loss: 1.208520
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.5293e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 1.046258
Average KL loss: 0.182987
Average total loss: 1.229245
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.5771e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.991923
Average KL loss: 0.183614
Average total loss: 1.175537
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.0241e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 1.005457
Average KL loss: 0.184007
Average total loss: 1.189464
tensor(0.0019, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.4961e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.998558
Average KL loss: 0.184457
Average total loss: 1.183016
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.8842e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.973738
Average KL loss: 0.184982
Average total loss: 1.158720
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-2.7726e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 1.019387
Average KL loss: 0.185595
Average total loss: 1.204983
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.0234e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.986530
Average KL loss: 0.186152
Average total loss: 1.172681
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-6.0054e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.981556
Average KL loss: 0.186666
Average total loss: 1.168222
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.2615e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.971550
Average KL loss: 0.187194
Average total loss: 1.158744
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-3.9144e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.959484
Average KL loss: 0.187580
Average total loss: 1.147064
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.4361e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.961766
Average KL loss: 0.187948
Average total loss: 1.149714
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-6.1195e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.945473
Average KL loss: 0.188246
Average total loss: 1.133719
tensor(0.0019, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-3.4974e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.977984
Average KL loss: 0.188693
Average total loss: 1.166678
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.0724e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.955021
Average KL loss: 0.189293
Average total loss: 1.144315
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.2052e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.941317
Average KL loss: 0.189687
Average total loss: 1.131003
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.4352e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.952500
Average KL loss: 0.189992
Average total loss: 1.142492
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.7548e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.967374
Average KL loss: 0.190592
Average total loss: 1.157967
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-3.8835e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.935854
Average KL loss: 0.190959
Average total loss: 1.126813
tensor(0.0020, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.6639e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.924323
Average KL loss: 0.191315
Average total loss: 1.115638
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-4.7004e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.922467
Average KL loss: 0.191647
Average total loss: 1.114114
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-7.0254e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.924321
Average KL loss: 0.191999
Average total loss: 1.116320
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-6.3145e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.911168
Average KL loss: 0.192368
Average total loss: 1.103537
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-4.1955e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.927321
Average KL loss: 0.192900
Average total loss: 1.120220
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-4.9373e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.905397
Average KL loss: 0.193477
Average total loss: 1.098875
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.9396e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.899321
Average KL loss: 0.193783
Average total loss: 1.093104
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-4.7006e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.884040
Average KL loss: 0.194000
Average total loss: 1.078040
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-4.3143e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.906854
Average KL loss: 0.194286
Average total loss: 1.101140
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-5.7883e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.897859
Average KL loss: 0.194639
Average total loss: 1.092497
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.8592e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.901250
Average KL loss: 0.194957
Average total loss: 1.096207
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-5.2840e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.867783
Average KL loss: 0.195388
Average total loss: 1.063171
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-5.3359e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.873918
Average KL loss: 0.195673
Average total loss: 1.069591
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-4.6472e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.875696
Average KL loss: 0.196026
Average total loss: 1.071721
 Percentile value: 0.0003962914051953703
Non-zero model percentage: 25.000003814697266%, Non-zero mask percentage: 25.000003814697266%

--- Pruning Level [2/12]: ---
conv1.weight         | nonzeros =    1107 /    1728             ( 64.06%) | total_pruned =     621 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
bn1.weight           | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
bn1.bias             | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   26507 /   36864             ( 71.90%) | total_pruned =   10357 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      52 /      64             ( 81.25%) | total_pruned =      12 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   15038 /   36864             ( 40.79%) | total_pruned =   21826 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      42 /      64             ( 65.62%) | total_pruned =      22 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   13275 /   36864             ( 36.01%) | total_pruned =   23589 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      56 /      64             ( 87.50%) | total_pruned =       8 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   11449 /   36864             ( 31.06%) | total_pruned =   25415 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   22931 /   73728             ( 31.10%) | total_pruned =   50797 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      30 /     128             ( 23.44%) | total_pruned =      98 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   43997 /  147456             ( 29.84%) | total_pruned =  103459 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     114 /     128             ( 89.06%) | total_pruned =      14 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    2657 /    8192             ( 32.43%) | total_pruned =    5535 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      92 /     128             ( 71.88%) | total_pruned =      36 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   35995 /  147456             ( 24.41%) | total_pruned =  111461 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     112 /     128             ( 87.50%) | total_pruned =      16 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      32 /     128             ( 25.00%) | total_pruned =      96 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   33481 /  147456             ( 22.71%) | total_pruned =  113975 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      70 /     128             ( 54.69%) | total_pruned =      58 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   86716 /  294912             ( 29.40%) | total_pruned =  208196 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  162834 /  589824             ( 27.61%) | total_pruned =  426990 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     190 /     256             ( 74.22%) | total_pruned =      66 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      21 /     256             (  8.20%) | total_pruned =     235 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    8994 /   32768             ( 27.45%) | total_pruned =   23774 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     171 /     256             ( 66.80%) | total_pruned =      85 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  132860 /  589824             ( 22.53%) | total_pruned =  456964 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     235 /     256             ( 91.80%) | total_pruned =      21 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      60 /     256             ( 23.44%) | total_pruned =     196 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  119731 /  589824             ( 20.30%) | total_pruned =  470093 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     149 /     256             ( 58.20%) | total_pruned =     107 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  316027 / 1179648             ( 26.79%) | total_pruned =  863621 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     464 /     512             ( 90.62%) | total_pruned =      48 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     394 /     512             ( 76.95%) | total_pruned =     118 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      66 /     512             ( 12.89%) | total_pruned =     446 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  578182 / 2359296             ( 24.51%) | total_pruned = 1781114 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     437 /     512             ( 85.35%) | total_pruned =      75 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     345 /     512             ( 67.38%) | total_pruned =     167 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      82 /     512             ( 16.02%) | total_pruned =     430 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   33434 /  131072             ( 25.51%) | total_pruned =   97638 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     318 /     512             ( 62.11%) | total_pruned =     194 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      81 /     512             ( 15.82%) | total_pruned =     431 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  533939 / 2359296             ( 22.63%) | total_pruned = 1825357 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     472 /     512             ( 92.19%) | total_pruned =      40 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     387 /     512             ( 75.59%) | total_pruned =     125 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      46 /     512             (  8.98%) | total_pruned =     466 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  604981 / 2359296             ( 25.64%) | total_pruned = 1754315 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     465 /     512             ( 90.82%) | total_pruned =      47 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     421 /     512             ( 82.23%) | total_pruned =      91 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     201 /     512             ( 39.26%) | total_pruned =     311 | shape = torch.Size([512])
linear.weight        | nonzeros =    2077 /    5120             ( 40.57%) | total_pruned =    3043 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       5 /      10             ( 50.00%) | total_pruned =       5 | shape = torch.Size([10])
alive: 2794691, pruned : 8384071, total: 11178762, Compression rate :       4.00x  ( 75.00% pruned)
Train Epoch: 51/100 Loss: 0.016344 Accuracy: 88.57 100.00 % Best test Accuracy: 88.57%
tensor(0.0020, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-7.0975e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.357798
Average KL loss: 0.182818
Average total loss: 1.540617
tensor(0.0027, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-6.7920e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.311282
Average KL loss: 0.170066
Average total loss: 1.481348
tensor(0.0028, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.9991e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.307840
Average KL loss: 0.164518
Average total loss: 1.472357
tensor(0.0029, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.9752e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.281107
Average KL loss: 0.161837
Average total loss: 1.442943
tensor(0.0029, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.5552e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.237129
Average KL loss: 0.160724
Average total loss: 1.397853
tensor(0.0029, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.7416e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.216260
Average KL loss: 0.160427
Average total loss: 1.376687
tensor(0.0029, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.4456e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.184342
Average KL loss: 0.160860
Average total loss: 1.345201
tensor(0.0028, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-8.8425e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.189103
Average KL loss: 0.161611
Average total loss: 1.350713
tensor(0.0028, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.9733e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.160979
Average KL loss: 0.162560
Average total loss: 1.323538
tensor(0.0028, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-3.4650e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.137078
Average KL loss: 0.163710
Average total loss: 1.300788
tensor(0.0028, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.2448e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.122727
Average KL loss: 0.164978
Average total loss: 1.287705
tensor(0.0028, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-6.9507e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.131513
Average KL loss: 0.166211
Average total loss: 1.297724
tensor(0.0028, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-5.4807e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.104638
Average KL loss: 0.167550
Average total loss: 1.272189
tensor(0.0027, device='cuda:0') tensor(0.0015, device='cuda:0') tensor(-4.1360e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.086828
Average KL loss: 0.168942
Average total loss: 1.255770
tensor(0.0027, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-3.9218e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.038642
Average KL loss: 0.170382
Average total loss: 1.209024
tensor(0.0027, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.5330e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 1.043176
Average KL loss: 0.171496
Average total loss: 1.214671
tensor(0.0027, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-3.8534e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.048518
Average KL loss: 0.172738
Average total loss: 1.221256
tensor(0.0027, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.5092e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 1.048942
Average KL loss: 0.174074
Average total loss: 1.223016
tensor(0.0026, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-5.4299e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 1.010547
Average KL loss: 0.175402
Average total loss: 1.185950
tensor(0.0026, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-7.1839e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 1.037528
Average KL loss: 0.176569
Average total loss: 1.214097
tensor(0.0026, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-3.7663e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 1.022399
Average KL loss: 0.177855
Average total loss: 1.200254
tensor(0.0026, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-6.0079e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 1.008147
Average KL loss: 0.178984
Average total loss: 1.187131
tensor(0.0026, device='cuda:0') tensor(0.0016, device='cuda:0') tensor(-4.4802e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 1.000824
Average KL loss: 0.180195
Average total loss: 1.181020
tensor(0.0026, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-5.1776e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 1.003412
Average KL loss: 0.181433
Average total loss: 1.184845
tensor(0.0026, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.4699e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.972693
Average KL loss: 0.182493
Average total loss: 1.155186
tensor(0.0026, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-5.3145e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.948990
Average KL loss: 0.183367
Average total loss: 1.132357
tensor(0.0025, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.5190e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.956074
Average KL loss: 0.184397
Average total loss: 1.140471
tensor(0.0025, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-4.6146e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.948790
Average KL loss: 0.185528
Average total loss: 1.134318
tensor(0.0025, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-6.1631e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.950276
Average KL loss: 0.186522
Average total loss: 1.136798
tensor(0.0025, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-2.8752e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.960570
Average KL loss: 0.187585
Average total loss: 1.148155
tensor(0.0025, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-4.4022e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.952241
Average KL loss: 0.188651
Average total loss: 1.140892
tensor(0.0025, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-3.9191e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.910149
Average KL loss: 0.189617
Average total loss: 1.099766
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.7163e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.919287
Average KL loss: 0.190324
Average total loss: 1.109611
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.7200e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.893785
Average KL loss: 0.191010
Average total loss: 1.084794
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-5.7051e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.892215
Average KL loss: 0.191770
Average total loss: 1.083985
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-3.2917e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.901345
Average KL loss: 0.192492
Average total loss: 1.093836
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-7.6137e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.893850
Average KL loss: 0.193288
Average total loss: 1.087138
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.2130e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.882821
Average KL loss: 0.193942
Average total loss: 1.076763
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-3.4946e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.868027
Average KL loss: 0.194741
Average total loss: 1.062768
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-5.0462e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.874904
Average KL loss: 0.195350
Average total loss: 1.070255
tensor(0.0025, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-1.7246e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.885996
Average KL loss: 0.196144
Average total loss: 1.082139
tensor(0.0024, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-5.0421e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.866118
Average KL loss: 0.196878
Average total loss: 1.062995
tensor(0.0024, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-3.8625e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.862162
Average KL loss: 0.197556
Average total loss: 1.059718
tensor(0.0024, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-3.9835e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.860397
Average KL loss: 0.198358
Average total loss: 1.058755
tensor(0.0024, device='cuda:0') tensor(0.0018, device='cuda:0') tensor(-4.4007e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.855131
Average KL loss: 0.198974
Average total loss: 1.054105
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.2706e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.865903
Average KL loss: 0.199522
Average total loss: 1.065425
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.9532e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.862506
Average KL loss: 0.200282
Average total loss: 1.062788
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.6042e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.852037
Average KL loss: 0.201013
Average total loss: 1.053050
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-5.2092e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.832913
Average KL loss: 0.201578
Average total loss: 1.034491
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.6820e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.836927
Average KL loss: 0.202069
Average total loss: 1.038997
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.0111e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.843169
Average KL loss: 0.202667
Average total loss: 1.045836
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.2169e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.827713
Average KL loss: 0.203291
Average total loss: 1.031005
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.5685e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.838907
Average KL loss: 0.203956
Average total loss: 1.042863
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.4676e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.829375
Average KL loss: 0.204515
Average total loss: 1.033889
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-4.2486e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.819245
Average KL loss: 0.205003
Average total loss: 1.024248
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.9215e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.801574
Average KL loss: 0.205415
Average total loss: 1.006989
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-2.6545e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.814152
Average KL loss: 0.205863
Average total loss: 1.020014
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-1.7532e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.801470
Average KL loss: 0.206320
Average total loss: 1.007790
tensor(0.0024, device='cuda:0') tensor(0.0019, device='cuda:0') tensor(-3.9626e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.799708
Average KL loss: 0.206920
Average total loss: 1.006628
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-5.0276e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.793618
Average KL loss: 0.207495
Average total loss: 1.001113
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.3177e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.797757
Average KL loss: 0.208052
Average total loss: 1.005809
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.0309e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.788078
Average KL loss: 0.208379
Average total loss: 0.996458
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-6.2728e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.791442
Average KL loss: 0.208752
Average total loss: 1.000194
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.0646e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.770341
Average KL loss: 0.209129
Average total loss: 0.979469
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-5.1190e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.793475
Average KL loss: 0.209582
Average total loss: 1.003057
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.9366e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.804005
Average KL loss: 0.210317
Average total loss: 1.014323
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.1353e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.788121
Average KL loss: 0.210755
Average total loss: 0.998876
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-1.8025e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.755131
Average KL loss: 0.211129
Average total loss: 0.966260
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.4974e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.749549
Average KL loss: 0.211384
Average total loss: 0.960933
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.6894e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.770421
Average KL loss: 0.211826
Average total loss: 0.982247
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-3.4428e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.757143
Average KL loss: 0.212257
Average total loss: 0.969401
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.6115e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.755331
Average KL loss: 0.212606
Average total loss: 0.967937
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.1794e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.756994
Average KL loss: 0.212993
Average total loss: 0.969987
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-4.1930e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.753193
Average KL loss: 0.213278
Average total loss: 0.966471
tensor(0.0024, device='cuda:0') tensor(0.0020, device='cuda:0') tensor(-2.4809e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.736923
Average KL loss: 0.213555
Average total loss: 0.950478
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-5.2472e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.741869
Average KL loss: 0.213871
Average total loss: 0.955740
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-3.3364e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.741871
Average KL loss: 0.214115
Average total loss: 0.955987
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-3.6273e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.742352
Average KL loss: 0.214440
Average total loss: 0.956793
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.1495e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.730246
Average KL loss: 0.214768
Average total loss: 0.945014
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.8183e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.741483
Average KL loss: 0.214995
Average total loss: 0.956479
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-5.6535e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.723275
Average KL loss: 0.215383
Average total loss: 0.938658
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-3.7076e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.715571
Average KL loss: 0.215637
Average total loss: 0.931208
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-4.2708e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.724887
Average KL loss: 0.215966
Average total loss: 0.940853
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.2720e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.731610
Average KL loss: 0.216294
Average total loss: 0.947904
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.8776e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.723000
Average KL loss: 0.216527
Average total loss: 0.939526
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-1.3907e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.716759
Average KL loss: 0.216749
Average total loss: 0.933508
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.1574e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.704671
Average KL loss: 0.216928
Average total loss: 0.921598
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-2.6997e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.698357
Average KL loss: 0.216986
Average total loss: 0.915342
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-4.3655e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.721568
Average KL loss: 0.217336
Average total loss: 0.938904
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-4.8942e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.704980
Average KL loss: 0.217696
Average total loss: 0.922676
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-4.8533e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.706840
Average KL loss: 0.218036
Average total loss: 0.924876
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-3.4126e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.711545
Average KL loss: 0.218200
Average total loss: 0.929745
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-3.4510e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.701098
Average KL loss: 0.218356
Average total loss: 0.919453
tensor(0.0024, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-4.2685e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.706801
Average KL loss: 0.218685
Average total loss: 0.925486
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.9321e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.682277
Average KL loss: 0.219023
Average total loss: 0.901300
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-5.0920e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.700209
Average KL loss: 0.219167
Average total loss: 0.919376
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.1959e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.685581
Average KL loss: 0.219336
Average total loss: 0.904917
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.4895e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.696065
Average KL loss: 0.219633
Average total loss: 0.915699
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-4.4669e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.680900
Average KL loss: 0.219885
Average total loss: 0.900784
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-4.3591e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.688927
Average KL loss: 0.219999
Average total loss: 0.908925
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.1388e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.693152
Average KL loss: 0.220158
Average total loss: 0.913310
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.3879e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.680882
Average KL loss: 0.220249
Average total loss: 0.901131
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-4.8070e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.686791
Average KL loss: 0.220467
Average total loss: 0.907258
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-3.5823e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.682666
Average KL loss: 0.220636
Average total loss: 0.903302
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.6366e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.661704
Average KL loss: 0.220799
Average total loss: 0.882502
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.0588e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.667485
Average KL loss: 0.220868
Average total loss: 0.888353
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.0920e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.663788
Average KL loss: 0.221074
Average total loss: 0.884862
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.8395e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.681554
Average KL loss: 0.221183
Average total loss: 0.902737
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.7501e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.668728
Average KL loss: 0.221451
Average total loss: 0.890179
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.2887e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.657981
Average KL loss: 0.221597
Average total loss: 0.879578
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.6585e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.655136
Average KL loss: 0.221682
Average total loss: 0.876818
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.7888e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.656586
Average KL loss: 0.221756
Average total loss: 0.878341
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.7151e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.662142
Average KL loss: 0.221904
Average total loss: 0.884046
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.0777e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.652542
Average KL loss: 0.222057
Average total loss: 0.874599
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-2.3875e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.645676
Average KL loss: 0.222247
Average total loss: 0.867923
tensor(0.0024, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(-1.5901e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.643826
Average KL loss: 0.222502
Average total loss: 0.866328
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.2779e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.668506
Average KL loss: 0.222730
Average total loss: 0.891236
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-4.1060e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.636766
Average KL loss: 0.222877
Average total loss: 0.859643
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-3.7158e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.653347
Average KL loss: 0.223112
Average total loss: 0.876459
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.1217e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.633833
Average KL loss: 0.223310
Average total loss: 0.857143
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-3.2498e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.637734
Average KL loss: 0.223345
Average total loss: 0.861080
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.8228e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.638083
Average KL loss: 0.223544
Average total loss: 0.861627
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.2708e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.635809
Average KL loss: 0.223696
Average total loss: 0.859505
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.9232e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.631351
Average KL loss: 0.223771
Average total loss: 0.855122
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.4113e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.637154
Average KL loss: 0.224002
Average total loss: 0.861156
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.6465e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.620805
Average KL loss: 0.224094
Average total loss: 0.844899
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-4.4888e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.626795
Average KL loss: 0.224153
Average total loss: 0.850948
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.7477e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.636866
Average KL loss: 0.224333
Average total loss: 0.861199
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.3590e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.621851
Average KL loss: 0.224532
Average total loss: 0.846383
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-3.5223e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.618711
Average KL loss: 0.224650
Average total loss: 0.843361
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.5687e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.623506
Average KL loss: 0.224680
Average total loss: 0.848186
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.9821e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.630884
Average KL loss: 0.224849
Average total loss: 0.855733
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.2869e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.617652
Average KL loss: 0.225087
Average total loss: 0.842739
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-1.5472e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.636143
Average KL loss: 0.225257
Average total loss: 0.861400
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.8210e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.617963
Average KL loss: 0.225495
Average total loss: 0.843458
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.5961e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.620749
Average KL loss: 0.225690
Average total loss: 0.846440
tensor(0.0024, device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-2.8252e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.608470
Average KL loss: 0.225897
Average total loss: 0.834367
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.7008e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.620102
Average KL loss: 0.226064
Average total loss: 0.846166
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.6655e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.605319
Average KL loss: 0.226167
Average total loss: 0.831486
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.7364e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.611264
Average KL loss: 0.226262
Average total loss: 0.837526
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.7612e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.603452
Average KL loss: 0.226325
Average total loss: 0.829777
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.7910e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.597485
Average KL loss: 0.226385
Average total loss: 0.823870
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.2173e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.611550
Average KL loss: 0.226570
Average total loss: 0.838120
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.6609e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.599726
Average KL loss: 0.226656
Average total loss: 0.826382
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.1601e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.598680
Average KL loss: 0.226619
Average total loss: 0.825299
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.9843e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.602681
Average KL loss: 0.226688
Average total loss: 0.829369
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.1423e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.598368
Average KL loss: 0.226783
Average total loss: 0.825151
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.4932e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.582944
Average KL loss: 0.226757
Average total loss: 0.809701
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.8880e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.596668
Average KL loss: 0.226897
Average total loss: 0.823565
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.7347e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.589396
Average KL loss: 0.227066
Average total loss: 0.816462
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.1222e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.596306
Average KL loss: 0.227163
Average total loss: 0.823469
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.2691e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.581756
Average KL loss: 0.227232
Average total loss: 0.808989
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.1489e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.583797
Average KL loss: 0.227392
Average total loss: 0.811189
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.4149e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.580959
Average KL loss: 0.227455
Average total loss: 0.808414
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-3.0346e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.597031
Average KL loss: 0.227584
Average total loss: 0.824615
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.4100e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.575996
Average KL loss: 0.227486
Average total loss: 0.803482
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-1.6479e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.577960
Average KL loss: 0.227468
Average total loss: 0.805428
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.0271e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.588078
Average KL loss: 0.227611
Average total loss: 0.815689
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.5268e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.571790
Average KL loss: 0.227775
Average total loss: 0.799565
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3141e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.586219
Average KL loss: 0.227839
Average total loss: 0.814058
tensor(0.0024, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(-2.3391e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.570181
Average KL loss: 0.227936
Average total loss: 0.798117
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.0593e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.586521
Average KL loss: 0.228018
Average total loss: 0.814539
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.6291e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.590509
Average KL loss: 0.228088
Average total loss: 0.818597
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.9895e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.583522
Average KL loss: 0.228163
Average total loss: 0.811685
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.1622e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.581652
Average KL loss: 0.228276
Average total loss: 0.809928
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.9465e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.577909
Average KL loss: 0.228478
Average total loss: 0.806387
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.7910e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.570103
Average KL loss: 0.228670
Average total loss: 0.798773
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.7185e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.565449
Average KL loss: 0.228751
Average total loss: 0.794200
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.9363e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.571707
Average KL loss: 0.228783
Average total loss: 0.800490
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-9.7950e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.567494
Average KL loss: 0.228880
Average total loss: 0.796374
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.5013e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.558613
Average KL loss: 0.229069
Average total loss: 0.787682
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.3310e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.561247
Average KL loss: 0.229168
Average total loss: 0.790415
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.2358e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.570794
Average KL loss: 0.229290
Average total loss: 0.800084
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.3039e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.555546
Average KL loss: 0.229387
Average total loss: 0.784934
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.4415e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.571440
Average KL loss: 0.229485
Average total loss: 0.800925
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.9896e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.555230
Average KL loss: 0.229631
Average total loss: 0.784861
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.4923e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.562231
Average KL loss: 0.229659
Average total loss: 0.791890
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.8635e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.549129
Average KL loss: 0.229696
Average total loss: 0.778825
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.2097e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.568796
Average KL loss: 0.229743
Average total loss: 0.798539
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.3068e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.565988
Average KL loss: 0.229911
Average total loss: 0.795900
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.5011e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.560528
Average KL loss: 0.229952
Average total loss: 0.790480
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.2662e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.557170
Average KL loss: 0.230095
Average total loss: 0.787265
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.3252e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.548377
Average KL loss: 0.230193
Average total loss: 0.778570
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.9211e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.551772
Average KL loss: 0.230151
Average total loss: 0.781923
tensor(0.0024, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.9401e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.555856
Average KL loss: 0.230317
Average total loss: 0.786173
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.8084e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.544708
Average KL loss: 0.230466
Average total loss: 0.775174
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.5880e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.547627
Average KL loss: 0.230541
Average total loss: 0.778169
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.4582e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.533075
Average KL loss: 0.230548
Average total loss: 0.763623
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.2924e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.538420
Average KL loss: 0.230479
Average total loss: 0.768899
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.5166e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.547287
Average KL loss: 0.230562
Average total loss: 0.777849
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.0985e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.532721
Average KL loss: 0.230671
Average total loss: 0.763392
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.8388e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.548439
Average KL loss: 0.230834
Average total loss: 0.779273
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.5787e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.542454
Average KL loss: 0.231072
Average total loss: 0.773526
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.3352e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.540193
Average KL loss: 0.231041
Average total loss: 0.771233
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.1395e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.538133
Average KL loss: 0.231019
Average total loss: 0.769152
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-6.6435e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.536557
Average KL loss: 0.230946
Average total loss: 0.767504
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.4823e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.545116
Average KL loss: 0.230961
Average total loss: 0.776078
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.3709e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.535902
Average KL loss: 0.231079
Average total loss: 0.766981
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.2171e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.537386
Average KL loss: 0.231132
Average total loss: 0.768518
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.1504e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.533805
Average KL loss: 0.231305
Average total loss: 0.765110
 Percentile value: 0.0005339316558092833
Non-zero model percentage: 12.500005722045898%, Non-zero mask percentage: 12.500005722045898%

--- Pruning Level [3/12]: ---
conv1.weight         | nonzeros =    1005 /    1728             ( 58.16%) | total_pruned =     723 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
bn1.weight           | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
bn1.bias             | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   24193 /   36864             ( 65.63%) | total_pruned =   12671 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      33 /      64             ( 51.56%) | total_pruned =      31 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   10994 /   36864             ( 29.82%) | total_pruned =   25870 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      48 /      64             ( 75.00%) | total_pruned =      16 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    9253 /   36864             ( 25.10%) | total_pruned =   27611 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    6775 /   36864             ( 18.38%) | total_pruned =   30089 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      46 /      64             ( 71.88%) | total_pruned =      18 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   13695 /   73728             ( 18.58%) | total_pruned =   60033 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   24857 /  147456             ( 16.86%) | total_pruned =  122599 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      35 /     128             ( 27.34%) | total_pruned =      93 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1512 /    8192             ( 18.46%) | total_pruned =    6680 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      85 /     128             ( 66.41%) | total_pruned =      43 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   19116 /  147456             ( 12.96%) | total_pruned =  128340 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   16311 /  147456             ( 11.06%) | total_pruned =  131145 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   50550 /  294912             ( 17.14%) | total_pruned =  244362 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     245 /     256             ( 95.70%) | total_pruned =      11 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   91016 /  589824             ( 15.43%) | total_pruned =  498808 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     122 /     256             ( 47.66%) | total_pruned =     134 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     229 /     256             ( 89.45%) | total_pruned =      27 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4782 /   32768             ( 14.59%) | total_pruned =   27986 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     216 /     256             ( 84.38%) | total_pruned =      40 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     151 /     256             ( 58.98%) | total_pruned =     105 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   62210 /  589824             ( 10.55%) | total_pruned =  527614 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     188 /     256             ( 73.44%) | total_pruned =      68 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      35 /     256             ( 13.67%) | total_pruned =     221 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   52456 /  589824             (  8.89%) | total_pruned =  537368 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     140 /     256             ( 54.69%) | total_pruned =     116 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  172577 / 1179648             ( 14.63%) | total_pruned = 1007071 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     436 /     512             ( 85.16%) | total_pruned =      76 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     392 /     512             ( 76.56%) | total_pruned =     120 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  282430 / 2359296             ( 11.97%) | total_pruned = 2076866 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     408 /     512             ( 79.69%) | total_pruned =     104 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     293 /     512             ( 57.23%) | total_pruned =     219 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   15083 /  131072             ( 11.51%) | total_pruned =  115989 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     493 /     512             ( 96.29%) | total_pruned =      19 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     241 /     512             ( 47.07%) | total_pruned =     271 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      64 /     512             ( 12.50%) | total_pruned =     448 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  233360 / 2359296             (  9.89%) | total_pruned = 2125936 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     472 /     512             ( 92.19%) | total_pruned =      40 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     356 /     512             ( 69.53%) | total_pruned =     156 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  296139 / 2359296             ( 12.55%) | total_pruned = 2063157 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     461 /     512             ( 90.04%) | total_pruned =      51 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     336 /     512             ( 65.62%) | total_pruned =     176 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     170 /     512             ( 33.20%) | total_pruned =     342 | shape = torch.Size([512])
linear.weight        | nonzeros =    1575 /    5120             ( 30.76%) | total_pruned =    3545 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 1397346, pruned : 9781416, total: 11178762, Compression rate :       8.00x  ( 87.50% pruned)
Train Epoch: 53/100 Loss: 0.029679 Accuracy: 87.58 99.99 % Best test Accuracy: 87.96%
tensor(0.0024, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-7.3221e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.923194
Average KL loss: 0.223546
Average total loss: 1.146740
tensor(0.0028, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-6.8963e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.864572
Average KL loss: 0.216354
Average total loss: 1.080926
tensor(0.0029, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-5.4347e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.855838
Average KL loss: 0.213204
Average total loss: 1.069042
tensor(0.0029, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-5.4394e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.837873
Average KL loss: 0.211602
Average total loss: 1.049475
tensor(0.0029, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-4.0192e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.828328
Average KL loss: 0.210917
Average total loss: 1.039244
tensor(0.0029, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-5.1406e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.810712
Average KL loss: 0.210787
Average total loss: 1.021500
tensor(0.0029, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.1378e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.801009
Average KL loss: 0.210913
Average total loss: 1.011922
tensor(0.0029, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.9706e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.780116
Average KL loss: 0.211341
Average total loss: 0.991457
tensor(0.0029, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-6.0547e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.781691
Average KL loss: 0.211884
Average total loss: 0.993575
tensor(0.0029, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.4111e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.751297
Average KL loss: 0.212557
Average total loss: 0.963854
tensor(0.0029, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.7574e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.753140
Average KL loss: 0.213149
Average total loss: 0.966289
tensor(0.0028, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.1995e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.760715
Average KL loss: 0.213835
Average total loss: 0.974550
tensor(0.0028, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-1.7300e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.727546
Average KL loss: 0.214559
Average total loss: 0.942105
tensor(0.0028, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.9871e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.735452
Average KL loss: 0.215142
Average total loss: 0.950594
tensor(0.0028, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.0475e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.730351
Average KL loss: 0.215802
Average total loss: 0.946153
tensor(0.0028, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.3252e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.730519
Average KL loss: 0.216417
Average total loss: 0.946936
tensor(0.0028, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-2.0275e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.713795
Average KL loss: 0.217135
Average total loss: 0.930930
tensor(0.0028, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-3.3339e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.720831
Average KL loss: 0.217892
Average total loss: 0.938724
tensor(0.0028, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-5.9341e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.711056
Average KL loss: 0.218632
Average total loss: 0.929689
tensor(0.0027, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.8861e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.707375
Average KL loss: 0.219322
Average total loss: 0.926697
tensor(0.0027, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.2772e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.704301
Average KL loss: 0.220058
Average total loss: 0.924359
tensor(0.0027, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.5104e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.685947
Average KL loss: 0.220734
Average total loss: 0.906681
tensor(0.0027, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.8504e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.698996
Average KL loss: 0.221310
Average total loss: 0.920307
tensor(0.0027, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.7632e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.679698
Average KL loss: 0.221888
Average total loss: 0.901585
tensor(0.0027, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.8584e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.676185
Average KL loss: 0.222482
Average total loss: 0.898666
tensor(0.0027, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-9.1935e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.684781
Average KL loss: 0.223052
Average total loss: 0.907833
tensor(0.0027, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.6746e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.667067
Average KL loss: 0.223626
Average total loss: 0.890693
tensor(0.0027, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.3232e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.670605
Average KL loss: 0.224224
Average total loss: 0.894829
tensor(0.0027, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.2413e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.672490
Average KL loss: 0.224805
Average total loss: 0.897294
tensor(0.0027, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.7340e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.662914
Average KL loss: 0.225342
Average total loss: 0.888255
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.3562e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.654088
Average KL loss: 0.225826
Average total loss: 0.879914
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-1.9632e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.660364
Average KL loss: 0.226293
Average total loss: 0.886657
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-3.4099e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.649918
Average KL loss: 0.226824
Average total loss: 0.876742
tensor(0.0026, device='cuda:0') tensor(0.0026, device='cuda:0') tensor(-2.2265e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.661290
Average KL loss: 0.227327
Average total loss: 0.888617
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.6943e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.657260
Average KL loss: 0.227777
Average total loss: 0.885036
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.6241e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.638349
Average KL loss: 0.228214
Average total loss: 0.866563
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-9.3095e-09, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.637265
Average KL loss: 0.228706
Average total loss: 0.865972
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-2.3549e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.644019
Average KL loss: 0.229147
Average total loss: 0.873166
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.7564e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.638325
Average KL loss: 0.229635
Average total loss: 0.867959
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.4886e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.631943
Average KL loss: 0.230126
Average total loss: 0.862070
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.9478e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.642877
Average KL loss: 0.230507
Average total loss: 0.873384
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-3.3411e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.627429
Average KL loss: 0.230875
Average total loss: 0.858304
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.3164e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.628310
Average KL loss: 0.231226
Average total loss: 0.859535
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.9305e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.622200
Average KL loss: 0.231595
Average total loss: 0.853795
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.3377e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.644325
Average KL loss: 0.231965
Average total loss: 0.876290
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.2553e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.621189
Average KL loss: 0.232374
Average total loss: 0.853564
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.7049e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.615839
Average KL loss: 0.232769
Average total loss: 0.848608
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.2655e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.611627
Average KL loss: 0.233151
Average total loss: 0.844778
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.4812e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.621876
Average KL loss: 0.233435
Average total loss: 0.855311
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.2708e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.614885
Average KL loss: 0.233779
Average total loss: 0.848664
tensor(0.0026, device='cuda:0') tensor(0.0027, device='cuda:0') tensor(-1.2900e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.635872
Average KL loss: 0.234116
Average total loss: 0.869988
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.3438e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.612350
Average KL loss: 0.234483
Average total loss: 0.846833
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-8.4885e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.598586
Average KL loss: 0.234780
Average total loss: 0.833366
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-6.8821e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.603166
Average KL loss: 0.235079
Average total loss: 0.838245
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.5907e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.616339
Average KL loss: 0.235474
Average total loss: 0.851813
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.0474e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.591362
Average KL loss: 0.235820
Average total loss: 0.827182
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.5491e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.611318
Average KL loss: 0.236081
Average total loss: 0.847399
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.0267e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.603255
Average KL loss: 0.236415
Average total loss: 0.839670
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.4355e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.592793
Average KL loss: 0.236762
Average total loss: 0.829556
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.8505e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.595683
Average KL loss: 0.236982
Average total loss: 0.832665
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.0366e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.596061
Average KL loss: 0.237293
Average total loss: 0.833354
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.5893e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.594083
Average KL loss: 0.237559
Average total loss: 0.831641
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-7.2605e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.594125
Average KL loss: 0.237824
Average total loss: 0.831948
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.3497e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.583797
Average KL loss: 0.238145
Average total loss: 0.821942
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-2.3167e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.600695
Average KL loss: 0.238402
Average total loss: 0.839098
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.5463e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.600319
Average KL loss: 0.238703
Average total loss: 0.839022
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.4338e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.587839
Average KL loss: 0.239006
Average total loss: 0.826845
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.4742e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.590728
Average KL loss: 0.239259
Average total loss: 0.829987
tensor(0.0025, device='cuda:0') tensor(0.0028, device='cuda:0') tensor(-1.6159e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.585895
Average KL loss: 0.239563
Average total loss: 0.825458
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.6954e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.587780
Average KL loss: 0.239844
Average total loss: 0.827624
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.7178e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.574409
Average KL loss: 0.240131
Average total loss: 0.814540
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.6515e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.587551
Average KL loss: 0.240311
Average total loss: 0.827862
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.9431e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.574958
Average KL loss: 0.240497
Average total loss: 0.815455
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.3481e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.576493
Average KL loss: 0.240654
Average total loss: 0.817147
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.3173e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.580308
Average KL loss: 0.240858
Average total loss: 0.821166
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.7740e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.583341
Average KL loss: 0.241132
Average total loss: 0.824473
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-5.8730e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.580641
Average KL loss: 0.241387
Average total loss: 0.822028
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.0399e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.575052
Average KL loss: 0.241596
Average total loss: 0.816648
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-2.0028e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.570059
Average KL loss: 0.241737
Average total loss: 0.811796
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-6.8927e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.572671
Average KL loss: 0.241868
Average total loss: 0.814539
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.1702e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.576959
Average KL loss: 0.242095
Average total loss: 0.819054
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.5271e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.556082
Average KL loss: 0.242303
Average total loss: 0.798386
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.2044e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.576951
Average KL loss: 0.242442
Average total loss: 0.819394
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.3005e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.563381
Average KL loss: 0.242660
Average total loss: 0.806040
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-7.9155e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.563438
Average KL loss: 0.242885
Average total loss: 0.806324
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.8303e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.560746
Average KL loss: 0.243057
Average total loss: 0.803803
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.7425e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.565739
Average KL loss: 0.243249
Average total loss: 0.808988
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.4030e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.560145
Average KL loss: 0.243480
Average total loss: 0.803625
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-3.8980e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.568323
Average KL loss: 0.243729
Average total loss: 0.812052
tensor(0.0025, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-1.6353e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.571146
Average KL loss: 0.243984
Average total loss: 0.815131
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.4394e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.554545
Average KL loss: 0.244206
Average total loss: 0.798751
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.7671e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.550123
Average KL loss: 0.244347
Average total loss: 0.794469
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.4700e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.559622
Average KL loss: 0.244564
Average total loss: 0.804186
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-9.6198e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.563708
Average KL loss: 0.244754
Average total loss: 0.808462
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.7470e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.550427
Average KL loss: 0.244994
Average total loss: 0.795421
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.3757e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.547028
Average KL loss: 0.245177
Average total loss: 0.792204
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.0145e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.563536
Average KL loss: 0.245330
Average total loss: 0.808866
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-6.9960e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.546653
Average KL loss: 0.245503
Average total loss: 0.792156
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.0120e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.547024
Average KL loss: 0.245615
Average total loss: 0.792639
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.9084e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.547396
Average KL loss: 0.245736
Average total loss: 0.793132
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.1058e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.554411
Average KL loss: 0.245902
Average total loss: 0.800314
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.5019e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.548855
Average KL loss: 0.246003
Average total loss: 0.794858
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.1459e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.543254
Average KL loss: 0.246127
Average total loss: 0.789381
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.3335e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.544339
Average KL loss: 0.246268
Average total loss: 0.790607
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-9.5547e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.537229
Average KL loss: 0.246445
Average total loss: 0.783674
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.4275e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.542122
Average KL loss: 0.246560
Average total loss: 0.788682
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.4083e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.532633
Average KL loss: 0.246623
Average total loss: 0.779256
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.0178e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.534347
Average KL loss: 0.246566
Average total loss: 0.780913
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-2.3148e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.538141
Average KL loss: 0.246673
Average total loss: 0.784814
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-8.0457e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.535562
Average KL loss: 0.246820
Average total loss: 0.782382
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-3.2540e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.550538
Average KL loss: 0.246896
Average total loss: 0.797434
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.0350e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.540931
Average KL loss: 0.247101
Average total loss: 0.788032
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-6.7849e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.536938
Average KL loss: 0.247253
Average total loss: 0.784191
tensor(0.0025, device='cuda:0') tensor(0.0030, device='cuda:0') tensor(-1.1798e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.534198
Average KL loss: 0.247343
Average total loss: 0.781541
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.0688e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.553061
Average KL loss: 0.247484
Average total loss: 0.800546
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.4465e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.533160
Average KL loss: 0.247698
Average total loss: 0.780858
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-8.7000e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.527812
Average KL loss: 0.247797
Average total loss: 0.775609
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.3490e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.531938
Average KL loss: 0.247900
Average total loss: 0.779837
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.7384e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.527681
Average KL loss: 0.248052
Average total loss: 0.775733
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-7.9588e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.532210
Average KL loss: 0.248145
Average total loss: 0.780356
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.3093e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.527087
Average KL loss: 0.248275
Average total loss: 0.775362
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-7.4330e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.528823
Average KL loss: 0.248459
Average total loss: 0.777282
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-7.6877e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.537503
Average KL loss: 0.248599
Average total loss: 0.786102
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.0303e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.532799
Average KL loss: 0.248737
Average total loss: 0.781536
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-7.3943e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.531105
Average KL loss: 0.248833
Average total loss: 0.779939
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-7.1154e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.525487
Average KL loss: 0.248987
Average total loss: 0.774474
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.9032e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.525088
Average KL loss: 0.249051
Average total loss: 0.774140
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.5379e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.532837
Average KL loss: 0.249146
Average total loss: 0.781983
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2667e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.525800
Average KL loss: 0.249302
Average total loss: 0.775102
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2878e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.518767
Average KL loss: 0.249404
Average total loss: 0.768170
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.0289e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.528314
Average KL loss: 0.249583
Average total loss: 0.777897
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2434e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.516063
Average KL loss: 0.249709
Average total loss: 0.765772
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.8858e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.523057
Average KL loss: 0.249763
Average total loss: 0.772819
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.9044e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.520845
Average KL loss: 0.249849
Average total loss: 0.770694
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.0169e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.525904
Average KL loss: 0.249928
Average total loss: 0.775831
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.2230e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.517894
Average KL loss: 0.250077
Average total loss: 0.767970
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-8.3985e-11, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.513378
Average KL loss: 0.250166
Average total loss: 0.763543
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-1.0291e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.514076
Average KL loss: 0.250196
Average total loss: 0.764272
tensor(0.0025, device='cuda:0') tensor(0.0031, device='cuda:0') tensor(-4.2279e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.515527
Average KL loss: 0.250275
Average total loss: 0.765802
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.3486e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.523495
Average KL loss: 0.250417
Average total loss: 0.773913
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.9737e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.525384
Average KL loss: 0.250555
Average total loss: 0.775939
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.4822e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.529520
Average KL loss: 0.250792
Average total loss: 0.780312
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.7190e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.519848
Average KL loss: 0.250955
Average total loss: 0.770803
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-8.6379e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.526699
Average KL loss: 0.250965
Average total loss: 0.777664
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.6440e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.513131
Average KL loss: 0.251072
Average total loss: 0.764203
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.3168e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.519027
Average KL loss: 0.251199
Average total loss: 0.770226
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.5553e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.507213
Average KL loss: 0.251300
Average total loss: 0.758513
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.4273e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.514312
Average KL loss: 0.251442
Average total loss: 0.765754
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.6541e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.517500
Average KL loss: 0.251617
Average total loss: 0.769116
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.3062e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.508850
Average KL loss: 0.251700
Average total loss: 0.760549
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.8416e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.526015
Average KL loss: 0.251781
Average total loss: 0.777796
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.8428e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.515999
Average KL loss: 0.251937
Average total loss: 0.767937
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.6621e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.502772
Average KL loss: 0.252011
Average total loss: 0.754783
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.4050e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.500914
Average KL loss: 0.252067
Average total loss: 0.752980
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.6169e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.511432
Average KL loss: 0.252125
Average total loss: 0.763557
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-5.4617e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.510194
Average KL loss: 0.252123
Average total loss: 0.762316
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.3524e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.513887
Average KL loss: 0.252237
Average total loss: 0.766125
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.3901e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.499267
Average KL loss: 0.252390
Average total loss: 0.751657
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.0570e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.500965
Average KL loss: 0.252427
Average total loss: 0.753393
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-6.1710e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.509134
Average KL loss: 0.252534
Average total loss: 0.761668
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-7.8048e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.507927
Average KL loss: 0.252589
Average total loss: 0.760516
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.6855e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.498129
Average KL loss: 0.252640
Average total loss: 0.750769
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-9.0579e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.502728
Average KL loss: 0.252707
Average total loss: 0.755435
tensor(0.0025, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.4201e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.495899
Average KL loss: 0.252842
Average total loss: 0.748740
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.6143e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.503826
Average KL loss: 0.252887
Average total loss: 0.756713
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-9.6463e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.495368
Average KL loss: 0.252965
Average total loss: 0.748333
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.0191e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.507663
Average KL loss: 0.253033
Average total loss: 0.760696
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-5.1496e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.496548
Average KL loss: 0.253214
Average total loss: 0.749763
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.8474e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.494525
Average KL loss: 0.253271
Average total loss: 0.747795
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.4453e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.498294
Average KL loss: 0.253374
Average total loss: 0.751668
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.2544e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.501511
Average KL loss: 0.253403
Average total loss: 0.754913
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.3993e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.503325
Average KL loss: 0.253502
Average total loss: 0.756827
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-8.5071e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.501208
Average KL loss: 0.253627
Average total loss: 0.754835
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-4.3586e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.502539
Average KL loss: 0.253677
Average total loss: 0.756216
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.2879e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.503011
Average KL loss: 0.253847
Average total loss: 0.756859
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-4.0834e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.492752
Average KL loss: 0.253915
Average total loss: 0.746667
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.1378e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.491336
Average KL loss: 0.253994
Average total loss: 0.745330
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.4366e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.495171
Average KL loss: 0.254070
Average total loss: 0.749241
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.4879e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.496152
Average KL loss: 0.254246
Average total loss: 0.750398
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.6272e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.489142
Average KL loss: 0.254320
Average total loss: 0.743462
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.7539e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.488864
Average KL loss: 0.254395
Average total loss: 0.743259
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.0724e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.490364
Average KL loss: 0.254454
Average total loss: 0.744818
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.3840e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.498193
Average KL loss: 0.254521
Average total loss: 0.752714
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-3.0372e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.486325
Average KL loss: 0.254588
Average total loss: 0.740912
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-4.7761e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.492775
Average KL loss: 0.254597
Average total loss: 0.747373
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-9.0546e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.495458
Average KL loss: 0.254660
Average total loss: 0.750119
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.4617e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.493971
Average KL loss: 0.254796
Average total loss: 0.748767
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.3739e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.498683
Average KL loss: 0.254900
Average total loss: 0.753583
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-4.5150e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.489270
Average KL loss: 0.254933
Average total loss: 0.744203
tensor(0.0025, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.1372e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.494830
Average KL loss: 0.255065
Average total loss: 0.749895
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.4854e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.496547
Average KL loss: 0.255118
Average total loss: 0.751664
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.4714e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.489699
Average KL loss: 0.255148
Average total loss: 0.744847
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-5.6428e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.486418
Average KL loss: 0.255157
Average total loss: 0.741575
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.0375e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.482529
Average KL loss: 0.255256
Average total loss: 0.737784
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.7874e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.498626
Average KL loss: 0.255379
Average total loss: 0.754005
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.9886e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.491024
Average KL loss: 0.255475
Average total loss: 0.746499
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.0647e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.488651
Average KL loss: 0.255476
Average total loss: 0.744127
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.9662e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.494559
Average KL loss: 0.255548
Average total loss: 0.750106
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-9.6345e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.484218
Average KL loss: 0.255658
Average total loss: 0.739876
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-8.9650e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.493486
Average KL loss: 0.255739
Average total loss: 0.749225
 Percentile value: 0.0018327258294448256
Non-zero model percentage: 6.250002861022949%, Non-zero mask percentage: 6.250002861022949%

--- Pruning Level [4/12]: ---
conv1.weight         | nonzeros =     184 /    1728             ( 10.65%) | total_pruned =    1544 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
bn1.weight           | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    1285 /   36864             (  3.49%) | total_pruned =   35579 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2445 /   36864             (  6.63%) | total_pruned =   34419 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      37 /      64             ( 57.81%) | total_pruned =      27 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2597 /   36864             (  7.04%) | total_pruned =   34267 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      50 /      64             ( 78.12%) | total_pruned =      14 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    4047 /   36864             ( 10.98%) | total_pruned =   32817 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      45 /      64             ( 70.31%) | total_pruned =      19 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    9070 /   73728             ( 12.30%) | total_pruned =   64658 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      37 /     128             ( 28.91%) | total_pruned =      91 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      22 /     128             ( 17.19%) | total_pruned =     106 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   15814 /  147456             ( 10.72%) | total_pruned =  131642 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1042 /    8192             ( 12.72%) | total_pruned =    7150 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8646 /  147456             (  5.86%) | total_pruned =  138810 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    6374 /  147456             (  4.32%) | total_pruned =  141082 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   30739 /  294912             ( 10.42%) | total_pruned =  264173 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      75 /     256             ( 29.30%) | total_pruned =     181 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   52947 /  589824             (  8.98%) | total_pruned =  536877 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      54 /     256             ( 21.09%) | total_pruned =     202 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     228 /     256             ( 89.06%) | total_pruned =      28 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2958 /   32768             (  9.03%) | total_pruned =   29810 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      27 /     256             ( 10.55%) | total_pruned =     229 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     138 /     256             ( 53.91%) | total_pruned =     118 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   33115 /  589824             (  5.61%) | total_pruned =  556709 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     134 /     256             ( 52.34%) | total_pruned =     122 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      28 /     256             ( 10.94%) | total_pruned =     228 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   24553 /  589824             (  4.16%) | total_pruned =  565271 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =      26 /     256             ( 10.16%) | total_pruned =     230 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   82935 / 1179648             (  7.03%) | total_pruned = 1096713 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      72 /     512             ( 14.06%) | total_pruned =     440 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     377 /     512             ( 73.63%) | total_pruned =     135 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      27 /     512             (  5.27%) | total_pruned =     485 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  121907 / 2359296             (  5.17%) | total_pruned = 2237389 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      47 /     512             (  9.18%) | total_pruned =     465 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     259 /     512             ( 50.59%) | total_pruned =     253 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      55 /     512             ( 10.74%) | total_pruned =     457 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    8129 /  131072             (  6.20%) | total_pruned =  122943 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     177 /     512             ( 34.57%) | total_pruned =     335 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      57 /     512             ( 11.13%) | total_pruned =     455 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  121253 / 2359296             (  5.14%) | total_pruned = 2238043 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     315 /     512             ( 61.52%) | total_pruned =     197 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  163495 / 2359296             (  6.93%) | total_pruned = 2195801 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     288 /     512             ( 56.25%) | total_pruned =     224 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     145 /     512             ( 28.32%) | total_pruned =     367 | shape = torch.Size([512])
linear.weight        | nonzeros =    1266 /    5120             ( 24.73%) | total_pruned =    3854 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 698673, pruned : 10480089, total: 11178762, Compression rate :      16.00x  ( 93.75% pruned)
Train Epoch: 71/100 Loss: 0.022347 Accuracy: 87.60 100.00 % Best test Accuracy: 87.86%
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-6.1813e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.827216
Average KL loss: 0.249703
Average total loss: 1.076919
tensor(0.0027, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-4.3296e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.816925
Average KL loss: 0.243690
Average total loss: 1.060615
tensor(0.0028, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.0996e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.788466
Average KL loss: 0.240692
Average total loss: 1.029158
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-4.7989e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.768593
Average KL loss: 0.238990
Average total loss: 1.007583
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.7020e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.756349
Average KL loss: 0.237951
Average total loss: 0.994301
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.3177e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.742499
Average KL loss: 0.237460
Average total loss: 0.979959
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.8345e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.743396
Average KL loss: 0.237233
Average total loss: 0.980629
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.3629e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.722689
Average KL loss: 0.237275
Average total loss: 0.959964
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.2285e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.723512
Average KL loss: 0.237451
Average total loss: 0.960964
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-3.4585e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.717686
Average KL loss: 0.237684
Average total loss: 0.955370
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.8709e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.703541
Average KL loss: 0.237996
Average total loss: 0.941537
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.8397e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.712833
Average KL loss: 0.238430
Average total loss: 0.951263
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-1.9241e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.691202
Average KL loss: 0.238918
Average total loss: 0.930120
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.4453e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.699226
Average KL loss: 0.239450
Average total loss: 0.938676
tensor(0.0028, device='cuda:0') tensor(0.0032, device='cuda:0') tensor(-2.9856e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.689043
Average KL loss: 0.239932
Average total loss: 0.928974
tensor(0.0027, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.2452e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.671592
Average KL loss: 0.240357
Average total loss: 0.911949
tensor(0.0027, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.8015e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.676831
Average KL loss: 0.240779
Average total loss: 0.917610
tensor(0.0027, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.5549e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.667967
Average KL loss: 0.241210
Average total loss: 0.909177
tensor(0.0027, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.7240e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.672511
Average KL loss: 0.241689
Average total loss: 0.914200
tensor(0.0027, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.4576e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.652374
Average KL loss: 0.242186
Average total loss: 0.894560
tensor(0.0027, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.1879e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.658101
Average KL loss: 0.242658
Average total loss: 0.900760
tensor(0.0027, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.2584e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.646919
Average KL loss: 0.243097
Average total loss: 0.890016
tensor(0.0027, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.5215e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.645621
Average KL loss: 0.243509
Average total loss: 0.889130
tensor(0.0027, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.6513e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.657253
Average KL loss: 0.243908
Average total loss: 0.901162
tensor(0.0027, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-9.3501e-09, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.646178
Average KL loss: 0.244352
Average total loss: 0.890530
tensor(0.0027, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-6.6494e-09, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.640027
Average KL loss: 0.244788
Average total loss: 0.884815
tensor(0.0027, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.5501e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.631617
Average KL loss: 0.245247
Average total loss: 0.876864
tensor(0.0027, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-7.9928e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.642589
Average KL loss: 0.245658
Average total loss: 0.888248
tensor(0.0027, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.2053e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.629840
Average KL loss: 0.246085
Average total loss: 0.875925
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.5160e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.629614
Average KL loss: 0.246469
Average total loss: 0.876083
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.7752e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.629014
Average KL loss: 0.246875
Average total loss: 0.875889
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.1170e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.624998
Average KL loss: 0.247279
Average total loss: 0.872278
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-2.1613e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.632112
Average KL loss: 0.247752
Average total loss: 0.879864
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.4819e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.623236
Average KL loss: 0.248060
Average total loss: 0.871296
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.4715e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.619657
Average KL loss: 0.248436
Average total loss: 0.868094
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-8.7032e-09, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.608920
Average KL loss: 0.248725
Average total loss: 0.857645
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.8976e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.606518
Average KL loss: 0.249041
Average total loss: 0.855559
tensor(0.0026, device='cuda:0') tensor(0.0033, device='cuda:0') tensor(-1.0958e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.608491
Average KL loss: 0.249360
Average total loss: 0.857851
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-8.3765e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.607976
Average KL loss: 0.249654
Average total loss: 0.857630
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.4519e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.596484
Average KL loss: 0.249895
Average total loss: 0.846379
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.1912e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.602242
Average KL loss: 0.250121
Average total loss: 0.852363
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.6764e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.595779
Average KL loss: 0.250400
Average total loss: 0.846179
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.6991e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.607525
Average KL loss: 0.250656
Average total loss: 0.858181
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-9.6776e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.601836
Average KL loss: 0.251006
Average total loss: 0.852842
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.5303e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.591520
Average KL loss: 0.251335
Average total loss: 0.842856
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-9.4437e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.582711
Average KL loss: 0.251573
Average total loss: 0.834284
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-9.2245e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.596962
Average KL loss: 0.251819
Average total loss: 0.848781
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-9.4980e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.589527
Average KL loss: 0.252103
Average total loss: 0.841630
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-9.4412e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.587519
Average KL loss: 0.252414
Average total loss: 0.839933
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-6.9987e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.596067
Average KL loss: 0.252701
Average total loss: 0.848768
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.4550e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.585409
Average KL loss: 0.252996
Average total loss: 0.838404
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.1045e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.586764
Average KL loss: 0.253230
Average total loss: 0.839994
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-2.0400e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.575197
Average KL loss: 0.253452
Average total loss: 0.828649
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.7089e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.585055
Average KL loss: 0.253709
Average total loss: 0.838764
tensor(0.0026, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-8.6294e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.574822
Average KL loss: 0.253962
Average total loss: 0.828784
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.7755e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.586055
Average KL loss: 0.254235
Average total loss: 0.840291
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-3.1357e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.583555
Average KL loss: 0.254540
Average total loss: 0.838095
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.3698e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.580373
Average KL loss: 0.254796
Average total loss: 0.835170
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.1377e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.577075
Average KL loss: 0.255114
Average total loss: 0.832189
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.7101e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.573778
Average KL loss: 0.255353
Average total loss: 0.829132
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.4827e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.582303
Average KL loss: 0.255576
Average total loss: 0.837880
tensor(0.0025, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-6.3415e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.568799
Average KL loss: 0.255775
Average total loss: 0.824574
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-8.7918e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.587371
Average KL loss: 0.255977
Average total loss: 0.843348
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.2127e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.574506
Average KL loss: 0.256200
Average total loss: 0.830706
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(3.1449e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.568145
Average KL loss: 0.256417
Average total loss: 0.824562
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.0747e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.573924
Average KL loss: 0.256602
Average total loss: 0.830527
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.3265e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.567117
Average KL loss: 0.256801
Average total loss: 0.823917
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.3269e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.559175
Average KL loss: 0.256969
Average total loss: 0.816144
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-7.6241e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.565352
Average KL loss: 0.257185
Average total loss: 0.822537
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(6.0315e-10, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.564769
Average KL loss: 0.257490
Average total loss: 0.822259
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.1642e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.567792
Average KL loss: 0.257791
Average total loss: 0.825584
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-7.9960e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.561295
Average KL loss: 0.258049
Average total loss: 0.819344
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(2.9303e-10, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.562556
Average KL loss: 0.258238
Average total loss: 0.820794
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.9606e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.553082
Average KL loss: 0.258439
Average total loss: 0.811521
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.9134e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.565609
Average KL loss: 0.258582
Average total loss: 0.824191
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-7.7074e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.557723
Average KL loss: 0.258847
Average total loss: 0.816570
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.9547e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.560203
Average KL loss: 0.259013
Average total loss: 0.819216
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.3123e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.562359
Average KL loss: 0.259282
Average total loss: 0.821640
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.0798e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.550409
Average KL loss: 0.259476
Average total loss: 0.809885
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.3804e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.546956
Average KL loss: 0.259606
Average total loss: 0.806562
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.1626e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.541667
Average KL loss: 0.259806
Average total loss: 0.801474
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.0442e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.550240
Average KL loss: 0.259969
Average total loss: 0.810209
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.0787e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.543782
Average KL loss: 0.260104
Average total loss: 0.803887
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.1943e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.563825
Average KL loss: 0.260349
Average total loss: 0.824174
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-9.7923e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.558683
Average KL loss: 0.260583
Average total loss: 0.819267
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-8.4568e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.549334
Average KL loss: 0.260726
Average total loss: 0.810061
tensor(0.0025, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-6.9184e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.546518
Average KL loss: 0.260918
Average total loss: 0.807436
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.4587e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.538720
Average KL loss: 0.261118
Average total loss: 0.799838
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-9.1461e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.539413
Average KL loss: 0.261271
Average total loss: 0.800684
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.2390e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.540548
Average KL loss: 0.261421
Average total loss: 0.801969
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-6.4524e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.547918
Average KL loss: 0.261555
Average total loss: 0.809472
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-9.4248e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.541539
Average KL loss: 0.261712
Average total loss: 0.803251
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.4518e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.542083
Average KL loss: 0.261810
Average total loss: 0.803892
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.1314e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.540384
Average KL loss: 0.261905
Average total loss: 0.802289
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.9394e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.538212
Average KL loss: 0.262021
Average total loss: 0.800234
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.3657e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.555301
Average KL loss: 0.262164
Average total loss: 0.817465
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.9238e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.539688
Average KL loss: 0.262340
Average total loss: 0.802028
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.5308e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.536441
Average KL loss: 0.262444
Average total loss: 0.798885
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.2494e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.532718
Average KL loss: 0.262575
Average total loss: 0.795293
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.0442e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.528996
Average KL loss: 0.262686
Average total loss: 0.791683
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.8246e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.524484
Average KL loss: 0.262842
Average total loss: 0.787327
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.6188e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.537665
Average KL loss: 0.262952
Average total loss: 0.800617
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.8184e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.541620
Average KL loss: 0.263134
Average total loss: 0.804754
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.7133e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.541990
Average KL loss: 0.263359
Average total loss: 0.805349
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.6857e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.535532
Average KL loss: 0.263498
Average total loss: 0.799030
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-8.5163e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.537534
Average KL loss: 0.263666
Average total loss: 0.801200
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.2115e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.540348
Average KL loss: 0.263808
Average total loss: 0.804156
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.0826e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.537542
Average KL loss: 0.263967
Average total loss: 0.801510
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.1010e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.539416
Average KL loss: 0.264146
Average total loss: 0.803562
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.2375e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.518394
Average KL loss: 0.264273
Average total loss: 0.782668
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.6473e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.525375
Average KL loss: 0.264381
Average total loss: 0.789756
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.1392e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.538489
Average KL loss: 0.264440
Average total loss: 0.802929
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.6786e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.532455
Average KL loss: 0.264552
Average total loss: 0.797007
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-6.8086e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.528150
Average KL loss: 0.264691
Average total loss: 0.792840
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.1848e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.537902
Average KL loss: 0.264826
Average total loss: 0.802729
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.5269e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.522690
Average KL loss: 0.264916
Average total loss: 0.787606
tensor(0.0025, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-8.9103e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.521968
Average KL loss: 0.264993
Average total loss: 0.786961
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.9063e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.540965
Average KL loss: 0.265117
Average total loss: 0.806082
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2169e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.530226
Average KL loss: 0.265261
Average total loss: 0.795486
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.0625e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.530861
Average KL loss: 0.265363
Average total loss: 0.796225
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.1355e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.524352
Average KL loss: 0.265505
Average total loss: 0.789856
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.9117e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.530870
Average KL loss: 0.265529
Average total loss: 0.796399
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.1748e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.526341
Average KL loss: 0.265524
Average total loss: 0.791865
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.6567e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.532973
Average KL loss: 0.265523
Average total loss: 0.798496
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3725e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.528455
Average KL loss: 0.265529
Average total loss: 0.793985
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.7232e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.524675
Average KL loss: 0.265531
Average total loss: 0.790206
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-6.5031e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.520857
Average KL loss: 0.265527
Average total loss: 0.786384
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(2.5282e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.526205
Average KL loss: 0.265520
Average total loss: 0.791724
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.4158e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.519018
Average KL loss: 0.265514
Average total loss: 0.784533
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-8.6943e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.531627
Average KL loss: 0.265510
Average total loss: 0.797138
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.4534e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.535823
Average KL loss: 0.265507
Average total loss: 0.801329
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3631e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.525534
Average KL loss: 0.265513
Average total loss: 0.791046
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.1705e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.523312
Average KL loss: 0.265515
Average total loss: 0.788826
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.9542e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.524318
Average KL loss: 0.265515
Average total loss: 0.789833
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(2.4404e-10, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.528460
Average KL loss: 0.265515
Average total loss: 0.793975
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-8.0002e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.515553
Average KL loss: 0.265514
Average total loss: 0.781068
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.4153e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.515017
Average KL loss: 0.265514
Average total loss: 0.780531
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-6.3044e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.526326
Average KL loss: 0.265513
Average total loss: 0.791839
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.6452e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.527419
Average KL loss: 0.265513
Average total loss: 0.792932
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.3766e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.527065
Average KL loss: 0.265513
Average total loss: 0.792578
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3291e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.524617
Average KL loss: 0.265513
Average total loss: 0.790130
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.5465e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.531307
Average KL loss: 0.265513
Average total loss: 0.796819
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.2253e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.517517
Average KL loss: 0.265512
Average total loss: 0.783029
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.6337e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.531663
Average KL loss: 0.265512
Average total loss: 0.797174
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2708e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.525038
Average KL loss: 0.265512
Average total loss: 0.790550
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-8.2349e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.526661
Average KL loss: 0.265513
Average total loss: 0.792173
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3300e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.530272
Average KL loss: 0.265512
Average total loss: 0.795784
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.1368e-09, device='cuda:0')
 Percentile value: 0.007980736903846264
Non-zero model percentage: 3.1250059604644775%, Non-zero mask percentage: 3.1250059604644775%

--- Pruning Level [5/12]: ---
conv1.weight         | nonzeros =     157 /    1728             (  9.09%) | total_pruned =    1571 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
bn1.weight           | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     678 /   36864             (  1.84%) | total_pruned =   36186 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    1320 /   36864             (  3.58%) | total_pruned =   35544 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1409 /   36864             (  3.82%) | total_pruned =   35455 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      40 /      64             ( 62.50%) | total_pruned =      24 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    2378 /   36864             (  6.45%) | total_pruned =   34486 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      43 /      64             ( 67.19%) | total_pruned =      21 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       2 /      64             (  3.12%) | total_pruned =      62 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    6053 /   73728             (  8.21%) | total_pruned =   67675 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     116 /     128             ( 90.62%) | total_pruned =      12 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   10111 /  147456             (  6.86%) | total_pruned =  137345 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     717 /    8192             (  8.75%) | total_pruned =    7475 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      74 /     128             ( 57.81%) | total_pruned =      54 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    4867 /  147456             (  3.30%) | total_pruned =  142589 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3201 /  147456             (  2.17%) | total_pruned =  144255 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   20193 /  294912             (  6.85%) | total_pruned =  274719 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =      30 /     256             ( 11.72%) | total_pruned =     226 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     243 /     256             ( 94.92%) | total_pruned =      13 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   33151 /  589824             (  5.62%) | total_pruned =  556673 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1714 /   32768             (  5.23%) | total_pruned =   31054 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     125 /     256             ( 48.83%) | total_pruned =     131 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   18126 /  589824             (  3.07%) | total_pruned =  571698 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     133 /     256             ( 51.95%) | total_pruned =     123 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      22 /     256             (  8.59%) | total_pruned =     234 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   11643 /  589824             (  1.97%) | total_pruned =  578181 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     131 /     256             ( 51.17%) | total_pruned =     125 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   45724 / 1179648             (  3.88%) | total_pruned = 1133924 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     369 /     512             ( 72.07%) | total_pruned =     143 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   53303 / 2359296             (  2.26%) | total_pruned = 2305993 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     206 /     512             ( 40.23%) | total_pruned =     306 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      37 /     512             (  7.23%) | total_pruned =     475 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    3511 /  131072             (  2.68%) | total_pruned =  127561 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     123 /     512             ( 24.02%) | total_pruned =     389 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      37 /     512             (  7.23%) | total_pruned =     475 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   48558 / 2359296             (  2.06%) | total_pruned = 2310738 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     228 /     512             ( 44.53%) | total_pruned =     284 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   78454 / 2359296             (  3.33%) | total_pruned = 2280842 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     228 /     512             ( 44.53%) | total_pruned =     284 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     112 /     512             ( 21.88%) | total_pruned =     400 | shape = torch.Size([512])
linear.weight        | nonzeros =     953 /    5120             ( 18.61%) | total_pruned =    4167 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 349337, pruned : 10829425, total: 11178762, Compression rate :      32.00x  ( 96.87% pruned)
Train Epoch: 73/100 Loss: 0.022843 Accuracy: 87.51 100.00 % Best test Accuracy: 87.58%
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-5.1586e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.853626
Average KL loss: 0.260578
Average total loss: 1.114204
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-4.0510e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.861096
Average KL loss: 0.255578
Average total loss: 1.116674
tensor(0.0027, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.2155e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.850072
Average KL loss: 0.252950
Average total loss: 1.103022
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.0317e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.816805
Average KL loss: 0.251425
Average total loss: 1.068229
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.4095e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.796344
Average KL loss: 0.250465
Average total loss: 1.046809
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-5.0397e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.777707
Average KL loss: 0.249911
Average total loss: 1.027618
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.2683e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.778578
Average KL loss: 0.249670
Average total loss: 1.028248
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.4190e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.763166
Average KL loss: 0.249625
Average total loss: 1.012791
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.0522e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.764637
Average KL loss: 0.249707
Average total loss: 1.014344
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.2738e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.754001
Average KL loss: 0.249978
Average total loss: 1.003979
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.4456e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.753826
Average KL loss: 0.250240
Average total loss: 1.004066
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.0783e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.746244
Average KL loss: 0.250537
Average total loss: 0.996781
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.6662e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.727590
Average KL loss: 0.250899
Average total loss: 0.978489
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-3.2496e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.718683
Average KL loss: 0.251321
Average total loss: 0.970004
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.6996e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.723198
Average KL loss: 0.251722
Average total loss: 0.974921
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.7068e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.702128
Average KL loss: 0.252095
Average total loss: 0.954223
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-1.2326e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.704915
Average KL loss: 0.252538
Average total loss: 0.957453
tensor(0.0027, device='cuda:0') tensor(0.0035, device='cuda:0') tensor(-2.9239e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.705575
Average KL loss: 0.252981
Average total loss: 0.958556
tensor(0.0027, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.7664e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.714703
Average KL loss: 0.253388
Average total loss: 0.968091
tensor(0.0027, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.1321e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.704588
Average KL loss: 0.253860
Average total loss: 0.958448
tensor(0.0027, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.4188e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.685151
Average KL loss: 0.254307
Average total loss: 0.939457
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.1235e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.680848
Average KL loss: 0.254772
Average total loss: 0.935621
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.7313e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.695098
Average KL loss: 0.255198
Average total loss: 0.950296
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.0277e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.682328
Average KL loss: 0.255620
Average total loss: 0.937948
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.1100e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.676377
Average KL loss: 0.256074
Average total loss: 0.932451
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.1699e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.692646
Average KL loss: 0.256477
Average total loss: 0.949123
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.3089e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.680282
Average KL loss: 0.256929
Average total loss: 0.937211
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.8926e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.671237
Average KL loss: 0.257333
Average total loss: 0.928570
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.9477e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.661236
Average KL loss: 0.257765
Average total loss: 0.919001
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.4069e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.660391
Average KL loss: 0.258098
Average total loss: 0.918489
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-3.0266e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.663843
Average KL loss: 0.258459
Average total loss: 0.922302
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-9.8265e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.653904
Average KL loss: 0.258865
Average total loss: 0.912769
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-7.3726e-09, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.680855
Average KL loss: 0.259248
Average total loss: 0.940103
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.8609e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.639359
Average KL loss: 0.259569
Average total loss: 0.898928
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.5321e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.638991
Average KL loss: 0.259870
Average total loss: 0.898862
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.6253e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.651193
Average KL loss: 0.260236
Average total loss: 0.911429
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.7716e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.651373
Average KL loss: 0.260585
Average total loss: 0.911958
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.0599e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.639535
Average KL loss: 0.260918
Average total loss: 0.900453
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-5.4607e-09, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.656028
Average KL loss: 0.261274
Average total loss: 0.917302
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-2.1442e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.640158
Average KL loss: 0.261679
Average total loss: 0.901838
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.8476e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.632899
Average KL loss: 0.262055
Average total loss: 0.894954
tensor(0.0026, device='cuda:0') tensor(0.0036, device='cuda:0') tensor(-1.3627e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.635584
Average KL loss: 0.262349
Average total loss: 0.897933
tensor(0.0026, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.0391e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.632592
Average KL loss: 0.262681
Average total loss: 0.895273
tensor(0.0026, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.7480e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.630862
Average KL loss: 0.263001
Average total loss: 0.893863
tensor(0.0026, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.4287e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.630915
Average KL loss: 0.263331
Average total loss: 0.894246
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.2238e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.635995
Average KL loss: 0.263696
Average total loss: 0.899691
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.8071e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.629369
Average KL loss: 0.264020
Average total loss: 0.893389
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-8.1352e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.624679
Average KL loss: 0.264322
Average total loss: 0.889002
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.4231e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.623857
Average KL loss: 0.264592
Average total loss: 0.888449
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-2.1912e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.617078
Average KL loss: 0.264866
Average total loss: 0.881944
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.3300e-10, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.618216
Average KL loss: 0.265139
Average total loss: 0.883355
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3806e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.619830
Average KL loss: 0.265453
Average total loss: 0.885283
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.1024e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.610274
Average KL loss: 0.265725
Average total loss: 0.875999
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-8.6994e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.608698
Average KL loss: 0.265978
Average total loss: 0.874676
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.1312e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.627333
Average KL loss: 0.266225
Average total loss: 0.893558
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.3006e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.611877
Average KL loss: 0.266503
Average total loss: 0.878380
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.0633e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.612834
Average KL loss: 0.266744
Average total loss: 0.879578
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.4566e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.606611
Average KL loss: 0.267074
Average total loss: 0.873686
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.6419e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.600770
Average KL loss: 0.267341
Average total loss: 0.868112
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.7472e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.601049
Average KL loss: 0.267594
Average total loss: 0.868643
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.5052e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.601936
Average KL loss: 0.267828
Average total loss: 0.869764
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-3.5106e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.600676
Average KL loss: 0.268034
Average total loss: 0.868710
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-6.4243e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.600513
Average KL loss: 0.268296
Average total loss: 0.868809
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-6.0727e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.605823
Average KL loss: 0.268502
Average total loss: 0.874325
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.1138e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.607851
Average KL loss: 0.268716
Average total loss: 0.876567
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-4.9507e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.591319
Average KL loss: 0.268980
Average total loss: 0.860299
tensor(0.0025, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-1.9403e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.594481
Average KL loss: 0.269149
Average total loss: 0.863630
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.5096e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.588719
Average KL loss: 0.269382
Average total loss: 0.858102
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(3.2545e-10, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.606587
Average KL loss: 0.269586
Average total loss: 0.876172
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.5724e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.589083
Average KL loss: 0.269821
Average total loss: 0.858903
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.2792e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.591608
Average KL loss: 0.270124
Average total loss: 0.861733
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(1.7204e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.584414
Average KL loss: 0.270384
Average total loss: 0.854798
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.5637e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.586183
Average KL loss: 0.270536
Average total loss: 0.856719
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.4227e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.582536
Average KL loss: 0.270750
Average total loss: 0.853287
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.4243e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.584249
Average KL loss: 0.270961
Average total loss: 0.855210
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-5.0809e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.588193
Average KL loss: 0.271182
Average total loss: 0.859374
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.5389e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.595594
Average KL loss: 0.271442
Average total loss: 0.867036
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-8.1524e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.580132
Average KL loss: 0.271660
Average total loss: 0.851792
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-4.1547e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.576971
Average KL loss: 0.271904
Average total loss: 0.848875
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.1816e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.595667
Average KL loss: 0.272163
Average total loss: 0.867830
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-5.6976e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.577317
Average KL loss: 0.272360
Average total loss: 0.849677
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-7.0106e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.592289
Average KL loss: 0.272502
Average total loss: 0.864791
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.1159e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.569853
Average KL loss: 0.272748
Average total loss: 0.842601
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-5.9873e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.573478
Average KL loss: 0.272952
Average total loss: 0.846431
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-7.7527e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.572321
Average KL loss: 0.273113
Average total loss: 0.845434
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.7423e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.570912
Average KL loss: 0.273295
Average total loss: 0.844206
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.2466e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.578637
Average KL loss: 0.273464
Average total loss: 0.852101
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.0146e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.578774
Average KL loss: 0.273622
Average total loss: 0.852396
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.4938e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.573062
Average KL loss: 0.273829
Average total loss: 0.846892
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.7176e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.569735
Average KL loss: 0.274001
Average total loss: 0.843736
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.2448e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.568533
Average KL loss: 0.274211
Average total loss: 0.842744
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.6279e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.567202
Average KL loss: 0.274393
Average total loss: 0.841595
tensor(0.0025, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-4.0496e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.563321
Average KL loss: 0.274569
Average total loss: 0.837890
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.1332e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.572841
Average KL loss: 0.274730
Average total loss: 0.847571
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.0044e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.587418
Average KL loss: 0.274956
Average total loss: 0.862373
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.8179e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.568225
Average KL loss: 0.275178
Average total loss: 0.843403
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.7932e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.566103
Average KL loss: 0.275316
Average total loss: 0.841419
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.2098e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.569897
Average KL loss: 0.275518
Average total loss: 0.845415
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.4865e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.556480
Average KL loss: 0.275728
Average total loss: 0.832208
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.2315e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.572573
Average KL loss: 0.275886
Average total loss: 0.848459
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.5227e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.558077
Average KL loss: 0.276040
Average total loss: 0.834117
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.9582e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.586195
Average KL loss: 0.276173
Average total loss: 0.862367
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.0571e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.570275
Average KL loss: 0.276340
Average total loss: 0.846616
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.8853e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.559125
Average KL loss: 0.276455
Average total loss: 0.835580
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.1447e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.564624
Average KL loss: 0.276618
Average total loss: 0.841242
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-9.9066e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.571468
Average KL loss: 0.276815
Average total loss: 0.848283
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.3031e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.566299
Average KL loss: 0.277047
Average total loss: 0.843346
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.0506e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.561838
Average KL loss: 0.277255
Average total loss: 0.839093
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-8.2746e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.550348
Average KL loss: 0.277383
Average total loss: 0.827731
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.0945e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.555631
Average KL loss: 0.277475
Average total loss: 0.833106
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.8776e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.553886
Average KL loss: 0.277621
Average total loss: 0.831507
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.2542e-10, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.563769
Average KL loss: 0.277791
Average total loss: 0.841560
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-4.7637e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.556776
Average KL loss: 0.277935
Average total loss: 0.834711
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-8.7607e-10, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.560282
Average KL loss: 0.278084
Average total loss: 0.838366
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.4129e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.554704
Average KL loss: 0.278267
Average total loss: 0.832971
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.1056e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.565484
Average KL loss: 0.278400
Average total loss: 0.843883
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.9955e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.542935
Average KL loss: 0.278499
Average total loss: 0.821434
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.0614e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.556921
Average KL loss: 0.278592
Average total loss: 0.835513
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.0366e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.558361
Average KL loss: 0.278687
Average total loss: 0.837048
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.2253e-12, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.552488
Average KL loss: 0.278739
Average total loss: 0.831227
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(3.3118e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.552933
Average KL loss: 0.278841
Average total loss: 0.831774
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(1.4856e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.544905
Average KL loss: 0.278994
Average total loss: 0.823899
tensor(0.0024, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.2471e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.557376
Average KL loss: 0.279155
Average total loss: 0.836531
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.1071e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.554177
Average KL loss: 0.279298
Average total loss: 0.833475
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(5.8229e-10, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.553491
Average KL loss: 0.279403
Average total loss: 0.832893
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.9274e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.542326
Average KL loss: 0.279577
Average total loss: 0.821903
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.2574e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.559295
Average KL loss: 0.279716
Average total loss: 0.839011
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.6674e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.546201
Average KL loss: 0.279896
Average total loss: 0.826097
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0134e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.543668
Average KL loss: 0.279941
Average total loss: 0.823608
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.4304e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.560857
Average KL loss: 0.279946
Average total loss: 0.840803
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.9370e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.547408
Average KL loss: 0.279945
Average total loss: 0.827353
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.8786e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.550345
Average KL loss: 0.279938
Average total loss: 0.830282
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.8578e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.544684
Average KL loss: 0.279937
Average total loss: 0.824622
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.7307e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.548310
Average KL loss: 0.279941
Average total loss: 0.828250
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.4657e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.555190
Average KL loss: 0.279948
Average total loss: 0.835138
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.3619e-10, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.544724
Average KL loss: 0.279955
Average total loss: 0.824678
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.3206e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.541002
Average KL loss: 0.279956
Average total loss: 0.820958
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0562e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.549763
Average KL loss: 0.279954
Average total loss: 0.829717
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.3661e-10, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.544716
Average KL loss: 0.279956
Average total loss: 0.824672
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.9493e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.547027
Average KL loss: 0.279958
Average total loss: 0.826985
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.2704e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.544023
Average KL loss: 0.279963
Average total loss: 0.823986
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.5460e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.554211
Average KL loss: 0.279958
Average total loss: 0.834169
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(1.2655e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.547525
Average KL loss: 0.279954
Average total loss: 0.827478
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.1342e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.547445
Average KL loss: 0.279955
Average total loss: 0.827400
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.4428e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.556900
Average KL loss: 0.279961
Average total loss: 0.836861
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.0296e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.541228
Average KL loss: 0.279967
Average total loss: 0.821195
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.6744e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.559765
Average KL loss: 0.279969
Average total loss: 0.839734
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.1620e-10, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.545084
Average KL loss: 0.279975
Average total loss: 0.825059
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-3.2695e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.546875
Average KL loss: 0.279978
Average total loss: 0.826853
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.1738e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.547139
Average KL loss: 0.279978
Average total loss: 0.827117
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-4.9040e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.543976
Average KL loss: 0.279977
Average total loss: 0.823953
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.6139e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.545432
Average KL loss: 0.279978
Average total loss: 0.825410
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.1726e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.554419
Average KL loss: 0.279978
Average total loss: 0.834397
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.8906e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.552739
Average KL loss: 0.279979
Average total loss: 0.832718
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.2575e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.556350
Average KL loss: 0.279979
Average total loss: 0.836329
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.1527e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.529762
Average KL loss: 0.279979
Average total loss: 0.809741
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(2.6643e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.546180
Average KL loss: 0.279979
Average total loss: 0.826159
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.5382e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.546409
Average KL loss: 0.279979
Average total loss: 0.826388
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.1302e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.540935
Average KL loss: 0.279979
Average total loss: 0.820915
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.3945e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.539280
Average KL loss: 0.279980
Average total loss: 0.819260
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.1247e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.538099
Average KL loss: 0.279979
Average total loss: 0.818078
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0029e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.552142
Average KL loss: 0.279979
Average total loss: 0.832121
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.2655e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.546682
Average KL loss: 0.279979
Average total loss: 0.826661
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.7326e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.541372
Average KL loss: 0.279979
Average total loss: 0.821351
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0560e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.542632
Average KL loss: 0.279979
Average total loss: 0.822611
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.9646e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.544415
Average KL loss: 0.279979
Average total loss: 0.824394
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.4722e-09, device='cuda:0')
 Percentile value: 0.04165918007493019
Non-zero model percentage: 1.5625073909759521%, Non-zero mask percentage: 1.5625073909759521%

--- Pruning Level [6/12]: ---
conv1.weight         | nonzeros =     140 /    1728             (  8.10%) | total_pruned =    1588 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
bn1.bias             | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     326 /   36864             (  0.88%) | total_pruned =   36538 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     639 /   36864             (  1.73%) | total_pruned =   36225 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     731 /   36864             (  1.98%) | total_pruned =   36133 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1511 /   36864             (  4.10%) | total_pruned =   35353 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      41 /      64             ( 64.06%) | total_pruned =      23 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4190 /   73728             (  5.68%) | total_pruned =   69538 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     113 /     128             ( 88.28%) | total_pruned =      15 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    6801 /  147456             (  4.61%) | total_pruned =  140655 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     513 /    8192             (  6.26%) | total_pruned =    7679 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3111 /  147456             (  2.11%) | total_pruned =  144345 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      62 /     128             ( 48.44%) | total_pruned =      66 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1925 /  147456             (  1.31%) | total_pruned =  145531 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   14067 /  294912             (  4.77%) | total_pruned =  280845 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   22103 /  589824             (  3.75%) | total_pruned =  567721 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     223 /     256             ( 87.11%) | total_pruned =      33 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1126 /   32768             (  3.44%) | total_pruned =   31642 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     116 /     256             ( 45.31%) | total_pruned =     140 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   11283 /  589824             (  1.91%) | total_pruned =  578541 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     131 /     256             ( 51.17%) | total_pruned =     125 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    6370 /  589824             (  1.08%) | total_pruned =  583454 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   26383 / 1179648             (  2.24%) | total_pruned = 1153265 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     360 /     512             ( 70.31%) | total_pruned =     152 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   22688 / 2359296             (  0.96%) | total_pruned = 2336608 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     165 /     512             ( 32.23%) | total_pruned =     347 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      23 /     512             (  4.49%) | total_pruned =     489 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    1283 /  131072             (  0.98%) | total_pruned =  129789 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      75 /     512             ( 14.65%) | total_pruned =     437 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      27 /     512             (  5.27%) | total_pruned =     485 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   14613 / 2359296             (  0.62%) | total_pruned = 2344683 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     183 /     512             ( 35.74%) | total_pruned =     329 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   31527 / 2359296             (  1.34%) | total_pruned = 2327769 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     161 /     512             ( 31.45%) | total_pruned =     351 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      78 /     512             ( 15.23%) | total_pruned =     434 | shape = torch.Size([512])
linear.weight        | nonzeros =     695 /    5120             ( 13.57%) | total_pruned =    4425 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 174669, pruned : 11004093, total: 11178762, Compression rate :      64.00x  ( 98.44% pruned)
Train Epoch: 78/100 Loss: 0.042922 Accuracy: 87.58 100.00 % Best test Accuracy: 87.74%
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.9547e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.893847
Average KL loss: 0.275680
Average total loss: 1.169527
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.6720e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.889563
Average KL loss: 0.271034
Average total loss: 1.160597
tensor(0.0026, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.4355e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.900488
Average KL loss: 0.268297
Average total loss: 1.168785
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-3.2064e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.852906
Average KL loss: 0.266504
Average total loss: 1.119410
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-3.3214e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.841314
Average KL loss: 0.265258
Average total loss: 1.106572
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.7562e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.833795
Average KL loss: 0.264380
Average total loss: 1.098175
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.3257e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.834075
Average KL loss: 0.263836
Average total loss: 1.097911
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.3220e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.815327
Average KL loss: 0.263479
Average total loss: 1.078806
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.9532e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.805442
Average KL loss: 0.263272
Average total loss: 1.068714
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-3.3740e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.797465
Average KL loss: 0.263167
Average total loss: 1.060632
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.5149e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.785771
Average KL loss: 0.263152
Average total loss: 1.048923
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.9473e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.788916
Average KL loss: 0.263253
Average total loss: 1.052169
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.9096e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.776365
Average KL loss: 0.263378
Average total loss: 1.039744
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.4518e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.783899
Average KL loss: 0.263533
Average total loss: 1.047431
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.7482e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.779107
Average KL loss: 0.263751
Average total loss: 1.042859
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.2384e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.753162
Average KL loss: 0.264006
Average total loss: 1.017168
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.2638e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.760976
Average KL loss: 0.264297
Average total loss: 1.025273
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.9428e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.739728
Average KL loss: 0.264633
Average total loss: 1.004362
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.2875e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.752537
Average KL loss: 0.264955
Average total loss: 1.017492
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.9134e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.741245
Average KL loss: 0.265294
Average total loss: 1.006539
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.8015e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.721520
Average KL loss: 0.265583
Average total loss: 0.987103
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-2.1601e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.725303
Average KL loss: 0.265917
Average total loss: 0.991220
tensor(0.0026, device='cuda:0') tensor(0.0038, device='cuda:0') tensor(-1.4769e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.717909
Average KL loss: 0.266233
Average total loss: 0.984142
tensor(0.0026, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.2991e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.722290
Average KL loss: 0.266535
Average total loss: 0.988824
tensor(0.0026, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.3958e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.725141
Average KL loss: 0.266883
Average total loss: 0.992024
tensor(0.0026, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.3867e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.718511
Average KL loss: 0.267254
Average total loss: 0.985765
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.4676e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.718005
Average KL loss: 0.267623
Average total loss: 0.985627
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.0344e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.717735
Average KL loss: 0.267956
Average total loss: 0.985691
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.3186e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.714860
Average KL loss: 0.268309
Average total loss: 0.983169
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.4471e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.712121
Average KL loss: 0.268652
Average total loss: 0.980773
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.4041e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.694235
Average KL loss: 0.268970
Average total loss: 0.963206
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-7.4992e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.693251
Average KL loss: 0.269240
Average total loss: 0.962491
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.0152e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.694298
Average KL loss: 0.269559
Average total loss: 0.963857
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.7275e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.695374
Average KL loss: 0.269931
Average total loss: 0.965305
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-5.2547e-09, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.696302
Average KL loss: 0.270259
Average total loss: 0.966560
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.9285e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.686617
Average KL loss: 0.270554
Average total loss: 0.957171
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.1601e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.678212
Average KL loss: 0.270819
Average total loss: 0.949031
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.5433e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.686653
Average KL loss: 0.271089
Average total loss: 0.957742
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.6949e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.680839
Average KL loss: 0.271404
Average total loss: 0.952242
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-3.2375e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.675604
Average KL loss: 0.271706
Average total loss: 0.947310
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.3231e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.676306
Average KL loss: 0.272000
Average total loss: 0.948306
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.1707e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.660251
Average KL loss: 0.272322
Average total loss: 0.932573
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.0354e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.677785
Average KL loss: 0.272652
Average total loss: 0.950436
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-6.4521e-09, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.674523
Average KL loss: 0.272962
Average total loss: 0.947484
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.9930e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.656472
Average KL loss: 0.273256
Average total loss: 0.929728
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.0351e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.666895
Average KL loss: 0.273555
Average total loss: 0.940450
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-2.4077e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.665378
Average KL loss: 0.273870
Average total loss: 0.939248
tensor(0.0025, device='cuda:0') tensor(0.0039, device='cuda:0') tensor(-1.5312e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.675443
Average KL loss: 0.274228
Average total loss: 0.949670
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.9609e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.657844
Average KL loss: 0.274562
Average total loss: 0.932406
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.4300e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.676193
Average KL loss: 0.274874
Average total loss: 0.951067
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.2081e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.659876
Average KL loss: 0.275155
Average total loss: 0.935031
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.4772e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.646473
Average KL loss: 0.275388
Average total loss: 0.921861
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-7.4848e-10, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.649728
Average KL loss: 0.275663
Average total loss: 0.925390
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.4552e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.635735
Average KL loss: 0.275991
Average total loss: 0.911726
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0937e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.648994
Average KL loss: 0.276306
Average total loss: 0.925300
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.4544e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.666621
Average KL loss: 0.276592
Average total loss: 0.943213
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.7760e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.652217
Average KL loss: 0.276902
Average total loss: 0.929118
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-6.8709e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.649392
Average KL loss: 0.277165
Average total loss: 0.926557
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-8.4988e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.646428
Average KL loss: 0.277454
Average total loss: 0.923882
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.2992e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.637830
Average KL loss: 0.277748
Average total loss: 0.915578
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.9734e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.633867
Average KL loss: 0.277988
Average total loss: 0.911855
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.3050e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.627039
Average KL loss: 0.278207
Average total loss: 0.905245
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.9670e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.646859
Average KL loss: 0.278466
Average total loss: 0.925325
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.3871e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.638167
Average KL loss: 0.278760
Average total loss: 0.916927
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(5.0657e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.626894
Average KL loss: 0.279019
Average total loss: 0.905913
tensor(0.0025, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.4891e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.626749
Average KL loss: 0.279216
Average total loss: 0.905964
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-9.0502e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.626665
Average KL loss: 0.279457
Average total loss: 0.906122
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.9807e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.637384
Average KL loss: 0.279754
Average total loss: 0.917138
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.2474e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.633839
Average KL loss: 0.280005
Average total loss: 0.913844
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0447e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.614348
Average KL loss: 0.280271
Average total loss: 0.894619
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-1.0039e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.618416
Average KL loss: 0.280517
Average total loss: 0.898933
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-5.2648e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.623216
Average KL loss: 0.280763
Average total loss: 0.903979
tensor(0.0024, device='cuda:0') tensor(0.0040, device='cuda:0') tensor(-2.0494e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.620037
Average KL loss: 0.281006
Average total loss: 0.901042
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.2126e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.626973
Average KL loss: 0.281263
Average total loss: 0.908236
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4547e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.615453
Average KL loss: 0.281530
Average total loss: 0.896983
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.4619e-09, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.614616
Average KL loss: 0.281722
Average total loss: 0.896338
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.1437e-10, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.610304
Average KL loss: 0.281931
Average total loss: 0.892236
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.5637e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.641226
Average KL loss: 0.282206
Average total loss: 0.923432
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.2205e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.612548
Average KL loss: 0.282427
Average total loss: 0.894974
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.2850e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.616010
Average KL loss: 0.282607
Average total loss: 0.898617
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.3696e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.606824
Average KL loss: 0.282797
Average total loss: 0.889621
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.4175e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.614838
Average KL loss: 0.283013
Average total loss: 0.897851
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.7999e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.624255
Average KL loss: 0.283259
Average total loss: 0.907514
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.7813e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.610385
Average KL loss: 0.283462
Average total loss: 0.893848
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-6.9520e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.611671
Average KL loss: 0.283676
Average total loss: 0.895348
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.1388e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.604602
Average KL loss: 0.283902
Average total loss: 0.888505
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4475e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.605979
Average KL loss: 0.284142
Average total loss: 0.890121
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-8.3548e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.598559
Average KL loss: 0.284364
Average total loss: 0.882922
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.0112e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.603494
Average KL loss: 0.284529
Average total loss: 0.888023
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4836e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.602187
Average KL loss: 0.284709
Average total loss: 0.886896
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.2475e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.596080
Average KL loss: 0.284923
Average total loss: 0.881003
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-7.8152e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.597461
Average KL loss: 0.285135
Average total loss: 0.882596
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.3810e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.603884
Average KL loss: 0.285303
Average total loss: 0.889187
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.9400e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.608266
Average KL loss: 0.285494
Average total loss: 0.893761
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-9.6806e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.598130
Average KL loss: 0.285695
Average total loss: 0.883825
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.8364e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.602214
Average KL loss: 0.285923
Average total loss: 0.888137
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4830e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.592349
Average KL loss: 0.286114
Average total loss: 0.878464
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.5846e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.606749
Average KL loss: 0.286320
Average total loss: 0.893069
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.9464e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.600356
Average KL loss: 0.286531
Average total loss: 0.886887
tensor(0.0024, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-5.9135e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.582153
Average KL loss: 0.286706
Average total loss: 0.868859
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.5778e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.603309
Average KL loss: 0.286877
Average total loss: 0.890186
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.2543e-10, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.589658
Average KL loss: 0.287071
Average total loss: 0.876728
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.8519e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.591626
Average KL loss: 0.287310
Average total loss: 0.878936
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.1255e-10, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.600362
Average KL loss: 0.287514
Average total loss: 0.887876
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.6994e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.594635
Average KL loss: 0.287708
Average total loss: 0.882343
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-7.7913e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.591454
Average KL loss: 0.287900
Average total loss: 0.879354
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-7.9839e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.593928
Average KL loss: 0.288093
Average total loss: 0.882021
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.4872e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.591574
Average KL loss: 0.288234
Average total loss: 0.879808
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.9381e-10, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.599730
Average KL loss: 0.288414
Average total loss: 0.888145
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-5.9366e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.591060
Average KL loss: 0.288676
Average total loss: 0.879736
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.2184e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.595491
Average KL loss: 0.288892
Average total loss: 0.884383
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.0279e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.587863
Average KL loss: 0.288994
Average total loss: 0.876857
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.9233e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.593892
Average KL loss: 0.288999
Average total loss: 0.882891
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-6.7778e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.573787
Average KL loss: 0.289007
Average total loss: 0.862794
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(3.0513e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.575636
Average KL loss: 0.289008
Average total loss: 0.864645
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-6.6194e-10, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.588875
Average KL loss: 0.289012
Average total loss: 0.877887
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-6.9467e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.579497
Average KL loss: 0.289022
Average total loss: 0.868518
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.0323e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.582861
Average KL loss: 0.289032
Average total loss: 0.871893
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.8195e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.586658
Average KL loss: 0.289041
Average total loss: 0.875699
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.0311e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.581626
Average KL loss: 0.289052
Average total loss: 0.870679
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.0683e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.580716
Average KL loss: 0.289061
Average total loss: 0.869777
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.4518e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.591604
Average KL loss: 0.289067
Average total loss: 0.880671
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.1873e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.590463
Average KL loss: 0.289074
Average total loss: 0.879537
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(3.9517e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.582550
Average KL loss: 0.289079
Average total loss: 0.871629
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-7.0304e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.580791
Average KL loss: 0.289085
Average total loss: 0.869876
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.8590e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.580163
Average KL loss: 0.289090
Average total loss: 0.869253
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.2115e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.599368
Average KL loss: 0.289091
Average total loss: 0.888459
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.9140e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.583339
Average KL loss: 0.289093
Average total loss: 0.872432
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-7.0788e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.589206
Average KL loss: 0.289093
Average total loss: 0.878299
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.7238e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.583417
Average KL loss: 0.289094
Average total loss: 0.872511
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(9.3732e-10, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.584506
Average KL loss: 0.289095
Average total loss: 0.873601
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-6.7135e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.592672
Average KL loss: 0.289097
Average total loss: 0.881768
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.1297e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.574604
Average KL loss: 0.289097
Average total loss: 0.863702
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.2153e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.581076
Average KL loss: 0.289098
Average total loss: 0.870175
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.7520e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.575004
Average KL loss: 0.289099
Average total loss: 0.864103
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.5431e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.572568
Average KL loss: 0.289100
Average total loss: 0.861669
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-9.5807e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.587617
Average KL loss: 0.289101
Average total loss: 0.876718
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-5.3625e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.592156
Average KL loss: 0.289102
Average total loss: 0.881258
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.6536e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.587244
Average KL loss: 0.289104
Average total loss: 0.876348
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.0974e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.578932
Average KL loss: 0.289105
Average total loss: 0.868037
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.1375e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.591404
Average KL loss: 0.289106
Average total loss: 0.880509
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-7.9716e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.586035
Average KL loss: 0.289107
Average total loss: 0.875141
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-6.8708e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.578325
Average KL loss: 0.289108
Average total loss: 0.867432
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.0654e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.581197
Average KL loss: 0.289109
Average total loss: 0.870306
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.8890e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.587612
Average KL loss: 0.289110
Average total loss: 0.876722
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.7857e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.591341
Average KL loss: 0.289111
Average total loss: 0.880452
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.1339e-08, device='cuda:0')
 Percentile value: 0.15118184685707092
Non-zero model percentage: 0.781258225440979%, Non-zero mask percentage: 0.781258225440979%

--- Pruning Level [7/12]: ---
conv1.weight         | nonzeros =     105 /    1728             (  6.08%) | total_pruned =    1623 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
bn1.bias             | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     130 /   36864             (  0.35%) | total_pruned =   36734 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     299 /   36864             (  0.81%) | total_pruned =   36565 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     381 /   36864             (  1.03%) | total_pruned =   36483 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     787 /   36864             (  2.13%) | total_pruned =   36077 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2863 /   73728             (  3.88%) | total_pruned =   70865 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4825 /  147456             (  3.27%) | total_pruned =  142631 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     342 /    8192             (  4.17%) | total_pruned =    7850 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2216 /  147456             (  1.50%) | total_pruned =  145240 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      61 /     128             ( 47.66%) | total_pruned =      67 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1386 /  147456             (  0.94%) | total_pruned =  146070 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   10010 /  294912             (  3.39%) | total_pruned =  284902 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     241 /     256             ( 94.14%) | total_pruned =      15 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   15130 /  589824             (  2.57%) | total_pruned =  574694 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     217 /     256             ( 84.77%) | total_pruned =      39 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     722 /   32768             (  2.20%) | total_pruned =   32046 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     105 /     256             ( 41.02%) | total_pruned =     151 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    7427 /  589824             (  1.26%) | total_pruned =  582397 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3984 /  589824             (  0.68%) | total_pruned =  585840 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     117 /     256             ( 45.70%) | total_pruned =     139 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   14879 / 1179648             (  1.26%) | total_pruned = 1164769 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     331 /     512             ( 64.65%) | total_pruned =     181 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   10277 / 2359296             (  0.44%) | total_pruned = 2349019 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     136 /     512             ( 26.56%) | total_pruned =     376 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     475 /  131072             (  0.36%) | total_pruned =  130597 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      48 /     512             (  9.38%) | total_pruned =     464 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    3958 / 2359296             (  0.17%) | total_pruned = 2355338 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     108 /     512             ( 21.09%) | total_pruned =     404 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    4603 / 2359296             (  0.20%) | total_pruned = 2354693 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      85 /     512             ( 16.60%) | total_pruned =     427 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
linear.weight        | nonzeros =     338 /    5120             (  6.60%) | total_pruned =    4782 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 87335, pruned : 11091427, total: 11178762, Compression rate :     128.00x  ( 99.22% pruned)
Train Epoch: 79/100 Loss: 0.025662 Accuracy: 86.92 99.99 % Best test Accuracy: 87.04%
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-4.9925e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.920074
Average KL loss: 0.285663
Average total loss: 1.205737
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.8190e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.910241
Average KL loss: 0.282031
Average total loss: 1.192272
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.4738e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.892382
Average KL loss: 0.279820
Average total loss: 1.172202
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.3288e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.896600
Average KL loss: 0.278308
Average total loss: 1.174908
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.6390e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.889724
Average KL loss: 0.277275
Average total loss: 1.166999
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.1634e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.880315
Average KL loss: 0.276538
Average total loss: 1.156853
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.9230e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.853693
Average KL loss: 0.276063
Average total loss: 1.129756
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.7132e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.835434
Average KL loss: 0.275735
Average total loss: 1.111169
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.4776e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.846440
Average KL loss: 0.275498
Average total loss: 1.121938
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.5660e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.837648
Average KL loss: 0.275349
Average total loss: 1.112997
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.2782e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.834412
Average KL loss: 0.275319
Average total loss: 1.109731
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.3657e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.822539
Average KL loss: 0.275346
Average total loss: 1.097885
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.4917e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.815060
Average KL loss: 0.275434
Average total loss: 1.090493
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.6108e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.811469
Average KL loss: 0.275564
Average total loss: 1.087033
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.3981e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.810491
Average KL loss: 0.275734
Average total loss: 1.086226
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.1873e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.800009
Average KL loss: 0.275903
Average total loss: 1.075911
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.3284e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.800819
Average KL loss: 0.276100
Average total loss: 1.076918
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.4998e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.795004
Average KL loss: 0.276276
Average total loss: 1.071280
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.8674e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.787044
Average KL loss: 0.276472
Average total loss: 1.063516
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.1924e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.796880
Average KL loss: 0.276723
Average total loss: 1.073603
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-9.0606e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.777330
Average KL loss: 0.277004
Average total loss: 1.054334
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.2581e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.772368
Average KL loss: 0.277252
Average total loss: 1.049621
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-9.0194e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.764853
Average KL loss: 0.277518
Average total loss: 1.042371
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.8779e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.754948
Average KL loss: 0.277758
Average total loss: 1.032706
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.9564e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.757154
Average KL loss: 0.278054
Average total loss: 1.035208
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-3.6350e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.751112
Average KL loss: 0.278344
Average total loss: 1.029456
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.0545e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.748822
Average KL loss: 0.278604
Average total loss: 1.027426
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.6349e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.766259
Average KL loss: 0.278921
Average total loss: 1.045180
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.3115e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.742415
Average KL loss: 0.279247
Average total loss: 1.021663
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.1492e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.751125
Average KL loss: 0.279568
Average total loss: 1.030692
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.4120e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.769731
Average KL loss: 0.279890
Average total loss: 1.049621
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.5067e-09, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.734817
Average KL loss: 0.280189
Average total loss: 1.015006
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-1.5859e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.733462
Average KL loss: 0.280537
Average total loss: 1.013999
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-4.0986e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.743215
Average KL loss: 0.280843
Average total loss: 1.024057
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.6331e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.747064
Average KL loss: 0.281193
Average total loss: 1.028258
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.5410e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.726907
Average KL loss: 0.281521
Average total loss: 1.008428
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.6057e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.720522
Average KL loss: 0.281803
Average total loss: 1.002325
tensor(0.0025, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-2.0850e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.727152
Average KL loss: 0.282123
Average total loss: 1.009275
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.4475e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.729279
Average KL loss: 0.282459
Average total loss: 1.011738
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.1034e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.716449
Average KL loss: 0.282758
Average total loss: 0.999207
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.3674e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.705719
Average KL loss: 0.283062
Average total loss: 0.988781
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.8202e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.721993
Average KL loss: 0.283364
Average total loss: 1.005357
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.0037e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.718272
Average KL loss: 0.283689
Average total loss: 1.001961
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.7403e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.708676
Average KL loss: 0.283995
Average total loss: 0.992671
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-7.2736e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.708829
Average KL loss: 0.284288
Average total loss: 0.993117
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.4246e-09, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.707672
Average KL loss: 0.284602
Average total loss: 0.992275
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-3.9689e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.698315
Average KL loss: 0.284873
Average total loss: 0.983188
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.3204e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.688804
Average KL loss: 0.285164
Average total loss: 0.973968
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.7021e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.696687
Average KL loss: 0.285482
Average total loss: 0.982169
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.9110e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.685323
Average KL loss: 0.285813
Average total loss: 0.971136
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.7220e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.679965
Average KL loss: 0.286151
Average total loss: 0.966116
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-9.8337e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.703889
Average KL loss: 0.286472
Average total loss: 0.990360
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.1197e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.681818
Average KL loss: 0.286728
Average total loss: 0.968546
tensor(0.0025, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.6225e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.695889
Average KL loss: 0.287017
Average total loss: 0.982905
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-8.1555e-09, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.695198
Average KL loss: 0.287318
Average total loss: 0.982516
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.0456e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.688094
Average KL loss: 0.287609
Average total loss: 0.975703
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.0097e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.678937
Average KL loss: 0.287930
Average total loss: 0.966867
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.1170e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.695933
Average KL loss: 0.288203
Average total loss: 0.984135
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-2.4333e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.680683
Average KL loss: 0.288534
Average total loss: 0.969217
tensor(0.0024, device='cuda:0') tensor(0.0042, device='cuda:0') tensor(-1.5856e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.675757
Average KL loss: 0.288853
Average total loss: 0.964610
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.6061e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.676413
Average KL loss: 0.289147
Average total loss: 0.965560
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.5107e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.675959
Average KL loss: 0.289444
Average total loss: 0.965403
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.6902e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.668459
Average KL loss: 0.289674
Average total loss: 0.958133
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(5.4012e-10, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.661011
Average KL loss: 0.289908
Average total loss: 0.950919
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.8738e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.665905
Average KL loss: 0.290207
Average total loss: 0.956112
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.2683e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.670349
Average KL loss: 0.290530
Average total loss: 0.960879
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.7438e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.676932
Average KL loss: 0.290880
Average total loss: 0.967812
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-6.1713e-11, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.659975
Average KL loss: 0.291229
Average total loss: 0.951204
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.8065e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.666323
Average KL loss: 0.291535
Average total loss: 0.957857
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.4812e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.665767
Average KL loss: 0.291842
Average total loss: 0.957609
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.2011e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.669316
Average KL loss: 0.292213
Average total loss: 0.961529
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.4077e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.671787
Average KL loss: 0.292529
Average total loss: 0.964316
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.9490e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.652278
Average KL loss: 0.292797
Average total loss: 0.945075
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.8774e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.640499
Average KL loss: 0.293017
Average total loss: 0.933516
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.1271e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.652948
Average KL loss: 0.293272
Average total loss: 0.946221
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.0536e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.657840
Average KL loss: 0.293584
Average total loss: 0.951424
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.2876e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.653270
Average KL loss: 0.293891
Average total loss: 0.947161
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-5.4091e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.643808
Average KL loss: 0.294187
Average total loss: 0.937994
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-9.7595e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.648359
Average KL loss: 0.294474
Average total loss: 0.942833
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-9.5463e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.656983
Average KL loss: 0.294736
Average total loss: 0.951718
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-8.2980e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.668416
Average KL loss: 0.295008
Average total loss: 0.963424
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(1.1179e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.647072
Average KL loss: 0.295246
Average total loss: 0.942318
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.3223e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.651789
Average KL loss: 0.295450
Average total loss: 0.947239
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-9.9430e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.656181
Average KL loss: 0.295726
Average total loss: 0.951907
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.3124e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.659167
Average KL loss: 0.296017
Average total loss: 0.955184
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-3.9786e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.645807
Average KL loss: 0.296173
Average total loss: 0.941980
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.3283e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.654818
Average KL loss: 0.296196
Average total loss: 0.951014
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(8.3972e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.649043
Average KL loss: 0.296221
Average total loss: 0.945264
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.2731e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.636429
Average KL loss: 0.296243
Average total loss: 0.932672
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-3.0302e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.643347
Average KL loss: 0.296266
Average total loss: 0.939613
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.2172e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.645752
Average KL loss: 0.296291
Average total loss: 0.942043
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-9.2718e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.647408
Average KL loss: 0.296321
Average total loss: 0.943729
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.5240e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.637940
Average KL loss: 0.296344
Average total loss: 0.934284
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(7.4260e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.642823
Average KL loss: 0.296366
Average total loss: 0.939189
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-8.6937e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.633495
Average KL loss: 0.296388
Average total loss: 0.929884
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.4306e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.638985
Average KL loss: 0.296410
Average total loss: 0.935395
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.7441e-10, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.633344
Average KL loss: 0.296435
Average total loss: 0.929778
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.0169e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.641449
Average KL loss: 0.296455
Average total loss: 0.937904
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.2505e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.633815
Average KL loss: 0.296476
Average total loss: 0.930291
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.2006e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.644551
Average KL loss: 0.296496
Average total loss: 0.941047
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-7.3221e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.654372
Average KL loss: 0.296519
Average total loss: 0.950890
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-8.1576e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.634312
Average KL loss: 0.296541
Average total loss: 0.930853
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.1368e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.655741
Average KL loss: 0.296558
Average total loss: 0.952300
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.1383e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.629303
Average KL loss: 0.296578
Average total loss: 0.925881
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-6.7603e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.645982
Average KL loss: 0.296602
Average total loss: 0.942583
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-9.2734e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.653180
Average KL loss: 0.296624
Average total loss: 0.949804
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-5.3430e-11, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.640138
Average KL loss: 0.296646
Average total loss: 0.936784
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.2658e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.651382
Average KL loss: 0.296667
Average total loss: 0.948049
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.2731e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.644137
Average KL loss: 0.296688
Average total loss: 0.940825
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.0343e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.642369
Average KL loss: 0.296710
Average total loss: 0.939078
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-9.3994e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.644230
Average KL loss: 0.296734
Average total loss: 0.940964
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.8041e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.645315
Average KL loss: 0.296762
Average total loss: 0.942077
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.0977e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.640889
Average KL loss: 0.296782
Average total loss: 0.937672
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.1102e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.658812
Average KL loss: 0.296807
Average total loss: 0.955619
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.3285e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.644851
Average KL loss: 0.296830
Average total loss: 0.941681
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-6.1514e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.637486
Average KL loss: 0.296843
Average total loss: 0.934330
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.3250e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.639183
Average KL loss: 0.296846
Average total loss: 0.936028
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.3159e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.641395
Average KL loss: 0.296848
Average total loss: 0.938243
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-7.4740e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.641831
Average KL loss: 0.296851
Average total loss: 0.938681
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.0827e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.635805
Average KL loss: 0.296853
Average total loss: 0.932658
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-3.5598e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.638600
Average KL loss: 0.296855
Average total loss: 0.935455
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.0406e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.647139
Average KL loss: 0.296857
Average total loss: 0.943996
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-4.8997e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.634056
Average KL loss: 0.296860
Average total loss: 0.930916
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-3.6373e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.637359
Average KL loss: 0.296862
Average total loss: 0.934221
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.4537e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.631583
Average KL loss: 0.296865
Average total loss: 0.928447
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-9.5654e-09, device='cuda:0')
 Percentile value: 0.38019925355911255
Non-zero model percentage: 0.39063358306884766%, Non-zero mask percentage: 0.39063358306884766%

--- Pruning Level [8/12]: ---
conv1.weight         | nonzeros =     102 /    1728             (  5.90%) | total_pruned =    1626 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
bn1.bias             | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      89 /   36864             (  0.24%) | total_pruned =   36775 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      15 /      64             ( 23.44%) | total_pruned =      49 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     217 /   36864             (  0.59%) | total_pruned =   36647 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     272 /   36864             (  0.74%) | total_pruned =   36592 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     570 /   36864             (  1.55%) | total_pruned =   36294 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1922 /   73728             (  2.61%) | total_pruned =   71806 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     108 /     128             ( 84.38%) | total_pruned =      20 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    3239 /  147456             (  2.20%) | total_pruned =  144217 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      99 /     128             ( 77.34%) | total_pruned =      29 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     220 /    8192             (  2.69%) | total_pruned =    7972 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      56 /     128             ( 43.75%) | total_pruned =      72 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1381 /  147456             (  0.94%) | total_pruned =  146075 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     917 /  147456             (  0.62%) | total_pruned =  146539 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    6075 /  294912             (  2.06%) | total_pruned =  288837 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    8733 /  589824             (  1.48%) | total_pruned =  581091 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     399 /   32768             (  1.22%) | total_pruned =   32369 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      95 /     256             ( 37.11%) | total_pruned =     161 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    4190 /  589824             (  0.71%) | total_pruned =  585634 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     125 /     256             ( 48.83%) | total_pruned =     131 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    2014 /  589824             (  0.34%) | total_pruned =  587810 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     104 /     256             ( 40.62%) | total_pruned =     152 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    5419 / 1179648             (  0.46%) | total_pruned = 1174229 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     310 /     512             ( 60.55%) | total_pruned =     202 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    3521 / 2359296             (  0.15%) | total_pruned = 2355775 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     116 /     512             ( 22.66%) | total_pruned =     396 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     110 /  131072             (  0.08%) | total_pruned =  130962 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      29 /     512             (  5.66%) | total_pruned =     483 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1327 / 2359296             (  0.06%) | total_pruned = 2357969 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      83 /     512             ( 16.21%) | total_pruned =     429 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     851 / 2359296             (  0.04%) | total_pruned = 2358445 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
linear.weight        | nonzeros =     118 /    5120             (  2.30%) | total_pruned =    5002 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 43668, pruned : 11135094, total: 11178762, Compression rate :     255.99x  ( 99.61% pruned)
Train Epoch: 77/100 Loss: 0.061191 Accuracy: 85.19 99.95 % Best test Accuracy: 86.29%
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.4900e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.068971
Average KL loss: 0.293912
Average total loss: 1.362883
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.5742e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.039222
Average KL loss: 0.290987
Average total loss: 1.330209
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-5.2445e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.027713
Average KL loss: 0.289321
Average total loss: 1.317034
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.6409e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.036078
Average KL loss: 0.288207
Average total loss: 1.324285
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-5.5603e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.003503
Average KL loss: 0.287433
Average total loss: 1.290935
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.0435e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.001382
Average KL loss: 0.286849
Average total loss: 1.288232
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.5232e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.982149
Average KL loss: 0.286400
Average total loss: 1.268548
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.3076e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.999361
Average KL loss: 0.286096
Average total loss: 1.285457
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-4.2996e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.979307
Average KL loss: 0.285878
Average total loss: 1.265185
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.8358e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.980209
Average KL loss: 0.285734
Average total loss: 1.265943
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.3003e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.954721
Average KL loss: 0.285634
Average total loss: 1.240355
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.2089e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.958771
Average KL loss: 0.285604
Average total loss: 1.244374
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.0320e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.929454
Average KL loss: 0.285632
Average total loss: 1.215086
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.0014e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.921912
Average KL loss: 0.285681
Average total loss: 1.207594
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.7885e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.930116
Average KL loss: 0.285747
Average total loss: 1.215863
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.1871e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.924327
Average KL loss: 0.285848
Average total loss: 1.210175
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.4501e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.913992
Average KL loss: 0.285978
Average total loss: 1.199970
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.2396e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.915009
Average KL loss: 0.286139
Average total loss: 1.201148
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.1270e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.897236
Average KL loss: 0.286308
Average total loss: 1.183544
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.5244e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.893064
Average KL loss: 0.286509
Average total loss: 1.179573
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.4178e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.894956
Average KL loss: 0.286696
Average total loss: 1.181652
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.8156e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.890399
Average KL loss: 0.286912
Average total loss: 1.177311
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.3212e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.883068
Average KL loss: 0.287160
Average total loss: 1.170229
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.7989e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.891889
Average KL loss: 0.287415
Average total loss: 1.179304
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.5679e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.875832
Average KL loss: 0.287659
Average total loss: 1.163492
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-3.1953e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.876702
Average KL loss: 0.287913
Average total loss: 1.164615
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-1.7572e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.860292
Average KL loss: 0.288194
Average total loss: 1.148486
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.2691e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.852902
Average KL loss: 0.288451
Average total loss: 1.141353
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.2572e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.855476
Average KL loss: 0.288681
Average total loss: 1.144157
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.4501e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.861804
Average KL loss: 0.288938
Average total loss: 1.150742
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.9554e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.842810
Average KL loss: 0.289216
Average total loss: 1.132026
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.2645e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.841789
Average KL loss: 0.289488
Average total loss: 1.131278
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.4805e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.843605
Average KL loss: 0.289747
Average total loss: 1.133352
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-7.5552e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.835640
Average KL loss: 0.290016
Average total loss: 1.125656
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.6741e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.823037
Average KL loss: 0.290305
Average total loss: 1.113342
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.1059e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.831080
Average KL loss: 0.290580
Average total loss: 1.121659
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.5124e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.822527
Average KL loss: 0.290881
Average total loss: 1.113408
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.5888e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.843846
Average KL loss: 0.291152
Average total loss: 1.134998
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.3455e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.817847
Average KL loss: 0.291467
Average total loss: 1.109314
tensor(0.0024, device='cuda:0') tensor(0.0043, device='cuda:0') tensor(-2.5901e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.832615
Average KL loss: 0.291798
Average total loss: 1.124412
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.2099e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.825643
Average KL loss: 0.292100
Average total loss: 1.117743
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.9647e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.804720
Average KL loss: 0.292394
Average total loss: 1.097114
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.0413e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.802115
Average KL loss: 0.292702
Average total loss: 1.094817
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.0127e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.809937
Average KL loss: 0.293027
Average total loss: 1.102963
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.5551e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.804939
Average KL loss: 0.293358
Average total loss: 1.098297
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.0585e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.794841
Average KL loss: 0.293650
Average total loss: 1.088491
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.5146e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.807922
Average KL loss: 0.293984
Average total loss: 1.101906
tensor(0.0024, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.8149e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.800148
Average KL loss: 0.294301
Average total loss: 1.094449
tensor(0.0023, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-6.2457e-09, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.794190
Average KL loss: 0.294573
Average total loss: 1.088763
tensor(0.0023, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.2182e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.788707
Average KL loss: 0.294887
Average total loss: 1.083594
tensor(0.0023, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.6519e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.799039
Average KL loss: 0.295196
Average total loss: 1.094236
tensor(0.0023, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.7074e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.782923
Average KL loss: 0.295514
Average total loss: 1.078437
tensor(0.0023, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-9.0719e-09, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.780551
Average KL loss: 0.295826
Average total loss: 1.076376
tensor(0.0023, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.6764e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.784625
Average KL loss: 0.296123
Average total loss: 1.080748
tensor(0.0023, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.4962e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.774421
Average KL loss: 0.296456
Average total loss: 1.070876
tensor(0.0023, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.3988e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.789375
Average KL loss: 0.296754
Average total loss: 1.086129
tensor(0.0023, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.0815e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.777359
Average KL loss: 0.297067
Average total loss: 1.074426
tensor(0.0023, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.8434e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.773800
Average KL loss: 0.297355
Average total loss: 1.071155
tensor(0.0023, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.8268e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.781179
Average KL loss: 0.297634
Average total loss: 1.078813
tensor(0.0023, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-2.6662e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.761240
Average KL loss: 0.297966
Average total loss: 1.059205
tensor(0.0023, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.4596e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.769362
Average KL loss: 0.298252
Average total loss: 1.067614
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.3790e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.750386
Average KL loss: 0.298595
Average total loss: 1.048981
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.8423e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.746244
Average KL loss: 0.298931
Average total loss: 1.045175
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.0185e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.753657
Average KL loss: 0.299252
Average total loss: 1.052909
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.2142e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.745623
Average KL loss: 0.299575
Average total loss: 1.045198
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.2537e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.752050
Average KL loss: 0.299841
Average total loss: 1.051891
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-8.6135e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.745623
Average KL loss: 0.300132
Average total loss: 1.045755
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.6913e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.762422
Average KL loss: 0.300464
Average total loss: 1.062886
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.5938e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.743289
Average KL loss: 0.300787
Average total loss: 1.044076
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.0429e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.747613
Average KL loss: 0.301066
Average total loss: 1.048679
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.2990e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.752561
Average KL loss: 0.301359
Average total loss: 1.053920
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.4727e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.740443
Average KL loss: 0.301650
Average total loss: 1.042093
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.5181e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.750789
Average KL loss: 0.301967
Average total loss: 1.052756
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.0217e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.746747
Average KL loss: 0.302321
Average total loss: 1.049068
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-9.8620e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.742083
Average KL loss: 0.302631
Average total loss: 1.044714
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.5225e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.755685
Average KL loss: 0.302983
Average total loss: 1.058667
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-2.2655e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.736421
Average KL loss: 0.303322
Average total loss: 1.039743
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-8.4983e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.738525
Average KL loss: 0.303650
Average total loss: 1.042174
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.6258e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.728185
Average KL loss: 0.303990
Average total loss: 1.032175
tensor(0.0023, device='cuda:0') tensor(0.0045, device='cuda:0') tensor(-1.9977e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.739236
Average KL loss: 0.304325
Average total loss: 1.043561
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.5213e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.731284
Average KL loss: 0.304635
Average total loss: 1.035919
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-2.3944e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.730533
Average KL loss: 0.304915
Average total loss: 1.035448
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-5.6196e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.738910
Average KL loss: 0.305224
Average total loss: 1.044134
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-2.8359e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.731841
Average KL loss: 0.305599
Average total loss: 1.037440
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-6.5426e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.726736
Average KL loss: 0.305931
Average total loss: 1.032667
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.0391e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.722999
Average KL loss: 0.306242
Average total loss: 1.029242
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-8.9523e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.726748
Average KL loss: 0.306547
Average total loss: 1.033295
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.7533e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.709403
Average KL loss: 0.306832
Average total loss: 1.016235
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.4478e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.712345
Average KL loss: 0.307135
Average total loss: 1.019481
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.7288e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.720959
Average KL loss: 0.307435
Average total loss: 1.028394
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.2414e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.729475
Average KL loss: 0.307726
Average total loss: 1.037200
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-2.4605e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.719352
Average KL loss: 0.308047
Average total loss: 1.027400
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.2381e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.704606
Average KL loss: 0.308333
Average total loss: 1.012939
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.4679e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.705686
Average KL loss: 0.308627
Average total loss: 1.014313
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.6159e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.708984
Average KL loss: 0.308898
Average total loss: 1.017881
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-9.2480e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.713707
Average KL loss: 0.309189
Average total loss: 1.022896
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.4177e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.705248
Average KL loss: 0.309469
Average total loss: 1.014717
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.3450e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.716545
Average KL loss: 0.309732
Average total loss: 1.026277
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-7.0950e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.735820
Average KL loss: 0.310023
Average total loss: 1.045843
tensor(0.0023, device='cuda:0') tensor(0.0046, device='cuda:0') tensor(-1.6483e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.714196
Average KL loss: 0.310307
Average total loss: 1.024503
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.6384e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.698923
Average KL loss: 0.310585
Average total loss: 1.009508
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.6064e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.703863
Average KL loss: 0.310842
Average total loss: 1.014705
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-4.8753e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.708965
Average KL loss: 0.311139
Average total loss: 1.020103
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-7.4327e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.693068
Average KL loss: 0.311448
Average total loss: 1.004515
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.1517e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.703828
Average KL loss: 0.311729
Average total loss: 1.015557
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-8.7115e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.695478
Average KL loss: 0.311972
Average total loss: 1.007450
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-5.9350e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.700429
Average KL loss: 0.312216
Average total loss: 1.012645
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-6.9985e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.700348
Average KL loss: 0.312496
Average total loss: 1.012844
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.1978e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.702591
Average KL loss: 0.312793
Average total loss: 1.015384
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.4558e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.701678
Average KL loss: 0.313103
Average total loss: 1.014781
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.8485e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.705037
Average KL loss: 0.313372
Average total loss: 1.018410
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.9303e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.699485
Average KL loss: 0.313629
Average total loss: 1.013115
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-9.6116e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.683714
Average KL loss: 0.313901
Average total loss: 0.997615
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-9.6627e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.689226
Average KL loss: 0.314152
Average total loss: 1.003379
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-6.3606e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.697554
Average KL loss: 0.314409
Average total loss: 1.011963
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.4086e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.689559
Average KL loss: 0.314646
Average total loss: 1.004206
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.4093e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.686480
Average KL loss: 0.314893
Average total loss: 1.001373
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-6.9526e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.676613
Average KL loss: 0.315122
Average total loss: 0.991735
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.4894e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.683731
Average KL loss: 0.315330
Average total loss: 0.999061
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.0897e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.676234
Average KL loss: 0.315591
Average total loss: 0.991826
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.3401e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.684666
Average KL loss: 0.315866
Average total loss: 1.000532
tensor(0.0023, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.4163e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.686129
Average KL loss: 0.316126
Average total loss: 1.002255
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.0930e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.683965
Average KL loss: 0.316392
Average total loss: 1.000357
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.5286e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.683711
Average KL loss: 0.316621
Average total loss: 1.000331
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-9.0241e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.677490
Average KL loss: 0.316863
Average total loss: 0.994353
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.4082e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.670431
Average KL loss: 0.317068
Average total loss: 0.987499
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.5657e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.670133
Average KL loss: 0.317304
Average total loss: 0.987437
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.1205e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.674024
Average KL loss: 0.317547
Average total loss: 0.991571
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.5329e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.673521
Average KL loss: 0.317765
Average total loss: 0.991286
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-7.7461e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.681057
Average KL loss: 0.317995
Average total loss: 0.999051
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-8.4890e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.670612
Average KL loss: 0.318216
Average total loss: 0.988829
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.2373e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.680446
Average KL loss: 0.318404
Average total loss: 0.998850
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(3.1581e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.661704
Average KL loss: 0.318619
Average total loss: 0.980322
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.6261e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.670667
Average KL loss: 0.318817
Average total loss: 0.989485
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.1243e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.668247
Average KL loss: 0.319054
Average total loss: 0.987301
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.0166e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.671889
Average KL loss: 0.319237
Average total loss: 0.991127
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-9.3691e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.668799
Average KL loss: 0.319423
Average total loss: 0.988222
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.2404e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.668346
Average KL loss: 0.319655
Average total loss: 0.988001
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-5.3497e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.672387
Average KL loss: 0.319878
Average total loss: 0.992265
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.1468e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.675886
Average KL loss: 0.320073
Average total loss: 0.995959
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-7.6226e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.665674
Average KL loss: 0.320270
Average total loss: 0.985944
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(1.4222e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.656504
Average KL loss: 0.320482
Average total loss: 0.976985
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-5.4706e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.663463
Average KL loss: 0.320718
Average total loss: 0.984180
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-6.1017e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.650948
Average KL loss: 0.320921
Average total loss: 0.971869
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.0446e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.658877
Average KL loss: 0.321149
Average total loss: 0.980026
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.6411e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.654330
Average KL loss: 0.321351
Average total loss: 0.975681
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.3588e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.674569
Average KL loss: 0.321585
Average total loss: 0.996155
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-4.1948e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.654901
Average KL loss: 0.321827
Average total loss: 0.976728
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-5.9563e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.647176
Average KL loss: 0.322025
Average total loss: 0.969201
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.3905e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.650792
Average KL loss: 0.322209
Average total loss: 0.973001
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-6.2404e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.659192
Average KL loss: 0.322392
Average total loss: 0.981585
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-6.7202e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.652485
Average KL loss: 0.322540
Average total loss: 0.975025
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.9958e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.654332
Average KL loss: 0.322701
Average total loss: 0.977033
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-3.7745e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.649967
Average KL loss: 0.322923
Average total loss: 0.972889
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.7834e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.660345
Average KL loss: 0.323133
Average total loss: 0.983478
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-9.1094e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.674239
Average KL loss: 0.323359
Average total loss: 0.997597
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-3.3383e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.655160
Average KL loss: 0.323603
Average total loss: 0.978762
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.1272e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.651928
Average KL loss: 0.323789
Average total loss: 0.975718
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-5.0234e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.660495
Average KL loss: 0.323986
Average total loss: 0.984481
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-7.4515e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.660628
Average KL loss: 0.324208
Average total loss: 0.984836
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.0576e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.641969
Average KL loss: 0.324326
Average total loss: 0.966295
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-5.3990e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.640975
Average KL loss: 0.324342
Average total loss: 0.965317
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.4185e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.645683
Average KL loss: 0.324357
Average total loss: 0.970041
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.0691e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.641780
Average KL loss: 0.324375
Average total loss: 0.966154
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.5599e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.653459
Average KL loss: 0.324391
Average total loss: 0.977850
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-5.1636e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.643067
Average KL loss: 0.324410
Average total loss: 0.967477
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-8.5457e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.654230
Average KL loss: 0.324423
Average total loss: 0.978653
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.2418e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.654596
Average KL loss: 0.324439
Average total loss: 0.979035
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-6.0039e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.652574
Average KL loss: 0.324454
Average total loss: 0.977028
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.8841e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.648298
Average KL loss: 0.324469
Average total loss: 0.972767
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.6295e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.651700
Average KL loss: 0.324484
Average total loss: 0.976184
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-9.3621e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.658842
Average KL loss: 0.324499
Average total loss: 0.983341
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.2012e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.665930
Average KL loss: 0.324515
Average total loss: 0.990444
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-8.4331e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.650715
Average KL loss: 0.324525
Average total loss: 0.975240
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-4.2114e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.646430
Average KL loss: 0.324527
Average total loss: 0.970957
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.2028e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.643914
Average KL loss: 0.324529
Average total loss: 0.968443
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.3110e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.661481
Average KL loss: 0.324531
Average total loss: 0.986012
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.8265e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.647988
Average KL loss: 0.324533
Average total loss: 0.972521
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.0153e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.653839
Average KL loss: 0.324535
Average total loss: 0.978374
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.0691e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.638554
Average KL loss: 0.324537
Average total loss: 0.963091
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.5869e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.644868
Average KL loss: 0.324538
Average total loss: 0.969406
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.1400e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.640604
Average KL loss: 0.324540
Average total loss: 0.965143
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-5.5532e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.646615
Average KL loss: 0.324542
Average total loss: 0.971156
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-4.1488e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.656843
Average KL loss: 0.324543
Average total loss: 0.981386
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.1595e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.662689
Average KL loss: 0.324545
Average total loss: 0.987234
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.2322e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.649921
Average KL loss: 0.324546
Average total loss: 0.974468
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-4.7855e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.645082
Average KL loss: 0.324548
Average total loss: 0.969630
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.6382e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.640689
Average KL loss: 0.324550
Average total loss: 0.965239
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.2564e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.648918
Average KL loss: 0.324552
Average total loss: 0.973470
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.4254e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.645984
Average KL loss: 0.324554
Average total loss: 0.970538
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-8.0631e-09, device='cuda:0')
 Percentile value: 0.787716805934906
Non-zero model percentage: 0.19531679153442383%, Non-zero mask percentage: 0.19531679153442383%

--- Pruning Level [9/12]: ---
conv1.weight         | nonzeros =      97 /    1728             (  5.61%) | total_pruned =    1631 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
bn1.bias             | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      75 /   36864             (  0.20%) | total_pruned =   36789 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     166 /   36864             (  0.45%) | total_pruned =   36698 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     181 /   36864             (  0.49%) | total_pruned =   36683 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     375 /   36864             (  1.02%) | total_pruned =   36489 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1195 /   73728             (  1.62%) | total_pruned =   72533 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     105 /     128             ( 82.03%) | total_pruned =      23 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1877 /  147456             (  1.27%) | total_pruned =  145579 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      98 /     128             ( 76.56%) | total_pruned =      30 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     140 /    8192             (  1.71%) | total_pruned =    8052 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      46 /     128             ( 35.94%) | total_pruned =      82 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     788 /  147456             (  0.53%) | total_pruned =  146668 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     571 /  147456             (  0.39%) | total_pruned =  146885 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      54 /     128             ( 42.19%) | total_pruned =      74 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    3080 /  294912             (  1.04%) | total_pruned =  291832 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     239 /     256             ( 93.36%) | total_pruned =      17 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    4230 /  589824             (  0.72%) | total_pruned =  585594 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     209 /     256             ( 81.64%) | total_pruned =      47 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     178 /   32768             (  0.54%) | total_pruned =   32590 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      65 /     256             ( 25.39%) | total_pruned =     191 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    2115 /  589824             (  0.36%) | total_pruned =  587709 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     123 /     256             ( 48.05%) | total_pruned =     133 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1073 /  589824             (  0.18%) | total_pruned =  588751 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      85 /     256             ( 33.20%) | total_pruned =     171 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    1742 / 1179648             (  0.15%) | total_pruned = 1177906 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     255 /     512             ( 49.80%) | total_pruned =     257 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      10 /     512             (  1.95%) | total_pruned =     502 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1219 / 2359296             (  0.05%) | total_pruned = 2358077 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      93 /     512             ( 18.16%) | total_pruned =     419 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      11 /     512             (  2.15%) | total_pruned =     501 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      39 /  131072             (  0.03%) | total_pruned =  131033 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     551 / 2359296             (  0.02%) | total_pruned = 2358745 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      69 /     512             ( 13.48%) | total_pruned =     443 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     333 / 2359296             (  0.01%) | total_pruned = 2358963 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      20 /     512             (  3.91%) | total_pruned =     492 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
linear.weight        | nonzeros =      64 /    5120             (  1.25%) | total_pruned =    5056 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 21834, pruned : 11156928, total: 11178762, Compression rate :     511.99x  ( 99.80% pruned)
Train Epoch: 99/100 Loss: 0.145580 Accuracy: 82.23 98.42 % Best test Accuracy: 84.69%
tensor(0.0023, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.3653e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.094125
Average KL loss: 0.321197
Average total loss: 1.415322
tensor(0.0023, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.0139e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.083090
Average KL loss: 0.316869
Average total loss: 1.399959
tensor(0.0022, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.7633e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.074821
Average KL loss: 0.313810
Average total loss: 1.388631
tensor(0.0022, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-5.0339e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.102833
Average KL loss: 0.311505
Average total loss: 1.414339
tensor(0.0022, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-4.6012e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.062309
Average KL loss: 0.309698
Average total loss: 1.372007
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.4295e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.085357
Average KL loss: 0.308231
Average total loss: 1.393587
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-4.0615e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.065111
Average KL loss: 0.307059
Average total loss: 1.372171
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.3036e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.058564
Average KL loss: 0.306083
Average total loss: 1.364648
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.9570e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.036255
Average KL loss: 0.305258
Average total loss: 1.341513
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.0030e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.056137
Average KL loss: 0.304545
Average total loss: 1.360683
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.3835e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 1.029547
Average KL loss: 0.303943
Average total loss: 1.333489
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.7553e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.016831
Average KL loss: 0.303408
Average total loss: 1.320239
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.5052e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 1.021527
Average KL loss: 0.302944
Average total loss: 1.324472
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.9215e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 1.017627
Average KL loss: 0.302549
Average total loss: 1.320176
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.6827e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.013387
Average KL loss: 0.302183
Average total loss: 1.315569
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.0698e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.985178
Average KL loss: 0.301853
Average total loss: 1.287030
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-4.9776e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.999308
Average KL loss: 0.301558
Average total loss: 1.300865
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.6544e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.986587
Average KL loss: 0.301299
Average total loss: 1.287886
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.0015e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.993899
Average KL loss: 0.301059
Average total loss: 1.294959
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.8875e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.973880
Average KL loss: 0.300874
Average total loss: 1.274753
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.3622e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.989096
Average KL loss: 0.300672
Average total loss: 1.289768
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.4140e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.974008
Average KL loss: 0.300503
Average total loss: 1.274511
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.9184e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.966286
Average KL loss: 0.300370
Average total loss: 1.266655
tensor(0.0022, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.5487e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.971992
Average KL loss: 0.300250
Average total loss: 1.272242
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.1436e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.974022
Average KL loss: 0.300144
Average total loss: 1.274166
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.8488e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.948868
Average KL loss: 0.300041
Average total loss: 1.248909
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-4.3150e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.932071
Average KL loss: 0.299959
Average total loss: 1.232030
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.7321e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.938493
Average KL loss: 0.299903
Average total loss: 1.238396
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.5968e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.920797
Average KL loss: 0.299837
Average total loss: 1.220634
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-7.0597e-09, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.930783
Average KL loss: 0.299819
Average total loss: 1.230602
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.6260e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.939174
Average KL loss: 0.299817
Average total loss: 1.238992
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.9749e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.943781
Average KL loss: 0.299800
Average total loss: 1.243581
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.5715e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.917356
Average KL loss: 0.299803
Average total loss: 1.217159
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-7.9109e-09, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.941250
Average KL loss: 0.299790
Average total loss: 1.241040
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.8795e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.934342
Average KL loss: 0.299793
Average total loss: 1.234135
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.6345e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.924141
Average KL loss: 0.299820
Average total loss: 1.223962
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.8429e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.906914
Average KL loss: 0.299865
Average total loss: 1.206778
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.1453e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.913649
Average KL loss: 0.299897
Average total loss: 1.213546
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.4578e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.908212
Average KL loss: 0.299951
Average total loss: 1.208163
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.2631e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.905180
Average KL loss: 0.299992
Average total loss: 1.205172
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.5961e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.890605
Average KL loss: 0.300039
Average total loss: 1.190644
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-5.6538e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.896171
Average KL loss: 0.300121
Average total loss: 1.196291
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-4.2751e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.891572
Average KL loss: 0.300197
Average total loss: 1.191768
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.2584e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.898843
Average KL loss: 0.300296
Average total loss: 1.199139
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.2115e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.900629
Average KL loss: 0.300412
Average total loss: 1.201041
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.8706e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.891988
Average KL loss: 0.300527
Average total loss: 1.192516
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.9404e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.887358
Average KL loss: 0.300657
Average total loss: 1.188015
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.7057e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.867012
Average KL loss: 0.300752
Average total loss: 1.167765
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.0190e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.887559
Average KL loss: 0.300870
Average total loss: 1.188429
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-2.6842e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.883689
Average KL loss: 0.301023
Average total loss: 1.184711
tensor(0.0021, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-3.1450e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.865834
Average KL loss: 0.301170
Average total loss: 1.167004
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.8488e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.875163
Average KL loss: 0.301316
Average total loss: 1.176479
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.4645e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.863355
Average KL loss: 0.301485
Average total loss: 1.164840
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.7088e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.895846
Average KL loss: 0.301651
Average total loss: 1.197497
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.0451e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.857337
Average KL loss: 0.301793
Average total loss: 1.159130
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.4362e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.872806
Average KL loss: 0.301951
Average total loss: 1.174757
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.3641e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.874367
Average KL loss: 0.302134
Average total loss: 1.176501
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.5550e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.848925
Average KL loss: 0.302341
Average total loss: 1.151266
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.6011e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.839310
Average KL loss: 0.302503
Average total loss: 1.141812
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.3319e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.853744
Average KL loss: 0.302642
Average total loss: 1.156387
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.9737e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.858112
Average KL loss: 0.302810
Average total loss: 1.160922
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-7.1574e-09, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.847880
Average KL loss: 0.303017
Average total loss: 1.150896
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.4137e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.840639
Average KL loss: 0.303213
Average total loss: 1.143852
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.4501e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.846857
Average KL loss: 0.303409
Average total loss: 1.150266
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.5878e-10, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.841417
Average KL loss: 0.303609
Average total loss: 1.145026
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.3024e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.850109
Average KL loss: 0.303822
Average total loss: 1.153931
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.3807e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.833728
Average KL loss: 0.304053
Average total loss: 1.137780
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.8342e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.843800
Average KL loss: 0.304302
Average total loss: 1.148102
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-8.2569e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.844107
Average KL loss: 0.304529
Average total loss: 1.148637
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.1796e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.835397
Average KL loss: 0.304740
Average total loss: 1.140138
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.3097e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.826726
Average KL loss: 0.304959
Average total loss: 1.131686
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-4.5193e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.843431
Average KL loss: 0.305191
Average total loss: 1.148622
tensor(0.0021, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-6.9157e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.829135
Average KL loss: 0.305400
Average total loss: 1.134535
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.5230e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.826792
Average KL loss: 0.305599
Average total loss: 1.132391
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.2870e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.822793
Average KL loss: 0.305796
Average total loss: 1.128590
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.8462e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.835184
Average KL loss: 0.306027
Average total loss: 1.141210
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.3135e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.821609
Average KL loss: 0.306248
Average total loss: 1.127858
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.9144e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.827271
Average KL loss: 0.306467
Average total loss: 1.133738
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-5.7823e-09, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.834573
Average KL loss: 0.306689
Average total loss: 1.141262
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.6210e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.812905
Average KL loss: 0.306907
Average total loss: 1.119811
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.9149e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.816371
Average KL loss: 0.307095
Average total loss: 1.123466
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.6051e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.811138
Average KL loss: 0.307310
Average total loss: 1.118448
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.6785e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.797747
Average KL loss: 0.307524
Average total loss: 1.105271
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-8.5620e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.811619
Average KL loss: 0.307747
Average total loss: 1.119366
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-6.6584e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.793707
Average KL loss: 0.307978
Average total loss: 1.101686
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.4360e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.802583
Average KL loss: 0.308181
Average total loss: 1.110765
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.2327e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.809886
Average KL loss: 0.308369
Average total loss: 1.118255
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.3926e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.813637
Average KL loss: 0.308587
Average total loss: 1.122224
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.1741e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.789414
Average KL loss: 0.308816
Average total loss: 1.098230
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.9068e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.794432
Average KL loss: 0.309036
Average total loss: 1.103468
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.1130e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.794603
Average KL loss: 0.309267
Average total loss: 1.103870
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-8.3535e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.810937
Average KL loss: 0.309482
Average total loss: 1.120419
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-9.5900e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.789570
Average KL loss: 0.309699
Average total loss: 1.099269
tensor(0.0021, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.9681e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.786478
Average KL loss: 0.309932
Average total loss: 1.096409
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.6697e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.784885
Average KL loss: 0.310167
Average total loss: 1.095052
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.5820e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.798716
Average KL loss: 0.310397
Average total loss: 1.109114
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-9.2929e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.796199
Average KL loss: 0.310619
Average total loss: 1.106818
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.6435e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.796192
Average KL loss: 0.310850
Average total loss: 1.107043
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-6.4492e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.800597
Average KL loss: 0.311080
Average total loss: 1.111677
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.2657e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.805917
Average KL loss: 0.311281
Average total loss: 1.117197
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-8.2585e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.792678
Average KL loss: 0.311495
Average total loss: 1.104173
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.7833e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.796287
Average KL loss: 0.311740
Average total loss: 1.108027
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.2333e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.778664
Average KL loss: 0.312007
Average total loss: 1.090671
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-8.2275e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.788928
Average KL loss: 0.312225
Average total loss: 1.101153
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.6925e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.781005
Average KL loss: 0.312429
Average total loss: 1.093434
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.2860e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.776799
Average KL loss: 0.312650
Average total loss: 1.089449
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.0462e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.789933
Average KL loss: 0.312893
Average total loss: 1.102826
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.2049e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.764478
Average KL loss: 0.313111
Average total loss: 1.077590
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.3257e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.764215
Average KL loss: 0.313350
Average total loss: 1.077565
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.1677e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.776204
Average KL loss: 0.313576
Average total loss: 1.089781
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.6048e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.774326
Average KL loss: 0.313782
Average total loss: 1.088108
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-7.1850e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.768022
Average KL loss: 0.313986
Average total loss: 1.082008
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.1019e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.770262
Average KL loss: 0.314212
Average total loss: 1.084474
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.3812e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.761652
Average KL loss: 0.314422
Average total loss: 1.076074
tensor(0.0021, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.4346e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.760654
Average KL loss: 0.314630
Average total loss: 1.075284
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-9.1627e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.760058
Average KL loss: 0.314837
Average total loss: 1.074895
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.3974e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.766924
Average KL loss: 0.315091
Average total loss: 1.082015
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-7.1662e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.753605
Average KL loss: 0.315330
Average total loss: 1.068935
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-8.5011e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.761987
Average KL loss: 0.315560
Average total loss: 1.077547
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.1724e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.759926
Average KL loss: 0.315771
Average total loss: 1.075698
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.3862e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.751632
Average KL loss: 0.315960
Average total loss: 1.067592
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-3.5244e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.757849
Average KL loss: 0.316148
Average total loss: 1.073997
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.6487e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.779088
Average KL loss: 0.316370
Average total loss: 1.095458
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-3.5290e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.752448
Average KL loss: 0.316582
Average total loss: 1.069030
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.0474e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.751322
Average KL loss: 0.316806
Average total loss: 1.068128
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-2.2482e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.759603
Average KL loss: 0.317020
Average total loss: 1.076624
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.9325e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.749094
Average KL loss: 0.317227
Average total loss: 1.066321
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.2487e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.758225
Average KL loss: 0.317451
Average total loss: 1.075675
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-2.1972e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.750356
Average KL loss: 0.317673
Average total loss: 1.068029
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-6.3432e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.752118
Average KL loss: 0.317906
Average total loss: 1.070025
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.8514e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.747868
Average KL loss: 0.318117
Average total loss: 1.065985
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.4890e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.753520
Average KL loss: 0.318302
Average total loss: 1.071822
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.0233e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.745950
Average KL loss: 0.318502
Average total loss: 1.064452
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.1226e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.761364
Average KL loss: 0.318707
Average total loss: 1.080071
tensor(0.0021, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.5537e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.769112
Average KL loss: 0.318911
Average total loss: 1.088023
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-7.1677e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.734678
Average KL loss: 0.319136
Average total loss: 1.053815
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.1397e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.740119
Average KL loss: 0.319348
Average total loss: 1.059467
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.2974e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.745427
Average KL loss: 0.319569
Average total loss: 1.064996
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.5710e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.738196
Average KL loss: 0.319783
Average total loss: 1.057979
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.5092e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.752852
Average KL loss: 0.319970
Average total loss: 1.072823
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1355e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.734635
Average KL loss: 0.320193
Average total loss: 1.054827
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1871e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.738200
Average KL loss: 0.320396
Average total loss: 1.058596
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.5307e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.728723
Average KL loss: 0.320599
Average total loss: 1.049322
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.5889e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.724073
Average KL loss: 0.320797
Average total loss: 1.044870
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.9899e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.741825
Average KL loss: 0.320995
Average total loss: 1.062820
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.5805e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.725763
Average KL loss: 0.321184
Average total loss: 1.046947
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.5134e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.741674
Average KL loss: 0.321355
Average total loss: 1.063029
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(2.3708e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.739572
Average KL loss: 0.321545
Average total loss: 1.061118
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.2957e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.717240
Average KL loss: 0.321734
Average total loss: 1.038974
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.6121e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.734579
Average KL loss: 0.321931
Average total loss: 1.056510
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.4106e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.731539
Average KL loss: 0.322128
Average total loss: 1.053667
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.8946e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.722436
Average KL loss: 0.322337
Average total loss: 1.044773
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.9996e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.713289
Average KL loss: 0.322546
Average total loss: 1.035835
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.2623e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.726778
Average KL loss: 0.322735
Average total loss: 1.049514
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0464e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.724652
Average KL loss: 0.322936
Average total loss: 1.047588
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.3426e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.726038
Average KL loss: 0.323128
Average total loss: 1.049166
tensor(0.0021, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.1707e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.711334
Average KL loss: 0.323302
Average total loss: 1.034635
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-9.5211e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.727245
Average KL loss: 0.323482
Average total loss: 1.050727
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.7624e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.716026
Average KL loss: 0.323663
Average total loss: 1.039689
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.8952e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.733367
Average KL loss: 0.323874
Average total loss: 1.057241
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.1695e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.717048
Average KL loss: 0.324090
Average total loss: 1.041138
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.3516e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.720167
Average KL loss: 0.324271
Average total loss: 1.044437
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.7054e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.725016
Average KL loss: 0.324463
Average total loss: 1.049479
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.6542e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.709541
Average KL loss: 0.324671
Average total loss: 1.034212
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-6.9424e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.701971
Average KL loss: 0.324878
Average total loss: 1.026849
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.7611e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.704697
Average KL loss: 0.325086
Average total loss: 1.029783
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.5424e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.711119
Average KL loss: 0.325277
Average total loss: 1.036396
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.4631e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.698522
Average KL loss: 0.325435
Average total loss: 1.023957
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.1248e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.701603
Average KL loss: 0.325612
Average total loss: 1.027215
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.9978e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.714832
Average KL loss: 0.325781
Average total loss: 1.040613
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.2500e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.708638
Average KL loss: 0.325964
Average total loss: 1.034602
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.5027e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.712050
Average KL loss: 0.326136
Average total loss: 1.038186
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-6.6907e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.720314
Average KL loss: 0.326307
Average total loss: 1.046621
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-7.8060e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.716234
Average KL loss: 0.326490
Average total loss: 1.042724
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.3863e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.720475
Average KL loss: 0.326699
Average total loss: 1.047174
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.8232e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.701264
Average KL loss: 0.326882
Average total loss: 1.028146
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-5.5640e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.708622
Average KL loss: 0.327042
Average total loss: 1.035664
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-1.2112e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.696522
Average KL loss: 0.327218
Average total loss: 1.023740
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-6.4772e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.708278
Average KL loss: 0.327400
Average total loss: 1.035678
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.9331e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.695488
Average KL loss: 0.327582
Average total loss: 1.023070
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.5772e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.702977
Average KL loss: 0.327769
Average total loss: 1.030746
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.2167e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.707911
Average KL loss: 0.327946
Average total loss: 1.035857
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.2239e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.709228
Average KL loss: 0.328101
Average total loss: 1.037328
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-7.7213e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.701081
Average KL loss: 0.328273
Average total loss: 1.029354
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(2.1043e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.705268
Average KL loss: 0.328449
Average total loss: 1.033717
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.2352e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.695752
Average KL loss: 0.328624
Average total loss: 1.024376
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.3524e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.706701
Average KL loss: 0.328780
Average total loss: 1.035481
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-3.1455e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.695869
Average KL loss: 0.328936
Average total loss: 1.024804
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.2440e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.699987
Average KL loss: 0.329102
Average total loss: 1.029089
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-6.9942e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.693858
Average KL loss: 0.329258
Average total loss: 1.023116
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.1768e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.699067
Average KL loss: 0.329401
Average total loss: 1.028468
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.4956e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.679677
Average KL loss: 0.329487
Average total loss: 1.009164
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.5423e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.691573
Average KL loss: 0.329503
Average total loss: 1.021077
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-9.9649e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.698088
Average KL loss: 0.329520
Average total loss: 1.027608
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-8.8528e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.702900
Average KL loss: 0.329536
Average total loss: 1.032435
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.3079e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.696741
Average KL loss: 0.329551
Average total loss: 1.026292
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-2.1451e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.696438
Average KL loss: 0.329567
Average total loss: 1.026006
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.6878e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.694500
Average KL loss: 0.329582
Average total loss: 1.024082
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.1012e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.689603
Average KL loss: 0.329600
Average total loss: 1.019203
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.1272e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.697403
Average KL loss: 0.329617
Average total loss: 1.027020
 Percentile value: 1.5132602453231812
Non-zero model percentage: 0.09765839576721191%, Non-zero mask percentage: 0.09765839576721191%

--- Pruning Level [10/12]: ---
conv1.weight         | nonzeros =      93 /    1728             (  5.38%) | total_pruned =    1635 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
bn1.bias             | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      59 /   36864             (  0.16%) | total_pruned =   36805 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     124 /   36864             (  0.34%) | total_pruned =   36740 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     133 /   36864             (  0.36%) | total_pruned =   36731 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     265 /   36864             (  0.72%) | total_pruned =   36599 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      35 /      64             ( 54.69%) | total_pruned =      29 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     699 /   73728             (  0.95%) | total_pruned =   73029 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     985 /  147456             (  0.67%) | total_pruned =  146471 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      79 /    8192             (  0.96%) | total_pruned =    8113 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      38 /     128             ( 29.69%) | total_pruned =      90 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     435 /  147456             (  0.30%) | total_pruned =  147021 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      57 /     128             ( 44.53%) | total_pruned =      71 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     353 /  147456             (  0.24%) | total_pruned =  147103 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      49 /     128             ( 38.28%) | total_pruned =      79 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1406 /  294912             (  0.48%) | total_pruned =  293506 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     231 /     256             ( 90.23%) | total_pruned =      25 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1778 /  589824             (  0.30%) | total_pruned =  588046 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     189 /     256             ( 73.83%) | total_pruned =      67 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      80 /   32768             (  0.24%) | total_pruned =   32688 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     975 /  589824             (  0.17%) | total_pruned =  588849 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     115 /     256             ( 44.92%) | total_pruned =     141 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     516 /  589824             (  0.09%) | total_pruned =  589308 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      59 /     256             ( 23.05%) | total_pruned =     197 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     610 / 1179648             (  0.05%) | total_pruned = 1179038 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     173 /     512             ( 33.79%) | total_pruned =     339 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     451 / 2359296             (  0.02%) | total_pruned = 2358845 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      70 /     512             ( 13.67%) | total_pruned =     442 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      17 /  131072             (  0.01%) | total_pruned =  131055 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     211 / 2359296             (  0.01%) | total_pruned = 2359085 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      44 /     512             (  8.59%) | total_pruned =     468 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     141 / 2359296             (  0.01%) | total_pruned = 2359155 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      14 /     512             (  2.73%) | total_pruned =     498 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
linear.weight        | nonzeros =      51 /    5120             (  1.00%) | total_pruned =    5069 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 10917, pruned : 11167845, total: 11178762, Compression rate :    1023.98x  ( 99.90% pruned)
Train Epoch: 99/100 Loss: 0.339881 Accuracy: 79.37 88.73 % Best test Accuracy: 80.66%
tensor(0.0021, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-3.2035e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 1.043710
Average KL loss: 0.326402
Average total loss: 1.370112
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-2.9592e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 1.035454
Average KL loss: 0.321415
Average total loss: 1.356869
tensor(0.0021, device='cuda:0') tensor(0.0053, device='cuda:0') tensor(-3.2670e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 1.059270
Average KL loss: 0.317192
Average total loss: 1.376461
tensor(0.0020, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.5050e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 1.025837
Average KL loss: 0.313484
Average total loss: 1.339321
tensor(0.0020, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.9202e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 1.013234
Average KL loss: 0.310205
Average total loss: 1.323439
tensor(0.0020, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-8.9383e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 1.028405
Average KL loss: 0.307260
Average total loss: 1.335665
tensor(0.0020, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-2.7867e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 1.023580
Average KL loss: 0.304644
Average total loss: 1.328225
tensor(0.0020, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.7633e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 1.007680
Average KL loss: 0.302335
Average total loss: 1.310015
tensor(0.0019, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.6199e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 1.021780
Average KL loss: 0.300254
Average total loss: 1.322034
tensor(0.0019, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.6527e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 1.012438
Average KL loss: 0.298367
Average total loss: 1.310805
tensor(0.0019, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.5136e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.996741
Average KL loss: 0.296678
Average total loss: 1.293419
tensor(0.0019, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.4752e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 1.009510
Average KL loss: 0.295132
Average total loss: 1.304642
tensor(0.0019, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-4.2799e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.997919
Average KL loss: 0.293746
Average total loss: 1.291664
tensor(0.0019, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.1294e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.977314
Average KL loss: 0.292457
Average total loss: 1.269771
tensor(0.0019, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.0044e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 1.006249
Average KL loss: 0.291259
Average total loss: 1.297508
tensor(0.0018, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.0341e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.993608
Average KL loss: 0.290168
Average total loss: 1.283776
tensor(0.0018, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.8754e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 1.006858
Average KL loss: 0.289140
Average total loss: 1.295998
tensor(0.0018, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-4.6436e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.983875
Average KL loss: 0.288187
Average total loss: 1.272062
tensor(0.0018, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-3.0030e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.952447
Average KL loss: 0.287286
Average total loss: 1.239733
tensor(0.0018, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.9326e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.981582
Average KL loss: 0.286441
Average total loss: 1.268023
tensor(0.0018, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.3210e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.950700
Average KL loss: 0.285652
Average total loss: 1.236352
tensor(0.0018, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-3.3290e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.972145
Average KL loss: 0.284902
Average total loss: 1.257048
tensor(0.0018, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.3830e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.964276
Average KL loss: 0.284179
Average total loss: 1.248455
tensor(0.0018, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.2093e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.945684
Average KL loss: 0.283493
Average total loss: 1.229177
tensor(0.0018, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.9791e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.961202
Average KL loss: 0.282856
Average total loss: 1.244058
tensor(0.0018, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.3035e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.956567
Average KL loss: 0.282245
Average total loss: 1.238812
tensor(0.0018, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.2450e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.959252
Average KL loss: 0.281670
Average total loss: 1.240923
tensor(0.0018, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.4276e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.937840
Average KL loss: 0.281105
Average total loss: 1.218945
tensor(0.0018, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.7448e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.959888
Average KL loss: 0.280554
Average total loss: 1.240441
tensor(0.0018, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.5379e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.934561
Average KL loss: 0.280017
Average total loss: 1.214577
tensor(0.0018, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.9592e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.916921
Average KL loss: 0.279501
Average total loss: 1.196422
tensor(0.0018, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.3799e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.933399
Average KL loss: 0.279000
Average total loss: 1.212399
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.4170e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.929253
Average KL loss: 0.278526
Average total loss: 1.207780
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.8532e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.946371
Average KL loss: 0.278077
Average total loss: 1.224448
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.3232e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.946033
Average KL loss: 0.277655
Average total loss: 1.223687
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.9211e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.928619
Average KL loss: 0.277243
Average total loss: 1.205862
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.3596e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.938766
Average KL loss: 0.276836
Average total loss: 1.215602
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.3516e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.912311
Average KL loss: 0.276457
Average total loss: 1.188769
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.4297e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.922572
Average KL loss: 0.276106
Average total loss: 1.198678
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.8210e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.906124
Average KL loss: 0.275773
Average total loss: 1.181897
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.5165e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.912984
Average KL loss: 0.275455
Average total loss: 1.188439
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.4167e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.910242
Average KL loss: 0.275143
Average total loss: 1.185385
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.2861e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.913378
Average KL loss: 0.274844
Average total loss: 1.188222
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.9451e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.903435
Average KL loss: 0.274550
Average total loss: 1.177985
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.2471e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.899187
Average KL loss: 0.274299
Average total loss: 1.173486
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.5839e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.903575
Average KL loss: 0.274058
Average total loss: 1.177633
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.3103e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.907678
Average KL loss: 0.273807
Average total loss: 1.181485
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.3138e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.898810
Average KL loss: 0.273602
Average total loss: 1.172411
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.8323e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.907240
Average KL loss: 0.273413
Average total loss: 1.180653
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.3467e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.903195
Average KL loss: 0.273227
Average total loss: 1.176423
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.5580e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.896645
Average KL loss: 0.273051
Average total loss: 1.169696
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.1128e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.877899
Average KL loss: 0.272902
Average total loss: 1.150801
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.4148e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.892411
Average KL loss: 0.272747
Average total loss: 1.165158
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.5079e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.891694
Average KL loss: 0.272605
Average total loss: 1.164298
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.7783e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.887659
Average KL loss: 0.272489
Average total loss: 1.160148
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.0577e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.883192
Average KL loss: 0.272399
Average total loss: 1.155592
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.5138e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.878135
Average KL loss: 0.272302
Average total loss: 1.150436
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.5839e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.873833
Average KL loss: 0.272210
Average total loss: 1.146043
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.3521e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.879767
Average KL loss: 0.272140
Average total loss: 1.151907
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.6103e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.870711
Average KL loss: 0.272070
Average total loss: 1.142780
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.2793e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.875734
Average KL loss: 0.272011
Average total loss: 1.147745
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.0800e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.881744
Average KL loss: 0.271968
Average total loss: 1.153712
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.4197e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.880895
Average KL loss: 0.271930
Average total loss: 1.152825
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.8596e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.877485
Average KL loss: 0.271912
Average total loss: 1.149397
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.6813e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.863820
Average KL loss: 0.271885
Average total loss: 1.135705
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.7273e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.893633
Average KL loss: 0.271878
Average total loss: 1.165511
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.7977e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.870986
Average KL loss: 0.271888
Average total loss: 1.142875
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-9.9900e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.870624
Average KL loss: 0.271888
Average total loss: 1.142512
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.0695e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.857921
Average KL loss: 0.271907
Average total loss: 1.129828
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.0237e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.843731
Average KL loss: 0.271926
Average total loss: 1.115657
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.4150e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.857493
Average KL loss: 0.271961
Average total loss: 1.129454
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-1.9865e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.853730
Average KL loss: 0.272008
Average total loss: 1.125738
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-2.0394e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.840608
Average KL loss: 0.272045
Average total loss: 1.112653
tensor(0.0017, device='cuda:0') tensor(0.0048, device='cuda:0') tensor(-3.4761e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.864699
Average KL loss: 0.272086
Average total loss: 1.136784
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-3.0109e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.852621
Average KL loss: 0.272156
Average total loss: 1.124778
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.3436e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.864597
Average KL loss: 0.272214
Average total loss: 1.136812
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.6080e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.838626
Average KL loss: 0.272271
Average total loss: 1.110896
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.3722e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.846001
Average KL loss: 0.272328
Average total loss: 1.118329
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.3877e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.832705
Average KL loss: 0.272381
Average total loss: 1.105086
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.0713e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.849712
Average KL loss: 0.272432
Average total loss: 1.122143
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.2573e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.845019
Average KL loss: 0.272476
Average total loss: 1.117495
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.6056e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.827728
Average KL loss: 0.272538
Average total loss: 1.100266
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.6221e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.841520
Average KL loss: 0.272609
Average total loss: 1.114129
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.3586e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.838330
Average KL loss: 0.272681
Average total loss: 1.111010
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.3068e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.858009
Average KL loss: 0.272747
Average total loss: 1.130755
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.5801e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.834733
Average KL loss: 0.272807
Average total loss: 1.107540
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.5186e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.841343
Average KL loss: 0.272878
Average total loss: 1.114221
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.9735e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.825429
Average KL loss: 0.272947
Average total loss: 1.098376
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.9786e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.832439
Average KL loss: 0.273014
Average total loss: 1.105453
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.0760e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.832451
Average KL loss: 0.273098
Average total loss: 1.105550
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.4867e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.837741
Average KL loss: 0.273169
Average total loss: 1.110910
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.4174e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.831292
Average KL loss: 0.273246
Average total loss: 1.104538
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-9.4161e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.820755
Average KL loss: 0.273324
Average total loss: 1.094079
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.0857e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.827990
Average KL loss: 0.273403
Average total loss: 1.101392
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.8729e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.836757
Average KL loss: 0.273504
Average total loss: 1.110261
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.4693e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.827188
Average KL loss: 0.273595
Average total loss: 1.100783
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.6593e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.817441
Average KL loss: 0.273693
Average total loss: 1.091134
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-2.1241e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.815119
Average KL loss: 0.273784
Average total loss: 1.088903
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-7.0529e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.819127
Average KL loss: 0.273871
Average total loss: 1.092998
tensor(0.0017, device='cuda:0') tensor(0.0049, device='cuda:0') tensor(-1.1089e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.819708
Average KL loss: 0.273963
Average total loss: 1.093671
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.4065e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.817412
Average KL loss: 0.274036
Average total loss: 1.091448
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.7753e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.806397
Average KL loss: 0.274132
Average total loss: 1.080529
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.6449e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.826582
Average KL loss: 0.274220
Average total loss: 1.100802
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-8.6010e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.805557
Average KL loss: 0.274313
Average total loss: 1.079870
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.7691e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.822603
Average KL loss: 0.274413
Average total loss: 1.097016
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.8775e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.807362
Average KL loss: 0.274499
Average total loss: 1.081861
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-4.6856e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.819824
Average KL loss: 0.274592
Average total loss: 1.094416
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.4178e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.804074
Average KL loss: 0.274679
Average total loss: 1.078754
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.2614e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.797490
Average KL loss: 0.274770
Average total loss: 1.072261
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-4.1943e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.806011
Average KL loss: 0.274856
Average total loss: 1.080867
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.4153e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.800303
Average KL loss: 0.274950
Average total loss: 1.075253
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.3689e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.822970
Average KL loss: 0.275059
Average total loss: 1.098029
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-2.2391e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.794999
Average KL loss: 0.275186
Average total loss: 1.070185
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.2108e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.808466
Average KL loss: 0.275275
Average total loss: 1.083741
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-3.3204e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.801974
Average KL loss: 0.275390
Average total loss: 1.077364
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.2741e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.817776
Average KL loss: 0.275493
Average total loss: 1.093269
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.4326e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.799320
Average KL loss: 0.275584
Average total loss: 1.074904
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.2820e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.813384
Average KL loss: 0.275688
Average total loss: 1.089071
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.1809e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.795626
Average KL loss: 0.275793
Average total loss: 1.071419
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.2413e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.810051
Average KL loss: 0.275889
Average total loss: 1.085940
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-8.1539e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.798943
Average KL loss: 0.275980
Average total loss: 1.074923
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.8113e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.797970
Average KL loss: 0.276078
Average total loss: 1.074048
tensor(0.0017, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.4150e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.789299
Average KL loss: 0.276180
Average total loss: 1.065479
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-2.0958e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.814979
Average KL loss: 0.276283
Average total loss: 1.091262
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.9197e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.796015
Average KL loss: 0.276396
Average total loss: 1.072411
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.5446e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.789399
Average KL loss: 0.276479
Average total loss: 1.065878
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.4305e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.788466
Average KL loss: 0.276588
Average total loss: 1.065054
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.4468e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.797991
Average KL loss: 0.276688
Average total loss: 1.074678
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.9210e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.776784
Average KL loss: 0.276796
Average total loss: 1.053580
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-8.3506e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.790261
Average KL loss: 0.276881
Average total loss: 1.067142
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-2.5138e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.783972
Average KL loss: 0.276992
Average total loss: 1.060964
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.1268e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.789820
Average KL loss: 0.277087
Average total loss: 1.066907
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.6017e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.775060
Average KL loss: 0.277188
Average total loss: 1.052248
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.5387e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.782965
Average KL loss: 0.277281
Average total loss: 1.060246
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.0378e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.781414
Average KL loss: 0.277378
Average total loss: 1.058792
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-8.0411e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.788940
Average KL loss: 0.277472
Average total loss: 1.066413
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.5365e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.778477
Average KL loss: 0.277576
Average total loss: 1.056054
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.1206e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.765795
Average KL loss: 0.277663
Average total loss: 1.043458
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.4492e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.777848
Average KL loss: 0.277733
Average total loss: 1.055581
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-3.6700e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.794641
Average KL loss: 0.277811
Average total loss: 1.072452
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.4214e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.776401
Average KL loss: 0.277904
Average total loss: 1.054305
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.3642e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.775244
Average KL loss: 0.278011
Average total loss: 1.053255
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-8.2218e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.780313
Average KL loss: 0.278099
Average total loss: 1.058412
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.1293e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.775167
Average KL loss: 0.278187
Average total loss: 1.053355
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-1.3578e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.783725
Average KL loss: 0.278294
Average total loss: 1.062019
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-2.5973e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.774531
Average KL loss: 0.278398
Average total loss: 1.052928
tensor(0.0017, device='cuda:0') tensor(0.0051, device='cuda:0') tensor(-7.7572e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.777465
Average KL loss: 0.278502
Average total loss: 1.055966
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.8462e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.779394
Average KL loss: 0.278610
Average total loss: 1.058003
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.3369e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.774613
Average KL loss: 0.278732
Average total loss: 1.053345
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.3593e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.770280
Average KL loss: 0.278792
Average total loss: 1.049073
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1923e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.776157
Average KL loss: 0.278803
Average total loss: 1.054960
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-8.9397e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.763090
Average KL loss: 0.278814
Average total loss: 1.041904
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-6.4663e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.776745
Average KL loss: 0.278823
Average total loss: 1.055568
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.8145e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.769298
Average KL loss: 0.278833
Average total loss: 1.048131
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.7706e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.767644
Average KL loss: 0.278842
Average total loss: 1.046486
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1105e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.767688
Average KL loss: 0.278852
Average total loss: 1.046540
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.6704e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.779342
Average KL loss: 0.278862
Average total loss: 1.058204
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.5481e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.773638
Average KL loss: 0.278873
Average total loss: 1.052511
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.3146e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.774998
Average KL loss: 0.278882
Average total loss: 1.053880
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.8640e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.777202
Average KL loss: 0.278892
Average total loss: 1.056094
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1219e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.773016
Average KL loss: 0.278903
Average total loss: 1.051919
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.7911e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.762788
Average KL loss: 0.278913
Average total loss: 1.041701
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-4.0641e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.784074
Average KL loss: 0.278920
Average total loss: 1.062994
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1602e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.769787
Average KL loss: 0.278928
Average total loss: 1.048715
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0823e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.782621
Average KL loss: 0.278939
Average total loss: 1.061560
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.9405e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.767194
Average KL loss: 0.278948
Average total loss: 1.046142
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.3595e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.763980
Average KL loss: 0.278958
Average total loss: 1.042938
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.5663e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.769351
Average KL loss: 0.278969
Average total loss: 1.048319
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.6907e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.770677
Average KL loss: 0.278978
Average total loss: 1.049656
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.4874e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.754433
Average KL loss: 0.278989
Average total loss: 1.033422
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.3554e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.750022
Average KL loss: 0.278997
Average total loss: 1.029019
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-8.1752e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.771118
Average KL loss: 0.279005
Average total loss: 1.050123
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-7.3346e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.766534
Average KL loss: 0.279015
Average total loss: 1.045549
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-3.9248e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.782177
Average KL loss: 0.279027
Average total loss: 1.061203
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.3013e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.770391
Average KL loss: 0.279036
Average total loss: 1.049427
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.8331e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.779759
Average KL loss: 0.279047
Average total loss: 1.058806
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.6454e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.757020
Average KL loss: 0.279057
Average total loss: 1.036077
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-7.1411e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.779244
Average KL loss: 0.279066
Average total loss: 1.058310
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1805e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.770002
Average KL loss: 0.279075
Average total loss: 1.049077
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-5.4735e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.757499
Average KL loss: 0.279083
Average total loss: 1.036582
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.7774e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.762837
Average KL loss: 0.279093
Average total loss: 1.041930
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.9239e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.767091
Average KL loss: 0.279105
Average total loss: 1.046196
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0567e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.754260
Average KL loss: 0.279111
Average total loss: 1.033371
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-7.0680e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.768306
Average KL loss: 0.279112
Average total loss: 1.047418
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.6763e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.765659
Average KL loss: 0.279113
Average total loss: 1.044772
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.5433e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.757081
Average KL loss: 0.279114
Average total loss: 1.036195
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.6124e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.758591
Average KL loss: 0.279115
Average total loss: 1.037707
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-2.8707e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.765071
Average KL loss: 0.279116
Average total loss: 1.044187
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.9692e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.772850
Average KL loss: 0.279117
Average total loss: 1.051967
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-8.9158e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.777695
Average KL loss: 0.279118
Average total loss: 1.056813
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0781e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.769592
Average KL loss: 0.279119
Average total loss: 1.048711
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.1255e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.765392
Average KL loss: 0.279120
Average total loss: 1.044513
tensor(0.0017, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.2126e-08, device='cuda:0')
 Percentile value: 2.414513349533081
Non-zero model percentage: 0.04883367195725441%, Non-zero mask percentage: 0.04883367195725441%

--- Pruning Level [11/12]: ---
conv1.weight         | nonzeros =      84 /    1728             (  4.86%) | total_pruned =    1644 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
bn1.bias             | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      40 /   36864             (  0.11%) | total_pruned =   36824 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      91 /   36864             (  0.25%) | total_pruned =   36773 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =      96 /   36864             (  0.26%) | total_pruned =   36768 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     181 /   36864             (  0.49%) | total_pruned =   36683 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      29 /      64             ( 45.31%) | total_pruned =      35 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       1 /      64             (  1.56%) | total_pruned =      63 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     334 /   73728             (  0.45%) | total_pruned =   73394 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     457 /  147456             (  0.31%) | total_pruned =  146999 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      80 /     128             ( 62.50%) | total_pruned =      48 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =      41 /    8192             (  0.50%) | total_pruned =    8151 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     224 /  147456             (  0.15%) | total_pruned =  147232 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      50 /     128             ( 39.06%) | total_pruned =      78 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     178 /  147456             (  0.12%) | total_pruned =  147278 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      43 /     128             ( 33.59%) | total_pruned =      85 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     567 /  294912             (  0.19%) | total_pruned =  294345 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     197 /     256             ( 76.95%) | total_pruned =      59 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     705 /  589824             (  0.12%) | total_pruned =  589119 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     159 /     256             ( 62.11%) | total_pruned =      97 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      34 /   32768             (  0.10%) | total_pruned =   32734 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     405 /  589824             (  0.07%) | total_pruned =  589419 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =      87 /     256             ( 33.98%) | total_pruned =     169 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       5 /     256             (  1.95%) | total_pruned =     251 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     253 /  589824             (  0.04%) | total_pruned =  589571 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      42 /     256             ( 16.41%) | total_pruned =     214 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     227 / 1179648             (  0.02%) | total_pruned = 1179421 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     102 /     512             ( 19.92%) | total_pruned =     410 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     191 / 2359296             (  0.01%) | total_pruned = 2359105 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      42 /     512             (  8.20%) | total_pruned =     470 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      14 /  131072             (  0.01%) | total_pruned =  131058 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       7 /     512             (  1.37%) | total_pruned =     505 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =      99 / 2359296             (  0.00%) | total_pruned = 2359197 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      30 /     512             (  5.86%) | total_pruned =     482 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =      61 / 2359296             (  0.00%) | total_pruned = 2359235 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
linear.weight        | nonzeros =      45 /    5120             (  0.88%) | total_pruned =    5075 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 5459, pruned : 11173303, total: 11178762, Compression rate :    2047.77x  ( 99.95% pruned)
Train Epoch: 99/100 Loss: 0.842107 Accuracy: 72.30 75.79 % Best test Accuracy: 72.69%
