Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Non-zero model percentage: 99.95706176757812%, Non-zero mask percentage: 99.99999237060547%

--- Pruning Level [0/12]: ---
conv1.weight         | nonzeros =    1728 /    1728             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.weight           | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
bn1.bias             | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   36864 /   36864             (100.00%) | total_pruned =       0 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   73728 /   73728             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =  147456 /  147456             (100.00%) | total_pruned =       0 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  294912 /  294912             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  589824 /  589824             (100.00%) | total_pruned =       0 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros = 1179648 / 1179648             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 2359296 / 2359296             (100.00%) | total_pruned =       0 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
linear.weight        | nonzeros =    5120 /    5120             (100.00%) | total_pruned =       0 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =      10 /      10             (100.00%) | total_pruned =       0 | shape = torch.Size([10])
alive: 11173962, pruned : 4800, total: 11178762, Compression rate :       1.00x  (  0.04% pruned)
Train Epoch: 57/100 Loss: 0.015782 Accuracy: 90.13 100.00 % Best test Accuracy: 90.50%
tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(-9.2495e-11, device='cuda:0')
Epoch 1
Average batch original loss after noise: 2.302784
Average KL loss: 0.000238
Average total loss: 2.303021
tensor(2.1524e-05, device='cuda:0') tensor(1.4304e-06, device='cuda:0') tensor(-1.8841e-10, device='cuda:0')
Epoch 2
Average batch original loss after noise: 2.303072
Average KL loss: 0.000252
Average total loss: 2.303324
tensor(2.8678e-05, device='cuda:0') tensor(2.1237e-06, device='cuda:0') tensor(-1.5648e-10, device='cuda:0')
Epoch 3
Average batch original loss after noise: 2.302890
Average KL loss: 0.000262
Average total loss: 2.303151
tensor(3.6531e-05, device='cuda:0') tensor(2.9867e-06, device='cuda:0') tensor(-7.0837e-11, device='cuda:0')
Epoch 4
Average batch original loss after noise: 2.302848
Average KL loss: 0.000273
Average total loss: 2.303121
tensor(4.5550e-05, device='cuda:0') tensor(3.9135e-06, device='cuda:0') tensor(-2.5863e-10, device='cuda:0')
Epoch 5
Average batch original loss after noise: 2.303081
Average KL loss: 0.000286
Average total loss: 2.303367
tensor(5.0177e-05, device='cuda:0') tensor(4.6136e-06, device='cuda:0') tensor(-2.5809e-10, device='cuda:0')
Epoch 6
Average batch original loss after noise: 2.302809
Average KL loss: 0.000294
Average total loss: 2.303103
tensor(4.7773e-05, device='cuda:0') tensor(4.7941e-06, device='cuda:0') tensor(2.2917e-10, device='cuda:0')
Epoch 7
Average batch original loss after noise: 2.302486
Average KL loss: 0.000300
Average total loss: 2.302786
tensor(6.1225e-05, device='cuda:0') tensor(5.8745e-06, device='cuda:0') tensor(-9.9136e-10, device='cuda:0')
Epoch 8
Average batch original loss after noise: 2.302406
Average KL loss: 0.000319
Average total loss: 2.302726
tensor(7.3249e-05, device='cuda:0') tensor(7.1344e-06, device='cuda:0') tensor(-9.2138e-11, device='cuda:0')
Epoch 9
Average batch original loss after noise: 2.302480
Average KL loss: 0.000335
Average total loss: 2.302816
tensor(8.1198e-05, device='cuda:0') tensor(8.2985e-06, device='cuda:0') tensor(-3.1339e-10, device='cuda:0')
Epoch 10
Average batch original loss after noise: 2.302155
Average KL loss: 0.000355
Average total loss: 2.302511
tensor(9.3260e-05, device='cuda:0') tensor(9.7565e-06, device='cuda:0') tensor(-5.5316e-11, device='cuda:0')
Epoch 11
Average batch original loss after noise: 2.302396
Average KL loss: 0.000372
Average total loss: 2.302768
tensor(0.0001, device='cuda:0') tensor(1.1582e-05, device='cuda:0') tensor(-8.6586e-10, device='cuda:0')
Epoch 12
Average batch original loss after noise: 2.302121
Average KL loss: 0.000405
Average total loss: 2.302527
tensor(0.0001, device='cuda:0') tensor(1.3587e-05, device='cuda:0') tensor(-6.2388e-10, device='cuda:0')
Epoch 13
Average batch original loss after noise: 2.301675
Average KL loss: 0.000436
Average total loss: 2.302112
tensor(0.0001, device='cuda:0') tensor(1.7392e-05, device='cuda:0') tensor(-7.4435e-10, device='cuda:0')
Epoch 14
Average batch original loss after noise: 2.301547
Average KL loss: 0.000483
Average total loss: 2.302030
tensor(0.0002, device='cuda:0') tensor(1.9621e-05, device='cuda:0') tensor(3.3871e-11, device='cuda:0')
Epoch 15
Average batch original loss after noise: 2.301568
Average KL loss: 0.000524
Average total loss: 2.302091
tensor(0.0002, device='cuda:0') tensor(2.3171e-05, device='cuda:0') tensor(-3.0903e-09, device='cuda:0')
Epoch 16
Average batch original loss after noise: 2.300760
Average KL loss: 0.000604
Average total loss: 2.301363
tensor(0.0002, device='cuda:0') tensor(3.0275e-05, device='cuda:0') tensor(-9.3059e-10, device='cuda:0')
Epoch 17
Average batch original loss after noise: 2.300947
Average KL loss: 0.000679
Average total loss: 2.301627
tensor(0.0002, device='cuda:0') tensor(3.4695e-05, device='cuda:0') tensor(-1.2944e-09, device='cuda:0')
Epoch 18
Average batch original loss after noise: 2.299989
Average KL loss: 0.000783
Average total loss: 2.300772
tensor(0.0003, device='cuda:0') tensor(4.3789e-05, device='cuda:0') tensor(-1.1885e-09, device='cuda:0')
Epoch 19
Average batch original loss after noise: 2.298188
Average KL loss: 0.000931
Average total loss: 2.299119
tensor(0.0004, device='cuda:0') tensor(5.9206e-05, device='cuda:0') tensor(-2.5036e-09, device='cuda:0')
Epoch 20
Average batch original loss after noise: 2.297188
Average KL loss: 0.001194
Average total loss: 2.298382
tensor(0.0005, device='cuda:0') tensor(7.9514e-05, device='cuda:0') tensor(-8.1646e-10, device='cuda:0')
Epoch 21
Average batch original loss after noise: 2.294569
Average KL loss: 0.001507
Average total loss: 2.296076
tensor(0.0006, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-1.1809e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 2.292101
Average KL loss: 0.002024
Average total loss: 2.294125
tensor(0.0007, device='cuda:0') tensor(0.0001, device='cuda:0') tensor(-3.8378e-09, device='cuda:0')
Epoch 23
Average batch original loss after noise: 2.285210
Average KL loss: 0.002698
Average total loss: 2.287908
tensor(0.0010, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(-1.3597e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 2.280799
Average KL loss: 0.003688
Average total loss: 2.284487
tensor(0.0012, device='cuda:0') tensor(0.0003, device='cuda:0') tensor(-1.7316e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 2.267780
Average KL loss: 0.005056
Average total loss: 2.272836
tensor(0.0015, device='cuda:0') tensor(0.0004, device='cuda:0') tensor(-1.3009e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 2.246832
Average KL loss: 0.006923
Average total loss: 2.253755
tensor(0.0020, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(-2.6819e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 2.224143
Average KL loss: 0.009556
Average total loss: 2.233699
tensor(0.0026, device='cuda:0') tensor(0.0008, device='cuda:0') tensor(-4.1531e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 2.186172
Average KL loss: 0.012714
Average total loss: 2.198887
tensor(0.0033, device='cuda:0') tensor(0.0010, device='cuda:0') tensor(-2.8943e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 2.149288
Average KL loss: 0.016797
Average total loss: 2.166085
tensor(0.0041, device='cuda:0') tensor(0.0013, device='cuda:0') tensor(-6.0443e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 2.095176
Average KL loss: 0.021520
Average total loss: 2.116696
tensor(0.0050, device='cuda:0') tensor(0.0017, device='cuda:0') tensor(-4.3650e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 2.040682
Average KL loss: 0.026712
Average total loss: 2.067394
tensor(0.0059, device='cuda:0') tensor(0.0021, device='cuda:0') tensor(-7.5284e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 1.968374
Average KL loss: 0.032510
Average total loss: 2.000885
tensor(0.0069, device='cuda:0') tensor(0.0025, device='cuda:0') tensor(-8.8118e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 1.907196
Average KL loss: 0.038442
Average total loss: 1.945639
tensor(0.0078, device='cuda:0') tensor(0.0029, device='cuda:0') tensor(-9.5019e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 1.860836
Average KL loss: 0.044576
Average total loss: 1.905411
tensor(0.0086, device='cuda:0') tensor(0.0034, device='cuda:0') tensor(-1.0879e-07, device='cuda:0')
Epoch 35
Average batch original loss after noise: 1.783952
Average KL loss: 0.050483
Average total loss: 1.834434
tensor(0.0094, device='cuda:0') tensor(0.0037, device='cuda:0') tensor(-9.2472e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 1.717388
Average KL loss: 0.055754
Average total loss: 1.773142
tensor(0.0101, device='cuda:0') tensor(0.0041, device='cuda:0') tensor(-9.2280e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 1.652066
Average KL loss: 0.060563
Average total loss: 1.712630
tensor(0.0107, device='cuda:0') tensor(0.0044, device='cuda:0') tensor(-1.1258e-07, device='cuda:0')
Epoch 38
Average batch original loss after noise: 1.598531
Average KL loss: 0.064900
Average total loss: 1.663432
tensor(0.0113, device='cuda:0') tensor(0.0047, device='cuda:0') tensor(-1.0607e-07, device='cuda:0')
Epoch 39
Average batch original loss after noise: 1.559782
Average KL loss: 0.068495
Average total loss: 1.628278
tensor(0.0117, device='cuda:0') tensor(0.0050, device='cuda:0') tensor(-1.2142e-07, device='cuda:0')
Epoch 40
Average batch original loss after noise: 1.507472
Average KL loss: 0.072035
Average total loss: 1.579507
tensor(0.0120, device='cuda:0') tensor(0.0052, device='cuda:0') tensor(-1.0386e-07, device='cuda:0')
Epoch 41
Average batch original loss after noise: 1.452641
Average KL loss: 0.075097
Average total loss: 1.527738
tensor(0.0124, device='cuda:0') tensor(0.0054, device='cuda:0') tensor(-1.1606e-07, device='cuda:0')
Epoch 42
Average batch original loss after noise: 1.429610
Average KL loss: 0.077792
Average total loss: 1.507402
tensor(0.0127, device='cuda:0') tensor(0.0056, device='cuda:0') tensor(-9.4762e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 1.365494
Average KL loss: 0.080253
Average total loss: 1.445747
tensor(0.0129, device='cuda:0') tensor(0.0058, device='cuda:0') tensor(-9.3129e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 1.345926
Average KL loss: 0.082721
Average total loss: 1.428646
tensor(0.0132, device='cuda:0') tensor(0.0059, device='cuda:0') tensor(-1.0374e-07, device='cuda:0')
Epoch 45
Average batch original loss after noise: 1.309089
Average KL loss: 0.084979
Average total loss: 1.394068
tensor(0.0134, device='cuda:0') tensor(0.0061, device='cuda:0') tensor(-1.0528e-07, device='cuda:0')
Epoch 46
Average batch original loss after noise: 1.272356
Average KL loss: 0.086814
Average total loss: 1.359170
tensor(0.0135, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(-9.2294e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 1.234033
Average KL loss: 0.088350
Average total loss: 1.322383
tensor(0.0136, device='cuda:0') tensor(0.0063, device='cuda:0') tensor(-9.8530e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 1.202692
Average KL loss: 0.089587
Average total loss: 1.292280
tensor(0.0137, device='cuda:0') tensor(0.0064, device='cuda:0') tensor(-9.4511e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 1.191873
Average KL loss: 0.090848
Average total loss: 1.282721
tensor(0.0138, device='cuda:0') tensor(0.0065, device='cuda:0') tensor(-9.9051e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 1.146692
Average KL loss: 0.091967
Average total loss: 1.238659
tensor(0.0139, device='cuda:0') tensor(0.0066, device='cuda:0') tensor(-8.7581e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 1.132930
Average KL loss: 0.093039
Average total loss: 1.225969
tensor(0.0140, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-8.9722e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 1.112927
Average KL loss: 0.093979
Average total loss: 1.206906
tensor(0.0140, device='cuda:0') tensor(0.0067, device='cuda:0') tensor(-7.9185e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 1.090079
Average KL loss: 0.094765
Average total loss: 1.184844
tensor(0.0140, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-8.1129e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 1.095018
Average KL loss: 0.095504
Average total loss: 1.190521
tensor(0.0141, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.8363e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 1.049257
Average KL loss: 0.096190
Average total loss: 1.145446
tensor(0.0141, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-7.8971e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 1.043943
Average KL loss: 0.096838
Average total loss: 1.140781
tensor(0.0141, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-8.0622e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 1.020781
Average KL loss: 0.097522
Average total loss: 1.118303
tensor(0.0141, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.6813e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 1.008655
Average KL loss: 0.097985
Average total loss: 1.106640
tensor(0.0141, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-7.6115e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.988220
Average KL loss: 0.098390
Average total loss: 1.086610
tensor(0.0141, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-8.1561e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.992085
Average KL loss: 0.098822
Average total loss: 1.090907
tensor(0.0141, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-7.2021e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.942284
Average KL loss: 0.099130
Average total loss: 1.041413
tensor(0.0141, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-6.6481e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.957085
Average KL loss: 0.099315
Average total loss: 1.056400
tensor(0.0141, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-8.8074e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.918881
Average KL loss: 0.099534
Average total loss: 1.018415
tensor(0.0140, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.4258e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.905253
Average KL loss: 0.099522
Average total loss: 1.004775
tensor(0.0140, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.9652e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.901939
Average KL loss: 0.099619
Average total loss: 1.001559
tensor(0.0139, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-7.3500e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.903804
Average KL loss: 0.099659
Average total loss: 1.003464
tensor(0.0139, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-8.9946e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.871726
Average KL loss: 0.099739
Average total loss: 0.971465
tensor(0.0139, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-5.5073e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.860811
Average KL loss: 0.099711
Average total loss: 0.960522
tensor(0.0138, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-7.1923e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.856319
Average KL loss: 0.099709
Average total loss: 0.956028
tensor(0.0138, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.8137e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.850031
Average KL loss: 0.099682
Average total loss: 0.949714
tensor(0.0138, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-7.1337e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.832297
Average KL loss: 0.099752
Average total loss: 0.932049
tensor(0.0138, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.7215e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.842729
Average KL loss: 0.099812
Average total loss: 0.942541
tensor(0.0138, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.7839e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.823157
Average KL loss: 0.099855
Average total loss: 0.923012
tensor(0.0137, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.8850e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.792652
Average KL loss: 0.099785
Average total loss: 0.892437
tensor(0.0137, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.9422e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.801965
Average KL loss: 0.099643
Average total loss: 0.901608
tensor(0.0136, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.2741e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.792783
Average KL loss: 0.099575
Average total loss: 0.892358
tensor(0.0136, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-7.3942e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.784176
Average KL loss: 0.099568
Average total loss: 0.883743
tensor(0.0136, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.1540e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.779601
Average KL loss: 0.099436
Average total loss: 0.879038
tensor(0.0135, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.7236e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.761099
Average KL loss: 0.099334
Average total loss: 0.860434
tensor(0.0135, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.4336e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.758091
Average KL loss: 0.099238
Average total loss: 0.857329
tensor(0.0135, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.4057e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.754753
Average KL loss: 0.099178
Average total loss: 0.853931
tensor(0.0134, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.0385e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.739377
Average KL loss: 0.099113
Average total loss: 0.838490
tensor(0.0134, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.0461e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.740048
Average KL loss: 0.099041
Average total loss: 0.839090
tensor(0.0133, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.1654e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.735712
Average KL loss: 0.098941
Average total loss: 0.834653
tensor(0.0133, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.8988e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.715999
Average KL loss: 0.098801
Average total loss: 0.814800
tensor(0.0133, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.7008e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.708026
Average KL loss: 0.098662
Average total loss: 0.806688
tensor(0.0132, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.8525e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.711642
Average KL loss: 0.098483
Average total loss: 0.810125
tensor(0.0132, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-6.4723e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.693515
Average KL loss: 0.098339
Average total loss: 0.791854
tensor(0.0132, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.2194e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.691551
Average KL loss: 0.098186
Average total loss: 0.789737
tensor(0.0131, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-5.7765e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.686402
Average KL loss: 0.098140
Average total loss: 0.784542
tensor(0.0131, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.2266e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.700545
Average KL loss: 0.098065
Average total loss: 0.798610
tensor(0.0131, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.8400e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.677219
Average KL loss: 0.097975
Average total loss: 0.775194
tensor(0.0130, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.7903e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.666041
Average KL loss: 0.097796
Average total loss: 0.763837
tensor(0.0130, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.9345e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.671770
Average KL loss: 0.097610
Average total loss: 0.769381
tensor(0.0130, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.8256e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.668836
Average KL loss: 0.097500
Average total loss: 0.766336
tensor(0.0129, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.2023e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.652346
Average KL loss: 0.097360
Average total loss: 0.749706
tensor(0.0129, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.4690e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.657028
Average KL loss: 0.097240
Average total loss: 0.754268
tensor(0.0129, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.1722e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.647097
Average KL loss: 0.097177
Average total loss: 0.744273
tensor(0.0128, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.9731e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.641298
Average KL loss: 0.097069
Average total loss: 0.738367
tensor(0.0128, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.3216e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.639825
Average KL loss: 0.097022
Average total loss: 0.736846
tensor(0.0128, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.1577e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.626074
Average KL loss: 0.096898
Average total loss: 0.722972
tensor(0.0128, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.2397e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.625508
Average KL loss: 0.096774
Average total loss: 0.722282
tensor(0.0127, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.1583e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.624300
Average KL loss: 0.096638
Average total loss: 0.720938
tensor(0.0127, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.2144e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.602780
Average KL loss: 0.096503
Average total loss: 0.699283
tensor(0.0127, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.6236e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.600632
Average KL loss: 0.096386
Average total loss: 0.697017
tensor(0.0127, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.8265e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.594321
Average KL loss: 0.096271
Average total loss: 0.690592
tensor(0.0126, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.2482e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.598352
Average KL loss: 0.096078
Average total loss: 0.694431
tensor(0.0126, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-6.6973e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.599009
Average KL loss: 0.095934
Average total loss: 0.694943
tensor(0.0126, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.2903e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.589385
Average KL loss: 0.095779
Average total loss: 0.685165
tensor(0.0125, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.9469e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.581655
Average KL loss: 0.095637
Average total loss: 0.677291
tensor(0.0125, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.1913e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.580251
Average KL loss: 0.095503
Average total loss: 0.675755
tensor(0.0125, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.7782e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.573504
Average KL loss: 0.095449
Average total loss: 0.668953
tensor(0.0125, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.9753e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.576909
Average KL loss: 0.095246
Average total loss: 0.672155
tensor(0.0124, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.4733e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.567314
Average KL loss: 0.095143
Average total loss: 0.662457
tensor(0.0124, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.8172e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.559848
Average KL loss: 0.095070
Average total loss: 0.654919
tensor(0.0124, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.7144e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.563193
Average KL loss: 0.094906
Average total loss: 0.658099
tensor(0.0123, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.4438e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.548870
Average KL loss: 0.094767
Average total loss: 0.643637
tensor(0.0123, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.2526e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.556459
Average KL loss: 0.094621
Average total loss: 0.651081
tensor(0.0123, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.0196e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.548901
Average KL loss: 0.094529
Average total loss: 0.643429
tensor(0.0122, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.9237e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.539659
Average KL loss: 0.094438
Average total loss: 0.634097
tensor(0.0122, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.5091e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.546736
Average KL loss: 0.094334
Average total loss: 0.641070
tensor(0.0122, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.2235e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.548298
Average KL loss: 0.094296
Average total loss: 0.642594
tensor(0.0122, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.6042e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.541824
Average KL loss: 0.094208
Average total loss: 0.636032
tensor(0.0122, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.2627e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.523251
Average KL loss: 0.094092
Average total loss: 0.617343
tensor(0.0121, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.7170e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.531462
Average KL loss: 0.094033
Average total loss: 0.625495
tensor(0.0121, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.0327e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.517025
Average KL loss: 0.093885
Average total loss: 0.610910
tensor(0.0121, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-5.1807e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.523878
Average KL loss: 0.093769
Average total loss: 0.617647
tensor(0.0121, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.2031e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.520093
Average KL loss: 0.093648
Average total loss: 0.613741
tensor(0.0120, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.9156e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.517140
Average KL loss: 0.093559
Average total loss: 0.610700
tensor(0.0120, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.4361e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.504469
Average KL loss: 0.093436
Average total loss: 0.597905
tensor(0.0120, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.9145e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.518100
Average KL loss: 0.093321
Average total loss: 0.611421
tensor(0.0120, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.0695e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.502701
Average KL loss: 0.093249
Average total loss: 0.595950
tensor(0.0119, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-2.0636e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.508864
Average KL loss: 0.093112
Average total loss: 0.601976
tensor(0.0119, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.6091e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.508866
Average KL loss: 0.093088
Average total loss: 0.601954
tensor(0.0119, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.1975e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.492239
Average KL loss: 0.093053
Average total loss: 0.585292
tensor(0.0119, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.6401e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.490387
Average KL loss: 0.092955
Average total loss: 0.583343
tensor(0.0119, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.0340e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.492227
Average KL loss: 0.092879
Average total loss: 0.585107
tensor(0.0119, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.0021e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.493675
Average KL loss: 0.092791
Average total loss: 0.586466
tensor(0.0119, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.1785e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.483209
Average KL loss: 0.092736
Average total loss: 0.575945
tensor(0.0118, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.1267e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.476047
Average KL loss: 0.092666
Average total loss: 0.568713
tensor(0.0118, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.4097e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.479902
Average KL loss: 0.092579
Average total loss: 0.572481
tensor(0.0118, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.0415e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.480659
Average KL loss: 0.092516
Average total loss: 0.573174
tensor(0.0118, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.4700e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.473626
Average KL loss: 0.092465
Average total loss: 0.566091
tensor(0.0118, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.3739e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.475503
Average KL loss: 0.092395
Average total loss: 0.567899
tensor(0.0118, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.9539e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.467192
Average KL loss: 0.092330
Average total loss: 0.559522
tensor(0.0117, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.7471e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.462728
Average KL loss: 0.092204
Average total loss: 0.554932
tensor(0.0117, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.9285e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.463601
Average KL loss: 0.092090
Average total loss: 0.555691
tensor(0.0117, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.2909e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.458679
Average KL loss: 0.091972
Average total loss: 0.550651
tensor(0.0117, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.8238e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.446606
Average KL loss: 0.091842
Average total loss: 0.538449
tensor(0.0117, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.9424e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.453285
Average KL loss: 0.091759
Average total loss: 0.545044
tensor(0.0116, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.6624e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.455279
Average KL loss: 0.091682
Average total loss: 0.546961
tensor(0.0116, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3117e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.450612
Average KL loss: 0.091619
Average total loss: 0.542230
tensor(0.0116, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.4026e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.436551
Average KL loss: 0.091500
Average total loss: 0.528051
tensor(0.0116, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-4.9661e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.449796
Average KL loss: 0.091396
Average total loss: 0.541193
tensor(0.0116, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.9935e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.448876
Average KL loss: 0.091333
Average total loss: 0.540210
tensor(0.0116, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.2787e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.428783
Average KL loss: 0.091299
Average total loss: 0.520083
tensor(0.0116, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.0340e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.431747
Average KL loss: 0.091172
Average total loss: 0.522920
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.6800e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.434417
Average KL loss: 0.091095
Average total loss: 0.525512
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3386e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.436909
Average KL loss: 0.091022
Average total loss: 0.527931
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.3018e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.438702
Average KL loss: 0.090996
Average total loss: 0.529697
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.6819e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.425258
Average KL loss: 0.090961
Average total loss: 0.516219
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.7779e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.430923
Average KL loss: 0.090921
Average total loss: 0.521843
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.0678e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.431937
Average KL loss: 0.090901
Average total loss: 0.522838
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-1.9149e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.420391
Average KL loss: 0.090837
Average total loss: 0.511228
tensor(0.0115, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.1540e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.420446
Average KL loss: 0.090759
Average total loss: 0.511206
tensor(0.0114, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.3577e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.426720
Average KL loss: 0.090696
Average total loss: 0.517416
tensor(0.0114, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.0425e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.414251
Average KL loss: 0.090646
Average total loss: 0.504897
tensor(0.0114, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.1868e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.410241
Average KL loss: 0.090547
Average total loss: 0.500788
tensor(0.0114, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.1651e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.409063
Average KL loss: 0.090440
Average total loss: 0.499503
tensor(0.0114, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-1.5064e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.406166
Average KL loss: 0.090388
Average total loss: 0.496555
tensor(0.0114, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.6049e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.404780
Average KL loss: 0.090298
Average total loss: 0.495078
tensor(0.0114, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.5409e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.411799
Average KL loss: 0.090272
Average total loss: 0.502071
tensor(0.0113, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.4672e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.400463
Average KL loss: 0.090255
Average total loss: 0.490718
tensor(0.0113, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.7945e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.398597
Average KL loss: 0.090192
Average total loss: 0.488789
tensor(0.0113, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.7315e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.399428
Average KL loss: 0.090095
Average total loss: 0.489523
tensor(0.0113, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.8066e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.398995
Average KL loss: 0.090065
Average total loss: 0.489060
tensor(0.0113, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.0002e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.396140
Average KL loss: 0.089966
Average total loss: 0.486106
tensor(0.0113, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.0582e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.399399
Average KL loss: 0.089909
Average total loss: 0.489308
tensor(0.0113, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.6049e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.386571
Average KL loss: 0.089877
Average total loss: 0.476448
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.6847e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.390330
Average KL loss: 0.089817
Average total loss: 0.480148
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.1636e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.391939
Average KL loss: 0.089742
Average total loss: 0.481681
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.4647e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.384593
Average KL loss: 0.089691
Average total loss: 0.474284
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.1607e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.386627
Average KL loss: 0.089650
Average total loss: 0.476277
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.8871e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.383859
Average KL loss: 0.089636
Average total loss: 0.473495
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.4482e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.385299
Average KL loss: 0.089600
Average total loss: 0.474898
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.9812e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.378705
Average KL loss: 0.089514
Average total loss: 0.468219
tensor(0.0112, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.8860e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.377478
Average KL loss: 0.089431
Average total loss: 0.466909
tensor(0.0111, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.4413e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.380714
Average KL loss: 0.089371
Average total loss: 0.470085
tensor(0.0111, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.1176e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.372511
Average KL loss: 0.089312
Average total loss: 0.461823
tensor(0.0111, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-1.9422e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.369916
Average KL loss: 0.089247
Average total loss: 0.459163
tensor(0.0111, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.0304e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.367963
Average KL loss: 0.089156
Average total loss: 0.457119
tensor(0.0111, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.1143e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.369760
Average KL loss: 0.089102
Average total loss: 0.458862
tensor(0.0111, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.9515e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.363148
Average KL loss: 0.089044
Average total loss: 0.452191
tensor(0.0111, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.0506e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.367882
Average KL loss: 0.089015
Average total loss: 0.456898
tensor(0.0111, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.2777e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.370037
Average KL loss: 0.088941
Average total loss: 0.458978
tensor(0.0111, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.9141e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.365662
Average KL loss: 0.088938
Average total loss: 0.454601
tensor(0.0111, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.8167e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.359931
Average KL loss: 0.088873
Average total loss: 0.448804
tensor(0.0111, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.7600e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.360399
Average KL loss: 0.088834
Average total loss: 0.449233
tensor(0.0110, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.8086e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.363123
Average KL loss: 0.088806
Average total loss: 0.451929
tensor(0.0110, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.8623e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.357688
Average KL loss: 0.088783
Average total loss: 0.446471
 Percentile value: 0.010431960225105286
Non-zero model percentage: 49.999996185302734%, Non-zero mask percentage: 49.999996185302734%

--- Pruning Level [1/12]: ---
conv1.weight         | nonzeros =     477 /    1728             ( 27.60%) | total_pruned =    1251 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
bn1.bias             | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    6416 /   36864             ( 17.40%) | total_pruned =   30448 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      59 /      64             ( 92.19%) | total_pruned =       5 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =   16156 /   36864             ( 43.83%) | total_pruned =   20708 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      55 /      64             ( 85.94%) | total_pruned =       9 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =   15795 /   36864             ( 42.85%) | total_pruned =   21069 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      64 /      64             (100.00%) | total_pruned =       0 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =   19781 /   36864             ( 53.66%) | total_pruned =   17083 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      61 /      64             ( 95.31%) | total_pruned =       3 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      39 /      64             ( 60.94%) | total_pruned =      25 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   41437 /   73728             ( 56.20%) | total_pruned =   32291 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      55 /     128             ( 42.97%) | total_pruned =      73 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   83186 /  147456             ( 56.41%) | total_pruned =   64270 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     128 /     128             (100.00%) | total_pruned =       0 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    4978 /    8192             ( 60.77%) | total_pruned =    3214 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     120 /     128             ( 93.75%) | total_pruned =       8 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      24 /     128             ( 18.75%) | total_pruned =     104 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   74112 /  147456             ( 50.26%) | total_pruned =   73344 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     124 /     128             ( 96.88%) | total_pruned =       4 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      21 /     128             ( 16.41%) | total_pruned =     107 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   73073 /  147456             ( 49.56%) | total_pruned =   74383 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =      14 /     128             ( 10.94%) | total_pruned =     114 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =  158411 /  294912             ( 53.71%) | total_pruned =  136501 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  312988 /  589824             ( 53.06%) | total_pruned =  276836 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     256 /     256             (100.00%) | total_pruned =       0 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      20 /     256             (  7.81%) | total_pruned =     236 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   18896 /   32768             ( 57.67%) | total_pruned =   13872 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     244 /     256             ( 95.31%) | total_pruned =      12 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      18 /     256             (  7.03%) | total_pruned =     238 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  301875 /  589824             ( 51.18%) | total_pruned =  287949 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  296741 /  589824             ( 50.31%) | total_pruned =  293083 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  594335 / 1179648             ( 50.38%) | total_pruned =  585313 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     499 /     512             ( 97.46%) | total_pruned =      13 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros = 1116000 / 2359296             ( 47.30%) | total_pruned = 1243296 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     485 /     512             ( 94.73%) | total_pruned =      27 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     287 /     512             ( 56.05%) | total_pruned =     225 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   64178 /  131072             ( 48.96%) | total_pruned =   66894 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     508 /     512             ( 99.22%) | total_pruned =       4 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     286 /     512             ( 55.86%) | total_pruned =     226 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros = 1062059 / 2359296             ( 45.02%) | total_pruned = 1297237 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros = 1317286 / 2359296             ( 55.83%) | total_pruned = 1042010 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     512 /     512             (100.00%) | total_pruned =       0 | shape = torch.Size([512])
linear.weight        | nonzeros =    5018 /    5120             ( 98.01%) | total_pruned =     102 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       4 /      10             ( 40.00%) | total_pruned =       6 | shape = torch.Size([10])
alive: 5589381, pruned : 5589381, total: 11178762, Compression rate :       2.00x  ( 50.00% pruned)
Train Epoch: 51/100 Loss: 0.015640 Accuracy: 89.72 100.00 % Best test Accuracy: 89.72%
tensor(0.0110, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-1.2173e-07, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.727624
Average KL loss: 0.083374
Average total loss: 0.810998
tensor(0.0132, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-1.0381e-07, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.697726
Average KL loss: 0.078103
Average total loss: 0.775829
tensor(0.0139, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-1.0650e-07, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.683039
Average KL loss: 0.075873
Average total loss: 0.758912
tensor(0.0143, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.8378e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.638596
Average KL loss: 0.074871
Average total loss: 0.713468
tensor(0.0145, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-9.4503e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.620817
Average KL loss: 0.074505
Average total loss: 0.695321
tensor(0.0146, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.7956e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.609186
Average KL loss: 0.074387
Average total loss: 0.683573
tensor(0.0147, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-5.1917e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.571126
Average KL loss: 0.074509
Average total loss: 0.645635
tensor(0.0147, device='cuda:0') tensor(0.0068, device='cuda:0') tensor(-7.2462e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.604722
Average KL loss: 0.074739
Average total loss: 0.679461
tensor(0.0148, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-4.2945e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.549854
Average KL loss: 0.075117
Average total loss: 0.624971
tensor(0.0148, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.6106e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.559210
Average KL loss: 0.075490
Average total loss: 0.634700
tensor(0.0148, device='cuda:0') tensor(0.0069, device='cuda:0') tensor(-5.1968e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.548878
Average KL loss: 0.075918
Average total loss: 0.624796
tensor(0.0148, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-5.9798e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.560554
Average KL loss: 0.076358
Average total loss: 0.636913
tensor(0.0147, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-6.0835e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.514378
Average KL loss: 0.076738
Average total loss: 0.591116
tensor(0.0147, device='cuda:0') tensor(0.0070, device='cuda:0') tensor(-3.8091e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.513227
Average KL loss: 0.077133
Average total loss: 0.590360
tensor(0.0147, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.2211e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.491378
Average KL loss: 0.077441
Average total loss: 0.568818
tensor(0.0147, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-5.2447e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.503778
Average KL loss: 0.077793
Average total loss: 0.581571
tensor(0.0147, device='cuda:0') tensor(0.0071, device='cuda:0') tensor(-6.8830e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.499270
Average KL loss: 0.078157
Average total loss: 0.577427
tensor(0.0146, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-3.1885e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.482443
Average KL loss: 0.078484
Average total loss: 0.560927
tensor(0.0146, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.1022e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.474646
Average KL loss: 0.078796
Average total loss: 0.553442
tensor(0.0146, device='cuda:0') tensor(0.0072, device='cuda:0') tensor(-4.2641e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.467706
Average KL loss: 0.079111
Average total loss: 0.546817
tensor(0.0145, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.4863e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.471752
Average KL loss: 0.079438
Average total loss: 0.551190
tensor(0.0145, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.3150e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.452276
Average KL loss: 0.079768
Average total loss: 0.532044
tensor(0.0145, device='cuda:0') tensor(0.0073, device='cuda:0') tensor(-4.2083e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.464076
Average KL loss: 0.080050
Average total loss: 0.544126
tensor(0.0145, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-3.5555e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.464545
Average KL loss: 0.080367
Average total loss: 0.544912
tensor(0.0144, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.0544e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.449757
Average KL loss: 0.080678
Average total loss: 0.530436
tensor(0.0144, device='cuda:0') tensor(0.0074, device='cuda:0') tensor(-4.4379e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.452294
Average KL loss: 0.080972
Average total loss: 0.533266
tensor(0.0143, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-2.8747e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.441933
Average KL loss: 0.081198
Average total loss: 0.523131
tensor(0.0143, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-4.5823e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.449773
Average KL loss: 0.081411
Average total loss: 0.531185
tensor(0.0143, device='cuda:0') tensor(0.0075, device='cuda:0') tensor(-3.0371e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.440212
Average KL loss: 0.081643
Average total loss: 0.521855
tensor(0.0143, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-2.5917e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.443774
Average KL loss: 0.081916
Average total loss: 0.525690
tensor(0.0142, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3398e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.428434
Average KL loss: 0.082197
Average total loss: 0.510631
tensor(0.0142, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.3467e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.426404
Average KL loss: 0.082395
Average total loss: 0.508799
tensor(0.0142, device='cuda:0') tensor(0.0076, device='cuda:0') tensor(-3.1070e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.425947
Average KL loss: 0.082623
Average total loss: 0.508569
tensor(0.0141, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.9975e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.427178
Average KL loss: 0.082801
Average total loss: 0.509979
tensor(0.0141, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-3.9090e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.423838
Average KL loss: 0.082981
Average total loss: 0.506819
tensor(0.0141, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-5.1352e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.420452
Average KL loss: 0.083120
Average total loss: 0.503572
tensor(0.0140, device='cuda:0') tensor(0.0077, device='cuda:0') tensor(-2.8330e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.402290
Average KL loss: 0.083274
Average total loss: 0.485564
tensor(0.0140, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-3.1580e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.412566
Average KL loss: 0.083450
Average total loss: 0.496016
tensor(0.0140, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.9700e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.400773
Average KL loss: 0.083688
Average total loss: 0.484460
tensor(0.0140, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.7362e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.403252
Average KL loss: 0.083864
Average total loss: 0.487116
tensor(0.0139, device='cuda:0') tensor(0.0078, device='cuda:0') tensor(-2.6366e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.391061
Average KL loss: 0.084016
Average total loss: 0.475076
tensor(0.0139, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.7204e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.385494
Average KL loss: 0.084186
Average total loss: 0.469680
tensor(0.0139, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-3.1649e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.392792
Average KL loss: 0.084369
Average total loss: 0.477161
tensor(0.0139, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.7011e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.377376
Average KL loss: 0.084510
Average total loss: 0.461886
tensor(0.0139, device='cuda:0') tensor(0.0079, device='cuda:0') tensor(-2.4391e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.380392
Average KL loss: 0.084712
Average total loss: 0.465103
tensor(0.0139, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.9205e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.402481
Average KL loss: 0.084839
Average total loss: 0.487320
tensor(0.0138, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.0089e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.374847
Average KL loss: 0.084956
Average total loss: 0.459803
tensor(0.0138, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-3.2698e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.379406
Average KL loss: 0.085122
Average total loss: 0.464528
tensor(0.0138, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.8400e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.373934
Average KL loss: 0.085217
Average total loss: 0.459151
tensor(0.0137, device='cuda:0') tensor(0.0080, device='cuda:0') tensor(-2.4381e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.360221
Average KL loss: 0.085293
Average total loss: 0.445514
tensor(0.0137, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.2385e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.360231
Average KL loss: 0.085318
Average total loss: 0.445549
tensor(0.0137, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.4947e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.365651
Average KL loss: 0.085457
Average total loss: 0.451108
tensor(0.0137, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.4354e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.361530
Average KL loss: 0.085568
Average total loss: 0.447098
tensor(0.0136, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.5385e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.370440
Average KL loss: 0.085687
Average total loss: 0.456127
tensor(0.0136, device='cuda:0') tensor(0.0081, device='cuda:0') tensor(-2.9768e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.361510
Average KL loss: 0.085809
Average total loss: 0.447319
tensor(0.0136, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.0139e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.360664
Average KL loss: 0.085897
Average total loss: 0.446561
tensor(0.0136, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.8895e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.352142
Average KL loss: 0.086017
Average total loss: 0.438158
tensor(0.0136, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.7525e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.351799
Average KL loss: 0.086111
Average total loss: 0.437910
tensor(0.0135, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.6619e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.349072
Average KL loss: 0.086188
Average total loss: 0.435259
tensor(0.0135, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-3.4600e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.358982
Average KL loss: 0.086286
Average total loss: 0.445268
tensor(0.0135, device='cuda:0') tensor(0.0082, device='cuda:0') tensor(-2.3503e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.349766
Average KL loss: 0.086410
Average total loss: 0.436177
tensor(0.0135, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.3787e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.357296
Average KL loss: 0.086537
Average total loss: 0.443834
tensor(0.0135, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.1356e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.336757
Average KL loss: 0.086616
Average total loss: 0.423374
tensor(0.0135, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.5149e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.342288
Average KL loss: 0.086672
Average total loss: 0.428959
tensor(0.0134, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-1.7089e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.336000
Average KL loss: 0.086741
Average total loss: 0.422741
tensor(0.0134, device='cuda:0') tensor(0.0083, device='cuda:0') tensor(-2.6736e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.348549
Average KL loss: 0.086780
Average total loss: 0.435329
tensor(0.0134, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.4043e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.351121
Average KL loss: 0.086920
Average total loss: 0.438040
tensor(0.0134, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.4416e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.339376
Average KL loss: 0.087027
Average total loss: 0.426403
tensor(0.0134, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.0446e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.328186
Average KL loss: 0.087128
Average total loss: 0.415315
tensor(0.0134, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-1.6693e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.331815
Average KL loss: 0.087207
Average total loss: 0.419022
tensor(0.0133, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-3.1925e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.328496
Average KL loss: 0.087299
Average total loss: 0.415795
tensor(0.0133, device='cuda:0') tensor(0.0084, device='cuda:0') tensor(-2.2597e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.337184
Average KL loss: 0.087343
Average total loss: 0.424526
tensor(0.0133, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.2961e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.333744
Average KL loss: 0.087442
Average total loss: 0.421186
tensor(0.0133, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.5044e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.328987
Average KL loss: 0.087479
Average total loss: 0.416467
tensor(0.0133, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-1.4281e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.327796
Average KL loss: 0.087533
Average total loss: 0.415329
tensor(0.0132, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-2.3735e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.308429
Average KL loss: 0.087545
Average total loss: 0.395974
tensor(0.0132, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.0439e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.323042
Average KL loss: 0.087559
Average total loss: 0.410601
tensor(0.0132, device='cuda:0') tensor(0.0085, device='cuda:0') tensor(-3.2668e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.311756
Average KL loss: 0.087619
Average total loss: 0.399375
tensor(0.0132, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.7644e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.313641
Average KL loss: 0.087681
Average total loss: 0.401322
tensor(0.0132, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.3975e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.320197
Average KL loss: 0.087738
Average total loss: 0.407935
tensor(0.0132, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-1.7768e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.305158
Average KL loss: 0.087743
Average total loss: 0.392900
tensor(0.0132, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.6205e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.318469
Average KL loss: 0.087786
Average total loss: 0.406255
tensor(0.0131, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.2514e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.311475
Average KL loss: 0.087854
Average total loss: 0.399330
tensor(0.0131, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-3.6185e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.312017
Average KL loss: 0.087907
Average total loss: 0.399924
tensor(0.0131, device='cuda:0') tensor(0.0086, device='cuda:0') tensor(-2.0686e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.303519
Average KL loss: 0.087954
Average total loss: 0.391474
tensor(0.0131, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.0028e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.300092
Average KL loss: 0.087941
Average total loss: 0.388033
tensor(0.0131, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.2855e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.295788
Average KL loss: 0.087941
Average total loss: 0.383729
tensor(0.0131, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.8756e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.302937
Average KL loss: 0.088002
Average total loss: 0.390938
tensor(0.0131, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-2.4126e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.304984
Average KL loss: 0.088036
Average total loss: 0.393020
tensor(0.0131, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.6622e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.298670
Average KL loss: 0.088050
Average total loss: 0.386720
tensor(0.0130, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.2410e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.304052
Average KL loss: 0.088091
Average total loss: 0.392143
tensor(0.0130, device='cuda:0') tensor(0.0087, device='cuda:0') tensor(-1.3704e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.294100
Average KL loss: 0.088152
Average total loss: 0.382251
tensor(0.0130, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-2.8125e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.302608
Average KL loss: 0.088200
Average total loss: 0.390808
tensor(0.0130, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.7947e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.299645
Average KL loss: 0.088231
Average total loss: 0.387876
tensor(0.0130, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.7043e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.292100
Average KL loss: 0.088242
Average total loss: 0.380342
tensor(0.0130, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-2.0974e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.296293
Average KL loss: 0.088295
Average total loss: 0.384588
tensor(0.0130, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.7212e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.296732
Average KL loss: 0.088341
Average total loss: 0.385073
tensor(0.0130, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-8.6638e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.293386
Average KL loss: 0.088410
Average total loss: 0.381795
tensor(0.0130, device='cuda:0') tensor(0.0088, device='cuda:0') tensor(-1.0253e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.286100
Average KL loss: 0.088449
Average total loss: 0.374549
tensor(0.0129, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.4068e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.292704
Average KL loss: 0.088452
Average total loss: 0.381156
tensor(0.0129, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-9.8254e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.283003
Average KL loss: 0.088463
Average total loss: 0.371467
tensor(0.0129, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-2.1514e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.283913
Average KL loss: 0.088446
Average total loss: 0.372358
tensor(0.0129, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.5775e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.287563
Average KL loss: 0.088491
Average total loss: 0.376054
tensor(0.0129, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-8.3675e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.290089
Average KL loss: 0.088552
Average total loss: 0.378642
tensor(0.0129, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-9.7233e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.287150
Average KL loss: 0.088546
Average total loss: 0.375696
tensor(0.0129, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.8324e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.277427
Average KL loss: 0.088534
Average total loss: 0.365960
tensor(0.0128, device='cuda:0') tensor(0.0089, device='cuda:0') tensor(-1.2654e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.277956
Average KL loss: 0.088523
Average total loss: 0.366479
tensor(0.0128, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-8.5576e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.274811
Average KL loss: 0.088550
Average total loss: 0.363361
tensor(0.0128, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.0636e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.280859
Average KL loss: 0.088584
Average total loss: 0.369443
tensor(0.0128, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.3259e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.279330
Average KL loss: 0.088629
Average total loss: 0.367959
tensor(0.0128, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.2683e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.267993
Average KL loss: 0.088619
Average total loss: 0.356611
tensor(0.0128, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.2573e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.268136
Average KL loss: 0.088599
Average total loss: 0.356735
tensor(0.0128, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.3850e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.270792
Average KL loss: 0.088570
Average total loss: 0.359361
tensor(0.0128, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.5388e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.269553
Average KL loss: 0.088563
Average total loss: 0.358116
tensor(0.0128, device='cuda:0') tensor(0.0090, device='cuda:0') tensor(-1.9647e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.280122
Average KL loss: 0.088575
Average total loss: 0.368697
tensor(0.0128, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.1979e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.271219
Average KL loss: 0.088634
Average total loss: 0.359854
tensor(0.0128, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.1292e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.278936
Average KL loss: 0.088663
Average total loss: 0.367599
tensor(0.0128, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.3385e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.267742
Average KL loss: 0.088691
Average total loss: 0.356433
tensor(0.0127, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.0085e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.269010
Average KL loss: 0.088706
Average total loss: 0.357716
tensor(0.0127, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.7836e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.268117
Average KL loss: 0.088713
Average total loss: 0.356831
tensor(0.0127, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-1.0280e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.270432
Average KL loss: 0.088765
Average total loss: 0.359197
tensor(0.0127, device='cuda:0') tensor(0.0091, device='cuda:0') tensor(-9.4791e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.262510
Average KL loss: 0.088799
Average total loss: 0.351309
tensor(0.0127, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-9.0939e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.261662
Average KL loss: 0.088777
Average total loss: 0.350439
tensor(0.0127, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-2.2444e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.255108
Average KL loss: 0.088737
Average total loss: 0.343845
tensor(0.0127, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.2662e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.255510
Average KL loss: 0.088712
Average total loss: 0.344222
tensor(0.0127, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.4582e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.259212
Average KL loss: 0.088704
Average total loss: 0.347916
tensor(0.0127, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.1913e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.256883
Average KL loss: 0.088702
Average total loss: 0.345586
tensor(0.0127, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-7.0961e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.259729
Average KL loss: 0.088722
Average total loss: 0.348451
tensor(0.0127, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-8.7870e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.259505
Average KL loss: 0.088688
Average total loss: 0.348193
tensor(0.0126, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.9915e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.257815
Average KL loss: 0.088673
Average total loss: 0.346488
tensor(0.0126, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-1.0822e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.252864
Average KL loss: 0.088688
Average total loss: 0.341552
tensor(0.0126, device='cuda:0') tensor(0.0092, device='cuda:0') tensor(-2.6397e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.254126
Average KL loss: 0.088691
Average total loss: 0.342817
tensor(0.0126, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.7243e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.253203
Average KL loss: 0.088702
Average total loss: 0.341905
tensor(0.0126, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-9.6780e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.253877
Average KL loss: 0.088713
Average total loss: 0.342590
tensor(0.0126, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.2494e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.251471
Average KL loss: 0.088724
Average total loss: 0.340195
tensor(0.0126, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.2911e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.258173
Average KL loss: 0.088710
Average total loss: 0.346882
tensor(0.0126, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.4759e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.248449
Average KL loss: 0.088709
Average total loss: 0.337159
tensor(0.0126, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-8.0684e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.247510
Average KL loss: 0.088708
Average total loss: 0.336218
tensor(0.0126, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-1.0172e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.242097
Average KL loss: 0.088697
Average total loss: 0.330795
tensor(0.0126, device='cuda:0') tensor(0.0093, device='cuda:0') tensor(-8.1475e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.243844
Average KL loss: 0.088682
Average total loss: 0.332526
tensor(0.0126, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-5.0476e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.255100
Average KL loss: 0.088669
Average total loss: 0.343769
tensor(0.0125, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.8933e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.242213
Average KL loss: 0.088655
Average total loss: 0.330869
tensor(0.0125, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-8.8616e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.248342
Average KL loss: 0.088596
Average total loss: 0.336938
tensor(0.0125, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-6.8354e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.249047
Average KL loss: 0.088607
Average total loss: 0.337654
tensor(0.0125, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.3120e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.244164
Average KL loss: 0.088598
Average total loss: 0.332762
tensor(0.0125, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.5154e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.243714
Average KL loss: 0.088608
Average total loss: 0.332322
tensor(0.0125, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.8497e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.237612
Average KL loss: 0.088576
Average total loss: 0.326188
tensor(0.0125, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-9.2963e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.235094
Average KL loss: 0.088521
Average total loss: 0.323615
tensor(0.0125, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-1.1703e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.243918
Average KL loss: 0.088491
Average total loss: 0.332409
tensor(0.0125, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-9.4385e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.234702
Average KL loss: 0.088488
Average total loss: 0.323189
tensor(0.0124, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.1606e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.240049
Average KL loss: 0.088470
Average total loss: 0.328520
tensor(0.0124, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.4759e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.238901
Average KL loss: 0.088475
Average total loss: 0.327377
tensor(0.0124, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.2117e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.236139
Average KL loss: 0.088497
Average total loss: 0.324636
tensor(0.0124, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.2044e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.237295
Average KL loss: 0.088484
Average total loss: 0.325779
tensor(0.0124, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.5245e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.238292
Average KL loss: 0.088483
Average total loss: 0.326775
tensor(0.0124, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-1.7678e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.234352
Average KL loss: 0.088515
Average total loss: 0.322867
tensor(0.0124, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-7.8108e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.234405
Average KL loss: 0.088490
Average total loss: 0.322894
tensor(0.0124, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-7.3774e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.232881
Average KL loss: 0.088500
Average total loss: 0.321381
tensor(0.0124, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-6.7651e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.227769
Average KL loss: 0.088464
Average total loss: 0.316234
tensor(0.0124, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.0807e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.240073
Average KL loss: 0.088463
Average total loss: 0.328536
tensor(0.0124, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-7.8866e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.228561
Average KL loss: 0.088450
Average total loss: 0.317012
tensor(0.0124, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.9416e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.234447
Average KL loss: 0.088449
Average total loss: 0.322896
tensor(0.0124, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-9.7450e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.229662
Average KL loss: 0.088456
Average total loss: 0.318118
tensor(0.0124, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-4.6982e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.227730
Average KL loss: 0.088420
Average total loss: 0.316150
tensor(0.0124, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.7546e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.223634
Average KL loss: 0.088395
Average total loss: 0.312028
tensor(0.0124, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-1.0416e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.233313
Average KL loss: 0.088378
Average total loss: 0.321691
tensor(0.0124, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-5.2975e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.222182
Average KL loss: 0.088344
Average total loss: 0.310526
tensor(0.0123, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-5.7920e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.224076
Average KL loss: 0.088349
Average total loss: 0.312425
tensor(0.0123, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-5.4903e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.226671
Average KL loss: 0.088310
Average total loss: 0.314981
tensor(0.0123, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.1953e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.230444
Average KL loss: 0.088321
Average total loss: 0.318765
tensor(0.0123, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.1527e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.223253
Average KL loss: 0.088334
Average total loss: 0.311587
tensor(0.0123, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-4.3538e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.225701
Average KL loss: 0.088315
Average total loss: 0.314016
tensor(0.0123, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-9.4568e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.222873
Average KL loss: 0.088327
Average total loss: 0.311200
tensor(0.0123, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-6.9965e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.222705
Average KL loss: 0.088315
Average total loss: 0.311020
tensor(0.0123, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-9.5413e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.221863
Average KL loss: 0.088261
Average total loss: 0.310124
tensor(0.0123, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.0554e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.219612
Average KL loss: 0.088229
Average total loss: 0.307841
tensor(0.0123, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.2526e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.224711
Average KL loss: 0.088199
Average total loss: 0.312910
tensor(0.0123, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.3241e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.226314
Average KL loss: 0.088217
Average total loss: 0.314531
tensor(0.0123, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-4.9207e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.218908
Average KL loss: 0.088237
Average total loss: 0.307145
tensor(0.0123, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-9.2424e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.218462
Average KL loss: 0.088195
Average total loss: 0.306657
tensor(0.0123, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-8.2918e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.218479
Average KL loss: 0.088176
Average total loss: 0.306656
tensor(0.0123, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-4.0138e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.219337
Average KL loss: 0.088155
Average total loss: 0.307492
tensor(0.0123, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-5.3503e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.217167
Average KL loss: 0.088156
Average total loss: 0.305323
tensor(0.0122, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.0864e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.215911
Average KL loss: 0.088122
Average total loss: 0.304033
tensor(0.0122, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-9.5999e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.209433
Average KL loss: 0.088106
Average total loss: 0.297539
tensor(0.0122, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-9.2889e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.216884
Average KL loss: 0.088059
Average total loss: 0.304943
tensor(0.0122, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.1437e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.219333
Average KL loss: 0.088060
Average total loss: 0.307392
tensor(0.0122, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-7.0768e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.206943
Average KL loss: 0.088050
Average total loss: 0.294993
tensor(0.0122, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-8.8373e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.215647
Average KL loss: 0.088004
Average total loss: 0.303652
tensor(0.0122, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-7.9075e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.210480
Average KL loss: 0.087963
Average total loss: 0.298444
tensor(0.0122, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-8.6455e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.208518
Average KL loss: 0.087914
Average total loss: 0.296432
tensor(0.0122, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-7.9479e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.209023
Average KL loss: 0.087869
Average total loss: 0.296892
tensor(0.0122, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-6.7641e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.213242
Average KL loss: 0.087846
Average total loss: 0.301088
tensor(0.0121, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.3070e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.212608
Average KL loss: 0.087834
Average total loss: 0.300442
tensor(0.0121, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-6.9846e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.205566
Average KL loss: 0.087826
Average total loss: 0.293392
tensor(0.0122, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-3.5756e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.205403
Average KL loss: 0.087833
Average total loss: 0.293236
tensor(0.0121, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-7.4075e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.210546
Average KL loss: 0.087798
Average total loss: 0.298344
tensor(0.0121, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-5.0474e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.212529
Average KL loss: 0.087795
Average total loss: 0.300325
tensor(0.0121, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.7977e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.207104
Average KL loss: 0.087781
Average total loss: 0.294886
tensor(0.0121, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-3.9750e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.205236
Average KL loss: 0.087730
Average total loss: 0.292966
 Percentile value: 0.01574932597577572
Non-zero model percentage: 25.000003814697266%, Non-zero mask percentage: 25.000003814697266%

--- Pruning Level [2/12]: ---
conv1.weight         | nonzeros =     313 /    1728             ( 18.11%) | total_pruned =    1415 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
bn1.bias             | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =    2254 /   36864             (  6.11%) | total_pruned =   34610 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      49 /      64             ( 76.56%) | total_pruned =      15 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    6549 /   36864             ( 17.77%) | total_pruned =   30315 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      47 /      64             ( 73.44%) | total_pruned =      17 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    6756 /   36864             ( 18.33%) | total_pruned =   30108 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      58 /      64             ( 90.62%) | total_pruned =       6 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    8875 /   36864             ( 24.07%) | total_pruned =   27989 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      53 /      64             ( 82.81%) | total_pruned =      11 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   22550 /   73728             ( 30.59%) | total_pruned =   51178 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     121 /     128             ( 94.53%) | total_pruned =       7 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      40 /     128             ( 31.25%) | total_pruned =      88 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   45869 /  147456             ( 31.11%) | total_pruned =  101587 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     123 /     128             ( 96.09%) | total_pruned =       5 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    3012 /    8192             ( 36.77%) | total_pruned =    5180 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     111 /     128             ( 86.72%) | total_pruned =      17 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   32259 /  147456             ( 21.88%) | total_pruned =  115197 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   28839 /  147456             ( 19.56%) | total_pruned =  118617 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     110 /     128             ( 85.94%) | total_pruned =      18 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   95666 /  294912             ( 32.44%) | total_pruned =  199246 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     254 /     256             ( 99.22%) | total_pruned =       2 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  185090 /  589824             ( 31.38%) | total_pruned =  404734 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     255 /     256             ( 99.61%) | total_pruned =       1 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =   11272 /   32768             ( 34.40%) | total_pruned =   21496 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     236 /     256             ( 92.19%) | total_pruned =      20 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =  152372 /  589824             ( 25.83%) | total_pruned =  437452 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =  138728 /  589824             ( 23.52%) | total_pruned =  451096 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  333773 / 1179648             ( 28.29%) | total_pruned =  845875 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     496 /     512             ( 96.88%) | total_pruned =      16 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  546875 / 2359296             ( 23.18%) | total_pruned = 1812421 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     482 /     512             ( 94.14%) | total_pruned =      30 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     208 /     512             ( 40.62%) | total_pruned =     304 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =   28006 /  131072             ( 21.37%) | total_pruned =  103066 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     450 /     512             ( 87.89%) | total_pruned =      62 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     201 /     512             ( 39.26%) | total_pruned =     311 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  433765 / 2359296             ( 18.39%) | total_pruned = 1925531 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     500 /     512             ( 97.66%) | total_pruned =      12 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  701257 / 2359296             ( 29.72%) | total_pruned = 1658039 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     505 /     512             ( 98.63%) | total_pruned =       7 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     503 /     512             ( 98.24%) | total_pruned =       9 | shape = torch.Size([512])
linear.weight        | nonzeros =    4913 /    5120             ( 95.96%) | total_pruned =     207 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 2794691, pruned : 8384071, total: 11178762, Compression rate :       4.00x  ( 75.00% pruned)
Train Epoch: 51/100 Loss: 0.014984 Accuracy: 89.58 100.00 % Best test Accuracy: 89.59%
tensor(0.0121, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-5.3414e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.433325
Average KL loss: 0.085020
Average total loss: 0.518345
tensor(0.0131, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-6.1609e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.409053
Average KL loss: 0.082606
Average total loss: 0.491659
tensor(0.0135, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-4.7659e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.412103
Average KL loss: 0.081659
Average total loss: 0.493762
tensor(0.0137, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-4.1871e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.387443
Average KL loss: 0.081313
Average total loss: 0.468756
tensor(0.0138, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-3.9975e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.379442
Average KL loss: 0.081263
Average total loss: 0.460705
tensor(0.0139, device='cuda:0') tensor(0.0094, device='cuda:0') tensor(-4.0913e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.384705
Average KL loss: 0.081329
Average total loss: 0.466033
tensor(0.0139, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.7326e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.365037
Average KL loss: 0.081500
Average total loss: 0.446537
tensor(0.0139, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.1993e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.370326
Average KL loss: 0.081699
Average total loss: 0.452025
tensor(0.0139, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.3480e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.357899
Average KL loss: 0.081910
Average total loss: 0.439810
tensor(0.0139, device='cuda:0') tensor(0.0095, device='cuda:0') tensor(-3.6844e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.340591
Average KL loss: 0.082137
Average total loss: 0.422728
tensor(0.0138, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-2.9706e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.351543
Average KL loss: 0.082360
Average total loss: 0.433903
tensor(0.0138, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-2.7874e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.340155
Average KL loss: 0.082606
Average total loss: 0.422761
tensor(0.0138, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-3.2410e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.335400
Average KL loss: 0.082854
Average total loss: 0.418254
tensor(0.0138, device='cuda:0') tensor(0.0096, device='cuda:0') tensor(-5.6399e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.331595
Average KL loss: 0.083087
Average total loss: 0.414682
tensor(0.0137, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-2.5578e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.325316
Average KL loss: 0.083303
Average total loss: 0.408619
tensor(0.0137, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-2.3248e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.328911
Average KL loss: 0.083530
Average total loss: 0.412441
tensor(0.0137, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-2.8980e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.328874
Average KL loss: 0.083783
Average total loss: 0.412656
tensor(0.0137, device='cuda:0') tensor(0.0097, device='cuda:0') tensor(-1.5019e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.325293
Average KL loss: 0.084020
Average total loss: 0.409313
tensor(0.0136, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-1.6285e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.317324
Average KL loss: 0.084247
Average total loss: 0.401571
tensor(0.0136, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-3.0166e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.321784
Average KL loss: 0.084422
Average total loss: 0.406206
tensor(0.0136, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-2.1633e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.308942
Average KL loss: 0.084647
Average total loss: 0.393588
tensor(0.0135, device='cuda:0') tensor(0.0098, device='cuda:0') tensor(-2.8105e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.311989
Average KL loss: 0.084821
Average total loss: 0.396810
tensor(0.0135, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.1795e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.315130
Average KL loss: 0.085024
Average total loss: 0.400154
tensor(0.0135, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-2.4103e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.308923
Average KL loss: 0.085260
Average total loss: 0.394183
tensor(0.0135, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-2.2815e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.300672
Average KL loss: 0.085490
Average total loss: 0.386162
tensor(0.0134, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-1.5435e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.295849
Average KL loss: 0.085608
Average total loss: 0.381456
tensor(0.0134, device='cuda:0') tensor(0.0099, device='cuda:0') tensor(-2.0041e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.299652
Average KL loss: 0.085777
Average total loss: 0.385429
tensor(0.0134, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-9.3812e-09, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.302597
Average KL loss: 0.085980
Average total loss: 0.388576
tensor(0.0134, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.7197e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.292337
Average KL loss: 0.086186
Average total loss: 0.378523
tensor(0.0133, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.3097e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.289044
Average KL loss: 0.086304
Average total loss: 0.375348
tensor(0.0133, device='cuda:0') tensor(0.0100, device='cuda:0') tensor(-1.8599e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.288507
Average KL loss: 0.086422
Average total loss: 0.374929
tensor(0.0133, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.1227e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.291560
Average KL loss: 0.086595
Average total loss: 0.378154
tensor(0.0133, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.6179e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.293068
Average KL loss: 0.086743
Average total loss: 0.379810
tensor(0.0133, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-2.3362e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.284159
Average KL loss: 0.086885
Average total loss: 0.371044
tensor(0.0132, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.2787e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.284123
Average KL loss: 0.087033
Average total loss: 0.371156
tensor(0.0132, device='cuda:0') tensor(0.0101, device='cuda:0') tensor(-1.1610e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.286846
Average KL loss: 0.087193
Average total loss: 0.374039
tensor(0.0132, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-2.5688e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.274779
Average KL loss: 0.087302
Average total loss: 0.362081
tensor(0.0132, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.9144e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.278103
Average KL loss: 0.087426
Average total loss: 0.365529
tensor(0.0132, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.0915e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.280519
Average KL loss: 0.087549
Average total loss: 0.368068
tensor(0.0132, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-2.3046e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.283132
Average KL loss: 0.087711
Average total loss: 0.370843
tensor(0.0132, device='cuda:0') tensor(0.0102, device='cuda:0') tensor(-1.3696e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.273473
Average KL loss: 0.087844
Average total loss: 0.361317
tensor(0.0131, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.3654e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.274118
Average KL loss: 0.087963
Average total loss: 0.362081
tensor(0.0131, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-2.9000e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.277382
Average KL loss: 0.088060
Average total loss: 0.365441
tensor(0.0131, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.3536e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.277929
Average KL loss: 0.088190
Average total loss: 0.366119
tensor(0.0131, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-2.0762e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.267340
Average KL loss: 0.088292
Average total loss: 0.355632
tensor(0.0131, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.4732e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.273841
Average KL loss: 0.088424
Average total loss: 0.362265
tensor(0.0131, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.8341e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.266583
Average KL loss: 0.088533
Average total loss: 0.355116
tensor(0.0130, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.3847e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.272225
Average KL loss: 0.088654
Average total loss: 0.360878
tensor(0.0130, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.7140e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.263664
Average KL loss: 0.088756
Average total loss: 0.352420
tensor(0.0130, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.8749e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.268245
Average KL loss: 0.088824
Average total loss: 0.357069
tensor(0.0130, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.2979e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.260548
Average KL loss: 0.088930
Average total loss: 0.349478
tensor(0.0130, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.6386e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.265246
Average KL loss: 0.089045
Average total loss: 0.354291
tensor(0.0130, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.6538e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.265116
Average KL loss: 0.089177
Average total loss: 0.354293
tensor(0.0130, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-7.0020e-09, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.259856
Average KL loss: 0.089274
Average total loss: 0.349130
tensor(0.0130, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.2170e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.261096
Average KL loss: 0.089371
Average total loss: 0.350467
tensor(0.0129, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-8.4834e-09, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.260797
Average KL loss: 0.089471
Average total loss: 0.350268
tensor(0.0129, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.4145e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.258932
Average KL loss: 0.089568
Average total loss: 0.348500
tensor(0.0129, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.4919e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.258763
Average KL loss: 0.089670
Average total loss: 0.348433
tensor(0.0129, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-3.2398e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.262948
Average KL loss: 0.089757
Average total loss: 0.352705
tensor(0.0129, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.0015e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.257442
Average KL loss: 0.089880
Average total loss: 0.347323
tensor(0.0129, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.8588e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.256383
Average KL loss: 0.089965
Average total loss: 0.346348
tensor(0.0129, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.1782e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.250401
Average KL loss: 0.090045
Average total loss: 0.340445
tensor(0.0129, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-9.9068e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.255291
Average KL loss: 0.090120
Average total loss: 0.345412
tensor(0.0129, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.0684e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.253010
Average KL loss: 0.090216
Average total loss: 0.343227
tensor(0.0129, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-8.0124e-09, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.251258
Average KL loss: 0.090320
Average total loss: 0.341579
tensor(0.0129, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.3620e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.254233
Average KL loss: 0.090399
Average total loss: 0.344631
tensor(0.0128, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-7.2728e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.249988
Average KL loss: 0.090479
Average total loss: 0.340467
tensor(0.0128, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-8.3333e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.252205
Average KL loss: 0.090557
Average total loss: 0.342762
tensor(0.0128, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-7.6416e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.249266
Average KL loss: 0.090610
Average total loss: 0.339876
tensor(0.0128, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.1054e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.241426
Average KL loss: 0.090685
Average total loss: 0.332111
tensor(0.0128, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-8.5841e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.244324
Average KL loss: 0.090742
Average total loss: 0.335066
tensor(0.0128, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-8.4721e-09, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.251108
Average KL loss: 0.090829
Average total loss: 0.341937
tensor(0.0128, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.3527e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.240063
Average KL loss: 0.090917
Average total loss: 0.330979
tensor(0.0128, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.1882e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.248953
Average KL loss: 0.090990
Average total loss: 0.339943
tensor(0.0128, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.0688e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.252395
Average KL loss: 0.091097
Average total loss: 0.343492
tensor(0.0128, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.3809e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.244709
Average KL loss: 0.091188
Average total loss: 0.335898
tensor(0.0128, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.5692e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.250895
Average KL loss: 0.091285
Average total loss: 0.342180
tensor(0.0128, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.8301e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.243625
Average KL loss: 0.091397
Average total loss: 0.335022
tensor(0.0128, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.2150e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.244733
Average KL loss: 0.091487
Average total loss: 0.336220
tensor(0.0127, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.4883e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.236271
Average KL loss: 0.091567
Average total loss: 0.327838
tensor(0.0127, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-1.4238e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.238629
Average KL loss: 0.091618
Average total loss: 0.330247
tensor(0.0127, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.4414e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.243113
Average KL loss: 0.091723
Average total loss: 0.334835
tensor(0.0127, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.0427e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.242270
Average KL loss: 0.091795
Average total loss: 0.334065
tensor(0.0127, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.6825e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.236543
Average KL loss: 0.091844
Average total loss: 0.328387
tensor(0.0127, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.0323e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.237087
Average KL loss: 0.091878
Average total loss: 0.328965
tensor(0.0127, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.1162e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.245699
Average KL loss: 0.091908
Average total loss: 0.337607
tensor(0.0127, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-6.4913e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.232364
Average KL loss: 0.092002
Average total loss: 0.324366
tensor(0.0127, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.1684e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.238757
Average KL loss: 0.092045
Average total loss: 0.330802
tensor(0.0127, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.3532e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.236821
Average KL loss: 0.092154
Average total loss: 0.328975
tensor(0.0127, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.4855e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.226599
Average KL loss: 0.092223
Average total loss: 0.318822
tensor(0.0127, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-9.1605e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.230845
Average KL loss: 0.092252
Average total loss: 0.323096
tensor(0.0127, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-8.6771e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.234280
Average KL loss: 0.092310
Average total loss: 0.326590
tensor(0.0127, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.3268e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.233442
Average KL loss: 0.092379
Average total loss: 0.325821
tensor(0.0127, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.4804e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.235621
Average KL loss: 0.092456
Average total loss: 0.328076
tensor(0.0127, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-8.0471e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.233952
Average KL loss: 0.092466
Average total loss: 0.326418
tensor(0.0126, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-8.5938e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.227435
Average KL loss: 0.092530
Average total loss: 0.319965
tensor(0.0126, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-8.1244e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.229276
Average KL loss: 0.092573
Average total loss: 0.321849
tensor(0.0126, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.4719e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.225121
Average KL loss: 0.092609
Average total loss: 0.317730
tensor(0.0126, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-8.4853e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.222618
Average KL loss: 0.092643
Average total loss: 0.315261
tensor(0.0126, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.4351e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.234232
Average KL loss: 0.092706
Average total loss: 0.326938
tensor(0.0126, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.0532e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.226214
Average KL loss: 0.092782
Average total loss: 0.318996
tensor(0.0126, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-6.7342e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.228702
Average KL loss: 0.092834
Average total loss: 0.321535
tensor(0.0126, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.8570e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.222006
Average KL loss: 0.092918
Average total loss: 0.314924
tensor(0.0126, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-8.3354e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.227135
Average KL loss: 0.092949
Average total loss: 0.320084
tensor(0.0126, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-9.4939e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.219201
Average KL loss: 0.093007
Average total loss: 0.312208
tensor(0.0126, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-6.5191e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.220300
Average KL loss: 0.093037
Average total loss: 0.313337
tensor(0.0126, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.3160e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.220849
Average KL loss: 0.093066
Average total loss: 0.313915
tensor(0.0126, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.9571e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.226841
Average KL loss: 0.093113
Average total loss: 0.319954
tensor(0.0126, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-7.5995e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.222680
Average KL loss: 0.093160
Average total loss: 0.315840
tensor(0.0126, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-6.3620e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.222273
Average KL loss: 0.093209
Average total loss: 0.315481
tensor(0.0126, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-8.9450e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.220946
Average KL loss: 0.093236
Average total loss: 0.314182
tensor(0.0126, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.2530e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.225319
Average KL loss: 0.093287
Average total loss: 0.318607
tensor(0.0126, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.5465e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.219704
Average KL loss: 0.093329
Average total loss: 0.313033
tensor(0.0126, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-9.3191e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.218109
Average KL loss: 0.093364
Average total loss: 0.311474
tensor(0.0126, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-8.5836e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.222612
Average KL loss: 0.093410
Average total loss: 0.316022
tensor(0.0125, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-8.7972e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.219778
Average KL loss: 0.093439
Average total loss: 0.313217
tensor(0.0125, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.4033e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.216130
Average KL loss: 0.093462
Average total loss: 0.309593
tensor(0.0125, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-6.5375e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.219934
Average KL loss: 0.093499
Average total loss: 0.313433
tensor(0.0125, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-8.1593e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.216992
Average KL loss: 0.093559
Average total loss: 0.310551
tensor(0.0125, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-5.5138e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.217532
Average KL loss: 0.093626
Average total loss: 0.311157
tensor(0.0125, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-6.7289e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.217413
Average KL loss: 0.093674
Average total loss: 0.311087
tensor(0.0125, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-7.6626e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.217721
Average KL loss: 0.093711
Average total loss: 0.311432
tensor(0.0125, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-7.5664e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.224612
Average KL loss: 0.093762
Average total loss: 0.318373
tensor(0.0125, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-7.7897e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.213738
Average KL loss: 0.093829
Average total loss: 0.307567
tensor(0.0125, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-8.8042e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.213485
Average KL loss: 0.093857
Average total loss: 0.307341
tensor(0.0125, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-6.3525e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.211087
Average KL loss: 0.093871
Average total loss: 0.304958
tensor(0.0125, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-9.1729e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.214488
Average KL loss: 0.093916
Average total loss: 0.308404
tensor(0.0125, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.0480e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.207773
Average KL loss: 0.093927
Average total loss: 0.301700
tensor(0.0125, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-9.7000e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.211299
Average KL loss: 0.093961
Average total loss: 0.305260
tensor(0.0125, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.5394e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.217165
Average KL loss: 0.093999
Average total loss: 0.311165
tensor(0.0125, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-6.0506e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.206535
Average KL loss: 0.094058
Average total loss: 0.300593
tensor(0.0125, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-9.5939e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.212163
Average KL loss: 0.094118
Average total loss: 0.306281
tensor(0.0125, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.9468e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.211350
Average KL loss: 0.094142
Average total loss: 0.305492
tensor(0.0125, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-7.7911e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.210834
Average KL loss: 0.094161
Average total loss: 0.304995
tensor(0.0125, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-5.9985e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.208476
Average KL loss: 0.094210
Average total loss: 0.302686
tensor(0.0125, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.3091e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.208157
Average KL loss: 0.094264
Average total loss: 0.302421
tensor(0.0125, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-7.3909e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.202018
Average KL loss: 0.094274
Average total loss: 0.296292
tensor(0.0125, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.1939e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.207545
Average KL loss: 0.094292
Average total loss: 0.301837
tensor(0.0125, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.8376e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.205839
Average KL loss: 0.094308
Average total loss: 0.300147
tensor(0.0125, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.6111e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.207694
Average KL loss: 0.094331
Average total loss: 0.302025
tensor(0.0125, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-8.9560e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.204716
Average KL loss: 0.094363
Average total loss: 0.299080
tensor(0.0124, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-4.8690e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.205562
Average KL loss: 0.094375
Average total loss: 0.299938
tensor(0.0124, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-5.0636e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.204887
Average KL loss: 0.094393
Average total loss: 0.299280
tensor(0.0124, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-9.7408e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.205345
Average KL loss: 0.094411
Average total loss: 0.299756
tensor(0.0124, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-5.5540e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.205299
Average KL loss: 0.094444
Average total loss: 0.299743
tensor(0.0124, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.4059e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.198737
Average KL loss: 0.094436
Average total loss: 0.293173
tensor(0.0124, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-6.8542e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.202623
Average KL loss: 0.094450
Average total loss: 0.297073
tensor(0.0124, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-5.6289e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.209173
Average KL loss: 0.094510
Average total loss: 0.303683
tensor(0.0124, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.3356e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.203151
Average KL loss: 0.094561
Average total loss: 0.297713
tensor(0.0124, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-9.6889e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.201669
Average KL loss: 0.094584
Average total loss: 0.296254
tensor(0.0124, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-7.1495e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.202771
Average KL loss: 0.094589
Average total loss: 0.297360
tensor(0.0124, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.0246e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.203105
Average KL loss: 0.094613
Average total loss: 0.297718
tensor(0.0124, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.1434e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.199405
Average KL loss: 0.094618
Average total loss: 0.294022
tensor(0.0124, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-7.1600e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.200926
Average KL loss: 0.094604
Average total loss: 0.295530
tensor(0.0124, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-3.5272e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.205471
Average KL loss: 0.094614
Average total loss: 0.300085
tensor(0.0124, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-7.2231e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.197180
Average KL loss: 0.094650
Average total loss: 0.291830
tensor(0.0124, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-5.8748e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.205396
Average KL loss: 0.094681
Average total loss: 0.300077
tensor(0.0124, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-7.2406e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.201833
Average KL loss: 0.094740
Average total loss: 0.296573
tensor(0.0124, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-8.7347e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.194738
Average KL loss: 0.094783
Average total loss: 0.289521
tensor(0.0124, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-6.8015e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.195546
Average KL loss: 0.094787
Average total loss: 0.290333
tensor(0.0124, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-7.6517e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.196947
Average KL loss: 0.094821
Average total loss: 0.291767
tensor(0.0124, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-6.4454e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.192015
Average KL loss: 0.094824
Average total loss: 0.286839
tensor(0.0124, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-6.3665e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.195266
Average KL loss: 0.094801
Average total loss: 0.290067
tensor(0.0124, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-7.4729e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.195109
Average KL loss: 0.094821
Average total loss: 0.289929
tensor(0.0124, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-6.5418e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.199888
Average KL loss: 0.094862
Average total loss: 0.294750
tensor(0.0124, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-7.3126e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.194626
Average KL loss: 0.094886
Average total loss: 0.289511
tensor(0.0124, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.2387e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.197586
Average KL loss: 0.094901
Average total loss: 0.292487
tensor(0.0124, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.0447e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.198612
Average KL loss: 0.094921
Average total loss: 0.293533
tensor(0.0124, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-4.6510e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.198200
Average KL loss: 0.094940
Average total loss: 0.293140
tensor(0.0124, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-7.9175e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.189605
Average KL loss: 0.094964
Average total loss: 0.284570
tensor(0.0124, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-9.3822e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.195076
Average KL loss: 0.094957
Average total loss: 0.290033
tensor(0.0124, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-8.2795e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.191744
Average KL loss: 0.095000
Average total loss: 0.286745
tensor(0.0123, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.4111e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.188028
Average KL loss: 0.094998
Average total loss: 0.283026
tensor(0.0123, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-8.7319e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.194942
Average KL loss: 0.095002
Average total loss: 0.289944
tensor(0.0123, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-4.0424e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.196998
Average KL loss: 0.095040
Average total loss: 0.292038
tensor(0.0123, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-8.6695e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.190546
Average KL loss: 0.095090
Average total loss: 0.285635
tensor(0.0123, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(1.6243e-10, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.195102
Average KL loss: 0.095082
Average total loss: 0.290184
tensor(0.0123, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-7.1324e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.192053
Average KL loss: 0.095138
Average total loss: 0.287191
tensor(0.0123, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-5.5461e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.186717
Average KL loss: 0.095152
Average total loss: 0.281869
tensor(0.0123, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-7.0429e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.192414
Average KL loss: 0.095165
Average total loss: 0.287578
tensor(0.0123, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.8094e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.193027
Average KL loss: 0.095193
Average total loss: 0.288220
tensor(0.0123, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-6.6318e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.188713
Average KL loss: 0.095203
Average total loss: 0.283916
tensor(0.0123, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-7.7492e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.193040
Average KL loss: 0.095238
Average total loss: 0.288278
tensor(0.0123, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-7.8310e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.192248
Average KL loss: 0.095285
Average total loss: 0.287533
tensor(0.0123, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.0898e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.189532
Average KL loss: 0.095299
Average total loss: 0.284831
tensor(0.0123, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-7.7859e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.189322
Average KL loss: 0.095296
Average total loss: 0.284618
tensor(0.0123, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.5491e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.188866
Average KL loss: 0.095296
Average total loss: 0.284162
tensor(0.0123, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-6.7645e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.191371
Average KL loss: 0.095340
Average total loss: 0.286711
tensor(0.0123, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-7.5224e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.188443
Average KL loss: 0.095367
Average total loss: 0.283810
tensor(0.0123, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.7663e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.186644
Average KL loss: 0.095358
Average total loss: 0.282002
tensor(0.0123, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-3.8849e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.186888
Average KL loss: 0.095342
Average total loss: 0.282229
tensor(0.0123, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-3.6956e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.188154
Average KL loss: 0.095333
Average total loss: 0.283487
tensor(0.0123, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.5556e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.195517
Average KL loss: 0.095327
Average total loss: 0.290844
tensor(0.0123, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-7.5664e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.192443
Average KL loss: 0.095322
Average total loss: 0.287765
tensor(0.0123, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-4.1519e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.188534
Average KL loss: 0.095313
Average total loss: 0.283848
tensor(0.0123, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-5.5352e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.189921
Average KL loss: 0.095306
Average total loss: 0.285227
tensor(0.0123, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-7.2331e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.186523
Average KL loss: 0.095300
Average total loss: 0.281823
tensor(0.0123, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-6.9659e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.188093
Average KL loss: 0.095295
Average total loss: 0.283388
tensor(0.0123, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-5.0411e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.190131
Average KL loss: 0.095293
Average total loss: 0.285424
tensor(0.0123, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-4.9412e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.191278
Average KL loss: 0.095292
Average total loss: 0.286570
 Percentile value: 0.03811880014836788
Non-zero model percentage: 12.500005722045898%, Non-zero mask percentage: 12.500005722045898%

--- Pruning Level [3/12]: ---
conv1.weight         | nonzeros =     225 /    1728             ( 13.02%) | total_pruned =    1503 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
bn1.bias             | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     781 /   36864             (  2.12%) | total_pruned =   36083 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      31 /      64             ( 48.44%) | total_pruned =      33 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =    2168 /   36864             (  5.88%) | total_pruned =   34696 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    2787 /   36864             (  7.56%) | total_pruned =   34077 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    3829 /   36864             ( 10.39%) | total_pruned =   33035 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      38 /      64             ( 59.38%) | total_pruned =      26 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =   10819 /   73728             ( 14.67%) | total_pruned =   62909 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     109 /     128             ( 85.16%) | total_pruned =      19 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      26 /     128             ( 20.31%) | total_pruned =     102 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   25991 /  147456             ( 17.63%) | total_pruned =  121465 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     119 /     128             ( 92.97%) | total_pruned =       9 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =      11 /     128             (  8.59%) | total_pruned =     117 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1653 /    8192             ( 20.18%) | total_pruned =    6539 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =     102 /     128             ( 79.69%) | total_pruned =      26 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =   15956 /  147456             ( 10.82%) | total_pruned =  131500 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =   13911 /  147456             (  9.43%) | total_pruned =  133545 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   58341 /  294912             ( 19.78%) | total_pruned =  236571 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     249 /     256             ( 97.27%) | total_pruned =       7 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =  107329 /  589824             ( 18.20%) | total_pruned =  482495 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     252 /     256             ( 98.44%) | total_pruned =       4 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    6689 /   32768             ( 20.41%) | total_pruned =   26079 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     222 /     256             ( 86.72%) | total_pruned =      34 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      17 /     256             (  6.64%) | total_pruned =     239 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   77965 /  589824             ( 13.22%) | total_pruned =  511859 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     222 /     256             ( 86.72%) | total_pruned =      34 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   63691 /  589824             ( 10.80%) | total_pruned =  526133 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     226 /     256             ( 88.28%) | total_pruned =      30 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =  173544 / 1179648             ( 14.71%) | total_pruned = 1006104 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     483 /     512             ( 94.34%) | total_pruned =      29 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      31 /     512             (  6.05%) | total_pruned =     481 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  226771 / 2359296             (  9.61%) | total_pruned = 2132525 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     463 /     512             ( 90.43%) | total_pruned =      49 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     192 /     512             ( 37.50%) | total_pruned =     320 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    8493 /  131072             (  6.48%) | total_pruned =  122579 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     332 /     512             ( 64.84%) | total_pruned =     180 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     187 /     512             ( 36.52%) | total_pruned =     325 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =  183256 / 2359296             (  7.77%) | total_pruned = 2176040 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     397 /     512             ( 77.54%) | total_pruned =     115 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  403286 / 2359296             ( 17.09%) | total_pruned = 1956010 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     490 /     512             ( 95.70%) | total_pruned =      22 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     485 /     512             ( 94.73%) | total_pruned =      27 | shape = torch.Size([512])
linear.weight        | nonzeros =    4735 /    5120             ( 92.48%) | total_pruned =     385 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       3 /      10             ( 30.00%) | total_pruned =       7 | shape = torch.Size([10])
alive: 1397346, pruned : 9781416, total: 11178762, Compression rate :       8.00x  ( 87.50% pruned)
Train Epoch: 58/100 Loss: 0.014223 Accuracy: 89.06 100.00 % Best test Accuracy: 89.18%
tensor(0.0123, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-4.6783e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.392552
Average KL loss: 0.092917
Average total loss: 0.485469
tensor(0.0125, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-4.7101e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.376845
Average KL loss: 0.090431
Average total loss: 0.467276
tensor(0.0127, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-4.1574e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.378292
Average KL loss: 0.089135
Average total loss: 0.467428
tensor(0.0127, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.9945e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.355519
Average KL loss: 0.088369
Average total loss: 0.443888
tensor(0.0128, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.1440e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.349037
Average KL loss: 0.087893
Average total loss: 0.436931
tensor(0.0128, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.0099e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.341527
Average KL loss: 0.087627
Average total loss: 0.429154
tensor(0.0128, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.6151e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.328421
Average KL loss: 0.087464
Average total loss: 0.415885
tensor(0.0128, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.0559e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.331596
Average KL loss: 0.087378
Average total loss: 0.418974
tensor(0.0128, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.8255e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.328417
Average KL loss: 0.087326
Average total loss: 0.415743
tensor(0.0127, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.6364e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.322507
Average KL loss: 0.087314
Average total loss: 0.409821
tensor(0.0127, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.5519e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.321188
Average KL loss: 0.087365
Average total loss: 0.408553
tensor(0.0127, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.4685e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.322356
Average KL loss: 0.087450
Average total loss: 0.409806
tensor(0.0127, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.2549e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.306374
Average KL loss: 0.087537
Average total loss: 0.393910
tensor(0.0127, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.9028e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.305080
Average KL loss: 0.087604
Average total loss: 0.392684
tensor(0.0126, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.5388e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.305387
Average KL loss: 0.087692
Average total loss: 0.393079
tensor(0.0126, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.6598e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.308219
Average KL loss: 0.087794
Average total loss: 0.396013
tensor(0.0126, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.1486e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.299905
Average KL loss: 0.087898
Average total loss: 0.387804
tensor(0.0125, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.1830e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.296082
Average KL loss: 0.088026
Average total loss: 0.384109
tensor(0.0125, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.0294e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.291033
Average KL loss: 0.088140
Average total loss: 0.379173
tensor(0.0125, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.9348e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.291612
Average KL loss: 0.088236
Average total loss: 0.379848
tensor(0.0125, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.1041e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.288595
Average KL loss: 0.088360
Average total loss: 0.376956
tensor(0.0124, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.2283e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.281026
Average KL loss: 0.088479
Average total loss: 0.369505
tensor(0.0124, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.1447e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.285529
Average KL loss: 0.088571
Average total loss: 0.374099
tensor(0.0124, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.7447e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.283013
Average KL loss: 0.088691
Average total loss: 0.371704
tensor(0.0124, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.6933e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.282803
Average KL loss: 0.088826
Average total loss: 0.371629
tensor(0.0124, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.1816e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.283172
Average KL loss: 0.088965
Average total loss: 0.372137
tensor(0.0123, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.3503e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.274634
Average KL loss: 0.089098
Average total loss: 0.363732
tensor(0.0123, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.4914e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.279071
Average KL loss: 0.089219
Average total loss: 0.368290
tensor(0.0123, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.8748e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.276283
Average KL loss: 0.089354
Average total loss: 0.365637
tensor(0.0123, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.7864e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.272721
Average KL loss: 0.089480
Average total loss: 0.362201
tensor(0.0123, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.4587e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.270428
Average KL loss: 0.089623
Average total loss: 0.360052
tensor(0.0122, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.8220e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.272941
Average KL loss: 0.089757
Average total loss: 0.362698
tensor(0.0122, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.3906e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.267726
Average KL loss: 0.089852
Average total loss: 0.357577
tensor(0.0122, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.3401e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.266367
Average KL loss: 0.089937
Average total loss: 0.356304
tensor(0.0122, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.7616e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.261284
Average KL loss: 0.090050
Average total loss: 0.351334
tensor(0.0122, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.9985e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.268287
Average KL loss: 0.090188
Average total loss: 0.358475
tensor(0.0122, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.8535e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.262479
Average KL loss: 0.090329
Average total loss: 0.352808
tensor(0.0122, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.5049e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.266989
Average KL loss: 0.090437
Average total loss: 0.357425
tensor(0.0121, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.8912e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.258136
Average KL loss: 0.090535
Average total loss: 0.348671
tensor(0.0121, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.7351e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.256012
Average KL loss: 0.090635
Average total loss: 0.346647
tensor(0.0121, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.3851e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.257631
Average KL loss: 0.090723
Average total loss: 0.348353
tensor(0.0121, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.0540e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.259796
Average KL loss: 0.090828
Average total loss: 0.350624
tensor(0.0121, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-9.8546e-09, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.256913
Average KL loss: 0.090916
Average total loss: 0.347828
tensor(0.0121, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.5866e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.257037
Average KL loss: 0.091022
Average total loss: 0.348059
tensor(0.0121, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-9.3642e-09, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.253060
Average KL loss: 0.091145
Average total loss: 0.344205
tensor(0.0121, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.6490e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.250346
Average KL loss: 0.091260
Average total loss: 0.341606
tensor(0.0120, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-9.8754e-09, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.242361
Average KL loss: 0.091348
Average total loss: 0.333708
tensor(0.0120, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.1420e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.254026
Average KL loss: 0.091426
Average total loss: 0.345452
tensor(0.0120, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.4123e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.245590
Average KL loss: 0.091523
Average total loss: 0.337113
tensor(0.0120, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.5066e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.249450
Average KL loss: 0.091605
Average total loss: 0.341055
tensor(0.0120, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.2512e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.244716
Average KL loss: 0.091672
Average total loss: 0.336389
tensor(0.0120, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.4253e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.244742
Average KL loss: 0.091750
Average total loss: 0.336492
tensor(0.0120, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.9058e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.246892
Average KL loss: 0.091846
Average total loss: 0.338737
tensor(0.0120, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.2861e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.244691
Average KL loss: 0.091939
Average total loss: 0.336630
tensor(0.0120, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.3487e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.239032
Average KL loss: 0.092017
Average total loss: 0.331048
tensor(0.0119, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.0435e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.240137
Average KL loss: 0.092080
Average total loss: 0.332217
tensor(0.0119, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.1020e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.246845
Average KL loss: 0.092174
Average total loss: 0.339019
tensor(0.0119, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-7.1066e-09, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.243139
Average KL loss: 0.092302
Average total loss: 0.335440
tensor(0.0119, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.0090e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.235845
Average KL loss: 0.092396
Average total loss: 0.328241
tensor(0.0119, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.9473e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.243182
Average KL loss: 0.092487
Average total loss: 0.335669
tensor(0.0119, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.1624e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.241701
Average KL loss: 0.092577
Average total loss: 0.334278
tensor(0.0119, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.1369e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.240413
Average KL loss: 0.092666
Average total loss: 0.333079
tensor(0.0119, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.5236e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.237252
Average KL loss: 0.092752
Average total loss: 0.330004
tensor(0.0119, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-7.8742e-09, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.235093
Average KL loss: 0.092839
Average total loss: 0.327932
tensor(0.0119, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.0298e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.234213
Average KL loss: 0.092914
Average total loss: 0.327127
tensor(0.0119, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-8.5907e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.229647
Average KL loss: 0.093004
Average total loss: 0.322651
tensor(0.0119, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.5101e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.236769
Average KL loss: 0.093093
Average total loss: 0.329862
tensor(0.0119, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-6.3784e-09, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.233641
Average KL loss: 0.093175
Average total loss: 0.326816
tensor(0.0118, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-9.8863e-09, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.231389
Average KL loss: 0.093269
Average total loss: 0.324657
tensor(0.0118, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.0577e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.232979
Average KL loss: 0.093361
Average total loss: 0.326340
tensor(0.0118, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.0818e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.233271
Average KL loss: 0.093426
Average total loss: 0.326697
tensor(0.0118, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.1849e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.226070
Average KL loss: 0.093508
Average total loss: 0.319578
tensor(0.0118, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.4287e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.229743
Average KL loss: 0.093582
Average total loss: 0.323325
tensor(0.0118, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.0287e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.231243
Average KL loss: 0.093687
Average total loss: 0.324930
tensor(0.0118, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.1569e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.233043
Average KL loss: 0.093789
Average total loss: 0.326833
tensor(0.0118, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.0071e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.231229
Average KL loss: 0.093873
Average total loss: 0.325102
tensor(0.0118, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-7.2351e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.236800
Average KL loss: 0.093939
Average total loss: 0.330739
tensor(0.0118, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-9.3295e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.225819
Average KL loss: 0.094040
Average total loss: 0.319858
tensor(0.0118, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.5973e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.228830
Average KL loss: 0.094129
Average total loss: 0.322959
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-9.9968e-09, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.226387
Average KL loss: 0.094212
Average total loss: 0.320599
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-7.3006e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.228515
Average KL loss: 0.094280
Average total loss: 0.322795
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-7.7065e-09, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.226172
Average KL loss: 0.094365
Average total loss: 0.320537
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-8.8959e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.228873
Average KL loss: 0.094436
Average total loss: 0.323309
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-6.0387e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.228161
Average KL loss: 0.094477
Average total loss: 0.322638
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-8.8519e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.224096
Average KL loss: 0.094480
Average total loss: 0.318577
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-6.5387e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.229975
Average KL loss: 0.094483
Average total loss: 0.324458
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.0448e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.230022
Average KL loss: 0.094487
Average total loss: 0.324510
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.0188e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.225602
Average KL loss: 0.094492
Average total loss: 0.320094
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-9.0562e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.221298
Average KL loss: 0.094495
Average total loss: 0.315793
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-9.8956e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.224944
Average KL loss: 0.094498
Average total loss: 0.319442
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-5.9854e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.224468
Average KL loss: 0.094504
Average total loss: 0.318971
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.0683e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.224047
Average KL loss: 0.094507
Average total loss: 0.318555
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.5707e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.223097
Average KL loss: 0.094513
Average total loss: 0.317611
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-7.2692e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.221687
Average KL loss: 0.094519
Average total loss: 0.316206
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-8.8292e-09, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.222749
Average KL loss: 0.094525
Average total loss: 0.317275
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.9753e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.221401
Average KL loss: 0.094529
Average total loss: 0.315931
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-8.2921e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.226119
Average KL loss: 0.094534
Average total loss: 0.320653
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-8.4499e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.225450
Average KL loss: 0.094540
Average total loss: 0.319990
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.2614e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.222796
Average KL loss: 0.094545
Average total loss: 0.317341
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.1142e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.222477
Average KL loss: 0.094549
Average total loss: 0.317026
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.3963e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.225856
Average KL loss: 0.094551
Average total loss: 0.320407
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.1686e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.225478
Average KL loss: 0.094551
Average total loss: 0.320030
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.1389e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.223796
Average KL loss: 0.094551
Average total loss: 0.318348
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-5.3241e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.219285
Average KL loss: 0.094552
Average total loss: 0.313836
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-7.5817e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.219718
Average KL loss: 0.094552
Average total loss: 0.314270
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.1897e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.223057
Average KL loss: 0.094552
Average total loss: 0.317610
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.7745e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.225393
Average KL loss: 0.094553
Average total loss: 0.319946
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.1778e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.222229
Average KL loss: 0.094553
Average total loss: 0.316782
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.7905e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.220895
Average KL loss: 0.094553
Average total loss: 0.315448
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-5.2885e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.223890
Average KL loss: 0.094554
Average total loss: 0.318443
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.4387e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.224337
Average KL loss: 0.094554
Average total loss: 0.318891
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-5.3045e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.224573
Average KL loss: 0.094554
Average total loss: 0.319127
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-7.9568e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.226598
Average KL loss: 0.094555
Average total loss: 0.321153
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.0575e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.227507
Average KL loss: 0.094555
Average total loss: 0.322063
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.3552e-08, device='cuda:0')
 Percentile value: 0.09759176522493362
Non-zero model percentage: 6.250002861022949%, Non-zero mask percentage: 6.250002861022949%

--- Pruning Level [4/12]: ---
conv1.weight         | nonzeros =     173 /    1728             ( 10.01%) | total_pruned =    1555 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
bn1.bias             | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     383 /   36864             (  1.04%) | total_pruned =   36481 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     950 /   36864             (  2.58%) | total_pruned =   35914 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      32 /      64             ( 50.00%) | total_pruned =      32 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =    1245 /   36864             (  3.38%) | total_pruned =   35619 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      34 /      64             ( 53.12%) | total_pruned =      30 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1973 /   36864             (  5.35%) | total_pruned =   34891 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      36 /      64             ( 56.25%) | total_pruned =      28 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    6192 /   73728             (  8.40%) | total_pruned =   67536 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =     107 /     128             ( 83.59%) | total_pruned =      21 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      23 /     128             ( 17.97%) | total_pruned =     105 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =   15319 /  147456             ( 10.39%) | total_pruned =  132137 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     115 /     128             ( 89.84%) | total_pruned =      13 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       7 /     128             (  5.47%) | total_pruned =     121 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =    1023 /    8192             ( 12.49%) | total_pruned =    7169 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      89 /     128             ( 69.53%) | total_pruned =      39 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    8734 /  147456             (  5.92%) | total_pruned =  138722 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    7721 /  147456             (  5.24%) | total_pruned =  139735 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      97 /     128             ( 75.78%) | total_pruned =      31 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   36272 /  294912             ( 12.30%) | total_pruned =  258640 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     242 /     256             ( 94.53%) | total_pruned =      14 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   65987 /  589824             ( 11.19%) | total_pruned =  523837 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     247 /     256             ( 96.48%) | total_pruned =       9 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      19 /     256             (  7.42%) | total_pruned =     237 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    4254 /   32768             ( 12.98%) | total_pruned =   28514 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     204 /     256             ( 79.69%) | total_pruned =      52 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   41959 /  589824             (  7.11%) | total_pruned =  547865 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     207 /     256             ( 80.86%) | total_pruned =      49 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   32821 /  589824             (  5.56%) | total_pruned =  557003 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     202 /     256             ( 78.91%) | total_pruned =      54 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   92076 / 1179648             (  7.81%) | total_pruned = 1087572 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     472 /     512             ( 92.19%) | total_pruned =      40 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =  104614 / 2359296             (  4.43%) | total_pruned = 2254682 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     425 /     512             ( 83.01%) | total_pruned =      87 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     173 /     512             ( 33.79%) | total_pruned =     339 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =    2862 /  131072             (  2.18%) | total_pruned =  128210 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     249 /     512             ( 48.63%) | total_pruned =     263 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     169 /     512             ( 33.01%) | total_pruned =     343 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   79750 / 2359296             (  3.38%) | total_pruned = 2279546 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     335 /     512             ( 65.43%) | total_pruned =     177 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =      13 /     512             (  2.54%) | total_pruned =     499 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =  185489 / 2359296             (  7.86%) | total_pruned = 2173807 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     475 /     512             ( 92.77%) | total_pruned =      37 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     434 /     512             ( 84.77%) | total_pruned =      78 | shape = torch.Size([512])
linear.weight        | nonzeros =    4215 /    5120             ( 82.32%) | total_pruned =     905 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 698673, pruned : 10480089, total: 11178762, Compression rate :      16.00x  ( 93.75% pruned)
Train Epoch: 55/100 Loss: 0.021816 Accuracy: 88.85 100.00 % Best test Accuracy: 89.10%
tensor(0.0118, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-3.7490e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.393553
Average KL loss: 0.093013
Average total loss: 0.486566
tensor(0.0117, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-3.9398e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.376247
Average KL loss: 0.091614
Average total loss: 0.467861
tensor(0.0118, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-4.7329e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.376447
Average KL loss: 0.090944
Average total loss: 0.467391
tensor(0.0119, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.3919e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.354107
Average KL loss: 0.090570
Average total loss: 0.444677
tensor(0.0119, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.8869e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.354786
Average KL loss: 0.090364
Average total loss: 0.445150
tensor(0.0119, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.1754e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.364574
Average KL loss: 0.090286
Average total loss: 0.454861
tensor(0.0119, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.8877e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.349993
Average KL loss: 0.090275
Average total loss: 0.440268
tensor(0.0119, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.7525e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.343740
Average KL loss: 0.090307
Average total loss: 0.434047
tensor(0.0119, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.7091e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.341439
Average KL loss: 0.090412
Average total loss: 0.431851
tensor(0.0119, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.7980e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.339183
Average KL loss: 0.090510
Average total loss: 0.429693
tensor(0.0119, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.5465e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.336180
Average KL loss: 0.090633
Average total loss: 0.426813
tensor(0.0118, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.2824e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.330390
Average KL loss: 0.090747
Average total loss: 0.421137
tensor(0.0118, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.9442e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.323916
Average KL loss: 0.090889
Average total loss: 0.414805
tensor(0.0118, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.3558e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.319218
Average KL loss: 0.091036
Average total loss: 0.410254
tensor(0.0118, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.4432e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.318958
Average KL loss: 0.091168
Average total loss: 0.410126
tensor(0.0118, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.6097e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.320240
Average KL loss: 0.091288
Average total loss: 0.411528
tensor(0.0118, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.1223e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.308624
Average KL loss: 0.091425
Average total loss: 0.400049
tensor(0.0118, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.8561e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.306346
Average KL loss: 0.091565
Average total loss: 0.397911
tensor(0.0117, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.4564e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.311648
Average KL loss: 0.091687
Average total loss: 0.403335
tensor(0.0117, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.9673e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.309243
Average KL loss: 0.091814
Average total loss: 0.401057
tensor(0.0117, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.1583e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.295791
Average KL loss: 0.091952
Average total loss: 0.387743
tensor(0.0117, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.3069e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.301043
Average KL loss: 0.092097
Average total loss: 0.393140
tensor(0.0117, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.7558e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.299161
Average KL loss: 0.092237
Average total loss: 0.391398
tensor(0.0117, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.6068e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.301834
Average KL loss: 0.092365
Average total loss: 0.394199
tensor(0.0116, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-2.2414e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.286895
Average KL loss: 0.092481
Average total loss: 0.379377
tensor(0.0116, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.8861e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.291894
Average KL loss: 0.092589
Average total loss: 0.384483
tensor(0.0116, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.8930e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.292023
Average KL loss: 0.092688
Average total loss: 0.384711
tensor(0.0116, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.7080e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.295435
Average KL loss: 0.092811
Average total loss: 0.388246
tensor(0.0116, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.8153e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.292181
Average KL loss: 0.092963
Average total loss: 0.385144
tensor(0.0116, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.6190e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.289812
Average KL loss: 0.093082
Average total loss: 0.382894
tensor(0.0116, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.4864e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.289591
Average KL loss: 0.093193
Average total loss: 0.382783
tensor(0.0115, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.5370e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.284792
Average KL loss: 0.093314
Average total loss: 0.378106
tensor(0.0115, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.1828e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.290446
Average KL loss: 0.093454
Average total loss: 0.383900
tensor(0.0115, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.2991e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.283686
Average KL loss: 0.093564
Average total loss: 0.377250
tensor(0.0115, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.7669e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.275986
Average KL loss: 0.093661
Average total loss: 0.369647
tensor(0.0115, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.5981e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.280989
Average KL loss: 0.093737
Average total loss: 0.374726
tensor(0.0115, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.2660e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.283758
Average KL loss: 0.093845
Average total loss: 0.377603
tensor(0.0115, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.2359e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.276496
Average KL loss: 0.093975
Average total loss: 0.370471
tensor(0.0115, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.3538e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.278263
Average KL loss: 0.094095
Average total loss: 0.372358
tensor(0.0115, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.1279e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.274257
Average KL loss: 0.094196
Average total loss: 0.368454
tensor(0.0114, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.6911e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.279584
Average KL loss: 0.094301
Average total loss: 0.373885
tensor(0.0114, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.2974e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.271405
Average KL loss: 0.094404
Average total loss: 0.365809
tensor(0.0114, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.3925e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.280220
Average KL loss: 0.094509
Average total loss: 0.374728
tensor(0.0114, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.2847e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.273732
Average KL loss: 0.094626
Average total loss: 0.368359
tensor(0.0114, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.2722e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.266335
Average KL loss: 0.094725
Average total loss: 0.361060
tensor(0.0114, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.1093e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.270204
Average KL loss: 0.094836
Average total loss: 0.365040
tensor(0.0114, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.4987e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.268386
Average KL loss: 0.094936
Average total loss: 0.363322
tensor(0.0114, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.2427e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.273394
Average KL loss: 0.095038
Average total loss: 0.368432
tensor(0.0114, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.8637e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.270404
Average KL loss: 0.095162
Average total loss: 0.365567
tensor(0.0114, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.7879e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.268784
Average KL loss: 0.095288
Average total loss: 0.364072
tensor(0.0114, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.7671e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.266973
Average KL loss: 0.095383
Average total loss: 0.362356
tensor(0.0114, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-9.3010e-09, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.262641
Average KL loss: 0.095485
Average total loss: 0.358126
tensor(0.0114, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.4112e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.262306
Average KL loss: 0.095584
Average total loss: 0.357890
tensor(0.0113, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.6647e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.260975
Average KL loss: 0.095692
Average total loss: 0.356667
tensor(0.0113, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.3458e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.260433
Average KL loss: 0.095780
Average total loss: 0.356214
tensor(0.0113, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.3954e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.265882
Average KL loss: 0.095873
Average total loss: 0.361755
tensor(0.0113, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-7.5490e-09, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.255103
Average KL loss: 0.095961
Average total loss: 0.351064
tensor(0.0113, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.1078e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.260796
Average KL loss: 0.096063
Average total loss: 0.356859
tensor(0.0113, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.1866e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.257383
Average KL loss: 0.096142
Average total loss: 0.353525
tensor(0.0113, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.3199e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.259180
Average KL loss: 0.096227
Average total loss: 0.355407
tensor(0.0113, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-9.8811e-09, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.251400
Average KL loss: 0.096320
Average total loss: 0.347719
tensor(0.0113, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.3495e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.247188
Average KL loss: 0.096412
Average total loss: 0.343600
tensor(0.0113, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-9.8057e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.255054
Average KL loss: 0.096484
Average total loss: 0.351538
tensor(0.0113, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-1.3107e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.249497
Average KL loss: 0.096558
Average total loss: 0.346055
tensor(0.0113, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.1222e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.247286
Average KL loss: 0.096644
Average total loss: 0.343929
tensor(0.0113, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.3049e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.246440
Average KL loss: 0.096721
Average total loss: 0.343161
tensor(0.0113, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-8.0762e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.245175
Average KL loss: 0.096815
Average total loss: 0.341990
tensor(0.0112, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.5017e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.254230
Average KL loss: 0.096922
Average total loss: 0.351152
tensor(0.0112, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-1.1775e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.249968
Average KL loss: 0.097025
Average total loss: 0.346993
tensor(0.0112, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-9.2281e-09, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.246609
Average KL loss: 0.097123
Average total loss: 0.343731
tensor(0.0112, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-9.5285e-09, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.247502
Average KL loss: 0.097221
Average total loss: 0.344723
tensor(0.0112, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.3343e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.243401
Average KL loss: 0.097309
Average total loss: 0.340710
tensor(0.0112, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-9.9083e-09, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.244701
Average KL loss: 0.097395
Average total loss: 0.342096
tensor(0.0112, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-9.1728e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.243567
Average KL loss: 0.097492
Average total loss: 0.341059
tensor(0.0112, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.7586e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.237697
Average KL loss: 0.097596
Average total loss: 0.335293
tensor(0.0112, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-1.2175e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.239227
Average KL loss: 0.097694
Average total loss: 0.336921
tensor(0.0112, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-9.2798e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.245644
Average KL loss: 0.097801
Average total loss: 0.343445
tensor(0.0112, device='cuda:0') tensor(0.0130, device='cuda:0') tensor(-6.9400e-09, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.244941
Average KL loss: 0.097903
Average total loss: 0.342844
tensor(0.0112, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.1536e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.242078
Average KL loss: 0.098010
Average total loss: 0.340088
tensor(0.0112, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.1609e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.234697
Average KL loss: 0.098090
Average total loss: 0.332787
tensor(0.0112, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-6.6221e-09, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.237160
Average KL loss: 0.098177
Average total loss: 0.335337
tensor(0.0112, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.2263e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.233607
Average KL loss: 0.098259
Average total loss: 0.331867
tensor(0.0112, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-8.9117e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.235278
Average KL loss: 0.098332
Average total loss: 0.333610
tensor(0.0112, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-7.5500e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.234609
Average KL loss: 0.098396
Average total loss: 0.333005
tensor(0.0112, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-1.0166e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.236087
Average KL loss: 0.098492
Average total loss: 0.334579
tensor(0.0112, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.5254e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.240479
Average KL loss: 0.098593
Average total loss: 0.339072
tensor(0.0112, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.1947e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.234297
Average KL loss: 0.098684
Average total loss: 0.332981
tensor(0.0112, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-9.7699e-09, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.239028
Average KL loss: 0.098771
Average total loss: 0.337799
tensor(0.0112, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.0884e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.229599
Average KL loss: 0.098865
Average total loss: 0.328464
tensor(0.0112, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.2638e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.234933
Average KL loss: 0.098944
Average total loss: 0.333877
tensor(0.0112, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-9.4935e-09, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.229045
Average KL loss: 0.099040
Average total loss: 0.328084
tensor(0.0112, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-8.2991e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.230921
Average KL loss: 0.099123
Average total loss: 0.330044
tensor(0.0111, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.1975e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.226811
Average KL loss: 0.099200
Average total loss: 0.326010
tensor(0.0111, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-8.9376e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.235584
Average KL loss: 0.099283
Average total loss: 0.334867
tensor(0.0111, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.1735e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.228434
Average KL loss: 0.099367
Average total loss: 0.327800
tensor(0.0111, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-8.9969e-09, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.224736
Average KL loss: 0.099465
Average total loss: 0.324201
tensor(0.0111, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-8.6266e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.226376
Average KL loss: 0.099544
Average total loss: 0.325920
tensor(0.0111, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-9.2321e-09, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.223189
Average KL loss: 0.099621
Average total loss: 0.322810
tensor(0.0111, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.0591e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.226398
Average KL loss: 0.099663
Average total loss: 0.326061
tensor(0.0111, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-6.1875e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.224801
Average KL loss: 0.099743
Average total loss: 0.324545
tensor(0.0111, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-9.3930e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.225575
Average KL loss: 0.099830
Average total loss: 0.325405
tensor(0.0111, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-9.2033e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.229102
Average KL loss: 0.099908
Average total loss: 0.329010
tensor(0.0111, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-8.2307e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.225417
Average KL loss: 0.099996
Average total loss: 0.325413
tensor(0.0111, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.0868e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.220827
Average KL loss: 0.100074
Average total loss: 0.320901
tensor(0.0111, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.3562e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.227540
Average KL loss: 0.100156
Average total loss: 0.327696
tensor(0.0111, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-4.7793e-09, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.223010
Average KL loss: 0.100234
Average total loss: 0.323244
tensor(0.0111, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-9.2071e-09, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.223652
Average KL loss: 0.100307
Average total loss: 0.323959
tensor(0.0111, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-6.4884e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.224381
Average KL loss: 0.100376
Average total loss: 0.324756
tensor(0.0111, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-5.0172e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.225486
Average KL loss: 0.100458
Average total loss: 0.325944
tensor(0.0111, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.4281e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.221792
Average KL loss: 0.100547
Average total loss: 0.322338
tensor(0.0111, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.1575e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.222715
Average KL loss: 0.100632
Average total loss: 0.323347
tensor(0.0111, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-5.9235e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.220939
Average KL loss: 0.100705
Average total loss: 0.321644
tensor(0.0111, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-8.3242e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.223302
Average KL loss: 0.100770
Average total loss: 0.324072
tensor(0.0111, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-7.5933e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.219501
Average KL loss: 0.100858
Average total loss: 0.320359
tensor(0.0111, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-6.6391e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.218029
Average KL loss: 0.100940
Average total loss: 0.318969
tensor(0.0111, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-8.5951e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.220138
Average KL loss: 0.101005
Average total loss: 0.321142
tensor(0.0111, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.0310e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.213230
Average KL loss: 0.101069
Average total loss: 0.314299
tensor(0.0111, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.7626e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.220961
Average KL loss: 0.101151
Average total loss: 0.322112
tensor(0.0111, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-5.4645e-09, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.219057
Average KL loss: 0.101245
Average total loss: 0.320303
tensor(0.0111, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.0109e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.214056
Average KL loss: 0.101328
Average total loss: 0.315384
tensor(0.0111, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.2968e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.215303
Average KL loss: 0.101379
Average total loss: 0.316682
tensor(0.0111, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-5.0002e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.215012
Average KL loss: 0.101440
Average total loss: 0.316452
tensor(0.0111, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.1385e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.220008
Average KL loss: 0.101510
Average total loss: 0.321518
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.1743e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.224355
Average KL loss: 0.101592
Average total loss: 0.325946
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-6.4186e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.216451
Average KL loss: 0.101661
Average total loss: 0.318112
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-8.0877e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.217562
Average KL loss: 0.101744
Average total loss: 0.319306
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-7.7996e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.213249
Average KL loss: 0.101830
Average total loss: 0.315080
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-7.4476e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.212358
Average KL loss: 0.101916
Average total loss: 0.314274
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-9.1139e-09, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.212820
Average KL loss: 0.101951
Average total loss: 0.314772
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-9.9974e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.211576
Average KL loss: 0.101956
Average total loss: 0.313531
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.4437e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.211528
Average KL loss: 0.101960
Average total loss: 0.313488
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.8174e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.210169
Average KL loss: 0.101964
Average total loss: 0.312132
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-7.7713e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.213059
Average KL loss: 0.101968
Average total loss: 0.315027
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-4.6329e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.211356
Average KL loss: 0.101972
Average total loss: 0.313328
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.0249e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.211825
Average KL loss: 0.101977
Average total loss: 0.313802
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.0267e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.211305
Average KL loss: 0.101981
Average total loss: 0.313286
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-6.4602e-09, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.214134
Average KL loss: 0.101984
Average total loss: 0.316118
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-6.9933e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.208605
Average KL loss: 0.101988
Average total loss: 0.310593
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-6.0453e-09, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.210950
Average KL loss: 0.101993
Average total loss: 0.312943
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-7.9287e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.210642
Average KL loss: 0.101997
Average total loss: 0.312639
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-8.3719e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.211971
Average KL loss: 0.101999
Average total loss: 0.313970
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.2443e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.212237
Average KL loss: 0.102002
Average total loss: 0.314240
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-4.6808e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.213360
Average KL loss: 0.102008
Average total loss: 0.315368
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-6.5334e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.209957
Average KL loss: 0.102015
Average total loss: 0.311972
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-9.0088e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.216999
Average KL loss: 0.102022
Average total loss: 0.319021
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.2005e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.211032
Average KL loss: 0.102029
Average total loss: 0.313060
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.2421e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.214100
Average KL loss: 0.102035
Average total loss: 0.316135
tensor(0.0111, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-8.3042e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.214650
Average KL loss: 0.102042
Average total loss: 0.316691
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-4.4949e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.208390
Average KL loss: 0.102047
Average total loss: 0.310437
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-6.3731e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.217249
Average KL loss: 0.102051
Average total loss: 0.319300
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.0525e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.213649
Average KL loss: 0.102057
Average total loss: 0.315705
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-5.4658e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.207879
Average KL loss: 0.102063
Average total loss: 0.309942
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.8993e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.211915
Average KL loss: 0.102067
Average total loss: 0.313982
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.8709e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.212431
Average KL loss: 0.102072
Average total loss: 0.314504
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.0830e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.209331
Average KL loss: 0.102078
Average total loss: 0.311409
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.1204e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.212380
Average KL loss: 0.102084
Average total loss: 0.314463
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.3705e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.210596
Average KL loss: 0.102088
Average total loss: 0.312684
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.4656e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.209496
Average KL loss: 0.102092
Average total loss: 0.311588
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.4603e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.207212
Average KL loss: 0.102096
Average total loss: 0.309308
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.1300e-09, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.206544
Average KL loss: 0.102100
Average total loss: 0.308645
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.5992e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.210607
Average KL loss: 0.102104
Average total loss: 0.312711
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-5.5782e-09, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.215858
Average KL loss: 0.102109
Average total loss: 0.317967
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.7976e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.212814
Average KL loss: 0.102115
Average total loss: 0.314930
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-5.7538e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.213251
Average KL loss: 0.102121
Average total loss: 0.315372
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.4592e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.212985
Average KL loss: 0.102126
Average total loss: 0.315111
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.7135e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.212254
Average KL loss: 0.102130
Average total loss: 0.314384
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-6.2973e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.208161
Average KL loss: 0.102135
Average total loss: 0.310296
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.7508e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.212512
Average KL loss: 0.102140
Average total loss: 0.314653
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-5.3651e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.210571
Average KL loss: 0.102146
Average total loss: 0.312717
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.7811e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.209523
Average KL loss: 0.102152
Average total loss: 0.311675
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.7942e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.211621
Average KL loss: 0.102157
Average total loss: 0.313778
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.0034e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.211062
Average KL loss: 0.102160
Average total loss: 0.313222
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.5146e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.211191
Average KL loss: 0.102160
Average total loss: 0.313351
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.4720e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.212429
Average KL loss: 0.102160
Average total loss: 0.314590
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.2808e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.207488
Average KL loss: 0.102161
Average total loss: 0.309648
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.5183e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.209873
Average KL loss: 0.102161
Average total loss: 0.312035
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-3.6137e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.204261
Average KL loss: 0.102161
Average total loss: 0.306423
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.1228e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.210069
Average KL loss: 0.102162
Average total loss: 0.312231
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-5.4753e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.209515
Average KL loss: 0.102162
Average total loss: 0.311677
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.1153e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.217312
Average KL loss: 0.102163
Average total loss: 0.319475
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-6.5205e-09, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.213485
Average KL loss: 0.102163
Average total loss: 0.315648
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.1057e-09, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.213953
Average KL loss: 0.102164
Average total loss: 0.316116
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.4683e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.212007
Average KL loss: 0.102164
Average total loss: 0.314171
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-6.9894e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.210294
Average KL loss: 0.102164
Average total loss: 0.312458
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-6.1239e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.213306
Average KL loss: 0.102165
Average total loss: 0.315471
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.9109e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.209507
Average KL loss: 0.102165
Average total loss: 0.311672
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-6.6624e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.209128
Average KL loss: 0.102166
Average total loss: 0.311293
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.8061e-09, device='cuda:0')
 Percentile value: 0.21345239877700806
Non-zero model percentage: 3.1250059604644775%, Non-zero mask percentage: 3.1250059604644775%

--- Pruning Level [5/12]: ---
conv1.weight         | nonzeros =     143 /    1728             (  8.28%) | total_pruned =    1585 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
bn1.bias             | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     230 /   36864             (  0.62%) | total_pruned =   36634 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      19 /      64             ( 29.69%) | total_pruned =      45 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     457 /   36864             (  1.24%) | total_pruned =   36407 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      20 /      64             ( 31.25%) | total_pruned =      44 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     734 /   36864             (  1.99%) | total_pruned =   36130 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1431 /   36864             (  3.88%) | total_pruned =   35433 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      28 /      64             ( 43.75%) | total_pruned =      36 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    4065 /   73728             (  5.51%) | total_pruned =   69663 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      93 /     128             ( 72.66%) | total_pruned =      35 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      18 /     128             ( 14.06%) | total_pruned =     110 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    9680 /  147456             (  6.56%) | total_pruned =  137776 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     104 /     128             ( 81.25%) | total_pruned =      24 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     754 /    8192             (  9.20%) | total_pruned =    7438 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       8 /     128             (  6.25%) | total_pruned =     120 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    5612 /  147456             (  3.81%) | total_pruned =  141844 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      72 /     128             ( 56.25%) | total_pruned =      56 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    5081 /  147456             (  3.45%) | total_pruned =  142375 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   23884 /  294912             (  8.10%) | total_pruned =  271028 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     227 /     256             ( 88.67%) | total_pruned =      29 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   41378 /  589824             (  7.02%) | total_pruned =  548446 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     236 /     256             ( 92.19%) | total_pruned =      20 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      16 /     256             (  6.25%) | total_pruned =     240 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    2783 /   32768             (  8.49%) | total_pruned =   29985 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     191 /     256             ( 74.61%) | total_pruned =      65 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      13 /     256             (  5.08%) | total_pruned =     243 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   24292 /  589824             (  4.12%) | total_pruned =  565532 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     179 /     256             ( 69.92%) | total_pruned =      77 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   19192 /  589824             (  3.25%) | total_pruned =  570632 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     184 /     256             ( 71.88%) | total_pruned =      72 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       8 /     256             (  3.12%) | total_pruned =     248 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   50198 / 1179648             (  4.26%) | total_pruned = 1129450 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     439 /     512             ( 85.74%) | total_pruned =      73 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      18 /     512             (  3.52%) | total_pruned =     494 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   49077 / 2359296             (  2.08%) | total_pruned = 2310219 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     368 /     512             ( 71.88%) | total_pruned =     144 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     153 /     512             ( 29.88%) | total_pruned =     359 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     982 /  131072             (  0.75%) | total_pruned =  130090 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =     142 /     512             ( 27.73%) | total_pruned =     370 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     149 /     512             ( 29.10%) | total_pruned =     363 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   31864 / 2359296             (  1.35%) | total_pruned = 2327432 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     238 /     512             ( 46.48%) | total_pruned =     274 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   70029 / 2359296             (  2.97%) | total_pruned = 2289267 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     396 /     512             ( 77.34%) | total_pruned =     116 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     380 /     512             ( 74.22%) | total_pruned =     132 | shape = torch.Size([512])
linear.weight        | nonzeros =    3502 /    5120             ( 68.40%) | total_pruned =    1618 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 349337, pruned : 10829425, total: 11178762, Compression rate :      32.00x  ( 96.87% pruned)
Train Epoch: 60/100 Loss: 0.018565 Accuracy: 89.14 100.00 % Best test Accuracy: 89.17%
tensor(0.0111, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-3.3440e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.347204
Average KL loss: 0.100833
Average total loss: 0.448037
tensor(0.0108, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.0196e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.342336
Average KL loss: 0.099598
Average total loss: 0.441935
tensor(0.0108, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.3218e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.334991
Average KL loss: 0.098939
Average total loss: 0.433929
tensor(0.0108, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.8535e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.336868
Average KL loss: 0.098514
Average total loss: 0.435382
tensor(0.0108, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.9264e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.324458
Average KL loss: 0.098230
Average total loss: 0.422689
tensor(0.0108, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.4075e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.322279
Average KL loss: 0.098028
Average total loss: 0.420307
tensor(0.0108, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.8396e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.320458
Average KL loss: 0.097911
Average total loss: 0.418368
tensor(0.0108, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-3.2185e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.320949
Average KL loss: 0.097838
Average total loss: 0.418787
tensor(0.0108, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.5880e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.306173
Average KL loss: 0.097785
Average total loss: 0.403958
tensor(0.0108, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.5215e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.307917
Average KL loss: 0.097761
Average total loss: 0.405678
tensor(0.0107, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.8466e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.305656
Average KL loss: 0.097761
Average total loss: 0.403417
tensor(0.0107, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.9709e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.299244
Average KL loss: 0.097769
Average total loss: 0.397013
tensor(0.0107, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.5946e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.308532
Average KL loss: 0.097805
Average total loss: 0.406337
tensor(0.0107, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.8403e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.302269
Average KL loss: 0.097846
Average total loss: 0.400115
tensor(0.0107, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.0875e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.294840
Average KL loss: 0.097889
Average total loss: 0.392729
tensor(0.0107, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.0302e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.295388
Average KL loss: 0.097966
Average total loss: 0.393353
tensor(0.0107, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-3.2985e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.291027
Average KL loss: 0.098050
Average total loss: 0.389077
tensor(0.0107, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.9234e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.292096
Average KL loss: 0.098114
Average total loss: 0.390210
tensor(0.0106, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.0735e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.290629
Average KL loss: 0.098188
Average total loss: 0.388817
tensor(0.0106, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.0508e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.283463
Average KL loss: 0.098255
Average total loss: 0.381718
tensor(0.0106, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.0039e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.281210
Average KL loss: 0.098323
Average total loss: 0.379533
tensor(0.0106, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.9341e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.281233
Average KL loss: 0.098386
Average total loss: 0.379619
tensor(0.0106, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.8630e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.281039
Average KL loss: 0.098465
Average total loss: 0.379503
tensor(0.0106, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.5021e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.279806
Average KL loss: 0.098539
Average total loss: 0.378345
tensor(0.0106, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.5657e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.275156
Average KL loss: 0.098603
Average total loss: 0.373760
tensor(0.0106, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.2200e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.272633
Average KL loss: 0.098673
Average total loss: 0.371306
tensor(0.0106, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.3472e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.270674
Average KL loss: 0.098731
Average total loss: 0.369405
tensor(0.0105, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.8405e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.272460
Average KL loss: 0.098804
Average total loss: 0.371265
tensor(0.0105, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.9922e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.270420
Average KL loss: 0.098890
Average total loss: 0.369310
tensor(0.0105, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.6451e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.268794
Average KL loss: 0.098964
Average total loss: 0.367757
tensor(0.0105, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.4659e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.274584
Average KL loss: 0.099057
Average total loss: 0.373641
tensor(0.0105, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-2.0390e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.268480
Average KL loss: 0.099167
Average total loss: 0.367648
tensor(0.0105, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.6818e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.262091
Average KL loss: 0.099268
Average total loss: 0.361358
tensor(0.0105, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.5127e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.261652
Average KL loss: 0.099334
Average total loss: 0.360986
tensor(0.0105, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.6257e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.262844
Average KL loss: 0.099407
Average total loss: 0.362251
tensor(0.0105, device='cuda:0') tensor(0.0132, device='cuda:0') tensor(-1.5945e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.269151
Average KL loss: 0.099492
Average total loss: 0.368643
tensor(0.0105, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.3982e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.261166
Average KL loss: 0.099553
Average total loss: 0.360719
tensor(0.0105, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.0165e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.266336
Average KL loss: 0.099622
Average total loss: 0.365958
tensor(0.0105, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.3324e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.261000
Average KL loss: 0.099706
Average total loss: 0.360705
tensor(0.0105, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.6030e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.258444
Average KL loss: 0.099775
Average total loss: 0.358219
tensor(0.0104, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.5265e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.262287
Average KL loss: 0.099849
Average total loss: 0.362136
tensor(0.0104, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-9.3804e-09, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.260128
Average KL loss: 0.099924
Average total loss: 0.360053
tensor(0.0104, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.0891e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.253857
Average KL loss: 0.100004
Average total loss: 0.353861
tensor(0.0104, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.4762e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.256848
Average KL loss: 0.100075
Average total loss: 0.356922
tensor(0.0104, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.3193e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.253044
Average KL loss: 0.100148
Average total loss: 0.353192
tensor(0.0104, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.3074e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.257741
Average KL loss: 0.100213
Average total loss: 0.357954
tensor(0.0104, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.4681e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.249034
Average KL loss: 0.100291
Average total loss: 0.349325
tensor(0.0104, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-5.6524e-09, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.253253
Average KL loss: 0.100370
Average total loss: 0.353622
tensor(0.0104, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.6687e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.249745
Average KL loss: 0.100444
Average total loss: 0.350189
tensor(0.0104, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-9.5549e-09, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.249626
Average KL loss: 0.100511
Average total loss: 0.350137
tensor(0.0104, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.5958e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.252345
Average KL loss: 0.100571
Average total loss: 0.352915
tensor(0.0104, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.0983e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.240955
Average KL loss: 0.100621
Average total loss: 0.341576
tensor(0.0104, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.4260e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.244041
Average KL loss: 0.100677
Average total loss: 0.344718
tensor(0.0104, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.4354e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.247542
Average KL loss: 0.100739
Average total loss: 0.348281
tensor(0.0104, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.1431e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.244308
Average KL loss: 0.100806
Average total loss: 0.345113
tensor(0.0104, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.3423e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.240716
Average KL loss: 0.100876
Average total loss: 0.341591
tensor(0.0103, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.7451e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.245236
Average KL loss: 0.100935
Average total loss: 0.346170
tensor(0.0103, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.3482e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.246254
Average KL loss: 0.100999
Average total loss: 0.347254
tensor(0.0103, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-7.6435e-09, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.240881
Average KL loss: 0.101071
Average total loss: 0.341952
tensor(0.0103, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.3550e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.239074
Average KL loss: 0.101153
Average total loss: 0.340227
tensor(0.0103, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.2040e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.237044
Average KL loss: 0.101231
Average total loss: 0.338275
tensor(0.0103, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.4392e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.243848
Average KL loss: 0.101309
Average total loss: 0.345158
tensor(0.0103, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.1249e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.241558
Average KL loss: 0.101386
Average total loss: 0.342944
tensor(0.0103, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.4181e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.243638
Average KL loss: 0.101450
Average total loss: 0.345087
tensor(0.0103, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.1793e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.235404
Average KL loss: 0.101514
Average total loss: 0.336918
tensor(0.0103, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.1598e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.233065
Average KL loss: 0.101601
Average total loss: 0.334666
tensor(0.0103, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-9.3447e-09, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.238210
Average KL loss: 0.101676
Average total loss: 0.339886
tensor(0.0103, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.2169e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.235842
Average KL loss: 0.101749
Average total loss: 0.337591
tensor(0.0103, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.0270e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.232658
Average KL loss: 0.101835
Average total loss: 0.334494
tensor(0.0103, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.2223e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.233183
Average KL loss: 0.101928
Average total loss: 0.335111
tensor(0.0103, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.0685e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.232044
Average KL loss: 0.102010
Average total loss: 0.334054
tensor(0.0103, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.0039e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.225731
Average KL loss: 0.102093
Average total loss: 0.327825
tensor(0.0103, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.0516e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.235049
Average KL loss: 0.102182
Average total loss: 0.337231
tensor(0.0103, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.4694e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.229431
Average KL loss: 0.102269
Average total loss: 0.331700
tensor(0.0103, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-8.7423e-09, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.229709
Average KL loss: 0.102347
Average total loss: 0.332056
tensor(0.0103, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.2941e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.229939
Average KL loss: 0.102416
Average total loss: 0.332355
tensor(0.0103, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.7850e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.223346
Average KL loss: 0.102473
Average total loss: 0.325818
tensor(0.0103, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.4304e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.230663
Average KL loss: 0.102558
Average total loss: 0.333220
tensor(0.0103, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.2546e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.221753
Average KL loss: 0.102643
Average total loss: 0.324396
tensor(0.0103, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.1873e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.227370
Average KL loss: 0.102726
Average total loss: 0.330095
tensor(0.0103, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.6950e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.231959
Average KL loss: 0.102806
Average total loss: 0.334765
tensor(0.0103, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.2122e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.226017
Average KL loss: 0.102890
Average total loss: 0.328907
tensor(0.0103, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-9.4714e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.224191
Average KL loss: 0.102977
Average total loss: 0.327168
tensor(0.0103, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.0245e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.226405
Average KL loss: 0.103072
Average total loss: 0.329477
tensor(0.0103, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-7.2417e-09, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.226254
Average KL loss: 0.103158
Average total loss: 0.329412
tensor(0.0103, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-5.9092e-09, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.220138
Average KL loss: 0.103235
Average total loss: 0.323373
tensor(0.0103, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-6.8482e-09, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.225260
Average KL loss: 0.103308
Average total loss: 0.328568
tensor(0.0102, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.3596e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.228583
Average KL loss: 0.103409
Average total loss: 0.331992
tensor(0.0102, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-7.0998e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.224358
Average KL loss: 0.103507
Average total loss: 0.327865
tensor(0.0102, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.0660e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.227610
Average KL loss: 0.103575
Average total loss: 0.331185
tensor(0.0102, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.4424e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.218054
Average KL loss: 0.103662
Average total loss: 0.321716
tensor(0.0102, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-5.1251e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.219052
Average KL loss: 0.103753
Average total loss: 0.322805
tensor(0.0102, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.6502e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.221764
Average KL loss: 0.103843
Average total loss: 0.325607
tensor(0.0102, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.4013e-09, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.218222
Average KL loss: 0.103926
Average total loss: 0.322148
tensor(0.0102, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.2074e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.212008
Average KL loss: 0.104003
Average total loss: 0.316011
tensor(0.0102, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.1754e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.222333
Average KL loss: 0.104095
Average total loss: 0.326428
tensor(0.0102, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-7.1123e-09, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.216834
Average KL loss: 0.104193
Average total loss: 0.321027
tensor(0.0102, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.0401e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.220428
Average KL loss: 0.104266
Average total loss: 0.324694
tensor(0.0102, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-8.1798e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.212845
Average KL loss: 0.104346
Average total loss: 0.317191
tensor(0.0102, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-9.7275e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.215800
Average KL loss: 0.104439
Average total loss: 0.320239
tensor(0.0102, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-8.3832e-09, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.211481
Average KL loss: 0.104525
Average total loss: 0.316005
tensor(0.0102, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.0396e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.213934
Average KL loss: 0.104589
Average total loss: 0.318523
tensor(0.0102, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.3586e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.215221
Average KL loss: 0.104667
Average total loss: 0.319888
tensor(0.0102, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-6.8612e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.217780
Average KL loss: 0.104751
Average total loss: 0.322531
tensor(0.0102, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-9.1211e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.211245
Average KL loss: 0.104839
Average total loss: 0.316084
tensor(0.0102, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.5421e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.208599
Average KL loss: 0.104913
Average total loss: 0.313512
tensor(0.0102, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.0046e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.212955
Average KL loss: 0.104970
Average total loss: 0.317925
tensor(0.0102, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.2110e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.206943
Average KL loss: 0.105045
Average total loss: 0.311988
tensor(0.0102, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-5.0367e-09, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.209522
Average KL loss: 0.105132
Average total loss: 0.314654
tensor(0.0102, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-9.9636e-09, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.208288
Average KL loss: 0.105193
Average total loss: 0.313481
tensor(0.0102, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-6.7131e-09, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.213861
Average KL loss: 0.105249
Average total loss: 0.319110
tensor(0.0102, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-6.7254e-09, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.210915
Average KL loss: 0.105326
Average total loss: 0.316241
tensor(0.0102, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-8.7868e-09, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.209071
Average KL loss: 0.105393
Average total loss: 0.314464
tensor(0.0102, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-9.1699e-09, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.210935
Average KL loss: 0.105470
Average total loss: 0.316406
tensor(0.0102, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-5.5662e-09, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.206283
Average KL loss: 0.105552
Average total loss: 0.311834
tensor(0.0102, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-8.5771e-09, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.212465
Average KL loss: 0.105614
Average total loss: 0.318080
tensor(0.0102, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-7.2030e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.207290
Average KL loss: 0.105688
Average total loss: 0.312978
tensor(0.0102, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.0547e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.209021
Average KL loss: 0.105758
Average total loss: 0.314779
tensor(0.0102, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.2909e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.208888
Average KL loss: 0.105849
Average total loss: 0.314737
tensor(0.0102, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-6.1514e-09, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.209002
Average KL loss: 0.105933
Average total loss: 0.314935
tensor(0.0102, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.0104e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.203176
Average KL loss: 0.106011
Average total loss: 0.309188
tensor(0.0102, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-5.9446e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.206138
Average KL loss: 0.106068
Average total loss: 0.312206
tensor(0.0102, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-7.4157e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.208515
Average KL loss: 0.106140
Average total loss: 0.314655
tensor(0.0102, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-8.6423e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.207619
Average KL loss: 0.106225
Average total loss: 0.313843
tensor(0.0102, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-8.4283e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.202168
Average KL loss: 0.106319
Average total loss: 0.308487
tensor(0.0102, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-6.6834e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.199573
Average KL loss: 0.106386
Average total loss: 0.305958
tensor(0.0102, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.0560e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.201377
Average KL loss: 0.106444
Average total loss: 0.307821
tensor(0.0102, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-8.0368e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.208239
Average KL loss: 0.106504
Average total loss: 0.314744
tensor(0.0102, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.0002e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.203637
Average KL loss: 0.106586
Average total loss: 0.310223
tensor(0.0102, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-5.5781e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.201991
Average KL loss: 0.106655
Average total loss: 0.308646
tensor(0.0102, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-9.2290e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.198635
Average KL loss: 0.106729
Average total loss: 0.305365
tensor(0.0102, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-7.0217e-09, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.199216
Average KL loss: 0.106785
Average total loss: 0.306001
tensor(0.0102, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-4.4985e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.207815
Average KL loss: 0.106845
Average total loss: 0.314660
tensor(0.0102, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-9.7288e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.202453
Average KL loss: 0.106913
Average total loss: 0.309365
tensor(0.0102, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-7.9480e-09, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.202765
Average KL loss: 0.106982
Average total loss: 0.309747
tensor(0.0102, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-8.5912e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.201489
Average KL loss: 0.107067
Average total loss: 0.308556
tensor(0.0102, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.5635e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.202322
Average KL loss: 0.107160
Average total loss: 0.309482
tensor(0.0102, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-9.2716e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.201291
Average KL loss: 0.107228
Average total loss: 0.308519
tensor(0.0102, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.0006e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.197260
Average KL loss: 0.107290
Average total loss: 0.304550
tensor(0.0102, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-5.7388e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.198934
Average KL loss: 0.107359
Average total loss: 0.306293
tensor(0.0102, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-5.8442e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.198656
Average KL loss: 0.107423
Average total loss: 0.306079
tensor(0.0102, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-7.0878e-09, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.198056
Average KL loss: 0.107485
Average total loss: 0.305541
tensor(0.0102, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.4654e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.200436
Average KL loss: 0.107560
Average total loss: 0.307996
tensor(0.0102, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-9.2270e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.200872
Average KL loss: 0.107627
Average total loss: 0.308499
tensor(0.0102, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.0295e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.198383
Average KL loss: 0.107680
Average total loss: 0.306063
tensor(0.0102, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-3.5865e-09, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.196387
Average KL loss: 0.107734
Average total loss: 0.304121
tensor(0.0102, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-5.2410e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.195783
Average KL loss: 0.107795
Average total loss: 0.303578
tensor(0.0102, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.1245e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.193409
Average KL loss: 0.107844
Average total loss: 0.301254
tensor(0.0102, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-4.0987e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.197607
Average KL loss: 0.107913
Average total loss: 0.305520
tensor(0.0102, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-7.8797e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.193179
Average KL loss: 0.107992
Average total loss: 0.301171
tensor(0.0102, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-3.9537e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.189416
Average KL loss: 0.108059
Average total loss: 0.297475
tensor(0.0102, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-9.4442e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.199692
Average KL loss: 0.108123
Average total loss: 0.307815
tensor(0.0102, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-7.5050e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.191793
Average KL loss: 0.108198
Average total loss: 0.299991
tensor(0.0102, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-5.1102e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.191670
Average KL loss: 0.108254
Average total loss: 0.299925
tensor(0.0102, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-9.6113e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.190678
Average KL loss: 0.108305
Average total loss: 0.298983
tensor(0.0102, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-8.7447e-09, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.195059
Average KL loss: 0.108345
Average total loss: 0.303403
tensor(0.0102, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-5.6482e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.190478
Average KL loss: 0.108410
Average total loss: 0.298889
tensor(0.0102, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-8.7515e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.194297
Average KL loss: 0.108469
Average total loss: 0.302767
tensor(0.0102, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.1368e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.197177
Average KL loss: 0.108545
Average total loss: 0.305722
tensor(0.0102, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.0432e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.190051
Average KL loss: 0.108623
Average total loss: 0.298674
tensor(0.0102, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-5.6571e-09, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.188042
Average KL loss: 0.108673
Average total loss: 0.296715
tensor(0.0102, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.0127e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.192549
Average KL loss: 0.108731
Average total loss: 0.301280
tensor(0.0102, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-6.2357e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.187064
Average KL loss: 0.108793
Average total loss: 0.295857
tensor(0.0102, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-6.7644e-09, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.192644
Average KL loss: 0.108848
Average total loss: 0.301492
tensor(0.0102, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-7.0933e-09, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.192977
Average KL loss: 0.108906
Average total loss: 0.301882
tensor(0.0102, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-5.7561e-09, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.187059
Average KL loss: 0.108954
Average total loss: 0.296013
tensor(0.0102, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-8.8144e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.190468
Average KL loss: 0.109015
Average total loss: 0.299483
tensor(0.0102, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-7.2271e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.186648
Average KL loss: 0.109076
Average total loss: 0.295724
tensor(0.0102, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-9.2929e-09, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.193100
Average KL loss: 0.109136
Average total loss: 0.302236
tensor(0.0102, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-9.5004e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.188392
Average KL loss: 0.109190
Average total loss: 0.297581
tensor(0.0102, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.2634e-09, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.184777
Average KL loss: 0.109248
Average total loss: 0.294025
tensor(0.0102, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-3.5808e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.190591
Average KL loss: 0.109309
Average total loss: 0.299900
tensor(0.0102, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-3.1851e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.186739
Average KL loss: 0.109374
Average total loss: 0.296113
tensor(0.0102, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-8.0985e-09, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.186040
Average KL loss: 0.109444
Average total loss: 0.295484
tensor(0.0102, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-6.4989e-09, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.186781
Average KL loss: 0.109501
Average total loss: 0.296283
tensor(0.0102, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-6.0903e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.187100
Average KL loss: 0.109550
Average total loss: 0.296650
tensor(0.0102, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-8.4362e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.183681
Average KL loss: 0.109609
Average total loss: 0.293290
tensor(0.0102, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-6.1170e-09, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.190478
Average KL loss: 0.109686
Average total loss: 0.300164
tensor(0.0102, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-6.7665e-09, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.183771
Average KL loss: 0.109749
Average total loss: 0.293520
tensor(0.0102, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-8.0351e-09, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.185112
Average KL loss: 0.109794
Average total loss: 0.294906
tensor(0.0102, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.1132e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.182865
Average KL loss: 0.109839
Average total loss: 0.292704
tensor(0.0102, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-1.1768e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.186631
Average KL loss: 0.109884
Average total loss: 0.296516
tensor(0.0102, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-9.5416e-09, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.184737
Average KL loss: 0.109932
Average total loss: 0.294669
tensor(0.0102, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-5.2788e-09, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.186566
Average KL loss: 0.109994
Average total loss: 0.296560
tensor(0.0102, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-8.3488e-09, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.183970
Average KL loss: 0.110050
Average total loss: 0.294020
tensor(0.0102, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-5.3848e-09, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.182406
Average KL loss: 0.110089
Average total loss: 0.292495
tensor(0.0102, device='cuda:0') tensor(0.0149, device='cuda:0') tensor(-5.3534e-09, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.186719
Average KL loss: 0.110140
Average total loss: 0.296859
tensor(0.0102, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-2.8737e-09, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.182662
Average KL loss: 0.110199
Average total loss: 0.292861
tensor(0.0102, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-4.9599e-09, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.180785
Average KL loss: 0.110251
Average total loss: 0.291036
tensor(0.0102, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-4.9996e-09, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.180828
Average KL loss: 0.110313
Average total loss: 0.291141
tensor(0.0102, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-6.3332e-09, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.178735
Average KL loss: 0.110369
Average total loss: 0.289104
tensor(0.0102, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-9.9159e-09, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.181011
Average KL loss: 0.110420
Average total loss: 0.291431
tensor(0.0102, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-5.0641e-09, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.188873
Average KL loss: 0.110491
Average total loss: 0.299364
tensor(0.0102, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-9.3525e-09, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.182173
Average KL loss: 0.110549
Average total loss: 0.292722
tensor(0.0102, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-3.8568e-09, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.182966
Average KL loss: 0.110588
Average total loss: 0.293554
tensor(0.0102, device='cuda:0') tensor(0.0150, device='cuda:0') tensor(-2.1774e-09, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.178210
Average KL loss: 0.110645
Average total loss: 0.288855
tensor(0.0102, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-8.1078e-09, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.181415
Average KL loss: 0.110693
Average total loss: 0.292107
tensor(0.0102, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-4.3449e-09, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.176997
Average KL loss: 0.110742
Average total loss: 0.287739
tensor(0.0102, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-7.5988e-09, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.178167
Average KL loss: 0.110785
Average total loss: 0.288952
tensor(0.0102, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-3.5088e-09, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.186538
Average KL loss: 0.110829
Average total loss: 0.297367
 Percentile value: 0.43236780166625977
Non-zero model percentage: 1.5625073909759521%, Non-zero mask percentage: 1.5625073909759521%

--- Pruning Level [6/12]: ---
conv1.weight         | nonzeros =     139 /    1728             (  8.04%) | total_pruned =    1589 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =     126 /   36864             (  0.34%) | total_pruned =   36738 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      14 /      64             ( 21.88%) | total_pruned =      50 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     225 /   36864             (  0.61%) | total_pruned =   36639 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      17 /      64             ( 26.56%) | total_pruned =      47 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     525 /   36864             (  1.42%) | total_pruned =   36339 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      24 /      64             ( 37.50%) | total_pruned =      40 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =    1076 /   36864             (  2.92%) | total_pruned =   35788 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      27 /      64             ( 42.19%) | total_pruned =      37 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    3046 /   73728             (  4.13%) | total_pruned =   70682 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      16 /     128             ( 12.50%) | total_pruned =     112 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    6845 /  147456             (  4.64%) | total_pruned =  140611 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =     100 /     128             ( 78.12%) | total_pruned =      28 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       5 /     128             (  3.91%) | total_pruned =     123 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     598 /    8192             (  7.30%) | total_pruned =    7594 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       6 /     128             (  4.69%) | total_pruned =     122 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    3748 /  147456             (  2.54%) | total_pruned =  143708 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    3535 /  147456             (  2.40%) | total_pruned =  143921 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      82 /     128             ( 64.06%) | total_pruned =      46 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =   15712 /  294912             (  5.33%) | total_pruned =  279200 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     225 /     256             ( 87.89%) | total_pruned =      31 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   26287 /  589824             (  4.46%) | total_pruned =  563537 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     234 /     256             ( 91.41%) | total_pruned =      22 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      14 /     256             (  5.47%) | total_pruned =     242 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1814 /   32768             (  5.54%) | total_pruned =   30954 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     176 /     256             ( 68.75%) | total_pruned =      80 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =   14514 /  589824             (  2.46%) | total_pruned =  575310 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     174 /     256             ( 67.97%) | total_pruned =      82 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =   11341 /  589824             (  1.92%) | total_pruned =  578483 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     171 /     256             ( 66.80%) | total_pruned =      85 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   26446 / 1179648             (  2.24%) | total_pruned = 1153202 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     420 /     512             ( 82.03%) | total_pruned =      92 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =   20683 / 2359296             (  0.88%) | total_pruned = 2338613 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     293 /     512             ( 57.23%) | total_pruned =     219 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =     118 /     512             ( 23.05%) | total_pruned =     394 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     415 /  131072             (  0.32%) | total_pruned =  130657 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      75 /     512             ( 14.65%) | total_pruned =     437 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =     116 /     512             ( 22.66%) | total_pruned =     396 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =   11825 / 2359296             (  0.50%) | total_pruned = 2347471 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     164 /     512             ( 32.03%) | total_pruned =     348 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       6 /     512             (  1.17%) | total_pruned =     506 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =   20278 / 2359296             (  0.86%) | total_pruned = 2339018 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     291 /     512             ( 56.84%) | total_pruned =     221 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     262 /     512             ( 51.17%) | total_pruned =     250 | shape = torch.Size([512])
linear.weight        | nonzeros =    2127 /    5120             ( 41.54%) | total_pruned =    2993 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 174669, pruned : 11004093, total: 11178762, Compression rate :      64.00x  ( 98.44% pruned)
Train Epoch: 65/100 Loss: 0.020717 Accuracy: 88.23 100.00 % Best test Accuracy: 88.36%
tensor(0.0102, device='cuda:0') tensor(0.0151, device='cuda:0') tensor(-2.8818e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.356616
Average KL loss: 0.109362
Average total loss: 0.465978
tensor(0.0099, device='cuda:0') tensor(0.0148, device='cuda:0') tensor(-2.3897e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.339931
Average KL loss: 0.107464
Average total loss: 0.447395
tensor(0.0097, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-3.4994e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.335675
Average KL loss: 0.106150
Average total loss: 0.441825
tensor(0.0096, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.5082e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.332499
Average KL loss: 0.105124
Average total loss: 0.437623
tensor(0.0095, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.2182e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.328228
Average KL loss: 0.104286
Average total loss: 0.432513
tensor(0.0094, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.5349e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.329785
Average KL loss: 0.103586
Average total loss: 0.433371
tensor(0.0094, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.2632e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.326742
Average KL loss: 0.102994
Average total loss: 0.429736
tensor(0.0093, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.6239e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.325632
Average KL loss: 0.102473
Average total loss: 0.428104
tensor(0.0093, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.0743e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.315263
Average KL loss: 0.102013
Average total loss: 0.417276
tensor(0.0093, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.3876e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.317642
Average KL loss: 0.101615
Average total loss: 0.419257
tensor(0.0092, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-3.7752e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.318130
Average KL loss: 0.101258
Average total loss: 0.419388
tensor(0.0092, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.9580e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.321228
Average KL loss: 0.100955
Average total loss: 0.422182
tensor(0.0092, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.8963e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.312276
Average KL loss: 0.100690
Average total loss: 0.412966
tensor(0.0091, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.9096e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.312346
Average KL loss: 0.100446
Average total loss: 0.412793
tensor(0.0091, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-3.1329e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.307020
Average KL loss: 0.100223
Average total loss: 0.407243
tensor(0.0091, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.1154e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.308403
Average KL loss: 0.100024
Average total loss: 0.408427
tensor(0.0090, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.8378e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.300247
Average KL loss: 0.099850
Average total loss: 0.400097
tensor(0.0090, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.6241e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.299693
Average KL loss: 0.099677
Average total loss: 0.399370
tensor(0.0090, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.0205e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.300875
Average KL loss: 0.099527
Average total loss: 0.400403
tensor(0.0090, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.3880e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.296007
Average KL loss: 0.099400
Average total loss: 0.395407
tensor(0.0090, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.9997e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.296077
Average KL loss: 0.099285
Average total loss: 0.395362
tensor(0.0089, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.3158e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.289415
Average KL loss: 0.099181
Average total loss: 0.388596
tensor(0.0089, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.5028e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.298562
Average KL loss: 0.099102
Average total loss: 0.397664
tensor(0.0089, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.5852e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.293044
Average KL loss: 0.099021
Average total loss: 0.392065
tensor(0.0089, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.9701e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.286002
Average KL loss: 0.098942
Average total loss: 0.384944
tensor(0.0089, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.2119e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.285539
Average KL loss: 0.098884
Average total loss: 0.384423
tensor(0.0089, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.6306e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.284614
Average KL loss: 0.098836
Average total loss: 0.383450
tensor(0.0088, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.8694e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.288111
Average KL loss: 0.098783
Average total loss: 0.386894
tensor(0.0088, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.8517e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.279833
Average KL loss: 0.098734
Average total loss: 0.378566
tensor(0.0088, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.2867e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.286807
Average KL loss: 0.098689
Average total loss: 0.385496
tensor(0.0088, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.8124e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.287367
Average KL loss: 0.098661
Average total loss: 0.386028
tensor(0.0088, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.9138e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.286506
Average KL loss: 0.098640
Average total loss: 0.385147
tensor(0.0088, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.5327e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.284405
Average KL loss: 0.098622
Average total loss: 0.383026
tensor(0.0088, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.0517e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.280401
Average KL loss: 0.098610
Average total loss: 0.379010
tensor(0.0088, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.5774e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.276160
Average KL loss: 0.098593
Average total loss: 0.374754
tensor(0.0088, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.4443e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.282500
Average KL loss: 0.098580
Average total loss: 0.381079
tensor(0.0087, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.3462e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.272605
Average KL loss: 0.098572
Average total loss: 0.371176
tensor(0.0087, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.7508e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.272524
Average KL loss: 0.098568
Average total loss: 0.371092
tensor(0.0087, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.8965e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.269361
Average KL loss: 0.098575
Average total loss: 0.367936
tensor(0.0087, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.2446e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.276421
Average KL loss: 0.098577
Average total loss: 0.374999
tensor(0.0087, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.3307e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.270500
Average KL loss: 0.098578
Average total loss: 0.369078
tensor(0.0087, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.6263e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.273780
Average KL loss: 0.098574
Average total loss: 0.372354
tensor(0.0087, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.4175e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.265828
Average KL loss: 0.098581
Average total loss: 0.364409
tensor(0.0087, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.0247e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.265660
Average KL loss: 0.098586
Average total loss: 0.364246
tensor(0.0087, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.7420e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.264545
Average KL loss: 0.098596
Average total loss: 0.363140
tensor(0.0087, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.0924e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.262684
Average KL loss: 0.098611
Average total loss: 0.361295
tensor(0.0087, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.3556e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.260150
Average KL loss: 0.098619
Average total loss: 0.358769
tensor(0.0087, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.3754e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.259476
Average KL loss: 0.098615
Average total loss: 0.358091
tensor(0.0087, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.4870e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.265408
Average KL loss: 0.098624
Average total loss: 0.364033
tensor(0.0087, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.4535e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.264091
Average KL loss: 0.098642
Average total loss: 0.362733
tensor(0.0087, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.6096e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.259582
Average KL loss: 0.098656
Average total loss: 0.358238
tensor(0.0086, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.4621e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.267134
Average KL loss: 0.098675
Average total loss: 0.365809
tensor(0.0086, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-1.4833e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.261215
Average KL loss: 0.098707
Average total loss: 0.359921
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.6666e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.264121
Average KL loss: 0.098740
Average total loss: 0.362861
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.9638e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.259434
Average KL loss: 0.098767
Average total loss: 0.358201
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.5633e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.256504
Average KL loss: 0.098783
Average total loss: 0.355286
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.4176e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.257076
Average KL loss: 0.098810
Average total loss: 0.355887
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.1855e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.255748
Average KL loss: 0.098840
Average total loss: 0.354587
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.2741e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.261006
Average KL loss: 0.098864
Average total loss: 0.359870
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-6.6917e-09, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.252984
Average KL loss: 0.098892
Average total loss: 0.351876
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.0072e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.258317
Average KL loss: 0.098930
Average total loss: 0.357247
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.7679e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.255223
Average KL loss: 0.098972
Average total loss: 0.354195
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-9.9738e-09, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.257653
Average KL loss: 0.099006
Average total loss: 0.356659
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.3401e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.249746
Average KL loss: 0.099040
Average total loss: 0.348786
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.2501e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.253612
Average KL loss: 0.099086
Average total loss: 0.352698
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.3316e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.250589
Average KL loss: 0.099137
Average total loss: 0.349726
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.4117e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.247251
Average KL loss: 0.099182
Average total loss: 0.346432
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.8124e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.248346
Average KL loss: 0.099236
Average total loss: 0.347582
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.3338e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.243034
Average KL loss: 0.099280
Average total loss: 0.342314
tensor(0.0086, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.2161e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.242129
Average KL loss: 0.099318
Average total loss: 0.341447
tensor(0.0086, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.2076e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.239222
Average KL loss: 0.099363
Average total loss: 0.338585
tensor(0.0086, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.3982e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.245401
Average KL loss: 0.099408
Average total loss: 0.344809
tensor(0.0086, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.0470e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.247897
Average KL loss: 0.099452
Average total loss: 0.347349
tensor(0.0086, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.3856e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.244403
Average KL loss: 0.099504
Average total loss: 0.343907
tensor(0.0086, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.7497e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.247039
Average KL loss: 0.099563
Average total loss: 0.346602
tensor(0.0086, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.3208e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.240301
Average KL loss: 0.099631
Average total loss: 0.339931
tensor(0.0086, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-8.8812e-09, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.238426
Average KL loss: 0.099698
Average total loss: 0.338124
tensor(0.0086, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.3721e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.243081
Average KL loss: 0.099749
Average total loss: 0.342829
tensor(0.0086, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.0046e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.245861
Average KL loss: 0.099814
Average total loss: 0.345676
tensor(0.0086, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.0994e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.238105
Average KL loss: 0.099885
Average total loss: 0.337990
tensor(0.0086, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.7603e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.240149
Average KL loss: 0.099959
Average total loss: 0.340108
tensor(0.0086, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.0574e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.233941
Average KL loss: 0.100032
Average total loss: 0.333972
tensor(0.0086, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-8.6334e-09, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.245814
Average KL loss: 0.100092
Average total loss: 0.345906
tensor(0.0086, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.3368e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.234516
Average KL loss: 0.100156
Average total loss: 0.334673
tensor(0.0086, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.5996e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.231238
Average KL loss: 0.100226
Average total loss: 0.331464
tensor(0.0086, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.0792e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.236653
Average KL loss: 0.100297
Average total loss: 0.336951
tensor(0.0086, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.4758e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.239681
Average KL loss: 0.100377
Average total loss: 0.340058
tensor(0.0086, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.3939e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.232366
Average KL loss: 0.100447
Average total loss: 0.332813
tensor(0.0086, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-4.8569e-09, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.234498
Average KL loss: 0.100524
Average total loss: 0.335022
tensor(0.0086, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-6.6782e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.233166
Average KL loss: 0.100606
Average total loss: 0.333772
tensor(0.0086, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.3556e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.247127
Average KL loss: 0.100685
Average total loss: 0.347812
tensor(0.0086, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.5217e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.235884
Average KL loss: 0.100774
Average total loss: 0.336658
tensor(0.0086, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-9.8271e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.228119
Average KL loss: 0.100847
Average total loss: 0.328966
tensor(0.0086, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.4588e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.234961
Average KL loss: 0.100922
Average total loss: 0.335882
tensor(0.0086, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.0238e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.229896
Average KL loss: 0.100999
Average total loss: 0.330895
tensor(0.0086, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.1934e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.230566
Average KL loss: 0.101077
Average total loss: 0.331643
tensor(0.0086, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.3587e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.227247
Average KL loss: 0.101165
Average total loss: 0.328411
tensor(0.0086, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.5435e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.231384
Average KL loss: 0.101249
Average total loss: 0.332634
tensor(0.0086, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.7155e-09, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.228591
Average KL loss: 0.101336
Average total loss: 0.329927
tensor(0.0086, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.7294e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.233844
Average KL loss: 0.101416
Average total loss: 0.335261
tensor(0.0086, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.2092e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.224141
Average KL loss: 0.101501
Average total loss: 0.325642
tensor(0.0086, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.4854e-09, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.231499
Average KL loss: 0.101578
Average total loss: 0.333076
tensor(0.0086, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-8.6623e-09, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.227291
Average KL loss: 0.101660
Average total loss: 0.328951
tensor(0.0086, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-5.1443e-09, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.224701
Average KL loss: 0.101736
Average total loss: 0.326437
tensor(0.0086, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-6.9725e-09, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.221639
Average KL loss: 0.101818
Average total loss: 0.323456
tensor(0.0086, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.0160e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.224773
Average KL loss: 0.101909
Average total loss: 0.326681
tensor(0.0086, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.0965e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.223300
Average KL loss: 0.101984
Average total loss: 0.325285
tensor(0.0086, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-9.7518e-09, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.226378
Average KL loss: 0.102057
Average total loss: 0.328435
tensor(0.0086, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.4565e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.221096
Average KL loss: 0.102137
Average total loss: 0.323233
tensor(0.0086, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.0456e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.226313
Average KL loss: 0.102222
Average total loss: 0.328535
tensor(0.0086, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.3123e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.220733
Average KL loss: 0.102298
Average total loss: 0.323031
tensor(0.0086, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.3166e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.220792
Average KL loss: 0.102380
Average total loss: 0.323171
tensor(0.0086, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.0004e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.215679
Average KL loss: 0.102461
Average total loss: 0.318140
tensor(0.0086, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.5135e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.216618
Average KL loss: 0.102534
Average total loss: 0.319152
tensor(0.0086, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.7038e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.222722
Average KL loss: 0.102606
Average total loss: 0.325328
tensor(0.0086, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.5658e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.227433
Average KL loss: 0.102686
Average total loss: 0.330119
tensor(0.0086, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-6.0579e-09, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.213873
Average KL loss: 0.102768
Average total loss: 0.316641
tensor(0.0086, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-9.0577e-09, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.218062
Average KL loss: 0.102847
Average total loss: 0.320909
tensor(0.0086, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.1036e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.222260
Average KL loss: 0.102927
Average total loss: 0.325187
tensor(0.0086, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.3874e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.220202
Average KL loss: 0.103013
Average total loss: 0.323215
tensor(0.0086, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-2.2189e-09, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.221604
Average KL loss: 0.103093
Average total loss: 0.324697
tensor(0.0086, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.1975e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.215174
Average KL loss: 0.103168
Average total loss: 0.318341
tensor(0.0086, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.0159e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.212826
Average KL loss: 0.103250
Average total loss: 0.316075
tensor(0.0086, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-8.9798e-09, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.217154
Average KL loss: 0.103327
Average total loss: 0.320481
tensor(0.0086, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-9.4562e-09, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.221106
Average KL loss: 0.103414
Average total loss: 0.324520
tensor(0.0086, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-8.4281e-09, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.211849
Average KL loss: 0.103505
Average total loss: 0.315354
tensor(0.0086, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-8.8484e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.216144
Average KL loss: 0.103577
Average total loss: 0.319721
tensor(0.0086, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-7.8251e-09, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.211767
Average KL loss: 0.103651
Average total loss: 0.315418
tensor(0.0086, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.0621e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.212516
Average KL loss: 0.103727
Average total loss: 0.316243
tensor(0.0086, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-4.7986e-09, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.213984
Average KL loss: 0.103805
Average total loss: 0.317789
tensor(0.0086, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-8.7868e-09, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.211238
Average KL loss: 0.103875
Average total loss: 0.315113
tensor(0.0086, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.0660e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.212722
Average KL loss: 0.103948
Average total loss: 0.316670
tensor(0.0086, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-6.7202e-09, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.211082
Average KL loss: 0.104027
Average total loss: 0.315108
tensor(0.0086, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-8.8328e-09, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.213189
Average KL loss: 0.104109
Average total loss: 0.317298
tensor(0.0086, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.0358e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.213177
Average KL loss: 0.104189
Average total loss: 0.317366
tensor(0.0086, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-7.2389e-09, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.211856
Average KL loss: 0.104259
Average total loss: 0.316115
tensor(0.0086, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.4324e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.210580
Average KL loss: 0.104324
Average total loss: 0.314904
tensor(0.0086, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-6.3988e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.219717
Average KL loss: 0.104396
Average total loss: 0.324112
tensor(0.0086, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.1456e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.212656
Average KL loss: 0.104479
Average total loss: 0.317135
tensor(0.0086, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-4.4329e-09, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.206739
Average KL loss: 0.104557
Average total loss: 0.311296
tensor(0.0086, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-5.9524e-09, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.216006
Average KL loss: 0.104644
Average total loss: 0.320650
tensor(0.0086, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.4207e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.203964
Average KL loss: 0.104729
Average total loss: 0.308693
tensor(0.0086, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-9.7736e-09, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.205417
Average KL loss: 0.104796
Average total loss: 0.310214
tensor(0.0086, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-9.9774e-09, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.206615
Average KL loss: 0.104872
Average total loss: 0.311487
tensor(0.0086, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-6.2757e-09, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.210706
Average KL loss: 0.104953
Average total loss: 0.315658
tensor(0.0086, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.3026e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.203652
Average KL loss: 0.105027
Average total loss: 0.308679
tensor(0.0086, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-7.9369e-09, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.206867
Average KL loss: 0.105100
Average total loss: 0.311967
tensor(0.0086, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-8.2490e-09, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.203655
Average KL loss: 0.105163
Average total loss: 0.308817
tensor(0.0086, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-6.3959e-09, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.205323
Average KL loss: 0.105236
Average total loss: 0.310559
tensor(0.0086, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-8.1630e-09, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.207282
Average KL loss: 0.105306
Average total loss: 0.312588
tensor(0.0086, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-7.2341e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.203815
Average KL loss: 0.105381
Average total loss: 0.309196
tensor(0.0086, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-8.7088e-09, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.206035
Average KL loss: 0.105460
Average total loss: 0.311494
tensor(0.0086, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-9.7956e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.203332
Average KL loss: 0.105536
Average total loss: 0.308869
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-7.4972e-09, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.202119
Average KL loss: 0.105578
Average total loss: 0.307698
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-7.1375e-09, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.199457
Average KL loss: 0.105586
Average total loss: 0.305042
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.1648e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.202115
Average KL loss: 0.105592
Average total loss: 0.307707
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-9.0760e-09, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.198955
Average KL loss: 0.105599
Average total loss: 0.304554
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-8.9549e-09, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.200890
Average KL loss: 0.105604
Average total loss: 0.306494
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-8.2140e-09, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.206724
Average KL loss: 0.105611
Average total loss: 0.312335
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.0598e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.204345
Average KL loss: 0.105618
Average total loss: 0.309962
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.3888e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.204047
Average KL loss: 0.105625
Average total loss: 0.309672
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.1385e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.209319
Average KL loss: 0.105632
Average total loss: 0.314951
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-9.2254e-09, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.206610
Average KL loss: 0.105640
Average total loss: 0.312250
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.3125e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.202927
Average KL loss: 0.105647
Average total loss: 0.308574
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.0385e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.200155
Average KL loss: 0.105654
Average total loss: 0.305809
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.0832e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.207623
Average KL loss: 0.105661
Average total loss: 0.313284
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-6.9703e-09, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.200491
Average KL loss: 0.105669
Average total loss: 0.306160
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-9.7248e-09, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.202325
Average KL loss: 0.105676
Average total loss: 0.308001
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.0632e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.205846
Average KL loss: 0.105681
Average total loss: 0.311526
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-5.5791e-09, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.202383
Average KL loss: 0.105681
Average total loss: 0.308064
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.0200e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.203461
Average KL loss: 0.105682
Average total loss: 0.309143
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-8.8603e-09, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.204150
Average KL loss: 0.105683
Average total loss: 0.309832
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-4.4909e-09, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.199133
Average KL loss: 0.105683
Average total loss: 0.304816
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.3998e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.199647
Average KL loss: 0.105684
Average total loss: 0.305331
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.1189e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.198938
Average KL loss: 0.105685
Average total loss: 0.304623
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-8.6898e-09, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.207278
Average KL loss: 0.105685
Average total loss: 0.312963
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-6.4708e-09, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.206755
Average KL loss: 0.105686
Average total loss: 0.312441
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.0101e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.202129
Average KL loss: 0.105687
Average total loss: 0.307816
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-5.3635e-09, device='cuda:0')
 Percentile value: 0.7560859322547913
Non-zero model percentage: 0.781258225440979%, Non-zero mask percentage: 0.781258225440979%

--- Pruning Level [7/12]: ---
conv1.weight         | nonzeros =     136 /    1728             (  7.87%) | total_pruned =    1592 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      88 /   36864             (  0.24%) | total_pruned =   36776 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     180 /   36864             (  0.49%) | total_pruned =   36684 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     412 /   36864             (  1.12%) | total_pruned =   36452 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     728 /   36864             (  1.97%) | total_pruned =   36136 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      26 /      64             ( 40.62%) | total_pruned =      38 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    2082 /   73728             (  2.82%) | total_pruned =   71646 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      86 /     128             ( 67.19%) | total_pruned =      42 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      12 /     128             (  9.38%) | total_pruned =     116 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    4335 /  147456             (  2.94%) | total_pruned =  143121 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      95 /     128             ( 74.22%) | total_pruned =      33 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     406 /    8192             (  4.96%) | total_pruned =    7786 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      69 /     128             ( 53.91%) | total_pruned =      59 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       4 /     128             (  3.12%) | total_pruned =     124 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    2301 /  147456             (  1.56%) | total_pruned =  145155 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      65 /     128             ( 50.78%) | total_pruned =      63 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    2183 /  147456             (  1.48%) | total_pruned =  145273 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      77 /     128             ( 60.16%) | total_pruned =      51 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    9566 /  294912             (  3.24%) | total_pruned =  285346 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     221 /     256             ( 86.33%) | total_pruned =      35 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       4 /     256             (  1.56%) | total_pruned =     252 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =   15495 /  589824             (  2.63%) | total_pruned =  574329 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     227 /     256             ( 88.67%) | total_pruned =      29 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      12 /     256             (  4.69%) | total_pruned =     244 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =    1055 /   32768             (  3.22%) | total_pruned =   31713 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     148 /     256             ( 57.81%) | total_pruned =     108 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    8322 /  589824             (  1.41%) | total_pruned =  581502 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     162 /     256             ( 63.28%) | total_pruned =      94 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    6644 /  589824             (  1.13%) | total_pruned =  583180 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     163 /     256             ( 63.67%) | total_pruned =      93 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =   12657 / 1179648             (  1.07%) | total_pruned = 1166991 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     379 /     512             ( 74.02%) | total_pruned =     133 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    8199 / 2359296             (  0.35%) | total_pruned = 2351097 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     197 /     512             ( 38.48%) | total_pruned =     315 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      76 /     512             ( 14.84%) | total_pruned =     436 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =     167 /  131072             (  0.13%) | total_pruned =  130905 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      41 /     512             (  8.01%) | total_pruned =     471 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      70 /     512             ( 13.67%) | total_pruned =     442 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    4029 / 2359296             (  0.17%) | total_pruned = 2355267 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =     111 /     512             ( 21.68%) | total_pruned =     401 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    4848 / 2359296             (  0.21%) | total_pruned = 2354448 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =     143 /     512             ( 27.93%) | total_pruned =     369 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =     114 /     512             ( 22.27%) | total_pruned =     398 | shape = torch.Size([512])
linear.weight        | nonzeros =     868 /    5120             ( 16.95%) | total_pruned =    4252 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       2 /      10             ( 20.00%) | total_pruned =       8 | shape = torch.Size([10])
alive: 87335, pruned : 11091427, total: 11178762, Compression rate :     128.00x  ( 99.22% pruned)
Train Epoch: 56/100 Loss: 0.025334 Accuracy: 87.59 100.00 % Best test Accuracy: 87.75%
tensor(0.0086, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-2.6077e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.329555
Average KL loss: 0.104718
Average total loss: 0.434272
tensor(0.0084, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-2.8945e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.325918
Average KL loss: 0.103550
Average total loss: 0.429468
tensor(0.0083, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-2.5147e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.316965
Average KL loss: 0.102745
Average total loss: 0.419710
tensor(0.0082, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.2560e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.318738
Average KL loss: 0.102161
Average total loss: 0.420900
tensor(0.0081, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.7219e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.317082
Average KL loss: 0.101729
Average total loss: 0.418811
tensor(0.0080, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.0905e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.316711
Average KL loss: 0.101406
Average total loss: 0.418117
tensor(0.0080, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.3350e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.326660
Average KL loss: 0.101164
Average total loss: 0.427824
tensor(0.0079, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-2.7621e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.304166
Average KL loss: 0.100973
Average total loss: 0.405138
tensor(0.0079, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.2232e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.304591
Average KL loss: 0.100818
Average total loss: 0.405409
tensor(0.0079, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.4626e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.303677
Average KL loss: 0.100688
Average total loss: 0.404364
tensor(0.0078, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.7405e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.308238
Average KL loss: 0.100583
Average total loss: 0.408821
tensor(0.0078, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.9387e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.298224
Average KL loss: 0.100498
Average total loss: 0.398722
tensor(0.0078, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.0362e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.298140
Average KL loss: 0.100424
Average total loss: 0.398564
tensor(0.0078, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-3.0603e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.293625
Average KL loss: 0.100362
Average total loss: 0.393987
tensor(0.0078, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.4858e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.298920
Average KL loss: 0.100311
Average total loss: 0.399231
tensor(0.0078, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.3595e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.296862
Average KL loss: 0.100267
Average total loss: 0.397129
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.0641e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.293449
Average KL loss: 0.100233
Average total loss: 0.393681
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.8943e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.299427
Average KL loss: 0.100209
Average total loss: 0.399636
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.7597e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.304320
Average KL loss: 0.100193
Average total loss: 0.404513
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.8725e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.295118
Average KL loss: 0.100178
Average total loss: 0.395297
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.5389e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.305175
Average KL loss: 0.100171
Average total loss: 0.405346
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.7254e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.286634
Average KL loss: 0.100167
Average total loss: 0.386802
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.4639e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.296850
Average KL loss: 0.100158
Average total loss: 0.397008
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.1963e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.286510
Average KL loss: 0.100163
Average total loss: 0.386673
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.3928e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.284429
Average KL loss: 0.100172
Average total loss: 0.384601
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.6956e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.282982
Average KL loss: 0.100184
Average total loss: 0.383166
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.7261e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.290501
Average KL loss: 0.100198
Average total loss: 0.390699
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.3387e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.278787
Average KL loss: 0.100217
Average total loss: 0.379005
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.1711e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.272144
Average KL loss: 0.100236
Average total loss: 0.372380
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.0984e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.279054
Average KL loss: 0.100255
Average total loss: 0.379309
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.9769e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.278340
Average KL loss: 0.100285
Average total loss: 0.378624
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.9177e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.276104
Average KL loss: 0.100321
Average total loss: 0.376425
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.5812e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.280491
Average KL loss: 0.100352
Average total loss: 0.380843
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.2529e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.271719
Average KL loss: 0.100378
Average total loss: 0.372097
tensor(0.0077, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.8085e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.277437
Average KL loss: 0.100409
Average total loss: 0.377845
tensor(0.0076, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.6191e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.274270
Average KL loss: 0.100446
Average total loss: 0.374716
tensor(0.0076, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.7570e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.269535
Average KL loss: 0.100481
Average total loss: 0.370016
tensor(0.0076, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-9.9181e-09, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.270424
Average KL loss: 0.100506
Average total loss: 0.370930
tensor(0.0076, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.8809e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.272179
Average KL loss: 0.100536
Average total loss: 0.372715
tensor(0.0076, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.5980e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.272931
Average KL loss: 0.100570
Average total loss: 0.373501
tensor(0.0076, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.2090e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.270289
Average KL loss: 0.100604
Average total loss: 0.370893
tensor(0.0076, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.8245e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.267288
Average KL loss: 0.100641
Average total loss: 0.367930
tensor(0.0076, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.6272e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.263343
Average KL loss: 0.100683
Average total loss: 0.364026
tensor(0.0076, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.7436e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.257868
Average KL loss: 0.100720
Average total loss: 0.358589
tensor(0.0076, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.9870e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.266054
Average KL loss: 0.100755
Average total loss: 0.366809
tensor(0.0076, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.7762e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.257298
Average KL loss: 0.100794
Average total loss: 0.358092
tensor(0.0076, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.4047e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.263564
Average KL loss: 0.100831
Average total loss: 0.364395
tensor(0.0076, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.5613e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.264991
Average KL loss: 0.100869
Average total loss: 0.365860
tensor(0.0076, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-2.5218e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.256327
Average KL loss: 0.100905
Average total loss: 0.357231
tensor(0.0076, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.6693e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.261499
Average KL loss: 0.100942
Average total loss: 0.362441
tensor(0.0076, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.5036e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.257978
Average KL loss: 0.100980
Average total loss: 0.358958
tensor(0.0076, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.5703e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.259209
Average KL loss: 0.101026
Average total loss: 0.360234
tensor(0.0076, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.5591e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.253432
Average KL loss: 0.101077
Average total loss: 0.354509
tensor(0.0076, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.9079e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.256300
Average KL loss: 0.101123
Average total loss: 0.357422
tensor(0.0076, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.6366e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.250381
Average KL loss: 0.101164
Average total loss: 0.351545
tensor(0.0076, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.8322e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.255599
Average KL loss: 0.101210
Average total loss: 0.356809
tensor(0.0076, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.6245e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.256208
Average KL loss: 0.101254
Average total loss: 0.357462
tensor(0.0076, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.7088e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.259110
Average KL loss: 0.101304
Average total loss: 0.360415
tensor(0.0076, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-1.6301e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.252521
Average KL loss: 0.101360
Average total loss: 0.353880
tensor(0.0076, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.0695e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.248378
Average KL loss: 0.101411
Average total loss: 0.349789
tensor(0.0076, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.5310e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.257676
Average KL loss: 0.101468
Average total loss: 0.359144
tensor(0.0076, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.4512e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.247504
Average KL loss: 0.101517
Average total loss: 0.349022
tensor(0.0076, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.2540e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.250600
Average KL loss: 0.101567
Average total loss: 0.352167
tensor(0.0076, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.1574e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.245833
Average KL loss: 0.101618
Average total loss: 0.347451
tensor(0.0076, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.8358e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.253007
Average KL loss: 0.101675
Average total loss: 0.354682
tensor(0.0076, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-8.9993e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.248697
Average KL loss: 0.101729
Average total loss: 0.350425
tensor(0.0076, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.1882e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.243262
Average KL loss: 0.101790
Average total loss: 0.345053
tensor(0.0076, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-1.3326e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.241972
Average KL loss: 0.101857
Average total loss: 0.343829
tensor(0.0076, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.3436e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.241420
Average KL loss: 0.101921
Average total loss: 0.343341
tensor(0.0076, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.6370e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.240478
Average KL loss: 0.101983
Average total loss: 0.342461
tensor(0.0076, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.4406e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.250142
Average KL loss: 0.102047
Average total loss: 0.352188
tensor(0.0076, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.4303e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.246588
Average KL loss: 0.102113
Average total loss: 0.348701
tensor(0.0076, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.3450e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.247885
Average KL loss: 0.102179
Average total loss: 0.350064
tensor(0.0076, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-8.9172e-09, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.247308
Average KL loss: 0.102249
Average total loss: 0.349557
tensor(0.0076, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.2890e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.243407
Average KL loss: 0.102318
Average total loss: 0.345725
tensor(0.0076, device='cuda:0') tensor(0.0141, device='cuda:0') tensor(-1.8755e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.242504
Average KL loss: 0.102390
Average total loss: 0.344894
tensor(0.0076, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.4775e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.239212
Average KL loss: 0.102459
Average total loss: 0.341671
tensor(0.0076, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.7393e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.243330
Average KL loss: 0.102525
Average total loss: 0.345855
tensor(0.0076, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.6282e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.243890
Average KL loss: 0.102596
Average total loss: 0.346486
tensor(0.0076, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.1949e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.239541
Average KL loss: 0.102660
Average total loss: 0.342201
tensor(0.0076, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.4743e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.243411
Average KL loss: 0.102729
Average total loss: 0.346140
tensor(0.0076, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.8343e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.238238
Average KL loss: 0.102800
Average total loss: 0.341038
tensor(0.0076, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-1.4055e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.234740
Average KL loss: 0.102874
Average total loss: 0.337614
tensor(0.0076, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-8.9148e-09, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.239455
Average KL loss: 0.102947
Average total loss: 0.342402
tensor(0.0076, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.1934e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.234050
Average KL loss: 0.103022
Average total loss: 0.337071
tensor(0.0076, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.5469e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.230431
Average KL loss: 0.103094
Average total loss: 0.333525
tensor(0.0076, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.9952e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.230179
Average KL loss: 0.103166
Average total loss: 0.333345
tensor(0.0076, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.7270e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.242463
Average KL loss: 0.103242
Average total loss: 0.345705
tensor(0.0076, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.7440e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.238220
Average KL loss: 0.103322
Average total loss: 0.341542
tensor(0.0076, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.6631e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.241473
Average KL loss: 0.103401
Average total loss: 0.344874
tensor(0.0076, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-1.4170e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.230889
Average KL loss: 0.103481
Average total loss: 0.334370
tensor(0.0076, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-9.3595e-09, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.229627
Average KL loss: 0.103558
Average total loss: 0.333185
tensor(0.0076, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.4716e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.236850
Average KL loss: 0.103636
Average total loss: 0.340486
tensor(0.0076, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.6013e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.233872
Average KL loss: 0.103713
Average total loss: 0.337585
tensor(0.0076, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.2567e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.229816
Average KL loss: 0.103794
Average total loss: 0.333610
tensor(0.0077, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.1260e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.228879
Average KL loss: 0.103870
Average total loss: 0.332749
tensor(0.0077, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.4024e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.232620
Average KL loss: 0.103942
Average total loss: 0.336562
tensor(0.0077, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-1.1034e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.231556
Average KL loss: 0.104019
Average total loss: 0.335575
tensor(0.0077, device='cuda:0') tensor(0.0144, device='cuda:0') tensor(-2.0112e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.229964
Average KL loss: 0.104105
Average total loss: 0.334069
tensor(0.0077, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-9.5834e-09, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.227300
Average KL loss: 0.104180
Average total loss: 0.331480
tensor(0.0077, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.3752e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.226602
Average KL loss: 0.104258
Average total loss: 0.330860
tensor(0.0077, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.2188e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.231479
Average KL loss: 0.104337
Average total loss: 0.335816
tensor(0.0077, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.5938e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.218449
Average KL loss: 0.104418
Average total loss: 0.322867
tensor(0.0077, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.6258e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.217003
Average KL loss: 0.104493
Average total loss: 0.321496
tensor(0.0077, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.4574e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.223901
Average KL loss: 0.104561
Average total loss: 0.328462
tensor(0.0077, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.0863e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.228595
Average KL loss: 0.104640
Average total loss: 0.333235
tensor(0.0077, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.2830e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.222447
Average KL loss: 0.104723
Average total loss: 0.327170
tensor(0.0077, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.2922e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.230842
Average KL loss: 0.104808
Average total loss: 0.335651
tensor(0.0077, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.0769e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.222620
Average KL loss: 0.104893
Average total loss: 0.327513
tensor(0.0077, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.1974e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.222631
Average KL loss: 0.104977
Average total loss: 0.327608
tensor(0.0077, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.1003e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.226668
Average KL loss: 0.105061
Average total loss: 0.331729
tensor(0.0077, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.4292e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.217945
Average KL loss: 0.105145
Average total loss: 0.323091
tensor(0.0077, device='cuda:0') tensor(0.0146, device='cuda:0') tensor(-1.1666e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.217811
Average KL loss: 0.105222
Average total loss: 0.323034
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.4900e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.223061
Average KL loss: 0.105298
Average total loss: 0.328359
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.1731e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.228106
Average KL loss: 0.105377
Average total loss: 0.333482
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.1753e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.224310
Average KL loss: 0.105421
Average total loss: 0.329731
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.3659e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.218276
Average KL loss: 0.105428
Average total loss: 0.323704
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.5117e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.222211
Average KL loss: 0.105435
Average total loss: 0.327647
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.2753e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.214901
Average KL loss: 0.105443
Average total loss: 0.320344
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.0406e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.223104
Average KL loss: 0.105451
Average total loss: 0.328555
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.2226e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.221749
Average KL loss: 0.105459
Average total loss: 0.327208
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-6.0250e-09, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.224417
Average KL loss: 0.105467
Average total loss: 0.329884
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-8.5847e-09, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.217358
Average KL loss: 0.105475
Average total loss: 0.322833
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.0590e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.221997
Average KL loss: 0.105482
Average total loss: 0.327479
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.2739e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.218031
Average KL loss: 0.105490
Average total loss: 0.323521
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.6430e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.219091
Average KL loss: 0.105498
Average total loss: 0.324589
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-8.4992e-09, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.216425
Average KL loss: 0.105506
Average total loss: 0.321931
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.2358e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.222749
Average KL loss: 0.105514
Average total loss: 0.328263
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.3671e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.212940
Average KL loss: 0.105521
Average total loss: 0.318461
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.3591e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.216634
Average KL loss: 0.105528
Average total loss: 0.322162
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.1877e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.219847
Average KL loss: 0.105536
Average total loss: 0.325382
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.9487e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.215596
Average KL loss: 0.105543
Average total loss: 0.321139
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.4077e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.211933
Average KL loss: 0.105550
Average total loss: 0.317483
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.0091e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.215512
Average KL loss: 0.105558
Average total loss: 0.321070
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.0105e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.221577
Average KL loss: 0.105566
Average total loss: 0.327142
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.1948e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.215014
Average KL loss: 0.105573
Average total loss: 0.320587
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.3729e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.217716
Average KL loss: 0.105581
Average total loss: 0.323297
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-8.3214e-09, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.222144
Average KL loss: 0.105589
Average total loss: 0.327733
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.6815e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.226058
Average KL loss: 0.105597
Average total loss: 0.331654
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.6966e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.220222
Average KL loss: 0.105606
Average total loss: 0.325827
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.4856e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.219639
Average KL loss: 0.105614
Average total loss: 0.325253
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.0741e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.213588
Average KL loss: 0.105622
Average total loss: 0.319210
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.2401e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.213584
Average KL loss: 0.105629
Average total loss: 0.319213
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.2400e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.219544
Average KL loss: 0.105637
Average total loss: 0.325181
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.0870e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.221744
Average KL loss: 0.105642
Average total loss: 0.327386
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.0199e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.217552
Average KL loss: 0.105643
Average total loss: 0.323194
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.3959e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.214897
Average KL loss: 0.105644
Average total loss: 0.320540
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.2871e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.222453
Average KL loss: 0.105644
Average total loss: 0.328097
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.3416e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.221364
Average KL loss: 0.105645
Average total loss: 0.327009
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.0214e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.227067
Average KL loss: 0.105646
Average total loss: 0.332713
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-9.7200e-09, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.222725
Average KL loss: 0.105647
Average total loss: 0.328371
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.5405e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.218681
Average KL loss: 0.105648
Average total loss: 0.324328
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-8.4076e-09, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.219540
Average KL loss: 0.105648
Average total loss: 0.325189
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.4556e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.220766
Average KL loss: 0.105649
Average total loss: 0.326415
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-1.5181e-08, device='cuda:0')
 Percentile value: 1.2345540523529053
Non-zero model percentage: 0.39063358306884766%, Non-zero mask percentage: 0.39063358306884766%

--- Pruning Level [8/12]: ---
conv1.weight         | nonzeros =     128 /    1728             (  7.41%) | total_pruned =    1600 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      75 /   36864             (  0.20%) | total_pruned =   36789 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     145 /   36864             (  0.39%) | total_pruned =   36719 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      16 /      64             ( 25.00%) | total_pruned =      48 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     325 /   36864             (  0.88%) | total_pruned =   36539 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     529 /   36864             (  1.44%) | total_pruned =   36335 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      25 /      64             ( 39.06%) | total_pruned =      39 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =    1423 /   73728             (  1.93%) | total_pruned =   72305 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      81 /     128             ( 63.28%) | total_pruned =      47 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    2598 /  147456             (  1.76%) | total_pruned =  144858 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      91 /     128             ( 71.09%) | total_pruned =      37 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     309 /    8192             (  3.77%) | total_pruned =    7883 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      66 /     128             ( 51.56%) | total_pruned =      62 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =    1307 /  147456             (  0.89%) | total_pruned =  146149 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =    1304 /  147456             (  0.88%) | total_pruned =  146152 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    5125 /  294912             (  1.74%) | total_pruned =  289787 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    7534 /  589824             (  1.28%) | total_pruned =  582290 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     219 /     256             ( 85.55%) | total_pruned =      37 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      11 /     256             (  4.30%) | total_pruned =     245 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     574 /   32768             (  1.75%) | total_pruned =   32194 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =     127 /     256             ( 49.61%) | total_pruned =     129 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    4069 /  589824             (  0.69%) | total_pruned =  585755 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     160 /     256             ( 62.50%) | total_pruned =      96 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    3352 /  589824             (  0.57%) | total_pruned =  586472 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     153 /     256             ( 59.77%) | total_pruned =     103 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    4985 / 1179648             (  0.42%) | total_pruned = 1174663 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     353 /     512             ( 68.95%) | total_pruned =     159 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    3400 / 2359296             (  0.14%) | total_pruned = 2355896 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     144 /     512             ( 28.12%) | total_pruned =     368 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      54 /     512             ( 10.55%) | total_pruned =     458 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      64 /  131072             (  0.05%) | total_pruned =  131008 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      21 /     512             (  4.10%) | total_pruned =     491 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      48 /     512             (  9.38%) | total_pruned =     464 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =    1806 / 2359296             (  0.08%) | total_pruned = 2357490 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      93 /     512             ( 18.16%) | total_pruned =     419 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =    1864 / 2359296             (  0.08%) | total_pruned = 2357432 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      74 /     512             ( 14.45%) | total_pruned =     438 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      67 /     512             ( 13.09%) | total_pruned =     445 | shape = torch.Size([512])
linear.weight        | nonzeros =     468 /    5120             (  9.14%) | total_pruned =    4652 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       1 /      10             ( 10.00%) | total_pruned =       9 | shape = torch.Size([10])
alive: 43668, pruned : 11135094, total: 11178762, Compression rate :     255.99x  ( 99.61% pruned)
Train Epoch: 77/100 Loss: 0.039031 Accuracy: 86.53 99.97 % Best test Accuracy: 87.14%
tensor(0.0077, device='cuda:0') tensor(0.0147, device='cuda:0') tensor(-2.6427e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.470239
Average KL loss: 0.104448
Average total loss: 0.574686
tensor(0.0075, device='cuda:0') tensor(0.0145, device='cuda:0') tensor(-1.9998e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.452112
Average KL loss: 0.102521
Average total loss: 0.554632
tensor(0.0074, device='cuda:0') tensor(0.0143, device='cuda:0') tensor(-3.1438e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.462549
Average KL loss: 0.100878
Average total loss: 0.563427
tensor(0.0072, device='cuda:0') tensor(0.0142, device='cuda:0') tensor(-3.9026e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.458068
Average KL loss: 0.099454
Average total loss: 0.557521
tensor(0.0071, device='cuda:0') tensor(0.0140, device='cuda:0') tensor(-3.8051e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.455512
Average KL loss: 0.098216
Average total loss: 0.553728
tensor(0.0070, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-3.0163e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.444824
Average KL loss: 0.097154
Average total loss: 0.541978
tensor(0.0069, device='cuda:0') tensor(0.0139, device='cuda:0') tensor(-3.4925e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.450805
Average KL loss: 0.096236
Average total loss: 0.547040
tensor(0.0068, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-3.1990e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.448397
Average KL loss: 0.095456
Average total loss: 0.543854
tensor(0.0067, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.8589e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.440645
Average KL loss: 0.094792
Average total loss: 0.535437
tensor(0.0066, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.2676e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.441957
Average KL loss: 0.094228
Average total loss: 0.536185
tensor(0.0066, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.0821e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.433861
Average KL loss: 0.093755
Average total loss: 0.527616
tensor(0.0065, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-3.0270e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.432115
Average KL loss: 0.093358
Average total loss: 0.525473
tensor(0.0064, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-4.4525e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.432197
Average KL loss: 0.093028
Average total loss: 0.525225
tensor(0.0064, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.0003e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.419666
Average KL loss: 0.092749
Average total loss: 0.512415
tensor(0.0063, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.5472e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.422163
Average KL loss: 0.092515
Average total loss: 0.514678
tensor(0.0063, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.3923e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.420644
Average KL loss: 0.092326
Average total loss: 0.512970
tensor(0.0062, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.6882e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.412724
Average KL loss: 0.092165
Average total loss: 0.504889
tensor(0.0062, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.9948e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.419333
Average KL loss: 0.092033
Average total loss: 0.511367
tensor(0.0062, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.4888e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.419671
Average KL loss: 0.091921
Average total loss: 0.511593
tensor(0.0061, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.5664e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.417409
Average KL loss: 0.091834
Average total loss: 0.509243
tensor(0.0061, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.6181e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.409146
Average KL loss: 0.091758
Average total loss: 0.500903
tensor(0.0061, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.7460e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.406334
Average KL loss: 0.091694
Average total loss: 0.498028
tensor(0.0061, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-8.9658e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.413796
Average KL loss: 0.091642
Average total loss: 0.505438
tensor(0.0061, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.9503e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.400166
Average KL loss: 0.091599
Average total loss: 0.491766
tensor(0.0060, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.6941e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.401382
Average KL loss: 0.091562
Average total loss: 0.492944
tensor(0.0060, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.2971e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.400872
Average KL loss: 0.091533
Average total loss: 0.492405
tensor(0.0060, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.4782e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.405918
Average KL loss: 0.091505
Average total loss: 0.497423
tensor(0.0060, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-3.3412e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.397412
Average KL loss: 0.091483
Average total loss: 0.488896
tensor(0.0060, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.2587e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.397153
Average KL loss: 0.091466
Average total loss: 0.488619
tensor(0.0060, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-3.1844e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.393158
Average KL loss: 0.091454
Average total loss: 0.484612
tensor(0.0060, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-3.1981e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.392308
Average KL loss: 0.091442
Average total loss: 0.483750
tensor(0.0060, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-3.1634e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.387992
Average KL loss: 0.091433
Average total loss: 0.479425
tensor(0.0060, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.7124e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.393182
Average KL loss: 0.091427
Average total loss: 0.484609
tensor(0.0060, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.2963e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.393113
Average KL loss: 0.091425
Average total loss: 0.484537
tensor(0.0060, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-6.8863e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.386086
Average KL loss: 0.091422
Average total loss: 0.477509
tensor(0.0060, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.4903e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.383710
Average KL loss: 0.091423
Average total loss: 0.475133
tensor(0.0060, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-3.2375e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.381232
Average KL loss: 0.091426
Average total loss: 0.472658
tensor(0.0059, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.5500e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.384967
Average KL loss: 0.091433
Average total loss: 0.476401
tensor(0.0059, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.4027e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.382428
Average KL loss: 0.091443
Average total loss: 0.473871
tensor(0.0059, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-2.3424e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.377272
Average KL loss: 0.091449
Average total loss: 0.468721
tensor(0.0059, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.6339e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.394504
Average KL loss: 0.091457
Average total loss: 0.485961
tensor(0.0059, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.0297e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.377280
Average KL loss: 0.091470
Average total loss: 0.468750
tensor(0.0059, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.2798e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.383025
Average KL loss: 0.091489
Average total loss: 0.474514
tensor(0.0059, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.3255e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.374828
Average KL loss: 0.091503
Average total loss: 0.466331
tensor(0.0059, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.8447e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.373775
Average KL loss: 0.091523
Average total loss: 0.465298
tensor(0.0059, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.3761e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.364455
Average KL loss: 0.091543
Average total loss: 0.455998
tensor(0.0059, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.5433e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.374550
Average KL loss: 0.091564
Average total loss: 0.466114
tensor(0.0059, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.4130e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.374281
Average KL loss: 0.091583
Average total loss: 0.465864
tensor(0.0059, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.3283e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.370894
Average KL loss: 0.091607
Average total loss: 0.462501
tensor(0.0059, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.4111e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.370970
Average KL loss: 0.091631
Average total loss: 0.462600
tensor(0.0059, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-2.0647e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.366655
Average KL loss: 0.091655
Average total loss: 0.458310
tensor(0.0059, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.3135e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.354323
Average KL loss: 0.091677
Average total loss: 0.446000
tensor(0.0059, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-3.0426e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.363970
Average KL loss: 0.091706
Average total loss: 0.455676
tensor(0.0059, device='cuda:0') tensor(0.0134, device='cuda:0') tensor(-1.9090e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.369697
Average KL loss: 0.091740
Average total loss: 0.461436
tensor(0.0059, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.5693e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.357446
Average KL loss: 0.091771
Average total loss: 0.449217
tensor(0.0059, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.2288e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.362468
Average KL loss: 0.091808
Average total loss: 0.454276
tensor(0.0059, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.8869e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.364082
Average KL loss: 0.091845
Average total loss: 0.455927
tensor(0.0059, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.1092e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.351340
Average KL loss: 0.091881
Average total loss: 0.443220
tensor(0.0059, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.5767e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.360470
Average KL loss: 0.091915
Average total loss: 0.452385
tensor(0.0059, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.0211e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.358622
Average KL loss: 0.091957
Average total loss: 0.450578
tensor(0.0059, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-1.9797e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.351128
Average KL loss: 0.091995
Average total loss: 0.443123
tensor(0.0059, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.3914e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.351131
Average KL loss: 0.092036
Average total loss: 0.443167
tensor(0.0059, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.0227e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.352171
Average KL loss: 0.092079
Average total loss: 0.444250
tensor(0.0059, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-2.6399e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.364929
Average KL loss: 0.092126
Average total loss: 0.457055
tensor(0.0059, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.9711e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.338830
Average KL loss: 0.092173
Average total loss: 0.431003
tensor(0.0059, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.7679e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.350980
Average KL loss: 0.092219
Average total loss: 0.443199
tensor(0.0059, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.8811e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.345646
Average KL loss: 0.092267
Average total loss: 0.437913
tensor(0.0059, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.7576e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.341917
Average KL loss: 0.092321
Average total loss: 0.434238
tensor(0.0059, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.8917e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.345044
Average KL loss: 0.092375
Average total loss: 0.437418
tensor(0.0059, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-2.2703e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.343089
Average KL loss: 0.092431
Average total loss: 0.435519
tensor(0.0059, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(-1.9818e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.338973
Average KL loss: 0.092489
Average total loss: 0.431462
tensor(0.0059, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-3.2377e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.338461
Average KL loss: 0.092545
Average total loss: 0.431006
tensor(0.0059, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.9688e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.345576
Average KL loss: 0.092602
Average total loss: 0.438179
tensor(0.0059, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.1508e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.345190
Average KL loss: 0.092660
Average total loss: 0.437850
tensor(0.0059, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.7823e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.338272
Average KL loss: 0.092720
Average total loss: 0.430992
tensor(0.0059, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.1284e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.346800
Average KL loss: 0.092781
Average total loss: 0.439581
tensor(0.0059, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.4027e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.344876
Average KL loss: 0.092813
Average total loss: 0.437689
tensor(0.0059, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.6533e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.337690
Average KL loss: 0.092819
Average total loss: 0.430510
tensor(0.0059, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.8558e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.334770
Average KL loss: 0.092826
Average total loss: 0.427595
tensor(0.0059, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.0490e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.332500
Average KL loss: 0.092832
Average total loss: 0.425332
tensor(0.0059, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.1951e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.339341
Average KL loss: 0.092838
Average total loss: 0.432180
tensor(0.0059, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.4515e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.336131
Average KL loss: 0.092845
Average total loss: 0.428976
tensor(0.0059, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.7429e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.340369
Average KL loss: 0.092851
Average total loss: 0.433220
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.8113e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.334326
Average KL loss: 0.092858
Average total loss: 0.427184
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.3237e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.334285
Average KL loss: 0.092864
Average total loss: 0.427149
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.1439e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.342621
Average KL loss: 0.092870
Average total loss: 0.435492
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.2072e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.333078
Average KL loss: 0.092877
Average total loss: 0.425955
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.9089e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.334908
Average KL loss: 0.092883
Average total loss: 0.427791
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.8553e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.340093
Average KL loss: 0.092890
Average total loss: 0.432983
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.0941e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.337673
Average KL loss: 0.092896
Average total loss: 0.430569
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.6396e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.332941
Average KL loss: 0.092902
Average total loss: 0.425843
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.7420e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.340809
Average KL loss: 0.092906
Average total loss: 0.433715
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.7841e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.337506
Average KL loss: 0.092907
Average total loss: 0.430412
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.8256e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.329681
Average KL loss: 0.092907
Average total loss: 0.422589
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.7822e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.340643
Average KL loss: 0.092908
Average total loss: 0.433551
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.1046e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.334752
Average KL loss: 0.092908
Average total loss: 0.427660
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.9254e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.332494
Average KL loss: 0.092909
Average total loss: 0.425403
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.3377e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.338339
Average KL loss: 0.092910
Average total loss: 0.431249
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.9150e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.338155
Average KL loss: 0.092910
Average total loss: 0.431065
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.3898e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.326720
Average KL loss: 0.092911
Average total loss: 0.419631
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.5371e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.337409
Average KL loss: 0.092912
Average total loss: 0.430321
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-2.8963e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.335223
Average KL loss: 0.092912
Average total loss: 0.428135
tensor(0.0060, device='cuda:0') tensor(0.0137, device='cuda:0') tensor(-1.8406e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.337859
Average KL loss: 0.092913
Average total loss: 0.430772
tensor(0.0060, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.1308e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.337206
Average KL loss: 0.092914
Average total loss: 0.430119
tensor(0.0060, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.0608e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.329719
Average KL loss: 0.092914
Average total loss: 0.422634
tensor(0.0060, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.2150e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.330935
Average KL loss: 0.092915
Average total loss: 0.423850
tensor(0.0060, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-2.1874e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.332919
Average KL loss: 0.092916
Average total loss: 0.425835
tensor(0.0060, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.3201e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.334835
Average KL loss: 0.092916
Average total loss: 0.427752
tensor(0.0060, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-4.6295e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.334450
Average KL loss: 0.092917
Average total loss: 0.427367
tensor(0.0060, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.9493e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.330675
Average KL loss: 0.092918
Average total loss: 0.423593
tensor(0.0060, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-1.9624e-08, device='cuda:0')
 Percentile value: 1.809396505355835
Non-zero model percentage: 0.19531679153442383%, Non-zero mask percentage: 0.19531679153442383%

--- Pruning Level [9/12]: ---
conv1.weight         | nonzeros =     126 /    1728             (  7.29%) | total_pruned =    1602 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      64 /   36864             (  0.17%) | total_pruned =   36800 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =      13 /      64             ( 20.31%) | total_pruned =      51 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =     105 /   36864             (  0.28%) | total_pruned =   36759 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      12 /      64             ( 18.75%) | total_pruned =      52 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     250 /   36864             (  0.68%) | total_pruned =   36614 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     412 /   36864             (  1.12%) | total_pruned =   36452 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      23 /      64             ( 35.94%) | total_pruned =      41 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     918 /   73728             (  1.25%) | total_pruned =   72810 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      78 /     128             ( 60.94%) | total_pruned =      50 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =      10 /     128             (  7.81%) | total_pruned =     118 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =    1444 /  147456             (  0.98%) | total_pruned =  146012 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      87 /     128             ( 67.97%) | total_pruned =      41 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     234 /    8192             (  2.86%) | total_pruned =    7958 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     728 /  147456             (  0.49%) | total_pruned =  146728 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     713 /  147456             (  0.48%) | total_pruned =  146743 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      71 /     128             ( 55.47%) | total_pruned =      57 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       2 /     128             (  1.56%) | total_pruned =     126 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    2603 /  294912             (  0.88%) | total_pruned =  292309 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     211 /     256             ( 82.42%) | total_pruned =      45 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    3299 /  589824             (  0.56%) | total_pruned =  586525 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     215 /     256             ( 83.98%) | total_pruned =      41 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =      10 /     256             (  3.91%) | total_pruned =     246 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     303 /   32768             (  0.92%) | total_pruned =   32465 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      99 /     256             ( 38.67%) | total_pruned =     157 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       9 /     256             (  3.52%) | total_pruned =     247 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =    1905 /  589824             (  0.32%) | total_pruned =  587919 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     155 /     256             ( 60.55%) | total_pruned =     101 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =    1574 /  589824             (  0.27%) | total_pruned =  588250 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =     130 /     256             ( 50.78%) | total_pruned =     126 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =    1924 / 1179648             (  0.16%) | total_pruned = 1177724 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     288 /     512             ( 56.25%) | total_pruned =     224 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       5 /     512             (  0.98%) | total_pruned =     507 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =    1239 / 2359296             (  0.05%) | total_pruned = 2358057 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =     105 /     512             ( 20.51%) | total_pruned =     407 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      34 /     512             (  6.64%) | total_pruned =     478 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      37 /  131072             (  0.03%) | total_pruned =  131035 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =      12 /     512             (  2.34%) | total_pruned =     500 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      28 /     512             (  5.47%) | total_pruned =     484 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     886 / 2359296             (  0.04%) | total_pruned = 2358410 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      77 /     512             ( 15.04%) | total_pruned =     435 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     844 / 2359296             (  0.04%) | total_pruned = 2358452 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      39 /     512             (  7.62%) | total_pruned =     473 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      33 /     512             (  6.45%) | total_pruned =     479 | shape = torch.Size([512])
linear.weight        | nonzeros =     281 /    5120             (  5.49%) | total_pruned =    4839 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 21834, pruned : 11156928, total: 11178762, Compression rate :     511.99x  ( 99.80% pruned)
Train Epoch: 99/100 Loss: 0.137454 Accuracy: 81.40 97.92 % Best test Accuracy: 83.58%
tensor(0.0060, device='cuda:0') tensor(0.0138, device='cuda:0') tensor(-4.1019e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.818272
Average KL loss: 0.091888
Average total loss: 0.910161
tensor(0.0058, device='cuda:0') tensor(0.0135, device='cuda:0') tensor(-3.6438e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.820622
Average KL loss: 0.090034
Average total loss: 0.910656
tensor(0.0058, device='cuda:0') tensor(0.0133, device='cuda:0') tensor(-4.8641e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.816251
Average KL loss: 0.088287
Average total loss: 0.904538
tensor(0.0057, device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-6.2850e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.807366
Average KL loss: 0.086630
Average total loss: 0.893996
tensor(0.0056, device='cuda:0') tensor(0.0129, device='cuda:0') tensor(-5.0611e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.805100
Average KL loss: 0.085059
Average total loss: 0.890159
tensor(0.0055, device='cuda:0') tensor(0.0128, device='cuda:0') tensor(-4.6921e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.792812
Average KL loss: 0.083573
Average total loss: 0.876385
tensor(0.0054, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-4.3864e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.800196
Average KL loss: 0.082172
Average total loss: 0.882368
tensor(0.0053, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.4157e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.799555
Average KL loss: 0.080859
Average total loss: 0.880413
tensor(0.0053, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-4.4449e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.772666
Average KL loss: 0.079630
Average total loss: 0.852297
tensor(0.0052, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.8435e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.769758
Average KL loss: 0.078482
Average total loss: 0.848240
tensor(0.0051, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-3.2566e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.766262
Average KL loss: 0.077416
Average total loss: 0.843678
tensor(0.0050, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-3.7966e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.759567
Average KL loss: 0.076429
Average total loss: 0.835996
tensor(0.0050, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-4.2596e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.776120
Average KL loss: 0.075520
Average total loss: 0.851640
tensor(0.0049, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-4.9082e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.769969
Average KL loss: 0.074684
Average total loss: 0.844653
tensor(0.0048, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.6717e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.759486
Average KL loss: 0.073917
Average total loss: 0.833403
tensor(0.0048, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.6982e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.745405
Average KL loss: 0.073214
Average total loss: 0.818619
tensor(0.0047, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-4.2831e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.753391
Average KL loss: 0.072575
Average total loss: 0.825966
tensor(0.0047, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.6708e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.747976
Average KL loss: 0.071995
Average total loss: 0.819971
tensor(0.0046, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-4.1036e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.735696
Average KL loss: 0.071466
Average total loss: 0.807162
tensor(0.0046, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-4.7328e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.731691
Average KL loss: 0.070989
Average total loss: 0.802679
tensor(0.0045, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-4.3366e-08, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.730231
Average KL loss: 0.070555
Average total loss: 0.800787
tensor(0.0045, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-3.7972e-08, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.736022
Average KL loss: 0.070165
Average total loss: 0.806186
tensor(0.0044, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-3.9559e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.749812
Average KL loss: 0.069815
Average total loss: 0.819627
tensor(0.0044, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-4.9653e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.720563
Average KL loss: 0.069500
Average total loss: 0.790063
tensor(0.0044, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-4.1231e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.716196
Average KL loss: 0.069217
Average total loss: 0.785414
tensor(0.0043, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-4.0703e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.720971
Average KL loss: 0.068962
Average total loss: 0.789932
tensor(0.0043, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-5.9479e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.721485
Average KL loss: 0.068734
Average total loss: 0.790219
tensor(0.0043, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-4.5109e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.709045
Average KL loss: 0.068529
Average total loss: 0.777574
tensor(0.0042, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-5.1844e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.707900
Average KL loss: 0.068341
Average total loss: 0.776242
tensor(0.0042, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-3.8423e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.709555
Average KL loss: 0.068173
Average total loss: 0.777729
tensor(0.0042, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-3.5619e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.700616
Average KL loss: 0.068021
Average total loss: 0.768637
tensor(0.0042, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-3.4367e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.709290
Average KL loss: 0.067882
Average total loss: 0.777172
tensor(0.0042, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.7445e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.688018
Average KL loss: 0.067761
Average total loss: 0.755780
tensor(0.0041, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.9526e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.695870
Average KL loss: 0.067650
Average total loss: 0.763520
tensor(0.0041, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.9388e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.686369
Average KL loss: 0.067548
Average total loss: 0.753917
tensor(0.0041, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-4.5082e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.695241
Average KL loss: 0.067452
Average total loss: 0.762693
tensor(0.0041, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.3780e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.685356
Average KL loss: 0.067364
Average total loss: 0.752720
tensor(0.0041, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.2892e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.687058
Average KL loss: 0.067282
Average total loss: 0.754340
tensor(0.0041, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.6568e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.692526
Average KL loss: 0.067207
Average total loss: 0.759732
tensor(0.0040, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.1565e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.674851
Average KL loss: 0.067135
Average total loss: 0.741986
tensor(0.0040, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.9068e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.680575
Average KL loss: 0.067070
Average total loss: 0.747645
tensor(0.0040, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.5845e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.676950
Average KL loss: 0.067009
Average total loss: 0.743959
tensor(0.0040, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.7529e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.671290
Average KL loss: 0.066952
Average total loss: 0.738242
tensor(0.0040, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-4.6197e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.660495
Average KL loss: 0.066898
Average total loss: 0.727393
tensor(0.0040, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-4.1383e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.663858
Average KL loss: 0.066847
Average total loss: 0.730705
tensor(0.0040, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.4232e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.671757
Average KL loss: 0.066799
Average total loss: 0.738556
tensor(0.0040, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.9764e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.662126
Average KL loss: 0.066752
Average total loss: 0.728878
tensor(0.0040, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.2579e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.663791
Average KL loss: 0.066707
Average total loss: 0.730498
tensor(0.0040, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.2540e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.667457
Average KL loss: 0.066665
Average total loss: 0.734122
tensor(0.0040, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.9284e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.652643
Average KL loss: 0.066625
Average total loss: 0.719268
tensor(0.0040, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.7267e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.651816
Average KL loss: 0.066587
Average total loss: 0.718403
tensor(0.0040, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.6237e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.652498
Average KL loss: 0.066552
Average total loss: 0.719049
tensor(0.0040, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.9155e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.658640
Average KL loss: 0.066516
Average total loss: 0.725155
tensor(0.0040, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-4.2822e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.653047
Average KL loss: 0.066484
Average total loss: 0.719531
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.6519e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.650396
Average KL loss: 0.066453
Average total loss: 0.716850
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.8746e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.644932
Average KL loss: 0.066424
Average total loss: 0.711356
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.4560e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.642017
Average KL loss: 0.066397
Average total loss: 0.708413
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.2447e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.639278
Average KL loss: 0.066370
Average total loss: 0.705648
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.1400e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.644759
Average KL loss: 0.066351
Average total loss: 0.711110
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.9097e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.636676
Average KL loss: 0.066332
Average total loss: 0.703007
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.9398e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.633107
Average KL loss: 0.066315
Average total loss: 0.699422
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.0628e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.640282
Average KL loss: 0.066300
Average total loss: 0.706582
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.0059e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.639937
Average KL loss: 0.066288
Average total loss: 0.706225
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.7308e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.638125
Average KL loss: 0.066278
Average total loss: 0.704403
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.7350e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.623516
Average KL loss: 0.066269
Average total loss: 0.689785
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.0499e-08, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.623253
Average KL loss: 0.066263
Average total loss: 0.689517
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.6728e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.614667
Average KL loss: 0.066259
Average total loss: 0.680926
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.4575e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.613289
Average KL loss: 0.066255
Average total loss: 0.679544
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-2.2172e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.609751
Average KL loss: 0.066255
Average total loss: 0.676006
tensor(0.0039, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-3.4569e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.620557
Average KL loss: 0.066256
Average total loss: 0.686813
tensor(0.0039, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-3.0749e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.613642
Average KL loss: 0.066260
Average total loss: 0.679902
tensor(0.0039, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-2.9835e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.615034
Average KL loss: 0.066264
Average total loss: 0.681298
tensor(0.0039, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-4.1560e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.618595
Average KL loss: 0.066271
Average total loss: 0.684866
tensor(0.0039, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-3.3105e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.606723
Average KL loss: 0.066280
Average total loss: 0.673003
tensor(0.0039, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-2.4387e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.619622
Average KL loss: 0.066292
Average total loss: 0.685913
tensor(0.0039, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-3.3868e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.594984
Average KL loss: 0.066303
Average total loss: 0.661287
tensor(0.0039, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-2.5728e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.606735
Average KL loss: 0.066315
Average total loss: 0.673050
tensor(0.0039, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-2.1302e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.603352
Average KL loss: 0.066332
Average total loss: 0.669684
tensor(0.0039, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-2.6635e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.597281
Average KL loss: 0.066346
Average total loss: 0.663627
tensor(0.0039, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-4.1834e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.612670
Average KL loss: 0.066364
Average total loss: 0.679034
tensor(0.0039, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-2.5349e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.606320
Average KL loss: 0.066385
Average total loss: 0.672705
tensor(0.0039, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.8746e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.581990
Average KL loss: 0.066405
Average total loss: 0.648395
tensor(0.0039, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-2.9507e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.597266
Average KL loss: 0.066424
Average total loss: 0.663690
tensor(0.0039, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-2.7951e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.598317
Average KL loss: 0.066445
Average total loss: 0.664761
tensor(0.0039, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.9503e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.589987
Average KL loss: 0.066467
Average total loss: 0.656453
tensor(0.0039, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-3.6842e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.605735
Average KL loss: 0.066489
Average total loss: 0.672224
tensor(0.0039, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-3.7773e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.602585
Average KL loss: 0.066513
Average total loss: 0.669098
tensor(0.0039, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-3.3120e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.583967
Average KL loss: 0.066539
Average total loss: 0.650506
tensor(0.0039, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-2.5140e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.595602
Average KL loss: 0.066565
Average total loss: 0.662168
tensor(0.0039, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-1.9957e-08, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.579974
Average KL loss: 0.066589
Average total loss: 0.646563
tensor(0.0039, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-3.3953e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.577981
Average KL loss: 0.066616
Average total loss: 0.644597
tensor(0.0039, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-3.1681e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.583386
Average KL loss: 0.066642
Average total loss: 0.650028
tensor(0.0039, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.3880e-08, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.575701
Average KL loss: 0.066665
Average total loss: 0.642366
tensor(0.0039, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.6938e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.586260
Average KL loss: 0.066691
Average total loss: 0.652951
tensor(0.0039, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.9258e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.565814
Average KL loss: 0.066718
Average total loss: 0.632532
tensor(0.0039, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.5939e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.583747
Average KL loss: 0.066745
Average total loss: 0.650492
tensor(0.0039, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.6838e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.578064
Average KL loss: 0.066775
Average total loss: 0.644838
tensor(0.0039, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.8883e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.574992
Average KL loss: 0.066803
Average total loss: 0.641794
tensor(0.0039, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.9752e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.569716
Average KL loss: 0.066829
Average total loss: 0.636545
tensor(0.0039, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.0704e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.569745
Average KL loss: 0.066855
Average total loss: 0.636600
tensor(0.0039, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-3.1534e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.561396
Average KL loss: 0.066882
Average total loss: 0.628278
tensor(0.0039, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.7825e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.566784
Average KL loss: 0.066908
Average total loss: 0.633692
tensor(0.0039, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.5864e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.561812
Average KL loss: 0.066933
Average total loss: 0.628745
tensor(0.0039, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.3940e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.553567
Average KL loss: 0.066962
Average total loss: 0.620529
tensor(0.0039, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.6318e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.560442
Average KL loss: 0.066987
Average total loss: 0.627429
tensor(0.0040, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.3937e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.555938
Average KL loss: 0.067012
Average total loss: 0.622950
tensor(0.0040, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.9965e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.568036
Average KL loss: 0.067040
Average total loss: 0.635076
tensor(0.0040, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.6939e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.558523
Average KL loss: 0.067067
Average total loss: 0.625590
tensor(0.0040, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-2.4543e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.552013
Average KL loss: 0.067096
Average total loss: 0.619109
tensor(0.0040, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.4885e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.555550
Average KL loss: 0.067124
Average total loss: 0.622673
tensor(0.0040, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.5467e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.559883
Average KL loss: 0.067154
Average total loss: 0.627036
tensor(0.0040, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.3013e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.543348
Average KL loss: 0.067182
Average total loss: 0.610530
tensor(0.0040, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.8775e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.558105
Average KL loss: 0.067209
Average total loss: 0.625314
tensor(0.0040, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.2875e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.540744
Average KL loss: 0.067238
Average total loss: 0.607982
tensor(0.0040, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.8354e-08, device='cuda:0')
Epoch 115
Average batch original loss after noise: 0.561405
Average KL loss: 0.067265
Average total loss: 0.628670
tensor(0.0040, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.8488e-08, device='cuda:0')
Epoch 116
Average batch original loss after noise: 0.548219
Average KL loss: 0.067296
Average total loss: 0.615515
tensor(0.0040, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-3.0629e-08, device='cuda:0')
Epoch 117
Average batch original loss after noise: 0.549561
Average KL loss: 0.067327
Average total loss: 0.616888
tensor(0.0040, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-2.6868e-08, device='cuda:0')
Epoch 118
Average batch original loss after noise: 0.535639
Average KL loss: 0.067357
Average total loss: 0.602995
tensor(0.0040, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.4769e-08, device='cuda:0')
Epoch 119
Average batch original loss after noise: 0.544875
Average KL loss: 0.067385
Average total loss: 0.612261
tensor(0.0040, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.3866e-08, device='cuda:0')
Epoch 120
Average batch original loss after noise: 0.545179
Average KL loss: 0.067413
Average total loss: 0.612593
tensor(0.0040, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.7463e-08, device='cuda:0')
Epoch 121
Average batch original loss after noise: 0.538391
Average KL loss: 0.067443
Average total loss: 0.605834
tensor(0.0040, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.6133e-08, device='cuda:0')
Epoch 122
Average batch original loss after noise: 0.546661
Average KL loss: 0.067473
Average total loss: 0.614134
tensor(0.0040, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.0037e-08, device='cuda:0')
Epoch 123
Average batch original loss after noise: 0.546109
Average KL loss: 0.067505
Average total loss: 0.613614
tensor(0.0040, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-3.8219e-08, device='cuda:0')
Epoch 124
Average batch original loss after noise: 0.539748
Average KL loss: 0.067537
Average total loss: 0.607285
tensor(0.0040, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.1505e-08, device='cuda:0')
Epoch 125
Average batch original loss after noise: 0.540576
Average KL loss: 0.067566
Average total loss: 0.608142
tensor(0.0040, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-2.1251e-08, device='cuda:0')
Epoch 126
Average batch original loss after noise: 0.527587
Average KL loss: 0.067595
Average total loss: 0.595182
tensor(0.0040, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.1516e-08, device='cuda:0')
Epoch 127
Average batch original loss after noise: 0.539542
Average KL loss: 0.067623
Average total loss: 0.607165
tensor(0.0040, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.3694e-08, device='cuda:0')
Epoch 128
Average batch original loss after noise: 0.528854
Average KL loss: 0.067649
Average total loss: 0.596503
tensor(0.0040, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.3380e-08, device='cuda:0')
Epoch 129
Average batch original loss after noise: 0.542294
Average KL loss: 0.067679
Average total loss: 0.609972
tensor(0.0040, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.7460e-08, device='cuda:0')
Epoch 130
Average batch original loss after noise: 0.538838
Average KL loss: 0.067709
Average total loss: 0.606547
tensor(0.0040, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.2059e-08, device='cuda:0')
Epoch 131
Average batch original loss after noise: 0.532788
Average KL loss: 0.067739
Average total loss: 0.600527
tensor(0.0040, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-3.0174e-08, device='cuda:0')
Epoch 132
Average batch original loss after noise: 0.524437
Average KL loss: 0.067770
Average total loss: 0.592207
tensor(0.0040, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.2768e-08, device='cuda:0')
Epoch 133
Average batch original loss after noise: 0.532024
Average KL loss: 0.067800
Average total loss: 0.599824
tensor(0.0040, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.2317e-08, device='cuda:0')
Epoch 134
Average batch original loss after noise: 0.527610
Average KL loss: 0.067829
Average total loss: 0.595438
tensor(0.0040, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-1.9884e-08, device='cuda:0')
Epoch 135
Average batch original loss after noise: 0.525306
Average KL loss: 0.067861
Average total loss: 0.593167
tensor(0.0040, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.0099e-08, device='cuda:0')
Epoch 136
Average batch original loss after noise: 0.525207
Average KL loss: 0.067889
Average total loss: 0.593097
tensor(0.0040, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.9630e-08, device='cuda:0')
Epoch 137
Average batch original loss after noise: 0.513313
Average KL loss: 0.067917
Average total loss: 0.581230
tensor(0.0040, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.4328e-08, device='cuda:0')
Epoch 138
Average batch original loss after noise: 0.526121
Average KL loss: 0.067946
Average total loss: 0.594066
tensor(0.0040, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.0166e-08, device='cuda:0')
Epoch 139
Average batch original loss after noise: 0.520245
Average KL loss: 0.067974
Average total loss: 0.588219
tensor(0.0040, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.2828e-08, device='cuda:0')
Epoch 140
Average batch original loss after noise: 0.525099
Average KL loss: 0.068002
Average total loss: 0.593101
tensor(0.0040, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-1.5123e-08, device='cuda:0')
Epoch 141
Average batch original loss after noise: 0.519245
Average KL loss: 0.068030
Average total loss: 0.587275
tensor(0.0040, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.4183e-08, device='cuda:0')
Epoch 142
Average batch original loss after noise: 0.527223
Average KL loss: 0.068057
Average total loss: 0.595280
tensor(0.0040, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.2493e-08, device='cuda:0')
Epoch 143
Average batch original loss after noise: 0.520242
Average KL loss: 0.068085
Average total loss: 0.588327
tensor(0.0040, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.9436e-08, device='cuda:0')
Epoch 144
Average batch original loss after noise: 0.521451
Average KL loss: 0.068116
Average total loss: 0.589567
tensor(0.0040, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.9469e-08, device='cuda:0')
Epoch 145
Average batch original loss after noise: 0.515684
Average KL loss: 0.068146
Average total loss: 0.583830
tensor(0.0040, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.8002e-08, device='cuda:0')
Epoch 146
Average batch original loss after noise: 0.522630
Average KL loss: 0.068175
Average total loss: 0.590805
tensor(0.0040, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.6874e-08, device='cuda:0')
Epoch 147
Average batch original loss after noise: 0.509964
Average KL loss: 0.068206
Average total loss: 0.578170
tensor(0.0040, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.9662e-08, device='cuda:0')
Epoch 148
Average batch original loss after noise: 0.513350
Average KL loss: 0.068236
Average total loss: 0.581586
tensor(0.0040, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.4125e-08, device='cuda:0')
Epoch 149
Average batch original loss after noise: 0.516617
Average KL loss: 0.068265
Average total loss: 0.584882
tensor(0.0040, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.8489e-08, device='cuda:0')
Epoch 150
Average batch original loss after noise: 0.527399
Average KL loss: 0.068294
Average total loss: 0.595693
tensor(0.0040, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.0901e-08, device='cuda:0')
Epoch 151
Average batch original loss after noise: 0.502660
Average KL loss: 0.068323
Average total loss: 0.570983
tensor(0.0040, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-1.9309e-08, device='cuda:0')
Epoch 152
Average batch original loss after noise: 0.510743
Average KL loss: 0.068355
Average total loss: 0.579098
tensor(0.0040, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.8839e-08, device='cuda:0')
Epoch 153
Average batch original loss after noise: 0.512629
Average KL loss: 0.068385
Average total loss: 0.581014
tensor(0.0040, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.0705e-08, device='cuda:0')
Epoch 154
Average batch original loss after noise: 0.515232
Average KL loss: 0.068413
Average total loss: 0.583646
tensor(0.0040, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.8673e-08, device='cuda:0')
Epoch 155
Average batch original loss after noise: 0.505508
Average KL loss: 0.068443
Average total loss: 0.573951
tensor(0.0040, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.6133e-08, device='cuda:0')
Epoch 156
Average batch original loss after noise: 0.506703
Average KL loss: 0.068473
Average total loss: 0.575176
tensor(0.0040, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.8122e-08, device='cuda:0')
Epoch 157
Average batch original loss after noise: 0.497222
Average KL loss: 0.068503
Average total loss: 0.565726
tensor(0.0040, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.3153e-08, device='cuda:0')
Epoch 158
Average batch original loss after noise: 0.508144
Average KL loss: 0.068535
Average total loss: 0.576679
tensor(0.0040, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.4455e-08, device='cuda:0')
Epoch 159
Average batch original loss after noise: 0.509873
Average KL loss: 0.068566
Average total loss: 0.578440
tensor(0.0040, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-1.7839e-08, device='cuda:0')
Epoch 160
Average batch original loss after noise: 0.492505
Average KL loss: 0.068596
Average total loss: 0.561100
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.8439e-08, device='cuda:0')
Epoch 161
Average batch original loss after noise: 0.504376
Average KL loss: 0.068624
Average total loss: 0.573000
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.5870e-08, device='cuda:0')
Epoch 162
Average batch original loss after noise: 0.498931
Average KL loss: 0.068653
Average total loss: 0.567585
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.0997e-08, device='cuda:0')
Epoch 163
Average batch original loss after noise: 0.505835
Average KL loss: 0.068682
Average total loss: 0.574517
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.4369e-08, device='cuda:0')
Epoch 164
Average batch original loss after noise: 0.499158
Average KL loss: 0.068713
Average total loss: 0.567871
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.0750e-08, device='cuda:0')
Epoch 165
Average batch original loss after noise: 0.492732
Average KL loss: 0.068744
Average total loss: 0.561475
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.3512e-08, device='cuda:0')
Epoch 166
Average batch original loss after noise: 0.493205
Average KL loss: 0.068775
Average total loss: 0.561980
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.7361e-08, device='cuda:0')
Epoch 167
Average batch original loss after noise: 0.493121
Average KL loss: 0.068806
Average total loss: 0.561927
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-1.7082e-08, device='cuda:0')
Epoch 168
Average batch original loss after noise: 0.503765
Average KL loss: 0.068837
Average total loss: 0.572601
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.8843e-08, device='cuda:0')
Epoch 169
Average batch original loss after noise: 0.487993
Average KL loss: 0.068867
Average total loss: 0.556860
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-3.1614e-08, device='cuda:0')
Epoch 170
Average batch original loss after noise: 0.495639
Average KL loss: 0.068898
Average total loss: 0.564537
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.3052e-08, device='cuda:0')
Epoch 171
Average batch original loss after noise: 0.490894
Average KL loss: 0.068928
Average total loss: 0.559823
tensor(0.0041, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.7949e-08, device='cuda:0')
Epoch 172
Average batch original loss after noise: 0.492046
Average KL loss: 0.068959
Average total loss: 0.561005
tensor(0.0041, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.2516e-08, device='cuda:0')
Epoch 173
Average batch original loss after noise: 0.492920
Average KL loss: 0.068988
Average total loss: 0.561908
tensor(0.0041, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.3338e-08, device='cuda:0')
Epoch 174
Average batch original loss after noise: 0.482506
Average KL loss: 0.069018
Average total loss: 0.551524
tensor(0.0041, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.2930e-08, device='cuda:0')
Epoch 175
Average batch original loss after noise: 0.492910
Average KL loss: 0.069048
Average total loss: 0.561958
tensor(0.0041, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-2.6120e-08, device='cuda:0')
Epoch 176
Average batch original loss after noise: 0.494086
Average KL loss: 0.069079
Average total loss: 0.563165
tensor(0.0041, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.8042e-08, device='cuda:0')
Epoch 177
Average batch original loss after noise: 0.488518
Average KL loss: 0.069111
Average total loss: 0.557629
tensor(0.0041, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-2.1376e-08, device='cuda:0')
Epoch 178
Average batch original loss after noise: 0.485472
Average KL loss: 0.069143
Average total loss: 0.554615
tensor(0.0041, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-2.0386e-08, device='cuda:0')
Epoch 179
Average batch original loss after noise: 0.489250
Average KL loss: 0.069174
Average total loss: 0.558425
tensor(0.0041, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.5071e-08, device='cuda:0')
Epoch 180
Average batch original loss after noise: 0.483963
Average KL loss: 0.069204
Average total loss: 0.553167
tensor(0.0041, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-2.1964e-08, device='cuda:0')
Epoch 181
Average batch original loss after noise: 0.485559
Average KL loss: 0.069236
Average total loss: 0.554795
tensor(0.0041, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.1718e-08, device='cuda:0')
Epoch 182
Average batch original loss after noise: 0.479845
Average KL loss: 0.069268
Average total loss: 0.549112
tensor(0.0041, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-1.6694e-08, device='cuda:0')
Epoch 183
Average batch original loss after noise: 0.474402
Average KL loss: 0.069300
Average total loss: 0.543703
tensor(0.0041, device='cuda:0') tensor(0.0124, device='cuda:0') tensor(-2.0901e-08, device='cuda:0')
Epoch 184
Average batch original loss after noise: 0.485408
Average KL loss: 0.069333
Average total loss: 0.554741
tensor(0.0041, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.8726e-08, device='cuda:0')
Epoch 185
Average batch original loss after noise: 0.475744
Average KL loss: 0.069365
Average total loss: 0.545109
tensor(0.0041, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.2751e-08, device='cuda:0')
Epoch 186
Average batch original loss after noise: 0.477219
Average KL loss: 0.069395
Average total loss: 0.546614
tensor(0.0041, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.0395e-08, device='cuda:0')
Epoch 187
Average batch original loss after noise: 0.479780
Average KL loss: 0.069425
Average total loss: 0.549205
tensor(0.0041, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-3.0299e-08, device='cuda:0')
Epoch 188
Average batch original loss after noise: 0.485818
Average KL loss: 0.069456
Average total loss: 0.555274
tensor(0.0041, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-2.0515e-08, device='cuda:0')
Epoch 189
Average batch original loss after noise: 0.476719
Average KL loss: 0.069487
Average total loss: 0.546206
tensor(0.0041, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.8417e-08, device='cuda:0')
Epoch 190
Average batch original loss after noise: 0.475460
Average KL loss: 0.069518
Average total loss: 0.544978
tensor(0.0041, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.9428e-08, device='cuda:0')
Epoch 191
Average batch original loss after noise: 0.472287
Average KL loss: 0.069550
Average total loss: 0.541837
tensor(0.0041, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.4050e-08, device='cuda:0')
Epoch 192
Average batch original loss after noise: 0.474734
Average KL loss: 0.069584
Average total loss: 0.544318
tensor(0.0041, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.0582e-08, device='cuda:0')
Epoch 193
Average batch original loss after noise: 0.474655
Average KL loss: 0.069614
Average total loss: 0.544269
tensor(0.0041, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.8167e-08, device='cuda:0')
Epoch 194
Average batch original loss after noise: 0.485073
Average KL loss: 0.069642
Average total loss: 0.554715
tensor(0.0041, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.3141e-08, device='cuda:0')
Epoch 195
Average batch original loss after noise: 0.465534
Average KL loss: 0.069671
Average total loss: 0.535205
tensor(0.0041, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.9213e-08, device='cuda:0')
Epoch 196
Average batch original loss after noise: 0.465783
Average KL loss: 0.069699
Average total loss: 0.535482
tensor(0.0041, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.3164e-08, device='cuda:0')
Epoch 197
Average batch original loss after noise: 0.465904
Average KL loss: 0.069727
Average total loss: 0.535631
tensor(0.0041, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-2.2157e-08, device='cuda:0')
Epoch 198
Average batch original loss after noise: 0.462552
Average KL loss: 0.069759
Average total loss: 0.532311
tensor(0.0041, device='cuda:0') tensor(0.0126, device='cuda:0') tensor(-1.5103e-08, device='cuda:0')
Epoch 199
Average batch original loss after noise: 0.470099
Average KL loss: 0.069790
Average total loss: 0.539889
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-3.3128e-08, device='cuda:0')
Epoch 200
Average batch original loss after noise: 0.471519
Average KL loss: 0.069822
Average total loss: 0.541340
 Percentile value: 2.7418580055236816
Non-zero model percentage: 0.09765839576721191%, Non-zero mask percentage: 0.09765839576721191%

--- Pruning Level [10/12]: ---
conv1.weight         | nonzeros =     121 /    1728             (  7.00%) | total_pruned =    1607 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      35 /   36864             (  0.09%) | total_pruned =   36829 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       8 /      64             ( 12.50%) | total_pruned =      56 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      62 /   36864             (  0.17%) | total_pruned =   36802 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       4 /      64             (  6.25%) | total_pruned =      60 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     174 /   36864             (  0.47%) | total_pruned =   36690 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     278 /   36864             (  0.75%) | total_pruned =   36586 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      22 /      64             ( 34.38%) | total_pruned =      42 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =      11 /      64             ( 17.19%) | total_pruned =      53 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     514 /   73728             (  0.70%) | total_pruned =   73214 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      68 /     128             ( 53.12%) | total_pruned =      60 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     750 /  147456             (  0.51%) | total_pruned =  146706 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      79 /     128             ( 61.72%) | total_pruned =      49 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     168 /    8192             (  2.05%) | total_pruned =    8024 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      47 /     128             ( 36.72%) | total_pruned =      81 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     426 /  147456             (  0.29%) | total_pruned =  147030 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      59 /     128             ( 46.09%) | total_pruned =      69 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     384 /  147456             (  0.26%) | total_pruned =  147072 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      60 /     128             ( 46.88%) | total_pruned =      68 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =    1252 /  294912             (  0.42%) | total_pruned =  293660 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     202 /     256             ( 78.91%) | total_pruned =      54 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       2 /     256             (  0.78%) | total_pruned =     254 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =    1463 /  589824             (  0.25%) | total_pruned =  588361 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     191 /     256             ( 74.61%) | total_pruned =      65 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       7 /     256             (  2.73%) | total_pruned =     249 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =     128 /   32768             (  0.39%) | total_pruned =   32640 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      63 /     256             ( 24.61%) | total_pruned =     193 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       6 /     256             (  2.34%) | total_pruned =     250 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     892 /  589824             (  0.15%) | total_pruned =  588932 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     135 /     256             ( 52.73%) | total_pruned =     121 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     738 /  589824             (  0.13%) | total_pruned =  589086 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      80 /     256             ( 31.25%) | total_pruned =     176 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     704 / 1179648             (  0.06%) | total_pruned = 1178944 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     162 /     512             ( 31.64%) | total_pruned =     350 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       4 /     512             (  0.78%) | total_pruned =     508 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     447 / 2359296             (  0.02%) | total_pruned = 2358849 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      75 /     512             ( 14.65%) | total_pruned =     437 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      24 /     512             (  4.69%) | total_pruned =     488 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      19 /  131072             (  0.01%) | total_pruned =  131053 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       9 /     512             (  1.76%) | total_pruned =     503 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      23 /     512             (  4.49%) | total_pruned =     489 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     346 / 2359296             (  0.01%) | total_pruned = 2358950 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      61 /     512             ( 11.91%) | total_pruned =     451 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       2 /     512             (  0.39%) | total_pruned =     510 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     302 / 2359296             (  0.01%) | total_pruned = 2358994 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      25 /     512             (  4.88%) | total_pruned =     487 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      22 /     512             (  4.30%) | total_pruned =     490 | shape = torch.Size([512])
linear.weight        | nonzeros =     189 /    5120             (  3.69%) | total_pruned =    4931 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 10917, pruned : 11167845, total: 11178762, Compression rate :    1023.98x  ( 99.90% pruned)
Train Epoch: 99/100 Loss: 0.290550 Accuracy: 80.59 89.99 % Best test Accuracy: 81.29%
tensor(0.0041, device='cuda:0') tensor(0.0127, device='cuda:0') tensor(-1.9883e-08, device='cuda:0')
Epoch 1
Average batch original loss after noise: 0.627605
Average KL loss: 0.069362
Average total loss: 0.696968
tensor(0.0041, device='cuda:0') tensor(0.0125, device='cuda:0') tensor(-1.8790e-08, device='cuda:0')
Epoch 2
Average batch original loss after noise: 0.645095
Average KL loss: 0.068521
Average total loss: 0.713616
tensor(0.0040, device='cuda:0') tensor(0.0123, device='cuda:0') tensor(-1.8994e-08, device='cuda:0')
Epoch 3
Average batch original loss after noise: 0.627275
Average KL loss: 0.067713
Average total loss: 0.694988
tensor(0.0040, device='cuda:0') tensor(0.0122, device='cuda:0') tensor(-2.1483e-08, device='cuda:0')
Epoch 4
Average batch original loss after noise: 0.634848
Average KL loss: 0.066918
Average total loss: 0.701766
tensor(0.0039, device='cuda:0') tensor(0.0121, device='cuda:0') tensor(-2.2692e-08, device='cuda:0')
Epoch 5
Average batch original loss after noise: 0.623685
Average KL loss: 0.066136
Average total loss: 0.689821
tensor(0.0039, device='cuda:0') tensor(0.0120, device='cuda:0') tensor(-2.4564e-08, device='cuda:0')
Epoch 6
Average batch original loss after noise: 0.631195
Average KL loss: 0.065366
Average total loss: 0.696561
tensor(0.0039, device='cuda:0') tensor(0.0119, device='cuda:0') tensor(-2.4363e-08, device='cuda:0')
Epoch 7
Average batch original loss after noise: 0.626290
Average KL loss: 0.064608
Average total loss: 0.690898
tensor(0.0038, device='cuda:0') tensor(0.0118, device='cuda:0') tensor(-2.0015e-08, device='cuda:0')
Epoch 8
Average batch original loss after noise: 0.619983
Average KL loss: 0.063865
Average total loss: 0.683848
tensor(0.0038, device='cuda:0') tensor(0.0117, device='cuda:0') tensor(-1.5316e-08, device='cuda:0')
Epoch 9
Average batch original loss after noise: 0.623358
Average KL loss: 0.063136
Average total loss: 0.686494
tensor(0.0038, device='cuda:0') tensor(0.0116, device='cuda:0') tensor(-1.7865e-08, device='cuda:0')
Epoch 10
Average batch original loss after noise: 0.610016
Average KL loss: 0.062422
Average total loss: 0.672438
tensor(0.0037, device='cuda:0') tensor(0.0115, device='cuda:0') tensor(-1.5109e-08, device='cuda:0')
Epoch 11
Average batch original loss after noise: 0.618132
Average KL loss: 0.061726
Average total loss: 0.679858
tensor(0.0037, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-2.2431e-08, device='cuda:0')
Epoch 12
Average batch original loss after noise: 0.613527
Average KL loss: 0.061049
Average total loss: 0.674577
tensor(0.0037, device='cuda:0') tensor(0.0114, device='cuda:0') tensor(-1.1858e-08, device='cuda:0')
Epoch 13
Average batch original loss after noise: 0.611355
Average KL loss: 0.060392
Average total loss: 0.671748
tensor(0.0036, device='cuda:0') tensor(0.0113, device='cuda:0') tensor(-2.4785e-08, device='cuda:0')
Epoch 14
Average batch original loss after noise: 0.614490
Average KL loss: 0.059754
Average total loss: 0.674244
tensor(0.0036, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-1.6180e-08, device='cuda:0')
Epoch 15
Average batch original loss after noise: 0.612196
Average KL loss: 0.059139
Average total loss: 0.671334
tensor(0.0036, device='cuda:0') tensor(0.0112, device='cuda:0') tensor(-2.3539e-08, device='cuda:0')
Epoch 16
Average batch original loss after noise: 0.618283
Average KL loss: 0.058544
Average total loss: 0.676827
tensor(0.0035, device='cuda:0') tensor(0.0111, device='cuda:0') tensor(-1.3386e-08, device='cuda:0')
Epoch 17
Average batch original loss after noise: 0.598767
Average KL loss: 0.057973
Average total loss: 0.656741
tensor(0.0035, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-1.6716e-08, device='cuda:0')
Epoch 18
Average batch original loss after noise: 0.609188
Average KL loss: 0.057425
Average total loss: 0.666613
tensor(0.0035, device='cuda:0') tensor(0.0110, device='cuda:0') tensor(-2.3016e-08, device='cuda:0')
Epoch 19
Average batch original loss after noise: 0.605380
Average KL loss: 0.056900
Average total loss: 0.662280
tensor(0.0035, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-2.5211e-08, device='cuda:0')
Epoch 20
Average batch original loss after noise: 0.601187
Average KL loss: 0.056399
Average total loss: 0.657586
tensor(0.0034, device='cuda:0') tensor(0.0109, device='cuda:0') tensor(-9.9410e-09, device='cuda:0')
Epoch 21
Average batch original loss after noise: 0.604362
Average KL loss: 0.055921
Average total loss: 0.660284
tensor(0.0034, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-6.8642e-09, device='cuda:0')
Epoch 22
Average batch original loss after noise: 0.607997
Average KL loss: 0.055467
Average total loss: 0.663464
tensor(0.0034, device='cuda:0') tensor(0.0108, device='cuda:0') tensor(-1.8764e-08, device='cuda:0')
Epoch 23
Average batch original loss after noise: 0.593661
Average KL loss: 0.055037
Average total loss: 0.648698
tensor(0.0034, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.0372e-08, device='cuda:0')
Epoch 24
Average batch original loss after noise: 0.599751
Average KL loss: 0.054630
Average total loss: 0.654381
tensor(0.0033, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-2.6629e-08, device='cuda:0')
Epoch 25
Average batch original loss after noise: 0.622176
Average KL loss: 0.054247
Average total loss: 0.676423
tensor(0.0033, device='cuda:0') tensor(0.0107, device='cuda:0') tensor(-1.3992e-08, device='cuda:0')
Epoch 26
Average batch original loss after noise: 0.620545
Average KL loss: 0.053885
Average total loss: 0.674430
tensor(0.0033, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.2771e-08, device='cuda:0')
Epoch 27
Average batch original loss after noise: 0.603221
Average KL loss: 0.053545
Average total loss: 0.656765
tensor(0.0033, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.7860e-08, device='cuda:0')
Epoch 28
Average batch original loss after noise: 0.601048
Average KL loss: 0.053226
Average total loss: 0.654274
tensor(0.0032, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.1168e-08, device='cuda:0')
Epoch 29
Average batch original loss after noise: 0.603063
Average KL loss: 0.052928
Average total loss: 0.655991
tensor(0.0032, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.5322e-08, device='cuda:0')
Epoch 30
Average batch original loss after noise: 0.602133
Average KL loss: 0.052650
Average total loss: 0.654783
tensor(0.0032, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.7932e-08, device='cuda:0')
Epoch 31
Average batch original loss after noise: 0.598162
Average KL loss: 0.052391
Average total loss: 0.650553
tensor(0.0032, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.2164e-08, device='cuda:0')
Epoch 32
Average batch original loss after noise: 0.584803
Average KL loss: 0.052149
Average total loss: 0.636953
tensor(0.0032, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.5612e-08, device='cuda:0')
Epoch 33
Average batch original loss after noise: 0.594861
Average KL loss: 0.051925
Average total loss: 0.646785
tensor(0.0031, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.9913e-08, device='cuda:0')
Epoch 34
Average batch original loss after noise: 0.594351
Average KL loss: 0.051717
Average total loss: 0.646069
tensor(0.0031, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.5368e-08, device='cuda:0')
Epoch 35
Average batch original loss after noise: 0.586533
Average KL loss: 0.051526
Average total loss: 0.638059
tensor(0.0031, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.7477e-08, device='cuda:0')
Epoch 36
Average batch original loss after noise: 0.588807
Average KL loss: 0.051350
Average total loss: 0.640157
tensor(0.0031, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-2.1158e-08, device='cuda:0')
Epoch 37
Average batch original loss after noise: 0.584493
Average KL loss: 0.051188
Average total loss: 0.635681
tensor(0.0031, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.8457e-08, device='cuda:0')
Epoch 38
Average batch original loss after noise: 0.576419
Average KL loss: 0.051038
Average total loss: 0.627457
tensor(0.0031, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.4673e-08, device='cuda:0')
Epoch 39
Average batch original loss after noise: 0.584218
Average KL loss: 0.050898
Average total loss: 0.635116
tensor(0.0031, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-2.3454e-08, device='cuda:0')
Epoch 40
Average batch original loss after noise: 0.595203
Average KL loss: 0.050771
Average total loss: 0.645974
tensor(0.0030, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.1480e-08, device='cuda:0')
Epoch 41
Average batch original loss after noise: 0.595426
Average KL loss: 0.050654
Average total loss: 0.646080
tensor(0.0030, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.6245e-08, device='cuda:0')
Epoch 42
Average batch original loss after noise: 0.579460
Average KL loss: 0.050544
Average total loss: 0.630004
tensor(0.0030, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.9658e-08, device='cuda:0')
Epoch 43
Average batch original loss after noise: 0.586233
Average KL loss: 0.050444
Average total loss: 0.636676
tensor(0.0030, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.5814e-08, device='cuda:0')
Epoch 44
Average batch original loss after noise: 0.568675
Average KL loss: 0.050352
Average total loss: 0.619026
tensor(0.0030, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.4497e-08, device='cuda:0')
Epoch 45
Average batch original loss after noise: 0.572150
Average KL loss: 0.050266
Average total loss: 0.622416
tensor(0.0030, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-2.0295e-08, device='cuda:0')
Epoch 46
Average batch original loss after noise: 0.578570
Average KL loss: 0.050187
Average total loss: 0.628757
tensor(0.0030, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.6479e-08, device='cuda:0')
Epoch 47
Average batch original loss after noise: 0.598046
Average KL loss: 0.050113
Average total loss: 0.648159
tensor(0.0030, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-2.4840e-08, device='cuda:0')
Epoch 48
Average batch original loss after noise: 0.571300
Average KL loss: 0.050047
Average total loss: 0.621347
tensor(0.0030, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.5799e-08, device='cuda:0')
Epoch 49
Average batch original loss after noise: 0.590733
Average KL loss: 0.049985
Average total loss: 0.640718
tensor(0.0030, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-1.4754e-08, device='cuda:0')
Epoch 50
Average batch original loss after noise: 0.571650
Average KL loss: 0.049926
Average total loss: 0.621576
tensor(0.0029, device='cuda:0') tensor(0.0103, device='cuda:0') tensor(-2.3582e-08, device='cuda:0')
Epoch 51
Average batch original loss after noise: 0.577667
Average KL loss: 0.049873
Average total loss: 0.627540
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.4813e-08, device='cuda:0')
Epoch 52
Average batch original loss after noise: 0.574507
Average KL loss: 0.049823
Average total loss: 0.624331
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.8750e-08, device='cuda:0')
Epoch 53
Average batch original loss after noise: 0.559190
Average KL loss: 0.049777
Average total loss: 0.608967
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.6345e-08, device='cuda:0')
Epoch 54
Average batch original loss after noise: 0.577144
Average KL loss: 0.049734
Average total loss: 0.626877
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.5552e-08, device='cuda:0')
Epoch 55
Average batch original loss after noise: 0.561711
Average KL loss: 0.049692
Average total loss: 0.611403
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.7209e-08, device='cuda:0')
Epoch 56
Average batch original loss after noise: 0.584540
Average KL loss: 0.049655
Average total loss: 0.634194
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-2.6355e-08, device='cuda:0')
Epoch 57
Average batch original loss after noise: 0.568231
Average KL loss: 0.049620
Average total loss: 0.617851
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.2201e-08, device='cuda:0')
Epoch 58
Average batch original loss after noise: 0.560819
Average KL loss: 0.049588
Average total loss: 0.610407
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.7959e-08, device='cuda:0')
Epoch 59
Average batch original loss after noise: 0.577398
Average KL loss: 0.049557
Average total loss: 0.626956
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.3566e-08, device='cuda:0')
Epoch 60
Average batch original loss after noise: 0.562804
Average KL loss: 0.049530
Average total loss: 0.612333
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.4086e-08, device='cuda:0')
Epoch 61
Average batch original loss after noise: 0.570272
Average KL loss: 0.049503
Average total loss: 0.619775
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.7357e-08, device='cuda:0')
Epoch 62
Average batch original loss after noise: 0.556458
Average KL loss: 0.049478
Average total loss: 0.605936
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.7233e-08, device='cuda:0')
Epoch 63
Average batch original loss after noise: 0.574306
Average KL loss: 0.049457
Average total loss: 0.623762
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-2.6661e-08, device='cuda:0')
Epoch 64
Average batch original loss after noise: 0.565730
Average KL loss: 0.049437
Average total loss: 0.615167
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.2731e-08, device='cuda:0')
Epoch 65
Average batch original loss after noise: 0.554929
Average KL loss: 0.049418
Average total loss: 0.604347
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-6.8726e-09, device='cuda:0')
Epoch 66
Average batch original loss after noise: 0.562072
Average KL loss: 0.049400
Average total loss: 0.611472
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.4380e-08, device='cuda:0')
Epoch 67
Average batch original loss after noise: 0.563856
Average KL loss: 0.049387
Average total loss: 0.613242
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.6965e-08, device='cuda:0')
Epoch 68
Average batch original loss after noise: 0.565997
Average KL loss: 0.049374
Average total loss: 0.615371
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.5570e-08, device='cuda:0')
Epoch 69
Average batch original loss after noise: 0.551981
Average KL loss: 0.049364
Average total loss: 0.601344
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-3.3078e-08, device='cuda:0')
Epoch 70
Average batch original loss after noise: 0.551204
Average KL loss: 0.049354
Average total loss: 0.600557
tensor(0.0029, device='cuda:0') tensor(0.0104, device='cuda:0') tensor(-1.2863e-08, device='cuda:0')
Epoch 71
Average batch original loss after noise: 0.557290
Average KL loss: 0.049346
Average total loss: 0.606636
tensor(0.0029, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.6323e-08, device='cuda:0')
Epoch 72
Average batch original loss after noise: 0.561880
Average KL loss: 0.049340
Average total loss: 0.611220
tensor(0.0029, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.6213e-08, device='cuda:0')
Epoch 73
Average batch original loss after noise: 0.550048
Average KL loss: 0.049334
Average total loss: 0.599382
tensor(0.0029, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.2365e-08, device='cuda:0')
Epoch 74
Average batch original loss after noise: 0.564988
Average KL loss: 0.049330
Average total loss: 0.614318
tensor(0.0029, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.4477e-08, device='cuda:0')
Epoch 75
Average batch original loss after noise: 0.562885
Average KL loss: 0.049327
Average total loss: 0.612212
tensor(0.0029, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-2.3803e-08, device='cuda:0')
Epoch 76
Average batch original loss after noise: 0.564316
Average KL loss: 0.049326
Average total loss: 0.613641
tensor(0.0029, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.4912e-08, device='cuda:0')
Epoch 77
Average batch original loss after noise: 0.572853
Average KL loss: 0.049325
Average total loss: 0.622178
tensor(0.0029, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.3257e-08, device='cuda:0')
Epoch 78
Average batch original loss after noise: 0.559313
Average KL loss: 0.049327
Average total loss: 0.608640
tensor(0.0029, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.4595e-08, device='cuda:0')
Epoch 79
Average batch original loss after noise: 0.555820
Average KL loss: 0.049329
Average total loss: 0.605149
tensor(0.0029, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.8963e-08, device='cuda:0')
Epoch 80
Average batch original loss after noise: 0.550943
Average KL loss: 0.049332
Average total loss: 0.600275
tensor(0.0029, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.2912e-08, device='cuda:0')
Epoch 81
Average batch original loss after noise: 0.558031
Average KL loss: 0.049336
Average total loss: 0.607367
tensor(0.0029, device='cuda:0') tensor(0.0105, device='cuda:0') tensor(-1.4279e-08, device='cuda:0')
Epoch 82
Average batch original loss after noise: 0.553124
Average KL loss: 0.049340
Average total loss: 0.602465
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.9932e-08, device='cuda:0')
Epoch 83
Average batch original loss after noise: 0.560565
Average KL loss: 0.049346
Average total loss: 0.609910
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.6972e-08, device='cuda:0')
Epoch 84
Average batch original loss after noise: 0.557470
Average KL loss: 0.049351
Average total loss: 0.606821
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.6599e-08, device='cuda:0')
Epoch 85
Average batch original loss after noise: 0.545028
Average KL loss: 0.049354
Average total loss: 0.594382
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.3939e-08, device='cuda:0')
Epoch 86
Average batch original loss after noise: 0.541580
Average KL loss: 0.049355
Average total loss: 0.590935
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.7672e-08, device='cuda:0')
Epoch 87
Average batch original loss after noise: 0.543025
Average KL loss: 0.049355
Average total loss: 0.592380
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.4056e-08, device='cuda:0')
Epoch 88
Average batch original loss after noise: 0.551764
Average KL loss: 0.049356
Average total loss: 0.601120
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.7148e-08, device='cuda:0')
Epoch 89
Average batch original loss after noise: 0.539132
Average KL loss: 0.049356
Average total loss: 0.588489
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-9.4991e-09, device='cuda:0')
Epoch 90
Average batch original loss after noise: 0.546470
Average KL loss: 0.049357
Average total loss: 0.595827
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.7284e-08, device='cuda:0')
Epoch 91
Average batch original loss after noise: 0.549404
Average KL loss: 0.049358
Average total loss: 0.598762
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.4123e-08, device='cuda:0')
Epoch 92
Average batch original loss after noise: 0.544361
Average KL loss: 0.049358
Average total loss: 0.593719
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-9.2278e-09, device='cuda:0')
Epoch 93
Average batch original loss after noise: 0.534883
Average KL loss: 0.049359
Average total loss: 0.584242
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.7185e-08, device='cuda:0')
Epoch 94
Average batch original loss after noise: 0.548555
Average KL loss: 0.049360
Average total loss: 0.597914
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.0207e-08, device='cuda:0')
Epoch 95
Average batch original loss after noise: 0.548160
Average KL loss: 0.049361
Average total loss: 0.597521
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.6511e-08, device='cuda:0')
Epoch 96
Average batch original loss after noise: 0.541419
Average KL loss: 0.049361
Average total loss: 0.590781
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.0647e-08, device='cuda:0')
Epoch 97
Average batch original loss after noise: 0.539458
Average KL loss: 0.049362
Average total loss: 0.588820
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.1671e-08, device='cuda:0')
Epoch 98
Average batch original loss after noise: 0.548599
Average KL loss: 0.049363
Average total loss: 0.597962
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.3481e-08, device='cuda:0')
Epoch 99
Average batch original loss after noise: 0.564148
Average KL loss: 0.049364
Average total loss: 0.613512
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.5823e-08, device='cuda:0')
Epoch 100
Average batch original loss after noise: 0.545536
Average KL loss: 0.049364
Average total loss: 0.594900
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.5954e-08, device='cuda:0')
Epoch 101
Average batch original loss after noise: 0.553871
Average KL loss: 0.049365
Average total loss: 0.603237
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.7224e-08, device='cuda:0')
Epoch 102
Average batch original loss after noise: 0.548739
Average KL loss: 0.049366
Average total loss: 0.598105
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.3159e-08, device='cuda:0')
Epoch 103
Average batch original loss after noise: 0.552500
Average KL loss: 0.049367
Average total loss: 0.601867
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.5195e-08, device='cuda:0')
Epoch 104
Average batch original loss after noise: 0.542339
Average KL loss: 0.049367
Average total loss: 0.591707
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.8706e-08, device='cuda:0')
Epoch 105
Average batch original loss after noise: 0.546269
Average KL loss: 0.049368
Average total loss: 0.595637
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.7216e-08, device='cuda:0')
Epoch 106
Average batch original loss after noise: 0.546638
Average KL loss: 0.049368
Average total loss: 0.596006
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.2290e-08, device='cuda:0')
Epoch 107
Average batch original loss after noise: 0.543954
Average KL loss: 0.049368
Average total loss: 0.593322
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.3552e-08, device='cuda:0')
Epoch 108
Average batch original loss after noise: 0.546543
Average KL loss: 0.049368
Average total loss: 0.595912
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.3303e-08, device='cuda:0')
Epoch 109
Average batch original loss after noise: 0.553343
Average KL loss: 0.049368
Average total loss: 0.602711
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.7981e-08, device='cuda:0')
Epoch 110
Average batch original loss after noise: 0.546582
Average KL loss: 0.049368
Average total loss: 0.595951
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.6110e-08, device='cuda:0')
Epoch 111
Average batch original loss after noise: 0.546209
Average KL loss: 0.049368
Average total loss: 0.595577
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.2664e-08, device='cuda:0')
Epoch 112
Average batch original loss after noise: 0.553900
Average KL loss: 0.049368
Average total loss: 0.603269
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-1.3184e-08, device='cuda:0')
Epoch 113
Average batch original loss after noise: 0.539604
Average KL loss: 0.049368
Average total loss: 0.588972
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-2.6162e-08, device='cuda:0')
Epoch 114
Average batch original loss after noise: 0.547918
Average KL loss: 0.049369
Average total loss: 0.597287
tensor(0.0029, device='cuda:0') tensor(0.0106, device='cuda:0') tensor(-9.1671e-09, device='cuda:0')
 Percentile value: 3.4795353412628174
Non-zero model percentage: 0.04883367195725441%, Non-zero mask percentage: 0.04883367195725441%

--- Pruning Level [11/12]: ---
conv1.weight         | nonzeros =     109 /    1728             (  6.31%) | total_pruned =    1619 | shape = torch.Size([64, 3, 3, 3])
conv1.bias           | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
bn1.weight           | nonzeros =      10 /      64             ( 15.62%) | total_pruned =      54 | shape = torch.Size([64])
bn1.bias             | nonzeros =       5 /      64             (  7.81%) | total_pruned =      59 | shape = torch.Size([64])
layer1.0.conv1.weight | nonzeros =      26 /   36864             (  0.07%) | total_pruned =   36838 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn1.weight  | nonzeros =       7 /      64             ( 10.94%) | total_pruned =      57 | shape = torch.Size([64])
layer1.0.bn1.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.0.conv2.weight | nonzeros =      39 /   36864             (  0.11%) | total_pruned =   36825 | shape = torch.Size([64, 64, 3, 3])
layer1.0.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.0.bn2.weight  | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer1.0.bn2.bias    | nonzeros =       3 /      64             (  4.69%) | total_pruned =      61 | shape = torch.Size([64])
layer1.1.conv1.weight | nonzeros =     116 /   36864             (  0.31%) | total_pruned =   36748 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv1.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn1.weight  | nonzeros =      21 /      64             ( 32.81%) | total_pruned =      43 | shape = torch.Size([64])
layer1.1.bn1.bias    | nonzeros =       6 /      64             (  9.38%) | total_pruned =      58 | shape = torch.Size([64])
layer1.1.conv2.weight | nonzeros =     162 /   36864             (  0.44%) | total_pruned =   36702 | shape = torch.Size([64, 64, 3, 3])
layer1.1.conv2.bias  | nonzeros =       0 /      64             (  0.00%) | total_pruned =      64 | shape = torch.Size([64])
layer1.1.bn2.weight  | nonzeros =      18 /      64             ( 28.12%) | total_pruned =      46 | shape = torch.Size([64])
layer1.1.bn2.bias    | nonzeros =       9 /      64             ( 14.06%) | total_pruned =      55 | shape = torch.Size([64])
layer2.0.conv1.weight | nonzeros =     239 /   73728             (  0.32%) | total_pruned =   73489 | shape = torch.Size([128, 64, 3, 3])
layer2.0.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn1.weight  | nonzeros =      64 /     128             ( 50.00%) | total_pruned =      64 | shape = torch.Size([128])
layer2.0.bn1.bias    | nonzeros =       9 /     128             (  7.03%) | total_pruned =     119 | shape = torch.Size([128])
layer2.0.conv2.weight | nonzeros =     340 /  147456             (  0.23%) | total_pruned =  147116 | shape = torch.Size([128, 128, 3, 3])
layer2.0.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.bn2.weight  | nonzeros =      76 /     128             ( 59.38%) | total_pruned =      52 | shape = torch.Size([128])
layer2.0.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.0.shortcut.0.weight | nonzeros =     115 /    8192             (  1.40%) | total_pruned =    8077 | shape = torch.Size([128, 64, 1, 1])
layer2.0.shortcut.0.bias | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.0.shortcut.1.weight | nonzeros =      42 /     128             ( 32.81%) | total_pruned =      86 | shape = torch.Size([128])
layer2.0.shortcut.1.bias | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer2.1.conv1.weight | nonzeros =     214 /  147456             (  0.15%) | total_pruned =  147242 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv1.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn1.weight  | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.1.bn1.bias    | nonzeros =       3 /     128             (  2.34%) | total_pruned =     125 | shape = torch.Size([128])
layer2.1.conv2.weight | nonzeros =     183 /  147456             (  0.12%) | total_pruned =  147273 | shape = torch.Size([128, 128, 3, 3])
layer2.1.conv2.bias  | nonzeros =       0 /     128             (  0.00%) | total_pruned =     128 | shape = torch.Size([128])
layer2.1.bn2.weight  | nonzeros =      53 /     128             ( 41.41%) | total_pruned =      75 | shape = torch.Size([128])
layer2.1.bn2.bias    | nonzeros =       1 /     128             (  0.78%) | total_pruned =     127 | shape = torch.Size([128])
layer3.0.conv1.weight | nonzeros =     499 /  294912             (  0.17%) | total_pruned =  294413 | shape = torch.Size([256, 128, 3, 3])
layer3.0.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn1.weight  | nonzeros =     181 /     256             ( 70.70%) | total_pruned =      75 | shape = torch.Size([256])
layer3.0.bn1.bias    | nonzeros =       1 /     256             (  0.39%) | total_pruned =     255 | shape = torch.Size([256])
layer3.0.conv2.weight | nonzeros =     517 /  589824             (  0.09%) | total_pruned =  589307 | shape = torch.Size([256, 256, 3, 3])
layer3.0.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.bn2.weight  | nonzeros =     169 /     256             ( 66.02%) | total_pruned =      87 | shape = torch.Size([256])
layer3.0.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.0.shortcut.0.weight | nonzeros =      50 /   32768             (  0.15%) | total_pruned =   32718 | shape = torch.Size([256, 128, 1, 1])
layer3.0.shortcut.0.bias | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.0.shortcut.1.weight | nonzeros =      36 /     256             ( 14.06%) | total_pruned =     220 | shape = torch.Size([256])
layer3.0.shortcut.1.bias | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer3.1.conv1.weight | nonzeros =     358 /  589824             (  0.06%) | total_pruned =  589466 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv1.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn1.weight  | nonzeros =     119 /     256             ( 46.48%) | total_pruned =     137 | shape = torch.Size([256])
layer3.1.bn1.bias    | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.conv2.weight | nonzeros =     320 /  589824             (  0.05%) | total_pruned =  589504 | shape = torch.Size([256, 256, 3, 3])
layer3.1.conv2.bias  | nonzeros =       0 /     256             (  0.00%) | total_pruned =     256 | shape = torch.Size([256])
layer3.1.bn2.weight  | nonzeros =      60 /     256             ( 23.44%) | total_pruned =     196 | shape = torch.Size([256])
layer3.1.bn2.bias    | nonzeros =       3 /     256             (  1.17%) | total_pruned =     253 | shape = torch.Size([256])
layer4.0.conv1.weight | nonzeros =     254 / 1179648             (  0.02%) | total_pruned = 1179394 | shape = torch.Size([512, 256, 3, 3])
layer4.0.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn1.weight  | nonzeros =     118 /     512             ( 23.05%) | total_pruned =     394 | shape = torch.Size([512])
layer4.0.bn1.bias    | nonzeros =       3 /     512             (  0.59%) | total_pruned =     509 | shape = torch.Size([512])
layer4.0.conv2.weight | nonzeros =     180 / 2359296             (  0.01%) | total_pruned = 2359116 | shape = torch.Size([512, 512, 3, 3])
layer4.0.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.bn2.weight  | nonzeros =      56 /     512             ( 10.94%) | total_pruned =     456 | shape = torch.Size([512])
layer4.0.bn2.bias    | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.0.shortcut.0.weight | nonzeros =      14 /  131072             (  0.01%) | total_pruned =  131058 | shape = torch.Size([512, 256, 1, 1])
layer4.0.shortcut.0.bias | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.0.shortcut.1.weight | nonzeros =       8 /     512             (  1.56%) | total_pruned =     504 | shape = torch.Size([512])
layer4.0.shortcut.1.bias | nonzeros =      19 /     512             (  3.71%) | total_pruned =     493 | shape = torch.Size([512])
layer4.1.conv1.weight | nonzeros =     179 / 2359296             (  0.01%) | total_pruned = 2359117 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv1.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn1.weight  | nonzeros =      40 /     512             (  7.81%) | total_pruned =     472 | shape = torch.Size([512])
layer4.1.bn1.bias    | nonzeros =       1 /     512             (  0.20%) | total_pruned =     511 | shape = torch.Size([512])
layer4.1.conv2.weight | nonzeros =     150 / 2359296             (  0.01%) | total_pruned = 2359146 | shape = torch.Size([512, 512, 3, 3])
layer4.1.conv2.bias  | nonzeros =       0 /     512             (  0.00%) | total_pruned =     512 | shape = torch.Size([512])
layer4.1.bn2.weight  | nonzeros =      17 /     512             (  3.32%) | total_pruned =     495 | shape = torch.Size([512])
layer4.1.bn2.bias    | nonzeros =      15 /     512             (  2.93%) | total_pruned =     497 | shape = torch.Size([512])
linear.weight        | nonzeros =     130 /    5120             (  2.54%) | total_pruned =    4990 | shape = torch.Size([10, 512])
linear.bias          | nonzeros =       0 /      10             (  0.00%) | total_pruned =      10 | shape = torch.Size([10])
alive: 5459, pruned : 11173303, total: 11178762, Compression rate :    2047.77x  ( 99.95% pruned)
Train Epoch: 99/100 Loss: 0.959437 Accuracy: 64.95 68.13 % Best test Accuracy: 65.04%
